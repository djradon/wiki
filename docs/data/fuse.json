{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"djradon's wiki","n":0.707},"1":{"v":"\nWelcome! And beware!  \n\n## Purpose\n\nThis vault is the \"[[learning-in-public|ar.swyx.learn-in-public]]\" part of my Second Brain. If you share some of my interests, please [reach out](https://djradon.github.io)! \n\n## Contents\n\n- [[t]] my personal wikipedia\n- [[idea]] (not necessarily mine)\n- Resource Notes, including highlights, thoughts and metadata, for various things:\n  - [[ar]] mostly articles, papers and web pages\n  - [[book]]\n  - [[community]]\n  - [[course]]\n  - [[event]]\n  - [[game]]\n  - [[loc]]\n  - [[org]]\n  - [[user]] \n  - [[prdct]] mostly software products, but also ontologies\n  - [[recipe]]\n  - [[video]] movies, tv episodes, youtube, etc\n- [[vs]]\n- [[wanted]]\n- Some \"Metadata Notes\":\n  - [[tags]] which may refer to any and multiple (or none) of the above\n  - [[c]]: ways to categorize resources\n  - [[p]]: ways to assert things about resources (mostly abandoned)\n\nIn terms of the [[t.km.zettelkasten]] method, this wiki is a commingling of literature notes with something @Sönke-Ahrens warned about: a \"personal Wikipedia or a database\" [^1]. \n\nIn terms of [[t.tm.getting-things-done]], it's references, someday-maybe, next actions, and public projects.\n\n## Beware!\n\nThis is a cluttered cupboard of jumbled jottings riddled with inaccuracies, confusion, and mistakes.\n\n## What This Is Not\n\n- evergreen-notes/digital-garden: for \"synthesized\" / original-ish publishable big-idea notes that should evolve over time, props to @andy-matuschak and @maggie-appleton\n- blog: for \"point-in-time\" items to be shared: personal news, articles, etc.\n  - e.g., [[ar.substack.carpe-noctem]]\n\n\n[^1]: [[book.how-to-take-smart-notes]]  ","n":0.069}}},{"i":2,"$":{"0":{"v":"Prct","n":1}}},{"i":3,"$":{"0":{"v":"EDTF Datatype","n":0.707},"1":{"v":"\n- https://github.com/edtf-datatype\n","n":0.707}}},{"i":4,"$":{"0":{"v":"Wanted","n":1}}},{"i":5,"$":{"0":{"v":"Vscode Frontmatter Single Quote Warning","n":0.447}}},{"i":6,"$":{"0":{"v":"Snakefarm","n":1},"1":{"v":"\n- like [[prdct.change_case_vscode]], but leaves camelCase alone","n":0.378}}},{"i":7,"$":{"0":{"v":"Modern RDF Data Editor","n":0.5},"1":{"v":"\n## Ideas\n\n- keep a cache (per-user, per dataset, per domain) of the most-used and trending properties and identifiers.\n\n## hey chatgpt, could you build a form-based (GUI) vscode extension for authoring RDF data?\n\nYes, it's definitely possible to build a form-based (GUI) VSCode extension for authoring RDF data. Here's how you could approach it:\n\n### Key Features for the Extension:\n1. **Form-Based Editing**:\n   - Create a user interface that lets users fill in forms to add or edit RDF triples.\n   - The form could include fields for the subject, predicate, object, and context (if named graphs are used).\n   - Users could select predefined vocabularies and predicates, potentially providing autocomplete suggestions.\n\n2. **Graph Visualization**:\n   - Integrate a simple graph visualization tool to provide a graphical view of RDF data.\n   - This can be implemented using libraries like **VivaGraphJS** or **D3.js** to offer a dynamic visualization of RDF data directly within VSCode.\n\n3. **Data Validation**:\n   - Add features to validate RDF data against a given schema, such as SHACL or OWL.\n   - Provide visual feedback when data does not conform to the schema, helping ensure RDF consistency.\n\n4. **Connection to Triplestores**:\n   - Enable users to connect to external RDF stores like Jena Fuseki, Stardog, or others.\n   - Allow users to load, query, and update RDF data directly from these sources, giving them more flexibility.\n\n5. **Integration with Git**:\n   - Given that many users might want to store RDF data in Git repositories, include direct Git integration for version control.\n   - Allow users to fork, commit, and merge RDF datasets directly from the extension.\n\n### Tools and Technologies to Use:\n- **VSCode API**: Use the Visual Studio Code API to create panels, form inputs, and commands. VSCode allows custom webviews, which are perfect for building form-based UIs within the IDE.\n- **React/HTML for GUI**: Use **React** or vanilla **HTML/CSS** to build the form-based UI components. VSCode's webview panels can display these forms and handle user input effectively.\n- **RDF Libraries**:\n  - **rdflib.js**: JavaScript library for parsing and serializing RDF data. This could help in handling the RDF data behind the scenes.\n  - **Turtle.js** or similar libraries can help manage serialization for various RDF formats (e.g., Turtle, JSON-LD).\n- **Data Visualization**:\n  - **D3.js** or **VivaGraphJS** to provide a visual representation of RDF triples, making it easier to understand the relationships between entities.\n- **Node.js Backend**: If needed, Node.js could be used to interact with external RDF stores or for other backend services.\n\n### Challenges:\n- **Complexity of RDF Data**: RDF can become complex quickly, especially with nested structures or ontologies. The UI would need to strike a balance between being intuitive and supporting advanced RDF capabilities.\n- **Extending Predicates and Vocabularies**: Handling various vocabularies and ensuring they’re up to date would require periodic updates or some way of fetching vocabularies dynamically.\n\n### Example Workflow:\n1. **User selects \"Create RDF Triple\" from a VSCode command palette.**\n2. **A form panel opens**, with input fields for \"Subject,\" \"Predicate,\" \"Object,\" and a dropdown for selecting a named graph (if applicable).\n3. **Validation messages** appear in real-time if the RDF input doesn’t conform to the selected schema.\n4. **Graph view** is available as a tab to visualize how new triples relate to existing ones.\n5. **Save and commit** directly to Git, with options to merge changes into a collaborative RDF dataset.\n\n### Benefits:\n- **Local-First Approach**: This extension could easily support a local-first workflow, letting users work on RDF files offline and integrate with Git for versioning.\n- **User-Friendly**: The form-based GUI could lower the barrier for users unfamiliar with RDF syntax, making semantic data authoring more accessible to non-programmers.\n\nThis kind of VSCode extension could be a very useful tool for semantic data management, especially for those who want the benefits of a GUI without leaving the VSCode environment. Let me know if you’re interested in any specific part of the development process, and I can provide more details!","n":0.04}}},{"i":8,"$":{"0":{"v":"Vs. (Comparisons)","n":0.707}}},{"i":9,"$":{"0":{"v":"Vocabulary vs Ontology vs Schema","n":0.447},"1":{"v":"\n- [[p.instanceOf]] [[c.comparison]]\n- [[p.hasComparand]] [[t.km.vocabulary]] [[t.km.ontology]] [[t.km.schema]]\n\n- > A formal ontology is a controlled vocabulary expressed in an ontology representation language. This language has a grammar for using vocabulary terms to express something meaningful within a specified domain of interest. The grammar contains formal constraints (e.g., specifies what it means to be a well-formed statement, assertion, query, etc.) on how terms in the ontology’s controlled vocabulary can be used together.\n  > - https://semwebtec.wordpress.com/2010/11/23/contolled-vocabulary-vs-ontology/\n\n## Resources\n\n- https://semwebtec.wordpress.com/2010/11/23/contolled-vocabulary-vs-ontology/\n- https://www.w3.org/wiki/SchemaVsOntology","n":0.115}}},{"i":10,"$":{"0":{"v":"TypeScript Vs JavaScript","n":0.577},"1":{"v":"\n## Opinions\n\n### You can do literally everything TS can with JSDocs\n\n By adding // @ts-check to the top of a .js file, it turns on the TS engine, which can infer types from JSDocs in the same way it does from TS. You can do literally everything TS can with JSDocs. I would strongly recommend the eslint-plugin-jsdoc. I use this ruleset:\n\n    https://github.com/tjw-lint/eslint-config-tjw-jsdoc\n\n\n### Use d.ts \n\n- https://www.reddit.com/r/vuejs/comments/st2zkt/comment/hx17byc/\n  - \" currently do both:\n\n    .d.ts for types\n\n    js files with docblocks that use those types\"\n\n## References\n\n- https://www.reddit.com/r/vuejs/comments/st2zkt/jsdoc_or_typescript/\n- ","n":0.109}}},{"i":11,"$":{"0":{"v":"Topic Vs Subject","n":0.577},"1":{"v":"\n\n\n- subject of an article tends to be singular; the \"main topic\"\n- a conversation might have a subject, but it might just touch on a bunch of topics\n\n- resources: \n  - https://citrinitas.com/topic-vs-subject-what-is-the-difference/\n","n":0.177}}},{"i":12,"$":{"0":{"v":"Three Dimensional Vs Four Dimensional Ontologies","n":0.408},"1":{"v":"\n## chatgpt4.0\n\nFour-dimensional (Perdurantist) Upper Ontologies:\n\n    SUMO\n    YAMATO\n    CIDOC CRM\n\nHybrid (Supports both 3D and 4D perspectives):\n\n    [[prdct.gfo]]\n\nPrimarily Three-dimensional (3D) with allowances for perdurants:\n\n    DOLCE\n    UFO / gUFO \n    BFO (strictly 3D for endurants)","n":0.177}}},{"i":13,"$":{"0":{"v":"Tbox Vs Abox vs MBox","n":0.447},"1":{"v":"\n- \"when writing an ontology you are often mostly defining classes and properties that you expect to reuse in lots of different sets of instance data. Thus the ontology is often mostly t-box assertions and you can think of the different instance datasets as a-boxes which will be coupled to the t-box (either explicitly with owl:imports or implicitly in your processing system). However, it is pretty common, and perfectly reasonable, for such ontologies to have a few individuals present (e.g. as symbolic labels) and so not be \"pure\" t-boxes.\"\n- \" you will /never/ find axioms that are soley TBox axiom in RDFS, since there will always be the additional RDF-inherited semantics for all the RDF triples that encode the axiom.\"\n- \"in contrast to OWL DL, in OWL Full you also never have a clear separation between the ABox and the TBox.\"\n- \"In OWL DL, classes are sets, while in RDFS a class is an individual with an associated set, the so called \"class extension\" of the individual.\"\n\n## Model Box (MBox)\n\n### @chatgpt.4\n\n- MBox \"not as standardized or widely used as the TBox and ABox\"\n- The MBox can be understood as a component that deals with the instances of models or theories defined in the TBox. It’s not about specific real-world instances (like the ABox), but rather about instances of the models or theories themselves.\n- It might involve scenarios, simulations, or hypothetical instances that are derived from the TBox but are not necessarily concrete or real-world facts like those in the ABox. The MBox can be used for testing hypotheses, running simulations, or exploring theoretical scenarios within the framework defined by the TBox.\n- In some interpretations, the MBox might also deal with meta-modeling or the representation of models about models. This can be important in more complex or layered semantic systems where you have models that are built on top of other models.\n\n\n## Resources\n\n- https://answers.knowledgegraph.tech/t/why-is-it-necessary-to-split-reasoning-into-t-box-and-a-box/4631\n- https://www.mkbergman.com/489/ontology-best-practices-for-data-driven-applications-part-2/\n- ","n":0.056}}},{"i":14,"$":{"0":{"v":"Structurizr Vs D2 vs Ilograph","n":0.447},"1":{"v":"\n## [[c.comparand]]\n\n- [[prdct.structurizr]]\n  - $25/mo ($5/mo per workspace)\n  - layers\n  - separate model \n- [[prdct.d2]] (and [[prdct.terrastruct]])\n  - $20/mo (per user)\n  - markdown\n  - structured data / [[t.cs.modeling.entity-relationship-diagram]]\n  - animation\n  - Using D2, you can create diagrams that declare shapes, connections, containers, and special objects. You can also make more customizations via programming that covers strings, comments, and overrides.\n  - flowcharts, state diagrams, and entity-relationship diagrams\n- [[prdct.ilograph]]\n\n\n## [[p.begsQuestion]]\n\n- are d2's multiple boards equivalent to multiple levels / containers in structurizr's model?\n\n\n## References\n\n- https://blog.logrocket.com/complete-guide-declarative-diagramming-d2/\n- https://www.baeldung.com/structurizr\n\n","n":0.109}}},{"i":15,"$":{"0":{"v":"Spade Vs Pade","n":0.577},"1":{"v":"\n\nattribute | Spade | Pade\n---------|----------|---------\n commits | 1766 | 226\n contribs | 16 | 15\n last | 2023-06-13 | 2022-10-25\nlicense | mit | mit\nfipa | Y | Y\n","n":0.189}}},{"i":16,"$":{"0":{"v":"Schema Vs Data Mode","n":0.5}}},{"i":17,"$":{"0":{"v":"Resources That Refer Vs Resources That Are","n":0.378},"1":{"v":"\n- aka: \n  - indicator vs resource\n  - sense vs content\n  - httpRange-14\n\n## Possibilities\n\nThere are four possibilities for a given URI:\n\n- the URI is being used to locate some content\n- the URI is being used to refer to a sense\n- the URI is being used to identify either content or sense but it’s not specified which\n- the URI is being used to both locate content and refer to a sense (ie a property applies equally to both)\n\n## Issues\n\n- one subtle issue: do content IRIs always have a sense, i.e., the abstract work that corresponds to the document\n- t.2024.09.21.13 or better to say that URIs that refer to a sense should also be able to return a document/thing that is\n  - would lead to the conclusion that by default, IRIs should be considered to refer to senses\n\n## Solutions\n\n- `#this` https://stackoverflow.com/questions/76470569/the-puzzling-semantics-of-rdftype\n- 303 \n- homegrown #1: \n  - use  anyIRI literals for referring to the information resource (so never in subject position)\n    - so if you want to say something about a resource, you have to reify it first\n  - otherwise, IRIreferences always are indicators/sense\n  - if you need to talk about something in the object position, refer to it indirectly\n- homegrown #2: \n  - always sense\n  - if you want to refer to a document or other ContentLocator, give it an indicator (e.g., using [[ko.relation-types.LocatableContent]])\n- link tag\n  - see [[proj.tomitc.drafts.solving-httprange-14]]\n\n## Thoughts\n\n- you could make sure \"sense\" URIs are just never resources/documents/content,\n  - maybe a LOD site has an indicator subdomain and a resource domain, indicator.stagecraft.io and content.stagecraft.io; or probably better, stagecraft.io/i/... and stagecraft.io/content\n  - t.2024.07.10.12 booooo! \n\n## Discussion\n\n\n\n- \"surely the distinction between a network-retrievable information resource and \"everything else\" is of fundamental importance to the whole architecture of the Web\"\n- \"**Distinguishing between Representations and Descriptions** using URIs, it is possible to identify both a thing (which may exist outside of the Web) and a Web document describing the thing... According to W3C guidelines ([AWWW], section 2.2.), we have a Web document (there called information resource) if all its essential characteristics can be conveyed in a message. Examples are a Web page, an image or a product catalog... The first solution is to use “hash URIs” for non-document resources... a URI that includes a hash cannot be retrieved directly, and therefore does not necessarily identify a Web document... The second solution is to use a special HTTP status code, 303 See Other, to give an indication that the requested resource is not a regular Web document.\"\n  - [[ar.w3.cool-uris]] \"https://www.w3.org/TR/cooluris/\"\n- \"the problem surfaces when IRIs are used to identify both a representation, i.e., the bytes on the wire, and an abstract resource such as a person.\" \n  - \"commonly known as the httpRange-14 issue [81], the identifier assigned by the W3C’s Technical Architecture Group (TAG) in its issue tracker. The resolution of that issue was an advice to the community [82] to either use fragment identifiers or HTTP 303 See Other redirects to signal that an IRI identifies an abstract resource (formally known as a non-information resource), such as a person, instead of the returned representation, i.e., the document describing the person.\"\n  - \"The most promising proposals at the time of this writing involve “punning” to use the same IRI to mean different things. They use the context in which an IRI is used to determine whether the representation or the abstract concept is meant.\"\n  - \n\n## Possible Solutions\n\n- the syntactic structure of the URI itself can indicate whether the URI is a subject address or a subject identifier; or else the syntactic context in which the URI is used can determine its role\n\n### 303 redirects\n\n- \"use a 303 See Other redirection to a URI whose content (which is the only sense of the URI in this design, remember) describes the original URI\"\n\n### Hash URI\n\nThis gives a very similar pattern to the 303 redirect, as you can see from the diagram below; the only difference is that instead of following a 303 See Other redirection to get from one URI to the other, you can use URI parsing: you chop off the fragment part of the URI and perform a GET on the resulting URI to get a description.\n\nSee [[vs.hash-vs-slash]]\n\n### Property determines content vs sense\n\n- \"The property itself determines whether it applies to the content located by the URI (the page) or a sense referred to by the URI (in this case, the thing the page describes)\"\n  - \"Some properties have a defined domain or range that precludes the property from being used to annotate content.\" but others don't, e.g. cc:license has a domain of cc:work\n- \"To support “punning”, therefore, RDF vocabulary designers would need to have additional properties that could be applied to RDF Properties to indicate how their subject (and object where applicable) should be interpreted.\"\n\n#### Ideas from Topic Maps\n- [subject indicators] divided into:\n  - 1. resourceRef (subject address)\n  - 2. subjectIndicatorRef (subject indicator)\n\n### For [[semantic_md]] \n\n\n\n\n\n## Thoughts\n\n- is it the same as \"[interpretation vs representation](https://w3c.github.io/rdf-star/UCR/rdf-star-ucr.html#distinguish-interpretation-from-representation)\"\n- > RDF has not been clear about whether a URI like \"http://www.w3.org/Consortium\" identifies the W3C or a web page about the W3C \n- notes/URIs/RRIs that refer to things (people, books, articles) \n  - could be called:\n    - reference notes\n    - pointer notes\n  - could further differentiate notes that refer to topics / abstract things\n- notes/URIs/RRIs that are actual things (daily notes, task items, statements, (unpublished) articles, blogs)\n    - could be called\n      - resource notes\n\n## what things that refer have in common with things that are\n\n- can have sense of \n  - \"Bibliography\": other resources related to the thing this note/resource refers to\n  - \"Footnote\": the things that appear in this note can be attributedTo an external resource\n- need different predicates for both senses\n\n\n## Notes (in the Dendron sense)\n\n- differentiate between notes that represent something (e.g. topics, solutions) and notes that are something (vs, journal)\n  - comes down to \"is about\" something vs \"is (a literary) something\"?\n    - could come down to resources being terms (instead of topics) [[vs.terms-vs-topics]]\n      - and contextual terms at that\n    - literary because the only things that refer to something and also are the something they refer to (self-referentiality) are\n      - literature\n      - symbols\n      - computer programs (and some pointers?)\n      - maybe logical statement\n  - using `type` for both seems wrong \n  - article is interesting b/c it can be both\n  - this is different that the class-individual confusion\n  - how much does it really matter?\n  - I guess resources that are something are just a special case (subset)  of the resources that represent something  ^AQ6h3rFksAfc\n\n## URIs / URLS\n\n- easier to judge from context: is the domain/range of the predicate a IRI? If not, it's about the thing the subject/object IRI refers to\n\n## Resources\n\n- \"maybe need to specify whether the note a subject unto itself or an identifier for another subject\"\n- [ ] [[p.summarized]] [Disambiguating RDF Identifiers](https://www.w3.org/2002/12/rdf-identifiers/) #to-read\n- [ ] [[p.summarized]] https://w3c.github.io/rdf-star/UCR/rdf-star-ucr.html#distinguish-interpretation-from-representation\n- [1]: [[ar.ontopia.curing-the-webs-identity-crisis]]\n\n\n## References\n\n- [[ar.third-generation-web-apis-bridging-the-gap-between-rest-and-linked-data]]\n- http://www.jenitennison.com/2012/05/11/using-punning-to-answer-httprange-14.html\n- https://stackoverflow.com/questions/22916998/rdf-303-redirect-clarification\n- https://stackoverflow.com/questions/76470569/the-puzzling-semantics-of-rdftype\n","n":0.03}}},{"i":18,"$":{"0":{"v":"Log","n":1},"1":{"v":"\n## t.2023.12.10.05\n\nremoved:\n```\n- when regular links (raw URL, URL in angle brackets, or URL in parentheses after single-square link text, aka markdown-style links) for subjects, predicates, and objects, they are always resourceRefs\n- wikilinks to notes in the local workspace (LRIs?) or URIs [[https://www.markdownguide.org/basic-syntax/]] are always used as subjectIndicatorRef\n  - so you can't say anything about notes themselves?\n    - maybe you put it in the frontmatter\n    - maybe you create a second, special \"ar\" note.\n    - maybe a special syntax to treat local\n      - maybe <http:///vs.rdfs-vs-owl.md>\n- if you want to say something about something that's not addressable\n  - create a note for it\n  - but I wanna use  an \"indicator note\" that someone else has made? Or I made and published on the web somewhere, and it's not in my local workspace\n    - make a new local note, point it at the indicator note. \n- `prdct.toml` is kinda an identifier; unlike a corresponding note in the topic hierarchy, it won't change\n- differentiate resources that are addressable with `hasURL` - but not sure if that helps\n```\n\n## t.2024.01.19.06\n\n- I'm almost ashamed that this contrast has remained so murky for so long. There are two separate issues:\n  1. for identifiers, are we identifying a web document or something that exists separately\n  2. for web documents, are they about something else or are they their own thing\n  \n### #1 \n\n- URL-like identifiers might return a document.\n  - Is there an issue of \"how would you refer to that document\", in case you wanted to?\n  - How does that document unambiguously convey that \"the URL you requested is (primarily?) an identifier\"\n\n### #2\n\n- is it just as easy as \"everything is its own thing, but some web documents (like wiki pages) have essentially a single subject (likely specified as the title, but that could be specified in metadata by using an identifier), as well as one or more topics; and some things dont\"\n- Maybe the issue is \"is a note a definition/model\" of something, i.e. an \"expression\" in WEMI parlance. \n\n### Examples\n\n- Does a daily journal note have a subject? Is its subject \"Dave's January 19th\"? Or is it \"Some things Dave thought and did (or wrote) on January 19th\"?\n- ","n":0.053}}},{"i":19,"$":{"0":{"v":"Rdfs Vs Owl","n":0.577},"1":{"v":"\n## vs RDF\n\n- The RDF vocabulary provides you terms for defining/describing instances.\n\nThe RDFS vocabulary provides you terms for defining/describing classes.\n\n## vs OWL\n\n> OWL = RDFS + more semantic features like cardinalities, union, intersection and more reasoning and inferring possibilities.\nIt may be sufficient to use RDFS if you just need to manipulate class hierarchies and data-types, but if you need more specific semantics (DL-based) , OWL is a better option.\n\n## Resources\n\n- https://www.researchgate.net/post/What-is-the-difference-between-RDF-Schema-and-Ontology-OWL\n- https://cambridgesemantics.com/blog/semantic-university/learn-owl-rdfs/rdfs-vs-owl/\n- https://link.springer.com/book/10.1007/978-3-540-92673-3\n- https://lists.w3.org/Archives/Public/semantic-web/2010Jun/0094.html and https://lists.w3.org/Archives/Public/semantic-web/2010Jun/0095.html","n":0.115}}},{"i":20,"$":{"0":{"v":"Rdf Statement Vs Assertion","n":0.5},"1":{"v":"\n- related: [[prdct.rdf]] \n\n## Description\n\n### Chatgpt4.o\n\nIn the context of **RDF** and **semantic web technologies**, the terms **assertion** and **statement** are closely related, but they can have slightly different connotations depending on the emphasis.\n\n### Statement\n- A **statement** in RDF refers to a **triple** consisting of a subject, predicate, and object.\n- It describes a piece of information that connects a subject and an object through a specific predicate. For example, the RDF triple `:Alice :knows :Bob` is an RDF statement about Alice and Bob.\n- Essentially, an RDF statement is the **data representation** of a relationship.\n\n### Assertion\n- An **assertion** implies that a **claim is being made** about the relationship between resources. When you make an RDF statement, you are asserting that the relationship described is **true** (or at least that you want it represented as if it were true).\n- In semantic web terminology, assertions are essentially the **truth claims** that a dataset makes. For example, by stating `:Alice :knows :Bob`, you are asserting that this relationship exists.\n- The term \"assertion\" emphasizes the **intent** of the statement—that the relationship is a **factual claim** in the context of the data model.\n\n### Practical Differences\n- **Statement** is a more **neutral** term, referring to the components of RDF data.\n- **Assertion** adds the nuance that the statement is a claim about the real world or the domain being described. In other words, an assertion implies the statement is **believed** or **intended** to reflect some truth.\n\n### Example\n- Suppose you have the RDF triple `:Earth :isPartOf :SolarSystem`.\n  - As a **statement**, this is just a structured piece of data in RDF format.\n  - As an **assertion**, it is a declaration that there is a fact being communicated: Earth is part of the Solar System.\n\n### Summary\n- Every **assertion** is a **statement**, but not all uses of the term \"statement\" imply an assertion (for example, if you're just describing the structure).\n- Assertions carry a sense of **truth** or **intent**, whereas statements are purely structural.\n\nThis subtle distinction can be important in the semantic web when discussing how RDF graphs are used to represent knowledge or when differentiating between merely storing data and making factual claims about the data.","n":0.053}}},{"i":21,"$":{"0":{"v":"Rdf Properties Vs Predicates","n":0.5},"1":{"v":"\n## Description\n\n- @chatgpt.4o: \"a predicate is the position in the triple, and a property is the resource that occupies that position.\"\n- properties: predicates or attributes\n  - but it's a fuzzy line. [[book.demystifying-owl-for-the-enterprise]] says dates are attributes, like \"created\", because it's a literal... but you can (and [[gd]] does) represent dates and times as entities\n- one of the biggest mistake of RDF: predicates are ??\n  - 2021-11-07 don't remember what I was going to say here, but likely something about how predicates supposedly express properties, when really they just express predicates (i.e., part of a property)\n- \"In RDF, a predicate is something that is in the second position of a triple. RDF have no way of referring to positions in triples, so you cannot use a property between two predicates. What is certainly meant by the OP is \"can we use owl:sameAs between two properties\". Properties can be identified with IRIs, IRIs can occur anywhere in a triple, subject and object can be related by way of a predicate, and any IRI are allowed in any position of a triple. So, syntactically speaking, it is allowed to relate two properties with owl:sameAs.\"\n\n\n- [[p.isRelated]] [[vs.property-graphs-vs-semantic-graphs]]\n\n## thoughts\n\n- 2021-11-07 : the predicate kinda corresponds to the \"attribute\" part of \"attribute-value pairs\"; property feels like it should correspond to a concrete attribute-value pair, not just a predicate. \n- some classes have default \"getter/setter\" verbs, that's kinda properties. so I can see \"The predicate indicates a binary relation, also known as a property.\"\n- \"The predicate indicates a binary relation, also known as a property.\"\n  - this is the kinda opposing what I've been thinking: the relation is the property, as opposed to the resource\n\n\n## references\n\n- https://www.mdpi.com/2073-8994/12/1/84/htm\n- https://www.wikidata.org/wiki/Wikidata:Relation_between_properties_in_RDF_and_in_Wikidat\n- [[ar.maverickphilosopher.predicates-and-properties]]\n- https://www.reddit.com/r/askphilosophy/comments/2z17hx/the_difference_between_a_property_and_a_predicate/","n":0.059}}},{"i":22,"$":{"0":{"v":"Put Vs Post","n":0.577},"1":{"v":"\nWhen one uses the POST operation is used to create a resource on the server, the resource is created as a subordinate resource to the URL that the POST operation provides. This places HTTP PUT vs. POST methods in stark contrast, as the PUT operation requires the exact URL of the resource to be created or updated.\n\n## References\n\n- https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/PUT-vs-POST-Whats-the-difference","n":0.13}}},{"i":23,"$":{"0":{"v":"Property Vs Attribute Vs Field","n":0.447},"1":{"v":"\n\n\n- [[p.hasContext]] \n  - [[t.cs.programming]]\n    - field: data member of a class, usually private; A class or struct may have instance fields or static fields or both\n    - attribute: public field, maybe accessed directly\n    - property: might be backed by a field\n      - interfaces can have properties but not fields\n  - [[t.phil.metaphysics]]\n    - property: something inherent about a thing, especially how it behaves under particular conditions, e.g. hardness\n    - attribute: additional info about a thing, e.g. applicability for furniture making\n\n\n## Thoughts\n\n- strength: 18 \n  - may look like an attribute, but is has a very specific context. you could specify that in a schema, but given how special strength is, each possible value is its own thing, not just a primitive, but a hook to hang your hat on.\n  - although, Strength scores cap out at 30 (20 for PCs relying on ability score increases).\n\n\n## Resources\n\n- https://stackoverflow.com/questions/295104/what-is-the-difference-between-a-field-and-a-property\n","n":0.082}}},{"i":24,"$":{"0":{"v":"Property Graphs Vs Semantic Graphs","n":0.447},"1":{"v":"\n- [[p.hasComparand]]\n  - [[t.cs.graph.semantic-graph]]\n  - [[Property Graph|t.cs.graph.property-graph]]\n\n\n## thoughts\n\n- they can be mapped to each other [^2]\n- property graphs support key-value pairs on entities and relationships\n  - \"Naturally annotated edges instead of inconvenient reification in knowledge graphs.\" [^1]\n  - but values are not other nodes\n- [when semantic graphs support reification, aren't they essentially the same?][1]\n  - maybe, and I think predicates are adequate to represent key-value pairs on\n    - subjects/objects (aka \"things\" or, in graph theory, [[gd.concepts.nodes]])\n- for time travel, maybe could be nice to have properties for valid datetimes\n\n## Related\n\n- [1]: [[ar.forbes.when-graphs-collide-the-coming-merger-of-property-and-semantic-graphs]]\n- [ ] http://blog.liu.se/olafhartig/2019/01/10/position-statement-rdf-star-and-sparql-star/\n- https://tdan.com/knowledge-graphs-vs-property-graphs-part-1/27140\n\n\n## Resources\n- https://dzone.com/articles/rdf-triple-stores-vs-labeled-property-graphs-whats\n  - \"RDF Can Have Multivalued Properties and the Labeled Property Graph Can Have Arrays\"\n- https://www.wisecube.ai/blog/knowledge-graphs-rdf-or-property-graphs-which-one-should-you-pick/\\\n  \n## References\n\n- https://flur.ee/fluree-blog/rdf-versus-lpg/\n\n[^1]: https://docs.arcadedb.com/#Graph-Database\n[^2]: https://protegeproject.github.io/owl2lpg/\n\n","n":0.092}}},{"i":25,"$":{"0":{"v":"Product Vs Solution","n":0.577},"1":{"v":"\n## [[p.hasExample]]\n\n- [\"When paired with a screw (another product) and a carpenter (a service), the screwdriver is part of a solution for building a home.\"][4]\n\n\n## thoughts\n\n- \"problems\" is just so negative\n  - [some sources][2] refer to \"business problems or opportunities\"\n    - need a name/Class for those two things\n- features can be solutions too\n  - sometimes you don't need a full product to solve a problem\n    - some might argue that \n  - if you buy \"capabilities are collections of features\", then capabilities can also be solutions. \n\n![[ar.juliandunn.whats-a-solution-vs-a-product]]\n\n## [[p.hasComparison]]\n\n- https://hackernoon.com/products-and-solutions-do-you-know-the-difference-4ff9169cefe3\n\n## References\n\n- [2]: https://netmind.net/en/course/use-case-modeling/\n- [3]: https://help.sonatype.com/docs/solutions-vs.-products\n- [4]: https://hackernoon.com/products-and-solutions-do-you-know-the-difference-4ff9169cefe3\n","n":0.102}}},{"i":26,"$":{"0":{"v":"Problem Vs Opportunity","n":0.577},"1":{"v":"\n\n\n## Resources\n\n- https://blog.sourcerer.io/problem-solution-vs-opportunity-4c4f70ce2fc0\n  - \"all problems are opportunities... but not all opportunities are problems\"\n    - [[eg]] of opportunities\n      - google \n      - automobile\n      - facebook\n      - television\n    - ultimately, not compelling examples; those things solved lots of problems; sure 1-to-1 isn't there\n- https://www.forbes.com/sites/glennllopis/2012/04/09/every-problem-is-the-same-just-packaged-differently/?sh=57b37d342d64\n  - put simply \"don't use opportunity as a euphemism for problem\"\n","n":0.136}}},{"i":27,"$":{"0":{"v":"Polyhierarchy Vs Heterarchy","n":0.577},"1":{"v":"\n## chatgpt4.o\n\n- **Polyhierarchy** and **heterarchy** are both terms used to describe different structures of organization or classification, especially in contexts like ontologies, taxonomies, and networked systems. While they share similarities in their flexibility and complexity, they have distinct meanings:\n\n### Polyhierarchy:\n\n- **Definition**: Polyhierarchy refers to a structure where a single entity can belong to multiple parent categories or classes. This means that an entity can be classified in more than one place within a hierarchical system.\n\n- **Characteristics**:\n  - **Multiple Inheritance**: An entity can inherit characteristics or properties from more than one parent class.\n  - **Complex Relationships**: Polyhierarchies allow for more complex relationships and categorizations because they can represent entities that logically belong in multiple categories.\n  - **Example in Ontologies**: In a polyhierarchical ontology, a concept like \"Amphibian\" might be categorized under both \"Aquatic Animals\" and \"Terrestrial Animals\" because it has characteristics of both groups.\n\n- **Use Cases**:\n  - **Medical Ontologies**: A medical condition might be classified under multiple systems (e.g., both a respiratory disorder and an infectious disease).\n  - **Library Systems**: A book might be classified under multiple genres (e.g., both \"Science Fiction\" and \"Fantasy\").\n\n### Heterarchy:\n\n- **Definition**: Heterarchy refers to a non-hierarchical structure where elements have multiple, non-linear relationships with one another. In a heterarchical system, no single entity or class is inherently above or below another, and relationships are often lateral or networked.\n\n- **Characteristics**:\n  - **No Strict Hierarchy**: Unlike in a hierarchy, there is no single root or top level; entities can be interconnected in various ways, without a clear top-down structure.\n  - **Flexible Organization**: Heterarchies allow for more flexible and dynamic relationships between entities, which can change based on context or interaction.\n  - **Example in Social Systems**: A heterarchical organization might be a network of professionals where no single person is in charge, but each has connections to multiple others based on expertise, collaboration, or other criteria.\n\n- **Use Cases**:\n  - **Neuroscience**: The human brain is often described as a heterarchical system, where different regions are interconnected in complex ways, with no strict hierarchy governing their interactions.\n  - **Organizational Structures**: Some modern organizations adopt heterarchical structures where decision-making is distributed, and roles are fluid, allowing for adaptability and collaboration.\n\n### Summary of Differences:\n\n- **Polyhierarchy**:\n  - Involves a hierarchical structure where entities can belong to multiple parent categories.\n  - Maintains a hierarchical organization but allows for multiple inheritance.\n  - Useful in complex classification systems where entities naturally fit into multiple categories.\n\n- **Heterarchy**:\n  - Involves a networked or lateral structure with no strict top-down hierarchy.\n  - Allows for flexible, non-linear relationships between entities.\n  - Useful in systems where relationships are dynamic, context-dependent, and non-hierarchical.\n\nBoth polyhierarchy and heterarchy are valuable for organizing complex information, but they cater to different needs and types of relationships. Polyhierarchy is more suited to structured classifications with overlapping categories, while heterarchy is ideal for systems where relationships are more fluid and multidimensional.\n\n## could a polyhierarchy have multiple top-items? or would that be a heterarchy?\n\nA polyhierarchy can have multiple top items and still be considered a polyhierarchy, as long as the overall structure remains hierarchical (i.e., entities are organized into levels or categories, with relationships that respect a top-down or parent-child structure). On the other hand, a heterarchy is characterized by the lack of such hierarchical organization, favoring a more network-like structure where there are no fixed top items.","n":0.043}}},{"i":28,"$":{"0":{"v":"Owl-Full vs KIF","n":0.577},"1":{"v":"\n- [[p.hasComparand]] [[prdct.owl.full]] [[prdct.kif]]\n\n## can you give examples of \"upper ontology\" or \"foundational ontology\" things that can't be expressed in OWL but can be expressed in KIF?\n\nUpper ontologies, also known as foundational ontologies, aim to provide a high-level, abstract framework that can be used to describe a wide range of more specific domain ontologies. Knowledge Interchange Format (KIF) is more expressive than OWL (Web Ontology Language) and can handle certain concepts that OWL struggles with. Here are some examples of concepts that are difficult or impossible to express in OWL but can be expressed in KIF:\n\n1. **Higher-Order Logic**:\n   - **OWL Limitation**: OWL is based on Description Logics, which are a subset of first-order logic. OWL cannot represent higher-order logic, such as properties of properties or classes of classes.\n   - **KIF Capability**: KIF supports higher-order logic, allowing expressions like \"A property of the property 'color' is that it can take multiple values\" or \"A class of classes.\"\n\n2. **Meta-modeling**:\n   - **OWL Limitation**: OWL struggles with meta-modeling, where classes are treated as instances of other classes (also known as \"punning\").\n   - **KIF Capability**: KIF can naturally express meta-level relationships, such as \"The class 'Vehicle' is an instance of the meta-class 'Concept'.\"\n\n3. **Complex Rules and Constraints**:\n   - **OWL Limitation**: OWL has limited expressiveness for complex rules and constraints. While SWRL (Semantic Web Rule Language) extends OWL, it is still not as expressive as some needs require.\n   - **KIF Capability**: KIF can express complex rules and constraints without the limitations present in OWL. For example, conditional statements involving multiple variables and their relationships can be easily expressed in KIF.\n\n4. **Non-monotonic Reasoning**:\n   - **OWL Limitation**: OWL assumes monotonic reasoning, meaning once something is true, it is always true. It cannot easily represent exceptions or default reasoning.\n   - **KIF Capability**: KIF supports non-monotonic reasoning, allowing for expressions like \"Typically, birds can fly, but penguins cannot.\"\n\n5. **Quantification Over Properties**:\n   - **OWL Limitation**: OWL does not support quantification over properties, such as \"For all properties, if they apply to A, they also apply to B.\"\n   - **KIF Capability**: KIF can handle quantification over properties, allowing more complex and abstract relationships to be modeled.\n\n6. **Arithmetic and Mathematical Functions**:\n   - **OWL Limitation**: OWL has limited support for arithmetic and other mathematical functions.\n   - **KIF Capability**: KIF can express complex mathematical relationships and functions, such as \"The sum of the values of properties X and Y must be greater than 10.\"\n\n### Example Expressions:\n\n1. **Higher-Order Logic in KIF**:\n   ```lisp\n   (forall (?property ?class)\n     (=> (and (property ?property)\n              (class ?class))\n         (exists (?meta-class)\n           (and (instance ?property ?meta-class)\n                (meta-class ?meta-class)))))\n   ```\n\n2. **Meta-modeling in KIF**:\n   ```lisp\n   (instance Vehicle Concept)\n   ```\n\n3. **Complex Rule in KIF**:\n   ```lisp\n   (forall (?x ?y)\n     (=> (and (Person ?x)\n              (Vehicle ?y)\n              (owns ?x ?y))\n         (responsible-for ?x ?y)))\n   ```\n\n4. **Non-monotonic Reasoning in KIF**:\n   ```lisp\n   (default (forall (?x)\n     (=> (Bird ?x)\n         (canFly ?x))))\n   (=> (Penguin ?x)\n       (not (canFly ?x)))\n   ```\n\n5. **Quantification Over Properties in KIF**:\n   ```lisp\n   (forall (?A ?B)\n     (=> (forall (?property)\n           (=> (applies ?property ?A)\n               (applies ?property ?B)))\n         (similar ?A ?B)))\n   ```\n\n6. **Mathematical Function in KIF**:\n   ```lisp\n   (forall (?x ?y)\n     (=> (and (valueOf ?x ?X)\n              (valueOf ?y ?Y))\n         (> (+ ?X ?Y) 10)))\n   ```\n\nThese examples illustrate the greater flexibility and expressive power of KIF compared to OWL, making it more suitable for certain advanced ontological modeling tasks.\n\n\n## can't owl-full accomodate properties of properties, classes of classes, and classes as instances of other classes (aka metaclasses).\n\nYes, OWL Full can indeed accommodate properties of properties, classes of classes, and classes as instances of other classes (also known as metaclasses). OWL Full is a syntactic extension of OWL DL that does not impose any restrictions on the use of RDF constructs. Here’s a closer look at how OWL Full handles these concepts:\n\n### Properties of Properties\n\nIn OWL Full, you can treat properties as instances and define properties of properties. For example, you can state that a property `hasColor` has another property `colorCategory`.\n\n```rdf\n:hasColor rdf:type rdf:Property .\n:colorCategory rdf:type rdf:Property .\n:hasColor :colorCategory :primaryColor .\n```\n\n### Classes of Classes\n\nOWL Full allows classes to be members of other classes. This can be used to create a hierarchy of metaclasses.\n\n```rdf\n:Vehicle rdf:type rdfs:Class .\n:Car rdf:type :Vehicle .\n:Truck rdf:type :Vehicle .\n:VehicleClass rdf:type rdfs:Class .\n:Vehicle rdf:type :VehicleClass .\n```\n\n### Classes as Instances of Other Classes (Metaclasses)\n\nIn OWL Full, you can make a class an instance of another class. This is useful for meta-modeling where you need to represent classes as instances.\n\n```rdf\n:Person rdf:type rdfs:Class .\n:Employee rdf:type :Person .\n:PersonClass rdf:type rdfs:Class .\n:Person rdf:type :PersonClass .\n```\n\n### Limitations and Considerations\n\nWhile OWL Full provides the flexibility to handle these constructs, it comes with certain trade-offs:\n\n1. **Decidability**: OWL Full is undecidable, meaning that reasoning tasks (like consistency checking or classification) might not terminate.\n2. **Tool Support**: Not all OWL tools fully support OWL Full due to its complexity and lack of computational guarantees.\n3. **Reasoning Performance**: Even if a tool supports OWL Full, reasoning might be significantly slower compared to OWL DL or OWL Lite.\n\n### Practical Implications\n\nFor many practical applications, the expressiveness of OWL Full might be necessary despite its limitations. However, if decidability and performance are critical, it might be beneficial to look into hybrid approaches or use OWL DL in combination with rule-based extensions like SWRL (Semantic Web Rule Language) for additional expressiveness.\n\n### Comparison to KIF\n\nWhile OWL Full extends the capabilities of OWL DL significantly, KIF (Knowledge Interchange Format) still offers even greater expressiveness. KIF allows for arbitrary logical expressions, including those beyond first-order logic, such as higher-order logic and more complex constraints that OWL Full cannot express directly.\n\n### Conclusion\n\nOWL Full can indeed handle properties of properties, classes of classes, and classes as instances of other classes, making it a powerful option for certain types of ontological modeling. However, it’s important to weigh its advantages against the potential downsides of undecidability and performance implications.","n":0.032}}},{"i":29,"$":{"0":{"v":"Noumenal Vs Phenomenal Objects","n":0.5},"1":{"v":"\n- related: [[t.phil.qualia]]\n\n![[ar.a-brief-note-on-how-phenomenal-objects-relate-to-objects-themselves#^2a0y73y0gq9x]]\n\n## Description\n\n- interlocutor: @chatgpt.4o\n\nThe terms **noumenal** and **phenomenal objects** are rooted in the philosophy of **Immanuel Kant**, specifically his work in **\"Critique of Pure Reason\"**. These terms represent two different aspects of reality, distinguished by the **limits of human perception** and understanding.\n\n### 1. **Phenomenal Objects**:\n   - These are the objects that we experience and perceive in the world through our **senses**. In Kant's philosophy, the **phenomenal realm** refers to the **world as we experience it**, where objects are shaped by our sensory input and mental faculties.\n   - The **phenomenon** is how things **appear** to us, not necessarily how they exist in themselves. According to Kant, human beings do not perceive the world directly; instead, we experience it through a \"filter\" of mental structures (space, time, causality) that allow us to make sense of sensory data.\n   - Example: A tree as you see it (with color, shape, texture) is a **phenomenal object**, which exists in your perceptual world.\n\n### 2. **Noumenal Objects**:\n   - Noumenal objects exist in the **noumenal realm**, which is the world as it exists **independently of human perception**—the **thing-in-itself** (or **Ding an sich** in German). Noumena are objects that exist, but they are beyond our capacity to know directly because they do not appear to us through sensory experience.\n   - Kant argues that we cannot have direct knowledge of **noumenal objects** because our faculties of perception and understanding (space, time, causality) are limited to the phenomenal world. The noumenal realm is what lies **beyond** our experience, a domain that we can speculate about but never truly access.\n   - Example: The **tree-in-itself**—the ultimate reality of the tree that exists independently of how it appears to you—is a noumenal object. \n\n### Distinction:\n- **Phenomenal objects** are objects as **we perceive them** through sensory experience, influenced by human cognition and perception.\n- **Noumenal objects** are objects as they **exist independently** of our perception, in a realm beyond human understanding.\n\nKant's distinction is crucial to his theory of knowledge, as he believes that we can never have direct access to the noumenal world but are confined to knowledge about the **phenomenal world**—the world of appearances shaped by our perception. This distinction between the phenomenal and noumenal realms is central to his epistemology and metaphysics. \n\n\n\n## References\n\n- [[ar.a-brief-note-on-how-phenomenal-objects-relate-to-objects-themselves]]","n":0.052}}},{"i":30,"$":{"0":{"v":"Node Based Game Servers","n":0.5},"1":{"v":"\n\n\n- [[p.hasComparand]] [[prdct.colyseus]] [[prdct.actionhero]] \n- resources:  https://www.npmtrends.com/actionhero-vs-colyseus-vs-pinus-vs-pomelo-vs-lance-gg\n- [[prdct.colyseus]] \n  - supports Unity\n  - development may have stalled (2022-01-22)\n- [[prdct.actionhero]]\n  - a web framework, not a game server\n- [[prdct.lance]]\n","n":0.189}}},{"i":31,"$":{"0":{"v":"Nats Jetstream Vs Memphis","n":0.5},"1":{"v":"\n\n\n## Resources\n\n- https://docs.memphis.dev/memphis/memphis/comparisons/nats-vs-memphis\n\n\n## References\n\n- https://docs.nats.io/nats-concepts/overview/compare-nats","n":0.447}}},{"i":32,"$":{"0":{"v":"Narrativist Vs Gamist Vs Simulationist","n":0.447},"1":{"v":"\n## References\n\n- https://www.reddit.com/r/rpg/comments/41bmv1/difference_between_simulationist_and_gamist/","n":0.577}}},{"i":33,"$":{"0":{"v":"Metaverse Vs Multiverse","n":0.577},"1":{"v":"\n![[t.cs.metaverse#metaverse]]\n\n![[t.multiverse#multiverse-cultural]]\n\n\nIn short, the metaverse is about **digital experiences**, while the multiverse is **a collection of cultural and literary realities**.\n\n","n":0.229}}},{"i":34,"$":{"0":{"v":"Metatype Vs Powertype","n":0.577},"1":{"v":"\n## chatgpt4.o\n\nThe concepts of **metatype** and **powertype** are both related to multi-level modeling, but they address different aspects of abstraction and classification in modeling systems. Here's a breakdown of their differences:\n\n### 1. **Metatype**:\n- **Definition**: A **metatype** is a **class that classifies other classes**. It exists at a higher level of abstraction and defines the types of classes. \n- **Purpose**: The purpose of a metatype is to create **meta-levels** where classes themselves are treated as instances of higher-level entities. This is often used in ontologies and modeling systems to distinguish between different levels of classification.\n- **Example**: In a meta-modeling system, if **Person** is a class, a **Metaclass** could be **EntityType**, which defines the structure and behavior of all classes like **Person**, **Car**, or **Organization**. These classes are instances of the **Metaclass**.\n\n- **Structure**: \n   - **Instance (M0)**: A specific person, such as \"John.\"\n   - **Class (M1)**: **Person** class, which defines properties like name and age.\n   - **Metaclass (M2)**: **EntityType**, which defines the concept of a class, including its structure and rules for defining classes like **Person**.\n\n### 2. **Powertype**:\n- **Definition**: A **powertype** is a **class whose instances are subclasses** of another class. In essence, a powertype classifies **types** of a particular class.\n- **Purpose**: The powertype concept is used when you need to distinguish between different **types** (or \"subtypes\") of a given class and manage their shared properties at a higher level of abstraction. It captures both the common features of these types and their distinct variations.\n- **Example**: In the example you mentioned:\n   - **Car_Model** is the **powertype** of **Car**.\n   - Instances of **Car_Model**, such as **2CV_Model**, represent specific car models, which are types of **Car**.\n   - **2CV_Model** defines properties for all instances of **2CV** cars (a subclass of **Car**), and actual cars like **My_2CV** (a specific car) have their own individual properties (such as mileage and license plate).\n   \n- **Structure**: \n   - **Instance (M0)**: A specific car like **My_2CV**.\n   - **Class (M1)**: **2CV** class, which represents all instances of the 2CV model.\n   - **Powertype (M2)**: **Car_Model**, which defines characteristics for different types of cars like 2CV_Model or Mustang_Model.\n\n### Key Differences:\n- **Metatype** refers to a higher level that classifies **classes** (meta-modeling), while **powertype** refers to a class that classifies **types** of a given class, focusing on distinguishing between **subclasses** (type hierarchy).\n- In **metatype** systems, the emphasis is on creating and managing meta-levels, while in **powertype** systems, the focus is on modeling and managing different types or variations within a particular class.\n\n### Summary:\n- **Metatype**: A metalevel concept that classifies classes (e.g., **Metaclass** that defines the structure of the **Person** class).\n- **Powertype**: A class that defines types (subclasses) of another class (e.g., **Car_Model** defining specific types of **Car**).\n\nEach concept serves a different role in modeling, depending on whether you are dealing with **meta-classification** (metatypes) or managing **subclass hierarchies** (powertypes).\n\n## References \n\n- [[ar.an-extensible-approach-to-multi-level-ontology-modelling#^vt540o589i6g]]","n":0.046}}},{"i":35,"$":{"0":{"v":"Message Broker Vs Stream Processo","n":0.447},"1":{"v":"\nresources: \n\n- https://www.upsolver.com/blog/kafka-versus-rabbitmq-architecture-performance-use-case\n  - [[prdct.kafka]] is pull-based; [[prdct.rabbitimq]] is push-baseed\n  - ","n":0.302}}},{"i":36,"$":{"0":{"v":"Junit Vs Testng","n":0.577},"1":{"v":"\n- Comparing TestNG Vs JUnit, TestNG annotations are easier to use and understand than JUnit. \n- \"TestNG allows us to create parallel tests, whereas JUnit does not support running parallel tests.\"\n  - but https://www.baeldung.com/junit-5-parallel-tests\n-  In TestNG, Test cases can be grouped together, while in JUnit, Grouping tests together is not possible.\n- \"the declaration of @BeforeClass and @AfterClass method has to be static in JUnit. By comparison, TestNG method declaration doesn’t have these constraints.\"\n- junit5's \"@MethodSource – passes external methods generating streams:\" seems awesome. could it take parameter streams from the network?","n":0.105}}},{"i":37,"$":{"0":{"v":"Intensional Vs Extensional Classes in Rdf","n":0.408},"1":{"v":"\n## classes in RDF are easily extensional, i.e., you can use rdf:type to include an instance in a class. how do you include instances intensionally\n\n- interlocutor: @chatgpt.4o\n\nIn RDF, **extensional class membership** is straightforward—using `rdf:type` allows you to assert that a specific resource (instance) belongs to a class. However, **intensional** class membership, where membership is defined by **conditions or criteria** rather than explicitly listed individuals, requires a different approach. Here are a few ways to model **intensional** class membership in RDF, often by using **OWL** or **SHACL** for richer expressivity:\n\n### 1. **Using OWL (Web Ontology Language) Restrictions**:\n   **OWL** allows you to define classes **intensionally** using **class descriptions** or **restrictions**. These restrictions define a class based on the properties that its instances must satisfy, rather than explicitly listing the instances.\n\n   For example:\n   ```turtle\n   :Person rdf:type owl:Class .\n   \n   :Adult rdf:type owl:Class ;\n          owl:equivalentClass [\n              rdf:type owl:Restriction ;\n              owl:onProperty :age ;\n              owl:hasValue 18\n          ] .\n   ```\n   In this case, the class `:Adult` is defined **intensionally** based on a restriction: any individual that has an `age` property with a value of 18 (or above) is considered an instance of the `:Adult` class.\n\n   Types of OWL restrictions that support intensional definitions include:\n   - **owl:someValuesFrom**: Defines a class of individuals that have at least one value for a given property from a specific class.\n   - **owl:allValuesFrom**: Defines a class where all property values must belong to a certain class.\n   - **owl:hasValue**: Defines membership based on a specific value for a property.\n   - **owl:IntersectionOf**, **owl:UnionOf**: Allows combining multiple classes using intersection or union.\n\n### 2. **Using SHACL (Shapes Constraint Language)**:\n   **SHACL** allows you to define **constraints** on instances using shapes that describe conditions an instance must meet to belong to a class. These constraints function similarly to OWL's restrictions, but SHACL focuses more on **validation** rather than inferencing.\n\n   For example, you can define a shape that enforces certain property constraints for a class:\n   ```turtle\n   :PersonShape a sh:NodeShape ;\n       sh:targetClass :Person ;\n       sh:property [\n           sh:path :age ;\n           sh:minInclusive 18\n       ] .\n   ```\n\n   In this case, the shape `:PersonShape` defines the conditions that a resource must meet (having an `age` greater than or equal to 18) to be considered a valid instance of the `:Person` class.\n\n### 3. **Rule-Based Approaches**:\n   Another approach is to use **rule-based systems**, like **[[SWRL|prdct.swrl]] (Semantic Web Rule Language)**, to define intensional membership. Rules can infer class membership based on certain conditions.\n\n   Example SWRL rule:\n   ```swrl\n   Person(?x) ^ age(?x, ?age) ^ swrlb:greaterThan(?age, 18) → Adult(?x)\n   ```\n   This rule states that if an individual `?x` is a `Person` and has an `age` greater than 18, then `?x` is inferred to be an `Adult`. This is an **intensional** way to infer class membership without explicitly stating it.\n\n### 4. **SPARQL Queries (Dynamic Membership)**:\n   Using **SPARQL queries**, you can dynamically query for instances that satisfy specific criteria, which gives you a **virtual intensional class**. This doesn’t formally create class membership but allows you to retrieve members based on conditions.\n\n   Example:\n   ```sparql\n   SELECT ?person WHERE {\n     ?person rdf:type :Person .\n     ?person :age ?age .\n     FILTER (?age >= 18)\n   }\n   ```\n\n### Conclusion:\nTo include instances **intensionally** in RDF, you typically need to extend RDF with **OWL** for logical restrictions or **SHACL** for constraints. These tools allow you to define classes based on conditions (rather than explicitly stating membership), providing a more **dynamic and rule-based** approach to class membership. While `rdf:type` is used for extensional membership, OWL restrictions, SHACL constraints, and SWRL rules enable intensional class definitions based on logical criteria.","n":0.042}}},{"i":38,"$":{"0":{"v":"Hypergraph Vs Metagraph","n":0.577},"1":{"v":"\n\n- resources: \n  - https://news.ycombinator.com/item?id=25064588\n    - #summary the hyperedge, rather than being an ordered pair of vertexes, is an ordered list of vertexes. The metagraph takes the hypergraph concept one step further: the hyperedge may also contain other hyperedges.\n  - [[Graphs, Metagraphs, Ram, Cpu|ar.opencog.graphs-metagraphs-ram-cpu]]\n    - [[p.hasSummaryPoints]]\n      - atoms are nodes or links\n      - links are lists of atoms\n- [ ] what about compound graphs, e.g. [[prdct.cytoscape]] says \n  - [[t.cs.graph.compound-graphs]] [[p.subClassOf]] [[t.cs.graph.hypergraph]]\n","n":0.118}}},{"i":39,"$":{"0":{"v":"Hex Vs Grid","n":0.577},"1":{"v":"\n## Thoughts\n\n- grid allows cardinal movement easily, especially on the micro scale with steps. But in 3d, you don't move in cardinal anyway. \n\n## Resources\n\n- https://www.reddit.com/r/RPGdesign/comments/74g0fo/question_hex_vs_squares_pros_and_cons_of_each/\n  - \"Hexes are better for outdoors, because they don't have any weird diagonals. Squares are better for indoors because most buildings have walls at right angles.\"\n- https://www.redblobgames.com/grids/hexagons/\n- [[prdct.h3]]","n":0.136}}},{"i":40,"$":{"0":{"v":"Hash Vs Slash","n":0.577},"1":{"v":"\n## Triply's take\n\n\n- Using a hash in IRIs assumes that the IRI without the hash serves the full content of the dataset, containing full descriptions of all hash-containing IRIs with that prefix. This assumption is often true for RDF stored in a single file on a plain file server. This assumption is almost always false for any other data publication system, including all sophisticated data publishing systems that use a column store, relational store, triple store, or document store. This means that an IRI strategy that uses hashes significantly narrows down the possible implementations of a linked data system that publishes data according to that IRI strategy.\n- Using a hash in IRIs assumes that the server does not return results in pages (pagination). A server that returns paginated results will often not return the full content of a dataset in the first request. This immediately violates the implementation of the hash component as standardized by HTTP(S), which requires that the full dataset is returned in the first successful reply.\n- Using a hash in IRIs assumes that the dataset in which all hash-containing IRIs occur is small enough to be downloaded from a server all at once and fully searched though by an unadvanced client. Specifically, the client cannot be assumed to use advanced forms of indexing to ensure speedy retrieval of the fragment. This means that retrieval may be a little bit faster for small vocabularies that are cached well by the client and whose terms are often looked up by the user, and that retrieval is slower or impossible in all other scenarios.\n- Using a hash in IRIs assumes that the small dataset in which all hash-containing IRIs occur will remain small forever. If new hash-containing IRIs are regularly added to the dataset, retrieval times will increase over time.\n\n## Daniel Garijo's take\n\n![[ar.best-practices-for-implementing-fair-vocabularies-and-ontologies-on-the-web#hash-versus-slash-uris]]\n\n## References\n\n- https://www.w3.org/wiki/HashVsSlash\n- https://triplydb.com/how-to-model/-/stories/how-to-model-iris\n- [[ar.best-practices-for-implementing-fair-vocabularies-and-ontologies-on-the-web]]\n- [[ar.best-practice-recipes-for-publishing-rdf-vocabularies]]","n":0.057}}},{"i":41,"$":{"0":{"v":"Fixed Vs Growth Mindset","n":0.5},"1":{"v":"\nfixed | growth |\n---------|----------|\nI'm not good at this | I can get good at it with effort & practice\nthis is too hard | everything is hard before it is easy\nI made a mistake | misktakes help me do it better next time\nIt's good enough | the more I do it, the better I'll get at it\nThey are smarter than me | I get smarter by learning more\nIf you change your mindset | you can change your whole life\n","n":0.113}}},{"i":42,"$":{"0":{"v":"Expansive Vs Contracted","n":0.577},"1":{"v":"\n\n\n- resources: \n  - https://www.intelligentchange.com/blogs/read/how-our-body-makes-decisions by @tim-ferris\n","n":0.378}}},{"i":43,"$":{"0":{"v":"Events Vs Messages","n":0.577},"1":{"v":"\n\n\nA Message is some data sent to a specific address. In Message Driven systems, each component has a unique address other components can send messages to. Each of these components, or recipients, awaits messages and reacts to them.\n\nAn Event is some data emitted from a component for anyone listening to consume.\n\n## [[p.provokedThoughts]]\n\n- it's a slim difference\n  - permissioned event queues are similar to broadcast messages\n  - you could imagine \n\n## Resources\n\n- https://azure.microsoft.com/en-us/blog/events-data-points-and-messages-choosing-the-right-azure-messaging-service-for-your-data/\n- https://thenewstack.io/supercharging-event-driven-integrations-using-apache-kafka-and-triggermesh/","n":0.117}}},{"i":44,"$":{"0":{"v":"Dul Vs D0","n":0.577},"1":{"v":"\n- comparands: [[prdct.dolce.dns-ultralite]] [[prdct.dolce.d0]]\n\n","n":0.5}}},{"i":45,"$":{"0":{"v":"Dolce Vs Ufo Vs Gfo Vs Sumo","n":0.378},"1":{"v":"\n## General\n\n\n### gUFO \n\n- gUFO has [[prdct.ontouml]] so perhaps more/easier applicability to software models\n- (somewhere) was intended for conceptual modeling, including simulation modeling\n  - @chatgpt: \"Unlike GFO and DOLCE, which have their roots in formal ontology and linguistic cognition respectively, UFO is designed to address the practical needs of conceptual modeling and simulation.\"\n- Instances of gufo:Type are classes, and should specialize the taxonomy of individuals of gUFO. For example, \\\"Person\\\" is a gufo:Type (more specifically a gufo:Kind), specializing gufo:Object. The mechanism that allows for this is called punning in OWL 2.\n\n### BFO\n\n- github version hasn't been touched since 2009, but BFO2020 (with ugly IRIs)\n\n#### BFO2020\n\n- [[prdct.basic-formal-ontology.2020]] identifiers are opaque grossness, like \n\n## Abstract/Particular\n\n- DOLCE claims to be an ontology of particulars\n- @chatgpt thinks [[prdct.gfo]] might have better concrete/abstract distinction;  \n\n## Mixins\n\n- see [[sh.question-log.2024.07.09#upper-ontologies-supporting-mixins]]\n- UFO has 'em\n- \n\n## Space\n\n### The Gauntlet\n\n- [[the-gauntlet]] is a fictional trade route through space  connecting [[Anchorpoint-Station]] and [[the-Frontier]]\n\n#### DOLCE\n\n- classes: #SpaceRegion and #PhysicalPlace \n- properties: #connects\n\n#### GFO\n\n- claims to use [[t.phil.space.brentano]], but #Space_time is disjoint with #Abstract !\n  - t.2024.07.22.16 mental != abstract\n\n#### SUMO\n\n- has #Path and #Route\n- #startsAt and #endsAt\n\n#### gUFO\n\n\n## References\n\n- [[ar.matching-bfo-dolce-gfo-and-sumo-an-evaluation-of-oaei-2018-matching-systems]]\n- [[sh.ontology.upper.log#results-of-onset]]\n- [[ar.some-open-issues-after-twenty-years-of-formal-ontology]]","n":0.073}}},{"i":46,"$":{"0":{"v":"Debate Vs Negotiation","n":0.577},"1":{"v":"\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^3i9ekyfm2c0l]]\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^n4877p2jlmwz]]\n\n## References\n\n- [[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming]]","n":0.577}}},{"i":47,"$":{"0":{"v":"Concrete Vs Abstract Syntax","n":0.5},"1":{"v":"\n- \"The concrete syntax of a language is its syntax in its representation that we see. The XML and custom language files have different concrete syntaxes. However both share the same basic structure: you have multiple mappings, each with a code, a target class name, and a set of fields. This basic structure is the abstract syntax. When most developers think about programming language syntax they don't make this separation, but it's an important one when you use DSLs. You can think of this in two ways. You can either say we have one language with two concrete syntaxes, or two languages that share the same abstract syntax.\"\n  - https://martinfowler.com/articles/languageWorkbench.html","n":0.095}}},{"i":48,"$":{"0":{"v":"Class vs. Type vs. Category","n":0.447},"1":{"v":"\n## Definition\n\n- a category is an intensional set (specifying necessary and sufficient conditions) with criteria for defining membership. A class is an extensional set where membership is explicitly asserted and specific properties can be defined as necessary.\n\n### [[prdct.rdf]]\n\n- in RDF, \"type\" is the class of an instance; Sub-classes can be said to be types of Classes but better to use subClassOf, e.g.:\n  - Car hasSubclass Ford #preferred\n  - Car type Ford #discouraged ^VCeEIajzeBga\n  - My old mustange type Ford #preferred \n\n- [RDF Core Schema](https://www.w3.org/2001/sw/RDFCore/Schema/20010618/) says \"type\" states that a resource is an instance of a class\n- type is problematic in informal speech; can mean instance of a class OR subClass of a Class\n  - e.g. Ford is a type of car, but Mustang is a type of Ford and convertible is a type of Mustang\n    - Ford is a type of car manufacturer though\n- type feels a little less formal, but outside of programming they mean pretty much the same thing\n\n### https://www.cerritos.edu/dwhitney/SitePages/CIS201/Lectures/IM-7ed-Chapter04.pdf\n\n A class is a category or classification used to describe a set of objects. So a class is a\ncategory, but it is also a set of objects. \n\n\n## Resources\n\n- https://dev.to/awwsmm/types-vs-classes-39an\n  - [[p.hasContext]] [[t.cs.programming]]\n- [[Discussion|p.instanceOf#discussion]]\n\n- https://www.cerritos.edu/dwhitney/SitePages/CIS201/Lectures/IM-7ed-Chapter04.pdf\n- https://www.semanticarts.com/wp-content/uploads/2018/10/CategoriesandClassesDMc060515newtemplate.pdf\n  - [[ar.ontologist.classes-categories-types-and-shapes]]","n":0.071}}},{"i":49,"$":{"0":{"v":"Class Vs Individual","n":0.577},"1":{"v":"\n- aka: [[t.phil.type-token-distinction]] \n- Superclasses/supertypes define inheritance relationships between classes or types.\n- Metaclasses/metatypes classify classes\n- powerclasses/powertypes define properties of their classes/types; i.e. a class that classifies types of a given class, focusing on distinguishing between subclasses \n  - [[prdct.unified-foundational-ontology.gUFO]] has gufo:Type which is the powerclass \n\n## Definitions\n\n- Only classes have superclasses, while other classifiers have supertypes.\n  - Since Class is also a Classifier, a superclass is always a supertype\n- powertype is a type whose instances are themselves types.\n\n## Conclusion\n\n- t.2024.07.11.09 after trying to formulate a comment for [[ar.medium.mike-dillinger.the-nature-of-knowledge-graph-predicates]], I feel a small a-ha!\n  - Data Scientist, as a sub-class of Occupation, requires that all its instances are occupations\n- 2+: \n\n## Issues\n\n- just like my Dendron notes, do we have separate classes for things, or can concepts just double as classes?\n  - based on my experience, it's better to just have one class/concept/universal, but can be aliased from multiple places\n    - t.2024.09.09.09 thinking about this more in \n\n### Classes as Values\n\n#### Approach 3: Create a parallel hierarchy of instances as property values\n\n- rdfs:seeAlso\n\n- in addition to [[book.semantic-modeling-for-data#class-or-individual]], there's:\n\n## Second Option + Linking Annotation\n\n- aka \"Create a parallel hierarchy of instances as property values\"\n- use one of the class annotation properties, e.g.\n  - rdfs:comment, **rdfs:seeAlso**, rdfs:isDefinedBy, or\n  - a custom annotation defined with owl:AnnotationProperty\n    - used to add additional information to classes, properties, or individuals without affecting the logical structure of the ontology.\n      - t.2024.05.25.14 well, kinda\n\n### AnnotationProperty example\n\n## Fourth Option: Using annotations as (non-logical) properties\n\n- maybe losing reasoning isn't important?\n  - transitive might be important,\n    - e.g.\n      - CharacterClassChoice shouldOccurBefore CharacterAbilityScoreChoice\n      - CharacterAbilityScoreChoice shouldOccurBefore CharacterSkillChoice\n      - \n \n\n## Thoughts\n\n### Punning\n\n- \"Punning is a simple way to provide for metamodeling that (a) does not require a major change to OWL 1.1 (DL) reasoners and (b) usually seems to satisfy the semantic requirements.\"\n- \"An IRI I can be used in an OWL 2 ontology to refer to more than one type of entity. Such usage of I is often called metamodeling, because it can be used to state facts about classes and properties themselves. In such cases, the entities that share the same IRI I should be understood as different \"views\" of the same underlying notion identified by the IRI I.\"\n\n## Resources\n\n- [[ar.onto-clean-in-owl-with-a-dl-reasoner-a-tutorial]]\n\n## References\n\n- https://www.w3.org/2007/OWL/wiki/Punning\n- https://stackoverflow.com/questions/38208212/does-owl-punning-treats-class-and-individual-with-same-name-as-same-semantically\n- https://lists.w3.org/Archives/Public/semantic-web/2011Jun/0245.html\n- https://www.w3.org/TR/swbp-classes-as-values/\n- [[ar.towards-ontological-foundations-for-conceptual-modeling-the-unified-foundational-ontology-ufo-story]]\n- [[ar.an-extensible-approach-to-multi-level-ontology-modelling#^vt540o589i6g]]","n":0.052}}},{"i":50,"$":{"0":{"v":"Atomized Fun Vs Multisensory Fun","n":0.447},"1":{"v":"\n- [[p.hasSource]] [[email.de-atomization-is-the-secret-to-happiness]]\n  - \"Playing the videogame is very fun, but it’s monolithic. It’s just play, there’s no environmental novelty full of multisensory stimuli to hook your memory into. It blurs from one moment to the next, and like bad American Chinese food, you find yourself paradoxically unsatiated when you’re done. There’s something more fun about complex fun, even if the individual moments might score lower on the hedonometer.\"\n  - \"atomization encourages us to reduce multivariate experiences, often the most important parts of life, to their single most obvious element:\"\n","n":0.105}}},{"i":51,"$":{"0":{"v":"Aggregation Vs Composition","n":0.577},"1":{"v":"\n- a composition is more than the some of its parts","n":0.302}}},{"i":52,"$":{"0":{"v":"Videos","n":1}}},{"i":53,"$":{"0":{"v":"New Twilight Zone","n":0.577}}},{"i":54,"$":{"0":{"v":"A Matter of Minutes (s01e38)","n":0.447},"1":{"v":"\n- superwork: [[superwork.twilight-zone]]\n- episode: 1.38\n\n![](/assets/images/2024-09-10-09-58-19.png)\n\n## Issues\n\n\n\n## Trivia\n\n- the movie theater downtown, whose ticket booth is used by Michael and Maureen as their hiding place, is showing Terry Gilliam's Time Bandits.\n\n## Quotes\n\n- \"Now think of time as an infinite series of boxcars all linked together, like this. Now each boxcar represents one minutes, and people like yourselves move from boxcar to boxcar as time moves forward. \n\n### Closing Narration\n\n\"Time, a handy fiction to explain why everything doesn't happen all at once. Or maybe we're the fiction, moving minute by minute...through the Twilight Zone. \"\n\n## References\n\n- https://twilightzone.fandom.com/wiki/A_Matter_of_Minutes\n- http://postcardsfromthezone.blogspot.com/2006/01/138-matter-of-minutes.html","n":0.102}}},{"i":55,"$":{"0":{"v":"Great Big Story","n":0.577}}},{"i":56,"$":{"0":{"v":"This Art Is Our Art","n":0.447},"1":{"v":"\n- @louie-gong [[p.cofounded]] [[org.eighth-generation]]","n":0.5}}},{"i":57,"$":{"0":{"v":"Young Frankenstein","n":0.707},"1":{"v":"\n![](/assets/images/2024-09-27-06-15-27.png)\n\n- written-by: @mel-brooks, @gene-wilder, @mary-shelley","n":0.447}}},{"i":58,"$":{"0":{"v":"Twilight Zone","n":0.707},"1":{"v":"\n## Quotes\n\n### Introductions\n\n- There is a fifth dimension beyond that which is known to man. It is a dimension as vast as space and as timeless as infinity. It is the middle ground between light and shadow, between science and superstition, and it lies between the pit of man's fears and the summit of his knowledge. This is the dimension of imagination. It is an area which we call \"The Twilight Zone\".\n  - https://www.youtube.com/watch?v=vB1Ot9MEOOs\n\n\n- You unlock this door with the key of imagination. Beyond it is another dimension: a dimension of sound, a dimension of sight, a dimension of mind. You’re moving into a land of both shadow and substance, of things and ideas. You’ve just crossed over into… the Twilight Zone.\n\n\n## References\n\n- https://grail.eecs.csuohio.edu/~somos/twizone.html\n- ","n":0.09}}},{"i":59,"$":{"0":{"v":"The Old Man in the Cave (s05e07)","n":0.378},"1":{"v":"\n- https://www.amazon.com/gp/video/detail/amzn1.dv.gti.58a9f770-248d-be20-d2ed-7509c6e802aa\n- tropes: [[t.psych.faith]], [[t.storytelling.tropes.after-the-end]], [[t.storytelling.tropes.benevolent-ai]]\n- air-date: 1963-10-08\n\n## Quotes\n\n- Goldsmith: \"All the compassion that's left on this earth is in that cave.\"\n- Jason: \"My god! My dear god... It's a machine.\"\n\n![](/assets/images/2024-09-25-13-25-08.png)\n\n![](/assets/images/2024-09-13-16-11-46.png)\n\n\n## References\n\n- https://tvtropes.org/pmwiki/pmwiki.php/Recap/TheTwilightZone1959S5E7TheOldManInTheCave\n- https://www.imdb.com/title/tt0734669/quotes/","n":0.171}}},{"i":60,"$":{"0":{"v":"Time Enough at Last (s01e08)","n":0.447},"1":{"v":"  \n- written-by: @rod-serling\n- directed-by: @hans-brahm\n- tropes: #isolation #irony #time\n- broadcast: 1959-10-20\n\n![](/assets/images/2024-09-10-10-29-22.png)\n\n![](/assets/images/2024-09-10-10-26-39.png)\n\n\n## References\n\n- [Episode Analysis by CineG](https://www.youtube.com/watch?v=t5gJQGkgDp8)","n":0.25}}},{"i":61,"$":{"0":{"v":"Total Recall","n":0.707},"1":{"v":"\n- http://imdb.com/title/tt0100802/\n- related: [[book.we-can-remember-it-for-you-wholesale]]","n":0.5}}},{"i":62,"$":{"0":{"v":"The Promised Land","n":0.577},"1":{"v":"\n- the villain was foppish, effeminate, and completely detestable\n- ludvig kahlen was awesome","n":0.277}}},{"i":63,"$":{"0":{"v":"The Muppet Movie","n":0.577},"1":{"v":"\n## Songs\n\n- [[music.the-magic-store]]\n\n## Reviews\n\n### The Twin Geeks\n\n“Kermit, does this movie have socially redeeming value?“\n\nThe Muppet Movie begins and ends with cinema. It is a celebration of the magic of movies, and the power that art holds. Kermit and his cohort of felted friends sit in a Hollywood screening room and watch a film about the Muppets. A movie within a movie, wheels within wheels. The film is an origin story that shows ‘approximately how it happened’, a road movie in the style of the Crosby/Hope ‘Road To..’ movies, a takedown of big business, and a celebration of art as a vehicle to make people happy. Littered with fabulous celebrity cameos, it is apparent that Jim Henson, Frank Oz, and the rest of the production team wanted to tip their hats to those that came before them – the comedians and artists that inspired and motivated them.\n\nWhat is it that draws me back to this movie, and The Muppets as a whole, again and again? Is it the vaudevillian comedic styling? Is it Paul Williams’ masterful songs? The daring and nuanced camerawork? The technicality and showmanship of the puppetry? The whimsical, wholesome nature? It’s obviously all of these things and more; but there is an earnestness to these movies that I rarely find elsewhere. An antiquated approach to spectacle and jokes, in productions that rely heavily on physical design and craft, done with nuance, care, and polish.\n\nCinema is a magic store, and I’ve found a home here.\n\n> Life is like a movie, write your own ending. Keep beliving, keep pretending.\n\n\n## References\n\n- https://thetwingeeks.com/2022/12/28/tg10-jacks-list-you-found-a-home-at-the-magic-store/","n":0.062}}},{"i":64,"$":{"0":{"v":"The Garden and the Stream a Technopastora","n":0.378},"1":{"v":"\n- [[p.hadPresenter]] @mike-caufield\n- [[p.isRelated]] \n  - [[The Garden and the Stream|idea.the-garden-and-the-stream]]\n \n","n":0.289}}},{"i":65,"$":{"0":{"v":"Tedx","n":1}}},{"i":66,"$":{"0":{"v":"Indigenous in Plain Sight","n":0.5},"1":{"v":"\n- [[p.hasURL]] https://www.youtube.com/watch?v=s3FL9uhTH_s\n- [[p.hadHost]] @gregg-deal","n":0.447}}},{"i":67,"$":{"0":{"v":"Tar","n":1},"1":{"v":"\n- \"If any of you have lost your nerve, then step away now and let no one judge you.\"","n":0.229}}},{"i":68,"$":{"0":{"v":"Singles","n":1},"1":{"v":"\n- [[c.crew.director]] @cameron-crowe","n":0.577}}},{"i":69,"$":{"0":{"v":"Secrets of Blackmoor","n":0.577}}},{"i":70,"$":{"0":{"v":"Russian Doll","n":0.707}}},{"i":71,"$":{"0":{"v":"Muppets Take Manhattan","n":0.577}}},{"i":72,"$":{"0":{"v":"Minions","n":1}}},{"i":73,"$":{"0":{"v":"House of Gucci","n":0.577}}},{"i":74,"$":{"0":{"v":"Grandmas Boy","n":0.707}}},{"i":75,"$":{"0":{"v":"Existenz","n":1},"1":{"v":"\n- director: @david-cronenberg","n":0.577}}},{"i":76,"$":{"0":{"v":"Dungeons and Dragons: Honor Among Thieves","n":0.408},"1":{"v":"\n- https://www.rottentomatoes.com/m/dungeons_and_dragons_honor_among_thieves","n":0.707}}},{"i":77,"$":{"0":{"v":"Dead Poets Society","n":0.577}}},{"i":78,"$":{"0":{"v":"Back to the Future","n":0.5}}},{"i":79,"$":{"0":{"v":"Andor","n":1}}},{"i":80,"$":{"0":{"v":"Aliens","n":1}}},{"i":81,"$":{"0":{"v":"Alien","n":1}}},{"i":82,"$":{"0":{"v":"Alien Resurrection","n":0.707}}},{"i":83,"$":{"0":{"v":"Alien 3","n":0.707}}},{"i":84,"$":{"0":{"v":"Users (People)","n":0.707}}},{"i":85,"$":{"0":{"v":"Gemini","n":1}}},{"i":86,"$":{"0":{"v":"1","n":1}}},{"i":87,"$":{"0":{"v":"5","n":1}}},{"i":88,"$":{"0":{"v":"Gemini 1.5 Advanced","n":0.577}}},{"i":89,"$":{"0":{"v":"Dendron","n":1}}},{"i":90,"$":{"0":{"v":"Derek Ardolf (ScriptAutomate)","n":0.577},"1":{"v":"\n\n\nDerek from Story Influx Press\n\n- [[p.workedFor]] [[org.dendron]] \n  - [[p.hasValidityPeriod]] 2021-10/.. \n- [[p.hasBlog]] https://www.influxpress.com/blog\n- [[p.alsoKnownAs]] ScriptAutomate\n","n":0.25}}},{"i":91,"$":{"0":{"v":"Chatgpt","n":1}}},{"i":92,"$":{"0":{"v":"3","n":1}}},{"i":93,"$":{"0":{"v":"ChatGPT 3.5","n":0.707}}},{"i":94,"$":{"0":{"v":"4o","n":1}}},{"i":95,"$":{"0":{"v":"ChatGPT 4.0","n":0.707},"1":{"v":"\n## t.2024.02.29.16\n\n- added customizations:\n  - What would you like ChatGPT to know about you to provide better responses?\n    - I'm working on a role-playing experience platform that will facilitate fantasy play in virtual worlds. When researching software products, libraries, and databases, I appreciate concrete examples and tutorials to help me understand things.\n  - How would you like ChatGPT to respond?\n    - I usually don't like \"filler\" content in responses, unless it's extremely relevant. No need for formality. Feel free to ask clarifying questions. ","n":0.11}}},{"i":96,"$":{"0":{"v":"Zubeida Khan","n":0.707}}},{"i":97,"$":{"0":{"v":"Zhamak Dehghani","n":0.707}}},{"i":98,"$":{"0":{"v":"Zach Adams","n":0.707},"1":{"v":"\nwrote the stories that @tarn-adams used to forge [[game.Dwarf-Fortress]]","n":0.333}}},{"i":99,"$":{"0":{"v":"Yves Goeleven","n":0.707}}},{"i":100,"$":{"0":{"v":"Xiaorong Xiang","n":0.707}}},{"i":101,"$":{"0":{"v":"Will Wright","n":0.707},"1":{"v":"\n- creator of [[game.the-sims]]\n- ","n":0.5}}},{"i":102,"$":{"0":{"v":"Will Carter","n":0.707},"1":{"v":"\n- hasn't developed on unreal, but keen on picking it up\n","n":0.302}}},{"i":103,"$":{"0":{"v":"Werner Kuhn","n":0.707}}},{"i":104,"$":{"0":{"v":"Wei Dai","n":0.707}}},{"i":105,"$":{"0":{"v":"Wayne Dyer","n":0.707},"1":{"v":"\n- applying Buddhist \"right speech\" rules to avoid upsetting any apple carts or promoting any true transformational change.","n":0.236}}},{"i":106,"$":{"0":{"v":"Walter Scott","n":0.707},"1":{"v":"\n- aka: Sir Walter Scott","n":0.447}}},{"i":107,"$":{"0":{"v":"Vladimir Propp","n":0.707}}},{"i":108,"$":{"0":{"v":"Vlad Sitalo","n":0.707},"1":{"v":"\n- [[p.hasSite]] [[Vlad's Roam Garden|ar.vlad-roam-garden]]\n- [[p.hasURL]] https://standardresume.co/r/vladyslavsitalo","n":0.378}}},{"i":109,"$":{"0":{"v":"Vish Hari","n":0.707},"1":{"v":"\n- agents can commit code \n- completing y-combinator\n- role: co-founder at [[org.ego]]","n":0.289}}},{"i":110,"$":{"0":{"v":"Vidoq","n":1}}},{"i":111,"$":{"0":{"v":"Victorio Carvalho","n":0.707}}},{"i":112,"$":{"0":{"v":"Veruska Zamborlini","n":0.707}}},{"i":113,"$":{"0":{"v":"Vaughn Vernon","n":0.707}}},{"i":114,"$":{"0":{"v":"Vannevar Bush","n":0.707},"1":{"v":"\n- [[p.wrote]] [[ar.atlantic.as-we-may-think]]\n","n":0.577}}},{"i":115,"$":{"0":{"v":"Valentina Presutti","n":0.707}}},{"i":116,"$":{"0":{"v":"Valentina Bartalesi","n":0.707}}},{"i":117,"$":{"0":{"v":"Ursula Leguin","n":0.707}}},{"i":118,"$":{"0":{"v":"Unoriginal","n":1}}},{"i":119,"$":{"0":{"v":"Umberto Eco","n":0.707}}},{"i":120,"$":{"0":{"v":"Trygve Reenskaug","n":0.707},"1":{"v":"\n- [[p.invented]] [[t.cs.sd.architecture.dci]] [[t.cs.sd.architecture.mvc]]","n":0.5}}},{"i":121,"$":{"0":{"v":"Trevor Perrin","n":0.707},"1":{"v":"\n\n- [[p.hasURL]] https://twitter.com/trevp__\n","n":0.577}}},{"i":122,"$":{"0":{"v":"Tony Gilroy","n":0.707},"1":{"v":"\n- [[p.wrote]] [[video.andor]]\n- ","n":0.577}}},{"i":123,"$":{"0":{"v":"Tomasz Miksa","n":0.707}}},{"i":124,"$":{"0":{"v":"Tom Johnson","n":0.707}}},{"i":125,"$":{"0":{"v":"Todd Schneider","n":0.707}}},{"i":126,"$":{"0":{"v":"Tobias Warden","n":0.707}}},{"i":127,"$":{"0":{"v":"Tim Kampik","n":0.707},"1":{"v":"\n- #demo https://people.cs.umu.se/~tkampik/demos/\n- #aka tkampik","n":0.447}}},{"i":128,"$":{"0":{"v":"Tim Grahl","n":0.707}}},{"i":129,"$":{"0":{"v":"Tim Ferris","n":0.707}}},{"i":130,"$":{"0":{"v":"Tim Berners-Lee","n":0.707}}},{"i":131,"$":{"0":{"v":"Tiago Prince Sales","n":0.577},"1":{"v":"\n![](/assets/images/2024-10-11-18-07-36.png)","n":1}}},{"i":132,"$":{"0":{"v":"Thomas Allom","n":0.707}}},{"i":133,"$":{"0":{"v":"Thom Van Kalkeren","n":0.577},"1":{"v":"\n- ","n":1}}},{"i":134,"$":{"0":{"v":"Terry Halpin","n":0.707},"1":{"v":"\n\n- \"any book written by Terry Halpin is not only a gem to read, but is also an important and practically useful book.\"\n  - [[p.attributedTo]] @herman-balsters","n":0.196}}},{"i":135,"$":{"0":{"v":"Telmo Menezes","n":0.707},"1":{"v":"\n- url: https://telmomenezes.net/","n":0.577}}},{"i":136,"$":{"0":{"v":"Tejas Kulkarni","n":0.707}}},{"i":137,"$":{"0":{"v":"Tarn Adams","n":0.707},"1":{"v":"\n- [[p.built]] [[game.Dwarf-Fortress]] by trying to make a simulator capable of generating @zach-adams's stories","n":0.267}}},{"i":138,"$":{"0":{"v":"Taras Wenc","n":0.707},"1":{"v":"\n- called me showboat. thankfully.\n- ","n":0.447}}},{"i":139,"$":{"0":{"v":"Tactiq","n":1}}},{"i":140,"$":{"0":{"v":"Swyx","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.swyx.io\n- https://www.netlify.com/blog/2019/10/07/complete-intro-to-netlify-in-3.5-hours/\n","n":0.5}}},{"i":141,"$":{"0":{"v":"Susannah Harmon Furr","n":0.577}}},{"i":142,"$":{"0":{"v":"Susan Rice","n":0.707}}},{"i":143,"$":{"0":{"v":"Steve Jobs","n":0.707}}},{"i":144,"$":{"0":{"v":"Stephan Bugaj","n":0.707},"1":{"v":"\n- chief creative officer \n- worked on sofia android\n- ","n":0.333}}},{"i":145,"$":{"0":{"v":"Stefano De Giorgis","n":0.577}}},{"i":146,"$":{"0":{"v":"Stefano Borgo","n":0.707}}},{"i":147,"$":{"0":{"v":"Stefan Shulz","n":0.707}}},{"i":148,"$":{"0":{"v":"Srivello","n":1}}},{"i":149,"$":{"0":{"v":"Speckledlemon","n":1},"1":{"v":"\n- https://www.reddit.com/user/speckledlemon/","n":0.707}}},{"i":150,"$":{"0":{"v":"Sotiris Batsakis","n":0.707}}},{"i":151,"$":{"0":{"v":"Simon Dobson","n":0.707},"1":{"v":"\n- https://simondobson.org/\n  - made-with: [[prdct.nikola]]","n":0.447}}},{"i":152,"$":{"0":{"v":"Simon Brown","n":0.707}}},{"i":153,"$":{"0":{"v":"Silvio Peroni","n":0.707}}},{"i":154,"$":{"0":{"v":"Sigourney Weaver","n":0.707}}},{"i":155,"$":{"0":{"v":"Seymour Chatman","n":0.707}}},{"i":156,"$":{"0":{"v":"Selja Seppaelae","n":0.707}}},{"i":157,"$":{"0":{"v":"Sebastiano Mandalà","n":0.707},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] sebas77\n","n":0.577}}},{"i":158,"$":{"0":{"v":"Scott Moehring","n":0.707},"1":{"v":"\r\n[[p.hasSite]] [[ar.moehr-better]]\r\n","n":0.707}}},{"i":159,"$":{"0":{"v":"Scott Christley","n":0.707}}},{"i":160,"$":{"0":{"v":"Sandro Hawke","n":0.707},"1":{"v":"\r\n- [[p.hasSite]] https://hawke.org/sandro/\r\n- [[p.hasURL]] http://www.w3.org/People/Sandro\r\n- [[p.workedFor]] [[org.World-Wide-Web-Consortium]]\r\n","n":0.378}}},{"i":161,"$":{"0":{"v":"Sander Mertens","n":0.707}}},{"i":162,"$":{"0":{"v":"Samer Buna","n":0.707},"1":{"v":"\n- [[p.hasExpertise]] [[prdct.node]]","n":0.577}}},{"i":163,"$":{"0":{"v":"Ryan Shaw","n":0.707}}},{"i":164,"$":{"0":{"v":"Ryan Crucible","n":0.707},"1":{"v":"\n- wants to work with experience builders","n":0.378}}},{"i":165,"$":{"0":{"v":"Ruben Wambacq","n":0.707},"1":{"v":"\n- email: \n- url: \n  - https://data.verborgh.org/ruben?object=%22Ruben%20Wambacq%22%40en\n    - uses [[prdct.linked-data-fragments-server]]\n- differnt_from:\n  - @ruben-verborgh\n  - @ruben-taelman","n":0.258}}},{"i":166,"$":{"0":{"v":"Ruben Verborgh","n":0.707}}},{"i":167,"$":{"0":{"v":"Ruben Taelman","n":0.707},"1":{"v":"\n- url:\n  - https://www.rubensworks.net\n- created:\n  - [[prdct.jsonld-streaming-parser-js]]\n  - [[prdct.comunica]]\n  - [[prdct.ostrich]]\n- wrote:\n  - [[ar.glenda-querying-rdf-archives-with-full-sparql]]\n","n":0.267}}},{"i":168,"$":{"0":{"v":"Royal Obrien","n":0.707},"1":{"v":"\n- [[c.role]] \n  - GM, the Linux Foundation\n  - VP Developer Platforms, [[org.nvidia]]","n":0.277}}},{"i":169,"$":{"0":{"v":"Roland Barthes","n":0.707}}},{"i":170,"$":{"0":{"v":"Roger Caillois","n":0.707}}},{"i":171,"$":{"0":{"v":"Rod Serling","n":0.707},"1":{"v":"\n- “I believe in God. But I believe in man more.”\n- He took his responsibility as a social dramatist — or, in his words, “the menacer of the public’s conscience” — seriously, and chaffed at sponsor-driven censorship. [^1]\n\n\n## References\n\n\n[^1]: https://forward.com/culture/430931/how-rod-serling-fought-injustice-and-nazis-on-the-twilight-zone/\n","n":0.158}}},{"i":172,"$":{"0":{"v":"Robin Sloane","n":0.707}}},{"i":173,"$":{"0":{"v":"Robert Yang","n":0.707},"1":{"v":"\n- url: https://author.al\n- role: CEO at [[org.altera]]\n\n## References\n","n":0.354}}},{"i":174,"$":{"0":{"v":"Robert Trypuz","n":0.707}}},{"i":175,"$":{"0":{"v":"Robert Porzel","n":0.707}}},{"i":176,"$":{"0":{"v":"Robert Martin","n":0.707},"1":{"v":"\n\n\n- [[p.creditedWith]] [[t.cs.programming.SOLID]]\n","n":0.577}}},{"i":177,"$":{"0":{"v":"Robert Clardy","n":0.707}}},{"i":178,"$":{"0":{"v":"Robert Alan","n":0.707}}},{"i":179,"$":{"0":{"v":"Rob Kuntz","n":0.707},"1":{"v":"\n- wrote:\n  - [[book.dave-arnesons-true-genius]]\n  - [[book.the-4th-category]]\n- \"with D&D's original publication, a breakout medium in storytelling — real time story crafting — was created, which corresponds in major ways to traditional oral storytelling.\"\n- \n\n## References\n\n- https://threelinestudiostore.com/THE-4TH-CATEGORY-p628165080","n":0.169}}},{"i":180,"$":{"0":{"v":"Rich Harris","n":0.707}}},{"i":181,"$":{"0":{"v":"Ricardo Montalban","n":0.707}}},{"i":182,"$":{"0":{"v":"Rhea Purohit","n":0.707},"1":{"v":"\n- focuses on research-driven storytelling in tech. She writes about going from zero to one with AI in her monthly column, Learning Curve.\n\n## References\n\n- [[ar.every.learning-curve.you-re-probably-using-ai-wrong]]\n\n","n":0.2}}},{"i":183,"$":{"0":{"v":"Remy Fannader","n":0.707},"1":{"v":"\n- wrote: ","n":0.707}}},{"i":184,"$":{"0":{"v":"Rema Vasan","n":0.707},"1":{"v":"\n- [[c.role]] head of global gaming business marketing at [[org.tiktok]]","n":0.316}}},{"i":185,"$":{"0":{"v":"Raymond Loewy","n":0.707}}},{"i":186,"$":{"0":{"v":"Ray Kurzweil","n":0.707}}},{"i":187,"$":{"0":{"v":"Ravi Sharma","n":0.707}}},{"i":188,"$":{"0":{"v":"Rachel Jepsen","n":0.707},"1":{"v":"\n- [[p.wrote]] [[ar.every.the-long-conversation]]","n":0.577}}},{"i":189,"$":{"0":{"v":"Willard Van Orman Quine","n":0.5},"1":{"v":"\n## Quotes\n\n- \"To be is to be the value of a variable\"","n":0.289}}},{"i":190,"$":{"0":{"v":"Przemyslaw Gradzki","n":0.707}}},{"i":191,"$":{"0":{"v":"Prince","n":1},"1":{"v":"\n## References\n\n- https://www.nytimes.com/2024/09/08/magazine/prince-netflix-ezra-edelman-documentary.html","n":0.577}}},{"i":192,"$":{"0":{"v":"Plato","n":1}}},{"i":193,"$":{"0":{"v":"Pink Martini","n":0.707}}},{"i":194,"$":{"0":{"v":"Pierre Levy","n":0.707}}},{"i":195,"$":{"0":{"v":"Philip K Dick","n":0.577}}},{"i":196,"$":{"0":{"v":"Phil Torres","n":0.707}}},{"i":197,"$":{"0":{"v":"Phil Lord","n":0.707},"1":{"v":"\n- http://homepages.cs.ncl.ac.uk/phillip.lord/\n- blog: https://www.russet.org.uk/blog/","n":0.5}}},{"i":198,"$":{"0":{"v":"Peter Mosses","n":0.707}}},{"i":199,"$":{"0":{"v":"Peter Hirshberg","n":0.707}}},{"i":200,"$":{"0":{"v":"Peggy Wang","n":0.707},"1":{"v":"\n- role: co-founder at [[org.ego]]\n- related: @vish-hari","n":0.378}}},{"i":201,"$":{"0":{"v":"Pawel Garbacz","n":0.707}}},{"i":202,"$":{"0":{"v":"Paul Williams","n":0.707},"1":{"v":"\n- https://en.wikipedia.org/wiki/Paul_Williams_(songwriter)","n":0.707}}},{"i":203,"$":{"0":{"v":"Paul Taylor","n":0.707}}},{"i":204,"$":{"0":{"v":"Paul Rissen","n":0.707}}},{"i":205,"$":{"0":{"v":"Paul Millerd","n":0.707}}},{"i":206,"$":{"0":{"v":"Paul Graham","n":0.707},"1":{"v":"\n- [[p.hasBlog]] http://www.paulgraham.com\n- ","n":0.577}}},{"i":207,"$":{"0":{"v":"Patryk Burek","n":0.707}}},{"i":208,"$":{"0":{"v":"Pat Hayes","n":0.707},"1":{"v":"\n## Re: RDF 2 Wishlist\n\nOn Nov 1, 2009, at 11:51 AM, [[user.sandro-hawke]] wrote:\n\n> So, what should W3C standardize next in the area of RDF, if anything?\n> OWL 2 added a bunch of stuff to OWL that users wanted and implementors\n> were willing to tackle.  Are there things like that around RDF?\n\nWell, I just used the invited talk to give my speech on this topic,  \nbut here's a more concrete list. I reserve the right to think of more  \ntomorrow.\n\n1. Clean up and simplify RDF abstract syntax. Literals can be  \nsubjects, properties can be blank nodes, etc. In fact, anything can be  \nanything in the triple space, in the conceptual graph model. The  \nexisting semantics can handle this without change. The spec gets to be  \nshorter and easier.\n1a. All literals are typed, plain literals are understood in  \nretrospect to be an abbreviation for typing with rdf:text.\n1b. If XMLLiteral is necessary, make it into an ordinary datatype. Or  \nget rid of it altogether.\n\n2. A better syntax than RDF/XML. I also like turtle or N3 style, but  \nwhatever, striped syntax is just too remote from the actual graph  \nmodel to be useful, and it imposes subtle and harmful influence over  \nthe whole language (eg it was why we don't have literals as  \nsubjects.)  FWIW, this is likely to be the hardest problem for  \nbackward compatibility, I suspect. I wonder how hard it would be to  \nhave a converter from RDF/XML into some other form, as a W3C service?\n\n3. Add a scope mechanism to the syntax, along the lines of the  \n'surfaces' idea in my talk. (Terminology and exact syntax for this can  \nbe adjusted to suit, but parentheses work well :-) This is an  \nextension to the current model, existing RDF documents are understood  \nto be on a document-level surface that was always there. As well as  \nmaking bnodes respectable, this provides a clean foundation for a  \nwhole lot of other things, including:\n3a. named surfaces (aka named graphs)\n3b. negation (see my ISWC talk) and hence full FOL as a natural and  \nwell-understood extension (without any retro changes to existing RDF)  \nThis is close to my heart, but not of immediate priority: Im more  \nconcerned that nothing is done which would break this as a future  \npathway.\n3c. NAF negation. I didn't go into this in the talk, but the big  \nproblem with any kind of nonmon reasoning on the Web is that nonmon  \n(notably NAF) only works inside fixed boundaries, and so far we don't  \nhave a way to draw the boundaries. Scoped surfaces give us this, and  \nso we could have for example 'closed' surfaces which support NAF  \nreasoning, and the whole logic can then be monotonic. Best of both  \nworlds, and IMO a better solution that the RIF idea of multiple  \nlogical 'zones' with conflicting semantics. Though it would be  \nstraightforward to link it to the RIF spec, I am pretty sure (the idea  \nwould be, for RIF, that it takes its logic-zone cue from the 'color'  \nof the surface it finds the rules on. All written in RDF, of course :-)\n3d. Named surfaces provide better mechanism than reification for RDF- \nmetadata-of-other-RDF (It is token level rather than abstract graph  \nlevel, which suddenly makes sense.)\n3e. Cleaner model for such things as unasserted annotations in OWL,  \nuse of RDF collections to encode OWL syntax, etc.., where some of the  \nRDF isn't really being, like, asserted, exactly.\n\n4. Deprecate RDF reification, containers.\n\n5. (related to 4) Choose a recommended way to encode n-ary relations,  \nexplain it fully, and deprecate all the others. Or, generalize RDF  \ntriples to n-tuples syntax, with the previous as a backward  \ncompatibility hack for old RDF.\n\n6. Build a clean version of SKOS into RDF, to replace RDFS. Current  \nRDFS is then OK but deprecated in favor of translation into newer  \nvocabulary, eg you should actually say that you want subclass/property  \nto be transitive, when you do. In the semantics, this is done by  \nchanging various 'iff's to 'if's, making reasoning searches easier.\n\n7. Include a modern, nuanced version of owl:imports into RDF. Should  \nbe possible to import only a part of a large ontology.\n\n8. Related to 6 & 7: provide some vocabulary and guidance for how to  \nlink RDF data without falling into the owl:sameAs black hole. Note, we  \nwon't completely solve this, but even a beginning would be a huge  \nimprovement over the current situation, and this should be done at the  \nRDF level rather than a forest of conflicting conventions growing into  \nuse.\n\n9. Provide some way (an RDF vocabulary?) to support versioning,  \ndeprecation, etc., if only some best practice recommendations.\n\nPat","n":0.036}}},{"i":209,"$":{"0":{"v":"Pascal Hitzler","n":0.707}}},{"i":210,"$":{"0":{"v":"Parker Conley","n":0.707}}},{"i":211,"$":{"0":{"v":"Otter Ai","n":0.707}}},{"i":212,"$":{"0":{"v":"Oskar Dudycz","n":0.707},"1":{"v":"\n- [[c.publisher]] [[ar.architecture-weekly]]","n":0.577}}},{"i":213,"$":{"0":{"v":"Normal Radtke","n":0.707},"1":{"v":"\n- worked-for: [[org.universitaet-leipzig]]","n":0.577}}},{"i":214,"$":{"0":{"v":"Nir Zicherman","n":0.707},"1":{"v":"\n- https://every.to/@nirzicherman","n":0.707}}},{"i":215,"$":{"0":{"v":"Nikos Papadakis","n":0.707}}},{"i":216,"$":{"0":{"v":"Nikos Maris","n":0.707}}},{"i":217,"$":{"0":{"v":"Niklas Luhman","n":0.707}}},{"i":218,"$":{"0":{"v":"Niklas Lidstrom","n":0.707}}},{"i":219,"$":{"0":{"v":"Nicole Van Der Hoeven","n":0.5},"1":{"v":"\n- https://nicolevanderhoeven.com/\n- Senior Developer Advocate at [[org.grafana]]","n":0.378}}},{"i":220,"$":{"0":{"v":"Nicolas Lazzari","n":0.707}}},{"i":221,"$":{"0":{"v":"Nicola Guarino","n":0.707}}},{"i":222,"$":{"0":{"v":"Nick Milo","n":0.707}}},{"i":223,"$":{"0":{"v":"Neil Trevett","n":0.707},"1":{"v":"\n-  [[c.role]] \n   -  initial chair, [[org.metaverse-standards-forum]]\n   -  president, [[org.khronos-group]]","n":0.316}}},{"i":224,"$":{"0":{"v":"Ned Markosian","n":0.707}}},{"i":225,"$":{"0":{"v":"Neal Stephensen","n":0.707},"1":{"v":"\n## References\n\n- https://www.wired.com/story/plaintext-neal-stephenson-named-the-metaverse-now-hes-building-it/","n":0.577}}},{"i":226,"$":{"0":{"v":"Nathan Furr","n":0.707}}},{"i":227,"$":{"0":{"v":"Natasha Noy","n":0.707}}},{"i":228,"$":{"0":{"v":"Natanael Arndt","n":0.707},"1":{"v":"\n- worked-for: [[org.universitaet-leipzig]]","n":0.577}}},{"i":229,"$":{"0":{"v":"Nat Eliason","n":0.707},"1":{"v":"\n\n\n- [[p.hasSite]] https://www.nateliason.com\n\n\n","n":0.577}}},{"i":230,"$":{"0":{"v":"Morgan Freeman","n":0.707}}},{"i":231,"$":{"0":{"v":"Mitch Lasky","n":0.707},"1":{"v":"\n- [[c.investor]]\n- created [[podcast.gamecraft]]\n- one of the greatest consumer investors of all time with a portfolio that includes Discord, Riot Games, and Snap. Much of his career was focused on video games","n":0.177}}},{"i":232,"$":{"0":{"v":"Mike Quigley","n":0.707},"1":{"v":"\n- [[c.role]] CMO, [[org.niantic]]","n":0.5}}},{"i":233,"$":{"0":{"v":"Mike Caufield","n":0.707},"1":{"v":"director of blended and networked learning at Washington State University Vancouver \r\n\r\n- [[p.hasSite]] https://hapgood.us/\r\n- [[p.creditedWith]] [[t.km.digital-gardening]]\r\n","n":0.25}}},{"i":234,"$":{"0":{"v":"Mike Bennett","n":0.707}}},{"i":235,"$":{"0":{"v":"Mieke Bal","n":0.707}}},{"i":236,"$":{"0":{"v":"Michael Uschold","n":0.707}}},{"i":237,"$":{"0":{"v":"Michael Mateas","n":0.707}}},{"i":238,"$":{"0":{"v":"Michael Martin","n":0.707},"1":{"v":"\n- worked-for: [[org.universitaet-leipzig]]","n":0.577}}},{"i":239,"$":{"0":{"v":"Michael Kearns","n":0.707},"1":{"v":"\n- [[p.cofounded]] [[org.virtasant]]\n","n":0.577}}},{"i":240,"$":{"0":{"v":"Michael Jewell","n":0.707}}},{"i":241,"$":{"0":{"v":"Michael Herzog","n":0.707}}},{"i":242,"$":{"0":{"v":"Michael Debellis","n":0.707}}},{"i":243,"$":{"0":{"v":"Mel Brooks","n":0.707}}},{"i":244,"$":{"0":{"v":"Megasploot","n":1},"1":{"v":"\n- created: [[prdct.wonderdraft]]","n":0.577}}},{"i":245,"$":{"0":{"v":"Max Wilson","n":0.707}}},{"i":246,"$":{"0":{"v":"Max Velmans","n":0.707}}},{"i":247,"$":{"0":{"v":"Matthew West","n":0.707},"1":{"v":"\n- dead","n":0.707}}},{"i":248,"$":{"0":{"v":"Matthew Kieran","n":0.707}}},{"i":249,"$":{"0":{"v":"Matt Margini","n":0.707}}},{"i":250,"$":{"0":{"v":"Mary Shelley","n":0.707}}},{"i":251,"$":{"0":{"v":"Martin Kleppmann","n":0.707}}},{"i":252,"$":{"0":{"v":"Martin Fowler","n":0.707}}},{"i":253,"$":{"0":{"v":"Marshall Mcluhan","n":0.707}}},{"i":254,"$":{"0":{"v":"Markus Lanthaler","n":0.707}}},{"i":255,"$":{"0":{"v":"Mark Otero","n":0.707},"1":{"v":"\n- [[c.role]] CEO [[org.azra-games]]\n- longtime dungeon master\n- took a break after 8 RPGs; players owning their characters brough him back\n- \"self-sovereign wealth creation\" : ","n":0.204}}},{"i":256,"$":{"0":{"v":"Mario Bittencourt","n":0.707},"1":{"v":"\n![](/assets/images/2023-11-28-09-19-47.png)","n":1}}},{"i":257,"$":{"0":{"v":"Maria Poveda Villalon","n":0.577}}},{"i":258,"$":{"0":{"v":"Maria Popova","n":0.707}}},{"i":259,"$":{"0":{"v":"Maria Keet","n":0.707},"1":{"v":"\n- url: http://www.meteck.org\n- blog\" https://keet.wordpress.com/\n\n[[prdct.dolce]]","n":0.447}}},{"i":260,"$":{"0":{"v":"Margaret Boden","n":0.707}}},{"i":261,"$":{"0":{"v":"Marcel Otto","n":0.707},"1":{"v":"\n- created: [[prdct.ontogen]], [[prdct.rtc-ex]], [[prdct.rdf.rtc]]","n":0.447}}},{"i":262,"$":{"0":{"v":"Marc Petit","n":0.707},"1":{"v":"\n- [[c.role]] VP Unreal Engine, Epic Games\n","n":0.378}}},{"i":263,"$":{"0":{"v":"Marc Duiker","n":0.707}}},{"i":264,"$":{"0":{"v":"Manu Sporny","n":0.707}}},{"i":265,"$":{"0":{"v":"Manfred Pfister","n":0.707}}},{"i":266,"$":{"0":{"v":"Maggie Appleton","n":0.707},"1":{"v":"\n- expert on what a [[c.digitalgarden]] is\n- evangelist of what a [[c.digitalgarden]] should be\n\n![](/assets/images/2023-06-05-09-36-17.png)","n":0.267}}},{"i":267,"$":{"0":{"v":"Madonna","n":1}}},{"i":268,"$":{"0":{"v":"M Schraefel","n":0.707}}},{"i":269,"$":{"0":{"v":"Linas Vepstas","n":0.707},"1":{"v":"\n\n- [[p.hasURL]] https://github.com/linas","n":0.577}}},{"i":270,"$":{"0":{"v":"Lex Sulzer","n":0.707}}},{"i":271,"$":{"0":{"v":"Lesley Lamport","n":0.707}}},{"i":272,"$":{"0":{"v":"Leonard Richardson","n":0.707}}},{"i":273,"$":{"0":{"v":"Lee D'Amato","n":0.707}}},{"i":274,"$":{"0":{"v":"Larry McMurtry","n":0.707}}},{"i":275,"$":{"0":{"v":"Kyren","n":1}}},{"i":276,"$":{"0":{"v":"Ksenia Se","n":0.707}}},{"i":277,"$":{"0":{"v":"Konrad Gnat","n":0.707}}},{"i":278,"$":{"0":{"v":"KJ Kearney","n":0.707},"1":{"v":"\n\n- \"Go for the [[t.mktg.mascots]] every time.\"\n","n":0.378}}},{"i":279,"$":{"0":{"v":"Kit Fine","n":0.707},"1":{"v":"\n@chatgpt.4o\n\nKit Fine is a distinguished philosopher known for his significant contributions to metaphysics, logic, and the philosophy of language. He is particularly noted for his work on topics such as the nature of reality, the structure of propositions, and the foundations of mathematics. Fine's work is characterized by its rigor and depth, and he is considered one of the leading figures in contemporary analytic philosophy.\n\n### Key Areas of Contribution:\n\n1. **Metaphysics**:\n   - Kit Fine has developed influential theories on topics like modality, essence, and the nature of reality. He has argued for a more nuanced understanding of the relationship between necessity and essence, challenging traditional views.\n   - He is known for his work on mereology (the study of parts and wholes) and has proposed alternative theories of parts, wholes, and identity.\n\n2. **Logic and Semantics**:\n   - Fine has made significant contributions to the study of logic, particularly in the area of non-classical logics, such as intuitionistic logic and relevance logic.\n   - His work on the semantics of natural language, particularly his analysis of conditionals and quantifiers, has been influential in the philosophy of language.\n\n3. **Philosophy of Mathematics**:\n   - Fine has also engaged with the philosophy of mathematics, examining the foundations of mathematical truth and the nature of mathematical objects.\n\n### Academic Background:\n- Kit Fine earned his PhD from the University of Warwick, and over the course of his career, he has held positions at several prestigious institutions, including the University of Oxford and the University of Southern California.\n- He is currently a professor at New York University (NYU), where he has been a faculty member for many years.\n\n### Notable Works:\n- **\"The Problem of De Re Modality\"**: In this work, Fine explores the nature of modal statements (statements about possibility and necessity) and their relationship to the objects they concern.\n- **\"Essence and Modality\"**: Fine challenges the conventional wisdom about the relationship between essence and modality, arguing for a more fine-grained approach to understanding necessity.\n- **\"Semantic Relationalism\"**: This book presents Fine's theory that the meanings of words and sentences are not fully determined by their intrinsic properties, but also by their relationships to other words and sentences.\n\n### Influence:\nKit Fine's work has had a profound impact on a wide range of areas in philosophy. He is widely regarded for his meticulous approach to philosophical problems and his ability to offer original and thought-provoking solutions to complex issues. His contributions continue to shape contemporary debates in metaphysics, logic, and the philosophy of language.","n":0.05}}},{"i":280,"$":{"0":{"v":"Kevin Lin","n":0.707},"1":{"v":"\r\n- [[p.alsoKnownAs]] kevins8\r\n- [[hasRole]] \r\n  - [[hasPosition]] CEO\r\n  - [[worksAt]] [[org.dendron]]\r\n","n":0.302}}},{"i":281,"$":{"0":{"v":"Kevin Fischer","n":0.707},"1":{"v":"\n- opensouls?\n- ","n":0.707}}},{"i":282,"$":{"0":{"v":"Kevin Feeny","n":0.707},"1":{"v":"\n\n- [[p.hasURL]] https://medium.com/@kevin_10337\n\n## [[prdct.medium]]\n\n- https://medium.com/terminusdb/graph-fundamentals-part-2-labelled-property-graphs-ba9a8edb5dfe\n  - \" RDF has a pure graph structure at a low-level but is often a confusing mess at a high level, while property graphs are the opposite\"\n  - jettisoning URLs in favor of local identifier becomes an ever more serious impediment — throwing away universal, uniform, dereferenceable identifiers in the age of the web looks less and less wise. \n  - \"property graphs will likely fade out as knowledge graphs become adopted by enterprises and incorporated into their infrastructure — a well defined schema is not an optional\"  \n- https://medium.com/terminusdb/graph-fundamentals-part-3-graph-schema-languages-1fc25ca294dd\n  - \"class hierarchies and typed properties are by far the most useful and important mechanisms for defining the structure of a graph\"\n  - open-world assumption is problematic\n- https://terminusdb.com/blog/graph-fundamentals-part-4-linked-data/\n  - the big problem [with reusing terms from well-known vocabularies] is that the well-known ontologies and vocabularies such as foaf and dublin-core that have been reused, cannot really be used as libraries in such a manner. They lack precise and correct definitions and they are full of errors and mutual inconsistencies [1] and they themselves use terms from other ontologies — creating huge and unwieldy dependency trees. If, for example, we want to use the foaf ontology as a library, we need to also include several dozen dependant libraries, some of which no longer exist. So, the linked data approach, in fact, just uses these terms as untyped tags — there is no clear and usable definition of what any of these terms actually mean — people just bung in whatever they want — creating a situation where there are effectively no reliable semantics to any of these terms.\n- https://medium.com/terminusdb/why-graph-will-win-703373bb5c41\n  - Everything is pre-joined — you don’t have to disassemble objects into normalised tables and reassemble them with joins.\n","n":0.059}}},{"i":283,"$":{"0":{"v":"Kevin Doubleday","n":0.707}}},{"i":284,"$":{"0":{"v":"Kenny Wtf","n":0.707},"1":{"v":"\n- active in @3mcd's [[prdct.javelin]] discord\n- [[p.hasURL]] https://github.com/kenjinp\n- ","n":0.354}}},{"i":285,"$":{"0":{"v":"Kenneth Iverson","n":0.707},"1":{"v":"\n- [[p.workedFor]] [[org.ibm]]\n- [[p.invented]] [[t.cs.languages.apl]]","n":0.447}}},{"i":286,"$":{"0":{"v":"Ken Baclawski","n":0.707}}},{"i":287,"$":{"0":{"v":"Keith Stuart","n":0.707},"1":{"v":"\n## Articles\n\n- [[ar.medium.onezero.in-the-future-video-games-will-care-about-you]]","n":0.577}}},{"i":288,"$":{"0":{"v":"Keanu","n":1}}},{"i":289,"$":{"0":{"v":"Katie Parrott","n":0.707}}},{"i":290,"$":{"0":{"v":"Katherine Price","n":0.707}}},{"i":291,"$":{"0":{"v":"Karl Menger","n":0.707}}},{"i":292,"$":{"0":{"v":"Karen Coyle","n":0.707}}},{"i":293,"$":{"0":{"v":"Justin Murphy","n":0.707},"1":{"v":"\n\n- [[p.created]] https://indiethinkers.org/\n","n":0.577}}},{"i":294,"$":{"0":{"v":"Justin Dowdy","n":0.707}}},{"i":295,"$":{"0":{"v":"Jurij Lotman","n":0.707}}},{"i":296,"$":{"0":{"v":"June Park","n":0.707}}},{"i":297,"$":{"0":{"v":"julian-dunn","n":1},"1":{"v":"\n- [[p.hasURL]] https://www.linkedin.com/in/julian/\n","n":0.577}}},{"i":298,"$":{"0":{"v":"Judith Altmann","n":0.707}}},{"i":299,"$":{"0":{"v":"Joyce Carol Oates","n":0.577}}},{"i":300,"$":{"0":{"v":"Joshua Johnson","n":0.707},"1":{"v":"\n- cofounder of gheppeto AI, trying to drive forward the divergent technology towards the holodeck","n":0.258}}},{"i":301,"$":{"0":{"v":"Jony Ive","n":0.707}}},{"i":302,"$":{"0":{"v":"Jonathan Gros Dubois","n":0.577}}},{"i":303,"$":{"0":{"v":"Jonathan Barbato","n":0.707}}},{"i":304,"$":{"0":{"v":"Jonas Lagoni","n":0.707},"1":{"v":"\n- url: https://github.com/jonaslagoni/\n- [[p.contributedTo]] [[prdct.gamingapi]]","n":0.447}}},{"i":305,"$":{"0":{"v":"Jon Phipps","n":0.707}}},{"i":306,"$":{"0":{"v":"John Sowa","n":0.707},"1":{"v":"\n- url: https://www.jfsowa.com/ontology/\n- created: [[prdct.kr-ontology]] \n\n\n## Quotes\n\n- \"The best way to do research is to break the definition.\"","n":0.236}}},{"i":307,"$":{"0":{"v":"John Riccitiello","n":0.707},"1":{"v":"\n- [[c.role]] CEO, [[org.unity-technologies]]","n":0.5}}},{"i":308,"$":{"0":{"v":"John Gruber","n":0.707},"1":{"v":"\n- [[p.created]] [[prdct.markdown]]\n- [[p.hasSite]] [[Daring Fireball|https://daringfireball.net/]]\n","n":0.408}}},{"i":309,"$":{"0":{"v":"John Gaeta","n":0.707},"1":{"v":"\n## References\n\n- https://www.imdb.com/name/nm1894536/awards/","n":0.577}}},{"i":310,"$":{"0":{"v":"John Boyd","n":0.707}}},{"i":311,"$":{"0":{"v":"Johannes Trame","n":0.707}}},{"i":312,"$":{"0":{"v":"Joep Meindertsma","n":0.707},"1":{"v":"\n\n- aka: \n  - https://github.com/joepio/\n  - https://www.reddit.com/user/joepmeneer/","n":0.378}}},{"i":313,"$":{"0":{"v":"Joel Spolsky","n":0.707}}},{"i":314,"$":{"0":{"v":"Joel Chan","n":0.707},"1":{"v":"\n- url: http://joelchan.me/\n- description: \n  - Joel Chan is an Assistant Professor at the [University of Marlyand’s College of Information Studies](https://ischool.umd.edu/).\n\nJoel’s “[research](http://joelchan.me/research/) and [teaching](http://joelchan.me/teaching/) explore **systems that support creative knowledge work**, in domains such as design and scientific discovery.”\n\nJoel’s research at the knowledge frontiers primarily covers the use of discourse graphs, seminally described in _[Discourse Graphs for Augmented Knowledge Synthesis: What and Why](http://joelchan.me/assets/pdf/Discourse_Graphs_for_Augmented_Knowledge_Synthesis_What_and_Why.pdf)_, is an information model or architecture “[that enables researchers and communicators to map their ideas and arguments in a modular, composable graph format](https://network-goods.notion.site/The-Discourse-Graph-starter-pack-312374c813b24ec6b4d53a054371ee5a).”","n":0.108}}},{"i":315,"$":{"0":{"v":"Joao Paulo Almeida","n":0.577},"1":{"v":"\n![](/assets/images/2024-10-11-18-08-17.png)","n":1}}},{"i":316,"$":{"0":{"v":"Joan Didion","n":0.707},"1":{"v":"\n\n\n- [[p.died]] 2021-12-23\n","n":0.577}}},{"i":317,"$":{"0":{"v":"Jess Martin","n":0.707}}},{"i":318,"$":{"0":{"v":"Jeremy Taylor","n":0.707},"1":{"v":"\n- head of product, xtdb at [[org.juxt]] ","n":0.378}}},{"i":319,"$":{"0":{"v":"Jeff Wheat","n":0.707},"1":{"v":"\n- [[p.workedFor]] [[org.lumu]]\n- talent shortage requires simplifications\n- you're up against nation-state actors\n- \"impossible to get cyber insurance if you've had a ransomware incident\"\n- \"if they come in with a meat axe, you're not going to get what you're paying for\"\n- \"one vendor is not enough; there are no silver bullets\"\n- current limitations of [[t.cs.security.security-operations-center]]\n  - alert fatigue\n  - limited information\n    - just because you caught one thing...\n  - siloed systems\n  - complex/limited integrations\n","n":0.117}}},{"i":320,"$":{"0":{"v":"Jeannie Warner","n":0.707},"1":{"v":"\n- [[p.workedFor]] [[org.exabeam]]","n":0.577}}},{"i":321,"$":{"0":{"v":"Jean Piaget","n":0.707}}},{"i":322,"$":{"0":{"v":"Javipalanca","n":1},"1":{"v":"\n- [[p.wrote]] [[prdct.spade]]","n":0.577}}},{"i":323,"$":{"0":{"v":"Janna Hastings","n":0.707}}},{"i":324,"$":{"0":{"v":"Janet Singer","n":0.707},"1":{"v":"\n- url: https://www.researchgate.net/profile/Janet-Singer\n- ","n":0.577}}},{"i":325,"$":{"0":{"v":"Janet Murray","n":0.707},"1":{"v":"\n- \"a lover of postmodern technology who hates postmodern theory, a digital-media scholar with the reference points of an old-fashioned literary critic, a literary critic who writes in the future tense\"\n- \"does not share the “naïve optimism” of the futurist @ray-kurzweil, for instance, who heralds the moment when human intelligence will merge with A.I.—or of the V.R. entrepreneur @chris-milk, who believes that virtual reality can instill empathy in people like a moral software update. She prefers the rationalism, and the humanism, of old-fashioned science fiction.\"\n\n## References\n\n- [[ar.newyorker.hamlet-on-the-holodeck-twenty-years-later]]","n":0.107}}},{"i":326,"$":{"0":{"v":"Jamie Mccusker","n":0.707}}},{"i":327,"$":{"0":{"v":"James Whiteside","n":0.707}}},{"i":328,"$":{"0":{"v":"James Lauder","n":0.707}}},{"i":329,"$":{"0":{"v":"James Clear","n":0.707},"1":{"v":"\n## [[c.quotes]]\n\n- Arguably the most important skill is controlling your attention.\n","n":0.302}}},{"i":330,"$":{"0":{"v":"James Buckhouse","n":0.707}}},{"i":331,"$":{"0":{"v":"James Borow","n":0.707}}},{"i":332,"$":{"0":{"v":"James Baldwin","n":0.707}}},{"i":333,"$":{"0":{"v":"Jakob Voss","n":0.707},"1":{"v":"\n\n\n- [[p.hasSite]] http://aboutdata.org\n\n","n":0.577}}},{"i":334,"$":{"0":{"v":"Jacob O'Bryant","n":0.707},"1":{"v":"\n- url: We curate articles from hundreds of blogs and newsletters and send you the ones that match your interests.","n":0.224}}},{"i":335,"$":{"0":{"v":"Jack Soslow","n":0.707}}},{"i":336,"$":{"0":{"v":"Jack Shepherd","n":0.707},"1":{"v":"\n- https://medium.com/@jackashepherd","n":0.707}}},{"i":337,"$":{"0":{"v":"Ivystive","n":1},"1":{"v":"\n- [[p.workedFor]] [[org.lamina1]] \n- [[c.account.twitter]] https://twitter.com/ivystive\n- [[c.account.instagram]] https://www.instagram.com/ivystive\n- lived-in: [[loc.los-angeles]]\n- ","n":0.316}}},{"i":338,"$":{"0":{"v":"Ivan Sutherland","n":0.707},"1":{"v":"\n- Sutherland's [[prdct.sketchpad]] was inspired by the [[prdct.memex]] from \" [[ar.atlantic.as-we-may-think]]\" by @vannevar-bush","n":0.277}}},{"i":339,"$":{"0":{"v":"Irene Polikoff","n":0.707},"1":{"v":"\n- role: co-founder of [[org.topquadrant]]","n":0.447}}},{"i":340,"$":{"0":{"v":"Immanuel Kant","n":0.707}}},{"i":341,"$":{"0":{"v":"Ian Bogost","n":0.707}}},{"i":342,"$":{"0":{"v":"Ian Bailey","n":0.707},"1":{"v":"\n- worked-at: [[org.telicent]]","n":0.577}}},{"i":343,"$":{"0":{"v":"Hubert Thielblot","n":0.707}}},{"i":344,"$":{"0":{"v":"Hillary Mason","n":0.707},"1":{"v":"\n- cofounder of [[org.hidden-door]]","n":0.5}}},{"i":345,"$":{"0":{"v":"Hilary Mante","n":0.707},"1":{"v":"\n## References\n\n- https://www.theguardian.com/books/2024/sep/19/hilary-mantel-mentor-seven-things-she-taught-me-writing-and-life","n":0.577}}},{"i":346,"$":{"0":{"v":"Henry David Thoreau","n":0.577}}},{"i":347,"$":{"0":{"v":"Helmut Bonheim","n":0.707}}},{"i":348,"$":{"0":{"v":"Heinrich Herre","n":0.707}}},{"i":349,"$":{"0":{"v":"Harvey Michael Pratt","n":0.577},"1":{"v":"\n- ai-powered video games; [[game.the-promenade]]\n- [x] giving invite codes\n- artist, engineer, founder in that order; people are only going to be happy if the games clap back","n":0.192}}},{"i":350,"$":{"0":{"v":"Hans Brahm","n":0.707},"1":{"v":"\n- https://en.wikipedia.org/wiki/John_Brahm\n\n## References\n\n","n":0.577}}},{"i":351,"$":{"0":{"v":"Guy Kawasaki","n":0.707},"1":{"v":"\n## [[p.wrote]] \n\n- [[book.art-of-the-start]]\n- that Apple 2 tutorial... \"Apple Presents the IIe\"","n":0.289}}},{"i":352,"$":{"0":{"v":"Griffith Morgan","n":0.707},"1":{"v":"\n- directed: [[video.secrets-of-blackmoor]]","n":0.577}}},{"i":353,"$":{"0":{"v":"Gregg Deal","n":0.707}}},{"i":354,"$":{"0":{"v":"Greg Solo","n":0.707}}},{"i":355,"$":{"0":{"v":"Greg Madey","n":0.707}}},{"i":356,"$":{"0":{"v":"Greg Costikyan","n":0.707}}},{"i":357,"$":{"0":{"v":"Grady Booch","n":0.707}}},{"i":358,"$":{"0":{"v":"Gordon Brander","n":0.707}}},{"i":359,"$":{"0":{"v":"Gordan Brander","n":0.707}}},{"i":360,"$":{"0":{"v":"Goran Nieragden","n":0.707}}},{"i":361,"$":{"0":{"v":"Gilad Bracha","n":0.707},"1":{"v":"\n- \"I find the word  theologian  quite irregular. How many biologians, geologians or philologians do you know? Computational theology is very much concerned with preventing this kind of irregularity, which is so characteristic of natural language, from  spreading in computing systems, especially programming languages.  So I opted for the more regular expression, Computational Theologist.\"\n- [[p.interestedIn]] [[t.cs.programming.reflection]]","n":0.134}}},{"i":362,"$":{"0":{"v":"Giancarlo Guizzardi","n":0.707},"1":{"v":"\n![](/assets/images/2024-10-11-18-08-00.png)","n":1}}},{"i":363,"$":{"0":{"v":"Gerd Wagner","n":0.707},"1":{"v":"\n- https://oxygen.informatik.tu-cottbus.de/publications/wagner/","n":0.707}}},{"i":364,"$":{"0":{"v":"George Svarovsky","n":0.707},"1":{"v":"\n- https://github.com/gsvarovsky\n- ","n":0.707}}},{"i":365,"$":{"0":{"v":"George Martin","n":0.707}}},{"i":366,"$":{"0":{"v":"George Beston","n":0.707}}},{"i":367,"$":{"0":{"v":"Gene Wilder","n":0.707}}},{"i":368,"$":{"0":{"v":"Gene Kirkwood","n":0.707}}},{"i":369,"$":{"0":{"v":"Gavin Mendel-Gleason","n":0.707},"1":{"v":"\n- https://www.linkedin.com/in/gavinmendelgleason\n- worked-at: [[org.terminusdb]] as CTO","n":0.408}}},{"i":370,"$":{"0":{"v":"Gary Marcus","n":0.707}}},{"i":371,"$":{"0":{"v":"Gary Berg-Cross","n":0.707}}},{"i":372,"$":{"0":{"v":"Fritz Laux","n":0.707},"1":{"v":"\n- [[p.workedFor]] [[org.reutlingen-university]]\n","n":0.577}}},{"i":373,"$":{"0":{"v":"Fred Baptiste","n":0.707}}},{"i":374,"$":{"0":{"v":"Franz Kafka","n":0.707}}},{"i":375,"$":{"0":{"v":"Franz Brentano","n":0.707}}},{"i":376,"$":{"0":{"v":"Frank Slootman","n":0.707}}},{"i":377,"$":{"0":{"v":"Frank Loebe","n":0.707}}},{"i":378,"$":{"0":{"v":"Fotis Jannidis","n":0.707}}},{"i":379,"$":{"0":{"v":"Filip Kovacevic","n":0.707}}},{"i":380,"$":{"0":{"v":"Fernando Doglio","n":0.707}}},{"i":381,"$":{"0":{"v":"Fajar Ekaputra","n":0.707}}},{"i":382,"$":{"0":{"v":"Faith Lawrence","n":0.707},"1":{"v":"\n- ","n":1}}},{"i":383,"$":{"0":{"v":"Fabian Neuhaus","n":0.707}}},{"i":384,"$":{"0":{"v":"Evdoxios Baratis","n":0.707}}},{"i":385,"$":{"0":{"v":"Evan Hemsley","n":0.707},"1":{"v":"\n- programmer on [[game.samurai-gunn-2]]","n":0.5}}},{"i":386,"$":{"0":{"v":"Evan Armstrong","n":0.707}}},{"i":387,"$":{"0":{"v":"Eva Thomas","n":0.707}}},{"i":388,"$":{"0":{"v":"Euripedes Petrakis","n":0.707}}},{"i":389,"$":{"0":{"v":"Eugeny","n":1}}},{"i":390,"$":{"0":{"v":"Eugenia","n":1},"1":{"v":"\n- created Replica chatbot for relationships","n":0.408}}},{"i":391,"$":{"0":{"v":"Eugene","n":1},"1":{"v":"\n- worked at occulus with @edward-saatchi","n":0.408}}},{"i":392,"$":{"0":{"v":"Eric Maisel","n":0.707}}},{"i":393,"$":{"0":{"v":"Eric Evans","n":0.707}}},{"i":394,"$":{"0":{"v":"Endel Dreyer","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://app.gumroad.com/endel\n- [[p.created]] [[prdct.colyseus]]\n- [[p.presented]]\n  - [Making Multiplayer Games with Colyseus, Node js and TypeScript - YouTube](https://www.youtube.com/watch?v=KnN6nRtfL44) at ","n":0.229}}},{"i":395,"$":{"0":{"v":"Emily Short","n":0.707},"1":{"v":"\n- blog: https://emshort.blog\n\n## Articles\n\n- [[ar.emshort.beyond-branching-quality-based-and-salience-based-narrative-structures]]","n":0.447}}},{"i":396,"$":{"0":{"v":"Elon Musk","n":0.707}}},{"i":397,"$":{"0":{"v":"Elizabeth Zalman","n":0.707}}},{"i":398,"$":{"0":{"v":"Elisa Kendall","n":0.707}}},{"i":399,"$":{"0":{"v":"Edwin Abbott","n":0.707}}},{"i":400,"$":{"0":{"v":"Edward Saatchi","n":0.707},"1":{"v":"\n- role: ceo at [[org.fable]]","n":0.447}}},{"i":401,"$":{"0":{"v":"Edward Morgan Forster","n":0.577}}},{"i":402,"$":{"0":{"v":"Edward Jonathan Lowe","n":0.577},"1":{"v":"\n- aka: E.J. Lowe, Jonathan","n":0.447}}},{"i":403,"$":{"0":{"v":"Ed Greenwood","n":0.707},"1":{"v":"\n## Resources\n\n- [Dragon magazine 244: Profiles](https://www.annarchive.com/files/Drmg244.pdf)","n":0.408}}},{"i":404,"$":{"0":{"v":"Douglas Ross","n":0.707},"1":{"v":"\n- \"by the late 1980s he considered Plex an \"intolerable burden of responsibility\"[31] to be its sole proponent and prophet.\"\n- ","n":0.224}}},{"i":405,"$":{"0":{"v":"Douglas Adams","n":0.707}}},{"i":406,"$":{"0":{"v":"Doug Sharp","n":0.707}}},{"i":407,"$":{"0":{"v":"Doraku","n":1},"1":{"v":"\n- aka: Paillat Laszlo\n- reddit: u/default_developer\n- ","n":0.408}}},{"i":408,"$":{"0":{"v":"Don Norman","n":0.707}}},{"i":409,"$":{"0":{"v":"Don Estridge","n":0.707}}},{"i":410,"$":{"0":{"v":"Dominik Tomaszuk","n":0.707}}},{"i":411,"$":{"0":{"v":"Djradon","n":1}}},{"i":412,"$":{"0":{"v":"Diorbert Pereira","n":0.707}}},{"i":413,"$":{"0":{"v":"Derek Sivers","n":0.707},"1":{"v":"\n- runs [[prdct.nownownow]]","n":0.577}}},{"i":414,"$":{"0":{"v":"Den Jones","n":0.707},"1":{"v":"\n- [[p.workedFor]]\n  - [[org.adobe]]\n  - [[org.cisco]]\n  - [[org.banyan-security]]","n":0.354}}},{"i":415,"$":{"0":{"v":"Deborah Mcguinness","n":0.707},"1":{"v":"\n- professor at RPI","n":0.5}}},{"i":416,"$":{"0":{"v":"Debasish Ghosh","n":0.707}}},{"i":417,"$":{"0":{"v":"Dean Allemang","n":0.707},"1":{"v":"\n- [[p.wrote]] [[book.semantic-web-for-the-working-ontologist]]","n":0.577}}},{"i":418,"$":{"0":{"v":"David Shotton","n":0.707}}},{"i":419,"$":{"0":{"v":"David Mark","n":0.707}}},{"i":420,"$":{"0":{"v":"David Krakauer","n":0.707},"1":{"v":"\n- \"president and William Miller Professor of Complex Systems at the Santa Fe Institute in New Mexico. He works on the evolution of intelligence and stupidity on Earth.\"\n\n","n":0.189}}},{"i":421,"$":{"0":{"v":"David Kadavy","n":0.707}}},{"i":422,"$":{"0":{"v":"David Goggins","n":0.707}}},{"i":423,"$":{"0":{"v":"David Foster Wallace","n":0.577}}},{"i":424,"$":{"0":{"v":"David Cronenberg","n":0.707}}},{"i":425,"$":{"0":{"v":"David Allen","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://gettingthingsdone.com/\n- [[p.creditedWith]] [[idea.write-only-syndrome]]\n","n":0.447}}},{"i":426,"$":{"0":{"v":"Dave","n":1},"1":{"v":"\n- https://orcid.org/0000-0002-4959-6058\n- https://nownownow.com/p/sbcs\n\n\n\n","n":0.577}}},{"i":427,"$":{"0":{"v":"Dave Browning","n":0.707},"1":{"v":"\n- https://dblp.org/pid/41/6472.html","n":0.707}}},{"i":428,"$":{"0":{"v":"Dave Arneson","n":0.707},"1":{"v":"\n![](/assets/images/2024-09-29-07-17-45.png)\n- inventor of role-playing gaming\n- “Why did it catch on so quickly? Because it offered almost pure escapism and the ability, in the game, to do anything and everything you wanted to do! Gads! Who wouldn’t get hooked on game playing nirvana like that after years of charts, tables, painting figures, etc.” ^y4ifwk0pc4o2\n- the things that D&D fans love the most about the game—the things that distinguish “role-playing” from “fantasy wargaming”—were Arneson’s vision.","n":0.117}}},{"i":429,"$":{"0":{"v":"Daniele Porello","n":0.707}}},{"i":430,"$":{"0":{"v":"Daniele Metilli","n":0.707}}},{"i":431,"$":{"0":{"v":"Daniel Meyer","n":0.707},"1":{"v":"\n#aka pubkey\n","n":0.707}}},{"i":432,"$":{"0":{"v":"Daniel Ingalls","n":0.707}}},{"i":433,"$":{"0":{"v":"Daniel Garijo","n":0.707}}},{"i":434,"$":{"0":{"v":"Daniel Evans","n":0.707},"1":{"v":"\n- [[c.role]] CEO [[org.reely]]","n":0.5}}},{"i":435,"$":{"0":{"v":"Daniel Cook","n":0.707}}},{"i":436,"$":{"0":{"v":"Daniel Bakas","n":0.707}}},{"i":437,"$":{"0":{"v":"Dan Shipper","n":0.707},"1":{"v":"\n- [[p.associatedWith]] [[ar.superorganizers]]","n":0.577}}},{"i":438,"$":{"0":{"v":"Colin Atkinson","n":0.707}}},{"i":439,"$":{"0":{"v":"Cliff Nass","n":0.707},"1":{"v":"\n\n\nThe late, great Professor of Communication.\n\n## quotes\n\n- > It turns out multitaskers are terrible at every aspect of multitasking. They’re terrible at ignoring irrelevant information; they’re terrible at keeping information in their head nicely and neatly organized; and they’re terrible at switching from one task to another. [...]\n  >\n  > One would think that if people were bad at multitasking, they would stop. However, when we talk with the multitaskers, they seem to think they’re great at it and seem totally unfazed and totally able to do more and more and more.\n  - [[p.hasSource]] [[nytimes|https://www.nytimes.com/2013/11/07/business/clifford-nass-researcher-on-multitasking-dies-at-55.html]]\n\n## Related\n","n":0.102}}},{"i":440,"$":{"0":{"v":"Claudio Masolo","n":0.707},"1":{"v":"\n- https://www.istc.cnr.it/en/people/claudio-masolo","n":0.707}}},{"i":441,"$":{"0":{"v":"Claudenir Fonseca","n":0.707},"1":{"v":"\n![](/assets/images/2024-10-11-18-08-35.png)","n":1}}},{"i":442,"$":{"0":{"v":"Claude","n":1}}},{"i":443,"$":{"0":{"v":"3","n":1}}},{"i":444,"$":{"0":{"v":"Sonnet","n":1}}},{"i":445,"$":{"0":{"v":"Opus","n":1}}},{"i":446,"$":{"0":{"v":"Cindy Daignault","n":0.707}}},{"i":447,"$":{"0":{"v":"Christopher Welty","n":0.707}}},{"i":448,"$":{"0":{"v":"Christoph Dorn","n":0.707},"1":{"v":"\n- [[c.role]] Head of Research, [[org.vaticle]]  ","n":0.408}}},{"i":449,"$":{"0":{"v":"Chris Partridge","n":0.707}}},{"i":450,"$":{"0":{"v":"Chris Mungall","n":0.707}}},{"i":451,"$":{"0":{"v":"Chris Milk","n":0.707}}},{"i":452,"$":{"0":{"v":"Chris Mahoney","n":0.707}}},{"i":453,"$":{"0":{"v":"Chris Kempes","n":0.707},"1":{"v":"\n- professor at the Santa Fe Institute, working at the intersection of physics, biology, and the earth sciences.","n":0.236}}},{"i":454,"$":{"0":{"v":"Chris Farkouh","n":0.707}}},{"i":455,"$":{"0":{"v":"Chris Aldrich","n":0.707},"1":{"v":"\n\n- [[p.hasBlog]] https://boffosocko.com/\n","n":0.577}}},{"i":456,"$":{"0":{"v":"Charles Sanders Peirce","n":0.577}}},{"i":457,"$":{"0":{"v":"Charles Feval","n":0.707},"1":{"v":"\n- [[c.website]] https://feval.ca/\n- [[p.workedFor]] [[org.microsoft]]","n":0.447}}},{"i":458,"$":{"0":{"v":"Charles Crnoevich","n":0.707}}},{"i":459,"$":{"0":{"v":"Cecilia D'Anastasio","n":0.707},"1":{"v":"\n- https://kotaku.com/author/ceciliadanastasio","n":0.707}}},{"i":460,"$":{"0":{"v":"Carsten Kessler","n":0.707}}},{"i":461,"$":{"0":{"v":"Carlo Meghini","n":0.707}}},{"i":462,"$":{"0":{"v":"Carl Sagan","n":0.707}}},{"i":463,"$":{"0":{"v":"Camille Roth","n":0.707},"1":{"v":"\n- url: https://camilleroth.github.io/","n":0.577}}},{"i":464,"$":{"0":{"v":"Cameron Crowe","n":0.707}}},{"i":465,"$":{"0":{"v":"Bud Powell","n":0.707}}},{"i":466,"$":{"0":{"v":"Brian Platz","n":0.707}}},{"i":467,"$":{"0":{"v":"Bret Victor","n":0.707},"1":{"v":"\n\n- [[p.hasSite]] [[ar.worrydream]]\n\n## [[p.hadTouch]] \n\n- [[2am stumbling|2022.11.30]] from [[ar.maggieappleton.programming-portals]], thanks @maggie-appleton  ^js94wphvf1wi","n":0.289}}},{"i":468,"$":{"0":{"v":"Boris Iordanov","n":0.707},"1":{"v":"\n- [[p.workedFor]]\n  - [[org.vaticle]] VP of Engineering\n  - [[org.granthika]]\n\n## Resources\n\n- https://blog.vaticle.com/meet-the-team-boris-iordanov-6a30a949cdab\n","n":0.302}}},{"i":469,"$":{"0":{"v":"Bob Doto","n":0.707}}},{"i":470,"$":{"0":{"v":"Billy Beane","n":0.707}}},{"i":471,"$":{"0":{"v":"Bill Wake","n":0.707},"1":{"v":"\n\n\n- [[p.invented]]\n  - INVEST model for user stories\n  - Arrange-Act-Assert pattern of [[t.cs.sd.testing.unit-testing]]. \n\n## [[p.said]]\n- stories aren't a spec, they're an input to collaboration\n","n":0.204}}},{"i":472,"$":{"0":{"v":"Bill Seitz","n":0.707}}},{"i":473,"$":{"0":{"v":"Benn Stancil","n":0.707}}},{"i":474,"$":{"0":{"v":"Beardontheblock","n":1},"1":{"v":"\n- [[c.account.twitter]] https://twitter.com/BeardOnTheBlock","n":0.577}}},{"i":475,"$":{"0":{"v":"Bart Nooteboom","n":0.707}}},{"i":476,"$":{"0":{"v":"Barry Smith","n":0.707},"1":{"v":"\n- [[p.workedOn]] [[prdct.open-biological-ontology]]","n":0.577}}},{"i":477,"$":{"0":{"v":"Bailie Macwheeble","n":0.707},"1":{"v":"\n- character in [[book.waverly]]\n","n":0.5}}},{"i":478,"$":{"0":{"v":"Assaf Sagy","n":0.707},"1":{"v":"\n- [[c.role]] global head of gaming, [[org.tiktok]]","n":0.378}}},{"i":479,"$":{"0":{"v":"Arthur Griffth","n":0.707}}},{"i":480,"$":{"0":{"v":"Antoine Zimmermann","n":0.707}}},{"i":481,"$":{"0":{"v":"Anthony Moretti","n":0.707}}},{"i":482,"$":{"0":{"v":"Ann Mckinnon","n":0.707}}},{"i":483,"$":{"0":{"v":"Angela Yu","n":0.707}}},{"i":484,"$":{"0":{"v":"Andy Matuschak","n":0.707},"1":{"v":"\n\n- [[p.hasSite]] \n  - [Andy's working notes](https://notes.andymatuschak.org)\n  - [Orbit helps you deeply internalize ideas through periodic review.](https://withorbit.com/)\n  \n","n":0.236}}},{"i":485,"$":{"0":{"v":"Andrew Johnson","n":0.707}}},{"i":486,"$":{"0":{"v":"Andrew Stern","n":0.707}}},{"i":487,"$":{"0":{"v":"Andrew Bird","n":0.707}}},{"i":488,"$":{"0":{"v":"Andreas Rauber","n":0.707}}},{"i":489,"$":{"0":{"v":"Andre Demori","n":0.707},"1":{"v":"\n- https://www.researchgate.net/profile/Andre-Demori-2\n","n":0.707}}},{"i":490,"$":{"0":{"v":"Anatoly Levenchuk","n":0.707}}},{"i":491,"$":{"0":{"v":"Anas Fahad Khan","n":0.577}}},{"i":492,"$":{"0":{"v":"Amie Thomasson","n":0.707},"1":{"v":"\n- wrote: [[book.fiction-and-metaphysics]]","n":0.577}}},{"i":493,"$":{"0":{"v":"Amelie Zollner Weber","n":0.577}}},{"i":494,"$":{"0":{"v":"Amber Atherton","n":0.707},"1":{"v":"\n- url: https://twitter.com/AmberAtherton\n- role: principle? at [[org.patron]]","n":0.378}}},{"i":495,"$":{"0":{"v":"Alvin Leung","n":0.707}}},{"i":496,"$":{"0":{"v":"Alexey Menshikov","n":0.707},"1":{"v":"\n- [[p.workedFor]] [[org.beatshapers]]","n":0.577}}},{"i":497,"$":{"0":{"v":"Alexander Zakusylo","n":0.707},"1":{"v":"\n- aka: zakgof\n","n":0.577}}},{"i":498,"$":{"0":{"v":"Alex Shkotin","n":0.707}}},{"i":499,"$":{"0":{"v":"Alex Martelli","n":0.707}}},{"i":500,"$":{"0":{"v":"Aldo Gangemi","n":0.707}}},{"i":501,"$":{"0":{"v":"Albert Bierstadt","n":0.707}}},{"i":502,"$":{"0":{"v":"Alan Ruttenberg","n":0.707}}},{"i":503,"$":{"0":{"v":"Alan Rector","n":0.707}}},{"i":504,"$":{"0":{"v":"Aglitchman","n":1}}},{"i":505,"$":{"0":{"v":"Adetayo Oludare Alade","n":0.577}}},{"i":506,"$":{"0":{"v":"Adam Prugel Bennett","n":0.577}}},{"i":507,"$":{"0":{"v":"Adam Pease","n":0.707}}},{"i":508,"$":{"0":{"v":"Adam Osborne","n":0.707}}},{"i":509,"$":{"0":{"v":"Ada Rose Canon","n":0.577}}},{"i":510,"$":{"0":{"v":"Aaron Sisto","n":0.707},"1":{"v":"\n- role: [[org.first-spark-ventures]]","n":0.577}}},{"i":511,"$":{"0":{"v":"Aaron Lynn","n":0.707},"1":{"v":"\n\r\n- [[p.hasSite]] https://aaronlynn.com/\r\n\r\n\r\n[[How to Set up Your Personal Task Management System|ar.aaronlynn.how-to-set-up-your-personal-task-management-system]]\r\nhow-to-set-up-your-personal-task-management-system\r\n\r\n- https://aaronlynn.com/personal-task-management/ \r\n  - [[topic.tm]] \r\n  - distinction between tasks, information and trash\r\n## Personal Ops\r\n\r\n1. Mission/Purpose.\r\n2. List of values.\r\n3. Reasons why.\r\n4. Select reminders and affirmations.\r\n5. List of virtues.\r\n6. List of vices.\r\n7. Long-term vision or vision of tomorrow.\r\n8. Gratitude list.\r\n","n":0.143}}},{"i":512,"$":{"0":{"v":"Tom Preston-Werner","n":0.707},"1":{"v":"\n\n\n- [[p.started]] [[prdct.github]]\n- [[p.created]] [[prdct.toml]]\n","n":0.447}}},{"i":513,"$":{"0":{"v":"Tim Kindberg","n":0.707},"1":{"v":"\n\n\n- [[p.hasBlog]] http://matter2media.com/blog/\n\n","n":0.577}}},{"i":514,"$":{"0":{"v":"Tiago Forte","n":0.707},"1":{"v":"\n\n\n- [[p.interviewed]] @sönke-ahrens \n","n":0.5}}},{"i":515,"$":{"0":{"v":"Sönke Ahrens","n":0.707},"1":{"v":"\n\n\n\n- [-] [[p.appearedIn]] [Interview and Q&A with Sönke Ahrens on How to Take Smart Notes](https://www.youtube.com/watch?v=kXnR7qX3BDc&t=1399s)\n","n":0.258}}},{"i":516,"$":{"0":{"v":"Mary-Oliver","n":1}}},{"i":517,"$":{"0":{"v":"Justin-Fodor","n":1},"1":{"v":"\n\n- [[p.workedFor]] [[prdct.kandji]]\n","n":0.577}}},{"i":518,"$":{"0":{"v":"John Carmack","n":0.707}}},{"i":519,"$":{"0":{"v":"Eric McDaniel","n":0.707},"1":{"v":"\n\n\n- [[p.created]] [[prdct.javelin]]\n","n":0.577}}},{"i":520,"$":{"0":{"v":"Daniel Lüdecke","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://github.com/strengejacke\n- [[p.hasSite]] http://www.danielluedecke.de/\n","n":0.447}}},{"i":521,"$":{"0":{"v":"Charlie Munger","n":0.707}}},{"i":522,"$":{"0":{"v":"Carl Jacobi","n":0.707}}},{"i":523,"$":{"0":{"v":"Bobby-Narang","n":1},"1":{"v":"\n\n- [[p.cofounded]] [[prdct.opensense]]\n","n":0.577}}},{"i":524,"$":{"0":{"v":"3mcd","n":1},"1":{"v":"\n- [[p.hasURL]] https://github.com/3mcd\n\n","n":0.577}}},{"i":525,"$":{"0":{"v":"Tags","n":1}}},{"i":526,"$":{"0":{"v":"Philosophy","n":1}}},{"i":527,"$":{"0":{"v":"Language","n":1}}},{"i":528,"$":{"0":{"v":"Cc by 4","n":0.577}}},{"i":529,"$":{"0":{"v":"CC-BY-4.0","n":1}}},{"i":530,"$":{"0":{"v":"writtenIn","n":1}}},{"i":531,"$":{"0":{"v":"Username","n":1}}},{"i":532,"$":{"0":{"v":"URL","n":1},"1":{"v":"\n- [[p.alsoKnownAs]] \n  - [[p.hasURL]]","n":0.447}}},{"i":533,"$":{"0":{"v":"TypeScript","n":1}}},{"i":534,"$":{"0":{"v":"Topic","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[p.hasTopic]]","n":0.577}}},{"i":535,"$":{"0":{"v":"Tools for Thought","n":0.577},"1":{"v":"\n\n- resources:  https://news.ycombinator.com/item?id=23667381\n  - talks about dealing with lotsa files in a single top-level directory... but Dendron's vaults can help\n- resources:  https://subconscious.substack.com/p/tools-for-thought-in-your-ooda-loop\n  - \"Tools for thought are tools for orientation. They’re the big circle in the OODA diagram. A tool for thought…\n\n    Expands your awareness. The more you sense, the broader your ability to orient in your environment.\n\n    Builds up a memory across time. Expanding your time horizon into a long now lets you act across broader timescales, lets you generalize across wider distributions, and avoid fat tailed risks.\n\n    Broadens the surface area for luck to strike, by collecting stepping stones that expand your adjacent possible.\n\n    Increases your bandwidth for synthesis by augmenting our intellect, and provoking creative insights.\n\n    Evolves the complexity of your world-model. The bigger the memes, the complex-er your thoughts.\"","n":0.087}}},{"i":536,"$":{"0":{"v":"Time","n":1}}},{"i":537,"$":{"0":{"v":"Tank","n":1},"1":{"v":"\n- #aka meat shield\n- description: deliberately attract enemy attention and attacks\n- [[gd.co-identities-vs-tag-for]]","n":0.289}}},{"i":538,"$":{"0":{"v":"Summary","n":1},"1":{"v":"\n- #aka [[p.hadSummary]]","n":0.577}}},{"i":539,"$":{"0":{"v":"subclass of","n":0.707},"1":{"v":"\n#aka [[p.subClassOf]]","n":0.707}}},{"i":540,"$":{"0":{"v":"Static Site Revolution","n":0.577},"1":{"v":"\n\nmost sites don't need server-side dynamic generation to be dynamic.\n\n- [[]]\n","n":0.302}}},{"i":541,"$":{"0":{"v":"Startup","n":1}}},{"i":542,"$":{"0":{"v":"Similar","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[p.similarTo]]","n":0.577}}},{"i":543,"$":{"0":{"v":"Serial","n":1}}},{"i":544,"$":{"0":{"v":"Scala","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.scala]]","n":0.577}}},{"i":545,"$":{"0":{"v":"Rv","n":1}}},{"i":546,"$":{"0":{"v":"Rust","n":1}}},{"i":547,"$":{"0":{"v":"Ruby","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.Ruby]]","n":0.577}}},{"i":548,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n[[p.equivalentPredicate]] resources: ","n":0.707}}},{"i":549,"$":{"0":{"v":"Repo","n":1}}},{"i":550,"$":{"0":{"v":"Related","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[c.topic.related]]","n":0.577}}},{"i":551,"$":{"0":{"v":"Python","n":1},"1":{"v":"\n- [[p.coreferences]] #python","n":0.577}}},{"i":552,"$":{"0":{"v":"Publisher","n":1},"1":{"v":"\n- [[p.alsoKnownAs]] \n  - [[c.publisher]]\n","n":0.447}}},{"i":553,"$":{"0":{"v":"Price","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[p.had]] [[c.pricing]]","n":0.5}}},{"i":554,"$":{"0":{"v":"Preferred","n":1}}},{"i":555,"$":{"0":{"v":"Polyseme","n":1}}},{"i":556,"$":{"0":{"v":"personal knowledge management","n":0.577},"1":{"v":"\n#aka [[p.isRelated]] [[t.km.pkm]]","n":0.577}}},{"i":557,"$":{"0":{"v":"PHP","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.php]]","n":0.577}}},{"i":558,"$":{"0":{"v":"Model","n":1},"1":{"v":"\n[[p.equivalentPredicate]] [[p.hasModelNumber]]","n":0.707}}},{"i":559,"$":{"0":{"v":"Looks Complicated","n":0.707}}},{"i":560,"$":{"0":{"v":"Log","n":1},"1":{"v":"\n## [[p.equivalentPredicate]] \n\n- [[p.hasLog]]","n":0.5}}},{"i":561,"$":{"0":{"v":"License","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[p.had]] [[c.license]]\n- [[p.hasTopic]] [[t.leg.licensing]]","n":0.408}}},{"i":562,"$":{"0":{"v":"Kotlin","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.kotlin]]","n":0.577}}},{"i":563,"$":{"0":{"v":"Julia","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.julia]]\n- [[p.supports]] [[prdct.llvm]] so [[prdct.wasm]] via [[prdct.emscripten]]\n\n## Resources\n\n### Julia for Games\n\n- https://discourse.julialang.org/t/is-julia-good-for-game-development/73804/5\n  - live-code new game rules while my children are playing it\n  - Change the game logic and game state interactively via RemoteREPL.jl\n  - \" I use @louisponet’s [[prdct.overseer-jl]] 93 and this hugely cleaned up the game logic in my game.\"\n  - [[c.mention]] [[game.gameoji]]","n":0.132}}},{"i":564,"$":{"0":{"v":"JavaScript","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.JavaScript]]","n":0.577}}},{"i":565,"$":{"0":{"v":"Java","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.java]]\n\n","n":0.577}}},{"i":566,"$":{"0":{"v":"It Is but It Isnt","n":0.447}}},{"i":567,"$":{"0":{"v":"Isolation","n":1}}},{"i":568,"$":{"0":{"v":"Irony","n":1}}},{"i":569,"$":{"0":{"v":"instanceOf","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[p.instanceOf]]","n":0.577}}},{"i":570,"$":{"0":{"v":"Important","n":1}}},{"i":571,"$":{"0":{"v":"i.e.","n":1},"1":{"v":"\n#aka [[p.hasParaphrase]]","n":0.707}}},{"i":572,"$":{"0":{"v":"Highlight","n":1},"1":{"v":"\n- [[p.alsoKnownAs]] [[p.hasHighlight]]","n":0.577}}},{"i":573,"$":{"0":{"v":"Heavy","n":1}}},{"i":574,"$":{"0":{"v":"Haskell","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.haskell]]","n":0.577}}},{"i":575,"$":{"0":{"v":"Haha","n":1}}},{"i":576,"$":{"0":{"v":"Groovy","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.groovy]]","n":0.577}}},{"i":577,"$":{"0":{"v":"Go","n":1}}},{"i":578,"$":{"0":{"v":"Gardening","n":1},"1":{"v":"\n- https://www.shoptinyhouses.com/products/aqua2use-grey-water-diversion-system with replacement filters https://www.rainharvest.com/aqua2use-six-replacement-filters-for-greywater-recycling-system.asp ^tpsurdulqibq\n  - [[p.hasReview]] \n    - This system is housed in a small plastic box (about 2′ x 2′ x 1′) with a series of filters inside and a low powered pump after the filters. The filters require manual cleaning. When they clog greywater can’t flow through them and it instead flows to the sewer/septic. The filtered greywater from this system isn’t clean enough for a drip irrigation system, it can be used with 1/4 inch outlets, or additional the system can include additional filters (not part of the Aqua2Use system) for smaller drip emitters. Users report problems with the pump and other technical difficulties, like the float switch getting hung up inside the box and burning out pump.\n- resources: \n  - https://www.latimes.com/lifestyle/story/2022-05-06/how-to-water-vegetable-garden-during-a-drought-and-hot-summer\n    - [[p.hasHighlight]] “In most cases, people are watering too much anyway, so one day a week is very doable and will probably be better for everybody, including the plants,” Savio says. “My neighbor used to come home and sprinkle her garden every night. She did it for her benefit because it was relaxing, but her plants had roots that were barely an inch into the soil. Her watering satisfied them each night, but when the 100-degree heat came all her plants were dead because there had been no system for their roots to grow deeper. Consequently, they literally fried in the soil.”\n    - ","n":0.066}}},{"i":579,"$":{"0":{"v":"Game Design","n":0.707},"1":{"v":"\n- [[p.equivalentTopic]] [[t.cs.game.design]]","n":0.577}}},{"i":580,"$":{"0":{"v":"Funny","n":1}}},{"i":581,"$":{"0":{"v":"Free Tier","n":0.707},"1":{"v":"\n- [[p.coreferences]] [[t.biz.free-tier]]","n":0.577}}},{"i":582,"$":{"0":{"v":"Features","n":1},"1":{"v":"\n[[p.equivalentPredicate]] [[p.hasFeature]]","n":0.707}}},{"i":583,"$":{"0":{"v":"Eureka","n":1}}},{"i":584,"$":{"0":{"v":"Epistemic Status","n":0.707},"1":{"v":"\n- #aka [[p.had]] [[t.comm.epistemic-status]]","n":0.5}}},{"i":585,"$":{"0":{"v":"Epistemic Effort","n":0.707},"1":{"v":"\n- #aka [[p.had]] [[t.comm.epistemic-effort]]","n":0.5}}},{"i":586,"$":{"0":{"v":"Email","n":1}}},{"i":587,"$":{"0":{"v":"Elm","n":1}}},{"i":588,"$":{"0":{"v":"eg","n":1},"1":{"v":"\n#aka [[p.hasExample]]","n":0.707}}},{"i":589,"$":{"0":{"v":"Effective Altruism","n":0.707}}},{"i":590,"$":{"0":{"v":"entity component system","n":0.577},"1":{"v":"\n\n- [[p.hasRelatedTopic]] [[t.cs.entity-component-system]]\n","n":0.577}}},{"i":591,"$":{"0":{"v":"Docs","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] docs: \n- [[p.references]] [[c.documentation]]","n":0.408}}},{"i":592,"$":{"0":{"v":"Discouraged","n":1},"1":{"v":"\n\n\n- could do something like `instanceOf` `RecommendationType`\n","n":0.378}}},{"i":593,"$":{"0":{"v":"Description","n":1},"1":{"v":"\n- [[p.hadDefinition]] \n  - [[p.hadDescription]]","n":0.447}}},{"i":594,"$":{"0":{"v":"Deprecated","n":1}}},{"i":595,"$":{"0":{"v":"Demo","n":1},"1":{"v":"\n[[p.equivalentPredicate]] [[p.hasDemonstration]]","n":0.707}}},{"i":596,"$":{"0":{"v":"Definition","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[p.hadDefinition]]","n":0.577}}},{"i":597,"$":{"0":{"v":"Decentraland","n":1}}},{"i":598,"$":{"0":{"v":"Dead","n":1},"1":{"v":"\n\n\n- [[p.hasSense]]\n  - a product that is no longer actively developed\n","n":0.302}}},{"i":599,"$":{"0":{"v":"Creator","n":1}}},{"i":600,"$":{"0":{"v":"Created","n":1},"1":{"v":"\n#aka [[p.createdOn]]","n":0.707}}},{"i":601,"$":{"0":{"v":"Copy","n":1},"1":{"v":"\n- #aka [[p.had]] [[c.copy]]","n":0.5}}},{"i":602,"$":{"0":{"v":"Cool","n":1}}},{"i":603,"$":{"0":{"v":"Contributors","n":1},"1":{"v":"\n- #aka [[p.had]] [[c.contributor]]","n":0.5}}},{"i":604,"$":{"0":{"v":"code23","n":1},"1":{"v":"\n- [[p.hasRelatedTopic]] [[pri-goal.javascript-practice]]","n":0.577}}},{"i":605,"$":{"0":{"v":"Closed Source","n":0.707}}},{"i":606,"$":{"0":{"v":"Clojure","n":1}}},{"i":607,"$":{"0":{"v":"Class","n":1},"1":{"v":"\n- [[p.equivalentPredicate]] [[p.instanceOf]]","n":0.577}}},{"i":608,"$":{"0":{"v":"C","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.c]]","n":0.577}}},{"i":609,"$":{"0":{"v":"C#","n":1},"1":{"v":"\n- [[p.references]] [[t.cs.languages.c-sharp]]","n":0.577}}},{"i":610,"$":{"0":{"v":"C++","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.c++]]","n":0.577}}},{"i":611,"$":{"0":{"v":"Broken","n":1}}},{"i":612,"$":{"0":{"v":"Brilliant","n":1},"1":{"v":"\n- [[p.tag-for]] `[[adj.brilliant]]`","n":0.577}}},{"i":613,"$":{"0":{"v":"Bosque","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.bosque]]","n":0.577}}},{"i":614,"$":{"0":{"v":"Blog","n":1},"1":{"v":"\n- [[p.coreferences]] [[p.hasBlog]]","n":0.577}}},{"i":615,"$":{"0":{"v":"Baas","n":1},"1":{"v":"\n- [[p.equivalentTopic]] [[t.cs.web.backend-as-a-service]]","n":0.577}}},{"i":616,"$":{"0":{"v":"Awesome","n":1}}},{"i":617,"$":{"0":{"v":"Author","n":1},"1":{"v":"\n[[p.equivalentPredicate]] [[p.hasAuthor]]","n":0.707}}},{"i":618,"$":{"0":{"v":"API","n":1}}},{"i":619,"$":{"0":{"v":"Alpha","n":1}}},{"i":620,"$":{"0":{"v":"aka","n":1},"1":{"v":"\n- #aka [[p.alsoKnownAs]]","n":0.577}}},{"i":621,"$":{"0":{"v":"DEVResolutions2024","n":1}}},{"i":622,"$":{"0":{"v":"Topics","n":1},"1":{"v":"\nThe \"personal wikipedia\" namespace\n","n":0.5}}},{"i":623,"$":{"0":{"v":"Religion","n":1}}},{"i":624,"$":{"0":{"v":"Judaism","n":1}}},{"i":625,"$":{"0":{"v":"Bat Mitzvah","n":0.707}}},{"i":626,"$":{"0":{"v":"Time","n":1}}},{"i":627,"$":{"0":{"v":"Equation of Time","n":0.577}}},{"i":628,"$":{"0":{"v":"Digital Representations","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://news.ycombinator.com/item?id=36260663\n  - ","n":0.5}}},{"i":629,"$":{"0":{"v":"Systems","n":1}}},{"i":630,"$":{"0":{"v":"Dynamic Systems","n":0.707}}},{"i":631,"$":{"0":{"v":"Symbols","n":1}}},{"i":632,"$":{"0":{"v":"Symbol of the Year","n":0.5},"1":{"v":"\n\n\n- [[p.organizedBy]] @todd-davies\n","n":0.577}}},{"i":633,"$":{"0":{"v":"Soc","n":1}}},{"i":634,"$":{"0":{"v":"Online Community","n":0.707}}},{"i":635,"$":{"0":{"v":"Sales","n":1}}},{"i":636,"$":{"0":{"v":"Configure Price Quote","n":0.577}}},{"i":637,"$":{"0":{"v":"Rec","n":1}}},{"i":638,"$":{"0":{"v":"Magic the Gathering","n":0.577}}},{"i":639,"$":{"0":{"v":"Color Wheel","n":0.707},"1":{"v":"\n![](/assets/images/2024-03-31-08-53-35.png)\n\n## References\n\n- https://www.lesswrong.com/posts/gvNnE6Th594kfdB3z/on-green\n  - mentions @ursula-leguin and [[ar.a-non-euclidean-view-of-california-as-a-cold-place-to-be]]","n":0.354}}},{"i":640,"$":{"0":{"v":"Magic Circles","n":0.707},"1":{"v":"\n- \"    Within the magic circle, special meanings accrue and cluster around objects and behaviors. In effect, a new reality is created, defined by the rules of the game and inhabited by its players.\n    (Salen, Zimmerman, 2004, “Rules of Play”)\"\n  - [[ar.substack.subconscious.ritual-technology]]","n":0.154}}},{"i":641,"$":{"0":{"v":"Game","n":1},"1":{"v":"\n## Description\n\n![[ar.atlantic.video-games-are-better-without-stories#^k9bfngdvg41y]]\n\n## Resources\n\n- [[book.finite-and-infinite-games]]\n- [[book.uncertainty-in-games]]\n\n## References\n\n[[ar.atlantic.video-games-are-better-without-stories]]","n":0.408}}},{"i":642,"$":{"0":{"v":"Time-Locked Progression","n":0.707},"1":{"v":"\n- related [[game.everquest]]\n\n## References\n\n- https://blog.playerauctions.com/others/everquest-progression-server/","n":0.447}}},{"i":643,"$":{"0":{"v":"Game Studies","n":0.707}}},{"i":644,"$":{"0":{"v":"Game Structures","n":0.707},"1":{"v":"\n-  \"Over time, for a variety of reasons, these explicit game structures became more and more simulationist in nature. As the focus shifted from structures that were fun to play to structures that were accurate “models of the game world”, however, the structures became rather boring and (as the details of the simulation became fetishized) often too complicated to use in actual play to any great effect.\"\n\n## References\n\n- [[ar.the-alexandrian.game-structures]]","n":0.12}}},{"i":645,"$":{"0":{"v":"Pointcrawl","n":1},"1":{"v":"\n## Resources\n\n- https://thealexandrian.net/wordpress/48666/roleplaying-games/pointcrawls\n","n":0.577}}},{"i":646,"$":{"0":{"v":"Principles","n":1},"1":{"v":"\n## References\n\n- [[book.uncertainty-in-games]]\n- [[book.finite-and-infinite-games]]","n":0.5}}},{"i":647,"$":{"0":{"v":"Mechanics Dynamics Aesthetics Framework","n":0.5},"1":{"v":"\n-   Mechanics are the base components of the game - its rules, every basic action the player can take in the game, the [algorithms](https://en.wikipedia.org/wiki/Algorithm \"Algorithm\") and data structures in the [game engine](https://en.wikipedia.org/wiki/Game_engine \"Game engine\") etc.\n-   Dynamics are the run-time behavior of the mechanics acting on player input and \"cooperating\" with other mechanics.\n-   Aesthetics are the emotional responses evoked in the player.\n    -   including:\n        - **Sensation** (_Game as sense-pleasure_): Player enjoys memorable audio-visual effects.\n        -   **Fantasy** (_Game as make-believe_): Imaginary world.\n        -   **Narrative** (_Game as drama_): A story that drives the player to keep coming back\n        -   **Challenge** (_Game as obstacle course_): Urge to master something. Boosts a game's replayability.\n        -   **Fellowship** (_Game as social framework_): A community where the player is an active part of it. Almost exclusive for multiplayer games.\n        -   **Discovery** (_Game as uncharted territory_): Urge to explore game world.\n        -   **Expression** (_Game as self-discovery_): Own creativity. For example, creating character resembling player's own avatar.\n        -   **Submission** (_Game as pastime_): Connection to the game, as a whole, despite constraints.\n        -   **Competition**\n\n## References\n\n-   [\"MDA: A Formal Approach to Game Design and Game Research\"](http://www.cs.northwestern.edu/~hunicke/pubs/MDA.pdf) (PDF). Robin Hunicke, Marc LeBlanc, Robert Zubek.\n- [\"Engineering emergence: applied theory for game design\"](http://www.lindstaedt.com.br/simuljogos/file352033.pdf) (PDF). Joris Dormans.\n- [Design, Dynamics, Experience (DDE): An Advancement of the MDA framework for Game Design\"](https://www.researchgate.net/publication/315854140). Wolfgang Walk, Daniel Görlich, Mark Barrett.\n  - [[ar.design-dynamics-experience]]","n":0.067}}},{"i":648,"$":{"0":{"v":"Design Dynamics Experience Framework","n":0.5},"1":{"v":"\n## References\n\n- [[ar.design-dynamics-experience]]","n":0.577}}},{"i":649,"$":{"0":{"v":"Death Game","n":0.707},"1":{"v":"\n\n## References\n\n- https://medium.com/@lawrenceoconnel/cheating-at-the-death-game-b42a3b5a31ab","n":0.577}}},{"i":650,"$":{"0":{"v":"Camping","n":1},"1":{"v":"\n\n## Resources\n\n- https://campnab.com\n","n":0.577}}},{"i":651,"$":{"0":{"v":"Psych","n":1}}},{"i":652,"$":{"0":{"v":"Theory of Mind","n":0.577}}},{"i":653,"$":{"0":{"v":"Heterarchy","n":1},"1":{"v":"\n\n\nThe concept of heterarchy was first employed in a modern context by Warren McCulloch in 1945.[2] As Carole L. Crumley has summarised, \"[h]e examined alternative cognitive structure(s), the collective organization of which he termed heterarchy. He demonstrated that the human brain, while reasonably orderly was not organized hierarchically. This understanding revolutionized the neural study of the brain and solved major problems in the fields of artificial intelligence and computer design.\"[3]\n\n## Resources\n\n- https://stream.syscoi.com/2021/01/24/heterarchy-a-big-concept-with-lots-of-connections-mcculloch-and-onwards/\n","n":0.118}}},{"i":654,"$":{"0":{"v":"Model","n":1}}},{"i":655,"$":{"0":{"v":"Pecs","n":1},"1":{"v":"\n- https://cdn.aaai.org/Symposia/Fall/2001/FS-01-02/FS01-02-027.pdf","n":0.707}}},{"i":656,"$":{"0":{"v":"Time Preference","n":0.707},"1":{"v":"\n- [[p.alsoKnownAs]] time discounting, delay discounting, temporal discounting, long-term orientation\n","n":0.316}}},{"i":657,"$":{"0":{"v":"Thinking Skills","n":0.707},"1":{"v":"\n\n\n- tools and techniques for better mentality\n","n":0.378}}},{"i":658,"$":{"0":{"v":"Inversion","n":1},"1":{"v":"\n\n\n## Resources\n\n- [[Inversion|ar.jamesclear.inversion]]\n","n":0.577}}},{"i":659,"$":{"0":{"v":"Symbolic Play","n":0.707},"1":{"v":"\n## Definitions\n\n### chatgpt4.o\n\n**Symbolic play**, also known as **pretend play** or **imaginative play**, refers to the type of play where children use objects, actions, or ideas to represent other objects, actions, or ideas as a form of creative expression. In symbolic play, children assign new meanings to objects or actions, such as pretending a **block is a car** or a **stick is a sword**. It allows them to explore the world, experiment with different social roles, and express their thoughts and feelings in a creative and non-literal way.\n\n### Key Characteristics of Symbolic Play:\n1. **Object Substitution**: Using one item to represent another, like a banana as a phone.\n2. **Role-Playing**: Taking on different characters, such as pretending to be a parent, doctor, or superhero.\n3. **Dramatic Scenarios**: Acting out scenes like cooking dinner, going to the store, or saving someone in danger.\n\n### Developmental Importance:\n- **Cognitive Development**: According to **Jean Piaget**, symbolic play helps children move from the sensorimotor stage to the preoperational stage by allowing them to use mental symbols and engage in representational thought (Piaget, 1962).\n- **Language Development**: Pretend play encourages children to use language in creative ways, helping them to expand their vocabulary and practice new words (Vygotsky, 1978).\n- **Social Skills**: When children engage in pretend play with peers, they learn negotiation, empathy, and cooperation.\n\n### Age Range:\n- Symbolic play usually begins around **18 months to 2 years** of age, as children develop the ability to represent objects and actions mentally.\n- It continues to evolve in complexity as children grow, reaching a peak in the **preschool years (ages 3-6)**, where children start to create elaborate, rule-based pretend scenarios.\n\nSymbolic play is a vital aspect of early childhood development that contributes to language, social, and cognitive growth, helping children make sense of the world around them in creative ways. \n\n### References:\n- **Piaget, J.** (1962). *Play, Dreams, and Imitation in Childhood*.","n":0.057}}},{"i":660,"$":{"0":{"v":"Structure Cast","n":0.707},"1":{"v":"\n- \"Invest a small amount of effort into a structure that will allow you to reel yourself towards your goal.\"\n- \n\n\n## References\n\n- https://threetimeswiser.substack.com/p/issue-380-goal-gradient-effect-structure","n":0.209}}},{"i":661,"$":{"0":{"v":"Stimulation","n":1},"1":{"v":"\n\n## Types\n\n### Stigmergy\n\n- the stimulation of the workers by the very performances they have achieve [^1]\n\n## References\n\n\n[^1]: [[ar.stigmergic-cues-and-their-uses-in-coordination-an-evolutionary-approach]]","n":0.236}}},{"i":662,"$":{"0":{"v":"Psychopathy","n":1},"1":{"v":"\n\n\n## References\n\n- [[You Have More in Common with a Psychopath than You Realise|ar.aeon.you-have-more-in-common-with-a-psychopath-than-you-realise]]\n- https://en.wikipedia.org/wiki/Psychopathy_Checklist \n","n":0.258}}},{"i":663,"$":{"0":{"v":"Procrastination","n":1},"1":{"v":"\n- Procrastination often occurs when we have a purpose but no process... we need to [[t.psych.structure-cast]]\n\n## References\n\n- https://threetimeswiser.substack.com/p/issue-380-goal-gradient-effect-structure","n":0.236}}},{"i":664,"$":{"0":{"v":"Playfulness","n":1},"1":{"v":"\n- \"Playfulness isn’t about playing games. It’s a quality of lightheartedness that allows you to do things in everyday life just for the pleasure of it.\"\n  - [[p.hasSource]] [[ar.nytimes.having-fun-suceeding-coronavirus-pandemic]]\n","n":0.186}}},{"i":665,"$":{"0":{"v":"Personality Traits","n":0.707}}},{"i":666,"$":{"0":{"v":"Shyness","n":1},"1":{"v":"\n\n\n- resources: \n  - https://psyche.co/ideas/childhood-shyness-can-be-advantageous-dont-pathologise-it\n","n":0.447}}},{"i":667,"$":{"0":{"v":"Ooda Loop","n":0.707},"1":{"v":"\n- [[p.attributedTo]] @john-boyd\n- ![](/assets/images/2023-06-26-08-17-24.png)\n\n## Highlights\n\n### Orientation\n\n- \"What this emphasis on orientation does is make conflict into a learning contest to better maintain awareness of the world.\"\n- \"when you are disoriented—you lose your agency. Your model is wrong. You pay attention to the wrong things, your actions stop making sense, you flail.\"\n- ","n":0.14}}},{"i":668,"$":{"0":{"v":"Motivation","n":1},"1":{"v":"\n## Resources\n\n- @james-clear\n  - \"Motivation comes and goes. If you want to do something consistently, then don't pick a level of difficulty that requires great motivation. Make it easy enough and simple enough that you'll do it even when you don't feel very motivated.\"\n\n## Character motivation\n\n![[email.the-3-keys-to-character-motivation#objects-of-desire]]\n\n## References\n\n- [[email.the-3-keys-to-character-motivation]]","n":0.144}}},{"i":669,"$":{"0":{"v":"Models","n":1}}},{"i":670,"$":{"0":{"v":"Psi Theory","n":0.707},"1":{"v":"\n## Description\n\nmodels the human mind as an information processing agent, controlled by a set of basic physiological, social and cognitive drives. Perceptual and cognitive processing are directed and modulated by these drives, which allow the autonomous establishment and pursuit of goals in an open environment.\n\nNext to the motivational and emotional system, Psi-theory suggests a neuro-symbolic model of representation, which encodes semantic relationships in a hierarchical spreading activation network. The representations are grounded in sensors and actuators, and are acquired by autonomous exploration. ","n":0.11}}},{"i":671,"$":{"0":{"v":"Personality","n":1},"1":{"v":"\n\n\n## Six Main Views\n\n- [[p.assertedBy]] @eric-maisel [1]\n\n1. biological\n2. psychological\n3. personality\n4. sociolgoical\n5. circumstantial\n6. self-communicating, dynamic, self-regulating, experimental organisms\n\n- first five were influential but not determinative\n\n## Four Main (Data-Driven) Types [2]\n\n- [[p.attributedTo]] @Martin-Gerlach et al \n\n-   **Average:** The most common type are people who are high in neuroticism and extraversion while lower in openness.\n-   **Reserved:** People in this type are not open or neurotic but they are emotionally stable. They tend to be introverted, agreeable and conscientious.\n-   **Role-models:** These people are natural leaders with low levels of neuroticism and high levels of agreeableness, extraversion, openness and conscientiousness. They listen to new ideas and are reliable.\n-   **Self-centered:** While these people score high in extraversion they rank below average openness, agreeableness and conscientiousness.\n\n## Implementations\n\n\n## Resources\n\n- [1]: [[The Sixth Model of Personality|ar.psychologytoday.the-sixth-model-personality]]\n- [2]: [[ar.today.personality-types-average-self-centered-role-model-or-reserved]]\n","n":0.088}}},{"i":672,"$":{"0":{"v":"OCEAN Model","n":0.707},"1":{"v":"\n\n- [[p.mentionedOn]] [[ar.jasss.ben-an-architecture-for-the-behavior-of-social-agents]]\n\n## Implementations\n\n- [[prdct.gama.ben]]","n":0.447}}},{"i":673,"$":{"0":{"v":"Intelligence","n":1},"1":{"v":"\n## Types of Intelligence\n\n- In 1983, Howard Gardner proposed the theory of Multiple Intelligences where he introduced eight different types of intelligences: Linguistic, Logical/Mathematical, Bodily-Kinesthetic, Musical, Interpersonal, Intrapersonal, Naturalist, and – you might guess – Spatial\n\n## References\n\nhttps://www.turingpost.com/p/cvhistory5","n":0.164}}},{"i":674,"$":{"0":{"v":"Intellectual Vices","n":0.707},"1":{"v":"\n\n\n## [[p.hasExample]]\n\n- Gullibility, carelessness, closed-mindedness, negligence, idleness, rigidity, obtuseness, prejudice, lack of thoroughness,  insensitivity to detail\n  - [[p.hasSource]] [[ar.aeon.bad-thinkers]] \n","n":0.224}}},{"i":675,"$":{"0":{"v":"Inspiration","n":1},"1":{"v":"\n## Resources\n\n- https://jamesclear.com/inspiration-types @james-clear\n  - consuming the success and ideas of others is passive inspiration\n  - active inspiration\n    - the act of creating things, applying new ideas to our goals, and making mistakes teaches us what is important to ourselves\n    - results in long—term passion and enthusiasm","n":0.146}}},{"i":676,"$":{"0":{"v":"Flow","n":1},"1":{"v":"\n## [[p.hasSource]] [[ar.nytimes.having-fun-suceeding-coronavirus-pandemic]]\n\n- \"flow is an active state\"\n- \"junk flow\" is the hypnoized state \n","n":0.258}}},{"i":677,"$":{"0":{"v":"Faith","n":1},"1":{"v":"\n## Ideas\n\n- It is a mistake to think that faith is entirely a religious thing or reserved only for the religious.\n\n## Examples\n\n- the faith that humans have in each other\n- faith in secular goals or ideals\n- faith in ourselves\n\n## References\n\n- https://iep.utm.edu/faith-contemporary-perspectives/","n":0.156}}},{"i":678,"$":{"0":{"v":"Escapism","n":1}}},{"i":679,"$":{"0":{"v":"Digital","n":1}}},{"i":680,"$":{"0":{"v":"Emotion","n":1},"1":{"v":"\n\n![](/assets/images/2023-07-11-21-20-36.png)","n":1}}},{"i":681,"$":{"0":{"v":"Connectedness","n":1}}},{"i":682,"$":{"0":{"v":"Collaborative Imagination","n":0.707},"1":{"v":"\n- ","n":1}}},{"i":683,"$":{"0":{"v":"Cognitive Bandwidth","n":0.707}}},{"i":684,"$":{"0":{"v":"Bias","n":1},"1":{"v":"\n- can be unconcious\n- ","n":0.5}}},{"i":685,"$":{"0":{"v":"Belief","n":1},"1":{"v":"\n\n\n## [[p.references]]\n\n- [[ar.aeon.you-dont-have-a-right-to-believe-whatever-you-want-to]]\n","n":0.577}}},{"i":686,"$":{"0":{"v":"Attention Residue","n":0.707},"1":{"v":"\n-  if we jump from task to task, it becomes impossible to give anything our complete focus. This limits our ability to do complex deep thinking and problem solving, so we can never perform at our best.\n   -  [[p.hasSource]] https://timelyapp.com/blog/attention-residue","n":0.158}}},{"i":687,"$":{"0":{"v":"ADD","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] ADHD\n  - ADHD includes the symptom of physical hyperactivity while ADD does not\n","n":0.258}}},{"i":688,"$":{"0":{"v":"Planning","n":1}}},{"i":689,"$":{"0":{"v":"Yearly Planning","n":0.707},"1":{"v":"\n\n\n- [[p.hasSolution]]\n  - [[Anthony Gustin's Annual Planning Document|ar.gustin-annual-review-2021]]\n","n":0.354}}},{"i":690,"$":{"0":{"v":"Goal Management","n":0.707},"1":{"v":"\n\r\n- can be personal, inter-personal, or organizational\r\n","n":0.378}}},{"i":691,"$":{"0":{"v":"Career Development Planning","n":0.577},"1":{"v":"\n\r\n- [[p.hasSameReferantAs]] https://en.wikipedia.org/wiki/Career_development#Career_Development_Planning\r\n","n":0.577}}},{"i":692,"$":{"0":{"v":"Phil","n":1}}},{"i":693,"$":{"0":{"v":"Vagueness","n":1}}},{"i":694,"$":{"0":{"v":"Supervaluationism","n":1},"1":{"v":"\n## Resources\n\n- https://plato.stanford.edu/entries/vagueness/#Sup","n":0.577}}},{"i":695,"$":{"0":{"v":"Realism","n":1}}},{"i":696,"$":{"0":{"v":"Integrative Realism","n":0.707},"1":{"v":"\n## Description\n\n- while reality exists independently, our knowledge and experience of it are mediated by cognitive and cultural frameworks.\n- Recognizes multiple, coexisting levels of reality (e.g., physical, mental, social, electronic) that interact with each other.\n- ","n":0.169}}},{"i":697,"$":{"0":{"v":"Logic","n":1}}},{"i":698,"$":{"0":{"v":"Situational Calculus","n":0.707},"1":{"v":"\n- \"Fluent is a component of [[t.phil.logic.situational-calculus]] which is a logical language for representing change. [46, 48]. It concerns situations, actions and fluents in a dynamic domain. Actions make the domain change from one situation to another. Fluents are situation-dependent functions for describing the effects of actions. In 4D Fluents model, fluents are properties that change over time [73]. These properties are special cases in that both the domain and range of them are temporal parts of the corresponding entities. \" ^vmhpi7mrf12z\n\n## References\n\n- [[ar.valid-time-rdf]]","n":0.109}}},{"i":699,"$":{"0":{"v":"Monotonicity","n":1},"1":{"v":"\n## Non-monotonicity\n\n- @chatgpt.4: non-monotonic reasoning allows for the possibility that new information can invalidate previous conclusions. This is often used in systems requiring more flexible and adaptive reasoning capabilities, such as in certain AI applications. However, this is not typically how RDF and OWL operate.","n":0.149}}},{"i":700,"$":{"0":{"v":"Induction","n":1}}},{"i":701,"$":{"0":{"v":"First Order Logic","n":0.577}}},{"i":702,"$":{"0":{"v":"Frame Logic","n":0.707},"1":{"v":"\n## Resources\n\n  - [[ar.inheritance-in-rule-based-frame-systems]]","n":0.5}}},{"i":703,"$":{"0":{"v":"Doxastic","n":1},"1":{"v":"\n- [[c.logic]]\n- ","n":0.707}}},{"i":704,"$":{"0":{"v":"Deduction","n":1}}},{"i":705,"$":{"0":{"v":"Abduction","n":1}}},{"i":706,"$":{"0":{"v":"Use Mention Distinction","n":0.577},"1":{"v":"\n##  [[c.example]]\n\n-   _Use_: Cheese is derived from milk.\n-   _Mention_: \"Cheese\" is derived from the [Old English](https://en.wikipedia.org/wiki/Old_English_language \"Old English language\") word _ċēse_.","n":0.218}}},{"i":707,"$":{"0":{"v":"Type Token Distinction","n":0.577}}},{"i":708,"$":{"0":{"v":"Time","n":1}}},{"i":709,"$":{"0":{"v":"Situational Calculus","n":0.707}}},{"i":710,"$":{"0":{"v":"Space","n":1}}},{"i":711,"$":{"0":{"v":"Brentano Space","n":0.707},"1":{"v":"\n## Key Aspects of Brentano's Theory of Space\n\n    Psychological Basis: Brentano’s conception of space is rooted in psychological experiences rather than physical or geometric abstractions. He believed that our understanding of space comes from the way we perceive objects and their spatial relations.\n\n    Intuitive and Non-Metric: Brentano’s space is intuitive and qualitative rather than metric and quantitative. It focuses on the relational aspects of space as directly experienced, such as adjacency, containment, and separation, rather than measurable distances and angles.\n\n    Topological Properties: Brentano’s spatial theory emphasizes topological properties (properties that remain unchanged under continuous transformations). This includes concepts like continuity, boundary, and connectedness.\n\n    Non-Extensional: Unlike traditional Euclidean space, which is extensional and involves precise measurements and coordinates, Brentano space is non-extensional, focusing on how space is experienced and understood subjectively.\n\n    Concept of Spatial Parts: Brentano also discussed the notion of spatial parts and wholes, which ties into his mereological (part-whole) theories. He was interested in how parts of space relate to each other and to the whole.\n\n##  Brentano Space in Modern Ontology\n\nIn modern ontological frameworks, Brentano’s ideas have influenced the way some spatial concepts are treated, particularly in foundational ontologies that aim to incorporate human cognitive and perceptual aspects of space.\nMereotopology\n\nBrentano's ideas are closely related to mereotopology, a field that combines mereology (the study of parts and wholes) with topology (the study of spatial properties preserved under continuous transformations). Mereotopology is concerned with the relationships between parts, wholes, and boundaries within a given space.\nExamples in Upper Ontologies\n\nModern upper ontologies that incorporate aspects of Brentano's ideas might focus on:\n\n    Topological Relations: Relations such as connectedness, boundaries, and interiors of spatial regions.\n    Mereological Relations: How parts of space relate to each other and to larger wholes.\n\nExample: DOLCE (Descriptive Ontology for Linguistic and Cognitive Engineering)\n\nDOLCE incorporates aspects of Brentano’s spatial theory by focusing on qualitative spatial relations.","n":0.057}}},{"i":712,"$":{"0":{"v":"Semiotics","n":1},"1":{"v":"\n- #definition the study of signs and symbols and their use or interpretation.\n- the relationship between a signifier and a signified is conventional.\n\n## References\n\n- [[ar.on-the-ontology-of-fictional-characters-a-semiotic-approach]]","n":0.2}}},{"i":713,"$":{"0":{"v":"Semantics","n":1},"1":{"v":"\n## Definitions\n\n### Natural language semantics\n\nthe rendering in language of interpretations about the entities, relations, and properties of the world, and includes notions of sense and reference: how do we refer to the referents?\n\n## References\n\n- [[ar.advanced-ontology-topics-events-roles-artifacts]]","n":0.169}}},{"i":714,"$":{"0":{"v":"Qualia","n":1}}},{"i":715,"$":{"0":{"v":"Properties","n":1},"1":{"v":"\n## Resources\n\n- https://plato.stanford.edu/entries/properties/  ^9mphswwdvft3\n  - \"Properties are those entities that can be predicated of things or, in other words, attributed to them. Thus, properties are often called predicables. Other terms for them are “attributes”, “qualities”, “features”, “characteristics”, “types”. Properties are also ways things are, entities that things exemplify or instantiate. For example, if we say that this is a leaf and is green, we are attributing the properties leaf and green to it, and, if the predication is veridical, the thing in question exemplifies these properties.\"\n  - According to a different conception, however, properties are themselves particulars, though _abstract_ ones. As so conceived, properties are nowadays commonly called [tropes](https://plato.stanford.edu/entries/properties//../tropes/)","n":0.096}}},{"i":716,"$":{"0":{"v":"Problem of Universals","n":0.577},"1":{"v":"\n## Summary\n\n- \"Should the properties an object has in common with other objects, such as color and shape, be considered to exist beyond those objects? And if a property exists separately from objects, what is the nature of that existence?\"[1]\n\n## References\n\n- https://ask.metafilter.com/58170/What-is-the-origin-of-the-phrase-Carving-nature-by-its-joints @plato","n":0.152}}},{"i":717,"$":{"0":{"v":"Perdurantism","n":1},"1":{"v":"\n\n## Description\n\n- Perdurantism is a philosophical theory of persistence and identity [34]. It is closely related to four dimensionalism. In 4D view, an object that persists through time has distinct temporal parts at every time instant during its existence in time. Each persisting object is considered a four dimensional spacetime worm that stretches across the space- time domain. Slicing the spacetime worm at a specific time instant or interval results a temporal part or time slice which manifests itself as entity-at-a-time.\n\n## Issues\n\n- counterintuitive\n\n## Features\n\n- helps to resolve a number of longstanding metaphysical conundrums relating to change over time.\n- provides a very useful way of modelling vagueness\n- able to meet several of the challenges raised against more traditional the- ories of time and change by the theory of special relativity (Effingham, 2012)\n\n## References\n\n- [[ar.valid-time-rdf]]\n- [[ar.representing-temporal-information-in-lexical-linked-data]]","n":0.086}}},{"i":718,"$":{"0":{"v":"Ontology","n":1},"1":{"v":"\n## Definitions\n\n- what are the real entities, relations, and properties of the world; what are the referents?\n\n## References\n\n- [[ar.advanced-ontology-topics-events-roles-artifacts]]","n":0.229}}},{"i":719,"$":{"0":{"v":"Sortal","n":1}}},{"i":720,"$":{"0":{"v":"Rigidity","n":1},"1":{"v":"\n## Modal Logic Rigidity\n\n- \"Ordinarily, the word is used to describe a\nterm, and means that the term denotes the same individual in all possible worlds\"\n- Rigidity is a second-order property: it is something that is predicated of properties\n\n\n## \"Guarino's Rigidity\"\n\n- \"These definitions bear comment because they differ from the standard use of the\nword ‘rigid’ in the modal logic literature. \n\n### Rigidity\n\n- Members of a rigid class/instances of rigid type necessarily belong to this class in all possible worlds unless they cease to exist. \n  - example: an atom\n    - @chatgpt While an atom can transmute into another element, it does not cease to be an atom. \n\n### Non-rigidity/semi-rigidity\n\n- (At least) some instances of a non-rigid class do not have to belong to that class in all possible contexts.\n  - example: a mass of 4kg (artifacts might \"pass through\" the class, but a certain number of atoms of gold will always be 4kg)\n  - example: PerformingArtist: I used to be one, but Pavement is always one.\n  - example: LuxuryGood, where jewelry is always but only cars > $30k are.\n  \n#### anti-rigidity\n\n- If every individual that instantiate a given type in a particular time can cease to do so and still exists, then we call that type ANTI-RIGID\n- no instance of the property has the property necessarily\n  - example: puppy\n\n\n## Use in ontologies\n\n- \"The notion of rigidity is brought to bear on the task of building ontologies by the constraint that an anti-rigid property can’t subsume a rigid one\"\n\n## References\n\n- [[ar.towards-a-consistent-logical-framework-for-ontological-analysis]]\n- https://ontouml.readthedocs.io/en/latest/classes/nonsortals/mixin/index.html","n":0.063}}},{"i":721,"$":{"0":{"v":"Ontology of Events","n":0.577},"1":{"v":"\n## Theories\n\n- phenomena that have happened\n- phenomena that are scheduled to happen\n\n### Moens & Steedman\n\n- Events have beginning and end points\n  - (what about ongoing events?)\n- Events are punctual or extended in time\n- Event types:\n  - Culmination: instantaneous, introduces a transition from one state to another\n    - Example: Harry reached the top. Harry has reached the top.\n  - Point: an indivisible whole\n    - Example: John hiccupped.\n  - Process: has no culmination\n    - Example: Harry climbed.\n      - but couldn't there be an implication that he climbed to somewhere\n  - CulminatedProcess: a process that has a culmination\n    - Example: Harry climbed to the top.\n  - States: indefinitely extending states of affairs\n\n## References\n\n- [[ar.lode-linking-open-descriptions-of-events]]","n":0.095}}},{"i":722,"$":{"0":{"v":"Morality","n":1}}},{"i":723,"$":{"0":{"v":"Honesty","n":1},"1":{"v":"\n![](/assets/images/2024-05-10-14-08-21.png)\n\n## Deep Honesty\n\n- Deep honesty is an act of trust in the recipient.\n  - but also, it’s hard to optimize in a shallowly honest way when you don’t understand the audience, so the unforeseen benefits of deep honesty can be especially helpful in these cases.\n\n## References\n\n- https://www.lesswrong.com/posts/szn26nTwJDBkhn8ka/deep-honesty","n":0.146}}},{"i":724,"$":{"0":{"v":"Metaphysics","n":1}}},{"i":725,"$":{"0":{"v":"Abstract Objects","n":0.707},"1":{"v":"\n\n## References\n\n- [[ar.stanford.encyclopedia-of-philosophy.abstract-objects]]","n":0.577}}},{"i":726,"$":{"0":{"v":"Mereolog","n":1},"1":{"v":"\n\n\n## References\n\n- https://plato.stanford.edu/entries/mereology/","n":0.577}}},{"i":727,"$":{"0":{"v":"Mentifact","n":1},"1":{"v":"\n- collections of ideas\n- a concept from anthropology and cultural studies that refers to the ideas, beliefs, values, and knowledge that make up the non-material aspects of culture\n\n## References\n\n- [[ar.isko.work]]","n":0.183}}},{"i":728,"$":{"0":{"v":"Lifeworld","n":1},"1":{"v":"\n\nThe 'lifeworld' is a grand theatre of objects variously arranged in space and time relative to perceiving subjects, is already-always there, and is the \"ground\" for all shared human experience.\n\n\nFor Habermas, the lifeworld is more or less the \"background\" environment of competences, practices, and attitudes representable in terms of one's cognitive horizon. Compared to Husserl with his focus on consciousness, however, Habermas, whose social theory is grounded in communication, focuses on the lifeworld as consisting of socially and culturally sedimented linguistic meanings. It is the lived realm of informal, culturally-grounded understandings and mutual accommodations.\n\n## [[p.hasSource]]\n\n- https://en.wikipedia.org/wiki/Lifeworld","n":0.102}}},{"i":729,"$":{"0":{"v":"Philosophy of Language","n":0.577}}},{"i":730,"$":{"0":{"v":"Names","n":1},"1":{"v":"\n![[daily.journal.2022.11.07#^dd2i53gynzhn]]\n  ","n":1}}},{"i":731,"$":{"0":{"v":"Indexicality","n":1},"1":{"v":"\n## Description\n\n- The modern concept originates in the semiotic theory of @charles-sanders-peirce, in which indexicality is one of the three fundamental sign modalities by which a sign relates to its referent (the others being iconicity and symbolism)\n- Words and expressions in language often derive some part of their referential meaning from indexicality.\n  - For example, I indexically refers to the entity that is speaking; now indexically refers to a time frame including the moment at which the word is spoken; and here indexically refers to a locational frame including the place where the word is spoken.\n  - Linguistic expressions that refer indexically are known as deictics\n\n## References\n\n- https://en.wikipedia.org/wiki/Indexicality","n":0.096}}},{"i":732,"$":{"0":{"v":"Freedom","n":1}}},{"i":733,"$":{"0":{"v":"Fiction","n":1},"1":{"v":"\n## References\n\n- [[ar.fictional-realism-and-commonsense-ontology]]","n":0.577}}},{"i":734,"$":{"0":{"v":"Fictional Entities","n":0.707},"1":{"v":"\n## References\n\n- [[ar.fictional-realism-and-commonsense-ontology]]\n- [[ar.on-the-ontology-of-fictional-characters-a-semiotic-approach]]\n- https://plato.stanford.edu/entries/fictional-entities/\n","n":0.447}}},{"i":735,"$":{"0":{"v":"Epistemology","n":1},"1":{"v":"\n## What is knowledge composed of, other than relations\n\n@chatgpt.4o\n\n**Knowledge** is composed of several fundamental components, **not just relations**. Other key elements that form knowledge include:\n\n### 1. **Concepts**:\n   - Concepts are the **basic units of thought** or understanding. They represent ideas, categories, or mental constructs that allow us to make sense of the world. For instance, concepts like \"tree,\" \"justice,\" or \"speed\" allow us to identify and categorize objects, properties, and processes in the world.\n   - **Example**: The concept of \"gravity\" is a fundamental idea that helps us understand why objects fall.\n\n### 2. **Facts**:\n   - Facts are **specific pieces of information** about the world that are believed to be true. They represent particular states of affairs or propositions that describe reality.\n   - **Example**: \"The Earth orbits the Sun\" is a factual piece of knowledge.\n\n### 3. **Propositions**:\n   - Propositions are **statements** that express ideas or assertions that can be true or false. They convey factual information but also encode **beliefs** or **claims**.\n   - **Example**: \"Water freezes at 0°C\" is a proposition that expresses a fact about the physical world.\n\n### 4. **Rules/Principles**:\n   - Rules or principles are **guidelines** or **laws** that govern how things behave or interact. They often arise from observations of patterns or regularities in the world and help organize knowledge into systems.\n   - **Example**: Newton's laws of motion describe how physical objects move and interact under forces.\n\n### 5. **Perceptions/Observations**:\n   - Perceptions and observations are the **direct experiences** or **sensory data** that we collect from interacting with the world. They are the **raw data** that help us form knowledge.\n   - **Example**: Observing that the sky is blue is a form of direct knowledge based on perception.\n\n### 6. **Beliefs**:\n   - **Beliefs** represent **personal or collective understandings** about how the world works, which may or may not be fully verifiable. They form the foundation upon which knowledge claims are built.\n   - **Example**: A belief that the universe has infinite possibilities can drive philosophical inquiries into metaphysics.\n\n### 7. **Cognitive Models**:\n   - Cognitive models are **mental frameworks** or **structures** that we use to organize information and predict outcomes. They help us make sense of the world by providing structured ways of interpreting data and experiences.\n   - **Example**: A mental model of how ecosystems work helps scientists understand the interactions between species and their environments.\n\n### 8. **Inferences/Conclusions**:\n   - Inferences and conclusions are the **reasoned outcomes** drawn from data, facts, and rules. They represent **deductions or inductions** that expand on what is known to predict or explain new information.\n   - **Example**: Based on past data, scientists infer that a certain species will thrive in a particular environment.\n\n### 9. **Experience**:\n   - **Practical experience** provides knowledge through **doing** or **practice**. It represents applied knowledge in real-world contexts, leading to skills and expertise.\n   - **Example**: A carpenter gains knowledge about wood types and tools through hands-on experience over years of practice.\n\n### Summary:\nKnowledge is a multifaceted structure composed of:\n- **Concepts**, **facts**, and **propositions** as core building blocks;\n- **Relations** that connect these components and give them meaning;\n- **Rules** and **principles** that guide understanding;\n- **Perceptions**, **beliefs**, **models**, and **inferences** that add depth;\n- **Experience** that refines and applies this knowledge.\n\nThese elements interact, with **relations** playing a vital role in linking them together, but knowledge itself is broader than just relational structures.","n":0.043}}},{"i":736,"$":{"0":{"v":"Relational","n":1},"1":{"v":"\n## Relational Theories of Knowledge\n\n@chatgpt.4o:\n\nYou are right in pointing out that **concepts**, **facts**, and **propositions** are often expressed **relationally**. In many philosophical and logical systems, knowledge is viewed as a web of interconnected facts, where **relations** between concepts give them meaning and context.\n\n### Relational Theories of Knowledge\nThe term **relational theory of knowledge** can broadly refer to any theory that emphasizes the **relations between entities** (such as concepts, propositions, or facts) as central to understanding and organizing knowledge. There isn’t a single, unified term that encapsulates all relational theories, but here are a few relevant frameworks and approaches that emphasize the relational nature of knowledge:\n\n### 1. **Relational Realism**:\n   - **Relational realism** holds that reality is fundamentally composed of **relations** rather than just objects or substances. In this view, knowledge is constructed by understanding the **relations between entities** rather than focusing solely on the entities themselves. This ties closely to some interpretations of quantum mechanics and relational models in the philosophy of science.\n   \n### 2. **Structural Realism**:\n   - In philosophy of science, **structural realism** argues that what we can know about the world is its **structure**, which is understood in terms of **relations** between entities rather than the entities themselves. This means that knowledge about reality is fundamentally relational in nature.\n\n### 3. **Network Epistemology**:\n   - **Network epistemology** is an approach that models **knowledge as a network** of interconnected propositions, concepts, or agents. This theory emphasizes how knowledge spreads and is structured through **connections and relationships** within a network of individuals or concepts. It views the relationships between knowledge claims as fundamental for understanding how knowledge is generated and validated.\n   \n### 4. **Relational Ontology**:\n   - In **relational ontology**, entities are seen as constituted by their relationships with other entities, implying that the very existence and nature of something is dependent on its relations. While this focuses on existence (ontology), the epistemic counterpart suggests that **knowing something** involves understanding the **relations** in which it is embedded.\n\n### 5. **Semantic Networks and Knowledge Graphs**:\n   - In the context of **knowledge representation** (like knowledge graphs or semantic networks), knowledge is explicitly modeled through **relations** between concepts or facts. These frameworks are inherently relational, expressing knowledge in the form of subject-predicate-object triples (as in RDF) or nodes and edges in a graph.\n   \n### 6. **Holism**:\n   - In epistemology, **holism** suggests that a single piece of knowledge or belief cannot be understood in isolation but only in relation to other beliefs or knowledge. This is known as the **web of belief** theory, which views knowledge as an interconnected structure where the relations between beliefs and knowledge claims determine their validity.\n\n### Summary:\nIn relational theories of knowledge, the key idea is that **knowledge arises from relations between entities** (concepts, facts, propositions) rather than just from the entities themselves in isolation. These theories highlight the importance of **context**, **structure**, and **connections** in constructing and understanding knowledge.\n\nWhile there isn’t a single term like “relational epistemology” in mainstream use, related frameworks like **structural realism**, **relational realism**, **network epistemology**, and **holism** capture aspects of this idea.","n":0.045}}},{"i":737,"$":{"0":{"v":"Objectivism","n":1}}},{"i":738,"$":{"0":{"v":"Constructivism","n":1}}},{"i":739,"$":{"0":{"v":"Endurantism","n":1}}},{"i":740,"$":{"0":{"v":"Deontology","n":1},"1":{"v":"\n## Definition\n\nDeontic means relating to moral ideas like permission, responsibility, and obligation. For example, deontic reasoning is the ability to understand social rules and what happens when they are broken. (gemini)","n":0.18}}},{"i":741,"$":{"0":{"v":"Decision Theory","n":0.707}}},{"i":742,"$":{"0":{"v":"Updateless","n":1},"1":{"v":"\n## Resources\n\n- [[ar.lesswrong.where-do-selfish-values-come-from]]","n":0.577}}},{"i":743,"$":{"0":{"v":"Philosophy of Creation","n":0.577},"1":{"v":"\n\n## [[t.km.ontology.applied]]\n- ontology of creative works\n  - [[t.library-science.work_expression_manifestation_item]]\n- [[t.km.ontology.multi-level-theory]]\n- \n\n\n\n\n## References\n\n- [[ar.creativity-as-an-epistemic-virtue]]","n":0.289}}},{"i":744,"$":{"0":{"v":"Conceptualization","n":1}}},{"i":745,"$":{"0":{"v":"Causality","n":1}}},{"i":746,"$":{"0":{"v":"Assumption of Three Dimensionalism","n":0.5},"1":{"v":"\n## Thoughts\n## Resources\n\n- [Identity Across Time: A Defense of Three-Dimensionalism](https://people.umass.edu/~lrb/files/bak09ideM.pdf)\n  - \"The career, or life, or history of a 3D object should not be conflated with the object itself.\"","n":0.186}}},{"i":747,"$":{"0":{"v":"Agency","n":1},"1":{"v":"\n\r\n## What is an agent?\r\n\r\n- [\"they act and their actions have consequences, they also resist conditions which they do not like and, in some circumstances, are able to change the conditions of their agency\"][1]\r\n\r\n- [\"Margaret Archer defines Corporate Agency as involving both formulating goals and actively organizing in order to reach them. Primary Agency does not show either of these characteristics.\"][2]\r\n\r\n- [\"Formal Corporate Agency (stated aims and coordinated action); Informal Corporate Agency (no stated aims but coordinated action); Withdrawn Agency (stated aims but no coordinated action); and Primary Agency (no stated aims and no coordinated action).\"][2]\r\n\r\n## [[p.hasSource]]\r\n\r\n- [1]: https://onlinelibrary.wiley.com/doi/abs/10.1111/jtsb.12019\r\n- [2]: https://www.tandfonline.com/doi/full/10.1080/14767430.2019.1663031\r\n","n":0.1}}},{"i":748,"$":{"0":{"v":"Org Theory","n":0.707}}},{"i":749,"$":{"0":{"v":"Workforce Analytics","n":0.707}}},{"i":750,"$":{"0":{"v":"Performance Management","n":0.707},"1":{"v":"\n\r\n- it's not purely a \"business\" topic, unless you consider every organization a business\r\n","n":0.267}}},{"i":751,"$":{"0":{"v":"Hierarchy","n":1},"1":{"v":"\n\n\n- [[p.reflected]] [[t.phil.epistemology.objectivism]]\n  - [[p.claimedBy]] https://www.systemsinnovation.io/post/hierarchy-heterarchy\n","n":0.408}}},{"i":752,"$":{"0":{"v":"Heterarchy","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[t.psych.theory-of-mind.heterarchy]]\n- [[p.reflected]] [[t.phil.epistemology.constructivism]]\n  - [[p.claimedBy]] https://www.systemsinnovation.io/post/hierarchy-heterarchy\n\n## Resources\n\n- https://www.systemsinnovation.io/post/hierarchy-heterarchy\n","n":0.316}}},{"i":753,"$":{"0":{"v":"CSCW","n":1}}},{"i":754,"$":{"0":{"v":"Management","n":1}}},{"i":755,"$":{"0":{"v":"Time to Value","n":0.577}}},{"i":756,"$":{"0":{"v":"SWOT Analysis","n":0.707}}},{"i":757,"$":{"0":{"v":"SBI","n":1}}},{"i":758,"$":{"0":{"v":"Quarterly Check-Ins","n":0.707}}},{"i":759,"$":{"0":{"v":"Product Led Growth","n":0.577},"1":{"v":"\n\n- design for the end user\n- deliver value before you capture value\n- invest in the product with GTM intent\n  - more science than art: linkage between [[t.management.time-to-value]] and revenue/retention\n  - ","n":0.183}}},{"i":760,"$":{"0":{"v":"Net Expansion Revenue","n":0.577},"1":{"v":"\n\n\nNER\n","n":1}}},{"i":761,"$":{"0":{"v":"Knowledge, Skills, and Abilities","n":0.5}}},{"i":762,"$":{"0":{"v":"Employee Engagement","n":0.707}}},{"i":763,"$":{"0":{"v":"customer success qualified lead","n":0.5}}},{"i":764,"$":{"0":{"v":"Leg","n":1}}},{"i":765,"$":{"0":{"v":"Licensing","n":1}}},{"i":766,"$":{"0":{"v":"Sustainable Use License","n":0.577},"1":{"v":"  \nurl: https://github.com/n8n-io/n8n/blob/master/LICENSE.md#sustainable-use-license\n\n## Sustainable Use License\n\nVersion 1.0\n\nAcceptance\n\nBy using the software, you agree to all of the terms and conditions below.\nCopyright License\n\nThe licensor grants you a non-exclusive, royalty-free, worldwide, non-sublicensable, non-transferable license to use, copy, distribute, make available, and prepare derivative works of the software, in each case subject to the limitations below.\nLimitations\n\nYou may use or modify the software only for your own internal business purposes or for non-commercial or personal use. You may distribute the software or provide it to others only if you do so free of charge for non-commercial purposes. You may not alter, remove, or obscure any licensing, copyright, or other notices of the licensor in the software. Any use of the licensor’s trademarks is subject to applicable law.\nPatents\n\nThe licensor grants you a license, under any patent claims the licensor can license, or becomes able to license, to make, have made, use, sell, offer for sale, import and have imported the software, in each case subject to the limitations and conditions in this license. This license does not cover any patent claims that you cause to be infringed by modifications or additions to the software. If you or your company make any written claim that the software infringes or contributes to infringement of any patent, your patent license for the software granted under these terms ends immediately. If your company makes such a claim, your patent license ends immediately for work on behalf of your company.\nNotices\n\nYou must ensure that anyone who gets a copy of any part of the software from you also gets a copy of these terms. If you modify the software, you must include in any modified copies of the software a prominent notice stating that you have modified the software.\nNo Other Rights\n\nThese terms do not imply any licenses other than those expressly granted in these terms.\nTermination\n\nIf you use the software in violation of these terms, such use is not licensed, and your license will automatically terminate. If the licensor provides you with a notice of your violation, and you cease all violation of this license no later than 30 days after you receive that notice, your license will be reinstated retroactively. However, if you violate these terms after such reinstatement, any additional violation of these terms will cause your license to terminate automatically and permanently.\nNo Liability\n\nAs far as the law allows, the software comes as is, without any warranty or condition, and the licensor will not be liable to you for any damages arising out of these terms or the use or nature of the software, under any kind of legal claim.\nDefinitions\n\nThe “licensor” is the entity offering these terms.\n\nThe “software” is the software the licensor makes available under these terms, including any portion of it.\n\n“You” refers to the individual or entity agreeing to these terms.\n\n“Your company” is any legal entity, sole proprietorship, or other kind of organization that you work for, plus all organizations that have control over, are under the control of, or are under common control with that organization. Control means ownership of substantially all the assets of an entity, or the power to direct its management and policies by vote, contract, or otherwise. Control can be direct or indirect.\n\n“Your license” is the license granted to you for the software under these terms.\n\n“Use” means anything you do with the software requiring your license.\n\n“Trademark” means trademarks, service marks, and similar rights.  ","n":0.042}}},{"i":767,"$":{"0":{"v":"N8n Enterprise License","n":0.577},"1":{"v":"\nurl: https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md\n\n# The n8n Enterprise License (the “Enterprise License”)\n\nCopyright (c) 2022-present n8n GmbH.\n\nWith regard to the n8n Software:\n\nThis software and associated documentation files (the \"Software\") may only be used in production, if you (and any entity that you represent) hold a valid n8n Enterprise license corresponding to your usage. Subject to the foregoing sentence, you are free to modify this Software and publish patches to the Software. You agree that n8n and/or its licensors (as applicable) retain all right, title and interest in and to all such modifications and/or patches, and all such modifications and/or patches may only be used, copied, modified, displayed, distributed, or otherwise exploited with a valid n8n Enterprise license for the corresponding usage. Notwithstanding the foregoing, you may copy and modify the Software for development and testing purposes, without requiring a subscription. You agree that n8n and/or its licensors (as applicable) retain all right, title and interest in and to all such modifications. You are not granted any other rights beyond what is expressly stated herein. Subject to the foregoing, it is forbidden to copy, merge, publish, distribute, sublicense, and/or sell the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nFor all third party components incorporated into the n8n Software, those components are licensed under the original license provided by the owner of the applicable component.","n":0.059}}},{"i":768,"$":{"0":{"v":"Fair Code","n":0.707},"1":{"v":"\nurl: https://faircode.io\n","n":0.707}}},{"i":769,"$":{"0":{"v":"Commons Clause","n":0.707},"1":{"v":"\nurl: https://commonsclause.com/\n\n- you can sell value-added software that uses commons clause components","n":0.289}}},{"i":770,"$":{"0":{"v":"Humanities","n":1}}},{"i":771,"$":{"0":{"v":"Structuralism","n":1},"1":{"v":"\n- focuses on understanding the underlying structures that govern human culture, thought, and language, rather than simply analyzing surface-level content. \n\n## @chatgpt.4o\n\n**Structuralism** is a theoretical framework that emerged in the early to mid-20th century, primarily in the fields of anthropology, linguistics, psychology, and literary theory. It focuses on understanding the underlying structures that govern human culture, thought, and language, rather than simply analyzing surface-level content. Structuralism posits that these structures are universal and can be uncovered through systematic study.\n\n### Key Concepts of Structuralism:\n\n1. **Structures**:\n   - The core idea of structuralism is that all human activities and cultural phenomena (like language, myths, customs, and literature) can be understood as parts of a larger, underlying structure. These structures are often not immediately visible but are essential in organizing and making sense of the world.\n\n2. **Binary Oppositions**:\n   - Structuralists believe that much of human thought and culture is organized around binary oppositions—pairs of contrasting concepts such as good/evil, life/death, male/female, and so on. These oppositions are fundamental to the way we understand and categorize the world.\n\n3. **Language as a Model**:\n   - Structuralism is heavily influenced by linguistics, particularly the work of Ferdinand de Saussure. Saussure's idea that language is a system of signs (where each sign is composed of a \"signifier\" and a \"signified\") provided a model for understanding all cultural phenomena as systems of signs.\n\n4. **Synchronic vs. Diachronic**:\n   - Structuralists often focus on the **synchronic** (at a given point in time) analysis of structures rather than the **diachronic** (across time) development. This means they are more interested in understanding the system as it exists at a specific moment rather than how it evolved.\n\n5. **Universal Structures**:\n   - Structuralists argue that the structures they study are universal, meaning they apply across different cultures and historical periods. For example, Claude Lévi-Strauss's work in anthropology suggested that myths from various cultures could be understood as variations of the same underlying structure.\n\n### Major Figures in Structuralism:\n\n1. **Ferdinand de Saussure**:\n   - A Swiss linguist whose ideas about the structure of language laid the foundation for structuralism. He introduced concepts like the sign, signifier, and signified, and emphasized the relational nature of language.\n\n2. **Claude Lévi-Strauss**:\n   - An anthropologist who applied structuralist ideas to the study of myths, kinship, and cultural practices. He argued that the same fundamental structures underlie all human cultures.\n\n3. **Roland Barthes**:\n   - A literary theorist and semiotician who extended structuralist ideas to the analysis of literature and popular culture, exploring how cultural meanings are constructed.\n\n4. **Roman Jakobson**:\n   - A linguist and literary theorist who contributed to the development of structuralism in the study of poetry, focusing on the structures that organize poetic language.\n\n5. **Jacques Lacan**:\n   - A psychoanalyst who reinterpreted Freud’s work through a structuralist lens, particularly in his theory of the unconscious as structured like a language.\n\n### Structuralism's Legacy and Critique:\nStructuralism had a profound impact on various fields, but it also faced criticism. One major critique was its tendency to downplay human agency and historical context, focusing instead on static structures. This critique gave rise to **post-structuralism**, which challenged and deconstructed the assumptions of structuralism, emphasizing the fluidity and instability of meaning.\n\n### Applications of Structuralism:\n- **Literary Theory**: Structuralism analyzes the underlying narrative structures and patterns in texts, looking beyond individual stories to uncover deeper, universal themes.\n- **Anthropology**: Structuralism is used to compare myths, rituals, and social practices across cultures, seeking out common structures that reveal human universality.\n- **Linguistics**: Structuralism examines the underlying rules and systems that govern language, influencing fields like semiotics and phonology.\n\nIn summary, structuralism is an approach that seeks to understand the deep, often hidden structures that shape human culture, language, and thought, with an emphasis on universality and systematic analysis.","n":0.041}}},{"i":772,"$":{"0":{"v":"Literature","n":1}}},{"i":773,"$":{"0":{"v":"Digital Humanities","n":0.707}}},{"i":774,"$":{"0":{"v":"Geo","n":1}}},{"i":775,"$":{"0":{"v":"Rhumb Line","n":0.707},"1":{"v":"\n- appears as a straight line on a Mercator projection map.","n":0.302}}},{"i":776,"$":{"0":{"v":"Meteorology","n":1}}},{"i":777,"$":{"0":{"v":"ECEF","n":1},"1":{"v":"\n- aka: geocentric coordinate system\n\n\n## Resources\n\n- https://gis.stackexchange.com/questions/339187/how-can-you-convert-between-geographic-data-from-and-to-3d-data-in-postgis\n  - \"how about simply using a 3D CRS then? EPSG:4978 is an ECEF CRS based on EPSG:4326 and in widespread use as the core (3D) CRS for the GPS system.\"\n  - mentions: [[prdct.proj4]]","n":0.158}}},{"i":778,"$":{"0":{"v":"Cartography","n":1}}},{"i":779,"$":{"0":{"v":"Fictional Worlds","n":0.707}}},{"i":780,"$":{"0":{"v":"Star Wars","n":0.707}}},{"i":781,"$":{"0":{"v":"Star Trek","n":0.707}}},{"i":782,"$":{"0":{"v":"Edu","n":1}}},{"i":783,"$":{"0":{"v":"Tacit Knowledg","n":0.707},"1":{"v":"\n## References\n\n- [[ar.lesswrong.the-best-tacit-knowledge-videos-on-every-subject]]","n":0.577}}},{"i":784,"$":{"0":{"v":"Learning in Public","n":0.577},"1":{"v":"\n- \"Most people learn in private, consuming information, but not creating content themselves.  Learning in Public is the act of creating “learning exhaust” by making the resources you wished you had found while you were learning. This means everything from mapping out the landscape of a new field of interest, to documenting the problems you ran into and how you solved them – all out in the open in order to give back.\"\n  - https://jonathanbarbato.com/what-is-a-digital-garden\n\n## Resources\n\n- https://jonathanbarbato.com/what-is-a-digital-garden (offline, no archive.org cache!)\n- [[ar.maggieappleton.a-brief-history-and-ethos-of-the-digital-garden]]\n- [[ar.swyx.learn-in-public]]","n":0.11}}},{"i":785,"$":{"0":{"v":"Courseware","n":1}}},{"i":786,"$":{"0":{"v":"Drama","n":1}}},{"i":787,"$":{"0":{"v":"Theater","n":1},"1":{"v":"\n## References\n\n- [[ar.guardian.whats-the-difference-between-drama-and-theatre]]","n":0.577}}},{"i":788,"$":{"0":{"v":"Theater of the Mind","n":0.5},"1":{"v":"\n## References\n\n- https://thedmlair.com/blogs/news/10-tips-for-using-theater-of-the-mind-in-d-d","n":0.577}}},{"i":789,"$":{"0":{"v":"Interactive Theater","n":0.707},"1":{"v":"\n\n![](/assets/images/2024-09-29-22-12-25.png)\n\n## vs\n\n![[t.drama.theater.immersive#immersive-theater-vs-interactive-theater]]\n\n\n## References\n\n- [[ar.interactive-theatre-audience-and-meaningful-agency-in-live-theatre]]","n":0.5}}},{"i":790,"$":{"0":{"v":"Improvisational Theater","n":0.707},"1":{"v":"\n- aka: improv\n\n**Improvisational theater** (often called **improv**) is a form of theater where most or all of the performance is **unscripted** and created spontaneously by the actors. The performers typically invent dialogue, characters, and plotlines on the spot, often based on audience suggestions. The key is creativity, quick thinking, and collaboration.\n\n### Examples of Improv:\n\n1. **Whose Line Is It Anyway?** – A popular improv TV show where comedians perform spontaneous skits based on prompts.\n2. **The Second City** – A famous improv comedy theater in Chicago that has produced many notable comedians.\n3. **Improv Everywhere** – A group that stages spontaneous performances in public spaces.","n":0.099}}},{"i":791,"$":{"0":{"v":"Immersive Theatre","n":0.707},"1":{"v":"\n## Description\n\n\n\n## vs\n\n### immersive theater vs interactive theater\n\n![](/assets/images/2024-09-29-15-32-43.png)\n\n- [[t.drama.theater.immersive]] feels like you are in it\n- [[t.drama.theater.interactive]] feels like you can affect it\n\n## References\n\n- [[ar.farkouh.interactive-drama]]\n- [[ar.interactive-theatre-audience-and-meaningful-agency-in-live-theatre]]","n":0.2}}},{"i":792,"$":{"0":{"v":"Narration","n":1},"1":{"v":"\n- \"What do you feel is different about narrating compared to acting?\n\nWhen you’re narrating the point is to try and to be clear and not speak in a monotone.\"\n  - @morgan-freeman https://www.nytimes.com/2023/10/24/arts/television/morgan-freeman-life-on-our-planet.html","n":0.177}}},{"i":793,"$":{"0":{"v":"Interactive Drama","n":0.707},"1":{"v":"\n- similar: [[t.storytelling.fiction.interactive]] [[t.roleplaying]]\n\n## Definitions\n\n- \"a contemporary form of digital storytelling that weaves together narrative conditions of film, video games and immersive theatre\" that uses \"technology to enable rich environmental design, character depth and participant immersion.\"\n\n### role-playing vs interactive drama\n\n#### a good contrast by claude\n\nRole-playing and interactive drama are related but distinct concepts:\n\n[[t.roleplaying]]:\n- Participants assume the roles of characters\n- Often more loosely structured\n- Can be done for entertainment, education, or training\n- May or may not have a predefined story or outcome\n- Common in games, therapy, and educational settings\n\n[[t.drama.interactive]]:\n- A form of theater or performance art\n- Audience members actively participate in the story\n- Has a more defined narrative structure\n- Often guided by professional actors or facilitators\n- Typically aims for a specific artistic or educational goal\n\nThe main differences are:\n1. Structure: Interactive drama usually has a more defined narrative, while role-playing can be more open-ended.\n2. Purpose: Interactive drama is often focused on artistic or educational outcomes, while role-playing has a broader range of applications.\n3. Guidance: Interactive drama is typically led by professionals, whereas role-playing can be more self-directed.\n4. Setting: Interactive drama is often a public or semi-public performance, while role-playing can occur in more private or informal settings.\n\n\n## Issues\n\n![[ar.atlantic.video-games-are-better-without-stories#^1zkjt6vkyokj]]\n\n## Examples\n\n- [[game.dragons-lair]]\n- [[game.fahrenheit-indigo-prophecy]]\n- [[game.detroit-become-human]]\n\n## Resources\n\n- http://www.interactivedramas.info/dramatist.htm : critical pieces, definitions, and explanations of Interactive Drama, Freeform Role Play, Murder Mystery Whodunits, and Live Action Role Playing Games\n\n## References\n\n- [[ar.farkouh.interactive-drama]]","n":0.067}}},{"i":794,"$":{"0":{"v":"Improvisation","n":1},"1":{"v":"\n- similar: [[t.drama.theater.improvisational]], improv","n":0.5}}},{"i":795,"$":{"0":{"v":"Gestus","n":1}}},{"i":796,"$":{"0":{"v":"Cosmology","n":1}}},{"i":797,"$":{"0":{"v":"Theoretical Cosmology","n":0.707}}},{"i":798,"$":{"0":{"v":"Biz","n":1}}},{"i":799,"$":{"0":{"v":"Quarterly Business Reviews","n":0.577}}},{"i":800,"$":{"0":{"v":"Free Tier","n":0.707}}},{"i":801,"$":{"0":{"v":"Diversity Equity and Inclusion","n":0.5}}},{"i":802,"$":{"0":{"v":"Business Intelligence","n":0.707}}},{"i":803,"$":{"0":{"v":"Typography","n":1},"1":{"v":"\n\n\n- [[c.Resource.List]]\n  - https://www.typewolf.com/top-10-slab-serif-fonts\n","n":0.5}}},{"i":804,"$":{"0":{"v":"Task Management","n":0.707},"1":{"v":"\n\n\n-  [[p.hasPro]] Can help stave off a fear of mortality. ^UGSjFupqZmIK\n  - [[p.attributedTo]] @Oliver-Burkman\n    - [[p.attributedTo]] @Clay-Skipper ^O7jsHLSrj0Bc\n\n## [[p.hasSolution]]\n\n- [[prdct.meistertask]]\n## [[p.hasQuote]] \n\n- ![[proj.bia#^rxGIZrgVBtUO:#*]]\n\n## [[c.Resource.List]]\n\n- https://collegeinfogeek.com/best-to-do-list-app/\n","n":0.2}}},{"i":805,"$":{"0":{"v":"The Five Second Rule","n":0.5},"1":{"v":"\n- when you need to start doing something, count yourself down and then launch\n- stimulates the prefrontal cortex, the part of the brain that's active when you're changing behavior, when you're learning something new, or when you're directing your thoughts.","n":0.158}}},{"i":806,"$":{"0":{"v":"Intend Philosophy","n":0.707},"1":{"v":"\n- url: https://intend.do/philosophy\n\n## Description\n\nThe main paradigmatic differences of Intend, compared to GTD-based systems are as follows:\n\n* choosing & doing, over organizing\n* aliveness, instead of exhaustiveness\n  - the to-do list has more inflow than outflow, meaning it gets longer and longer\n  - lots of low-value tasks get added and never removed, although they may still create guilt — even though it is not actually worth ever doing them!\n  - when the person gains a new understanding of how it makes sense to approach that project/goal, old obsolete tasks don’t get cleared\n  - (they may not even realize there's a contradiction between their new understanding and their old tasks)\n* goals as fundamental, rather than tasks\n* proactive, rather than reactive\n\n\n### the focus is on doing things, not on making and organizing lists.\n\n- The main way that the app currently embodies this philosophy is by not offering any place in the app to write down a bunch of stuff that you're not planning to work on yet and may never work on. It's not that we think such lists are not valuable—they are. But they have costs, and one of those costs is that people get too focused on keeping the list organized, at the expense of focusing on what they're actually trying to achieve and taking actions towards achieving those things.\n\n- \"almost nobody I've met actually consistently does the GTD weekly review (which means they aren't actually following the GTD system, but a hollow shell of GTD that nobody ever claimed would work).\"\n","n":0.063}}},{"i":807,"$":{"0":{"v":"Getting Things Done","n":0.577},"1":{"v":"\n\n\n\n- [[p.alsoKnownAs]] GTD\n- comparable: [[t.tm.intend-philosophy]]\n\na personal productivity paradigm originated by @David-Allen\n\n- [[p.hasURL]] https://gettingthingsdone.com/\n- [[p.references]] [[book.getting-things-done-2nd-edition]]\n- [[c.podcastseries]] [[podcast.gtd]]\n\n## advanced workflow poster\n\n![](/assets/images/2021-09-28-07-50-10.png)\n\n- [[p.hasCreator]] @scott-moehring\n\n## workflow\n\n![](/assets/images/2021-09-27-22-08-18.png)\n\n## workflow map\n\n![](/assets/images/2021-09-28-07-38-03.png)\n\n## resources\n\n- http://www.moehrbetter.com/uploads/8/9/0/3/890360/gtd_workflow_advanced.pdf\n\n## References\n\n- https://fortelabs.co/blog/gtd-x-pkm/ \n\n\n---\nid: 6jd03jqhbnbh4db93ynwq31\ntitle: The Three Kinds of Role-Playing Magic\ndesc: ''\nupdated: 1719860452797\ncreated: 1719859234014\n---\n\n![barbarian behind a laptop, typing out a magical transcript of a rpg gaming session](/assets/images/2024-07-01-11-46-51.png)\n\n\nEveryone who's played an RPG knows \"in-game\" magic. The stuff of clerics, wizards, warlocks, enchanted weapons, magical traps, and cursed knickers. You could easily argue that the GM's ability to invoke arbitrary fantasy-reality and the players' ability to give life to characters are forms of performative (real-world) magic too.\n\nA third kind of magic might be in the remnants and re-tellings of the shared fiction. \n\nThose of us who summarize fantastical happenings as or after they transpire  get the opportunity for additional twists of fantasy-reality. It's more than magical. With the benefit of even a few seconds of hindsight, you have the chance to create an adaptation that might be funnier, pithier, more memorable, more apt, or more exciting than the original performance. Not to mention additional remixing and offshoots. It's art all the way down. \n\nIf magic is the ability to bend reality, let's not forget that \"post-production\" magicians get a chance to work wonders too, the kind evoked by that old Hollywood euphemism, \"The Magic Store.\"","n":0.068}}},{"i":808,"$":{"0":{"v":"Storytelling","n":1}}},{"i":809,"$":{"0":{"v":"Perspective","n":1}}},{"i":810,"$":{"0":{"v":"Third Person","n":0.707},"1":{"v":"\n- ","n":1}}},{"i":811,"$":{"0":{"v":"Third-Person Omniscient","n":0.707}}},{"i":812,"$":{"0":{"v":"Third-Person Limited","n":0.707}}},{"i":813,"$":{"0":{"v":"Second Person","n":0.707},"1":{"v":"\n- addresses the audience, like \"Choose Your Own Adventure\", [[c.software.game-framework.interactivefiction]] or most text adventures\n- \"who is the you in a second person point of view story? There are actually a few different possibilities:\n\n    The narrator is addressing the reader\n\n    The narrator is addressing themselves\n\n    The narrator is addressing another character\"\n\n## Pros\n\n-   In a second person narrative, the writer casts the reader as the main character. **The reader is placed at the very centre of the story**, which makes for an intense and immersive reader experience.\n    \n\n-   This POV can also be used **to reinforce the key themes and ideas of the story**. Perhaps the narrator wants to distance themselves from their own narrative because the topic is difficult to think or talk about. Or perhaps self-talk is central to your narrator's identity.\n    \n\n-   **Second person POV is an exciting challenge for a writer**. And an original and intriguing format for a reader. To avoid putting too much pressure on either party, short stories written in the second person provide a good introduction to this mode of storytelling.\n\n## Cons\n\n-   **It’s not something writers or readers are used to**. It’s rare to come across fiction written in the second person. And – honestly – writers don’t tend to consider it as one of the narrative formats available to them.\n    \n\n-   **Readers don’t always like it**. They may feel uncomfortable or alienated from events when being told by a narrator that they have acted or spoken in ways that feel far removed from their own real life experience.\n    \n\n-   Because readers don’t tend to like second person point of view narratives, **it’s much harder to convince an agent or publisher** that your story has commercial potential.\n    \n\n-   A reader will inevitably question this form of storytelling. So a writer has to convince the reader that the second person point of view is necessary to the narrative. **Very few stories really require it** – so writers simply choose other points of view.\n\n\n## Resources\n\n### Resource Lists\n\n- https://www.aplaceofintent.co.uk/blog/6-examples-and-excerpts-of-second-person-point-of-view-in-fiction\n\n","n":0.055}}},{"i":814,"$":{"0":{"v":"First Person","n":0.707},"1":{"v":"\n- The \"me\" perspective. Common in [[t.humanities.literature]] but uncommon in [[c.software.game-framework.interactivefiction]]","n":0.302}}},{"i":815,"$":{"0":{"v":"Formalism","n":1}}},{"i":816,"$":{"0":{"v":"Russian Formalism","n":0.707},"1":{"v":"\n![[ar.representing-narratives-in-digital-libraries-the-narrative-ontology#russian-formalists]]\n\n## \n\n## Issues\n\n### Sjuzhet vs Fabula\n\n- sjuzhet = \"narrative structure\"\n  - the order in which events are told, the pacing, and any narrative techniques like flashbacks, foreshadowing, or other forms of temporal manipulation.\n- see [[sh.question-log.2024.08.28.fabulary-vs-fabularia#fabula-is-just-another-narrative]]\n\n### chatgpt.4o\n\nRussian Formalism was a significant movement in literary theory during the early 20th century, and it contributed many foundational ideas about narrative structure, especially through the work of scholars like Viktor Shklovsky, Boris Eikhenbaum, and Vladimir Propp. While their ideas have been influential, they have also faced several criticisms over the years. Here are some of the main criticisms of the Russian Formalist conceptualization of narrative:\n\n### 1. **Overemphasis on Form at the Expense of Content**:\n   - **Criticism**: Russian Formalists focused heavily on the structure and mechanics of narrative, often at the expense of considering the content, themes, or social context of the work. This led to a somewhat narrow analysis that some critics argue overlooks the deeper meaning or significance of literature.\n   - **Response**: Formalists argued that their approach was a necessary corrective to earlier approaches that ignored the specifics of literary form, but this emphasis can lead to a neglect of how form and content interact.\n\n### 2. **Neglect of Historical and Social Context**:\n   - **Criticism**: Formalism was criticized for its lack of attention to the historical, social, and cultural contexts in which literature is produced and consumed. By focusing almost exclusively on the text's internal mechanics, Formalists were seen as disregarding the ways in which literature is influenced by and influences its broader environment.\n   - **Response**: Later movements, like Marxist criticism and Cultural Studies, emerged in part as reactions against this perceived limitation, emphasizing the importance of contextual factors in literary analysis.\n\n### 3. **Mechanistic Approach**:\n   - **Criticism**: The Russian Formalists' approach has been criticized as being too mechanistic, reducing the complex, dynamic process of literary creation and interpretation to a set of formal techniques or devices. This criticism suggests that their analyses risk oversimplifying literature and ignoring its emotional and experiential dimensions.\n   - **Response**: While Formalists provided valuable tools for understanding narrative structure, critics argue that their approach does not fully capture the richness and complexity of literary works.\n\n### 4. **Limitations in Understanding Narrative Evolution**:\n   - **Criticism**: Russian Formalists were primarily concerned with the synchronic analysis of texts—examining narratives at a single point in time—rather than considering how narratives evolve over time within particular historical or cultural contexts. This has been seen as a limitation, especially when trying to understand the development of literary genres or the influence of historical events on literature.\n   - **Response**: The emphasis on synchronic analysis allowed Formalists to develop precise tools for narrative analysis, but this focus also meant that diachronic (historical) analysis was often underdeveloped.\n\n### 5. **Inadequate Attention to Reader Response**:\n   - **Criticism**: Formalists were primarily interested in the text itself and the ways it was constructed, often neglecting the role of the reader in interpreting and giving meaning to the narrative. This led to criticism that their approach was overly text-centric and did not account for the variability of reader interpretations.\n   - **Response**: Reader-response theory and later developments in hermeneutics challenged the Formalist view by emphasizing the active role of the reader in creating meaning, something the Formalists did not sufficiently address.\n\n### 6. **Theoretical Rigidity**:\n   - **Criticism**: Some critics argue that Russian Formalism could be rigid in its theoretical applications, leading to formulaic analyses. For example, Vladimir Propp's morphology of folktales, while groundbreaking, has been criticized for being too rigid and not accounting for the variability and creativity found in actual storytelling practices.\n   - **Response**: Propp’s work was groundbreaking in systematizing the study of narrative structure, but critics suggest that it does not adequately address narratives that fall outside the patterns he identified.\n\n### 7. **Political Criticism**:\n   - **Criticism**: In the Soviet context, Russian Formalism faced political criticism for its perceived detachment from the social and political realities of the time. Marxist critics, in particular, argued that Formalism’s focus on aesthetics and form was politically disengaged, making it incompatible with the goals of socialist realism and other politically oriented literary theories.\n   - **Response**: Formalists maintained that their focus on the autonomy of literature was important for understanding its unique qualities, but this stance led to significant tension with Marxist critics and the Soviet state.\n\n### Conclusion:\nWhile Russian Formalism has been highly influential in the development of literary theory, it has also faced significant criticism, particularly for its emphasis on form over content, its neglect of historical and social context, and its sometimes rigid theoretical frameworks. These criticisms have led to the development of other schools of thought that aim to provide a more holistic understanding of literature, taking into account a wider range of factors including reader response, historical context, and ideological content.\n\n## References\n\n- ","n":0.036}}},{"i":817,"$":{"0":{"v":"Tropes","n":1},"1":{"v":"\n\n## Resources\n\n- https://tvtropes.org/pmwiki/pmwiki.php/Main/Tropes \n  - **[Genre Tropes](https://tvtropes.org/pmwiki/pmwiki.php/Main/GenreTropes \"/pmwiki/pmwiki.php/Main/GenreTropes\")**\n  -   **[Media Tropes](https://tvtropes.org/pmwiki/pmwiki.php/Main/MediaTropes \"/pmwiki/pmwiki.php/Main/MediaTropes\")**\n  -   **[Narrative Tropes](https://tvtropes.org/pmwiki/pmwiki.php/Main/NarrativeTropes \"/pmwiki/pmwiki.php/Main/NarrativeTropes\")**\n  -   **[Topical Tropes](https://tvtropes.org/pmwiki/pmwiki.php/Main/TopicalTropes \"/pmwiki/pmwiki.php/Main/TopicalTropes\")**\n-   \n\n### Resources List\n\n- https://tvtropes.org/pmwiki/pmwiki.php/Main/BooksOnTrope","n":0.204}}},{"i":818,"$":{"0":{"v":"Historical Fiction","n":0.707},"1":{"v":"\n## References\n\n- https://tvtropes.org/pmwiki/pmwiki.php/Main/HistoricalFiction","n":0.577}}},{"i":819,"$":{"0":{"v":"Benevolent AI","n":0.707},"1":{"v":"\n- https://tvtropes.org/pmwiki/pmwiki.php/Main/BenevolentAI","n":0.707}}},{"i":820,"$":{"0":{"v":"After the End","n":0.577},"1":{"v":"\n\n## References\n\n- https://tvtropes.org/pmwiki/pmwiki.php/Main/AfterTheEnd","n":0.577}}},{"i":821,"$":{"0":{"v":"Trope","n":1},"1":{"v":"\n\n\n## References\n\n- https://www.reddit.com/r/whatstheword/comments/crpztz/how_is_a_trope_essentially_different_from_a_motif/","n":0.577}}},{"i":822,"$":{"0":{"v":"Theme","n":1},"1":{"v":"\n## Definition\n\n- the main idea of your story\n- ","n":0.354}}},{"i":823,"$":{"0":{"v":"Tension","n":1}}},{"i":824,"$":{"0":{"v":"Technical Writing","n":0.707},"1":{"v":"\n\n\n## [[c.Resource.List]]\n\n- https://javascript.plainenglish.io/top-10-insanely-amazing-resources-for-technical-writers-a5262c46cdb7\n","n":0.577}}},{"i":825,"$":{"0":{"v":"Structure","n":1},"1":{"v":"\n## Description\n\n### Interactive Structure\n\n- An interactive narrative is one which is composed with a branching structure where a single starting point may lead to multiple developments and outcomes. The principle of all such games is that, at each step of the narrative, the user makes choices that advance the story, leading to a new series of choices. Authoring non-linear narrative or dialogue thus implies imagining an indefinite number of parallel stories.\n- In a gamebook, readers are told to turn to a certain page according to the choice they wish to make to continue the story. Typically, the choice will be an action rather than dialogue. For example, the hero hears a noise in another room and must decide to open the door and investigate, run away, or call for help. This kind of interactive experience of a story is possible with video games and books (where the reader is free to turn the pages) but less adapted to other forms of entertainment. [[Improvisational theater|t.drama.improvisation]] is similarly open-ended, but of course cannot be said to be authored.\n  - t.2024.09.24.03 well, the setup is authored\n  \n## References\n\n- https://en.wikipedia.org/wiki/Story_structure#Interactive_narrative","n":0.073}}},{"i":826,"$":{"0":{"v":"Setting","n":1},"1":{"v":"\n## Definition\n\n### Elements\n\n- [[t.storytelling.character]]\n- [[t.storytelling.plot]]\n- [[t.storytelling.setting]]\n- [[t.storytelling.tension]]\n- [[t.storytelling.theme]]\n\n\n### Trope modalities\n\n- [[t.lit]]\n- [[t.drama]]\n- [[t.music]]\n\n\n","n":0.277}}},{"i":827,"$":{"0":{"v":"Sententia","n":1}}},{"i":828,"$":{"0":{"v":"Plot","n":1}}},{"i":829,"$":{"0":{"v":"Contrived Plot","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://www.helpingwritersbecomeauthors.com/how-to-avoid-cardboard-characters-and-plot-contrivances-while-youre-at-it/","n":0.577}}},{"i":830,"$":{"0":{"v":"Narratology","n":1},"1":{"v":"\n\n## References\n\n- [[ar.representing-narratives-in-digital-libraries-the-narrative-ontology]]","n":0.577}}},{"i":831,"$":{"0":{"v":"Salience-based narrative","n":0.707},"1":{"v":"\n## Features\n\n- can be tied to pretty much any testable information in the world state.\n![[ar.emshort.beyond-branching-quality-based-and-salience-based-narrative-structures#^nt9g9zslhb88]]\n","n":0.258}}},{"i":832,"$":{"0":{"v":"Quality-Based Narrative","n":0.707},"1":{"v":"\n- https://emshort.wordpress.com/category/quality-based-narrative/","n":0.707}}},{"i":833,"$":{"0":{"v":"Narrative Engineering","n":0.707},"1":{"v":"\n- http://www.failbettergames.com/tag/narrative-engineering/\n\n\n## Solutions\n\n- [[prdct.storynexus]]","n":0.5}}},{"i":834,"$":{"0":{"v":"Jannidis Three Levels","n":0.577},"1":{"v":"\n## @chatgpt.4o\n\nFotis Jannidis, a scholar in literary studies, proposed a model of narrative communication that distinguishes between three levels of communication within a narrative. These levels help analyze how stories are structured and how information is conveyed from the author to the reader through various intermediaries. The three levels are:\n\n### 1. **Real Communication (External Level)**\n   - **Participants**: The actual author and the actual reader.\n   - **Description**: This is the level of communication that occurs outside the narrative itself. It involves the real, flesh-and-blood author who writes the text and the real reader who interprets it. This level is concerned with the external context, such as the author’s intentions, the historical and cultural background, and the reader’s response to the text.\n   - **Example**: When you read a novel, the real communication is the interaction between you (the reader) and the novelist (the author).\n\n### 2. **Narrative Communication (Internal Level)**\n   - **Participants**: The implied author, the narrator, the narratee, and the implied reader.\n   - **Description**: This level deals with the communication that happens within the narrative itself. The implied author is the version of the author that is constructed by the text, and the implied reader is the ideal reader the text seems to be addressing. The narrator is the voice telling the story, and the narratee is the entity within the text to whom the narrator is speaking. This level focuses on how the story is presented to the reader through the narrative voice and perspective.\n   - **Example**: In a first-person novel, the narrator (a character within the story) might be telling their tale to an implied audience, who represents the narratee. The implied author shapes the narrative voice and how the story unfolds.\n\n### 3. **Fictional Communication (Diegetic Level)**\n   - **Participants**: Characters within the story.\n   - **Description**: This level is concerned with the communication that occurs between characters within the fictional world of the narrative. It involves dialogue, thoughts, and interactions between the characters as they engage with one another. This level is entirely within the diegesis (the world of the story).\n   - **Example**: In a novel, when two characters are having a conversation, the communication between them is at the fictional communication level.\n\n### Summary:\n- **Real Communication**: Interaction between the real author and the real reader.\n- **Narrative Communication**: Interaction within the narrative, involving the implied author, narrator, narratee, and implied reader.\n- **Fictional Communication**: Interaction between characters within the story's fictional world.\n\nThese three levels of communication help to dissect the complex layers through which a story is conveyed and received, offering a framework for understanding the different participants and interactions involved in the narrative process.","n":0.048}}},{"i":835,"$":{"0":{"v":"Chatmans Three Levels of Narrative","n":0.447},"1":{"v":"\n- similar: [[t.storytelling.narratology.jannidis-three-levels]]\n\n## chatgpt.4o\n\nSeymour Chatman, a prominent narrative theorist, proposed a model of narrative communication that distinguishes between different levels of communication within a narrative. His model is influenced by structuralist theories and provides a framework for analyzing how stories are communicated from the author to the reader (or viewer) through various intermediaries.\n\n### Chatman’s Levels of Narrative Communication:\n\n1. **Real Author and Real Reader (External Communication)**:\n   - **Real Author**: The actual person who creates the narrative text.\n   - **Real Reader**: The actual person who reads or interprets the narrative text.\n   - **Description**: This level of communication happens outside the text itself. It involves the interaction between the person who writes the narrative and the person who reads it. The real author has intentions and purposes for writing the text, and the real reader interprets and responds to the text based on their own context and background.\n\n2. **Implied Author and Implied Reader (Narrative Communication)**:\n   - **Implied Author**: A construct of the narrative text, representing an idealized version of the author as inferred by the reader. This is not the same as the real author but rather the authorial presence that the text suggests.\n   - **Implied Reader**: Similarly, this is the ideal reader that the text seems to be addressing. The implied reader is a construct of the text, representing the audience that the implied author envisions.\n   - **Description**: This level is concerned with the narrative as a constructed artifact. The implied author is the narrative persona that the text seems to present, and the implied reader is the hypothetical reader who is best suited to understand and appreciate the narrative as intended by the implied author.\n\n3. **Narrator and Narratee (Internal Communication)**:\n   - **Narrator**: The voice or persona within the narrative that tells the story. The narrator may be a character in the story (first-person narrator) or an outside observer (third-person narrator), and they may have varying levels of reliability and knowledge.\n   - **Narratee**: The entity within the narrative to whom the narrator is speaking. The narratee is a fictional audience created by the narrator's discourse, and it may be a character within the story or a more abstract figure.\n   - **Description**: This is the level of communication within the story itself, where the narrator conveys the events and information to the narratee. The relationship between the narrator and the narratee helps shape how the story is presented and understood within the narrative world.\n\n### Summary:\n- **Real Author and Real Reader**: The interaction between the actual writer and reader outside the text.\n- **Implied Author and Implied Reader**: The idealized author and reader as constructed by the text, representing the intended communication within the narrative.\n- **Narrator and Narratee**: The communication that occurs within the narrative, involving the storyteller and the fictional audience.\n\nChatman’s levels of narrative communication help to clarify the different layers through which a narrative operates, from the real-world context of writing and reading to the fictional communication within the story itself. This model is useful for analyzing how meaning is constructed and conveyed in narratives.","n":0.045}}},{"i":836,"$":{"0":{"v":"Master Plotlines","n":0.707},"1":{"v":"\n\n## 20 Master Plotlines\n\n- [[p.hasSource]] https://www.sciencedirect.com/science/article/pii/S0363811115000570?utm_medium=email&utm_source=substack#bib0080\n- #summary\n  - (1) Quest, (2) Adventure, (3) Pursuit, (4) Rescue, (5) Escape, (6) Revenge, (7) Riddle/Mystery, (8) Rivalry, (9) Underdog, (10) Temptation, (11) Metamorphosis, (12) Transformation, (13) Maturation, (14) Love, (15) Forbidden Love, (16) Sacrifice, (17) Discovery, (18) Wretched Excess, and (19 & 20) Rise & Fall\n- [[p.hadDetail]] \n\n> Adventure\tIn an adventure story our attention is on the journey. Often, adventures take the characters to exotic locations, dangerous and unexpected places. Adventure is used to tell stories of Olympic athletes, new space technology, automotive innovations, a war correspondent, or the exciting experiences of a visionary CEO or leader. Adventure stories are useful as frames for important speeches, television interviews, historical documents, and other venues like the Internet and social media.\n\n> Discovery\tDiscovery is a character based plot. Discovery is a plot about people and their quest to understand who they are and the world around them: “Who am I?” “How did I get here?” “Why am I here?” “What does this all mean?” Discovery answers life's questions using characters and situations that seem real and concrete. Discovery plots fit well with activists (GLBTQ, animal protection/rights, outdoors people, protest leaders), as well as individuals and leaders in other contexts.\n\n> Escape\tThe escape plot is literal, someone is being held against his/he will and wants to escape. Consider Edward Snowden who fled the US and his lengthy confinement to the Russian airport transit zone, the Swiss Hostage who recently escaped from Islamist terrorists (www.cnn.com/2014/12/06/world/asia/philippines-swiss-escapes), etc. In the escape plot, the victim is his/her own hero. Often the victim is portrayed as having been wrongly accused or falsely imprisoned. In the escape plot, instead of waiting patiently to be rescued, the victim often frees him/herself. Escape plots often revolve around unfair imprisonment.\n\n> Forbidden Love\tThis story takes many forms: older man and younger women, younger man and older woman, couple united across racial, ethnic, or class boundaries, etc. Forbidden love often ends badly. The lovers are forced to conform to society, and face disillusionment, death, mutilation, etc. Social convention usually wins. Forbidden love stories are used by politicians, activist organizations, and members of racial and ethic groups working for social harmony.\n\n> Love\tThe common story is of two lovers who find each other in the beginning of the story, but circumstances separate them. They spend the remainder of the story trying to get back together. Love stories may be used in an assortment of contexts including animal welfare organizations, environmental activists, organizations supporting partner benefits, etc.\n\n>\n Maturation\tMaturation is a coming of age story. The focus of the story is on the protagonist's moral and psychological growth. Consider children subjected to cyber-bullying or dealing with terminal or potentially fatal diseases. Activists and immigrant organizations tell maturation stories. The prodigal son, and the “local boy/girl does good” story are forms of maturation.\n\n> Metamorphosis\tThe metamorphosis plot is about literal change from one form to another (lycanthrope, vampire, robot, transgender). Public relations, stories about metamorphosis are becoming increasingly real as technology allows us to create more-realistic computers and robots/androids, sentient computer viruses and operating systems, transplant heads on to new bodies, etc. Similarly, activist organizations (health and GLBTQ) often deal with physical and emotional transformation. This plot will also be reified as DARPA robots eventually take to the battlefields or streets, or evolve into “personal helpers/pets,” etc.\n\n> Pursuit\tThe pursuit story is essentially a hide-and-seek, where one person, organization, or group pursues another. Consider the search for subatomic particles like the Higgs boson, a scientist defecting from another country, international computer hackers, “deadbeat dads” hiding from the law, or soldiers on the trail of a captured comrade. A pursuit story might be used to frame a feature story, or used in supplementary material on the Internet, social media, and annual report, internal documents used to socialize new employees, as narrative frames for organizational videos, etc.\n\n> Quest\tThe quest is the “search for a person, place, or thing, tangible or intangible.” The protagonist hopes that their life will be changed if they find the object of their quest. The quest could be for a disease cure, a new automotive technology, a rewarding career, a college major or job, or the place for a perfect vacation. The quest story is suitable for organizational histories, social media and blogs, annual reports, etc.\n\n> Rescue\tTypically, the hero(ine) of the rescue plot has to venture out into the cruel world searching for someone or something. Rescue is a physical plot, depending heavily on action. Another genre of rescue pits the protagonist against a powerful enemy in an effort to save the business, farm, etc. Thus, the “victim,” in this case could be the “truth,” “freedom,” etc. embodied in a publication, public building, trial, park, etc. The rescue plot is used by activist groups, to sell KickStarter campaigns, to warrant supporting petitions and action alerts, and of course, for organizations like NASA, trying to get kids interested in science and technology.\n\n> Revenge\tThe revenge story is about taking the law into one's own hands when the powers that be fail to do what is right. The protagonist does not want to have to break the law, but is forced into it by circumstances. The protagonist of the revenge story is generally a good person forced to take vengeance into his/her own hands. The revenge story often pits the little guy against the big corporation or a corrupt governmental agency or police department. Revenge has been used to describe hacking activities, governmental actions in other countries, employee (and company) mistreatment stories, etc.\n\n> Riddle/Mystery\tThe riddle challenges the audience to figure out what happened by means of enigmatic clues and bits of seemingly trivial information. Some riddles have existed for ages (such as mathematics, physics, and cryptology questions), while others have just emerged as the physical, social, and economic environment has changed with climate change, finance, crime, etc. Science and governmental organizations often draw upon mystery.\n\n> Rise/Fall\tThis is the rise and fall story so common among politicians, entertainers, celebrities, etc. Indeed, the fall or descent story often follows from the “wretched excess” plot. The story can recount either the rise, or the fall, or both. Rise and fall stories have been used extensively for propaganda purposes, and for marketing and reputation building activities.\n\n> Rivalry\tRivalry pits two competing characters that are working for the same goal against each other. Famous examples include the Tesla/Edison rivalry surrounding AC vs. DC current, and the more modern rivalries among space exploration companies competing to be the first to create space tourism and reusable rockets. Rivalry is a perfect plot for competing scientists, researchers, and activists. Rivalry is a plot about human nature and morality. Rivalry can be a competitive story, in which each character wants to be the first to reach a particular goal (make it to the top of the mountain, reach the North Pole, sequence human DNA, cure cancer), or a historical story.\n\n> Sacrifice\tSacrifice often takes the form of one person making a sacrifice that is out of character for him/her and comes with a stiff price tag. The story needs to lead up to the point where s/he is ready and willing to make the sacrifice but to be believable this process needs to be built up. Often the person making the sacrifice is seemingly without morals. Explorers, activists, test pilots, single parents, war heroes, scientists working in remote or dangerous locations, people working for racial, religious, economic, or political rights, and other dynamic figures are perfect for telling sacrifice stories.\n\n> Temptation/Greed\tThe temptation story is about a person rather than the object of their temptation. What is the character being tempted with? What is the price to be paid for giving in? The temptation story emerges every few years as a new ponzi scheme emerges, or surrounding greed in the banking industry. Activist and politicians use it to frame legal reform. Consider the story of Major General Smedley Butler for an excellent example.\n\n> Transformation\tTransformation occurs when someone experiences a life-changing event like the loss of a loved one from cancer, an insurance company denies coverage for a life-threatening illness, a person contracts AIDS, etc. The transformation story can support new converts to causes, activism by previously passive supporters, etc. We see transformations as people switch political parties, shift their ideologies from conservative to liberal, suffer an illness and throw themselves into becoming more-healthy, etc. Transformation is useful in political public relations contexts, by activists, and in social media and blog content.\n\n> Underdog\tThe underdog is the little guy/gal against the big corporation, government, agency, etc. The underdog needs to appear motivated and realistic. Often the underdog is an-over-the top personality, but there is a reluctant underdog who struggles against petty tyranny. The underdog plot is used to frame activist messages (environmental, climate change, educational spending assistance for the homeless), fund-raising campaigns (AIDS, breast cancer) or other health/disease issue (medicinal marijuana, RU486, abortion).\n\n> Wretched Excess\tThe plot usually revolves around a single person, although a focus on a group of people and how they were changed is possible. The wretched excess plot is employed by activists, religious groups, and others, often to support issues management efforts, new legislation, increased taxes/regulation, CEO fraud or misbehavior, corporate misinformation, etc.\n>","n":0.026}}},{"i":837,"$":{"0":{"v":"Interactive Storytelling","n":0.707},"1":{"v":"\n- related: [[t.drama.interactive]]\n- \"understand natural language and gestural input based on the context of the story and then integrate the player’s interactions into a space of potential plot directions and characters\"\n![[ar.atlantic.video-games-are-better-without-stories#^6abg9iz5r68q]]\n\n## Issues\n\n- stories are linear, games are not\n- \n\n## Examples\n\n- [[game.facade]]\n\n## References\n\n- [[ar.a-preliminary-poetics-for-interactive-drama-and-games]]\n- [[ar.i-have-no-words-i-must-design]]","n":0.151}}},{"i":838,"$":{"0":{"v":"Holodeck","n":1},"1":{"v":"\n## The Dream\n\n![[ar.atlantic.video-games-are-better-without-stories#^6abg9iz5r68q]]\n![[ar.atlantic.video-games-are-better-without-stories#^0mdcsuektdle]]\n\n## Issues\n\n![[ar.atlantic.video-games-are-better-without-stories#^am8zjmvo93jr]]","n":0.5}}},{"i":839,"$":{"0":{"v":"Fiction","n":1},"1":{"v":"\n## Definition\n\n- \"any creative work, chiefly any narrative work, portraying individuals, events, or places that are imaginary or in ways that are imaginary.\"\n- \"In a traditional narrow sense, \"fiction\" refers to written narratives in prose – often referring specifically to novels, novellas, and short stories. More broadly, however, fiction encompasses imaginary narratives expressed in any medium, including not just writings but also live theatrical performances, films, television programs, radio dramas, comics, role-playing games, and video games.\"\n\n\n## References\n\n- https://en.wikipedia.org/wiki/Fiction","n":0.113}}},{"i":840,"$":{"0":{"v":"Young Adult","n":0.707}}},{"i":841,"$":{"0":{"v":"Writing","n":1}}},{"i":842,"$":{"0":{"v":"Own Voices","n":0.707},"1":{"v":"\n- books (or other media) about characters from underrepresented/marginalized groups in which the author shares the same identity\n  - e.g. [Monstrous Design](https://www.amazon.com/Monstrous-Design-Battalion-Dead-Dunn-ebook/dp/B0BPCMFKXL?ref_=ast_sto_dp)","n":0.213}}},{"i":843,"$":{"0":{"v":"Interactive Fiction","n":0.707},"1":{"v":"\n- aka: visual novels\n- similar: \n \n## Description\n\n- \"a text based story with narrative style of literature and interactivity aided by static or sprite based visuals\"\n- \"Early versions of this genre came in the form of Choose-Your-Own-Adventure like novels, told on paper which allows the reader to choose one of a few paths depending on their choice. They are often told in 2nd person, and provide the reader the sights and sounds of the environment so that they sense they are interacting with the world while making those choices.\" [^1]\n- \"closely compared to \"video games\" for the sake that its an interactive medium with cause, effect, and consequences. However, most of the IF community sees it as a literary narrative.\" [^1]\n\n## Perspective\n\n- \"Some IF works dispense with second-person narrative entirely, opting for a first-person perspective ('I') or even placing the player in the position of an observer, rather than a direct participant. In some 'experimental' IF, the concept of self-identification is eliminated, and the player instead takes the role of an inanimate object, a force of nature, or an abstract concept; experimental IF usually pushes the limits of the concept and challenges many assumptions about the medium.\" \n\n## Examples\n\n- [[game.sentou-gakuen]]\n\n## Solutions\n\n- [[prdct.istory]]\n- [[prdct.twine]]\n- [[prdct.quest]], [[prdct.questjs]]\n- [[prdct.choicescript]]\n- [[prdct.game2text]]\n\n## Resources\n\n- [[ar.what-people-said-about-the-missing-tools-and-some-that-arent-missing-at-all]]\n- [[ar.arstechnica.from-infocom-to-80-days-an-oral-history-of-text-games-and-interactive-fiction]]\n- https://www.ifwiki.org/Engine_List\n- https://emshort.blog/2019/07/14/a-top-20-list-of-if/\n\n## References\n\n- https://game2text.com/user-guide/visual-novels/\n- https://en.wikipedia.org/wiki/Interactive_fiction\n- [[ar.story-vs-game-the-battle-of-interactive-fiction]]  \n- [[ar.dev-to.online-visual-novel-in-godot-case-study-on-sentou-gakuen]]  \n\n[^1]: https://mythicscribes.com/community/threads/interactive-fiction-is-it-a-legitimate-genre.22298/","n":0.067}}},{"i":844,"$":{"0":{"v":"Environmental Storytelling","n":0.707},"1":{"v":"\n![[ar.atlantic.video-games-are-better-without-stories#^a497l444fdio]]\n\n## Examples\n\n- [[game.gone-home]]\n- [[game.what-remains-of-edith-finch]]\n- [[game.dear-esther]]\n\n\n## References \n\n- https://www.gamedeveloper.com/design/environmental-storytelling","n":0.354}}},{"i":845,"$":{"0":{"v":"Emotional Arcs","n":0.707},"1":{"v":"* ‘Rags to riches’ (rise).\n* ‘Tragedy,’ or ‘Riches to rags’ (fall).\n* ‘Man in a hole’ (fall-rise).\n* ‘Icarus’ (rise-fall).\n* ‘Cinderella’ (rise-fall-rise).\n* ‘Oedipus’ (fall-rise-fall).`","n":0.213}}},{"i":846,"$":{"0":{"v":"Digital Storytelling","n":0.707},"1":{"v":"\n## Solutions\n\n- [[t.drama.interactive]]\n- [[t.storytelling.fiction.interactive]]\n  \n## References\n\n- [[t.storytelling.holodeck]]\n","n":0.378}}},{"i":847,"$":{"0":{"v":"Diegesis","n":1},"1":{"v":"\n**Diegesis** is a term used in narrative theory and film studies to refer to the narrative world in which the story takes place. It encompasses everything that exists within the fictional universe of the story, including characters, events, objects, and settings.\n\n### Key Aspects of Diegesis:\n\n1. **Diegetic Elements**:\n   - These are the elements that are part of the story world itself. If a character in a film hears music playing on the radio, that music is diegetic because it exists within the narrative world. Similarly, dialogue between characters, sounds made by objects or actions in the story, and anything else that the characters can perceive are considered diegetic.\n\n2. **Non-Diegetic Elements**:\n   - These elements are not part of the story world and are intended only for the audience. Examples include background music (soundtrack), voice-over narration (when the narrator is not a character within the story), or text that appears on the screen to provide context (like subtitles or credits). The characters in the story are unaware of non-diegetic elements.\n\n3. **Diegetic vs. Non-Diegetic**:\n   - Understanding the distinction between diegetic and non-diegetic elements is crucial in analyzing how a story is told. In film, for example, a non-diegetic soundtrack might influence the mood of a scene without the characters being aware of it, while diegetic sounds or music can have an impact on the characters themselves.\n\n### Example in Film:\n- **Diegetic**: A character playing a song on a guitar within a movie. The character and other characters in the scene can hear it, and it exists within the film's world.\n- **Non-Diegetic**: The orchestral score playing in the background during an action sequence. The audience hears it, but the characters do not.\n\n### Diegesis in Literature:\nIn literary theory, diegesis refers to the world of the story as it is narrated by the narrator. The term is often contrasted with \"mimesis,\" which refers to the imitation or representation of reality in art. Diegesis involves the recounting of events and descriptions, while mimesis involves showing events through dialogue or direct action.\n\n### Summary:\nDiegesis is the term used to describe the narrative world in which the story unfolds","n":0.054}}},{"i":848,"$":{"0":{"v":"Collaborative Story-Telling","n":0.707},"1":{"v":"\n- aka: collaborative story-writing, collaborative story-creation\n- similar: [[t.drama.interactive]]\n\n## Description\n\n### [[user.chatgpt.4o]]\n\n**Collaborative storytelling** can take many forms, where participants work together to create a narrative. Some popular examples include:\n\n1. **Tabletop RPGs** (e.g., **Dungeons & Dragons**): Players and a game master build a story through role-playing, with the plot evolving based on their decisions.\n2. **Shared-world fiction**: Writers contribute stories set in a common universe (e.g., **Star Wars expanded universe**).\n3. **Online role-playing communities**: In forums or platforms like **Discord**, participants write parts of a story collaboratively.\n4. **Improv storytelling**: Groups use improv techniques to co-create stories live (e.g., improv theater).\n\n## References\n\n- https://www.reddit.com/r/fansofcriticalrole/comments/12byt6d/the_problem_about_collaborative_storytelling/","n":0.102}}},{"i":849,"$":{"0":{"v":"Character","n":1}}},{"i":850,"$":{"0":{"v":"Greimas Six Actants","n":0.577},"1":{"v":"\n## @chatgpt.4o\n\nAlgirdas Julien Greimas, a Lithuanian-French semiotician, developed a theory of narrative structure known as the **\"actantial model,\"** which is a tool for analyzing the roles that characters and elements play in a story. Greimas proposed that there are six fundamental \"actants\" that can be identified in any narrative. These actants are not specific characters but rather functional roles that characters or entities can occupy within a narrative structure.\n\n### The Six Actants:\n\n1. **Subject**:\n   - **Role**: The primary character or entity that drives the action of the story, often the protagonist.\n   - **Goal**: The subject seeks to achieve something, typically represented by the \"object.\"\n   - **Example**: In a hero’s journey, the hero is the subject.\n\n2. **Object**:\n   - **Role**: The goal or desired outcome that the subject is striving to obtain or achieve.\n   - **Example**: In a quest narrative, the object might be a magical artifact that the hero seeks.\n\n3. **Sender**:\n   - **Role**: The entity or force that sends the subject on the quest or assigns the task.\n   - **Example**: In many fairy tales, the king who sends the hero on a quest is the sender.\n\n4. **Receiver**:\n   - **Role**: The entity that benefits from the subject’s success; often the same as the subject but can also be another character or group.\n   - **Example**: If the hero is retrieving a stolen treasure, the original owner of the treasure could be the receiver.\n\n5. **Helper**:\n   - **Role**: Characters, forces, or tools that assist the subject in achieving the object.\n   - **Example**: In many stories, the helper could be a sidekick, a magical creature, or even a weapon that aids the hero.\n\n6. **Opponent** (also referred to as \"Antagonist\"):\n   - **Role**: The character, force, or obstacle that opposes the subject and creates conflict.\n   - **Example**: The villain or antagonist in a story who tries to prevent the hero from achieving the object.\n\n### Actantial Model Structure:\nThese six actants can be visualized as occupying different positions in a narrative structure:\n\n- **Subject → Object**: The subject is striving to achieve or obtain the object.\n- **Sender → Receiver**: The sender motivates or compels the subject to pursue the object, ultimately for the benefit of the receiver.\n- **Helper → Opponent**: The helper assists the subject, while the opponent tries to hinder the subject.\n\n### Application in Narrative Analysis:\nGreimas’ actantial model can be applied to a wide range of narratives, from simple fairy tales to complex modern stories. By identifying the actants in a story, analysts can better understand the underlying structure and the roles that different characters and elements play.\n\n### Example in a Classic Tale:\nIn the story of **\"Little Red Riding Hood\"**:\n- **Subject**: Little Red Riding Hood.\n- **Object**: Delivering the basket of food to her grandmother.\n- **Sender**: Little Red Riding Hood's mother.\n- **Receiver**: The grandmother.\n- **Helper**: The woodsman who saves her.\n- **Opponent**: The Big Bad Wolf.\n\nThis model helps in breaking down the narrative into its functional components, making it easier to analyze the dynamics of storytelling.\n\n","n":0.046}}},{"i":851,"$":{"0":{"v":"Alternate Reality","n":0.707},"1":{"v":"\n- aka: parallel universe, alternate universe, parallel world, parallel dimension, or alternative dimension\n\n## References\n\n- https://en.wikipedia.org/wiki/Parallel_universes_in_fiction","n":0.258}}},{"i":852,"$":{"0":{"v":"Social Science","n":0.707}}},{"i":853,"$":{"0":{"v":"The Great Weirding","n":0.577},"1":{"v":"\n## Resources\n\n- https://studio.ribbonfarm.com/p/the-great-weirding\n- https://www.theatlantic.com/technology/archive/2016/09/harambe-the-perfect-meme/498743/","n":0.5}}},{"i":854,"$":{"0":{"v":"Computational Social Science","n":0.577}}},{"i":855,"$":{"0":{"v":"Roleplaying","n":1},"1":{"v":"\n## Description\n\n- broadly construed, includes acting, role-playing gaming, and some kinds of therapy, training, and education\n- can be social, but doesn't have to be\n\n![[t.drama.interactive#role-playing-vs-interactive-drama]]\n\n## Examples\n\n- @sigourney-weaver played the fictional role of Ripley in [[superwork.alien]]\n  - specifically, she played Ellen Ripley in [[video.alien]], [[video.aliens]], [[video.alien-3]], [[video.alien-resurrection]] and [[game.alien-isolation]]\n  \n## Thoughts\n\n- role-playing can be thought of as a spectrum\n  - seriousness axis:\n    - not-serious: \n  - pretending axis:\n\n### \"RPGs\"\n\nsee [[t.cs.game.rpg]]\n","n":0.121}}},{"i":856,"$":{"0":{"v":"Award","n":1}}},{"i":857,"$":{"0":{"v":"Ennie","n":1}}},{"i":858,"$":{"0":{"v":"World","n":1},"1":{"v":"\n- [[p.hadDefinition]]\n  - a fictionalized or simulated planet","n":0.354}}},{"i":859,"$":{"0":{"v":"World Building","n":0.707},"1":{"v":"\n\n## Resources\n  \n- https://rpgbot.net/general-tabletop/worldbuilding/\n","n":0.5}}},{"i":860,"$":{"0":{"v":"Virtual Tabletop","n":0.707},"1":{"v":"\n\n## Solutions\n\n- [[prdct.alchemy-rpg]]\n- [[prdct.arkenforge]]\n- [[prdct.d20-pro]]\n- [[prdct.fantasy-grounds]]\n- [[prdct.foundry-vtt]]\n- [[prdct.lets-role]]\n- [[prdct.online-assistant]]\n- [[prdct.owlbear-rodeo]]\n- [[prdct.quest-portal]]\n- [[prdct.role]]\n- [[prdct.roll20]]\n- [[prdct.tableplop]]\n- [[prdct.tabletop-simulator-tts]]\n- [[prdct.talespire]]\n\n### Utilities and Add-Ons\n\n- [[prdct.beyond20]]\n- [[prdct.plutonium]]\n\n## References\n\n- https://www.reddit.com/r/FantasyGrounds/comments/x3s4f4/why_is_fantasy_grounds_so_popular/ \n- https://startplaying.games/blog/posts/a-comprehensive-list-of-virtual-tabletops\n","n":0.2}}},{"i":861,"$":{"0":{"v":"Timeline Management","n":0.707},"1":{"v":"\n\n\n## Resources\n\n- [[ar.cmu.rti-the-role-of-time]]\n- http://www.simile-widgets.org/timeline/","n":0.5}}},{"i":862,"$":{"0":{"v":"Srd","n":1}}},{"i":863,"$":{"0":{"v":"5","n":1},"1":{"v":"\n## References\n\n- https://www.dndbeyond.com/forums/d-d-beyond-general/general-discussion/162983-srd-5-1-changes-from-5-0-ignore-me","n":0.577}}},{"i":864,"$":{"0":{"v":"Squad","n":1}}},{"i":865,"$":{"0":{"v":"Simple Roleplaying","n":0.707}}},{"i":866,"$":{"0":{"v":"Setting","n":1},"1":{"v":"\n- [[p.hadDefinition]]\n  - \"the time and place in which the fiction of a campaign or other role-playing game is supposed to happen... The largest scale of a setting is to include multiple worlds in a sort of universe or multiverse... \"\n    - https://rpgmuseum.fandom.com/wiki/Setting\n  - may have a [[sh.metaplot]]\n\n## Possible Solutions (open-source)\n\n- Santharia (dead)\n- [[game.tyuns]] just starting t.2023.11.17\n- [[setting.metamor-keep]]\n\n## Resources\n\n- https://www.reddit.com/r/rpg/comments/eu5453/a_shared_free_and_open_source_setting_for_role/\n- https://taholtorf.wordpress.com/2013/01/20/an-open-source-fantasy-world/","n":0.128}}},{"i":867,"$":{"0":{"v":"Session","n":1}}},{"i":868,"$":{"0":{"v":"Scenario","n":1},"1":{"v":"\n## chatgpt4.o\n\nA **role-playing scenario** is a structured narrative framework that sets the stage for a role-playing session, whether it's tabletop, live-action, or computer-aided. It provides the players with the context, objectives, and challenges that guide their interactions with the game world and each other.\n\n### Key Elements of a Role-Playing Scenario:\n\n#### 1. **Setting**:\n   - **Description**: The world or environment in which the scenario takes place. It includes the geographical, social, political, and cultural context that shapes the game world.\n   - **Examples**: A medieval kingdom, a dystopian future city, or a space station orbiting a distant planet.\n   - **Role**: The setting gives players a sense of the world’s rules, physical constraints, and atmosphere.\n\n#### 2. **Backstory**:\n   - **Description**: The historical and narrative context that leads up to the current scenario. It includes key events or conditions that have shaped the present situation.\n   - **Examples**: A war between two kingdoms that has left the land in ruins, a starship crash-landing on an alien planet, or the discovery of a forbidden magical artifact.\n   - **Role**: The backstory provides depth and a sense of continuity, helping players understand the motivations and stakes.\n\n#### 3. **Objectives**:\n   - **Description**: The goals or tasks that the characters (or players) may achieve. These can be specific and immediate, or more open-ended and long-term.\n   - **Examples**: Defeating a dragon, solving a murder mystery, negotiating peace between warring factions, or escaping a haunted mansion.\n   - **Role**: Objectives drive the plot and give players something to focus on, creating a sense of direction.\n\n#### 4. **Characters (PCs and NPCs)**:\n   - **Player Characters (PCs)**: The characters controlled by the players. Each PC has its own motivations, abilities, and backstory.\n   - **Non-Player Characters (NPCs)**: Characters controlled by the game master (GM) or system. NPCs can be allies, enemies, or neutral figures within the scenario.\n   - **Role**: Characters provide the means for role-playing and interaction within the game world. NPCs help flesh out the world and move the plot forward.\n\n#### 5. **Plot Hooks**:\n   - **Description**: Events or situations designed to grab the players’ attention and draw them into the scenario. These hooks encourage engagement and prompt characters to take action.\n   - **Examples**: A mysterious figure offering a quest, an attack on a nearby village, or the sudden disappearance of a key NPC.\n   - **Role**: Plot hooks introduce conflict, intrigue, or urgency, pulling players into the story and giving them reasons to act.\n\n#### 6. **Conflict/Challenges**:\n   - **Description**: Obstacles, enemies, or dilemmas that the players must overcome to achieve their objectives. These can be physical, mental, social, or moral in nature.\n   - **Examples**: Combat with monsters, solving puzzles, navigating treacherous terrain, or negotiating with hostile factions.\n   - **Role**: Conflict creates tension and drama, making the scenario engaging and providing opportunities for character development and teamwork.\n\n#### 7. **Scenes and Encounters**:\n   - **Description**: Specific moments or events where players interact with the environment, NPCs, or each other. Encounters can be pre-planned or dynamically created based on player actions.\n   - **Examples**: A tense negotiation with a crime lord, an ambush by thieves, or a trek through a dangerous forest.\n   - **Role**: Scenes and encounters are the building blocks of the scenario, breaking up the session into meaningful moments where characters make decisions or face challenges.\n\n#### 8. **Rules and Mechanics**:\n   - **Description**: The game mechanics or rules that govern how characters interact with the scenario. These include systems for combat, skills, social interactions, and more.\n   - **Examples**: Dice rolls for skill checks, hit points for combat, or decision trees for dialogue.\n   - **Role**: Mechanics provide structure and fairness to the scenario, determining outcomes and ensuring consistency.\n\n#### 9. **Moral/Philosophical Dilemmas**:\n   - **Description**: Situations that force characters to make difficult choices with moral or ethical consequences. These dilemmas often reveal character motivations and challenge the players’ decision-making.\n   - **Examples**: Deciding whether to sacrifice a few to save many, choosing sides in a morally ambiguous conflict, or dealing with the consequences of breaking the law for the greater good.\n   - **Role**: Moral dilemmas add depth and complexity to the scenario, creating emotional engagement and making decisions feel meaningful.\n\n#### 10. **Factions/Groups**:\n   - **Description**: Organized groups within the scenario that have their own goals, power structures, and influence over the events. Factions can be allies, enemies, or neutral entities.\n   - **Examples**: A thieves' guild, a royal court, a rebel faction, or a mysterious cult.\n   - **Role**: Factions add social dynamics, political intrigue, and opportunities for alliances or conflicts, creating layers of interaction within the scenario.\n\n#### 11. **Outcome/Consequences**:\n   - **Description**: The potential results of the players’ actions, which can change the course of the story. These may be pre-planned or emerge organically based on the players’ decisions.\n   - **Examples**: Saving a town from destruction, but angering a powerful faction; solving a mystery, but at the cost of a key ally’s life.\n   - **Role**: Consequences provide a sense of agency and impact, showing players that their decisions matter and shaping the evolution of the story.\n\n#### 12. **Atmosphere/Tone**:\n   - **Description**: The mood or feel of the scenario, which can be created through descriptive language, music, or other immersive elements.\n   - **Examples**: Dark and eerie for a horror setting, light and adventurous for a high-fantasy quest.\n   - **Role**: Atmosphere enhances immersion, drawing players deeper into the world and reinforcing the emotional impact of events.\n\n### Conclusion:\nA role-playing scenario is a dynamic and multi-faceted framework that includes the **setting**, **characters**, **plot**, **conflict**, and other elements to create an engaging and immersive experience. Each element contributes to the depth and richness of the story, allowing players to interact with the world in meaningful ways.","n":0.033}}},{"i":869,"$":{"0":{"v":"Structure","n":1},"1":{"v":"\n- topics: [[game-system.dungeons-and-dragons]] [[t.roleplaying.scenario-structure]]\n\n## Issues\n\n- \"The game holds out the promise of characters advancing into truly epic levels of power — founding kingdoms in AD&D, becoming literal gods in Basic D&D, the _Epic Level Handbook_ in 3<sup>rd</sup> Edition, the Paragon and Epic tiers of 4<sup>th</sup> Edition — but a significant portion of the fanbase has mostly been interested in playing Aragorn and Conan (i.e., fairly gritty fantasy heroes [rooted pretty firmly in reality](https://thealexandrian.net/wordpress/587/roleplaying-games/dd-calibrating-your-expectations-2)).\"\n- \"as you gain the powers of a demigod, the scenario structure of the dungeon — exploring an unknown location one room at a time — begins to fall apart\"\n- \"they also shred railroads: It becomes increasingly difficult for a DM to force their players to do stuff as the power level and options available to the PCs proliferate.\"\n\n## References\n\n- [[ar.the-alexandrian.soloing-smaug-the-struggle-for-the-soul-of-dd]]","n":0.087}}},{"i":870,"$":{"0":{"v":"Scenario Structure","n":0.707},"1":{"v":"\n![[ar.the-alexandrian.game-structures#two-fundamental-questions-of-scenario-structure]]\n\n\n## References\n\n- [[ar.the-alexandrian.game-structures]]","n":0.577}}},{"i":871,"$":{"0":{"v":"Play by Post (PbP)","n":0.5},"1":{"v":"\n## Description\n\n- can supplement a synchronous game ()\n\n## Issues\n\n- not (as) social\n- slowness (ain't the problem)\n\n## References\n\n- [[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming]]","n":0.236}}},{"i":872,"$":{"0":{"v":"Pen and Paper Roleplaying","n":0.5},"1":{"v":"\n\n## References\n\n- [[ar.dungeons-deceptions-the-first-d-d-players-push-back]]","n":0.577}}},{"i":873,"$":{"0":{"v":"Party","n":1},"1":{"v":"\n#aka group, team\n\n- [[p.hadDefinition]]\n  - a set of [[sh.t.participant]]s \n\n- [[p.comparableTo]] [[t.roleplaying.squad]] \n  - a party is \"in-game\" and may have [[t.roleplaying.npcs]]\n  - ","n":0.209}}},{"i":874,"$":{"0":{"v":"out-of-game","n":1}}},{"i":875,"$":{"0":{"v":"Objective Management","n":0.707}}},{"i":876,"$":{"0":{"v":"NPCs","n":1}}},{"i":877,"$":{"0":{"v":"Module","n":1}}},{"i":878,"$":{"0":{"v":"MMORPG","n":1},"1":{"v":"\n- the \"players\" might be autonomous digital agents, so MMO might be consistent with cozy, bespoke gaming\n","n":0.243}}},{"i":879,"$":{"0":{"v":"Maps","n":1},"1":{"v":"\n- [[p.hasSubClass]]\n  - [[t.roleplaying.maps.overworld]]\n  - [[t.roleplaying.maps.adventure]]\n  - [[t.roleplaying.maps.combat]]\n- \"The over-world is for travel, the adventure maps are for planning, and the combat maps are for fighting. Each type of map may see varying amounts of use. From experience with groups we’ve run, the over-world map generally lasts for the whole campaign, and thus gets the most use.\"\n  - https://www.masterthedungeon.com/dnd-maps/","n":0.13}}},{"i":880,"$":{"0":{"v":"Overworld Maps","n":0.707}}},{"i":881,"$":{"0":{"v":"Combat Maps","n":0.707},"1":{"v":"\n#aka grid maps\n\n- typically each square = 5ft","n":0.354}}},{"i":882,"$":{"0":{"v":"Adventure Maps","n":0.707}}},{"i":883,"$":{"0":{"v":"RPG Map Making","n":0.577},"1":{"v":"\n\n- [[c.Resource.List]] \n  - https://wiki.roll20.net/Useful_links_for_mapping\n","n":0.447}}},{"i":884,"$":{"0":{"v":"Hex Grid","n":0.707}}},{"i":885,"$":{"0":{"v":"Loot","n":1}}},{"i":886,"$":{"0":{"v":"Location Management","n":0.707}}},{"i":887,"$":{"0":{"v":"Live Action Role-Playing (LARP)","n":0.5},"1":{"v":"\n**LARPing** (Live Action Role-Playing) involves participants physically acting out their character roles in a story or game. It blends elements of improvisational theater, role-playing games, and physical reenactment.\n\n## Examples\n\n### from chatgpt:\n\nHere are some popular examples of LARPing:\n\n### 1. **Dystopia Rising**:\n   - A **post-apocalyptic LARP** where participants play survivors of a world overrun by zombies and mutants. The game features elements of survival horror, community building, and resource management.\n\n### 2. **Vampire: The Masquerade**:\n   - A well-known **gothic-horror LARP** set in the World of Darkness universe, where participants take on roles as vampires. This LARP involves deep social interactions, political intrigue, and navigating vampire society, often in public venues like nightclubs or rented spaces.\n\n### 3. **Bicolline** (Quebec, Canada):\n   - One of the largest medieval-fantasy LARP events, **Bicolline** involves thousands of participants who come together to role-play knights, wizards, merchants, and other characters in a medieval village. The game features grand battles, diplomacy, and elaborate settings.\n\n### 4. **College of Wizardry** (Poland):\n   - Inspired by the Harry Potter universe, **College of Wizardry** takes place in a real castle in Poland. Participants play as students, professors, or staff members of a magical school. The game involves attending \"classes,\" magical duels, and uncovering mysteries.\n\n### 5. **Dagorhir**:\n   - A **combat-focused LARP** involving large-scale battles with foam weapons, based loosely on fantasy literature. Unlike story-heavy LARPs, Dagorhir emphasizes physical combat, medieval tactics, and athleticism.\n\n### 6. **ConQuest of Mythodea** (Germany):\n   - This is the **largest LARP event in the world**, with thousands of participants from different countries. It’s set in a high-fantasy universe with elaborate quests, political intrigue, and massive combat scenarios.\n\n### 7. **Nordic LARP**:\n   - **Nordic LARP** is a style of LARP popular in Scandinavian countries, focusing on deep immersion, emotional experiences, and social themes. One example is **\"Just a Little Lovin'\"**, which explores themes of love and loss during the AIDS crisis in the 1980s.\n\n### 8. **Old Town Festival** (Poland):\n   - An immersive **post-apocalyptic LARP** that recreates a world inspired by games like *Fallout*. It’s known for its detailed props, costumes, and highly immersive atmosphere.\n\n### 9. **New World Magischola** (United States):\n   - A **wizard school LARP** set in an American magical academy, inspired by the Harry Potter universe but featuring its own original lore. Participants take part in classes, solve mysteries, and navigate magical conflicts over a multi-day event.\n\n### 10. **Empire** (United Kingdom):\n   - A high-fantasy LARP run by **Profound Decisions**, set in a fictional empire. Players create their own characters, participate in battles, and engage in a political structure, with the game featuring immersive camps, trading, and rituals.\n\nThese LARP examples span a range of genres—from fantasy to horror and dystopian settings—and each offers a different level of **immersion, combat, or narrative focus**, depending on the preferences of the participants. LARPs can range from light, fun scenarios to more intense, emotionally charged experiences, allowing participants to deeply explore different roles and stories.\n\n## References\n\n- https://en.wikipedia.org/wiki/Live_action_role-playing_game","n":0.046}}},{"i":888,"$":{"0":{"v":"Item Management","n":0.707},"1":{"v":"\n- [[p.comparableTo]] [[t.roleplaying.inventory-management]]\n  - inventory is player-focused; the DM has a bigger challenge\n","n":0.277}}},{"i":889,"$":{"0":{"v":"Inventory Management","n":0.707}}},{"i":890,"$":{"0":{"v":"in-game","n":1},"1":{"v":"\n- [[p.hadDefinition]]\n  - things that virtually exist or happen in a [[sh.t.continuity]]\n\n## [[p.provokedThoughts]]\n\n- theoretically, in-game characters don't know of the [[t.roleplaying.oog]] world, but that can be seen as a challenge of authentic acting","n":0.174}}},{"i":891,"$":{"0":{"v":"GM","n":1}}},{"i":892,"$":{"0":{"v":"Role-Playing Games","n":0.707}}},{"i":893,"$":{"0":{"v":"Freeform Roleplaying","n":0.707},"1":{"v":"\n- similar: [[t.storytelling.collaborative]]\n- kids do it naturally\n- related: [[vs.narrativist-vs-gamist-vs-simulationist]]\n\n## Testimony\n\n- \"I ran a game like this for a year or so. It's fun, but it removes a lot of the credibility that a system adds. A system lets players form expectations based on their understanding of the mechanics, which opens up emotions like dread and hope. I also find that players believing that the world runs on rules that aren't entirely in the DM's control leads to more investment in characters and outcomes.\"\n  - https://www.reddit.com/r/rpg/comments/r5et2b/comment/hmmoo8c/\n","n":0.108}}},{"i":894,"$":{"0":{"v":"Dynamic World","n":0.707},"1":{"v":"\n- in most campaigns, the temporal flow is focused on the players. If the players aren't interacting with a character or setting, usually there's not much going on. \n- in a more realistic / complex world, things are happening all the time","n":0.154}}},{"i":895,"$":{"0":{"v":"Conventions","n":1},"1":{"v":"\n## Resources\n\n### Resource Lists\n\n- https://www.reddit.com/r/rpg/wiki/con/\n\n## References\n\n- ","n":0.408}}},{"i":896,"$":{"0":{"v":"Computer-Assisted Role-Play (CARP)","n":0.577},"1":{"v":"\n## Examples of Role-Play\n\n- movies and tv should be considered a type of (highly-directed, highly-scripted) roleplay.\n- improv theater\n- certain kinds of job training\n- a psychotherapeutical technique\n\n## Solutions\n\n### Virtual Tabletops\n\n- ","n":0.186}}},{"i":897,"$":{"0":{"v":"Clan","n":1},"1":{"v":"\n#aka faction, guild, community\n- ","n":0.5}}},{"i":898,"$":{"0":{"v":"Character","n":1}}},{"i":899,"$":{"0":{"v":"Character Sheet","n":0.707}}},{"i":900,"$":{"0":{"v":"Character Management","n":0.707}}},{"i":901,"$":{"0":{"v":"Campaign","n":1}}},{"i":902,"$":{"0":{"v":"Campaign Management","n":0.707}}},{"i":903,"$":{"0":{"v":"Project Management","n":0.707}}},{"i":904,"$":{"0":{"v":"Product Management","n":0.707},"1":{"v":"\n\n## Product Ideas\n\n- a [[t.pdm.user-problem]], an [[t.pdm.opportunity]] or a [[t.pdm.solution]]\n  - [[p.hasSource]] https://support.atlassian.com/jira-product-discovery/docs/what-is-an-idea/\n\n\n- > [Product ideas] are fragile. If they were resolved, they would not be ideas, they would be products. It takes determined effort not to be consumed by the problems of a new idea. Problems are easy to articulate and understand, and they take the oxygen. Steve focused on the actual ideas, however partial and unlikely.\n  >\n  > @jony-ive, https://www.wsj.com/articles/jony-ive-steve-jobs-memories-10th-anniversary-11633354769 \n\n## Terminology\n\n> - An **attribute** is used to describe the characteristics or properties of something.\n> - A **feature** is often described as a prominent attribute.\n> -   **function** is what something does.\n> - **Form** is the external experience or shape.\n> - **Design** involves all the above.\n> - **Meaning** involves all the above plus the relationship of the product or service to emotional and psychosocial needs.\n- [[p.hasSource]] https://saylordotorg.github.io/text_developing-new-products-and-services/s10-conceptualizing-products-servi.html\n\n### Product Goal\n\n- big picture, important\n- [represent the crucial accomplishments needed to make your vision a reality.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiu_9vj5q30AhVlHzQIHYtFDGMQFnoECAIQAQ&url=https%3A%2F%2Fwww.aha.io%2Froadmapping%2Fguide%2Fproduct-strategy%2Fwhat-are-product-goals-and-initiatives&usg=AOvVaw0xcI-j6qTYyzgoEv_qlZTw)\n\n### Requirements\n\n- resources:  https://www.agilebusiness.org/page/ProjectFramework_15_RequirementsandUserStories\n\n### User Stories\n\n![[User Stories|t.pdm.user-stories]]\n\n### Story Maps\n\n- resources:  https://www.altexsoft.com/blog/uxdesign/a-complete-guide-to-user-story-mapping-process-tips-advantages-and-use-cases-in-product-management/\n- [[p.attributedTo]] [Jeff Patton](https://www.scrumalliance.org/community/profile/jpatton)\n- [[p.hasElements]]\n  - Items are arranged in two dimensions\n    - ![](/assets/images/2021-11-23-21-54-51.png)\n    - Backbone. epics/themes are the basis of the map.\n    - Stories: arranged in both vertical and horizontal dimensions. User stories are grouped under corresponding epics, describing more specific tasks a user may require. If an epic describes a search phase, it may include stories like basic search, filtering products, advanced search, etc. When stories are prioritized vertically, they can be divided into releases.\n  - User Personas\n  - Ideas and Nice-to-haves\n- [[p.hasPro]]\n  - Built-in user journey.\n    - although, imagine a 3d visualization overlapping user journeys and their interaction points. \n\n## Resources\n\n- https://www.productplan.com/glossary","n":0.061}}},{"i":905,"$":{"0":{"v":"UX","n":1}}},{"i":906,"$":{"0":{"v":"Prototyping","n":1}}},{"i":907,"$":{"0":{"v":"vendor lock-in","n":0.707}}},{"i":908,"$":{"0":{"v":"User Stories","n":0.707},"1":{"v":"\n\n\n- requirements expressed from the perspective of the user\n- should be INVEST \n  - i.e.\n    -  independent\n    -  negotiable\n    -  valuable\n    -  estimable\n    -  small\n    -  testable\n  -  [[p.attributedTo]] @bill-wake\n","n":0.183}}},{"i":909,"$":{"0":{"v":"User Problem","n":0.707},"1":{"v":"\n#product-management\n\n- a challenge that [[t.pdm.solution]]s can be applied to\n- [[p.comparableTo]] [[t.pdm.desire]]\n- [[p.equivalentClass]] [[c.problem]]\n","n":0.277}}},{"i":910,"$":{"0":{"v":"Use Cases","n":0.707},"1":{"v":"\n- [[p.hadDefinition]] \"a scenario showing how a product’s user might interact with the product to achieve a specific goal.\"\n  - [[p.hasSource]] https://www.productplan.com/glossary/use-case/","n":0.213}}},{"i":911,"$":{"0":{"v":"Story Mapping","n":0.707},"1":{"v":"\n\n\n## References\n\nhttps://www.nimblework.com/agile/story-mapping/","n":0.707}}},{"i":912,"$":{"0":{"v":"Solution","n":1},"1":{"v":"\n#product-management\n\n- [[p.correspondsTo]] [[c.solution]]\n- [[p.equivalentClass]] [[c.solution]]\n","n":0.447}}},{"i":913,"$":{"0":{"v":"Session Replay","n":0.707}}},{"i":914,"$":{"0":{"v":"PRD","n":1}}},{"i":915,"$":{"0":{"v":"Opportunity","n":1}}},{"i":916,"$":{"0":{"v":"Feature","n":1}}},{"i":917,"$":{"0":{"v":"Feature-Benefit Matrix","n":0.707},"1":{"v":"\n\n\n- [[p.isRelated]] \n  - [[t.mktg]]\n  - [[t.pdm.feature]]\n- [[p.hasExample]]\n  - ![](/assets/images/2022-04-15-18-03-44.png)\n    - [[p.hasSource]]https://www.scaledagileframework.com/features-and-capabilities/\n\n\n## Resources\n\n- https://www.wordstream.com/blog/ws/2017/02/21/features-vs-benefits\n- https://blog.servify.tech/posts/product-feature-benefit-matrix/\n\n","n":0.258}}},{"i":918,"$":{"0":{"v":"Desire","n":1},"1":{"v":"\n#product-management\n\n- not everything is a problem; or rather, problem doesn't have the right connotations for every place where you could apply a solution, capability, etc.\n","n":0.2}}},{"i":919,"$":{"0":{"v":"Product Design","n":0.707},"1":{"v":"\n- resources:  https://www.productplan.com/glossary/product-design/","n":0.577}}},{"i":920,"$":{"0":{"v":"Visual","n":1}}},{"i":921,"$":{"0":{"v":"Double Diamond","n":0.707},"1":{"v":"\n![](/assets/images/2023-01-11-10-14-40.png)","n":1}}},{"i":922,"$":{"0":{"v":"Data Lock-In","n":0.707},"1":{"v":"\n[[c.problem]]\n\n- it's not effective your data if you can extract it from its host","n":0.267}}},{"i":923,"$":{"0":{"v":"Capability","n":1},"1":{"v":"\n## [[p.hadDefinition]]\n\n- \"Capabilities are different from features and benefits as they’re the intermediary that connects a feature to the benefit. Capabilities help customers understand how a product’s features are beneficial. The best way to define a capability is to answer the question “what does this product allow me to do? Capabilities are different from [[benefits|t.pdm.benefit]]. Benefits are emotions and feelings while capabilities are tasks or actions. Understanding the difference is key because when users seek a solution to their problem, they tend to focus on a task or capability that they want. If product development narrows its attention to only features and benefits, customers may fail to identify the connection between a product and what they need to accomplish.\"\n  - [[p.hasSource]] https://challengingcoder.com/product-features-and-capablity/\n- \"Capabilities behave the same way as features. However, they are at a higher level of abstraction and support the definition and development of large Solutions\"\n\n","n":0.082}}},{"i":924,"$":{"0":{"v":"Benefit","n":1},"1":{"v":"\n## [[p.hadDefinition]]\n\n- \"Advantages explain the significance of a feature and how it solves a problem, often in a factual, concrete, or measurable way. Benefits, on the other hand, are subjective and appeal to the emotions or pains of the prospect.\"\n  - https://blog.hubspot.com/sales/how-to-sell-benefits-not-features","n":0.154}}},{"i":925,"$":{"0":{"v":"Analytics","n":1}}},{"i":926,"$":{"0":{"v":"Negotiation","n":1},"1":{"v":"\n\n\n## Resources\n\n- https://www.indeed.com/career-advice/career-development/types-of-negotiation\n","n":0.577}}},{"i":927,"$":{"0":{"v":"Music","n":1}}},{"i":928,"$":{"0":{"v":"Lo-Fi Music","n":0.707}}},{"i":929,"$":{"0":{"v":"Multiverse (Cultural)","n":0.707},"1":{"v":"\n- related: [[superwork]] [[t.storytelling.alternate-reality]]\n\n## **Multiverse (cultural)**\n\nA conceptual collection of all our created realities, including ones created in the [[t.cs.metaverse]], literature, film, and video games. Each universe within the multiverse can have different timelines. ^7qcsvcwota9i\n\n## Definitions\n\n- a collection of all the different imagined, artistic, and narrative realities that arise from human creativity across cultures\n- encompass literature, film, games, folklore, and even virtual worlds\n- By focusing on culture, it emphasizes the diverse ways societies and groups create and interact with their own unique worlds\n\n## Thoughts\n\n- the physical world (obviously), plus all the worlds in our heads, books, games, and other creative works\n  - i.e., cultural and mental realities\n\n## References\n\n- [[vs.metaverse-vs-multiverse]]","n":0.096}}},{"i":930,"$":{"0":{"v":"Marketing","n":1},"1":{"v":"\r\nYou can't help people if you don't get out the message.\r\n","n":0.302}}},{"i":931,"$":{"0":{"v":"Partner Marketing","n":0.707}}},{"i":932,"$":{"0":{"v":"Mascots","n":1}}},{"i":933,"$":{"0":{"v":"MAID","n":1}}},{"i":934,"$":{"0":{"v":"Dsp","n":1},"1":{"v":"\n-  allows an advertiser to buy advertising with the help of automation; maximizes the efficiency of every impression\n\n## [[c.process]]\n\nFirst, the advertiser uploads creative, sets up targeting and puts down a budget for their campaigns. This can all be done via the dashboard. Once the campaign creative is uploaded, the DSP scours through its network of publishers for sites and mobile apps that fit the advertiser’s criteria and makes a bid for placement. After this, the DSP resolves the bid, places the ad, and manages payment – all in a matter of milliseconds.","n":0.104}}},{"i":935,"$":{"0":{"v":"data management platform","n":0.577},"1":{"v":"\nA data management platform (DMP) collects, organizes, and activates first-, second-, and third-party audience data\n\n","n":0.258}}},{"i":936,"$":{"0":{"v":"Deal Id","n":0.707}}},{"i":937,"$":{"0":{"v":"Co-Marketing","n":1},"1":{"v":"\n\n- working with your partners to market together","n":0.354}}},{"i":938,"$":{"0":{"v":"Buying Signals","n":0.707},"1":{"v":"![](/assets/images/2022-11-02-12-42-34.png)","n":1}}},{"i":939,"$":{"0":{"v":"ABM","n":1}}},{"i":940,"$":{"0":{"v":"Math","n":1}}},{"i":941,"$":{"0":{"v":"Quaternion","n":1},"1":{"v":"\n\n## References\n\n- https://www.3dgep.com/understanding-quaternions/","n":0.577}}},{"i":942,"$":{"0":{"v":"Geometry","n":1},"1":{"v":"\n## Resources\n\n- [Geonotations Survival Guide](http://www.gaia-gis.it/gaia-sins/GeoNotations.pdf)","n":0.447}}},{"i":943,"$":{"0":{"v":"Voronoi Diagram","n":0.707},"1":{"v":"\n![](/assets/images/2023-01-09-08-38-06.png)","n":1}}},{"i":944,"$":{"0":{"v":"Taxicab Geometry","n":0.707},"1":{"v":"\n#aka Manhattan geometry\n","n":0.577}}},{"i":945,"$":{"0":{"v":"Delaunay Triangulation","n":0.707},"1":{"v":"\n## [[p.hasLearningResource]]\n\n- https://observablehq.com/@mbostock/the-delaunays-dual","n":0.577}}},{"i":946,"$":{"0":{"v":"Chebyshev Distance","n":0.707},"1":{"v":"\n- aka: maximum metric\n- ","n":0.5}}},{"i":947,"$":{"0":{"v":"Ling","n":1}}},{"i":948,"$":{"0":{"v":"Nlp","n":1}}},{"i":949,"$":{"0":{"v":"Argumentation Mining","n":0.707},"1":{"v":"\n## Resources\n\n- https://direct.mit.edu/coli/article/45/4/765/93362/Argument-Mining-A-Survey\n  - [[p.mentioned]] \n    - [[t.ling.conversation-graph]]\n    - [[prdct.fipa.acl]] (has typo, \"coordination language\")\n","n":0.267}}},{"i":950,"$":{"0":{"v":"Latin","n":1}}},{"i":951,"$":{"0":{"v":"Carpe Diem","n":0.707},"1":{"v":"\n- taken from Roman poet Horace’s Odes, written over 2,000 years ago.\n\n\n## References\n\n- https://medium.com/the-cellar-door/carpe-diem-doesnt-mean-seize-the-day-770fbf63a820\n- https://daily.jstor.org/how-carpe-diem-got-lost-in-translation/\n- https://medium.com/fourth-wave/carpe-diem-is-not-go-crazy-c5800d7d34eb\n- ","n":0.25}}},{"i":952,"$":{"0":{"v":"Tense","n":1},"1":{"v":"\n## Definitions\n\n### Standard Tense\n\n- in English, the present\n- \n\n## Verb Forms vs Verb Tense\n\nchatgpt4.o:\n\n- \"Verb forms\" and \"verb tense\" are related concepts but serve different roles in grammar:\n\n### Verb Forms\n\"Verb forms\" refer to the various versions a verb can take depending on the context, function, or grammar requirement. They include:\n\n1. **Base Form**: The simple form of the verb without any endings (e.g., *run*, *write*).\n2. **Past Form**: Used for past actions, often ending in \"-ed\" for regular verbs (e.g., *ran*, *wrote*).\n3. **Past Participle**: Used in perfect tenses or passive voice, usually the same as the past form for regular verbs, but different for irregular verbs (e.g., *run* -> *run*, *write* -> *written*).\n4. **Present Participle (Gerund)**: The \"-ing\" form of the verb, used for continuous tenses or as a gerund (e.g., *running*, *writing*).\n5. **Third Person Singular Form**: The form of the verb used with \"he, she, it\" in the present tense, often ending in \"-s\" (e.g., *runs*, *writes*).\n\n### Verb Tense\n\"Verb tense\" refers to the time an action takes place—past, present, or future. It provides temporal context to an action or state and can also indicate continuity or completion. Common verb tenses include:\n\n1. **Simple Tenses**:\n   - **Present Simple**: Describes general truths or habitual actions (e.g., *She writes*).\n   - **Past Simple**: Describes completed actions in the past (e.g., *She wrote*).\n   - **Future Simple**: Describes actions that will happen in the future (e.g., *She will write*).\n\n2. **Continuous (Progressive) Tenses**:\n   - **Present Continuous**: Describes ongoing actions in the present (e.g., *She is writing*).\n   - **Past Continuous**: Describes ongoing actions in the past (e.g., *She was writing*).\n   - **Future Continuous**: Describes actions that will be ongoing in the future (e.g., *She will be writing*).\n\n3. **Perfect Tenses**:\n   - **Present Perfect**: Describes actions that occurred at an unspecified time or have relevance to the present (e.g., *She has written*).\n   - **Past Perfect**: Describes actions completed before a certain point in the past (e.g., *She had written*).\n   - **Future Perfect**: Describes actions that will be completed by a certain point in the future (e.g., *She will have written*).\n\n4. **Perfect Continuous Tenses**:\n   - **Present Perfect Continuous**: Describes actions that began in the past and are still ongoing or have recently finished (e.g., *She has been writing*).\n   - **Past Perfect Continuous**: Describes ongoing actions that were happening before a point in the past (e.g., *She had been writing*).\n   - **Future Perfect Continuous**: Describes actions that will be ongoing up until a certain point in the future (e.g., *She will have been writing*).\n\n**Summary**:\n- **Verb Forms** describe the structure of the verb itself, like its base, participles, and conjugations.\n- **Verb Tenses** describe the timing and type of action, providing context for when something happens. \n\nThe forms are used to create the various tenses and other grammatical structures in a language.\n\n\n## References\n\n- https://www.grammarly.com/blog/parts-of-speech/verb-tenses/","n":0.047}}},{"i":953,"$":{"0":{"v":"Syntax","n":1}}},{"i":954,"$":{"0":{"v":"Syntactic Annotation","n":0.707},"1":{"v":"\n## Resources\n\n- https://www.ling.upenn.edu/hist-corpora/annotation/syn-intro.htm\n- ","n":0.577}}},{"i":955,"$":{"0":{"v":"Speech Act","n":0.707},"1":{"v":"\n## description:\n\n- \"Whereas an act of speech is any act of uttering meaningful words... speech acts are those acts that can (though need not) be performed by saying that one is doing so.\"\n  - https://plato.stanford.edu/entries/speech-acts/","n":0.169}}},{"i":956,"$":{"0":{"v":"Semantic Property","n":0.707},"1":{"v":"\n\n\n- Semantic properties or meaning properties are those aspects of a linguistic unit, such as a morpheme, word, or sentence, that contribute to the meaning of that unit. Basic semantic properties include being meaningful or meaningless – for example, whether a given word is part of a language's lexicon with a generally understood meaning; polysemy, having multiple, typically related, meanings; ambiguity, having meanings which aren't necessarily related; and anomaly, where the elements of a unit are semantically incompatible with each other, although possibly grammatically sound. Beyond the expression itself, there are higher-level semantic relations that describe the relationship between units: these include synonymy, antonymy, and hyponymy.\nBesides basic properties of semantics, semantic property is also sometimes used to describe the semantic components of a word, such as man assuming that the referent is human, male, and adult, or female being a common component of girl, woman, and actress. In this sense, semantic properties are used to define the semantic field of a word or set of words.\n  - [[p.hasSource]] wikipedia, https://artsandculture.google.com/entity/semantic-property/m0c896?hl=en\n","n":0.077}}},{"i":957,"$":{"0":{"v":"Reduplication","n":1},"1":{"v":"\n- a morphological process in which the root or stem of a word (or part of it) or even the whole word is repeated exactly or with a slight change.","n":0.183}}},{"i":958,"$":{"0":{"v":"Prose","n":1}}},{"i":959,"$":{"0":{"v":"Paralinguistic Features","n":0.707},"1":{"v":"\n- [[c.example]]  ^498lymlvqisb\n  - facial expressions, laughter, eye contact, gestures\n  - metadata?\n  - prosodic: pitch, intonation and stress; loudness, timbre, speech rate, pauses\n-  did they fix it","n":0.192}}},{"i":960,"$":{"0":{"v":"Grammar","n":1}}},{"i":961,"$":{"0":{"v":"Verb","n":1},"1":{"v":"\n\n\n- [[p.hasType]]\n  - multi-word verbs\n    - [[p.hasType]]\n      - phrasal verbs (main verb + adverb particle)\n        - often have meanings which we cannot easily guess from their individual parts\n        - object can come before or after the particle if the object is not a pronoun\n      - prepositional verbs\n        - an idiomatic expression that combines a verb and a preposition to make a new verb with a distinct meaning\n        - always have an object\n      - phrasal-prepositional verbs\n        - e.g.\n          - catch up with\n          - come up against\n  - “Implicit object” (IO) is a name for what happens when a verb we normally consider transitive appears without an object:\"\n    - [[p.hasSource]] https://repository.upenn.edu/cgi/viewcontent.cgi?article=1715&context=pwpl\n    - \"often argued that the IO needs to be recoverable from the context\" but clearly not. \n    - \"recoverability is a matter of degree. At a minimum, one simply knows that an object exists; at a maximum, one knows exactly what it is; and there is plenty of middle ground in between.\"\n    - \"manner verbs from result verbs and propose that result verbs\ndo not allow IOs.\" \n      - [[p.hasSource]] Rappaport Hovav and Levin (1998); Rappaport Hovav (2008)\n      - but whether IOs are allowed isn't easy to distinguish\n\n## [[p.begsQuestion]]\n\n- > \"What's the precisest term for verbs that belong to the same stem without any affixes?\"\n  - [[p.hasAnswers]]\n    - verb form\n    - Inflected forms (singular/ plural or present/ past tense) ~~or derived forms (using affixes to make new words)~~\n    - paradigm or declension\n      - \" For the English verb 'walk', the paradigm consists of 'walk', 'walks', 'walking', and 'walked'\"\n  - [[p.hasSource]] https://linguistics.stackexchange.com/questions/36305/whats-the-precisest-term-for-verbs-that-belong-to-the-same-stem-without-any-aff/36462#36462\n\n## Mood\n\nWe recognize three or four Moods in verbs:\n\n- **Indicative** is a statement: I walk quickly.\n- **Imperative** is a command: Walk to the store! \n  - (arguably part of subjunctive)\n    - [[p.hasSource]] https://www.kaptest.com/study/gmat/gmat-verbal-subjunctive/\n- **Subjunctive** is a prediction or possibility. In modern English we need to use a modal to indicate a subjunctive: I might walk to the store later. I could walk to the store.\n- **Infinitive** is formed from a verb but acts as a noun, adjective or adverb; \n  - might not be a mood\n    - [[p.hasSource]] https://www.quora.com/What-are-the-meanings-of-infinitive-indicative-subjunctive-and-imperative-in-grammar\n","n":0.054}}},{"i":962,"$":{"0":{"v":"Verb Phrase","n":0.707},"1":{"v":"\n\n\n## Resources\n- https://owl.purdue.edu/owl/general_writing/mechanics/gerunds_participles_and_infinitives/infinitives.html\n- https://linguisticsgirl.com/verb-phrase-complement-english-grammar/\n","n":0.5}}},{"i":963,"$":{"0":{"v":"Tree Adjoining Grammar","n":0.577},"1":{"v":"\n- #aka TAG\n\n## Features\n\n- \"Tree-adjoining grammars are more powerful (in terms of weak generative capacity) than context-free grammars, but less powerful than linear context-free rewriting systems,[7] indexed[note 1] or context-sensitive grammars.\" \n\n\n## Resources\n\n- https://github.com/topics/tree-adjoining-grammar","n":0.171}}},{"i":964,"$":{"0":{"v":"Theta Theory","n":0.707},"1":{"v":"\n- Theta theory addresses the specific semantic relationships between a verb and its arguments. Verbs assign thematic roles (theta roles) to each NP that is obligatory (must be included in the verb phrase). Theta theory requires that theta criterion be fulfilled in order for a verb to used grammatically.","n":0.143}}},{"i":965,"$":{"0":{"v":"Thematic Roles","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://www.linguisticsnetwork.com/semantics-thematic-roles/ has a [[c.example.bad]]:\n  - \"You can't say: 'the ball hit the child'\"\n    - you can! it might be a slightly different sense of hit\n- http://www.sfu.ca/~hedberg/Thematic_Roles.pdf\n  - \"Possible Universal Subject Hierarchy: – AGENT > RECIPIENT/BENEFICIARY > THEME/PATIENT > INSTRUMENT > LOCATION\"\n- https://www.ling.upenn.edu/~beatrice/syntax-textbook/box-thematic.html\n\n## Related Topics\n\n- [[t.ling.grammar.theta-theory]]\n\n## References\n\n- [[book.speech-and-language-processing]]","n":0.143}}},{"i":966,"$":{"0":{"v":"Subject","n":1},"1":{"v":"\n- the thing about which a statement is made","n":0.333}}},{"i":967,"$":{"0":{"v":"Complement","n":1},"1":{"v":"\n- #definition follows a linking verb to describe or rename the subject","n":0.289}}},{"i":968,"$":{"0":{"v":"Prepositions","n":1},"1":{"v":"\n## [[p.hasSubClass]]\n\n- [[p.hasSource]] https://onlymyenglish.com/types-of-preposition/\n  - Simple Preposition\n  - Compound Preposition.\n  - Double Preposition.\n  - Disguised Preposition.\n  - Phrasal Preposition.\n  - Participle Preposition.\n  - Detached Preposition\n  - Appropriate Preposition\n\n- [Some of the most common prepositions that begin prepositional phrases are to, of, about, at, before, after, by, behind, during, for, from, in, over, under, and with.][1]\n\n## Resources\n\n- [1]: https://www.grammarly.com/blog/prepositional-phrase/\n- http://www.lel.ed.ac.uk/~packema/teaching/msc-syntax/MSc%20Syntax%20lecture%203.pdf\n  - [-] Let us call the constituents that appear in the subject, direct object, and indirect object\npositions the syntactic arguments of the verb – to be distinguished from the semantic\narguments as discussed above. Thus, the syntactic valency of a verb is the property\nthat determines how many syntactic arguments the verb takes, as opposed to the\nsemantic valency of a predicate, which says how many semantic arguments the\npredicate takes","n":0.089}}},{"i":969,"$":{"0":{"v":"Prepositional Phrase","n":0.707}}},{"i":970,"$":{"0":{"v":"Predicate","n":1},"1":{"v":"\n- Predicates can be one verb or verb phrase (simple predicate), two or more verbs joined with a conjunction (compound predicate), or even all the words in the sentence that give more information about the subject (complete predicate)\n  - [[p.hasSource]] https://grammar.yourdictionary.com/sentences/what/what-is-a-predicate.html\n\n\n## [[c.question]]\n\n- [-] Is a simple predicate still a relation? I've seen where people say that a unary relation is basically a reflexive/recursive relationship, like \"i slapped myself\", as opposed to a property like, \"i slept\".\n\n## Ideas\n\n- predicate arguments can have [[t.ling.grammar.thematic-roles]]\n- https://www.ling.upenn.edu/~beatrice/syntax-textbook/box-thematic.html\n  - It is often convenient to identify arguments of (Fregean) predicates in terms of the following **thematic roles,** which are illustrated below. ^ft4hys2l0uwp\n\n    agent\n    cause\n    instrument\n    experiencer\n    recipient\n    location\n    path\n    goal\n    measure\n    theme ","n":0.093}}},{"i":971,"$":{"0":{"v":"Particle","n":1},"1":{"v":"\n\n\n-  function word associated with another word or phrase to impart meaning \n-  are typically words that encode grammatical categories (such as negation, mood, tense, or case), [[clitic|t.ling.grammar.clitic]], or fillers or (oral) discourse markers\n","n":0.171}}},{"i":972,"$":{"0":{"v":"Object","n":1}}},{"i":973,"$":{"0":{"v":"Direct","n":1},"1":{"v":"\n- [[p.hasExample]]\n  - \"You forgave me my mistake\"\n    - https://www.britannica.com/dictionary/eb/qa/Direct-and-Indirect-Objects\n      - [[p.argues]] that \"my mistake\" is direct, and that it's being forgiven _for_ me\n      - @dave [[p.thought]] it could go either way","n":0.177}}},{"i":974,"$":{"0":{"v":"Noun","n":1},"1":{"v":"\n\n- abstract or concrete\n","n":0.5}}},{"i":975,"$":{"0":{"v":"Nominal","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] Substantive\n- [\"The updated term for substantive is nominal, and it applies to any noun or pronoun or any word, phrase, or clause that performs the same function as a noun\"][1]\n\n## Resources\n\n- http://guidetogrammar.org/grammar/objects.htm\n- [1]: https://www.thoughtco.com/substantive-grammar-1692157\n","n":0.167}}},{"i":976,"$":{"0":{"v":"Grammatical Mood","n":0.707}}},{"i":977,"$":{"0":{"v":"Linking Verb","n":0.707},"1":{"v":"\n## eg\n\n- to be / was\n- sense verbs\n  - looked, but not lookedAt or lookedFor\n  - felt \n  - smelled\n  - tasted\n\n## Description\n\n- https://www.grammar-monster.com/glossary/linking_verbs.htm","n":0.204}}},{"i":978,"$":{"0":{"v":"Head-driven Phase Structure Grammar","n":0.5}}},{"i":979,"$":{"0":{"v":"Context Free  Grammar","n":0.577}}},{"i":980,"$":{"0":{"v":"Conjunction","n":1}}},{"i":981,"$":{"0":{"v":"Clitic","n":1}}},{"i":982,"$":{"0":{"v":"Deictics","n":1},"1":{"v":"\nA deictic expression or deixis is a word or phrase (such as this, that, these, those, now, then, here) that points to the time, place, or situation in which a speaker is speaking. Deixis is expressed in English by way of personal pronouns, demonstratives, adverbs, and tense.","n":0.146}}},{"i":983,"$":{"0":{"v":"Conversation Graph","n":0.707},"1":{"v":"\n![](/assets/images/2023-05-02-21-10-06.png)","n":1}}},{"i":984,"$":{"0":{"v":"Computational Linguistics","n":0.707},"1":{"v":"\n\n\n- [[p.hasCommunity]] [[community.acl]]\n","n":0.577}}},{"i":985,"$":{"0":{"v":"Library Science","n":0.707}}},{"i":986,"$":{"0":{"v":"Work, Expression, Manifestation, Item","n":0.5},"1":{"v":"\n- implementations: [[prdct.frbr-core]] [[prdct.fabio]] [[prdct.functional-requirements-for-information-resources-frir]] [[prdct.anglo-american-cataloguing-rules-aacr2]] [[prdct.resource-description-and-access-rda]]\n\n![](/assets/images/2024-08-22-09-39-54.png)\n\n## Terms\n\n### Endeavor\n\n- a super-class created by [[prdct.openwemi]] to encompass all the layers/planes\n- might better be called a \"creation\", as endeavor (imho) could include trying to shower more often\n\n### Superwork\n\n- \"works and their instantiations cluster in metaphorical constellations, having orbital and therefore gravitational relationship to each other, and that there are different sorts of celestial bodies in the bibliographical universe. These “constellations” are groupings of instantiations of works — not only the progenitor work itself, but also its editions, translations, abridgments, adaptations, excerpts, etc., and their instantiations as well. These have been termed variously “bibliographic families” (Wilson [1978]), “superworks” (Svenonius 2001), “textual identity networks” (Leazer and Furner 1999), and “instantiation networks” (Smiraglia 2008).\" [^2]\n\n### Work\n\n- the essence of a creation, such as a novel, a symphony, a painting, a statue, a thesis\n- analagous to Platonic Form\n- have two properties:\n  - ideational content\n    - changes are called mutations\n  - semantic content\n    - changes are called derivations\n- The main purpose of this class is to enable bringing together intellectually equivalent Expressions in order to display to a user all available alternatives of the same intellectual or artistic content.\n- A Work is the outcome of an intellectual process of one or more persons. \n- Inherent to the notion of work is the existence of recognisable realizations of the work in the form of one or more expressions. \n  - Works are often regarded as finished and discrete e.g. when declared as such by the creator of the work or based on the elaboration or logical coherence of its content. \n  - However, works may be recognized as existing but unfinished e.g. if the creators deliberately or accidentally never explicitly finished a particular Expression but have left behind partial expressions.\n  - In the absence of explicit information about the initial conception, which is rarely available, the first expression created constitutes witness of the beginning of existence of a Work.\n\n### Expression\n\n- realisations of Works in the form of identifiable immaterial objects, such as texts, poems, jokes, musical or choreographic notations, movement pattern, sound pattern, images, multimedia objects, or any combination of such forms. \n- The substance of F2 Expression is signs\n- Expressions do not depend on a specific physical carrier and can exist on one or more carriers simultaneously. \n  - As far as bibliographic practice is concerned, only instances of F2 Expression that are externalised on physical carriers other than both the creator's brain and an auditor's brain are taken into account.\n- Differences in form imply different Expressions (e.g., from text to spoken word, a transcript of a recording)\n- Similarly, differences in language or means of performance imply different Expressions\n- if a text is revised or modified, the result is considered to be a new F2 Expression\n- While theoretically any change in signs will result in a new Expression, conventionally the context and use will determine the rules for distinguishing among expressions.\n- \"There are many ways a work can be expressed, and it can be difficult to determine what constitutes a separate expression, and what is a new work entirely; cataloger judgment is required. In general, translations, revisions, versions, illustrated editions, abridgements, and illustrated editions would be considered unique expressions of the same work.\" [^1]\n- In D&D, each edition has its own expression of spells, items, classes, etc.\n- In-world, each setting? has its own version of these thing? Or each ruleset.\n- \"Most works will have only one or two expressions—a text version and a spoken word version, say—but a great classic like Pride and Prejudice is likely to have many expressions.\"\n\n### Manifestation\n\n- comprises products rendering one or more Expressions\n- A Manifestation is defined by both the overall content and the form of its presentation. \n- The substance of F3 Manifestation is not only signs, but also the manner in which they are presented to be consumed by users, including the kind of media adopted.\n- An F3 Manifestation is the outcome of a publication process where one or more F2 Expressions are prepared for public dissemination, but it may also be a unique form created directly on some material carrier without the intent of being formally published.\n- Manifestation can be identified by the physical features for the medium of distribution, if applicable.\n- In the case of industrial products such as printed books or music CDs, but also digital material, an instance of F3 Manifestation can be regarded as the prototype for all copies of it.\n- An instance of F5 Item that consists of a physical object or set of objects with clear physical boundaries is also an instance of E22 Human-Made Object. An instance of F5 Item that is stored on a part of a larger physical support (such as an electronic file among others on a disc) can also be considered to be an instance of E25 Human-Made Feature.\n- The notion of F5 Item is only relevant with regard to the production process, from a bibliographic point of view. The physical units managed by cultural heritage institutions in their holdings are a distinct notion: a unit of holdings certainly can be equal to an instance of F5 Item, but it also can be either 'biggerâ€ than one (e.g., when two instances of F5 Item are bound together (in the case of printed books)), or 'smaller' than one (e.g., for incomplete holdings, such as when only one CD from a two-CD set is held).\n- \"A single expression may have many manifestations, especially if (as with Pride and Prejudice) the book is frequently reprinted.\"\n- In D&D, could a manifestation be [[prdct.roll20]]'s version of a thing vs [[prdct.one_dnd]]? That's oow\n  - t.2024.08.21.11 \n    - yes, as long as all the (observable) symbols are the same?\n    - no, since the underlying representation are probably different?\n    - might depend on what \"thing\" is. But if it's a spell, as opposed to a spell-casting interface, I'm leaning to yes\n  - t.2024.08.21.12\n    - ~[[ar.functional-requirements-for-information-resource-provenance-on-the-web#^w1t3fxtaiozl]]\n- in-world, \n  - in a place without mass-production, unique items have a single manifestation. But perhaps in a bespoke workshop, a certain well-honed process could lead to a manifestation of an object with multiple corresponding items? \n  - or maybe groups of things that don't have distinct identities \n\n### Item\n\n## Issues\n\n- 'Despite initial positive assessments of FRBR clarifying the thoughts around the conceptual underpinnings of works, there has been later disagreement about what the Group 1 entities actually mean.[[5]](https://en.wikipedia.org/wiki/Functional_Requirements_for_Bibliographic_Records#cite_note-5) The distinction between Works and Expressions is also unclear in many cases.'\n- [[Resources That Refer Vs Resources That Are|vs.resources-that-refer-vs-resources-that-are]]\n- [[idea.instances-are-sometimes-classes]]\n- a group of concrete things: set of items? or manifestation\n  - t.2024.08.21.12 set of items\n- the relationships between the WEMI entities are disjoint from each other and are fixed in order. Being disjoint, the entities cannot share data elements if RDF reasoning will be applied. \n  - This is mainly a problem with sharing between metadata schemas that have distributed their data elements differently, such as the BIBFRAME three-level model and the Resource Description and Access (RDA) adherence to the four-level models of FRBR or LRM.(Baker, 2014) \n  - In the FRBR model all intervening entities are required: the only route from the manifestation to the work is through the link between manifestation and expression and between expression and work. (Shotton, 2019) The relationships are therefore immutable and all “higher” entities must be present for a “lower” entity to be described.\n\n\n## References\n\n[^1]: https://rdabasics.com/2012/08/24/theoretical-foundations/\n[^2]: [[ar.isko.work]]\n\n- https://cidoc-crm.org/extensions/lrmoo/owl/1.0/LRMoo_v1.0.owl\n- [[ar.reconceptualizing-superwork-for-improved-access-to-popular-cultural-objects]]\n- [[ar.works-expressions-manifestations-items-an-ontology]]","n":0.029}}},{"i":987,"$":{"0":{"v":"Superwork","n":1},"1":{"v":"\n## Definition\n\n- an overarching collection that includes or is related to multiple individual works\n\n## Thoughts\n\n- often have a single [[t.storytelling.setting]], but on the fringes, can cross into/merge other settings\n","n":0.186}}},{"i":988,"$":{"0":{"v":"Law","n":1}}},{"i":989,"$":{"0":{"v":"Trademarks","n":1},"1":{"v":"\n## Compatibility with Open-Source Licenses\n\n- Trademark enforcement is not inconsistent with open source principles: it restricts how a brand identifier can be used, rather than restricting what you can do with the open source code.\n\n## References\n\n- https://google.github.io/opencasebook/trademarks/","n":0.164}}},{"i":990,"$":{"0":{"v":"Knowledge Management","n":0.707},"1":{"v":"\nTurning thoughts into understanding and wisdom\n","n":0.408}}},{"i":991,"$":{"0":{"v":"Zettelkasten","n":1},"1":{"v":"\n## [[p.vs]]\n\n### [[t.tm.getting-things-done]]\n\n- zk supports writing and open-ended objectives; gtd relies on clearly defined objectives\n- gtd requires breaking down projects into smaller, concrete next steps\n\n### [[t.km.digital-gardening]]\n\n- the slip-box is a lot like a digital garden, but not necessarily [[ar.swyx.learn-in-public]]\n- maybe digital gardening doesn't specify the rest of the note-taking methodology. \n- digital garden is more high-level / contentful than, at least, my notes\n\n## @niklas-luhman speaks through others\n\n### \"needs of a communication system\"\n\n- without surprise or disappointment there’s no information\n- information\n- complexity\n\n## Use Cases\n\n- [[t.storytelling.fiction.writing]]\n  - resources:  [Zettelkasten for fiction writing](https://zettelkasten.de/fiction)\n\n## References\n\n- https://notes.andymatuschak.org/Zettelkasten\n\n## [[c.Resource.List]]\n\n- https://zettelkasten.de/posts/overview/\n\n## Resources\n\n- https://zettelkasten.de/posts/extend-your-mind-and-memory-with-a-zettelkasten/\n- [[ar.readwise.a-system-for-writing]]\n\nA practical history of personal knowledge management tools, from Lumann's Zettelkasten through Notion, Roam, and Obsidian, to my current recommended tool, Dendron. We'll look at the features of Dendron-flavored markdown and also explore the benefits of \"learning in public\" with a Digital Garden.","n":0.085}}},{"i":992,"$":{"0":{"v":"Vocabulary","n":1},"1":{"v":"\n\n\n- [[c.Resource.List]] https://github.com/solid/solid-namespace\n","n":0.577}}},{"i":993,"$":{"0":{"v":"Knowledge Visualization","n":0.707},"1":{"v":"\n\r\nVisualizing knowledge often looks like a graph\r\n","n":0.378}}},{"i":994,"$":{"0":{"v":"Uncertainty","n":1},"1":{"v":"\n\n\n\n## Resources\n- https://www.w3.org/2005/Incubator/urw3/wiki/Fine_grained_version_of_Uncertainty_Ontology\n","n":0.577}}},{"i":995,"$":{"0":{"v":"Taxonomy","n":1},"1":{"v":"\n\n\n## Dave's General Taxonomy\n## [[p.hasExample]]\n  \n- https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Lists_of_topics\n  - not great; management comes under business; biology listed in multiple places\n","n":0.229}}},{"i":996,"$":{"0":{"v":"Tagging","n":1}}},{"i":997,"$":{"0":{"v":"Schema","n":1}}},{"i":998,"$":{"0":{"v":"Reification","n":1},"1":{"v":"\n- related: [[t.km.meta-knowledge]]\n![[ar.reification-and-truthmaking-patterns#^r9mf84mrcvyu]]\n- [Don’t Like RDF Reification? Making Statements about Statements Using Singleton Property](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4350149/)\n\n## Issues\n\n- \"RDF reification has attracted a lot of criticism in the past, essentially by being a crude tool immediately damaging the transparency of the model and its usability on the query level.\"\n\n\n\n## Examples\n\n- [Statements about Statements about Anne Bonny](https://gist.github.com/niklasl/f4a5dee1b991ff5a19a33360c6fd3078) by @niklas-lidstrom\n\n## References\n\n- [[ar.medium.modelling-data-with-hypergraphs]]","n":0.132}}},{"i":999,"$":{"0":{"v":"Reference Management","n":0.707}}},{"i":1000,"$":{"0":{"v":"Programmable Notes","n":0.707},"1":{"v":"\n## [[p.hasRelatedTopic]]\n\n- [[t.cs.end-user-programming]]\n\n## Resources\n\n- https://maggieappleton.com/programmatic-notes","n":0.447}}},{"i":1001,"$":{"0":{"v":"PKM","n":1},"1":{"v":"\n\n\n- [[p.isRelated]] [[t.km.note-taking]] [[t.km.digital-gardening]] [[t.tm]]\n\n## Comparison\n\n- https://www.pcmag.com/picks/ditching-evernote-here-are-your-top-alternatives\n- ","n":0.378}}},{"i":1002,"$":{"0":{"v":"Cornell Method","n":0.707},"1":{"v":"\n- developed in the 1950s by education professor Walter Pauk at Cornell\n- promotes critical thinking, efficient summarization, and effective review by helping students identify crucial points, connect ideas, and engage actively with the material","n":0.171}}},{"i":1003,"$":{"0":{"v":"PARA","n":1},"1":{"v":"\n\n\n- [[p.attributedTo]] @tiago-forte\n\n## [[p.hasRecipe]]\n\n- formulate your Project List and then replicate that list across every single tool you use, now and in the future. ^IoqWYbtXfBja\n  - consistent spelling, punctuation, and capitalization, so that your transitions between programs are as seamless as possible.\n-  put personally relevant information in Areas, and generally useful information in Resources\n## Highlights\n\n- \"what you’re committed to is not a collection of vague responsibilities, but a short list of tangible outcomes. In other words, projects.\"\n- a project without a corresponding goal is known as a “hobby.”\n- a goal without a corresponding project, that’s called a “dream.”\n  - or a backlog item\n- any PKM approach that doesn’t tie into execution tools is destined to languish on the back burner forever.\n- perform organizational work opportunistically\n- project list should change every week\n\n## Issues\n\n- Where do specific products fit?\n - https://fortelabs.co/blog/para/ [[p.hasExample]] \"Areas of responsibility\"\n   - \"Financial Reporting\" \n   - \"Product Development\"\n   - aka \"Responsibility Types\"\n - What about \"GraphDown\"? \n   - no goal, it's a product\n - [[p.decided]] products are areas\n- What about contexts\n\n## [[p.begsQuestion]]\n\n- how do areas relate to themes and initiatives\n- how do projects related to epics and stories\n\n## Resources\n\n- [[email.para-on-paper]]\n\n### [[p.hasLearningResource]] \n\n- https://fortelabs.co/blog/para/\n- https://fortelabs.co/blog/p-a-r-a-ii-operations-manual/\n","n":0.071}}},{"i":1004,"$":{"0":{"v":"Ontology","n":1},"1":{"v":"\n## Definitions\n\na logical theory accounting for the intended meaning of a formal vocabulary, i.e. its ontological commitment to a particular conceptualization of the world. The intended models of a logical language using such a vocabulary are constrained by its ontological commitment. An ontology indirectly reflects this commitment (and the underlying conceptualization) by approximating these intended models.\n\n## Thoughts\n\n- \"facts assumed to always be true by a community\" is tricky\n  - a-box assertions about a fictional setting could qualify as an ontology. \n\n\n### \"Schools\"\n\n  - Philosophy School\n  - Vocabulary and Taxonomy School\n      - These taxonomies often model a domain as hierarchical structures without defining what a link in the hierarchy actually means. As a result, they often mix sub-component and sub-class hierarchies.\n  - Relational School\n  - Object-Oriented School\n  - Standards School\n  - Linked Data School\n  - NLP/LLM School\n  - Data-Centric School\n  \n## Issues\n\n- \n\n## Ontology Libraries\n\n[[prdct.romulus]]\n[[prdct.ontohub-org]]\n[[prdct.ontology-lookup-service]]\n[[prdct.ontologydesignpatterns-org]]\nhttps://github.com/iddi/sofia/tree/master/eu.sofia.adk.common/ontologies/foundational\n\n## Formal Upper Ontologies\n\n  [[prdct.basic-formal-ontology]]\n  [[prdct.gfo]]\n  [[prdct.cidoc-crm]]\n  [UMBEL – Upper Mapping and Binding Exchange Layer](https://en.wikipedia.org/wiki/UMBEL \"UMBEL\"), a subset of OpenCyc\n[[prdct.dolce]]\n  [[prdct.dolce.dns-ultralite]]\n  [[prdct.dolce.lite-plus]]\n  [[prdct.dolce.lite]]\n  [[prdct.sumo]]\n      has an associated open source [Sigma knowledge engineering environment](https://en.wikipedia.org/wiki/Sigma_knowledge_engineering_environment \"Sigma knowledge engineering environment\"). [[prdct.sigmakee]]\n\n## Mid-level Ontologies\n\n[[prdct.cognitive-characteristics-ontology]]\n\n## Solutions\n\n[[prdct.oxo]] / [[prdct.ontology-lookup-service]]\n\n## Related\n\n@quine's ontological relativity\n\n## Resources\n\n- https://dgarijo.github.io/Widoco/doc/bestPractices/index-en.html\n- https://www.springer.com/gp/book/9783540709992\n- [+] [[prdct.w3id]]\n- [[ar.the-ontology-of-relations]]\n- [OntoJIT: Exploiting CLR Compiler Support for Performing Entailment Reasoning over Executable Ontologies](http://www.ijke.org/vol4/93-SE030.pdf)\n- https://tdan.com/the-data-centric-revolution-best-practices-and-schools-of-ontology-design/31412\n- [Ontology Development 101: A Guide to Creating Your\n- First Ontology](https://www.cs.upc.edu/~jvazquez/teaching/sma-upc/docs/ontology101.pdf)\n- [[ar.foundational-ontologies-in-action]]\n- [Developing and using ontologies in behavioural science: addressing issues raised](https://wellcomeopenresearch.org/articles/7-222)\n- [[book.an-introduction-to-ontology-engineering-keet]]\n- [[ar.ontology-development-101-a-guide-to-creating-your-first-ontology]]\n- https://dgarijo.github.io/Widoco/doc/bestPractices/index-en.html\n\n### Resource List\n\n[[ar.where-to-publish-and-find-ontologies-a-survey-of-ontology-libraries]]\n  mentions: \n    [[prdct.cupboard]] (dead)\n    [[prdct.obo-foundry]]\n    [[prdct.ontology-lookup-service]]\n    [[prdct.ontologydesignpatterns-org]]\n      mentions: [[prdct.cognitive-characteristics-ontology]]\n[[prdct.ontohub-org]]\n\n## References\n\n- [[ar.formal-ontologies-and-information-systems]]\n- https://web.njit.edu/~geller/what_is_an_ontology.html","n":0.064}}},{"i":1005,"$":{"0":{"v":"Upper Ontologies","n":0.707},"1":{"v":"\n- similar: [[t.km.ontology.foundational]]\n\n![](/assets/images/2024-06-06-12-25-20.png)\n\n## Issues\n\n### Foundational Ontologies need to be written in a language like KIF\n\n- \"using OWL alone would be non-sensical\"\n\n## Matching\n\n- manages semantic heterogeneity among various information sources\n- Ontology matching is semantic technology that focus to solve this issue by automating integration of distributed information sources\n\n## References\n\n- https://ontology4.us/english/Ontologies/Upper-Ontologies/Concepts_Comparison/index.html\n- https://cw.fel.cvut.cz/b201/_media/courses/osw/lecture-08matching-h.pdf\n- [[ar.a-comparison-of-upper-ontologies]]","n":0.14}}},{"i":1006,"$":{"0":{"v":"Publication","n":1}}},{"i":1007,"$":{"0":{"v":"Processes","n":1},"1":{"v":"\n## References\n\n- [[ar.process-and-causality]]","n":0.577}}},{"i":1008,"$":{"0":{"v":"Powerclass","n":1},"1":{"v":"\n\n## Issues\n\n- is a powertype just a metatype whose instances are used in the inheritance hierarchy of another class?\n- a class could have multiple powertypes.\n  - multiple-inheritance\n- \n\n## References\n\n[[ar.an-extensible-approach-to-multi-level-ontology-modelling]]","n":0.186}}},{"i":1009,"$":{"0":{"v":"Multi-Level Theory","n":0.707},"1":{"v":"\n- similar: [[t.cs.semantic-web.class.class-as-values]]\n\n## Implementations\n\n- [[prdct.ml2]], [[prdct.melanie]], [[prdct.deeptelos]], [[prdct.ontouml]], [[ar.incorporating-types-of-types-in-ontology-driven-conceptual-modeling]]\n\n## chatgpt4.o\n\n(with a few prompts to fix things up)\n\n### Multi-Level Theory (MLT) Summary with Corrected Examples\n\n**Multi-Level Theory (MLT)** is a framework used in modeling and ontology to represent entities across multiple levels of abstraction. Unlike traditional class hierarchies where entities are related by subclass relationships, MLT focuses on meta-class relationships, where each level defines a higher-order structure or type for the level below it.\n\n### Levels of MLT:\n\n1. **M3 Level (Meta-Meta-Level): \"Types\"**\n   - **Description**: This is the most abstract level, representing the concept of types or classes themselves. It defines the meta-structure for how types are organized and classified.\n   - **Example**: \"Types\" define what it means to be a type or class in any domain. It provides the foundational concept from which other types (meta-classes) are derived.\n\n2. **M2 Level (Meta-Level): \"OrganizationalUnitType\"**\n   - **Description**: At this level, you have the meta-class that defines the general concept of organizational units. This meta-class provides the template for various kinds of organizational units, such as departments, teams, or divisions.\n   - **Example**: \"OrganizationalUnitType\" is a meta-class that describes general properties and behaviors of organizational units across different contexts. It serves as a blueprint for more specific classes like \"Department Class.\"\n\n3. **M1 Level (Type Level): \"HR Department Class\"**\n   - **Description**: This level represents a specific type within the broader concept of OrganizationalUnitType. \"HR Department Class\" is a type that can have different kinds of departments as its subclasses, such as HR Department, Finance Department, etc.\n   - **Example**: \"Department Class\" is a class within the \"OrganizationalUnitType.\" It specifies what it means to be a department and can be further specialized into subclasses like \"HR Department\" or \"Finance Department.\"\n\n4. **M0 Level (Instance Level): \"HR Department of Company X\"**\n   - **Description**: This is the instance level where specific, real-world examples exist. Instances are actual entities that are instantiated from the classes defined at the M1 level.\n   - **Example**: \"HR Department of Company X\" is an actual, specific department within a particular organization. It is an instance of the \"HR Department\" subclass, which itself is part of the \"Department Class.\"\n\n### Example in Practice:\n\n- **M3: Types** \n  - Defines the fundamental concept of a \"type\" or \"class.\"\n  \n- **M2: OrganizationalUnitType**\n  - Specifies meta-classes for organizational units, like \"Department Class.\"\n\n- **M1: Department Class**\n  - Describes specific types of departments, with potential subclasses like \"HR Department.\"\n\n- **M0: HR Department of Company X**\n  - A concrete instance of a department in the real world, such as the HR department in a specific company.\n\n### Key Points:\n\n- **Meta-Class Relationships**: Each level is related to the one above it through meta-classification, not subclassing. For example, \"OrganizationalUnitType\" at M2 defines what \"Department Class\" at M1 can be, and \"Department Class\" at M1 defines what the instances at M0 can be.\n- **Instantiation**: Entities at a lower level instantiate or realize the types defined at the higher levels, with M0 entities being real-world examples of the M1 types.\n- **Abstraction**: Higher levels are more abstract, defining broader concepts that provide structure and constraints to the more specific types and instances at lower levels.\n\nThis structured approach allows for the modeling of complex systems where entities exist at multiple levels of abstraction, providing a clear and organized way to represent and relate these entities across different levels.\n\n## References\n\n- [[ar.multi-level-conceptual-modeling-theory-language-and-application]]\n- [[ar.melanie-multi-level-modeling-and-ontology-engineering-environment]]\n- [[ar.deep-telos-and-dmla-a-contribution-to-the-multi-2022-collaborative-comparison-challenge]]\n- [[ar.an-extensible-approach-to-multi-level-ontology-modelling]]\n- [[ar.multi-level-ontology-based-conceptual-modeling]]","n":0.043}}},{"i":1010,"$":{"0":{"v":"Modular Ontologies","n":0.707},"1":{"v":"\n- \"Building an ontology from small modules that can be specialized for different domains brings\nunderstandability and homogeneity to the overall ontology. Modular ontologies based on\nsuch module specializations enable developers of specific applications to create custom views\nby selecting the set of required specializations. The underlying knowledge factorization also\nstreamlines the development process and eases maintainability and resilience, considering that\nproblems arising within a module are handled in a targeted fashion.\"\n\n## References\n\n- [[ar.the-acimov-methodology-agile-and-continuous-integration-for-modular-ontologies-and-vocabularies]]","n":0.12}}},{"i":1011,"$":{"0":{"v":"Metadata","n":1}}},{"i":1012,"$":{"0":{"v":"Information Content Entity","n":0.577},"1":{"v":"\n- different-from: \n\nAn Information Content Entity (ICE) refers to any entity that represents some content that can be interpreted. Examples include data sets, documents, and pieces of software. The key characteristic of ICEs is that they have content that can be interpreted or understood by an agent (human or machine). ICEs are abstract entities; they do not have a physical form but rather exist as pieces of information.\nExamples:\n\n- A PDF document (the content, not the file itself)\n- The text of a book (regardless of whether it's printed on paper or displayed on a screen)\n- A piece of software code","n":0.101}}},{"i":1013,"$":{"0":{"v":"Information Bearing Entity","n":0.577},"1":{"v":"\nrefers to any physical entity that can carry or store information. IBEs are the physical carriers of ICEs. They provide the medium through which information content can be stored, transmitted, or retrieved.\nExamples:\n\n- A physical book (the paper and ink that carry the text)\n- A USB drive (the hardware storing digital data)\n- A CD-ROM (the physical disc containing digital content)","n":0.13}}},{"i":1014,"$":{"0":{"v":"Four Category","n":0.707},"1":{"v":"\n![](/assets/images/2024-07-22-15-31-09.png)\n\n## Description\n\n### ChatGPT\n\nThe diagram is from E.J. Lowe's work on the Four-Category Ontology. This ontology, a significant contribution to contemporary metaphysics, is discussed in Lowe's book \"[[book.the-four-category-ontology-a-metaphysical-foundation-for-natural-science]]\" published by Oxford University Press.\n\nIn this framework, Lowe identifies four fundamental categories:\n\n1. **Substantial Universals (Kinds):** These are the categories that classify objects into types.\n2. **Non-substantial Universals (Attributes):** These are properties or characteristics that objects can have.\n3. **Substantial Particulars (Objects):** These are individual substances or entities.\n4. **Non-substantial Particulars (Modes):** These are specific instances of properties or attributes that particular objects possess.\n\nThese categories are interconnected in what Lowe calls the \"Ontological Square,\" illustrating how attributes characterize kinds, modes instantiate attributes, and objects instantiate kinds.\n\nFor more detailed information, you can refer to the [Oxford Academic publication](https://academic.oup.com/book/3774) and further discussions in various reviews and analyses of Lowe's work on academic platforms【7†source】【8†source】.\n\n## References\n\n- [[book.the-four-category-ontology-a-metaphysical-foundation-for-natural-science]]","n":0.086}}},{"i":1015,"$":{"0":{"v":"Foundational Ontology","n":0.707},"1":{"v":"\n- https://github.com/iddi/sofia/tree/master/eu.sofia.adk.common/ontologies/foundational\n\n## Definition\n\n- \"while a top-level ontology is a classification system that deals with general domain-independent categories only, a foundational ontology is a top-level (formal) ontology that has been built and motivated by the upfront and explicit choice of its core principles” ([[Borgo and Hitzler, 2018|ar.some-open-issues-after-twenty-years-of-formal-ontology]])    \n\n## Benefits\n\n    one does not have to ‘reinvent the wheel’ with respect to the basic categories and relations to represent the subject domain,\n    it improves overall quality of the ontology by using principled design decisions, and\n    it facilitates interoperability among ontologies that are aligned to the same foundational ontology.\n\nFrom the viewpoint of Ontology, a foundational ontology serves to clarify philosophical details and be upfront about them, bring assumptions to the fore and justify them, and, with that, it may become clear where there are any philosophical agreements and disagreements and what their underlying causes are.\n\nA subset of domain ontology developers do not see a benefit:\n\n    they consider them too abstract, too expressive and comprehensive for the envisioned ontology-driven information system, and\n    it takes excessive effort to understand them in sufficient detail such that it would not weigh up to the benefits.\n\n\n## References\n\n- [[book.an-introduction-to-ontology-engineering-keet]]\n- [[ar.foundational-ontologies-from-theory-to-practice-and-back]]\n- [[vs.dolce-vs-ufo-vs-gfo-vs-sumo]]","n":0.072}}},{"i":1016,"$":{"0":{"v":"Fictional","n":1},"1":{"v":"\n## Thoughts\n\n- maybe it's that \"the idea of Batman\" exists\n  - t.2024.06.08.17 i.e., the character Batman is abstract\n    - t.2024.07.23.19 except it has a time, like conception time\n\n## Issues and Arguments\n\n- \"if we admit a certain kind of entity, we cannot but admit all the other kinds of entities that figure in the identity conditions of such an entity; we admit fictional works; so we cannot but also admit fictional objects because they figure in the identity conditions of fictional works (cf. Voltolini 2003, 2006).\"\n- \"Lee (2022), for example, argues that the identity of fictional characters is (usually) to be settled by appeal to authorial intentions rather than principles of identity, and that this is enough to disarm alleged examples of ontic determinacy\"\n- \"a work is fiction iff (a) it is the product of a fictive intent and (b) if the work is true, then it is at most accidentally true. (1990: 46)\" but \"So there are parts of many, if not most, works of fiction that are non-accidentally true, and so the works should not straightforwardly count as fiction according to the criteria set out by Currie and by Lamarque and Olsen.\"\n\n\n## Resources\n\n- https://plato.stanford.edu/entries/fictional-entities/\n- https://plato.stanford.edu/entries/fiction/#SpeeActAcco\n- [[ar.fictional-realism-and-commonsense-ontology]]\n- [[ar.towards-a-semantics-for-the-artifactual-theory-of-fiction-and-beyond]]\n- [[ar.the-ontology-of-fiction-a-study-of-dependent-objects]]\n\n\n![[ar.the-ontology-of-fiction-a-study-of-dependent-objects#similar-books-and-articles]]","n":0.071}}},{"i":1017,"$":{"0":{"v":"Event","n":1},"1":{"v":"\nsee [[ar.lode-linking-open-descriptions-of-events]]\n\n## References\n\n- https://www.researchgate.net/publication/220916829_F_-_A_model_of_events_based_on_the_foundational_ontology_DOLCEDnS_ultralite\n- [[prdct.event-model-f]]","n":0.447}}},{"i":1018,"$":{"0":{"v":"Continuant Vs Occurrent","n":0.577},"1":{"v":"\n![[sh.question-log.2024.03.26]]\n\n## References\n\n- https://therecouldbebadgers.wordpress.com/2018/06/27/endurants-perdurants-continuants-occurrents/\n\ncontinuant/endurant","n":0.577}}},{"i":1019,"$":{"0":{"v":"Classonomies","n":1},"1":{"v":"\n- \"Classonomies consist of classes. Typically, a very large number of classes. The classes, while otherwise largely “undefined”, may be organized taxonomically using rdfs:subClassOf statements. By undefined, I mean classes that have no ontological definitions. Classes that do not define characteristics (i.e., properties) of their members. Instead, they have the kind of information one typically associates with instances e.g., synonyms, acronyms, various identifiers, descriptive text and, possibly, variety of other statements.\"\n- \"Thesauri are not expected to be semantically precise. They simply group broader and narrower topics.\"\n-- **Rule #1 of the Ontology Development: If you can’t answer a question about what resources will be members of a class, you can’t create a class.**\n- An obvious approach to turning such classonomies into thesauri is [[prdct.skos]]\n\n## Examples\n\n- https://raw.githubusercontent.com/BFO-ontology/BFO-2020/master/src/owl/profiles/temporal%20extensions/temporalized%20relations/owl/bfo-temporalized-relations.ttl\n\n## References\n\n- https://www.topquadrant.com/resources/what-are-classonomies-and-why-you-may-want-to-avoid-them/","n":0.089}}},{"i":1020,"$":{"0":{"v":"Applied Ontology","n":0.707},"1":{"v":"\n[[Applied ontology|t.km.ontology.applied]] involves the investigation of the nature of various domains of interest (like fiction or roleplaying) and the cognitive and linguistic constructs we use to understand them.\n\n\n## References\n\n- [[ar.applied-ontology]]","n":0.183}}},{"i":1021,"$":{"0":{"v":"Note Taking","n":0.707},"1":{"v":"\n\r\nEverybody does it, but does anybody do it well?\r\n\r\n- [People who write extensively about note-writing rarely have a serious context of use](https://notes.andymatuschak.org/zUMFE66dxeweppDvgbNAb5hukXzXQu8ErVNv) \r\n- [“Better note-taking” misses the point; what matters is “better thinking”](https://notes.andymatuschak.org/z7kEFe6NfUSgtaDuUjST1oczKKzQQeQWk4Dbc)\r\n  - Usually true. But if you're developing a new note-taking system, they both matter.\n","n":0.146}}},{"i":1022,"$":{"0":{"v":"Bullet Journaling","n":0.707},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] BuJo\n","n":0.577}}},{"i":1023,"$":{"0":{"v":"Modeling","n":1},"1":{"v":"\n## References\n\n- [[ar.theory-framework-knowledge-hub-message-1]]","n":0.577}}},{"i":1024,"$":{"0":{"v":"Meta Knowledge","n":0.707},"1":{"v":"\n- related: [[t.cs.semantic-web.singleton-property]]\n\n\n## Metaknowledge\n\nfrom [[ar.don-t-like-rdf-reification-making-statements-about-statements-using-singleton-property]]\n\n```\n### Table 1\n\nSample queries for different types of meta knowledge, \neach query example is assigned an identifier (P, T, S, and C) for references\n\nQuery type\n\nExamples\n\nProvenance\n\nP1. Where is this fact from?\n\nP2. When was it created?\n\nP3. Who created this fact?\n\n___\n\nTemporal\n\nT1. When did this event occur?\n\nT2. What is the time span of this event?\n\nT3. Which events were in the same year?\n\n___\n\nSpatial\n\nS1. What is the location of this event?\n\nS2. Which events were at the same place?\n\n___\n\nCertainty\n\nC1. What is the confidence of this fact?\n\n```\n","n":0.11}}},{"i":1025,"$":{"0":{"v":"Provenance","n":1},"1":{"v":"\n\n\n## Related\n\n- https://www.w3.org/ns/prov\n  - [[p.hasHighlight]] actedOnBehalfOf, Activity\n","n":0.378}}},{"i":1026,"$":{"0":{"v":"Annotation","n":1},"1":{"v":"\n\n\n## Related\n\n- https://www.w3.org/TR/annotation-vocab/\n","n":0.577}}},{"i":1027,"$":{"0":{"v":"Lineage","n":1}}},{"i":1028,"$":{"0":{"v":"Knowledge Representation","n":0.707}}},{"i":1029,"$":{"0":{"v":"Knowledge Organization System","n":0.577},"1":{"v":"\n\n\n- [[p.hasExample]] thesauri, taxonomies, classification schemes, topic maps\n","n":0.354}}},{"i":1030,"$":{"0":{"v":"Knowledge Transmission","n":0.707},"1":{"v":"\n## Resources\n\n- [Model of Knowledge Transfer Within an Organisation](https://www.jasss.org/21/2/3.html)","n":0.333}}},{"i":1031,"$":{"0":{"v":"Knowledge Representation","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://www.cliki.net/knowledge%20representation%20systems\n- https://www.lisperati.com/tellstuff/index.html","n":0.5}}},{"i":1032,"$":{"0":{"v":"Knowledge Graph","n":0.707},"1":{"v":"\n## Resources\n\n- https://www.kaggle.com/code/pavansanagapati/knowledge-graph-nlp-tutorial-bert-spacy-nltk\n  - file:///C:/Users/drichardson/Downloads/16604-Article%20Text-20098-1-2-20210518.pdf\n- https://analyticsindiamag.com/all-you-need-to-know-about-temporal-knowledge-graphs/\n- [[ar.towardsdatascience.a-guide-to-knowledge-graphs]]\n\n\n## [[c.specialization]]\n\n- [[t.km.knowledge-graph.temporal]]\n","n":0.333}}},{"i":1033,"$":{"0":{"v":"Temporal Knowledge Graph","n":0.577},"1":{"v":"\n- [[p.similarTo]] [[t.km.knowledge-graph.dynamic]]\n\n## Implementations\n\n- https://github.com/INK-USC/DArtNet\n\n## [[c.resource.list]]\n\n- https://github.com/topics/temporal-knowledge-graph\n","n":0.378}}},{"i":1034,"$":{"0":{"v":"Rslt","n":1},"1":{"v":"\n- isomorphic to what some programmers call a \"hypergraph\"\n\n## Resources\n\n- https://github.com/JeffreyBenjaminBrown/hode/blob/master/docs/rslt/rslt.md","n":0.302}}},{"i":1035,"$":{"0":{"v":"Labelled Property Graph","n":0.577},"1":{"v":"\n- \"LPGs shine brightest in these limited scenarios where edge properties and path discovery are paramount.\"\n\n## Properties of Properties:\n\nIn the world of LPGs, edges can bear their own properties, allowing for the inclusion of valuable metadata such as the source of information, date of assertion, and confidence level. This can be emulated with objects in standard RDF but unfortunately there is a performance cost. A better approach is RDF-* and SPARQL-*, which is about to be standardized, and is already supported by several RDF databases.\n\n## Property Path Discovery:\n\nLGPs have an advantageous ability to traverse the shortest path between two nodes, which is valuable for unraveling complex relationships and uncovering hidden insights. While this may not be a pivotal concern for all domains, it holds particular significance for those where relationships are multi-faceted and require in-depth exploration. This is only important for certain domains, such as social networks, so it is of limited importance. However, there is nothing about property graphs that is special here, as it’s just a function of the query language. Unfortunately, SPARQL doesn’t include this, but any RDF database (including Fluree) can implement this operation, if the application demands for it.\n\nIt’s important to note that LPGs shine brightest in these limited scenarios where edge properties and path discovery are paramount. The beauty of the RDF ecosystem lies in its versatility and adaptability. The introduction of RDF-* and SPARQL-* speaks to the growing recognition of these specialized features within the RDF paradigm.\n\n- resources:  https://medium.com/neo4j/graph-modeling-labels-71775ff7d121\n  - a label in Neo4j is just a “set membership marker”\n  - Use labels to indicate semantic class of information and set membership, and use them to get the speed-ups of “semi-free” indexing\n  - Don’t design a data model if you don’t know what queries you want to ask of the database\n    - \"Data models exist to facilitate answering questions from the databases — they are not for creating pristine semantic models of domains\"\n    - Creating great semantic models is arguably futile, because a model is a map and the map is not the territory.\n\n## References\n\n- https://flur.ee/fluree-blog/rdf-versus-lpg/","n":0.054}}},{"i":1036,"$":{"0":{"v":"Dynamic","n":1},"1":{"v":"\n## Implementations\n\n- [[prdct.ergoai]]","n":0.577}}},{"i":1037,"$":{"0":{"v":"Humane Semantic Web","n":0.577}}},{"i":1038,"$":{"0":{"v":"Formalization","n":1},"1":{"v":"\n\n## References\n\n- [[ar.theory-framework-knowledge-hub-message-1]]","n":0.577}}},{"i":1039,"$":{"0":{"v":"Folgezettel","n":1},"1":{"v":"\n\n\n- [[p.hadDefinition]] \n  - a nested sequence of ideas\n    - [[p.hasSource]] [[ar.medium.the-folgezettel-conundrum]]\n\n\n## Resources\n-  https://zettelkasten.de/posts/understanding-hierarchy-translating-folgezettel/\n\n","n":0.267}}},{"i":1040,"$":{"0":{"v":"Evergreen Notes","n":0.707},"1":{"v":"\r\n\r\n- \"note-taking that aspires towards cumulative personal knowledge, rather than simply information capture.\" \r\n  - [[p.hasSource]] https://maggieappleton.com/evergreens\r\n- [[p.attributedTo]] @andy-matuschak\r\n\r\n## Principles\r\n\r\n-   [Evergreen notes should be atomic](https://notes.andymatuschak.org/z4Rrmh17vMBbauEGnFPTZSK3UmdsGExLRfZz1)\r\n-   [Evergreen notes should be concept-oriented](https://notes.andymatuschak.org/z6bci25mVUBNFdVWSrQNKr6u7AZ1jFzfTVbMF)\r\n-   [Evergreen notes should be densely linked](https://notes.andymatuschak.org/z2HUE4ABbQjUNjrNemvkTCsLa1LPDRuwh1tXC)\r\n-   [Prefer associative ontologies to hierarchical taxonomies](https://notes.andymatuschak.org/z29hLZHiVt7W2uss2uMpSZquAX5T6vaeSF6Cy)\r\n-   [Write notes for yourself by default, disregarding audience](https://notes.andymatuschak.org/z8AfCaQJdp852orumhXPxHb3r278FHA9xZN8J)\r\n\r\n## [[p.vs]] [[t.km.zettelkasten]]\r\n\r\n### [Similarities and differences between evergreen note-writing and Zettelkasten](https://notes.andymatuschak.org/z4AX7pHAu5uUfmrq4K4zig9x8jmmF62XgaMXm)\r\n\r\n","n":0.129}}},{"i":1041,"$":{"0":{"v":"Event Calculus","n":0.707},"1":{"v":"\n## Concepts\n\n### Fluent\n\n- a function or a predicate that varies over time, and is used to describe the effects of actions\n\n### Events\n\n- represent changes performed over time\n- In the EC, the terms Actions and Events are interchangeable\n- Davidson’s theory defines action as a particular subclass of event that is endowed with intentionality.\n\n","n":0.139}}},{"i":1042,"$":{"0":{"v":"Discourse Graph","n":0.707},"1":{"v":"\n## [[p.hasComponent]]\n\n- ","n":0.707}}},{"i":1043,"$":{"0":{"v":"Digital Gardening","n":0.707},"1":{"v":"\n\"The Garden is the web as topology. The web as space. It’s the integrative web, the iterative web, the web as an arrangement and rearrangement of things to one another.\" \n\n## The Six Patterns of Gardening [[According To|p.attributedTo]] @maggie-appleton  ^uy4kfmq24q12\n\n-  Topography over Timelines \n-  Continuous Growth\n-  Imperfection & Learning in Public\n-  Playful, Personal, and Experimental\n-  [[t.km.digital-gardening.intercropping]] & Content Diversity\n-  Independent Ownership  ^s2h2dn8la4g6\n\n## Build a model\n\n- > Instead of building an argument about the issue this attempts to build a model of the issue that can generate new understandings. [[ar.hapgood.the-garden-and-the-stream-a-technopastoral]]\n\n## [[p.hasPro]]\n\n- Relationship building\n- Collaborative\n- Forcing function for learning depth. \n- Search engine optimization. \n- Gives you a long-term asset\n- You don't have to spend lots of time figuring out how you're going to standout in the newsfeed.\n- Create something that matches your style and brand quickly. \n- Own the content, domain, and traffic.\n\n## Issues\n\n- takes time\n- opportunity cost\n- switching cost\n- There might be parts you don't want to be public\n## [[p.hadHistory]]\n\n- \"By late 2020 this whole concept had attracted enough attention for the MIT Tech Review to write [a short piece](https://www.technologyreview.com/2020/09/03/1007716/digital-gardens-let-you-cultivate-your-own-little-bit-of-the-internet/) on it. Perhaps this is the watershed moment when a Twitter buzzword has \"made it.\"\n  - [[p.hasSource]] https://maggieappleton.com/garden-history\n## References \n\n- https://maggieappleton.com/garden-history @maggie-appleton\n- https://twitter.com/Mappletons/status/1250532315459194880  \n- https://courses.thoughtleader.school/mmc/topic-directory/digital-gardens","n":0.07}}},{"i":1044,"$":{"0":{"v":"Intercropping","n":1},"1":{"v":"\n- [[p.hasContext]] [[t.km.digital-gardening]]\n\n## Description\n\n- Gardens are not just a collection of interlinked words. While linear writing is an incredible medium that has served us well for a little over 5000 years, it is daft to pretend working in a single medium is a sufficient way to explore complex ideas.\n\nIt is also absurd to ignore the fact we're living in an audio-visual cornucopia that the web makes possible. Podcasts, videos, diagrams, illustrations, interactive web animations, academic papers, tweets, rough sketches, and code snippets should all live and grow in the garden.\n\n## References\n\n- https://maggieappleton.com/garden-history#5-intercropping-&-content-diversity","n":0.104}}},{"i":1045,"$":{"0":{"v":"Description Logic","n":0.707},"1":{"v":"\n- \"originated as an attempt to give frame languages a logical semantics\"\n- most often used for classification reasoning\n- restriction to binary relations is typical\n- strong influence on [[t.cs.semantic-web]]\n- have [[vs.tbox-vs-abox-vs-mbox]]\n\n## Referneces\n\n- [[book.ontology-a-practical-guide]]","n":0.177}}},{"i":1046,"$":{"0":{"v":"Dendron","n":1},"1":{"v":"\n\n\n- [[p.hasSameReferantAs]] [[prdct.dendron]] \n","n":0.5}}},{"i":1047,"$":{"0":{"v":"Rfc","n":1}}},{"i":1048,"$":{"0":{"v":"Dendron RFC13","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] [Dendron RFC13 - Todo Notes](https://wiki.dendron.so/notes/716e2699-42e1-44bd-9b97-124f03173ddc.html)\n\n","n":0.378}}},{"i":1049,"$":{"0":{"v":"Dendron Reference Test","n":0.577},"1":{"v":"\n\r\n## Section-1\r\n\r\nSunt animi inventore atque quia ex aut minus.\r\nVoluptate ipsa et esse. ^paragraph-1\r\n\r\nPorro ad nesciunt sed eius ut enim est eveniet.\r\nOmnis sint necessitatibus aut. ^paragraph-2\r\n\r\n* Aliquam et sit autem. ^first\r\n* Est sapiente quis ut est.\r\n* Est incidunt et debitis vel ab. ^third\r\n  * third sub-bullet\r\n* Maxime harum aut mollitia debitis ipsa.\r\n\r\n### Section-1a\r\n\r\ntest-paragraph-1a1 in Section 1a\r\n\r\ntest-paragraph-1a2 with block anchor ^test-paragraph-1a2\r\n\r\ntest-paragraph-1a3 is also a good one\r\n\r\n## Section-2\r\n\r\n\r\n","n":0.124}}},{"i":1050,"$":{"0":{"v":"Collective Knowledge Management","n":0.577}}},{"i":1051,"$":{"0":{"v":"Bioinformatics","n":1},"1":{"v":"\n\n## Solutions\n\n- [[prdct.obo-foundry]]\n- [[prdct.gfo.bio]]\n\n\n## References\n\n- https://www.w3.org/wiki/Semantic_Bioinformatics","n":0.408}}},{"i":1052,"$":{"0":{"v":"Attribution","n":1}}},{"i":1053,"$":{"0":{"v":"Ambiguity","n":1}}},{"i":1054,"$":{"0":{"v":"ACE","n":1},"1":{"v":"\n- author: @nick-milo\n\n## 3 Headspaces\n\n- Atlas\n  - places you can go\n  - add, relate, communicate\n- Calendar / Time\n- Efforts / Action\n  - 4 intensities\n    - On\n    - Ongoing\n    - Simmering\n    - Sleeping\n\n\n## Resources\n\n- https://tfthacker.substack.com/p/ace-an-exciting-framework-for-pkm\n- ","n":0.171}}},{"i":1055,"$":{"0":{"v":"History","n":1}}},{"i":1056,"$":{"0":{"v":"Military History","n":0.707}}},{"i":1057,"$":{"0":{"v":"Cs","n":1}}},{"i":1058,"$":{"0":{"v":"Web","n":1}}},{"i":1059,"$":{"0":{"v":"Social","n":1}}},{"i":1060,"$":{"0":{"v":"Social Bookmarking","n":0.707}}},{"i":1061,"$":{"0":{"v":"Site","n":1}}},{"i":1062,"$":{"0":{"v":"Site Search","n":0.707},"1":{"v":"\n\n\n- [[p.vs]] [[t.cs.web.search]]\n  - [[t.cs.web.site.search]] [[p.hasSense]] internal search within a site\n  - ![[t.cs.web.search#^HxuyfUkt4cMy]]\n","n":0.277}}},{"i":1063,"$":{"0":{"v":"Webhooks","n":1},"1":{"v":"\n\n## Comparisons\n\n### Webhooks vs Event Consumption\n\n- Webhooks deliver or push events to your clients’ services, requiring them to handle the resulting back pressure. Using a scalable message broker to support consumption can alleviate this burden for your clients. How? By allowing clients to pull events based on their availability.\n- Standard webhook systems generally lack event persistence for future audits and replays, a capability inherently provided by persisted message brokers.\n\n## References\n\n- https://dev.to/memphis_dev/comparing-webhooks-and-event-consumption-a-comparative-analysis-37a3","n":0.119}}},{"i":1064,"$":{"0":{"v":"W3c","n":1},"1":{"v":"\n- same-as: [[org.w3c]]","n":0.577}}},{"i":1065,"$":{"0":{"v":"Rdf","n":1}}},{"i":1066,"$":{"0":{"v":"RDF Vocabulary","n":0.707},"1":{"v":"\n- #definition sets of terms used to describe things.\n\n## Terms\n\nTerm\n: either a class or a property.[^1]\n  - Object type properties (relationships)\n  - Data type properties (attributes)\n\nProperty\n: either a data property or an object property\n\n## Re-use\n\n- \n\n## References\n\n\n- [^1]: https://data.europa.eu/sites/default/files/d2.1.2_training_module_2.4_designing_and_developing_vocabularies_in_rdf_en_edp.pdf\n- https://blogs.pjjk.net/phil/blog/\n- https://semiceu.github.io/style-guide/1.0.0/clarification-on-reuse.html\n","n":0.156}}},{"i":1067,"$":{"0":{"v":"Spatio-Temporal RDF","n":0.707},"1":{"v":"\n\n\n## Solutions\n\n- [[prdct.eagle]]\n- [[prdct.prov-o]]\n- [[prdct.dcat-data-catalog.v2]] has frequency (of publishing),\n\n## References\n\n- [[ar.a-comprehensive-overview-of-rdf-for-spatial-and-spatiotemporal-data-management]]\n- [[ar.fuzzy-spatiotemporal-data-modeling-and-operations-in-rdf]]\n- [[ar.eagle-a-scalable-query-processing-engine-for-linked-sensor-data]]\n- [[ar.star-vers-versioning-and-timestamping-rdf-data-by-means-of-rdf-star-an-approach-based-on-annotated-triples]]\n- https://stackoverflow.com/questions/41830542/simple-versioning-in-rdf-data has no solutions","n":0.236}}},{"i":1068,"$":{"0":{"v":"Resource","n":1},"1":{"v":"\n\n![](/assets/images/2021-10-07-06-59-00.png)\n","n":1}}},{"i":1069,"$":{"0":{"v":"Property Value","n":0.707}}},{"i":1070,"$":{"0":{"v":"Open World Assumption","n":0.577},"1":{"v":"\n## Description\n\n### Irene’s Principles\n\nThe OWA stands for precisely two principles:\n\n- Non unique names\n- Negation is not a failure\n\n\n\n## References\n\n- [[ar.linkedin.the-open-world-assumption-in-modeling-what-does-it-mean-to-you]]\n\n\n","n":0.224}}},{"i":1071,"$":{"0":{"v":"Named Graphs","n":0.707},"1":{"v":"\n- In Carroll et al. [CARROLL-05], a named graph is defined as a pair comprising an IRI and an RDF graph. The notion of RDF interpretation is extended to named graphs by saying that the graph IRI in the pair must denote the pair itself. This non-ambiguously answers the question of what the graph IRI denotes. This can then be used to define proper dataset semantics, as shown in Section 3.3. Note that it is deliberate that the graph IRI is forced to denote the pair rather than the RDF graph. This is done in order to differentiate two occurrences of the same RDF graph that could have been published at different times, or authored by different people. A simple reference to the RDF graph would simply identify a mathematical set, which is the same wherever it occurs.\n\n## Semantics\n\nMany options, none chosen:\n\n3.1 Named graphs have no meaning\n3.2 Default graph as union or as merge\n3.3 The graph name denotes the named graph or the graph\n3.4 Each named graph defines its own context\n3.5 Named graph are in a particular relationship with what the graph name dereferences to\n3.6 Quad semantics\n  - extends RDF semantics instead of re-using\n\n\"the Working Group discussed the possibility to define several semantics, among which an implementation could choose, and provide the means to declare which semantics is adopted.\n\nThis was not retained eventually, because of the lack of experience, so there is no definite option for this\"\n\n## References\n\n- https://www.w3.org/TR/rdf11-datasets/","n":0.065}}},{"i":1072,"$":{"0":{"v":"Monotonicity","n":1}}},{"i":1073,"$":{"0":{"v":"Linkset","n":1},"1":{"v":"\n## Description\n\nA linkset is a collection of such RDF links between two datasets. It is a set of RDF triples where all subjects are in one dataset and all objects are in another dataset. RDF links often have the owl:sameAs predicate, but any other property could occur as the predicate of RDF links as well.\n\nIn VoID, a linkset is modelled as an instance of the void:Linkset class. void:Linkset is a subclass of void:Dataset.\n\n## References\n\nhttps://www.w3.org/TR/void/#dataset","n":0.116}}},{"i":1074,"$":{"0":{"v":"Dynamic-RDF","n":1},"1":{"v":"\n\n\n[[a|p.instanceOf]] [[programming language|c.ProgrammingLanguage]] for [[RDF|prdct.rdf]], written in RDF\n\n## [[Related|p.hasResource]] \n\n- [DRDF: Dynamic Resource DescriptionFramework](https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=15852&context=rtd)\n","n":0.267}}},{"i":1075,"$":{"0":{"v":"Concept","n":1},"1":{"v":"\n\n![](/assets/images/2021-11-26-07-34-50.png)","n":1}}},{"i":1076,"$":{"0":{"v":"Iri","n":1},"1":{"v":"\n\n\n## Resources\n\n- https://www.stardog.com/tutorials/data-model/#iris\n  - [[p.hasHighlight]]\n    - gives an example of the [[t.cs.web.ietf.rfc4151-tag-IRI-scheme]]\n    - \"It is considered good practice to avoid bnodes as much as possible so that all nodes can be referenced directly in queries and transactions.\" ^VMiYw8SewgDF\n","n":0.162}}},{"i":1077,"$":{"0":{"v":"Design Issues","n":0.707},"1":{"v":"\n- https://www.w3.org/DesignIssues/\n\n## Linked Data\n\n- https://www.w3.org/DesignIssues/LinkedData.html\n\n* Use URIs as names for things\n* Use HTTP URIs so that people can look up those names\n* When someone looks up a URI, provide useful information, using the standards (RDF*, SPARQL)\n* Include links to other URIs. so that they can discover more things. (sic)\n\n## Icing on the cake\n\n- \"It would certainly be interesting for someone to make a web interface for a version control system which is all icing on the original cake, where at any point you can strip off the ,stuff and get back to the original file live on the web site\"\n  - @tim-berners-lee\n- \"The [[prdct.memento]] protocol is a good example of a machine-readable icing on the cake. It adds HTTP headers to allow older versions of a web page to be found, allowing a momento-equipped browser to explore the timeline of a web page's histroy.'\"\n\n### Conclusion\n\n- the \"icing on the cake\" pattern, in which all services around a live web page are available at URIs made by adding small strings to the same URI, has many nice properties. It is easy to use, and scales well as new facilities are added. Future systems, especially version control systems, but also access control systems, should be desigend with that in mind. Not only should one make the facilities available to a human user by adding (say) the comma by hand, but also make the facilities visible to software by adding a link of some sort.","n":0.064}}},{"i":1078,"$":{"0":{"v":"Transport","n":1}}},{"i":1079,"$":{"0":{"v":"Topic Maps","n":0.707}}},{"i":1080,"$":{"0":{"v":"Synthetics Monitoring","n":0.707}}},{"i":1081,"$":{"0":{"v":"Sustainable Web Apps","n":0.577},"1":{"v":"\n- related: [[prdct.m-ld]]\n\n## why do so many existing apps lock-in their users and their attention, and keep control over their users' personal data?\n\nFirst: there is an economic incentive to developing apps without these properties. Data is valuable, and companies who produce applications would prefer to have access to as much of it as possible. Active users are valuable, as they produce valuable data, and are also available to target with another revenue source, advertising. Thus, the more an application developer can keep users and their data tied to a platform, the more that application will succeed economically—that is, until and unless the users demand an alternative. However, it's hard for users to make much progress simply asking for change; the most effective way for users to make their needs known is to actually leave the services they disagree with in favor of those which treat them better, and to do that, there must be alternatives available to move to.\n\nThus, the second reason: there is a technological disincentive. It's simply much easier to develop an application in which everyone's data is centralized in a database under the application developer's control. Exposing that data via some sort of API is a good deal of extra effort that can be hard to justify. Interchanging data with other applications, to the point of eliminating lock-in, is even harder to justify, as it both gives users a route to leave the application and is even harder to build than simply exposing the data in some ad-hoc format.\n\n## Architecture\n\n![](/assets/images/2024-05-30-08-50-20.png)\n\n-   The JavaScript code and other static assets of the Web App (the _app_, in pink) are served from some origin via HTTP.\n-   The app establishes a working Graph Model, comprised of _semantic web_ data \\[\\[RDF-NOT\\]\\] (non-specific serialisation).\n-   The Graph is stored locally, and so is available without a network round-trip (unless it has to be fetched to get started!). It is [[local-first|t.cs.sd.local-first]] \\[\\[LOFI\\]\\].\n-   If other replicas of the Graph exist elsewhere, they are synchronised, when the network is available, via a Message Delivery service.\n-   If desired for data safety, the Graph can also be replicated to a Backup service, having its own persistent storage.\n-   Such a Backup service may also expose the data in the Graph as Linked Data \\[\\[LINKED-DATA\\]\\] via its own API. This makes the data de-referencable, via HTTP, for more loosely-coupled consumers.\n\n## References\n\n- https://github.com/m-ld/sustainable-web-apps/blob/main/spec/index.md\n- https://github.com/m-ld/sustainable-web-apps/blob/main/spec/design/architecture.md","n":0.051}}},{"i":1082,"$":{"0":{"v":"Static Site Generator","n":0.577}}},{"i":1083,"$":{"0":{"v":"Server-Side Rendering","n":0.707},"1":{"v":"\n\n\n- [[p.vs]] [[t.cs.web.csr]]  ^Vt5OrE5fAaQ8\n  - resources: \n    - https://medium.com/walmartglobaltech/the-benefits-of-server-side-rendering-over-client-side-rendering-5d07ff2cefe8\n","n":0.333}}},{"i":1084,"$":{"0":{"v":"Simple Object Access Protocol","n":0.5}}},{"i":1085,"$":{"0":{"v":"Signals","n":1},"1":{"v":"\n- https://dev.to/this-is-learning/the-evolution-of-signals-in-javascript-8ob\n- ","n":0.707}}},{"i":1086,"$":{"0":{"v":"Web Search","n":0.707},"1":{"v":"\n\n\n- [[p.hasSense]] search indexable content across sites ^HxuyfUkt4cMy\n","n":0.354}}},{"i":1087,"$":{"0":{"v":"REST","n":1},"1":{"v":"\n## Architectural Constraints\n\n-   Uniform interface\n-   Client-server\n-   Stateless\n-   Cacheable\n-   Layered system\n-   Code on demand (optional)\n\n## Thoughts\n\n\n\n## Related\n\n- [[t.cs.web.rest.richardson-maturity-model]]\n\n\n## References\n\n- https://restfulapi.net/rest-architectural-constraints/","n":0.229}}},{"i":1088,"$":{"0":{"v":"Richardson Maturity Model","n":0.577}}},{"i":1089,"$":{"0":{"v":"Now Page","n":0.707},"1":{"v":"\n- attributed-to: @derek-sivers\n\n## Examples\n\n- [[now]]\n\n## References\n\n- https://nownownow.com/about\n","n":0.378}}},{"i":1090,"$":{"0":{"v":"Jungle","n":1},"1":{"v":"\n- unlike a [[t.cs.web.digital-garden]], a digital jungle is a poorly-tended, rampant collection of notes, usually for personal use, i.e., not fit for public consumption. \n- note quality varies; most notes are stubs with no development; other notes are overgrown or weeds from other places","n":0.151}}},{"i":1091,"$":{"0":{"v":"Ietf","n":1}}},{"i":1092,"$":{"0":{"v":"Rfc5988 Web Linking","n":0.577},"1":{"v":"\n\r\n- [[p.similarTo]] \r\n\r\n- [[p.hasSpecification]] https://datatracker.ietf.org/doc/html/rfc5988\r\n\r\n```\r\n Each link in RFC 5988 contains the following properties:\r\n\r\n    1. Target URI: Each link should contain a target Internationalized Resource Identifiers (IRIs). This is represented by the href attribute.\r\n    2. Link relation type: The link relation type describes how the current context (source) is related to the target resource. This is represented by the rel attribute.\r\n    3. Attributes for target IRI: The attributes for a link included hreflang, media, title, and type, and any extension link parameters.\r\n```\r\n","n":0.11}}},{"i":1093,"$":{"0":{"v":"rfc4151-tag-IRI-scheme","n":1},"1":{"v":"\n\n\n- [[p.hasTopic]] [[t.km.tagging]]\n- [[p.hasSpecification]] https://datatracker.ietf.org/doc/html/rfc4151 #it-is-but-it-isnt\n- [[p.hasAuthor]] @tim-kindberg @sandro-hawke\n\n## Highlights\n\n-   Identifiers are likely to be unique across space and time, and come from a practically inexhaustible supply.\n-   Identifiers are relatively convenient for humans to mint (create), read, type, remember etc.\n-   No central registration is necessary, at least for holders of domain names or email addresses; and there is negligible cost to mint each new identifier.\n-   The identifiers are independent of any particular resolution scheme.\n","n":0.116}}},{"i":1094,"$":{"0":{"v":"rfc3986-URIs","n":1},"1":{"v":"\n\n\n- [[p.hasSpecification]] https://datatracker.ietf.org/doc/html/rfc3986\n","n":0.577}}},{"i":1095,"$":{"0":{"v":"Draft Kelly Json Hal","n":0.5},"1":{"v":"\n\n\n[[p.correspondsTo]] [[prdct.hal]]\n","n":0.707}}},{"i":1096,"$":{"0":{"v":"Identity","n":1}}},{"i":1097,"$":{"0":{"v":"Cloud Infrastructure Entitlement Management","n":0.5}}},{"i":1098,"$":{"0":{"v":"HTML","n":1},"1":{"v":"\n## References\n\n- https://medium.com/coding-beauty/rare-html-tags-e838a5444c40","n":0.577}}},{"i":1099,"$":{"0":{"v":"HATEOAS","n":1},"1":{"v":"\n- related: [[prdct.hal]] [[prdct.json.hyper-schema]]\n\n\n- [[c.Resource.List]] https://restfulapi.net/hateoas/\n    - [[p.hasComment]] \n\n    - > The dynamic example would be when client building the menu based on links returned for the resource. So server (base on user’s authorization) will return only links accessible for the user and client will build the menu dynamically.\n    - > clients needs to know about possible actions, but with hypermedia links they don’t have to know about the business logic. Say you have your typical blog with post resources. Some possible actions might be to like, edit, delete and archive posts. Without links, clients would need to know the business logic about when it is possible to like/edit/delete/archive a certain post resource. With links, the server tells clients what they can do, by providing the corresponding links.\n\n- [[p.hasCriticism]]\n  - https://medium.com/@andreasreiser94/why-hateoas-is-useless-and-what-that-means-for-rest-a65194471bc8\n    - summary: no good server-side frameworks/tools and no good  clients\n\n## Ideas\n\n- could RDFa be used for embedding semantic data? \n  - Apparently\n    - \"When representations are provided in hypertext form with typed relations (using microformats of HTML, RDF in N3 or XML, or even SVG), then automated agents can traverse these applications almost as well as any human. There are plenty of examples in the linked data communities. More important to me is that the same design reflects good human-Web design, and thus we can design the protocols to support both machine and human-driven applications by following the same architectural style.\" [^1]\n\n\n## Implementations\n\n- [[prdct.spring.hateoas]]\n- \n\n\n## Resources\n\n- https://www.kapresoft.com/software/2023/11/09/rest-hateoas-best-practices.html\n- https://www.baeldung.com/spring-hateoas-tutorial mentions [[prdct.spring.hateoas]]\n- https://news.ycombinator.com/item?id=36944686\n- https://unitcoding.com/implementing-hateoas/ mentions [[prdct.riskfirst_hateoas]]\n- https://spring.io/guides/gs/rest-hateoas\n\n## References\n- [[ar.hatoeas-is-for-humans]]\n- https://softwareengineering.stackexchange.com/questions/388325/advantages-of-hateoas-based-restful-service\n\n[^1]: https://webofdata.wordpress.com/2009/12/15/hateos-revisited-rdfa/\n\n","n":0.063}}},{"i":1100,"$":{"0":{"v":"Fetch","n":1}}},{"i":1101,"$":{"0":{"v":"Digital Garden","n":0.707},"1":{"v":"\n## References\n\n- [[c.DigitalGarden]]\n","n":0.577}}},{"i":1102,"$":{"0":{"v":"Client-Side Rendering","n":0.707},"1":{"v":"\n\n\n- ![[Server-Side Rendering|t.cs.web.ssr#^Vt5OrE5fAaQ8]]\n","n":0.577}}},{"i":1103,"$":{"0":{"v":"Content Discovery","n":0.707}}},{"i":1104,"$":{"0":{"v":"Web Browser","n":0.707}}},{"i":1105,"$":{"0":{"v":"Backend as a Service","n":0.5}}},{"i":1106,"$":{"0":{"v":"Ajax","n":1},"1":{"v":"\n\n\n- \"Today we call this Asynchronous JavaScript and XML data exchange “AJAX”, but ironically, AJAX doesn’t typically even use XML anymore. Most of the time, this data is exchanged as JSON, or YAML, HTML or some other format.\" [[p.isHighlightOf]] [[ar.medium.plainenglish.rest-is-dying-get-rid-of-it]]\n","n":0.158}}},{"i":1107,"$":{"0":{"v":"Accessibility","n":1}}},{"i":1108,"$":{"0":{"v":"UI","n":1}}},{"i":1109,"$":{"0":{"v":"Programming Portals","n":0.707},"1":{"v":"\n- [[p.similarTo]] [[t.cs.end-user-programming]]\n- resources:  [[ar.maggieappleton.programming-portals]]","n":0.447}}},{"i":1110,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\n\n[[p.hasSolution]]\n- [[prdct.inquirer]]\n- [[prdct.bandersnatch]]\n- [[prdct.commander]] ","n":0.5}}},{"i":1111,"$":{"0":{"v":"Dynamic Prompts","n":0.707},"1":{"v":"\n- [[prdct.cliffy]]'s version doesn't seem to be dynamic in the sense of client-server dynamic\n","n":0.267}}},{"i":1112,"$":{"0":{"v":"Runtime Environment","n":0.707}}},{"i":1113,"$":{"0":{"v":"Node.js","n":1}}},{"i":1114,"$":{"0":{"v":"Event Loop","n":0.707},"1":{"v":"\n- [[p.hasLearningResource]] https://blog.risingstack.com/node-js-at-scale-understanding-node-js-event-loop/","n":0.577}}},{"i":1115,"$":{"0":{"v":"Recursion","n":1}}},{"i":1116,"$":{"0":{"v":"Tail Call Optimization","n":0.577}}},{"i":1117,"$":{"0":{"v":"Real Time_collaboration","n":0.707}}},{"i":1118,"$":{"0":{"v":"Operational Transformation","n":0.707},"1":{"v":"\n## Implementations\n\n- [[prdct.sharedb]]\n- \n\n\n## References\n\n- https://irisate.com/collaborative-editing-solutions-round-up/","n":0.408}}},{"i":1119,"$":{"0":{"v":"Modeling","n":1}}},{"i":1120,"$":{"0":{"v":"Entity Relationship Diagram","n":0.577},"1":{"v":"\n## Highlights\n\n- \"Strong vs. Weak entities and relationships: Entities can either exist on their own or they can only exist when associated with some other entity type.\"\n\n## Issues \n\n- https://dba.stackexchange.com/questions/197343/entity-relationship-diagrams-identifying-which-way-a-relationship-flows  \n  - (ERD diagrams suck)\n    - also https://stackoverflow.com/questions/15941149/how-we-identify-the-relation-direction-in-an-er-diagram-if-we-use-chens-notation\n  - but then, https://holowczak.com/drawing-entity-relationship-diagrams-with-uml-notation-using-lucidchart/?doing_wp_cron=1684965923.8165609836578369140625\n\n## Resources\n\n- https://stackoverflow.com/questions/38034049/is-optionality-mandatory-optional-and-participation-total-partial-are-same/38035173#38035173\n- https://www.conceptdraw.com/examples/double-line-in-er-diagram-represents","n":0.149}}},{"i":1121,"$":{"0":{"v":"Enhanced Entity Relationship Model","n":0.5},"1":{"v":"\n- #aka EER\n- description: The EER model includes all of the concepts introduced by the ER model. Additionally it includes the concepts of a subclass and superclass (Is-a), along with the concepts of specialization and generalization. Furthermore, it introduces the concept of a union type or category, which represents a collection of objects that is the union of objects of different entity types.","n":0.126}}},{"i":1122,"$":{"0":{"v":"Machine Learning","n":0.707}}},{"i":1123,"$":{"0":{"v":"Deme","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://wiki.opencog.org/w/MOSES_terminology#Deme\n  - #summary \"During the optimization phase, an optimizer algorithm, such as hill-climbing, simulated annealing, or the Bayesian optimization algorithm is used to work with the population, locating the best possible knob settings for the given representation. In practice, in the actual implementation, a deme is just a set of scored instances. This is because all instances in a deme share the same representation, field set and knob mapping.\"\n","n":0.119}}},{"i":1124,"$":{"0":{"v":"Itsm","n":1}}},{"i":1125,"$":{"0":{"v":"IT Asset Discovery","n":0.577}}},{"i":1126,"$":{"0":{"v":"Git","n":1}}},{"i":1127,"$":{"0":{"v":"Rebase","n":1},"1":{"v":"\n## [[p.hasLearningResource]]\n\n- https://www.derekgourlay.com/blog/git-when-to-merge-vs-when-to-rebase/\n","n":0.577}}},{"i":1128,"$":{"0":{"v":"Games","n":1}}},{"i":1129,"$":{"0":{"v":"Deterministic Lockstep","n":0.707},"1":{"v":"\n\n- resources: \n  - https://www.gafferongames.com/post/deterministic_lockstep/\n  - https://news.ycombinator.com/item?id=27253890\n    - \" Floating point issues are thus generally approached by using fixed-point math instead.\"\n","n":0.218}}},{"i":1130,"$":{"0":{"v":"Data","n":1}}},{"i":1131,"$":{"0":{"v":"Structure","n":1}}},{"i":1132,"$":{"0":{"v":"Hitchhiker Tree","n":0.707},"1":{"v":"\n\n\n## Resources\n\n- https://github.com/datacrypt-project/hitchhiker-tree\n","n":0.577}}},{"i":1133,"$":{"0":{"v":"Dbms","n":1}}},{"i":1134,"$":{"0":{"v":"Graph Database","n":0.707},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] GDBMS\n- ","n":0.577}}},{"i":1135,"$":{"0":{"v":"Data Visualization","n":0.707}}},{"i":1136,"$":{"0":{"v":"Vector Embedding","n":0.707}}},{"i":1137,"$":{"0":{"v":"Types","n":1},"1":{"v":"\n\n\ne.g. csv, XML, JSON, blobs, graphs, tables, ERM, metadata\n","n":0.333}}},{"i":1138,"$":{"0":{"v":"Time Travel","n":0.707},"1":{"v":"\n\n\nIn a data context, the ability to view the state of an entire dataset at a particular transaction time (or decision time?). \n\n- [[p.isRelated]] [[t.cs.data.temporality]]\n","n":0.2}}},{"i":1139,"$":{"0":{"v":"Data Temporality","n":0.707},"1":{"v":"\n\n## Assertive Time and Effective Time\n\n- suggested names for transaction time and valid time, where decision time is not used\n- [x] why does transaction time need a period?\n  - if you have a history of transactions, the \"current\" state has no tx-end. old states have a timestamp of when they were superseded. Seems like you could impute an old state's tx-end tho, but I bet for querying, having the tx-end stored is nice.\n  - t.2024.07.12.14 in open-world assumption, or in cases of gaps where a fact gets (soft-)deleted and then re-created\n  - for clarity, perhaps \"record-commissioned-at\" and \"record-decomissioned-at\"\n\n## Decision Time\n\n![[t.cs.data.temporality.decision-time]]\n- t.2024.07.12.14 probably just \"an application time\"\n\n## Completion Time\n\n- just made this up, it's like due date but doesn't have the \"external constraint\" sense \n  - [[p.created]] 2021-10-31\n- applies to intended activity (tasks), goals\n- could sometimes be represented as \"ending instant/period of valid time\"\n- [[idea.defining-done-is-hard]]\n- t.2024.07.12.14 probably just another application time\n\n## Probabilistic Time\n\n- Triangle Distribution\n  - wrong: \"The really nice thing about Triangle distributions is the Mean and the Mode are the same\"\n- \n\n## [[TimeML|prdct.timeml]]\n\n- functionInDocument ::= 'CREATION_TIME' | 'EXPIRATION_TIME' | 'MODIFICATION_TIME' | 'PUBLICATION_TIME' | 'RELEASE_TIME'| 'RECEPTION_TIME' | 'NONE' \n\n## Allen's Interval Algebra\n\n- see [[t.cs.time.allens-interval-algebra]]\n\n## Solutions\n\n- '[of [[prdct.MariaDB]] and [[prdct.Postgres]]], MariaDB supports temporal tables in the core product and sticks to the SQL:2011 standard most closely. I would recommend MariaDB for those interested in temporal tables in existing SQL databases.' [^1]\n- [[prdct.sirixdb]] and [[prdct.xtdb]]\n- [[prdct.TerminusDB]] and [[prdct.Dolt]]\n- [[prdct.strabon]] and [[prdct.allegrograph]]\n\n## Resources\n\n- [[ar.psu.decision-time-in-temporal-databases]]\n- [[ar.au.semantics-of-temporal-models-with-multiple-temporal-dimensions]]\n- https://aclanthology.org/2021.naacl-main.67.pdf\n- [DESIGN AND IMPLEMENTATION OF HLA TIME MANAGEMENT IN THE RTI VERSION F.0](https://www.informs-sim.org/wsc97papers/0373.PDF)\n- https://robinpokorny.medium.com/why-developers-should-stop-using-iso-8601-for-date-time-e6ee5fc8ad87\n- https://medium.com/towards-nesy/temporal-logic-model-checking-cf05fc917688\n- https://herdingcats.typepad.com/my_weblog/2006/02/deterministic_v.html\n  - has a comment preferring PERT (Project Evaluation and Review Technique) distribution: (Min+4*Mode+Max)/6\n- https://en.wikipedia.org/wiki/Allen%27s_interval_algebra\n- [[ar.bitemporal-data-model-making-it-happened-in-postgres]]\n- [^1]: https://www.dolthub.com/blog/2023-08-07-temporal-database/\n- https://blog.podsnap.com/bitemp.html\n- https://realfiction.net/posts/2d-or-bitemporal-historization-a-primer/\n- [[book.bitemporal-data-theory-and-practice]]\n- [[ar.enabling-retroactive-computing-through-event-sourcing]]\n","n":0.06}}},{"i":1140,"$":{"0":{"v":"Valid Time","n":0.707},"1":{"v":"\n\n\n- the period (time range) when a data statement was true/in-scope\n","n":0.302}}},{"i":1141,"$":{"0":{"v":"Transaction Time","n":0.707},"1":{"v":"\n- different_from: [[t.cs.data.temporality.valid-time]]\n\n- sometimes transaction time is a single point (instant): creation\n- sometimes transaction time is a range (interval): from creation until update (valid-in-database) time\n  - valid-in-database end of range is \"NOW\" until update/deletion occurs\n  - if update, the transaction end time should be inferrable (with pretty good accuracy) from creation time for next record\n  - if delete, range seems more practical\n  - in immutable datastores, only delete\n","n":0.121}}},{"i":1142,"$":{"0":{"v":"Retroactive Computing","n":0.707}}},{"i":1143,"$":{"0":{"v":"PERT distribution","n":0.707},"1":{"v":"![](/assets/images/2023-12-20-11-30-05.png)\n\n\nReferences:\n- https://herdingcats.typepad.com/my_weblog/2006/02/deterministic_v.html\n- ","n":0.707}}},{"i":1144,"$":{"0":{"v":"Hybrid Time","n":0.707},"1":{"v":"\n\n\n## Resources\n\n- https://martinfowler.com/articles/patterns-of-distributed-systems/hybrid-clock.html\n- https://learning.oreilly.com/library/view/patterns-of-distributed/9780138222246/ch23.xhtml#ch23lev1sec2","n":0.5}}},{"i":1145,"$":{"0":{"v":"Glocal","n":1},"1":{"v":"\nIn addition to \"instants\" (but should've been called intervals) and \"local times\" (which are really the same, but just displayed in the user's time zone), Glocal time is like \"midnight on New Years\", it's not a single instant, but a set of ahowever-many-time-zones instants. Or \"sunrise\" is actually an infinite number of instants.![](/assets/images/2024-02-07-21-32-38.png)\n\n![](/assets/images/2024-02-07-21-30-14.png)\n\n## References\n\n- https://david-gilbertson.medium.com/the-three-types-of-time-dd67abc8e59d","n":0.135}}},{"i":1146,"$":{"0":{"v":"Decision Time","n":0.707},"1":{"v":"\n- for tri-temporal tables, the decision date will never be after the transaction date, while the valid date might still be arbitrary.\n\n## References\n\n- https://dba.stackexchange.com/questions/116497/interpreting-decision-time-dt-in-temporal-databases\n- https://en.wikipedia.org/wiki/Temporal_database\n- https://www.dolthub.com/blog/2023-08-07-temporal-database/ has a tri-temporal example","n":0.183}}},{"i":1147,"$":{"0":{"v":"Snapshot","n":1},"1":{"v":"\n- in [[t.cs.sd.event-sourcing]], \"snapshots are a write-model optimization\"\n  - https://www.eventstore.com/blog/snapshots-in-event-sourcing","n":0.316}}},{"i":1148,"$":{"0":{"v":"Semantic Layer","n":0.707},"1":{"v":"\n\n- [[p.hasFeature]]\n  - Shared Business Logic\n    - A semantic layer contains the core logic required for business analysis, transforming the underlying data model into familiar business definitions (dimensions, measures, hierarchies) and easy-to-understand terms. It can contain commonly used derived measures, such as year-over-year, month-over-month, month-to-date, etc. Users can directly consume the calculated measures and reuse the semantics in different downstream applications.\n      - [[p.hasSource]] https://kyligence.io/blog/semantic-layer-the-bi-trend-you-dont-want-to-miss-in-2020/\n  - Unified Security Policy\n  - High-Performance Backend Engines \n\n- [[p.hadCallToAction]]\n  -  To unleash the power of Hadoop-based data lakes, a semantic layer is needed, and my challenge to The Apache Software Foundation is to start a semantic layer for Hadoop project that will operationally integrate with Apache’s Hadoop-based data security and governance projects.\n     -  [[p.hasSource]] https://rcgglobalservices.com/making-data-lakes-usable-why-we-need-a-semantic-layer-and-why-it-should-be-open-source/\n\n## [[p.hasSolution]]\n\n- [[prdct.kylin]]\n- [[prdct.kyligence-unified-semantic-layer]]\n- ","n":0.09}}},{"i":1149,"$":{"0":{"v":"Self Sovereign","n":0.707},"1":{"v":"\n\n## References\n\n- https://gobekli.io/navigating-the-digital-evolution-the-journey-of-self-sovereign-data/","n":0.577}}},{"i":1150,"$":{"0":{"v":"Data Science","n":0.707}}},{"i":1151,"$":{"0":{"v":"Data Publication","n":0.707}}},{"i":1152,"$":{"0":{"v":"Probability Claims","n":0.707},"1":{"v":"\n## [[p.supportedBy]]\n\n- [[prdct.arbital]]\n- [[prdct.RDF-star]]","n":0.5}}},{"i":1153,"$":{"0":{"v":"Personal Online Datastore","n":0.577}}},{"i":1154,"$":{"0":{"v":"Open Data","n":0.707},"1":{"v":"\n\n![[t.cs.data.fair#fair-data-vs-open-data]]","n":1}}},{"i":1155,"$":{"0":{"v":"Object Role Modeling","n":0.577},"1":{"v":"\n\n- [[p.hasSolution]] \n  - [[prdct.boston]]\n\n- resources: \n  - https://factengine.ai/index.php/articles/object-role-modeling\n  - http://www.orm.net/\n  - https://towardsdatascience.com/return-clauses-in-natural-language-queries-74a4a2fd53e6\n","n":0.277}}},{"i":1156,"$":{"0":{"v":"Object Relational Mapping","n":0.577}}},{"i":1157,"$":{"0":{"v":"Metadata","n":1}}},{"i":1158,"$":{"0":{"v":"Materialized View","n":0.707},"1":{"v":"\n## Comparisons\n\n### Materialized Views vs Read-Through Cache\n\n-   With the materialized view, there is a principled _translation process_ from the write-optimized data in the log into the read-optimized data in the view. That translation runs in a separate process which you can monitor, debug, scale and maintain independently from the rest of your application. By contrast, in the typical read-through caching approach, the cache management logic is deeply intertwined with the rest of the application, it’s easy to introduce bugs, and it’s difficult to understand what is happening.\n-   A cache is filled on demand when there is a cache miss (so the first request for a given object is always slow). By contrast, a materialized view is _precomputed_, i.e. its entire contents are computed before anyone asks for it — just like a secondary index. This means there is no such thing as a cache miss: if an item doesn’t exist in the materialized view, it doesn’t exist in the database. There is no need to fall back to some kind of underlying database.\n-   Once you have this process for translating logs into views, you have great flexibility to create new views: if you want to present your existing data in some new way, you can simply create a new stream processing job, consume the input log from the beginning, and thus build a completely new view onto all the existing data. (If you think about it, this is pretty much what a database does internally when you create a new secondary index on an existing table.) You can then maintain both views in parallel, gradually move applications to the new view, and eventually discard the old view. No more scary stop-the-world schema migrations.\n-   \n\n## References\n\n- https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/","n":0.059}}},{"i":1159,"$":{"0":{"v":"Linked Data","n":0.707},"1":{"v":"\n## Solutions\n\n- [[prdct.plow]]\n- [[prdct.pylode]]\n- [[prdct.lode]]\n- [[prdct.widoco]]\n\n## Resources\n\n-   [Linked Data Tutorial](http://www4.wiwiss.fu-berlin.de/bizer/pub/linkeddatatutorial/)\n-   [Linked Data Book](http://linkeddatabook.com/editions/1.0/)\n\n## References\n\n- [[prdct.lode]]","n":0.258}}},{"i":1160,"$":{"0":{"v":"Data Labelling","n":0.707}}},{"i":1161,"$":{"0":{"v":"Hypothetical","n":1}}},{"i":1162,"$":{"0":{"v":"FAIR Data","n":0.707},"1":{"v":"\n**Findable**  \nThe first step in (re)using data is to find them. Metadata and data should be easy to find for both humans and computers. Machine-readable metadata are essential for automatic discovery of datasets and services, so this is an essential component of the [FAIRification process](https://www.go-fair.org/fair-principles/fairification-process/).\n\n[**F1**. (Meta)data are assigned a globally unique and persistent identifier](https://www.go-fair.org/fair-principles/fair-data-principles-explained/f1-meta-data-assigned-globally-unique-persistent-identifiers/)\n\n[**F2**. Data are described with rich metadata (defined by R1 below)](https://www.go-fair.org/fair-principles/fair-data-principles-explained/f2-data-described-rich-metadata/)\n\n[**F3**. Metadata clearly and explicitly include the identifier of the data they describe](https://www.go-fair.org/fair-principles/f3-metadata-clearly-explicitly-include-identifier-data-describe/)\n\n[**F4**. (Meta)data are registered or indexed in a searchable resource](https://www.go-fair.org/fair-principles/f4-metadata-registered-indexed-searchable-resource/)\n\n**Accessible**  \nOnce the user finds the required data, she/he/they need to know how they can be accessed, possibly including authentication and authorisation.\n\n[**A1**. (Meta)data are retrievable by their identifier using a standardised communications protocol](https://www.go-fair.org/fair-principles/542-2/)\n\n[**A1.1** The protocol is open, free, and universally implementable](https://www.go-fair.org/fair-principles/a1-1-protocol-open-free-universally-implementable/)\n\n[**A1.2** The protocol allows for an authentication and authorisation procedure, where necessary](https://www.go-fair.org/fair-principles/a1-2-protocol-allows-authentication-authorisation-required/)\n\n[**A2**. Metadata are accessible, even when the data are no longer available](https://www.go-fair.org/fair-principles/a2-metadata-accessible-even-data-no-longer-available/)\n\n**Interoperable**  \nThe data usually need to be integrated with other data. In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing.\n\n[**I1**. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.](https://www.go-fair.org/fair-principles/i1-metadata-use-formal-accessible-shared-broadly-applicable-language-knowledge-representation/)\n\n[**I2**. (Meta)data use vocabularies that follow FAIR principles](https://www.go-fair.org/fair-principles/i2-metadata-use-vocabularies-follow-fair-principles/)\n\n[**I3**. (Meta)data include qualified references to other (meta)data](https://www.go-fair.org/fair-principles/i3-metadata-include-qualified-references-metadata/)\n\n**Reusable**  \nThe ultimate goal of FAIR is to optimise the reuse of data. To achieve this, metadata and data should be well-described so that they can be replicated and/or combined in different settings.\n\n[**R1**. (Meta)data are richly described with a plurality of accurate and relevant attributes](https://www.go-fair.org/fair-principles/r1-metadata-richly-described-plurality-accurate-relevant-attributes/)\n\n[**R1.1**. (Meta)data are released with a clear and accessible data usage license](https://www.go-fair.org/fair-principles/r1-1-metadata-released-clear-accessible-data-usage-license/)\n\n[**R1.2**. (Meta)data are associated with detailed provenance](https://www.go-fair.org/fair-principles/r1-2-metadata-associated-detailed-provenance/)\n\n[**R1.3**. (Meta)data meet domain-relevant community standards](https://www.go-fair.org/fair-principles/r1-3-metadata-meet-domain-relevant-community-standards/)\n\nThe principles refer to three types of entities: data (or any digital object), metadata (information about that digital object), and infrastructure. For instance, principle F4 defines that both metadata and data are registered or indexed in a searchable resource (the infrastructure component).\n\n\n## FAIR Data vs Open Data \n\n- [[t.cs.data.fair]] focuses on the complexity of data collected for research\n- [[t.cs.data.open]] primarily emphasises giving the public access to non-confidential data\n\n## References\n\n- [[ar.fair-versus-open-data-a-comparison-of-objectives]]","n":0.055}}},{"i":1163,"$":{"0":{"v":"DBMS","n":1}}},{"i":1164,"$":{"0":{"v":"DBaaS","n":1}}},{"i":1165,"$":{"0":{"v":"Datacentric","n":1},"1":{"v":"\n## References\n\n- https://nordicapis.com/exploring-the-hidden-powers-of-hypermedia/","n":0.577}}},{"i":1166,"$":{"0":{"v":"Data Mesh","n":0.707},"1":{"v":"\n## [[c.principle]]\n\n- \"domain-driven ownership of data\"\n- \"data as a product\"\n- \"self-serve data platform\"\n- \"federated computational governance\"\n\n\n- resources: \n  - https://github.com/GavinMendelGleason/data_mesh\n  - https://terminusdb.com/blog/knowledge-graph-data-mesh-metaverse-2/\n  - ","n":0.209}}},{"i":1167,"$":{"0":{"v":"Data Centric","n":0.707},"1":{"v":"\n- http://datacentricmanifesto.org/\n\n## Principles\n\n\n1. Data is a key asset of any person, organization, and society.\n2. Data is self-describing and does not rely on an application for interpretation and meaning.\n3. Data is expressed in open, non-proprietary formats.\n4. Access to and security of the data is a responsibility of the enterprise data layer or the personal data vault, and not managed by applications.\n5. Applications are allowed to visit the data, perform their magic and express the results of their process back into the data layer.\n","n":0.11}}},{"i":1168,"$":{"0":{"v":"Data Control Managemen (DCM)","n":0.5},"1":{"v":"\n## Solutions\n\n- [[prdct.ontogen]]\n\n## SCM inadequacy for DCM\n\n### Introducing Ontogen\n\n\"-   Roles: In an SCM, the committer is the crucial role. While SCMs recognize the difference between author and committer, in practice, this is usually of little importance. For a dataset, however, authorship, i.e., the exact source of datasets, is of greater importance, and many other roles are relevant and should be differentiable, such as data processors (people or systems that transform, clean, or enrich raw data), data curators (experts who organize, categorize, and enrich data with metadata), data protection officers, etc.\n-   Lack of metadata: Datasets often require extensive metadata (e.g., origin, license, timestamps) that are not natively supported in SCMs.\n-   Granularity of changes: SCMs often work at the file level, while for datasets, individual records or fields may be relevant.\n-   Database integration: DCMs should ideally be able to interact directly with database systems, which is not provided for in SCMs.\"\n\n\n## References\n\n- https://ontogen.io/introduction/part-1","n":0.081}}},{"i":1169,"$":{"0":{"v":"Collaborative Customer Facing Data","n":0.5},"1":{"v":"\n## Description\n\n**Collaborative:** Users/Customers are likely to be iteratively working with the data that is presented back to them. _“That’s great, but have you got it in blue?”_, that sort of thing. I wrote about iterative AI, \\[[here](https://generativeai.pub/iterative-ai-in-the-generative-age-c697c81fb98b)\\].\n\n**Customer Facing Data:** Our customers are interfacing with our solution because they want something. Maybe their bank balance, maybe legal documents or advice, maybe holiday suggestions or available seats in a cinema. We might think it is our data, but customers want it to be their data. They are only interested in customer facing data, not the data we sell to third parties or hide behind their back. They want service and they want to feel important.\n\n\n![](/assets/images/2024-04-14-16-37-34.png)\n\n## References\n\n- https://victormorgante.medium.com/lets-ditch-rag-f63faed1b96f","n":0.093}}},{"i":1170,"$":{"0":{"v":"Data Catalog","n":0.707},"1":{"v":"\n\n\n## Related\n\n- [[prdct.dcat-data-catalog.v2]]\n","n":0.577}}},{"i":1171,"$":{"0":{"v":"Blocks","n":1},"1":{"v":"- [[c.implementation]]\n  - [[prdct.block-protocol]]\n  - [[prdct.github.blocks]]","n":0.408}}},{"i":1172,"$":{"0":{"v":"5 Star Open Data Model","n":0.447},"1":{"v":"\n- https://5stardata.info/\n- mentions: [[ar.linked-data-basics-for-techies]]\n\n## Examples\n\n- http://www.sparontologies.net/examples#fivestars_1","n":0.408}}},{"i":1173,"$":{"0":{"v":"Blockchain","n":1}}},{"i":1174,"$":{"0":{"v":"Metamask","n":1}}},{"i":1175,"$":{"0":{"v":"Metamask Snaps","n":0.707}}},{"i":1176,"$":{"0":{"v":"Crypto","n":1}}},{"i":1177,"$":{"0":{"v":"Zil","n":1},"1":{"v":"\n\n## Resources\n\n- https://www.reddit.com/r/zilliqa/comments/pj3ngd/time_to_retract_the_idea_that_zilliqas_downtime/\n","n":0.577}}},{"i":1178,"$":{"0":{"v":"Solana","n":1}}},{"i":1179,"$":{"0":{"v":"Polygon","n":1}}},{"i":1180,"$":{"0":{"v":"NEAR","n":1}}},{"i":1181,"$":{"0":{"v":"Mumbai","n":1}}},{"i":1182,"$":{"0":{"v":"Cryptoraiders","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://play.cryptoraiders.xyz\n","n":0.577}}},{"i":1183,"$":{"0":{"v":"Avalanche","n":1},"1":{"v":"\n- [[p.compatibleWith]] [[prdct.ethereum-virtual-machine]]\n- [[p.supports]] [[prdct.solidity]]","n":0.447}}},{"i":1184,"$":{"0":{"v":"Verifiable Random Function","n":0.577},"1":{"v":"\n## Resources\n\n- https://lamasfinance.medium.com/vrf-and-lamas-finances-on-chain-random-solution-on-solana-1c314f09cbca [[org.lamas-finance]]","n":0.5}}},{"i":1185,"$":{"0":{"v":"Stella","n":1}}},{"i":1186,"$":{"0":{"v":"Proof of History","n":0.577},"1":{"v":"\n## References\n\n- https://medium.com/solana-labs/proof-of-history-a-clock-for-blockchain-cf47a61a9274","n":0.577}}},{"i":1187,"$":{"0":{"v":"Indexing","n":1},"1":{"v":"\n## ChatGPT\n\nBlockchain data indexing serves several important purposes in the world of blockchain technology:\n\n    Efficient Data Retrieval: Indexing allows for faster and more efficient data retrieval from the blockchain. Blockchain data is typically stored in a way that makes it secure and immutable but not optimized for quick searching. Indexing structures, like hash tables or search trees, enable users to find specific transactions or data quickly without scanning the entire blockchain.\n\n    Real-time Updates: Indexing systems can continuously update to reflect the latest changes in the blockchain. This is crucial for applications that require real-time access to blockchain data, such as wallets, explorers, and smart contract platforms.\n\n    Querying and Analysis: Blockchain indexing enables sophisticated querying and data analysis. It allows users to extract valuable insights from blockchain data, identify patterns, and conduct audits. This is useful for researchers, analysts, and businesses looking to make data-driven decisions.\n\n    Smart Contract Execution: Many smart contracts need to reference specific data on the blockchain. Indexing provides a way for these contracts to quickly access the data they need to execute their code efficiently.\n\n    User-Friendly Interfaces: Blockchain indexing is often used to create user-friendly interfaces, such as blockchain explorers. These interfaces make it easier for non-technical users to interact with and understand blockchain data. Users can search for transactions, addresses, or tokens and view detailed information without needing in-depth knowledge of blockchain technology.\n\n    Reducing Resource Consumption: Indexing can help reduce the resource consumption required for running a full node. A full node stores the entire blockchain and can be resource-intensive. Indexing allows nodes to serve data more efficiently, making it feasible for more participants to run nodes and contribute to the network's security and decentralization.\n\n    Compatibility with Existing Tools: Many existing software tools, libraries, and APIs rely on indexed blockchain data to interact with blockchains. Indexing ensures compatibility with these tools and allows developers to build on top of blockchain networks.","n":0.056}}},{"i":1188,"$":{"0":{"v":"DAO","n":1},"1":{"v":"\n## Resources\n\n- https://www.alchemy.com/overviews/how-to-use-dao-reputation-tools\n- https://www.alchemy.com/overviews/how-to-use-dao-accounting-tools\n  - [[p.mentioned]] [[prdct.bulla]]","n":0.378}}},{"i":1189,"$":{"0":{"v":"Contracts","n":1}}},{"i":1190,"$":{"0":{"v":"Constellation","n":1}}},{"i":1191,"$":{"0":{"v":"Application","n":1}}},{"i":1192,"$":{"0":{"v":"Service","n":1}}},{"i":1193,"$":{"0":{"v":"Network Serivces","n":0.707}}},{"i":1194,"$":{"0":{"v":"Webapp","n":1}}},{"i":1195,"$":{"0":{"v":"Workflow","n":1},"1":{"v":"\n## Comparisons\n\n### Orchestration/Workflow Engines vs Rules/Process Engines\n\n- Rules Engine: Choose when you need to centralize complex business logic, codify a large set of rules and decisions, and require clarity around why certain decisions are made.\n- Process Engine: Choose when you have structured business processes with well-defined steps and a need for visual process flow representation (BPMN).\n- Orchestration Framework: Use when you need to coordinate activities across multiple microservices, manage long-running processes that span multiple systems, or require fault tolerance and scalability in a distributed environment\n- Rules/process engines are often used for decision automation and process automation within a single application,\n-  orchestration frameworks are more suitable for orchestrating distributed, event-driven workflows involving multiple services or external systems.\n- In practice, these two paradigms can be combined, where orchestration frameworks can leverage rules/process engines for decision-making or process automation within individual tasks or steps of a larger orchestration workflow.\n\n## Resources\n\n- https://github.com/meirwah/awesome-workflow-engines\n","n":0.082}}},{"i":1196,"$":{"0":{"v":"Library","n":1}}},{"i":1197,"$":{"0":{"v":"Web3","n":1}}},{"i":1198,"$":{"0":{"v":"Virtual Worlds","n":0.707},"1":{"v":"\n- type: [[t.storytelling.alternate-reality]]\n\n## Description\n\n- a computer-simulated environment which may be populated by many simultaneous users who can create a personal avatar and independently explore the virtual world, participate in its activities, and communicate with others. These avatars can be textual, graphical representations, or live video avatars with auditory and touch sensations. [^1]\n\n## Comparisons\n\n### virtual worlds vs virtual reality\n\n- \"While classic sensory-imitating virtual reality relies on tricking the perceptual system into experiencing an immersive environment, virtual worlds typically rely on mentally and emotionally engaging content which gives rise to an immersive experience.\" [^1]\n\n## References\n\n[^1]: https://en.wikipedia.org/wiki/Virtual_world","n":0.103}}},{"i":1199,"$":{"0":{"v":"Virtual Reality","n":0.707},"1":{"v":"\n## Comparisons\n\n![[t.cs.virtual-worlds#virtual-worlds-vs-virtual-reality]]\n\n## Implementations\n\n- [[prdct.karaspace]]","n":0.5}}},{"i":1200,"$":{"0":{"v":"VR Training","n":0.707}}},{"i":1201,"$":{"0":{"v":"Version Control","n":0.707}}},{"i":1202,"$":{"0":{"v":"UX Monitoring","n":0.707}}},{"i":1203,"$":{"0":{"v":"Traits","n":1},"1":{"v":"\n- [[p.similarTo]] [[t.cs.sd.mixin]]\n\n## [[p.hadDefinition]]\n\n\"You don't really care for IS-A -- you really only care for BEHAVES-LIKE-A-(in-this-specific-context), so, if you do test, this behaviour is what you should be testing for.\"\n  - @alex-martelli\n\n\"A better, more modern way to implement OOP is using traits.\"\n  - https://itnext.io/straits-9ef2b9a563cd\n\n## [[p.vs]] [[t.cs.sd.mixin]] ^bx54pp894a62\n\n- The main difference between traits and alternative composition techniques such as multiple inheritance and mixins is that upon trait composition, name conflicts (a.k.a. name clashes) should be explicitly resolved by the composer. This is in contrast to mixins and multiple inheritance, which define various kinds of linearization schemes that impose an implicit precedence on the composed entities, with one entity overriding all of the methods of another entity. While such systems often work well in small reuse scenarios, they are not robust: small changes in the ordering of mixins/classes somewhere high up in the inheritance/mixin chain may impact the way name clashes are resolved further down the inheritance/mixin chain. In addition, the linearization imposed by mixins/multiple inheritance precludes a composer to give precedence to both a method m1 from one mixin/class A and a method m2 from another mixin/class B: either all of A's methods take precedence over B, or all of B's methods take precedence over A.\n  - https://github.com/traitsjs/traits.js\n\n## Implementations\n\n- #php has traits with properties\n  - https://stackoverflow.com/questions/47727003/can-traits-have-properties-methods-with-private-protected-visibility-can-tr\n- javascript has traits with symbol:\n  - \"Recent versions of JavaScript (i.e. ECMAScript 6) added a new primitive data type, symbol, which can be used to implement traits effectively. A symbol is basically a unique identifier that can be used as a property and that will never collide with anything else... The standard calls this feature protocol.\"\n    - https://itnext.io/straits-9ef2b9a563cd\n- [[t.cs.languages.gdscript]]\n  - [Add a Trait system for GDScript](https://github.com/godotengine/godot-proposals/issues/6416)\n- scala \n  - but \"Scala supports \"traits\", although these should have been called mixins (there is no explicit conflict resolution).\" \n    - https://github.com/traitsjs/traits.js\n- java\n  - https://dzone.com/articles/definition-of-the-trait-pattern-in-java\n    - http://ageofjava.com/java/Using-Traits-in-Java-8\n  - \n\n- c# has default interface methods, but no fields/data\n\n### c#\n\n- https://www.reddit.com/r/csharp/comments/7uc6dt/ive_created_a_mixin_library_for_c_and_would_like/\n- [[prdct.partial-mixins]]\n","n":0.056}}},{"i":1204,"$":{"0":{"v":"Tracing","n":1}}},{"i":1205,"$":{"0":{"v":"Time","n":1},"1":{"v":"\n## Allen's interval algebra\n\n\n### Implementations\n\n-   [A simple java library implementing the concept of Allen's temporal relations and the path consistency algorithm](https://code.google.com/p/allenintervalrelationships/)\n-   [Java library implementing Allen's Interval Algebra](https://github.com/Breinify/brein-time-utilities) (incl. data and index structures, e.g., [interval tree](https://en.wikipedia.org/wiki/Interval_tree \"Interval tree\"))\n-   [OWL-Time Time Ontology in OWL](https://www.w3.org/TR/owl-time/) an OWL-2 DL ontology of temporal concepts, for describing the temporal properties of resources in the world or described in Web pages.\n-   [GQR](https://github.com/m-westphal/gqr) is a reasoner for Allen's interval algebra (and many others)\n-   [qualreas](https://github.com/alreich/qualreas) is a Python framework for qualitative reasoning over networks of relation algebras, such as RCC-8, Allen's interval algebra, and Allen's algebra integrated with Time Points and situated in either Left- or Right-Branching Time.\n-   [SparQ](https://github.com/dwolter/SparQ) is a reasoner for Allen's interval algebra (and many others)\n-   [EveXL](https://www.metaphorofitself.net/evexl-introduction) is a small domain-specific language for the detection of events that implements the Interval Algebra's operators via ASCII art patterns.","n":0.084}}},{"i":1206,"$":{"0":{"v":"Interval Tree","n":0.707},"1":{"v":"\n## Description\n\n### ChatGPT\n\nAn interval tree is a specialized type of binary search tree that's used to hold intervals and allows for efficiently querying all intervals that overlap with any given interval or point. Here's a bit more about how it works and what it's good for:\nStructure:\n\n    Nodes: Each node in an interval tree stores an interval (e.g., [start, end]) and a reference to the maximum endpoint of any interval stored in the subtree rooted at this node. This helps in efficient searching.\n    Balancing: To ensure efficient operations, the tree is generally kept balanced, often implemented as a red-black tree.\n\nOperations:\n\n    Insertion: You can insert a new interval into the tree, updating the necessary max values.\n    Deletion: You can remove an interval, again adjusting the max values in nodes accordingly.\n    Searching: The primary feature of the interval tree is searching for all intervals that overlap with a given interval or point. This is done by exploring branches of the tree based on comparisons with interval endpoints and the max values in nodes.\n\nUse Cases:\n\n    Computer Graphics: Used for handling overlapping regions in graphics.\n    Genomics: Useful in managing genomic ranges and querying overlaps.\n    Network Scheduling: Helps in managing tasks in time intervals and checking for conflicts.\n\nThis structure is powerful for scenarios where you need to manage and query overlapping segments efficiently, reducing the potential complexity from linear (in naive approaches) to logarithmic with respect to the number of intervals in the tree.","n":0.065}}},{"i":1207,"$":{"0":{"v":"Allens Interval Algebra","n":0.577},"1":{"v":"\n## Features\n\n- 13 base relations capture \n- Allen's interval algebra can be used for the description of both temporal intervals and spatial configurations. For the latter use, the relations are interpreted as describing the relative position of spatial objects.\n","n":0.16}}},{"i":1208,"$":{"0":{"v":"Synthetic Intelligence","n":0.707},"1":{"v":"\n- not human, not thing, not god; but similar","n":0.333}}},{"i":1209,"$":{"0":{"v":"Speech Recognition","n":0.707},"1":{"v":"\ndescription: Many speech recognition applications and devices are available, but the more advanced solutions use AI and machine learning. They integrate grammar, syntax, structure, and ","n":0.2}}},{"i":1210,"$":{"0":{"v":"Diarization","n":1},"1":{"v":"\n- #definition the process of partitioning an audio stream containing human speech into homogeneous segments according to the identity of each speaker","n":0.213}}},{"i":1211,"$":{"0":{"v":"Software Analysis","n":0.707},"1":{"v":"\n\n## Solutions\n\n- [[prdct.moose]]","n":0.577}}},{"i":1212,"$":{"0":{"v":"Simulation","n":1}}},{"i":1213,"$":{"0":{"v":"Simulation Time","n":0.707},"1":{"v":"\n## Resources\n\n- https://support.tetcos.com/support/solutions/articles/14000057035-what-is-simulation-time-\n  - Therefore, simulation time is not allowed to progress during an event, but only between events. In fact, the simulation time is always equal to the time at which the current event occurs. Therefore, simulation time can be viewed as a variable that \"jumps\" to track the time specified for each new event.\n  - Note that when running in \"Emulation mode\" simulation time and wall clock will be exactly synchronized since it involves the transfer of real packets across the virtual network in NetSim.","n":0.107}}},{"i":1214,"$":{"0":{"v":"Stochastic Clock Structure","n":0.577},"1":{"v":"\n\n## Features of Stochastic Clock Structures\n\n- Random Timing Intervals:\n  - The time between events (or ticks) in a stochastic clock is not fixed but follows a specific probability distribution. Common distributions include exponential, Poisson, and Gaussian distributions.\n\n- Markov Processes:\n  - Many stochastic clock models are based on Markov processes, where the probability of transitioning to the next state depends only on the current state and not on the sequence of previous states.","n":0.118}}},{"i":1215,"$":{"0":{"v":"Participatory Simulation","n":0.707}}},{"i":1216,"$":{"0":{"v":"Live Virtual Constructive","n":0.577},"1":{"v":"\n## Wikipedia\n\nThe LVC categories as defined by the United States Department of Defense in the Modeling and Simulation Glossary[2] as follows:\n\n- Live - A simulation involving real people operating real systems. Military training events using real equipment are live simulations. They are considered simulations because they are not conducted against a live enemy.\n- Virtual - A simulation involving real people operating simulated systems. Virtual simulations inject a Human-in-the-Loop into a central role by exercising motor control skills (e.g., flying jet or tank simulator), decision making skills (e.g., committing fire control resources to action), or communication skills (e.g., as members of a C4I team).\n- Constructive - A simulation involving simulated people operating simulated systems. Real people stimulate (make inputs to) such simulations, but are not involved in determining the outcomes. A constructive simulation is a computer program. For example, a military user may input data instructing a unit to move and to engage an enemy target. The constructive simulation determines the speed of movement, the effect of the engagement with the enemy and any battle damage that may occur. These terms should not be confused with specific constructive models such as Computer Generated Forces (CGF), a generic term used to refer to computer representations of forces in simulations that attempts to model human behavior. CGF is just one example model being used in a constructive environment. There are many types of constructive models that involve simulated people operating simulated systems.","n":0.065}}},{"i":1217,"$":{"0":{"v":"Distributed Interactive Simulation","n":0.577},"1":{"v":"\n\n\n- [[p.hasSense]] \n  - IEEE standard for conducting real-time platform-level wargaming across multiple host computers\n    - [[p.correspondsTo]] [[prdct.dis]]\n    - [[p.similarTo]] [[prdct.hla]]\n  - [[p.subClassOf]] [[t.cs.simulation]]\n","n":0.204}}},{"i":1218,"$":{"0":{"v":"Discrete Time Simulation","n":0.577},"1":{"v":"\n- \"In a DTS, simulation time progresses by a fixed amount that can often be selected by simulation engineers.\"\n![](/assets/images/2024-01-29-22-20-37.png)\n\n## Resources\n\n- https://softwaresim.com/blog/introduction-to-discrete-time-simulation/\n- https://www.cs.ucf.edu/~czou/CDA6530-13/DiscreteTime-Simulation.pdf","n":0.213}}},{"i":1219,"$":{"0":{"v":"Discrete Event Simulation","n":0.577},"1":{"v":"\n![[ar.towards-an-ontological-foundation-of-discrete-event-simulation#^f4xouwm2jcoa]]\n\n- In event-based simulation, the entities all run in a single thread. At the time of making a request, the entities provide a callback function that must be invoked when the waiting condition is over. This style of programming is widely used in Graphical User Interface designs where preconfigured callback functions are called by the system when any event of interest occurs (e.g. mouse click).\n- The proponents of process-based programming claim that their design leads to a better readability of code. Whereas the adherents of event-based programming argue that their approach is more structured since the actions for each different kind of events are encapsulated as different functions.\n  - https://simjs.z5.web.core.windows.net/basics.html#basics-design\n\n## NetLogo\n\nDiscrete event scheduling is most useful for models where agents spend a lot of time sitting idle despite knowing when they need to act next. Sometimes in a NetLogo model, you end up testing a certain condition or set of conditions for every agent on every tick (usually in the form of an “ask”), just waiting for the time to be ripe…. this can get cumbersome and expensive. In some models, you might know in advance exactly when a particular agent needs to act. Dynamic scheduling cuts out all of those superfluous tests. The action is performed only when needed, with no condition testing and very little overhead.\n\nFor example, if an agent is a state machine and spends most of the time in the state “at rest” and has a predictable schedule that knows that the agent should transition to the state “awake” at tick 105, then using a dynamic scheduler allows you to avoid code that looks like: “if ticks = 105 [ do-something ]”, which has to be evaluated every tick!\n\nA second common use of discrete event scheduling is when it is important to keep track of exactly when events occur in continuous time, so the simplifying assumption that all events happen only at regular ticks is not appropriate. One classic example is queuing models (e.g., how long customers have to stand in line for a bank teller), which use a continuous random number distribution (e.g., an exponential distribution) to determine when the next agent enters the queue.\n\n\n\n## Resources\n\n- https://softwaresim.com/blog/a-gentle-introduction-to-discrete-event-simulation/\n- [[ar.object-event-modeling-for-des-and-is-engineering]]\n\n## References\n\n- https://ccl.northwestern.edu/netlogo/docs/time.html","n":0.052}}},{"i":1220,"$":{"0":{"v":"ABMS","n":1}}},{"i":1221,"$":{"0":{"v":"Serverless","n":1},"1":{"v":"\n\n\n- [[p.hasSolution]] [[prdct.aws.lambda]]\n","n":0.577}}},{"i":1222,"$":{"0":{"v":"Semantic Web","n":0.707},"1":{"v":"\n- [[p.isRelated]]\n  - [[t.cs.web.w3c.rdf.iri]]\n  - https://en.wikipedia.org/wiki/Semantic_publishing \n    - \"Semantic publication provides a way for computers to understand the structure and even the meaning of the published information, making information search and data integration more efficient\" \n  - [[prdct.linked-data-fragments]]\n  - [[idea.the-semantic-web-is-dead]]\n\n## Philosophy\n\n### Original Vision\n\n- @tim-berners-lee: \"I have a dream for the Web [in which computers] become capable of analyzing all the data on the Web – the content, links, and transactions between people and computers. A \"Semantic Web\", which makes this possible, has yet to emerge, but when it does, the day-to-day mechanisms of trade, bureaucracy and our daily lives will be handled by machines talking to machines. The \"intelligent agents\" people have touted for ages will finally materialize.\"\n\n### Why do we need the semantic web?\n\n- @gavin-mendel-gleason: \"Because distributed, interoperable, well-defined data is literally the most central problem for the current and near-future human economy. Knowledge is power, and distributable, actionable knowledge, creates opportunities and efficiencies impossible without it.\"\n\n## Interesting\n\n### CURIEs\n\n- a CURIE (Compact URI) is a compact representation of a Uniform Resource Identifier (URI). CURIEs are designed to shorten the lengthy URIs often used in Semantic Web technologies, making them more manageable and easier to read. The structure of a CURIE is generally divided into two parts: a prefix and a reference. \n  - e.g.: `foaf:Person`\n\n## Solutions\n\n- [[prdct.swrl]]\n\n### Reasoners\n\n- [[prdct.eye]]\n\n## Issues\n\n- [[ar.ycombinator.the-semantic-web-is-now-widely-adopted]]\n\n### n-ary relationships\n\n- according to [^1], no problem! ^hpcz3e0llqgb\n- according to https://terminusdb.com/blog/graph-fundamentals-part-3-graph-schema-languages/ lots of problems\n  - no closed-world\n  - different meaning for domain and range in rdfs vs owl\n- according to https://www.datasciencecentral.com/why-graphql-will-rewrite-the-semantic-web/\n  - too complex\n  - lack of intrinsic sequencing\n\n\n### sameAs vs exactMatch \n\n- Use owl:sameAs when you are certain that two URIs refer to the same entity in every possible way.\n- Use skos:exactMatch when you want to link concepts that are highly similar or equivalent, especially in the context of knowledge organization and concept mapping, but where there may be some contextual or definitional differences.\n\n### Complexity\n\n- according to [[ar.topquadrant.why-i-dont-use-owl-anymore]], \"I no longer used RDFS/OWL. I now use [[prdct.shacl]] for everything... because I like to keep things as simple as posssible\".\n\n## Resources\n\n- https://www.w3.org/wiki/RdfThesaurus\n- [[book.design-and-implementation-of-ontologies-in-java-and-apache-jena]]\n- [^1]: https://www.w3.org/TR/swbp-n-aryRelations/\n- [[book.foundations-of-semantic-web-technologies]]\n- https://github.com/semantalytics/awesome-semantic-web\n\n## References\n\n- [[ar.a-review-of-the-semantic-web-field]]\n- ","n":0.053}}},{"i":1223,"$":{"0":{"v":"Visualization","n":1},"1":{"v":"\n## References\n\n- [[ar.justin2004.intuitive-graph-viz]]","n":0.577}}},{"i":1224,"$":{"0":{"v":"Temporal Semantic Web","n":0.577},"1":{"v":"\n![](/assets/images/2024-07-10-09-58-55.png)\n\n## References\n\n- [[ar.telicent.4d-ontology]]\n- [[ar.valid-time-rdf]]\n- [[ar.linked-data-and-time-modeling-researcher-life-lines-by-events]]","n":0.447}}},{"i":1225,"$":{"0":{"v":"Singleton Propert","n":0.707},"1":{"v":"\n## Thoughts\n\n- they imply the subject, but seems like it breaks things\n- do you need a new singleton property when the related/meta data changes?\n- doesn't help with n-ary relations\n\n## References\n\n- [[ar.valid-time-rdf#singleton-property]]","n":0.18}}},{"i":1226,"$":{"0":{"v":"Relator","n":1},"1":{"v":"\n- aka: [[Relationship to Entity Conversion|ar.valid-time-rdf#relationship-to-entity-conversion-rec]]\n\n## Features\n\n- allows all n-ary relationships\n  - even so-called unary relationships like \"Dave walked\" can be expressed, e.g.\n```turtle\n:dave-walking a :walking-relationship;\n  :walker :dave;\n  :tense :past-tense\n\n```\n\n## Issues\n\n- \"If modelling relationships as classes is useful, then why not use this pattern for all non-trivial relationships in a model? The main reason is that it causes explosion in the number of terms in a vocabulary, e.g. each predicate is replaced with two predicates and a class. A vocabulary can quickly become unwieldy, so the value of the extra modelling structure needs to be justified with clear requirements for needing the extra complexity. As described here, the primary reason is to qualify the relation.\" \n\n## Implementations\n\n- https://bioportal.bioontology.org/ontologies/GFO?p=classes&conceptid=gfo%3ARelator\n- https://nemo-ufes.github.io/gufo/#Relator\n- https://patterns.dataincubator.org/book/qualified-relation.html\n\n## References\n\n- https://ontouml.readthedocs.io/en/latest/classes/sortals/relator/index.html","n":0.091}}},{"i":1227,"$":{"0":{"v":"Relationship to Entity Conversion","n":0.5},"1":{"v":"\n## Pros\n\n- \"[Object Property] reification technique is extremely useful and we have incorporated it into our practice; nearly every relationship is reified.\n\nThere’s nothing particularly deep about reification. It’s using the standard expressivity of OWL in a repeatable pattern to convey the meaning we want. But it is, again, tedious and error-prone to do manually.\n  - i.e., use [[prdct.opencaesar]]\n\n## Cons\n\n- While N-ary relation approach can be applied to OWL, it would incur overheads. For instance, multiple inverse properties are needed for a N-ary relation. Moreover, the use of cardinality re- strictions becomes limiting on some roles that depend on the class of some other roles [53]\n\n## References\n\n- [[ar.valid-time-rdf]]","n":0.097}}},{"i":1228,"$":{"0":{"v":"Reasoner","n":1},"1":{"v":"\n## Decidability\n\n- [[prdct.owl.dl]] is decidable\n  - \"There are many things systems engineers care about that are beyond the reasoning power of Description Logic. DL reasoners cannot solve differential equations, for example. But a great deal of what we care about, including the structure of systems of differential-algebraic equations can be expressed in assertions about types, properties, and relationships, and OWL reasoning can help us. In these situations we may use a specialized reasoner (e.g., Mathematica) to solve a problem, but a DL-based front end can help us construct the problem efficiently and with confidence in its correctness.\"\n\n## Implementations\n\n### Open-Source\n\n-   [Cwm](https://en.wikipedia.org/wiki/Cwm_(software) \"Cwm (software)\"), a forward-chaining reasoner used for querying, checking, transforming and filtering information. Its core language is RDF, extended to include rules, and it uses RDF/XML or N3 serializations as required.\n-   [Drools](https://en.wikipedia.org/wiki/Drools \"Drools\"), a forward-chaining inference-based rules engine which uses an enhanced implementation of the [Rete algorithm](https://en.wikipedia.org/wiki/Rete_algorithm \"Rete algorithm\").  \n    -   also, [[prdct.drools.swrlapi]]\n-   [Evrete](https://www.evrete.org), a forward-chaining Java rule engine that uses the [Rete algorithm](https://en.wikipedia.org/wiki/Rete_algorithm \"Rete algorithm\") and is compliant with the Java Rule Engine API (JSR 94).\n-   [D3web](https://en.wikipedia.org/wiki/D3web \"D3web\"), a platform for [knowledge-based systems](https://en.wikipedia.org/wiki/Knowledge-based_systems \"Knowledge-based systems\") ([expert systems](https://en.wikipedia.org/wiki/Expert_systems \"Expert systems\")).\n-   [Flora-2](https://en.wikipedia.org/wiki/Flora-2 \"Flora-2\"), an object-oriented, rule-based knowledge-representation and reasoning system.\n-  [[prdct.jena]] [Jena](https://en.wikipedia.org/wiki/Jena_(framework) \"Jena (framework)\"), an open-source semantic-web framework for Java which includes a number of different semantic-reasoning modules.\n-   [NRules](https://github.com/NRules/NRules) a forward-chaining inference-based rules engine implemented in [C#](https://en.wikipedia.org/wiki/C_Sharp_(programming_language) \"C Sharp (programming language)\") which uses an enhanced implementation of the [Rete algorithm](https://en.wikipedia.org/wiki/Rete_algorithm \"Rete algorithm\")\n-   [Prova](https://en.wikipedia.org/wiki/Prova \"Prova\"), a semantic-web rule engine which supports data integration via SPARQL queries and type systems (RDFS, OWL ontologies as type system).\n-   [DIP](https://github.com/kodymoodley/defeasibleinferenceplatform), Defeasible-Inference Platform (DIP) is an [Web Ontology Language](https://en.wikipedia.org/wiki/Web_Ontology_Language \"Web Ontology Language\") reasoner and [Protégé](https://en.wikipedia.org/wiki/Prot%C3%A9g%C3%A9_(software) \"Protégé (software)\") desktop plugin for representing and reasoning with defeasible subsumption.<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"https://en.wikipedia.org/wiki/Semantic_reasoner#cite_note-3\">[3]</a></sup> It implements a [Preferential entailment](https://en.wikipedia.org/wiki/Preferential_entailment \"Preferential entailment\") style of reasoning that reduces to \"classical entailment\" i.e., without the need to modify the underlying decision procedure.\n\n### from awesome-ontology\n\n-   [CEL](https://julianmendez.github.io/cel/) - A lightweight Description Logic (EL+) reasoner for large-scale biomedical ontologies. (Common Lisp+Java)\n-   [ELK](https://github.com/liveontologies/elk-reasoner) - An ontology reasoner that aims to support the OWL 2 EL profile. (Java)\n-   [EYE](https://github.com/josd/eye) - A reasoning engine which performs semibackward chaining and supports Euler paths. (Prolog)\n-   [FaCT++](http://owl.man.ac.uk/factplusplus/) - The new generation of the well-known [FaCT](http://www.cs.man.ac.uk/~horrocks/FaCT) OWL-DL reasoner which uses optimised tableaux algorithms. (C++)\n-   [Flora-2 (Ergo Lite)](http://flora.sourceforge.net/) - A F-logic based reasoning system. (Prolog)\n-   [HyLAR](https://github.com/ucbl/HyLAR-Reasoner) - A rule-based incremental reasoner for the Web. (JavaScript)\n-   [jcel](https://github.com/julianmendez/jcel) - A reasoner for the description logic EL+. (Java)\n-   [Openllet](https://github.com/Galigator/openllet) - An OWL DL reasoner build on top of Pellet 2. (Java)\n-   [OWL-RL](https://github.com/RDFLib/OWL-RL) - A simple implementation of the OWL2 RL Profile, as well as a basic RDFS inference, on top of RDFLib. (Python)\n-   [pyfactxx](https://github.com/tilde-lab/pyfactxx) - Python bindings for upgraded FaCT reasoner and RDFLib integration. (Python/C++)\n-   [Racer](https://www.ifis.uni-luebeck.de/~moeller/racer/) - A knowledge representation system that implements a highly optimized tableau calculus for the description logic SRIQ(D). (Common Lisp+Java)\n-   [Whelk](https://github.com/balhoff/whelk) - A Scala OWL reasoner based on the algorithm implemented in ELK, using immutable data structures.\n\n## References\n\n- https://www.opencaesar.io/blog/2021/06/19/OML-Origin-and-Rationale.html\n- http://owl.cs.manchester.ac.uk/tools/list-of-reasoners/","n":0.045}}},{"i":1229,"$":{"0":{"v":"Punning","n":1},"1":{"v":"\n\n## References\n\n- [[book.semantic-modeling-for-data]]","n":0.577}}},{"i":1230,"$":{"0":{"v":"Owl","n":1},"1":{"v":"\n- see-also: [[prdct.owl]]\n","n":0.577}}},{"i":1231,"$":{"0":{"v":"Rdf Based Semantics","n":0.577},"1":{"v":"\n## References\n\n- https://www.w3.org/TR/owl2-rdf-based-semantics/","n":0.577}}},{"i":1232,"$":{"0":{"v":"Namedindividual","n":1},"1":{"v":"\n- owl:NamedIndividual is used as a declaration. As such, it does not affect reasoning and serves only to check that a particular entity is used in accordance with how it was declared. This is not important much when you use the RDF-based semantics (and in OWL 2 Full, it is the same class as owl:Thing), but OWL 2 DL distinguishes between named (using IRI) and anonymous (using bNode) individuals, and some profiles of it even disallow anonymous individuals completely.\n- Protegé here does its best to ensure that the ontology is acceptable in the various lower profiles, by marking declarations based on the way they are identified, but it is not strictly an error if you do something like _:bnode a owl:NamedIndividual . ‒ you may use that to convey that it really is a proper individual that has an (unknown) IRI, as opposed to an existential quantifier-like notion used by RDFS.\n\n## References\n\n- https://stackoverflow.com/questions/77016188/why-does-prot%C3%A9g%C3%A9-add-owlnamedindividual-as-rdftype-for-each-instance-that-has","n":0.081}}},{"i":1233,"$":{"0":{"v":"Imports","n":1},"1":{"v":"\n## Desiderata\n\n- @pat-hayes: \"7. Include a modern, nuanced version of owl:imports into RDF. Should  \nbe possible to import only a part of a large ontology.\"\n  - t.2024.10.05.07 or coversely, use [[idea.micro-ontologies]]\n\n\n## References\n\n- https://www.w3.org/2007/OWL/wiki/Imports.html especially https://www.w3.org/2007/OWL/wiki/Imports.html#Bijan.27s_Scenario:_Generating_Variants\n- https://lists.w3.org/Archives/Public/semantic-web/2009Nov/0040.html","n":0.167}}},{"i":1234,"$":{"0":{"v":"Functional Syntax","n":0.707},"1":{"v":"\n- https://www.w3.org/TR/owl2-syntax/","n":0.707}}},{"i":1235,"$":{"0":{"v":"Direct Semantics","n":0.707},"1":{"v":"\n- https://www.w3.org/TR/owl2-semantics/ (2012)\n\n## Features\n\n- compatible with the description logic SROIQ\n-  applies to onolotgies that can be expressed in the functional syntax","n":0.218}}},{"i":1236,"$":{"0":{"v":"Semantic Web Ontology","n":0.577}}},{"i":1237,"$":{"0":{"v":"Modular","n":1},"1":{"v":"\n## References\n\n- [[ar.modular-ontology-modeling]]\n- [[ar.bobdc.using-owlincludes]]","n":0.5}}},{"i":1238,"$":{"0":{"v":"Design Patterns","n":0.707},"1":{"v":"\n\n## Highlights\n\n### Resources\n\n- http://ontologydesignpatterns.org/wiki/Community:Proliferation_of_URIs%2C_Managing_Coreference\n- [[book.ontology-engineering-with-ontology-design-patterns-foundations-and-applications]]\n- ","n":0.447}}},{"i":1239,"$":{"0":{"v":"N3 Patch","n":0.707},"1":{"v":"\n\n\n## References\n\n- https://solidproject.org/TR/2021/protocol-20211217","n":0.577}}},{"i":1240,"$":{"0":{"v":"N Ary Relationships","n":0.577},"1":{"v":"\n\n## References\n\n- [[ar.a-reusable-ontology-for-fluents-in-owl#^t9qzkemy80rd]]\n- [[ar.annotated-hypergraphs-models-and-applications]]\n- [[ar.arxiv.semantic-hypergraphs]]\n- [[ar.linked-data-and-time-modeling-researcher-life-lines-by-events#n-ary-relations]]\n- [[ar.representing-time-in-rdf#approach-4-n-ary-relations]]","n":0.378}}},{"i":1241,"$":{"0":{"v":"Literal Proxy","n":0.707},"1":{"v":"\n## References\n\n- [[pub.question-log.2024.09.05.saying-things-about-literals]]","n":0.577}}},{"i":1242,"$":{"0":{"v":"Linked Data Platform","n":0.577},"1":{"v":"\n- similar: [[prdct.linked-data-templates]]\n\n## Features\n\n- Trellis does not do everything. There will naturally be a desire to make use of external systems, such as a search engine or a triple store. Trellis makes it easy to support real-time integrations of such external components by publishing a notification every time a resource is added, modified or deleted. These notifications conform to the Activity Streams 2.0 specification.\n\n## Resources\n\n- https://www.w3.org/TR/ldp-primer/\n\n## References\n\n- [[ar.medium.linked-data-uptake]]\n- https://www.w3.org/TR/ldp/","n":0.12}}},{"i":1243,"$":{"0":{"v":"Dataset","n":1},"1":{"v":"\n## void vs dcat\n\n\n\n\n## References\n\n![[prdct.void-vocabulary-of-interlinked-datasets#^2i30z3o7shd9]]\n\n\n","n":0.447}}},{"i":1244,"$":{"0":{"v":"Data Cube","n":0.707},"1":{"v":"\n- https://www.w3.org/TR/vocab-data-cube/\n\n## References\n\n- [[ar.w3.vocab-data-cube]]","n":0.5}}},{"i":1245,"$":{"0":{"v":"Class","n":1},"1":{"v":"\n- A class is specified as an instance of\nrdfs:Class (or any of its subclasses like\nowl:Class) using the object property rdf:type\n(abbreviated in Turtle with a), e.g., `:Species a rdfs:Class.` ^6ij3g83vefyj\n\n\n## References\n\n[[ar.an-extensible-approach-to-multi-level-ontology-modelling]]","n":0.183}}},{"i":1246,"$":{"0":{"v":"Class as Values","n":0.577},"1":{"v":"\n## References\n\n- [[ar.representing-classes-as-property-values-on-the-semantic-web]]","n":0.577}}},{"i":1247,"$":{"0":{"v":"Aspect Classes","n":0.707},"1":{"v":"\n- intrinsic non-sortal?\n  - @chatgpt: \"Aspects are a specific type of non-sortal that represent intrinsic properties or features of individuals that can be perceived and measured but do not provide a principle of identity on their own. They characterize individuals but do not define what the individuals fundamentally are.\"\n- in [[prdct.ontouml]], mode and quality are aspects\n  - mode (aka intrinsic modes?): unstructured, (are not given values?) e.g. intention, hole, disease, ability\n  - quality: structured","n":0.116}}},{"i":1248,"$":{"0":{"v":"Axiomatization","n":1}}},{"i":1249,"$":{"0":{"v":"Security","n":1}}},{"i":1250,"$":{"0":{"v":"Zero Trust Network Access","n":0.5}}},{"i":1251,"$":{"0":{"v":"Workload Security","n":0.707}}},{"i":1252,"$":{"0":{"v":"Vulnerability Management","n":0.707}}},{"i":1253,"$":{"0":{"v":"User and Entity Behavior Analytics","n":0.447}}},{"i":1254,"$":{"0":{"v":"User and Behavior Analysis","n":0.5}}},{"i":1255,"$":{"0":{"v":"SIEM","n":1},"1":{"v":"\n- [[p.pronounced]] \"sims\"\n- ","n":0.577}}},{"i":1256,"$":{"0":{"v":"Security Operations Center","n":0.577},"1":{"v":"\n- [[p.hadDefinition]]\n  - a combination of people, processes, automation, and technology protecting the information systems of an organization through proactive design and configuration, ongoing monitoring of normal system and user state, the research and implementation of adversary-aligned defensive capabilities, detection of unintended actions or undesirable state, minimizing damage.\n  - ","n":0.143}}},{"i":1257,"$":{"0":{"v":"Security Awareness Training","n":0.577}}},{"i":1258,"$":{"0":{"v":"Secure Web Gateway","n":0.577}}},{"i":1259,"$":{"0":{"v":"Risk Management","n":0.707}}},{"i":1260,"$":{"0":{"v":"Prioritization","n":1}}},{"i":1261,"$":{"0":{"v":"Penetration Testing","n":0.707}}},{"i":1262,"$":{"0":{"v":"Object Capability Model","n":0.577},"1":{"v":"\n\n- resources: \n  - https://decentralized-id.com/web-standards/object-capabilities/\n\n\n[[c.implementation]]\nNotable research and commercial systems employing capability-based security include the following:\n\n-   [Tahoe-LAFS](https://en.wikipedia.org/wiki/Tahoe-LAFS \"Tahoe-LAFS\"), an open-source capability-based filesystem\n-   [GNOSIS](https://en.wikipedia.org/wiki/GNOSIS \"GNOSIS\"), an operating system developed at [Tymshare](https://en.wikipedia.org/wiki/Tymshare \"Tymshare\")\n    -   [KeyKOS](https://en.wikipedia.org/wiki/KeyKOS \"KeyKOS\"), successor to GNOSIS\n        -   EROS, The [Extremely Reliable Operating System](https://en.wikipedia.org/wiki/Extremely_Reliable_Operating_System \"Extremely Reliable Operating System\"), successor to KeyKOS\n            -   [CapROS](https://en.wikipedia.org/wiki/CapROS \"CapROS\"), a project to further develop the EROS code base for commercial use\n-   [Cambridge CAP computer](https://en.wikipedia.org/wiki/Cambridge_CAP_computer \"Cambridge CAP computer\")\n-   [Hydra (operating system)](https://en.wikipedia.org/wiki/Hydra_(operating_system) \"Hydra (operating system)\"), part of the [C.mmp](https://en.wikipedia.org/wiki/C.mmp \"C.mmp\") project at [Carnegie Mellon University](https://en.wikipedia.org/wiki/Carnegie_Mellon_University \"Carnegie Mellon University\")\n-   StarOS, part of the CM\\* project at [Carnegie Mellon University](https://en.wikipedia.org/wiki/Carnegie_Mellon_University \"Carnegie Mellon University\")\n-   IBM [System/38](https://en.wikipedia.org/wiki/System/38 \"System/38\") and [AS/400](https://en.wikipedia.org/wiki/AS/400 \"AS/400\")\n-   [Intel iAPX 432](https://en.wikipedia.org/wiki/Intel_iAPX_432 \"Intel iAPX 432\")\n-   [Plessey System 250](https://en.wikipedia.org/wiki/Plessey_250 \"Plessey 250\")\n-   [Flex](https://en.wikipedia.org/wiki/Flex_machine \"Flex machine\")\n-   [L4 microkernel family](https://en.wikipedia.org/wiki/L4_microkernel_family \"L4 microkernel family\"):\n    -   OKL4 from Open Kernel Labs\n    -   seL4 from NICTA\n    -   Fiasco.OC and NOVA from [TU Dresden](https://en.wikipedia.org/wiki/TU_Dresden \"TU Dresden\")\n-   [Amoeba](https://en.wikipedia.org/wiki/Amoeba_(operating_system) \"Amoeba (operating system)\") distributed operating system\n-   [FreeBSD](https://en.wikipedia.org/wiki/FreeBSD \"FreeBSD\") [Capsicum](https://en.wikipedia.org/wiki/Capsicum_(Unix) \"Capsicum (Unix)\")[\\[3\\]](https://en.wikipedia.org/wiki/Capability-based_security#cite_note-3)[\\[4\\]](https://en.wikipedia.org/wiki/Capability-based_security#cite_note-4)\n-   [Genode](https://en.wikipedia.org/wiki/Genode \"Genode\")[\\[5\\]](https://en.wikipedia.org/wiki/Capability-based_security#cite_note-5)\n-   [Google Fuchsia](https://en.wikipedia.org/wiki/Google_Fuchsia \"Google Fuchsia\")[\\[6\\]](https://en.wikipedia.org/wiki/Capability-based_security#cite_note-6)\n-   [WebAssembly](https://en.wikipedia.org/wiki/WebAssembly \"WebAssembly\") System Interface (WASI)\n","n":0.076}}},{"i":1263,"$":{"0":{"v":"It Asset Discovery","n":0.577}}},{"i":1264,"$":{"0":{"v":"Cyber Risk","n":0.707}}},{"i":1265,"$":{"0":{"v":"Cyber Risk Prioritization","n":0.577}}},{"i":1266,"$":{"0":{"v":"Cyber Hygiene","n":0.707}}},{"i":1267,"$":{"0":{"v":"Container","n":1}}},{"i":1268,"$":{"0":{"v":"Code Security","n":0.707}}},{"i":1269,"$":{"0":{"v":"Cloud Security Posture Management","n":0.5}}},{"i":1270,"$":{"0":{"v":"Cloud Native Application Protection Platform","n":0.447},"1":{"v":"\n- [[t.cs.security.code-security]]\n- [[t.cs.security.vulnerability-management]]\n- [[t.cs.security.cloud-security-posture-management]]\n- [[t.cs.security.attack-path-analysis]]\n- [[t.cs.security.user-and-entity-behavior-analytics]] / [[t.cs.web.identity.cloud-infrastructure-entitlement-management]]\n- [[t.cs.security.workload-security]]\n- [[t.cs.security.container]]","n":0.316}}},{"i":1271,"$":{"0":{"v":"Charter of Trust","n":0.577},"1":{"v":"\n- protect data\n- prevent damage to people, companies and infrastructure\n- Create a reliable foundation on which confidence in a networked, digital world can take root and grow\n- ","n":0.192}}},{"i":1272,"$":{"0":{"v":"Attack Surface Management","n":0.577}}},{"i":1273,"$":{"0":{"v":"Attack Simulations","n":0.707}}},{"i":1274,"$":{"0":{"v":"Attack Path Analysis","n":0.577}}},{"i":1275,"$":{"0":{"v":"Software Development","n":0.707},"1":{"v":"\n- description: Programming, but also design, architecture, testing, DevOps, processes, and other aspects of producing software-based solutions. \n","n":0.236}}},{"i":1276,"$":{"0":{"v":"Platform","n":1}}},{"i":1277,"$":{"0":{"v":"Dot Net","n":0.707}}},{"i":1278,"$":{"0":{"v":".NET 6","n":0.707}}},{"i":1279,"$":{"0":{"v":"Pattern","n":1}}},{"i":1280,"$":{"0":{"v":"Strategy","n":1},"1":{"v":"\n## Resources\n\n- https://www.sebaslab.com/entity-component-system-design-to-achieve-true-inversion-of-flow-control/\n  - \"The Strategy Pattern is a common pattern used by frameworks to take control of the application code execution, however, the way it’s implemented by game frameworks is slightly different from what we used to read in the design pattern books. Once the strategy interface is provided by the framework layer, the user is expected to implement it and register the implementation with the framework managers.\"\n- ","n":0.12}}},{"i":1281,"$":{"0":{"v":"Reactor","n":1},"1":{"v":"\n## References\n\n- https://en.wikipedia.org/wiki/Reactor_pattern","n":0.577}}},{"i":1282,"$":{"0":{"v":"Expand and Contract","n":0.577},"1":{"v":"\n## References\n\n- https://openpracticelibrary.com/practice/expand-and-contract-pattern/\n- ","n":0.577}}},{"i":1283,"$":{"0":{"v":"Dddhamburger","n":1},"1":{"v":"\n## References\n\n- https://medium.com/@remast/the-ddd-hamburger-for-go-61dba99c4aaf","n":0.577}}},{"i":1284,"$":{"0":{"v":"Blackboard","n":1},"1":{"v":"\n## Resources\n\n- https://social.technet.microsoft.com/wiki/contents/articles/13215.blackboard-design-pattern.aspx\n- https://social.technet.microsoft.com/wiki/contents/articles/13461.blackboard-design-pattern-a-practical-c-example-radar-defence-system.aspx\n- https://medium.com/coinmonks/blackboard-pattern-ed3981551908\n- - [An agent-based blackboard system for multi-objective optimization](https://academic.oup.com/jcde/article/9/2/480/6551194)","n":0.277}}},{"i":1285,"$":{"0":{"v":"Backend for Fronten","n":0.577},"1":{"v":"\n## References\n\n- https://awesome-architecture.com/cloud-design-patterns/bff/","n":0.577}}},{"i":1286,"$":{"0":{"v":"Zombocom Problem","n":0.707},"1":{"v":"\n\n## References\n\n- [[ar.squishy.the-zombocom-problem]]","n":0.577}}},{"i":1287,"$":{"0":{"v":"Utility Class","n":0.707},"1":{"v":"\n- \"Utility classes should be static and stateless. Stateful Utility classes are always a design error.\"\n  - https://www.sebaslab.com/entity-component-system-design-to-achieve-true-inversion-of-flow-control/","n":0.236}}},{"i":1288,"$":{"0":{"v":"Twelve Factor","n":0.707},"1":{"v":"\n- https://12factor.net/\n\n## Summary\n\n## I. Codebase: One codebase tracked in revision control, many deploys\n\n-  there should be a one-to-one correlation between an application and its codebase.\n- If an application consists of multiple repositories (each with a different root commit), it is considered a distributed system rather than a single 12-factor app.\n- To adhere to the 12-factor principles, shared code (common functionality) should be factored into libraries that can be included via a dependency manager.\n\n## II. Dependencies: Explicitly declare and isolate dependencies\n\n\n## III. Config: Store config in the environment\n\n\n## IV. Backing services: Treat backing services as attached resources\n\n\n## V. Build, release, run: Strictly separate build and run stages\n\n\n## VI. Processes: Execute the app as one or more stateless processes\n\n\n## VII. Port binding: Export services via port binding\n\n- The twelve-factor app is completely self-contained and does not rely on runtime injection of a webserver into the execution environment to create a web-facing service.\n\n## VIII. Concurrency: Scale out via the process model\n\n\n## IX. Disposability: Maximize robustness with fast startup and graceful shutdown\n\n\n## X. Dev/prod parity: Keep development, staging, and production as similar as possible\n\n\n## XI. Logs: Treat logs as event streams\n\n\n## XII. Admin processes: Run admin/management tasks as one-off processes","n":0.071}}},{"i":1289,"$":{"0":{"v":"Testing","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] QA; quality assurance\n","n":0.447}}},{"i":1290,"$":{"0":{"v":"Unit Testing","n":0.707}}},{"i":1291,"$":{"0":{"v":"Test Driven Development","n":0.577}}},{"i":1292,"$":{"0":{"v":"Specification (Software Development)","n":0.577}}},{"i":1293,"$":{"0":{"v":"REST","n":1},"1":{"v":"\n- related: [[t.cs.web.hateoas]]\n\n## Issues\n\n- REST API endpoints are fixed. Each endpoint would give you a pre-determined amount of data, irrespective of how much data the client needs. Squeezing efficiency in such a system leads developers to generate an ever-increasing number of endpoints, each returning a contained set of results. The client would then call them in sequence to generate a view for the end-user.\n\n## References\n\n- https://dgraph.io/blog/post/building-native-graphql-database-dgraph/","n":0.123}}},{"i":1294,"$":{"0":{"v":"Requirements","n":1}}},{"i":1295,"$":{"0":{"v":"Polyrepo","n":1},"1":{"v":"\n- aka: multirepo, multi-repo\n\n## Resources\n\n- https://kinsta.com/blog/monorepo-vs-multi-repo/\n\n","n":0.408}}},{"i":1296,"$":{"0":{"v":"Patterns","n":1}}},{"i":1297,"$":{"0":{"v":"Saga","n":1},"1":{"v":"\n- sequence of local transactions","n":0.447}}},{"i":1298,"$":{"0":{"v":"Request Endpoint Response","n":0.577},"1":{"v":"\n## Rationale\n\n### addresses “Swollen Controller Problem.”\n-   **Simplifying Concepts**: It provides a clear structure for REST API endpoints, focusing on the essential components.\n-   **Reducing Controller Complexity**: Unlike traditional MVC controllers, which can become bloated, the REPR pattern encourages smaller controllers dedicated to specific endpoints.\n-   **Enforcing Clarity**: By adhering to the REPR pattern, developers maintain a clear separation of concerns, leading to more maintainable and extensible APIs.\n\n\n## References\n\n- https://blog.stackademic.com/the-repr-pattern-simplifying-api-development-dd58a5be476f","n":0.122}}},{"i":1299,"$":{"0":{"v":"Repository","n":1},"1":{"v":"\n## References\n\n- https://medium.com/@iamprovidence/is-repository-an-anti-pattern-6aba7422fa48\n- https://klaviyo.tech/the-repository-pattern-e321a9929f82","n":0.5}}},{"i":1300,"$":{"0":{"v":"Gateway Aggregation Pattern","n":0.577},"1":{"v":"\n- [aggregates multiple client requests targeting multiple backend services in a single client request, dispatches the requests to various backend services, then aggregates the responses received from all backend services into one response and sends it back to the client](https://learning.oreilly.com/library/view/distributed-net-with/9781801818971/B17740_02_ePub.xhtml#:-:text=aggregates%20multiple%20clien,nds%20it%20back%20to%20the%20client)","n":0.158}}},{"i":1301,"$":{"0":{"v":"Fantastic Nine","n":0.707},"1":{"v":"\n- url: https://www.messagehandler.net/patterns/\n- #creator @yves-goeleven\n  \n![](/assets/images/2023-10-06-13-10-52.png)\n\n## Summary\n\n- Complexity is our enemy\n- Messaging: passing information across time [[t.cs.data.temporality]]\n  - Past: event, fact\n  - Present: state, properties\n  - Future: command, intent\n- system types:\n  - line of business\n  - IoT\n  - [[t.biz.business-intelligence]]\n\n### [[t.cs.sd.patterns.fantastic-nine.aggregate-root-decider]]\n\n![[t.cs.sd.patterns.fantastic-nine.aggregate-root-decider]]\n\n### [[t.cs.sd.patterns.fantastic-nine.task-processing]]\n\n![[t.cs.sd.patterns.fantastic-nine.task-processing]]\n\n### [[t.cs.sd.patterns.fantastic-nine.projection]]\n\n![[t.cs.sd.patterns.fantastic-nine.projection]]\n\n### [[t.cs.sd.patterns.fantastic-nine.reaction]]\n\n![[t.cs.sd.patterns.fantastic-nine.reaction]]\n\n### [[t.cs.sd.patterns.fantastic-nine.delegation]]\n\n![[t.cs.sd.patterns.fantastic-nine.delegation]]\n\n### [[t.cs.sd.patterns.fantastic-nine.event-generator]]\n\n![[t.cs.sd.patterns.fantastic-nine.event-generator]]\n\n### [[t.cs.sd.patterns.fantastic-nine.stream-processing]]\n\n![[t.cs.sd.patterns.fantastic-nine.stream-processing]]\n\n### [[t.cs.sd.patterns.fantastic-nine.downstream-activity]]\n\n![[t.cs.sd.patterns.fantastic-nine.downstream-activity]]\n\n### [[t.cs.sd.patterns.fantastic-nine.state-transformation]]\n\n![[t.cs.sd.patterns.fantastic-nine.state-transformation]]\n\n### Bonus integration styles\n\n- [[t.cs.sd.architecture.orchestration]]\n- [[t.cs.sd.architecture.choreography]]\n\n## Highlights\n\n- focus on information flow over time, not data structure\n- 3 types of information: command, event, state\n- 9 transition patterns\n\n\n## Resources\n\n- https://www.architecture-weekly.com/p/webinar-13-yves-goeleven-the-fantastic","n":0.115}}},{"i":1302,"$":{"0":{"v":"Task Processing","n":0.707},"1":{"v":"\n- used when a command needs to be invoked after a certain condition has become true, but usually only when conditions are not known\n- in many cases, let user invoke the command at the right time\n- in Line of Business applications, this is the only thing the UI is used for\n- when conditions are known / only postponed in time, it can be automated\n- when conditions are comples, background service monitors state until conditions are met","n":0.115}}},{"i":1303,"$":{"0":{"v":"Stream Processing","n":0.707},"1":{"v":"\n- use to filter, count, group, join, or window event streams\n- into a new derived (more meaningful) event\n- needs a standing query engine... i.e., [[prdct.azure.databricks]] or [[prdct.reactivex]]\n- typically followed by a [[t.cs.sd.patterns.fantastic-nine.reaction]]","n":0.177}}},{"i":1304,"$":{"0":{"v":"State Transformation","n":0.707},"1":{"v":"\n- transforms state into report (which is also state, just more high-level) or a different structure (e.g. visual)\n- common method is [[t.cs.sd.patterns.etl]]\n- ","n":0.213}}},{"i":1305,"$":{"0":{"v":"Reaction","n":1},"1":{"v":"\n- invoke an action in response to an event\n- transient: notify a person who may or may not be paying attention\n- guaranteed reaction: obligation to \"perform a command\", use delivery guarantees\n  ","n":0.18}}},{"i":1306,"$":{"0":{"v":"Projection","n":1},"1":{"v":"\n- turn event history into human-readable state\n- same person? on demand.\n- another person? eventual consistency... choose the destination database depending on querying needs","n":0.209}}},{"i":1307,"$":{"0":{"v":"Event Generator","n":0.707},"1":{"v":"\n- typical use is to capture state changes, i.e., sensors\n- virtual event generators can be used to detect changes in databases","n":0.218}}},{"i":1308,"$":{"0":{"v":"Downstream Activity","n":0.707},"1":{"v":"\n- command needs a result\n- low-level, immediate","n":0.378}}},{"i":1309,"$":{"0":{"v":"Delegation","n":1},"1":{"v":"\n- an extension to a LoB system\n- delegate to the pros\n- [[t.cs.sd.patterns.saga]] is a series of delegations","n":0.243}}},{"i":1310,"$":{"0":{"v":"Aggregate Root Decider","n":0.577},"1":{"v":"\n- \"protect the system when taking a meaningful decision\"\n- weird name choice\n- @yves-goeleven doesn't have internal state in his agg roots\n","n":0.218}}},{"i":1311,"$":{"0":{"v":"ETL","n":1}}},{"i":1312,"$":{"0":{"v":"DTO","n":1},"1":{"v":"\n## [[c.analysis]]\n\n- https://learn.microsoft.com/en-us/archive/msdn-magazine/2009/august/pros-and-cons-of-data-transfer-objects","n":0.577}}},{"i":1313,"$":{"0":{"v":"Observability","n":1},"1":{"v":"\n\n- [[p.hasPart]] [[t.cs.logging]]\n\n","n":0.577}}},{"i":1314,"$":{"0":{"v":"Monorepo","n":1},"1":{"v":"\n\n\n\n- [[hasBenefits]] single source of truth (unified versions,simplified dependency managers), large-scale refactoring (atomic changes), better collaboration (less boundaries, wide code visibility, clear tree structure, flexible ownership), and fluid continuous integration and delivery.  ^lvSVpxfF2vnH\n- [[p.hasIssue]] increases the codebase complexity, build time, and effort invested in both code health and tooling. ^OPAsgOm9Zor9\n\n## Javascript Monorepo Tooling\n\n- generally performs three functions:  ^BN4KDj2uWEcE\n  - installer\n  - task-runner\n  - publisher\n\n\n## References\n\n- [[#^lvSVpxfF2vnH]], [[^OPAsgOm9Zor9]] [[p.attributedTo]] https://ageek.dev/monorepo\n- [[#^BN4KDj2uWEcE]] https://dev.to/hipstersmoothie/javascript-monorepo-tooling-48b9\n","n":0.119}}},{"i":1315,"$":{"0":{"v":"Moldable Development","n":0.707},"1":{"v":"\n## Resources\n\n- https://lepiter.io/feenk/teaching-moldable-development-dkbj2hlidhiph2eodusb87ye6/\n\n- [wtf is moldable development](https://blog.container-solutions.com/wtf-is-moldable-development) \n  - Don’t ask “what are the dependencies in my system?” as this is a generic question that makes sense in any system, and hence, has little value. Instead, ask something like: “are there dependencies between these two modules I want to split that do not go through the designated API?” This question is about something contextual (those two modules), it has direct value (you want to split them) and is specifying what is interesting and what is not (API and non-API dependencies).\n- https://www.infoq.com/articles/moldable-development/\n\n## References\n\n- [[t.cs.sd.zombocom-problem]]","n":0.104}}},{"i":1316,"$":{"0":{"v":"Modulith","n":1},"1":{"v":"\n## References\n\n- https://levelup.gitconnected.com/architecture-style-modulith-vs-microservices-90c7c75713db","n":0.577}}},{"i":1317,"$":{"0":{"v":"Modeling","n":1},"1":{"v":"\n- [[c.software.tools.Modeling]]\n\n## Solutions\n\n- [[prdct.cogniam]]\n- [[prdct.likec4]]","n":0.447}}},{"i":1318,"$":{"0":{"v":"Uml","n":1}}},{"i":1319,"$":{"0":{"v":"Class Diagram","n":0.707}}},{"i":1320,"$":{"0":{"v":"Spacetime Diagrams","n":0.707},"1":{"v":"\n- related: [[c.software.visualization.temporal]]","n":0.577}}},{"i":1321,"$":{"0":{"v":"Conceptual Modeling","n":0.707},"1":{"v":"\n- Conceptual modeling is the activity of formally describing some aspects of the physical and social world around us for the purposes of understanding and communication.\n- It is generally considered a fundamental activity in information systems engineering, in which a given subject domain is described independently of specific implementation choices\n\n## References\n\n- [[ar.multi-level-ontology-based-conceptual-modeling]]","n":0.139}}},{"i":1322,"$":{"0":{"v":"Ontology-Driven Conceptual Modeling","n":0.577}}},{"i":1323,"$":{"0":{"v":"Model Based Systems Engineering Mbse","n":0.447}}},{"i":1324,"$":{"0":{"v":"Mixin","n":1},"1":{"v":"\n- [[c.comparable]] \n  - [[t.cs.entity-component-system]] [[t.cs.programming.code-reuse]]\n  - [[t.cs.traits]]\n\n## Issues\n\n- where is the data? \n\n## [[p.supportedBy]]\n\n- c# (since C# 8.0, by means of default methods of interfaces), but no data?\n- scala Scala has a rich type system and Traits are a part of it which helps implement mixin behaviour.\n  - but \"Traits are Mixins just with some slightly different properties from a programming language designers point of view like Mixins require [[t.cs.sd.mixin.linearization]] while Traits are flattened and Traits traditionally don’t contain states.\"\n- #rust Rust makes extensive use of mixins via traits. Traits, like in Scala, allow users to implement behaviours for a defined type. They are also used for generics and dynamic dispatch, which allow for types with same traits to be used interchangeably statically or dynamically at runtime respectively\n- java \n  - default methods for interfaces [^1]\n    -  (could work if every actor had a weak dictionary or whatever) \n  - \n- javascript\n  - https://javascript.info/mixins\n```\n// copy the methods\nObject.assign(User.prototype, sayHiMixin);\n```\n\n## c.Implementation\n\n- https://github.com/LokiMidgard/PartialMixins c#\n\n## Resources\n\n- https://stackoverflow.com/questions/255553/is-it-possible-to-implement-mixins-in-c / https://www.c-sharpcorner.com/UploadFile/b942f9/how-to-create-mixin-using-C-Sharp-4-0/\n- https://www.reddit.com/r/csharp/comments/7uc6dt/ive_created_a_mixin_library_for_c_and_would_like/\n- [The Power of Lua and Mixins](https://github.com/a327ex/blog/issues/2) ^wklu5ctv3kui\n- https://stackoverflow.com/questions/28882903/uml-representation-of-php-trait\n\n## References\n\n[^1]: http://hannesdorfmann.com/android/java-mixins/","n":0.075}}},{"i":1325,"$":{"0":{"v":"Linearization","n":1},"1":{"v":"- how a language orders all the (transitively) inherited classes and included modules/mixins/traits","n":0.277}}},{"i":1326,"$":{"0":{"v":"Messaging","n":1},"1":{"v":"\n## Implementations\n\n- [[prdct.masstransit]]\n- [[prdct.dapr]]\n- [[prdct.wolverine]]\n\n## Comparisons\n\n### vs API\n\n- messaging \"shift the concept from client/server pair to a producer/consumer\"\n- Temporal Decoupling\n- Supports a One to Many Semantic\n- Thinking in terms of asynchronous execution is not a natural way for many\n- you can receive messages out of order or multiple copies\n\n## References\n\n[^1]: https://medium.com/better-programming/api-vs-messaging-how-to-choose-which-one-to-use-d6634599d2bd","n":0.14}}},{"i":1327,"$":{"0":{"v":"Messaging Queues","n":0.707},"1":{"v":"\n## Resources\n\n- https://www.baeldung.com/pub-sub-vs-message-queues\n  - Message queues are often used where we want to delegate work from a service. In doing so, we want to ensure that the work is only executed one time.","n":0.174}}},{"i":1328,"$":{"0":{"v":"PubSub","n":1},"1":{"v":"\n## [[p.hasSolution]]\n\n- [[prdct.kafka]] / [[prdct.nats]] / [[prdct.memphis]] / [[prdct.solace]] / [[prdct.pulsar]] / \n- [[prdct.azure.pub-sub]] / [[prdct.gcp.pub-sub]] / [[prdct.aws.sns]] \n- [[prdct.rabbitimq]]\n- [[prdct.socketcluster]]\n\n.","n":0.218}}},{"i":1329,"$":{"0":{"v":"Low Code","n":0.707}}},{"i":1330,"$":{"0":{"v":"Local First","n":0.707},"1":{"v":"\n## References\n\n- [[ar.maggieappleton.home-cooked-software]]","n":0.577}}},{"i":1331,"$":{"0":{"v":"Live Tutorials","n":0.707},"1":{"v":"\n## Resources\n\n- https://medium.com/feenk/live-tutorials-inside-the-ide-b392f15b920b\n  - \"To make IDEs truly integrated, we need to place the creation and consumption of tutorials deeply into their core.\"","n":0.209}}},{"i":1332,"$":{"0":{"v":"Literate Programming","n":0.707},"1":{"v":"\n\n## Solutions\n\n- [[prdct.literatecs]]\n\n## Resources\n\n- https://witheve.com/deepdives/literate.html\n- https://thenewstack.io/why-literate-programming-might-help-you-write-better-code/\n- https://johtela.github.io/LiterateCS/Introduction.html","n":0.378}}},{"i":1333,"$":{"0":{"v":"Interface Definition Language","n":0.577}}},{"i":1334,"$":{"0":{"v":"Interactive Programming","n":0.707},"1":{"v":"\n## Examples\n\n- https://clojure.org/guides/repl/introduction","n":0.577}}},{"i":1335,"$":{"0":{"v":"Home-Cooked Software","n":0.707},"1":{"v":"\n\n## References\n\n- [[ar.maggieappleton.home-cooked-software]]\n- [[ar.home-cooked-app]]\n- ","n":0.5}}},{"i":1336,"$":{"0":{"v":"Feature Slices","n":0.707},"1":{"v":"\n## Code Organization\n\n### By Module/Folder\n\n```\nFeatures/\n├── Users/\n│   ├── GetUsers/\n│   ├── CreateUser/\n│   ├── SetUserActive/\n│   └── ...\n├── Orders/\n│   ├── PlaceOrder/\n│   ├── CancelOrder/\n│   └── ...\n```\n\n### Onion by Module/Folder\n\n```\nMyApplication.sln\n│\n├── Modules/\n│   ├── UsersModule/\n│   │   ├── UsersModule.csproj\n│   │   ├── Domain/\n│   │   │   └── ...\n│   │   ├── Application/\n│   │   │   ├── Services/\n│   │   │   ├── DTOs/\n│   │   │   └── ...\n│   │   └── Infrastructure/\n│   │       ├── Repositories/\n│   │       └── ...\n│   │\n│   ├── OrdersModule/\n│   │   ├── OrdersModule.csproj\n│   │   ├── Domain/\n│   │   │   └── ...\n│   │   ├── Application/\n│   │   │   ├── Services/\n│   │   │   ├── DTOs/\n│   │   │   └── ...\n│   │   └── Infrastructure/\n│   │       ├── Repositories/\n│   │       └── ...\n│   │\n│   └── ...\n│\n└── WebApp/\n    ├── WebApp.csproj\n    ├── Pages/\n    ├── Program.cs\n    └── ...\n```\n\n## References\n\n- https://levelup.gitconnected.com/the-core-question-are-vertical-slices-just-modular-monoliths-9b1ef2358c53","n":0.094}}},{"i":1337,"$":{"0":{"v":"Feature Oriented Development","n":0.577}}},{"i":1338,"$":{"0":{"v":"Feature Flag","n":0.707}}},{"i":1339,"$":{"0":{"v":"Example Driven Development","n":0.577},"1":{"v":"\n- description: Examples offer a simple and direct model of composition that lends itself well both for supporting testing and for enabling prototyping. And when combined with a moldable development environment, examples also serve as units of documentation.","n":0.162}}},{"i":1340,"$":{"0":{"v":"Event Storming","n":0.707},"1":{"v":"\n\n\n## Resources\n\n- [[ar.architecture-weekly.webinar-9-radek-maziarka-modularization]]\n\n## Examples\n\n- [[ar.medium.event-storming-black-magic-or-real]]","n":0.447}}},{"i":1341,"$":{"0":{"v":"Event Sourcing","n":0.707},"1":{"v":"\n- replaying events will produce the most up-to-date state of each entity without necessarily knowing how this state was produced in the first place\n  - [[p.hasSource]] https://opencredo.com/blogs/events-and-commands-two-faces-of-the-same-coin/\n- [[p.couldBeConfusedWith]] \n  - [[t.cs.sd.architecture.cqrs]]\n    - \"Often CQRS is considered an enabler for Event Sourcing\"\n    - ![](/assets/images/2022-11-25-20-12-58.png)\n    - \"commands are external actions while events are internal facts\"\n      - https://opencredo.com/blogs/events-and-commands-two-faces-of-the-same-coin/\n  - [[t.cs.sd.architecture.event-driven]]\n    - \"Should event objects used in the event-sourcing implementation also be directly used for communication? No! When solely depending on events used in the event-sourcing pattern, a direct dependency is created on the application's internal data. By creating a separate contract that represents the exact data change, a direct dependence on the same models is avoided, and internal data models are not leaked.\" ^vnn4oe20j4t5\n      - [[p.hasSource]] [[Event Sourcing versus Event Driven Architecture|ar.medium.event-sourcing-versus-event-driven-architecture]]\n    - \"Event sourcing is a more domain specific pattern. It does not care about any other domains and it does not require an event stream. It’s sole purpose is to store its domain state as a sequence of events. These events are stored to record state changes rather than communicating.\"\n      - [[p.hasSource]] https://jgao.io/post/event-sourcing/\n        - but also says \"any system which uses “event sourcing” as its core mechanics can be seen as also as an event-driven system,\"\n  - [[t.cs.sd.architecture.command-sourcing]]\n  - [[t.cs.sd.architecture.event-streaming]]\n    - \"Event Sourcing is about durable state stored and read as events, and Event Streaming is about moving events from one place to another.\"\n      - https://event-driven.io/en/event_streaming_is_not_event_sourcing/\n\n## [[p.hasRelatedSolution]]\n\n- [[prdct.castore]]\n- [[prdct.eventstoredb]]\n- [[prdct.marten]]\n- [[prdct.eventide]]\n\n## Issues\n\n- \"The external systems that your application communicates with are usually not prepared for event sourcing, so you should be careful when you replay your events... To solve this challenge, you should handle replays in your communication layers!\"\n  - [[p.hasSource]] [[Event Sourcing with Examples Node.js at Scale|ar.risingstack.event-sourcing-with-examples-node-js-at-scale]]\n\n\n## Resources\n\n- https://medium.com/digitalfrontiers/the-good-the-bad-and-the-ugly-how-to-choose-an-event-store-f1f2a3b70b2d\n  - [[p.hasHighlight]]\n    - \"In order to realize ES, the storage solution aka event store must provide capabilities to read all events using sequential reading, to read all events related to a specific entity, and append events to the event store. Additionally, it must provide transactional capabilities when appending multiple events at once and it must be scalable in terms of the total number of events.\"\n- [[Event Sourcing versus Event Driven Architecture|ar.medium.event-sourcing-versus-event-driven-architecture]]\n- [[ar.event-driven.type-script-node-js-event-sourcing]]\n- [[ar.domaincentric.event-sourcing-projections]]\n- [[ar.event-driven.projections-and-read-models-in-event-driven-architecture]]\n- https://github.com/oskardudycz/EventSourcing.NodeJS\n- https://stackoverflow.com/questions/67356709/event-sourcing-and-domain-event\n- https://stackoverflow.com/questions/71083541/event-sourcing-vs-event-driven-architecture-difference\n- https://medium.com/andamp/event-sourcing-with-spring-modulith-2b35b0569dbb\n  - mentions: [[prdct.spring.modulith]]","n":0.052}}},{"i":1342,"$":{"0":{"v":"Projection","n":1},"1":{"v":"\n## [[c.claim]]\n\n###  projection implementations tend to have a couple of moving parts\n\n- A repository that allows to find or store a state\n- A projector that has event handlers that know how to update or create a state\n\n### the only difference between [[t.cs.sd.event-sourcing.projection]] and [[t.cs.sd.ddd.aggregate]] is intent\n\n- Internal aggregate state exists so that we can make a decision if a command should be processed, and if yes then what are the new events that should be persisted (so the C from CQRS). \n- On the other hand projections always answer a question about the facts that already happened to the system (the Q part of CQRS).\n\n## Resources\n\n- [[ar.domaincentric.event-sourcing-projections]]","n":0.097}}},{"i":1343,"$":{"0":{"v":"Event Modeling","n":0.707},"1":{"v":"\n## Solutions\n\n- \n\n## Resources\n\n- [x] https://jeasthamdev.medium.com/event-modeling-by-example-c6a4ccb4ddf6\n- https://eventmodeling.org/posts/event-modeling-cheatsheet/","n":0.378}}},{"i":1344,"$":{"0":{"v":"Domain Driven Design","n":0.577},"1":{"v":"\n## [[c.model]] \n\n-   Entities, which are objects with unique identities that have a lifecycle.\n-   Aggregates, which are clusters of related objects that form a transactional consistency boundary.\n-   Value objects are objects that have no unique identity and are defined by their properties.\n-   Domain services are operations or algorithms that are not specific to any single entity or value object.","n":0.13}}},{"i":1345,"$":{"0":{"v":"Domain Relationships","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://blog.sapiensworks.com/post/2016/08/24/DDD-Relationships\n  - [[p.hasHighlight]] \"Most of the time when people think relationship they use the programmer mindset and they look for: has-a or is-a or parent-child or (worse) one-to-many etc relationships. Which is valid when you write code but absolutely wrong when you do domain modelling.\"","n":0.146}}},{"i":1346,"$":{"0":{"v":"Dev Console","n":0.707},"1":{"v":"\n\n- [[p.hasLearningResource]]\n  - [[course.pluralsight.increase-productivity-add-a-dev-console-to-your-app-with-java-script]]\n","n":0.5}}},{"i":1347,"$":{"0":{"v":"Software Design","n":0.707}}},{"i":1348,"$":{"0":{"v":"Ubiquitous Language","n":0.707}}},{"i":1349,"$":{"0":{"v":"Domain Language","n":0.707}}},{"i":1350,"$":{"0":{"v":"Domain-Driven Design","n":0.707},"1":{"v":"\n\n## References\n\n- [[ar.medium.the-most-common-domain-driven-design-mistake]]\n","n":0.577}}},{"i":1351,"$":{"0":{"v":"Ubiquitous Language","n":0.707}}},{"i":1352,"$":{"0":{"v":"Domain Event","n":0.707},"1":{"v":"\n## [[c.caveat]]\n\n- he use of domain events proper, should be delayed as long as possible, opting instead for a carefully designed aggregate structure and use cases.\n  - https://medium.com/unil-ci-software-engineering/be-careful-with-domain-events-2ef8866f6cd6\n  - https://medium.com/@alexdorand/event-storming-black-magic-or-real-4a7ff000b74c","n":0.183}}},{"i":1353,"$":{"0":{"v":"Bounded Context","n":0.707},"1":{"v":"\n## Resources\n\n- [Can a bounded context be made up of other bounded contexts?](https://softwareengineering.stackexchange.com/questions/379990/can-a-bounded-context-be-made-up-of-other-bounded-contexts)\n  - \"I associate the term domain more with the problem space, more with the business space, and the term bounded context more with the solution space, the automation that we bring to enhance the domain (or make the domain viable).\"\n- https://stackoverflow.com/questions/36329458/ddd-what-is-the-scope-of-the-ubiquitous-language-is-it-domain-or-bounded-conte/36332778#36332778","n":0.136}}},{"i":1354,"$":{"0":{"v":"Aggregate","n":1}}},{"i":1355,"$":{"0":{"v":"Databases","n":1}}},{"i":1356,"$":{"0":{"v":"Time Series","n":0.707}}},{"i":1357,"$":{"0":{"v":"Document Databases","n":0.707}}},{"i":1358,"$":{"0":{"v":"DOD","n":1},"1":{"v":"\n## Resources\n\n- (The Data-Oriented Design Process for Game Development)[https://www.computer.org/csdl/magazine/co/2022/05/09771161/1DeEYnefsoU]\n- https://www.dataorienteddesign.com/dodbook/","n":0.316}}},{"i":1359,"$":{"0":{"v":"Crows Foot Notation","n":0.577},"1":{"v":"\n## References\n\n- https://vertabelo.com/blog/crow-s-foot-notation/","n":0.577}}},{"i":1360,"$":{"0":{"v":"Continuous Integration","n":0.707}}},{"i":1361,"$":{"0":{"v":"Concept Design","n":0.707},"1":{"v":"\n## Summary\n\n###  Stage One: Design = Functionality\n\n### \n\n## Resources\n\n- https://subconscious.substack.com/p/\n\n","n":0.316}}},{"i":1362,"$":{"0":{"v":"Computer Aided Software Engineering","n":0.5},"1":{"v":"\n## \n\n## [[c.software.tools]]\n\n- [[prdct.umple]]\n\n### Comparison\n\n- https://www.ionos.com/digitalguide/websites/web-development/the-best-uml-tools/\n  - [[p.mentioned]]\n    - [[prdct.rational-rhapsody]]\n- https://en.wikipedia.org/wiki/Comparison_of_code_generation_tools\n- [[ar.sciencedirect.a-systematic-comparison-of-roundtrip-software-engineering-approaches-applied-to-uml-class-diagram]]\n","n":0.289}}},{"i":1363,"$":{"0":{"v":"Round Trip","n":0.707},"1":{"v":"\n## [[c.quotes]]\n\n- \"There is no model. Only code. -- Yoda on modeling languages. Actually, its quite the opposite. There is no code, only models.\"\n  - https://wiki.c2.com/?RoundTripEngineering\n\n## [[c.software.tools]]\n\n- [[prdct.magicdraw]]\n- [[prdct.visual-paradigm]]\n- [[prdct.enterprise-architect]]\n- [[prdct.umodel]]\n- [[prdct.modelio]]\n\n## Resources\n\n- [[ar.sciencedirect.a-systematic-comparison-of-roundtrip-software-engineering-approaches-applied-to-uml-class-diagram]]","n":0.171}}},{"i":1364,"$":{"0":{"v":"C4 Model","n":0.707},"1":{"v":"\n- [[p.hasURL]] https://c4model.com/\n\n## Solutions\n  - [[prdct.structurizr]]\n  - [[prdct.c4-plantuml]]\n  - [[prdct.icepanel]]\n  - [[prdct.carbide]]\n  - \n\n- [[p.hasHighlight]]\n  -  To document a library, framework or SDK, you might be better off using something like UML\n  -  Sometimes diagrams work better showing dependency relationships (e.g. uses, reads from, etc), and sometimes data flow (e.g. customer update events) works better.\n     -  most relationships can be expressed either way, and the more explicit you can be, the better. For example, describing a relationship as \"sends customer update events to\" can be more descriptive than simply \"customer update events\". \n-  \n\n## Comparison\n\n![[prdct.ilograph#concrete-vs-abstract-models]]\n\n## Questions \n\n### \"is X a container or a component?\".\n\n## Issues\n\n### Overly-prescriptive abstractions\n\n- using domain-specific abstractions makes more sense than using arbitrary ones. Diagram authors benefit from thinking about each system on its own terms (and in its own terms). Diagram viewers do, too.\n- The top-down, abstraction-first approach of C4 risks focusing too much on a system’s abstractions at the expense of its concrete resources.\n\n\n### Product Selector\n\n- https://c4model.com/ \n\n- resources: \n  - https://alpha2phi.medium.com/code-based-diagramming-6b1bcc732aab\n  - https://c4model.com/\n    - [[p.mentioned]]\n      - [[prdct.model]]\n      - [[prdct.pumla]]\n      - [[prdct.rdb-model]]\n      - \n\n## References\n\n- https://www.ilograph.com/blog/posts/concrete-diagramming-models/\n- https://www.reddit.com/r/softwarearchitecture/comments/16upcj2/dynamic_nested_diagram_for_software_architecture/\n- https://medium.com/nick-tune-tech-strategy-blog/domain-driven-architecture-diagrams-139a75acb578","n":0.074}}},{"i":1365,"$":{"0":{"v":"Business Process Modeling","n":0.577}}},{"i":1366,"$":{"0":{"v":"Barefoot Developers","n":0.707},"1":{"v":"\n- attributed-to: @maggie-appleton\n\n## References\n\n- [[ar.maggieappleton.home-cooked-software]]","n":0.447}}},{"i":1367,"$":{"0":{"v":"Assessment (Software Development)","n":0.577}}},{"i":1368,"$":{"0":{"v":"Architecture","n":1},"1":{"v":"\n\n## Role\n\n- understanding and managing Architectural Drivers: requirements, quality attributes, constraints, and principles\n- designing software\n  - includes technology selection\n- identifying and mitigating technical risks\n- leadership\n- quality assurance   \n\n## vs Design\n\n### @simon-brown\n\n In the real world, the distinction between architecture and design isn’t clear-cut, but this definition does provide us with a basis to think about what might be significant (i.e. “architectural”) in our own software systems. For example, this could include: \n  - The overall shape of the software system (e.g. client-server, web-based, native mobile, distributed, microservices, asynchronous vs synchronous, etc). \n  - The structure of the code inside the various parts of the software system (e.g. whether the code is structured as components, layers, features, ports and adapters, etc). What is “software architecture”? 14 \n  - The choice of technologies (i.e. programming language, deployment platform, etc). \n  - The choice of frameworks (e.g. web MVC framework, persistence/ORM framework, etc). \n  - The choice of design approach/patterns (e.g. the approach to performance, scalability, availability, etc).\n\n## Resources\n\n- https://nikolaschou.medium.com/open-sourcing-software-architecture-models-17b0149ba638 introduces https://www.softwarearchitecturemodels.com\n- https://blog.bitloops.com/over-engineered-todo-app-to-learn-ddd-hexagonal-architecture-cqrs-and-event-sourcing-74b53a6210fc\n\n## References\n\n- [[book.software-architecture-for-developers]]\n- https://chickensoft.games/blog/game-architecture/","n":0.076}}},{"i":1369,"$":{"0":{"v":"Vertical Slice","n":0.707}}},{"i":1370,"$":{"0":{"v":"Togaf","n":1},"1":{"v":"\n\n![](/assets/images/2023-07-25-22-18-22.png)\n\n## Resources\n\n- https://www.cio.com/article/228328/what-is-togaf-an-enterprise-architecture-methodology-for-business.html\n- ","n":0.577}}},{"i":1371,"$":{"0":{"v":"Serverless","n":1},"1":{"v":"\n\n- aka: SAM (AWS)\n\n## Issues\n\n- \"once the rose-tinted sunglasses of the ‘free tier’ come off we all must come to grips with what serverless really is: an attempt to lock in customers to a few proprietary services.\" ^s9iot2yvvndt\n- \"The truth about serverless was that it was never really serverless. It was developing on someone else’s server and that involves risk.\" ^dirgz2zn129f\n\n## References\n\n- [[ar.andrewzuo.a-eulogy-for-serverless]]","n":0.126}}},{"i":1372,"$":{"0":{"v":"Relay Architecture","n":0.707},"1":{"v":"\n![[ar.squishy.natures-many-attempts-to-evolve-a-nostr#^1fayi8skch8g]]","n":1}}},{"i":1373,"$":{"0":{"v":"Pool Architecture","n":0.707},"1":{"v":"\n- related: [[t.cs.sd.architecture.cell]]\n\n## Description\n\n- \"each client runs its dedicated monolith, with reserved infrastructure, allowing you to scale depending on their needs.\"\n\n## References\n\n- https://medium.com/@raphael.moutard/forget-your-microservices-the-unparalleled-benefits-of-pool-architecture-63b462989856","n":0.209}}},{"i":1374,"$":{"0":{"v":"Orchestration","n":1},"1":{"v":"\n![](/assets/images/2023-10-06-14-20-41.png)\n- similar: [[t.cs.workflow]]\n- related: [[t.cs.sd.architecture.choreography]]\n  - but they're not opposites; it's kinda a false distinction. if systems determine their behavior based on messages, and the messages are \"do this by then\", you're getting orchestrated\n\n- \"a dedicated workflow service acts as the central orchestrator, coordinating the various microservices involved in a business process. This service initiates the process flow, manages the sequence of events and service invocations, and handles errors or retries as needed. The orchestration pattern simplifies the development and maintenance of complex event-driven processes while providing better observability and control compared to the choreography pattern.\" ^21ydosqb6dt1\n\n\n## Implementations\n\n- [[prdct.workflow-core]]\n- [[prdct.prefect]]\n- [[prdct.temporal]]\n- [[prdct.infinitic]] pulsar\n- [[prdct.argo.events]] kubernetes\n- [[prdct.flogo]] kafka and pulsar\n- [[prdct.iwf]] Go, requires [[prdct.cadence]]\n\n## Resources\n\n- https://dzone.com/articles/orchestration-pattern-managing-distributed-transac\n  - \"We have designed an appropriate architecture where all services operate within their bounded context. However, we still need a component that is aware of the entire business workflow.\"\n\n## References\n\n- https://gillesbarbier.medium.com/an-easy-path-from-api-based-microservices-to-an-event-driven-architecture-for-improved-reliability-00d7d0bc3828","n":0.083}}},{"i":1375,"$":{"0":{"v":"Onion","n":1}}},{"i":1376,"$":{"0":{"v":"Mvc","n":1},"1":{"v":"\n- [[c.pattern.architecture]]","n":0.707}}},{"i":1377,"$":{"0":{"v":"Monolith","n":1},"1":{"v":"\n- contrast: [[t.cs.sd.architecture.microservices]]\n  \n## References\n\n- https://levelup.gitconnected.com/the-core-question-are-vertical-slices-just-modular-monoliths-9b1ef2358c53","n":0.408}}},{"i":1378,"$":{"0":{"v":"Microservice","n":1},"1":{"v":"\n## Issues\n\n- The benefit, they say, is a separation of concerns. Although it has used many names throughout the years: clean code, single responsibility, modularity, and now ‘microservices’. These were marketed as the future, but it has turned out to be a maintenance nightmare. ^p4h5j6adklcs","n":0.149}}},{"i":1379,"$":{"0":{"v":"Lean","n":1},"1":{"v":"\n## References\n\n- https://medium.com/@aboutcoding/lean-architecture-7393fb48e13a","n":0.577}}},{"i":1380,"$":{"0":{"v":"Inversion of Control","n":0.577},"1":{"v":"\n## description:\n\n- Inversion of Control is a widely-used architectural concept that's one of the distinguishing characteristics of frameworks, as opposed to libraries. Whereas typical flow of control has app-specific code call shared code (in a library), Inversion of Control reverses this relationship, and has shared code (in a framework) call app-specific code instead. \n  - https://forums.coregames.com/t/advanced-code-architecture-for-core-part-3-inversion-of-control-and-script-loading/3202\n\n## Cons\n\n- \"You shouldn’t use an IoC container to develop games\"\n  - https://www.sebaslab.com/entity-component-system-design-to-achieve-true-inversion-of-flow-control/","n":0.121}}},{"i":1381,"$":{"0":{"v":"Hexagon Architecture","n":0.707},"1":{"v":"\n\n- [[c.pattern.architecture]]\n\n## Resources\n\n- https://medium.com/mcdonalds-technical-blog/hexagonal-architectures-the-sequel-073c9ee79385\n- https://lo0o0p.medium.com/my-flavour-of-hexagonal-architecture-ef3f0fb2c92c","n":0.447}}},{"i":1382,"$":{"0":{"v":"Event Streaming","n":0.707},"1":{"v":"\n- https://thenewstack.io/choosing-between-message-queues-and-event-streams/\n- topics: [[t.cs.sd.messaging.queues]] [[t.cs.sd.architecture.event-streaming]]\n\n## Highlights\n\n- events constantly push data into our applications. These applications react, blending streams together, building views, changing state, and moving themselves forward. In the streaming model there is no shared database. The database is the event stream, and the application simply molds it into something new.\n  - In fairness, streaming systems still have database-like attributes such as tables (for lookups) and transactions (for atomicity), but the approach has a radically different feel, more akin to functional or dataflow languages (and there is much cross-pollination between the streaming and functional programming communities).\n\n\n## Solutions\n\n- [[prdct.kafka]]\n- [[prdct.nats.jetstream]]\n- [[prdct.memphis]]\n- \n\n## Comparisons\n\n### Memphis vs Jetstream\n\n\n\n\n## References\n\n- https://pandio.com/event-streams-queues/\n- https://pandio.com/what-is-event-streaming-why-is-it-growing-in-popularity/\n- https://learning.oreilly.com/library/view/designing-event-driven-systems/9781492038252/ch01.html\n- https://thenewstack.io/choosing-between-message-queues-and-event-streams/\n- https://docs.memphis.dev/memphis/memphis-broker/comparisons/nats-vs-memphis\n- https://km.aifb.kit.edu/sites/lodstream/","n":0.094}}},{"i":1383,"$":{"0":{"v":"Event Driven Architecture","n":0.577},"1":{"v":"\n\n## [[p.hadDefinition]]\n\n- \"In an event driven architecture there is no client/server paradigm.\"\n\n### https://www.confluent.io/kafka-summit-san-francisco-2019/building-event-driven-architectures-with-kafka-and-cloud-events/\n\n- event notification\n- event-carried state transfer\n- [[t.cs.sd.event-sourcing]]\n\n\n## Resources \n\n- https://serverlessland.com/event-driven-architecture/visuals #cool\n- https://cloud.google.com/eventarc/docs/event-driven-architectures\n- https://medium.com/geekculture/event-sourcing-versus-event-driven-architecture-753aa5a5d0f6\n  - [[p.hasHighlight]]  ^973t2iqz9www\n    - \"the event is used as a data contract to communicate the information\" \n    - \"The publisher and the consumer must have a common understanding of the message that gets shared.\"\n    - \"Should event objects used in the event-sourcing implementation also be directly used for communication? No! When solely depending on events used in the event-sourcing pattern, a direct dependency is created on the application's internal data. By creating a separate contract that represents the exact data change, a direct dependence on the same models is avoided, and internal data models are not leaked.\"\n- https://thenewstack.io/supercharging-event-driven-integrations-using-apache-kafka-and-triggermesh/\n  - \"The difference between a message and an event can be confusing at first. An event is a notification that a state has changed. A message, however, contains additional information that represents more than just a notification. There is additional data associated with a message. Eventing is like a phone call, but it doesn’t tell you who is on the line or what their message is. A message provides the details of the call — e.g. who called and a transcription of what was discussed.\"\n- https://danieltammadge.com/2021/11/message-brokers-vs-event-brokers/\n  - \"Often people don’t separate brokers, but in the book Building Event-Driven Microservices, the author div\n  - \"I have seen a Kafka being used to send time-sensitive events that needed to be consumed by all running subscribers when a non-log based broker should have been used, such as RabbitMQ, AWS SQS or AWS SNS or even REDIS.\"\n- https://danieltammadge.com/2022/07/why-not-having-a-schema-registry-can-be-a-fatal-mistake-in-event-driven-architecture/\n- https://apisix.apache.org/blog/2022/09/23/build-event-driven-api/\n- https://memphis.dev/blog/why-event-first-programming-changes-everything/ lists benefits of EDA, and has a section on \"When should you use event-driven architecture?\"\n- https://azure.microsoft.com/en-us/blog/events-data-points-and-messages-choosing-the-right-azure-messaging-service-for-your-data/\n  - \"Events largely fall into two big categories: They either hold information about specific actions that have been carried out by the publishing application, or they carry informational data points as elements of a continuously published stream.\"\n- https://serverlessland.com/event-driven-architecture/visuals/document-event-driven-architectures\n  - [[c.mention]] [[prdct.event-catalog]]\n- https://www.architecture-weekly.com/p/architecture-weekly-152-6th-november\n  - https://waswani.medium.com/event-driven-architecture-the-hard-parts-events-vs-messages-0fcfc7243703\n    - \"So there is a concern of sequence in which things need to be executed to meet the business requirement. And also, the producer service must know the target services which need to perform the required action which goes against the principle of Event Driven Architecture. With Events, because all the consumers react in parallel, controlling the sequence is tough. Messages help to achieve this sequential execution when needed.\"\n- [[ar.medium.simpplr-technology.event-driven-architecture-the-hard-parts-should-it-be-event-or-a-message]]\n- [[ar.event-granularity-modelling-events-in-event-driven-applications]]\n- [[ar.medium.exploring-advanced-error-handling-patterns-with-event-driven-architecture-part-i]]\n- [[ar.medium.event-driven-programming-in-simulation-games]]\n\n### [[p.hasLearningResource]]\n\n- [[ar.medium.edge-coders.understanding-node-js-event-driven-architecture]]\n- [[ar.architecture-weekly.inmemory-message-bus-in-typescript]]\n\n","n":0.05}}},{"i":1384,"$":{"0":{"v":"Event Broker","n":0.707},"1":{"v":"\n#aka event streamer, event router\n- [[p.equivalentClass]] [[t.cs.sd.architecture.event-driven.event-broker]]","n":0.378}}},{"i":1385,"$":{"0":{"v":"EBI Architecture","n":0.707},"1":{"v":"\n\n- [[c.pattern.architecture]]\n\n## Resources\n\n- https://herbertograca.com/2017/08/24/ebi-architecture/","n":0.5}}},{"i":1386,"$":{"0":{"v":"Dependency Inversion","n":0.707},"1":{"v":"\n## Summary\n\n- For Flow of Control Dependencies, inject dependencies as interfaces, or abstractions.\n- Ensure the abstractions, or interfaces, are defined in a higher level module and implemented in a lower level module to ensure the Source Code Dependency is Inverted.\n\n## Details\n\n- Flow of Control Dependency — when you are debugging code and the line of execution goes from one project into another project or dll.\n- Source Code Dependency — where one project references another project or dll.\n- We invert a Source Code Dependency when we identify that the rate of change of a project is more than the project that depends on it.\n- an Abstraction is an interface and a Detail is an implementation.\n\n## [[c.conclusion]]\n\n- For Flow of Control Dependencies, inject dependencies as interfaces, or abstractions.\n- Ensure the abstractions, or interfaces, are defined in a higher level module and implemented in a lower level module to ensure the Source Code Dependency is Inverted.\n\n## Resources\n\n- 1: https://medium.com/codex/the-difference-between-dependency-inversion-and-dependency-injection-15935337ca1b\n","n":0.08}}},{"i":1387,"$":{"0":{"v":"DCI Architecture","n":0.707},"1":{"v":"- #creator @trygve-reenskaug\n\n## Resources\n\n- https://en.wikipedia.org/wiki/Data,_context_and_interaction#cite_note-Artima-1","n":0.447}}},{"i":1388,"$":{"0":{"v":"Command Query Responsibility Segregation","n":0.5},"1":{"v":"\n- expressions of intent could also be considered commands\n  - but maybe best to add another layer.\n\n## Resources\n\n- https://medium.com/digitalfrontiers/the-good-the-bad-and-the-ugly-how-to-choose-an-event-store-f1f2a3b70b2d\n- https://betterprogramming.pub/choosing-a-cqrs-architecture-that-works-for-you-02619555b0a0\n- https://betterprogramming.pub/commands-in-an-event-driven-architecture-2b01892bf2dc","n":0.218}}},{"i":1389,"$":{"0":{"v":"Command Sourcing","n":0.707}}},{"i":1390,"$":{"0":{"v":"Clean Architecture","n":0.707},"1":{"v":"\n- [[c.pattern.architecture]]\n\n## Resources\n\n- [[ar.medium.the-clean-architecture-beginner-s-guide]]\n- [[ar.medium.backend-side-architecture-evolution-n-layered-ddd-hexagon-onion-clean-architecture]]","n":0.447}}},{"i":1391,"$":{"0":{"v":"Choreography","n":1},"1":{"v":"\n![](/assets/images/2023-10-06-14-21-19.png)\n\n- harder to reason about, because reactions can happen anywhere in the system\n\n## vs [[t.cs.sd.architecture.orchestration]]\n\n- \"Orchestration is a centralized approach to making all control decisions about interactions between services. Here a central orchestrator service coordinates all of the other services that execute a business transaction or workflow. By contrast, a choreography is a decentralized approach to coordinating this workflow, where each service determines its own behavior based on the messages it receives from other services.\"\n\n\n## Implementations\n\n- [[prdct.masstransit]] c#\n\n## Resources\n\n- https://www.infoworld.com/article/3687638/orchestration-and-choreography-in-net-microservices.html","n":0.112}}},{"i":1392,"$":{"0":{"v":"Cell","n":1},"1":{"v":"\n\n## Description\n\n- \"A cell is a collection of components, grouped from design and implementation into deployment. A cell is independently deployable, manageable, and observable. Components inside the cell can communicate with each other using supported transports for intra-cell communication. External communication must happen through the edge-gateway or proxy, which provides APIs, events, or streams via governed network endpoints using standard network protocols.\n\nA cell can have 1:n components grouped. Components inside the cells are reusable and can instantiate in multiple cells. The cell should document its offers. The capabilities of a cell must be network accessible endpoints. In addition, if the cell needs access to external dependencies, then these must also be exposed as network endpoints through a cell-gateway. These endpoints can expose APIs, events, or streams. Any interfaces that the microservices or serverless components offer that are not made available by the control point should be inaccessible from outside the cell. Every component within the cell should be versioned. The cell should have a name and a version identifier. The versions should change when the cell’s requirements and/or offers change.\"\n\n\n## References\n\n- https://github.com/wso2/reference-architecture/blob/master/reference-architecture-cell-based.md","n":0.074}}},{"i":1393,"$":{"0":{"v":"Bce","n":1},"1":{"v":"\n- [[c.pattern.architecture]]","n":0.707}}},{"i":1394,"$":{"0":{"v":"Backend for Frontend","n":0.577},"1":{"v":"\n## [[p.hasLearningResource]]\n\n- https://samnewman.io/patterns/architectural/bff/\n  - #highlight \"Conceptually, you should think of the user-facing application as being two components - a client-side application living outside your perimeter, and a server-side component (the BFF) inside your perimeter.\"\n- https://www.thoughtworks.com/insights/blog/bff-soundcloud","n":0.171}}},{"i":1395,"$":{"0":{"v":"Architecture Decision Records","n":0.577},"1":{"v":"\n- url: https://adr.github.io/\n- [[p.hasSolution]] [[prdct.madr]]\n\n## Resources\n\n- https://adr.github.io/\n- - https://icepanel.io/blog/2023-03-29-architecture-decision-records-adrs","n":0.333}}},{"i":1396,"$":{"0":{"v":"API First","n":0.707},"1":{"v":"\n## Thoughts\n\n- \"An API-first development approach needs prototype-first thinking\"\n\n## Resources\n\n- https://www.postman.com/api-platform/api-design/\n  - [[p.mentioned]] [[prdct.asyncapi]]\n- https://blog.postman.com/what-is-an-api-first-company/\n- https://blog.postman.com/how-to-improve-api-ecosystem-with-mapping/\n- https://apisyouwonthate.com/blog/api-design-first-vs-code-first/\n  - [[p.mentioned]] [[prdct.stoplight]]\n\n## References\n\n- https://www.wiremock.io/post/an-api-first-development-approach-needs-prototype-first-thinking","n":0.213}}},{"i":1397,"$":{"0":{"v":"Anti Patterns","n":0.707}}},{"i":1398,"$":{"0":{"v":"Integration Database","n":0.707},"1":{"v":"\n## References\n\n- https://martinfowler.com/bliki/IntegrationDatabase.html","n":0.577}}},{"i":1399,"$":{"0":{"v":"A B Testing","n":0.577}}},{"i":1400,"$":{"0":{"v":"Scripting","n":1}}},{"i":1401,"$":{"0":{"v":"Rule Engine","n":0.707},"1":{"v":"\n- [[p.differentFrom]] [[t.cs.workflow]]\n  - https://kissflow.com/workflow/workflow-engine-business-rule-engine-difference/\n- #aka [[c.software.decisionengine]]; Business Rule Management System; \n\n## Implementations\n\n### generic \n\n- [[prdct.aws.emr]] https://aws.amazon.com/blogs/apn/building-an-agile-business-rules-engine-on-aws/\n### java\n\n- [[prdct.drools]]\n\n### c#\n\n- [[prdct.rulesengine]]\n- [[prdct.dmn-engine]]\n- [[prdct.json-rules-engine]]\n- [[prdct.jint]]\n- [[prdct.dmn-engine]]\n## Value Proposition\n\n- Business leaders with subject matter expertise can define and manage their own logic, independent of engineering.\n\n\n## Resources\n\n- https://www.youtube.com/watch?v=_tUzQP3Q0rA\n- https://martinfowler.com/bliki/RulesEngine.html\n- http://coding-time.blogspot.com/2011/07/how-to-implement-rule-engine-in-c.html\n\n### https://www.reddit.com/r/dotnet/comments/vq5280/microsoft_rulesengine_feedback_from_those_that/\n\nsome important caveats with rules engines in general:\n\n1.  Need to be able to resolve conflicting rules in the engine itself - looks like RulesEngine does not natively handle this (not surprised, that's domain-specific.) You need an input validation layer that tells the user that their rule is invalid because it will never produce a successful result.\n2.  Persisting rule state - if you have long-running workflows, i.e. the type that is common with event-sourcing, you have one of two methods for executing domain events against a rules engine: 1. replay all events against the rules engine each time a new event is received or 2. persist the \"completion state\" of each rule each time an event is persisted, and recover that as a separate snapshot. The challenge with the second approach is how you handle updating a rules set - we were able to invalidate individual rules using a hash signature while preserving the output values of rules that were unchanged.\n3.  Adding new rulesets on the fly - if you want the ability to dynamically create new campaigns, you have to decide how you want to handle historical data. In our case, since we were a high volume streaming operation, our choice was to not retroactively apply older events when new rules were added as this would create a \"thundering herd\" problem for us. We only applied new rules to entities that processed new events after the additional rule-based campaigns were defined.\n\n\n## [[p.vs]] [[t.cs.workflow]]\n\n| **Workflow Engine** |  **Business Engine** |\n| --- | --- |\n|    Based on process |    Based on rules |\n| Specific to a workflow | Enterprise specific |\n| A program designed to run workflow instances based on the process model | A program designed to help with complex decision-making |\n| Inherent driving force in an [automated workflow](https://kissflow.com/workflow/workflow-automation/) | Works as a pluggable element that could be separated from the application code |\n| Help with carrying out a business process | Help with creating business knowledge |\n\n\n\n## Implementations\n\n","n":0.052}}},{"i":1402,"$":{"0":{"v":"Dynamic Expressions","n":0.707},"1":{"v":" \n\n## [[prdct.openai]] \n\n\"Dynamic expression support\" in a rules engine refers to the ability of the engine to evaluate and process expressions that are constructed or modified at runtime. In a rules engine context, an expression is a piece of logic or a condition that determines how the engine should behave or make decisions based on the data it processes.\n\nTraditionally, rules engines work with predefined rules and conditions that are usually set up in advance. These rules are often written in a specific language or format, and they dictate how the engine should react to certain inputs or events. However, in some scenarios, it's beneficial to be able to generate or modify these rules dynamically based on changing conditions or user input.\n\nDynamic expression support allows the rules engine to handle situations where the conditions or actions need to be determined on the fly, based on variables, calculations, or user-specific inputs. This can be particularly useful in situations where:\n\n    User Customization: Users might need to customize the behavior of the rules engine based on their specific needs, and they can create or modify rules dynamically.\n\n    Complex Logic: The conditions or actions are complex and need to be generated programmatically rather than being predefined.\n\n    Adaptive Decision Making: The rules need to adapt to changing circumstances or evolving data.\n\n    Runtime Calculations: Rules depend on calculations or data transformations that are determined at runtime.\n\n    Scenario-Specific Rules: Different scenarios require different rules, and these rules are generated based on the context.\n\nIn essence, dynamic expression support empowers the rules engine to be more flexible and versatile in handling various scenarios by allowing the rules themselves to be generated, modified, or adapted dynamically based on real-time conditions and requirements. This can lead to more efficient and responsive decision-making processes.\n","n":0.059}}},{"i":1403,"$":{"0":{"v":"Reactive","n":1},"1":{"v":"\n\n\n- resources:  \n  - https://dev.to/lloyds-digital/comparing-reactivity-models-react-vs-vue-vs-svelte-vs-mobx-vs-solid-29m8\n","n":0.447}}},{"i":1404,"$":{"0":{"v":"Programming","n":1},"1":{"v":"\n\n\nthe art of getting computers to do what they're supposed to do.\n","n":0.289}}},{"i":1405,"$":{"0":{"v":"Functions","n":1}}},{"i":1406,"$":{"0":{"v":"Callbacks","n":1}}},{"i":1407,"$":{"0":{"v":"Arrow functions","n":0.707}}},{"i":1408,"$":{"0":{"v":"Anonymous Functions","n":0.707}}},{"i":1409,"$":{"0":{"v":"Type Providers","n":0.707},"1":{"v":"\n## Resources\n\n- https://github.com/dotnet/csharplang/discussions/236\n  - [[p.mentioned]] [[prdct.dotnet.interactive]]","n":0.408}}},{"i":1410,"$":{"0":{"v":"Temporal Dead Zone","n":0.577},"1":{"v":"\nwhen something is in-scope, but not yet declared","n":0.354}}},{"i":1411,"$":{"0":{"v":"SOLID","n":1},"1":{"v":"\n\n\n\n- [[p.attributedTo]] @robert-martin\n- [[p.hasSummaryPoints]]\n  - The Single-responsibility principle: \"There should never be more than one reason for a class to change.\"[5] In other words, every class should have only one responsibility.[6]\n  - The Open–closed principle: \"Software entities ... should be open for extension, but closed for modification.\"[7]\n  - The [[Liskov substitution principle|t.cs.programming.liskov-substitution-principle]]: \"Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.\"[8] See also design by contract.[8]\n  - The Interface segregation principle: \"Many client-specific interfaces are better than one general-purpose interface.\"[9][4]\n  - The Dependency inversion principle: \"Depend upon abstractions, [not] concretions.\"[10][4]\n","n":0.099}}},{"i":1412,"$":{"0":{"v":"Repl","n":1},"1":{"v":"\n- [[p.hasComparison]] https://softwareengineering.stackexchange.com/questions/168285/difference-between-a-repl-and-interactive-shell\n  -  [[p.hadSummary]] \"If you juggle files and ready-made programs, you're using it as a shell. If you're testing libraries or language semantics, it's a REPL\"","n":0.189}}},{"i":1413,"$":{"0":{"v":"Reflection","n":1},"1":{"v":"\n- the ability of a process to examine, introspect, and modify its own structure and behavior #definition ","n":0.243}}},{"i":1414,"$":{"0":{"v":"Readability","n":1}}},{"i":1415,"$":{"0":{"v":"Programming Patterns","n":0.707}}},{"i":1416,"$":{"0":{"v":"Singleton","n":1},"1":{"v":"\n- \n\n## Java\n\nTo implement a singleton pattern, we have different approaches, but all of them have the following common concepts.\n\n- Private constructor to restrict instantiation of the class from other classes.\n- Private static variable of the same class that is the only instance of the class.\n- Public static method that returns the instance of the class, this is the global access point for the outer world to get the instance of the singleton class.\n\n### 1. Eager initialization\n\nIn eager initialization, the instance of the singleton class is created at the time of class loading. The drawback to eager initialization is that the method is created even though the client application might not be using it.\n\n### 2. Static block initialization \n\nimplementation is similar to eager initialization, except that instance of the class is created in the static block that provides the option for exception handling.\n\n### 3. Lazy Initialization\n\nLazy initialization method to implement the singleton pattern creates the instance in the global access method.\n\n### 4. Thread Safe Singleton\n\nA simple way to create a thread-safe singleton class is to make the global access method synchronized so that only one thread can execute this method at a time.\n\n  - reduces the performance because of the cost associated with the synchronized method, although we need it only for the first few threads that might create separate instances.\n\n### 5. Bill Pugh Singleton Implementation\n\nPrior to Java 5... the previous approaches used to fail in certain scenarios where too many threads tried to get the instance of the singleton class simultaneously. So Bill Pugh came up with a different approach to create the singleton class using an inner static helper class.\n\n### 6. Using Reflection to destroy Singleton Pattern\n\nReflection can be used to destroy all the previous singleton implementation approaches.\n\n### 7. Enum Singleton\n\nTo overcome this situation with Reflection, Joshua Bloch suggests the use of enum to implement the singleton design pattern as Java ensures that any enum value is instantiated only once in a Java program. Since Java Enum values are globally accessible, so is the singleton. The drawback is that the enum type is somewhat inflexible (for example, it does not allow lazy initialization).\n\n### 8. Serialization and Singleton\n\nSometimes in distributed systems, we need to implement Serializable interface in the singleton class so that we can store its state in the file system and retrieve it at a later point in time. Here is a small singleton class that implements Serializable.\n  - The problem with serialized singleton class is that whenever we deserialize it, it will create a new instance of the class.\n  - To overcome this scenario, all we need to do is provide the implementation of readResolve() method.\n\n## References\n\n- https://www.digitalocean.com/community/tutorials/java-singleton-design-pattern-best-practices-examples","n":0.048}}},{"i":1417,"$":{"0":{"v":"Observer","n":1}}},{"i":1418,"$":{"0":{"v":"Loops (Programming)","n":0.707}}},{"i":1419,"$":{"0":{"v":"Logic Programming","n":0.707},"1":{"v":"\n## Resources\n\n- [[course.introduction-to-logic-programming]]","n":0.577}}},{"i":1420,"$":{"0":{"v":"Live Programming","n":0.707},"1":{"v":"\n## Resources\n\n- https://blog.lassus.se/files/liveprogramming.pdf","n":0.577}}},{"i":1421,"$":{"0":{"v":"Liskov Substitution Principle","n":0.577},"1":{"v":"\n- [[p.instanceOf]] [[c.concept]], ","n":0.577}}},{"i":1422,"$":{"0":{"v":"Functional Programming","n":0.707},"1":{"v":"\n## Resources\n\n- https://www.reddit.com/r/gamedev/comments/17jl96h/are_there_game_engines_that_use_a_functional/\n  - mentions [[prdct.nu]]","n":0.408}}},{"i":1423,"$":{"0":{"v":"Fold","n":1},"1":{"v":"\n- [[p.hadDefinition]] https://en.wikipedia.org/wiki/Fold_(higher-order_function)\n  - the order in which the elements are combined may influence the final result's value. On lists, there are two obvious ways to carry this out: either by combining the first element with the result of recursively combining the rest (called a right fold), or by combining the result of recursively combining all elements but the last one, with the last element (called a left fold).\n  - ","n":0.12}}},{"i":1424,"$":{"0":{"v":"Code Reuse","n":0.707}}},{"i":1425,"$":{"0":{"v":"Arrays","n":1}}},{"i":1426,"$":{"0":{"v":"Privacy","n":1}}},{"i":1427,"$":{"0":{"v":"Record of Processing Activity","n":0.5},"1":{"v":"\nRecord of processing activities kept by a data controller should include:  \n  \n\n-   Name and contact details of the data controller.\n    \n-   The purpose of processing the data.\n    \n-   Categories of the data subjects and types of personal data.\n    \n-   Categories of data recipients, including those who have already received a user’s data and those who will receive a user’s data in the future .\n    \n-   Transfers of data to a third country or an international organization.\n    \n-   Time limits for erasure of different categories of data.\n    \n-   A general description of technical and organizational security measures.","n":0.102}}},{"i":1428,"$":{"0":{"v":"Primitive","n":1}}},{"i":1429,"$":{"0":{"v":"OS","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.platform]]\n","n":0.577}}},{"i":1430,"$":{"0":{"v":"Windows","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[t.cs.os]]\n","n":0.577}}},{"i":1431,"$":{"0":{"v":"Mac","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[t.cs.os]]\n","n":0.577}}},{"i":1432,"$":{"0":{"v":"Linux","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[t.cs.os]]\n","n":0.577}}},{"i":1433,"$":{"0":{"v":"Offline First","n":0.707},"1":{"v":"\n- app works \"as well\" when not connected","n":0.354}}},{"i":1434,"$":{"0":{"v":"Object Orientation","n":0.707},"1":{"v":"\n\n## [[c.principle]] \n\n![[Rustconf Talk|ar.rustconf-talk#^hkms0rjrw5lz]]\n\n## Ideas \n\n![[Rustconf Talk|ar.rustconf-talk#^c47v165vrmv6]] \n\n## References  \n\n- [[ar.rustconf-talk]]","n":0.302}}},{"i":1435,"$":{"0":{"v":"Invariant","n":1},"1":{"v":"\n- description: a set of assertions that must always hold true during the life of an object for the program to be valid.\n- eg An example of invariant could be that exactly one of two member variables should be null. Or that if one has a given value, then the set of allowed values for the other is this or that...\n- [[c.pattern]] I sometime use a member function of the object to check that the invariant holds. If this is not the case, an assert is raised. And the method is called at the start and exit of each method that changes the object (in C++, this is only one line...)\n\n## Resources\n\n- https://softwareengineering.stackexchange.com/questions/32727/what-are-invariants-how-can-they-be-used-and-have-you-ever-used-it-in-your-pro","n":0.094}}},{"i":1436,"$":{"0":{"v":"Nlp","n":1},"1":{"v":"\n## Implementations\n\n- [[prdct.corenlp]]\n\n## Resources\n\n\n### https://www.kaggle.com/code/pavansanagapati/knowledge-graph-nlp-tutorial-bert-spacy-nltk\n\n#### Ambiguity and Uncertainty in Language\n\nAmbiguity, generally used in natural language processing, can be referred as the ability of being understood in more than one way. In simple terms, we can say that ambiguity is the capability of being understood in more than one way. Natural language is very ambiguous. NLP has the following types of ambiguities −\n\nLexical Ambiguity\n\nThe ambiguity of a single word is called lexical ambiguity. For example, treating the word silver as a noun, an adjective, or a verb.\n\nSyntactic Ambiguity\n\nThis kind of ambiguity occurs when a sentence is parsed in different ways. For example, the sentence “The man saw the girl with the telescope”. It is ambiguous whether the man saw the girl carrying a telescope or he saw her through his telescope.\n\nSemantic Ambiguity\n\nThis kind of ambiguity occurs when the meaning of the words themselves can be misinterpreted. In other words, semantic ambiguity happens when a sentence contains an ambiguous word or phrase. For example, the sentence “The car hit the pole while it was moving” is having semantic ambiguity because the interpretations can be “The car, while moving, hit the pole” and “The car hit the pole while the pole was moving”.\n\nAnaphoric Ambiguity\n\nThis kind of ambiguity arises due to the use of anaphora entities in discourse. For example, the horse ran up the hill. It was very steep. It soon got tired. Here, the anaphoric reference of “it” in two situations cause ambiguity.\n\nPragmatic ambiguity\n\nSuch kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations like I like you (just like you like me), I like you (just like someone else dose).\n\n\n","n":0.057}}},{"i":1437,"$":{"0":{"v":"Text Graph","n":0.707},"1":{"v":"\n\n\n- [[p.hasConferenceSeries]] [[event.textgraphs-conference]]\n","n":0.577}}},{"i":1438,"$":{"0":{"v":"Embeddings","n":1},"1":{"v":"\n## Solutions\n\n- [[prdct.rdf2vec]]\n\n## References\n\n- https://every.to/chain-of-thought/reid-hoffman-on-how-ai-might-answer-our-biggest-questions","n":0.447}}},{"i":1439,"$":{"0":{"v":"Naming","n":1},"1":{"v":"\n## References\n\n- http://www.skyhunter.com/marcs/petnames/IntroPetNames.html","n":0.577}}},{"i":1440,"$":{"0":{"v":"Pet Names","n":0.707},"1":{"v":"\nEach name set consists of three elements: a key that is global and securely unique (but not necessarily memorable); a nickname that is global and memorable (but not at all unique) , and a petname that is securely unique and memorable (but private, not global):\n\n    Keys lie at the heart of the security properties of the petname system. Nicknames and petnames exist to make it easy for human beings to manipulate keys. The security of the system can be no stronger than the unforgeability of the keys. Self-authenticating public/private key pairs make excellent keys since they have strong unforgeability properties. But there are other ways of achieving unforgeability. A trusted path can also work well as the key: the full pathname to a file on a specific computer is also unforgeable (or at least, as unforgeable as the designation of the specific computer, which can be quite strong in some cases). It does not make any difference in a petname system whether a key can be mimicked: keys are handled only by the computer, the human being handles the keys only indirectly via petnames. For a particular person, for a particular application, there is a one-to-one mapping between a key and a petname.\n\n    Nicknames can be used to assist in discovery of keys, and for help in selecting a petname. Nicknames are chosen by the owners of  keys in hopes of creating a distinctive, if not unique, mapping from the memorable nickname to the key. Such nicknames often are promulgated throughout the world in the hopes of making the nickname stick in the mind as a reference to the key. Since there are strong incentives to \"take ownership\" of a nickname, even though true ownership is not possible, nicknames are the most often misunderstood part of a petname system.\n\n    In the simple case, a nickname has a one-to-many mapping to keys The name John Smith is obviously a nickname: there are many John Smiths.Other nicknames produce the illusion of being globally unique: the name Marc Stiegler appears to be globally unique at the time of this writing. But there is no security property in this accident of global uniqueness. The uniqueness of the name Marc Stiegler would change quite quickly if, through the mysterious forces of human whimsy, the name suddenly became desirable. Sometimes the desirability of a nickname is not whimsical, but venal. It is already desirable for some applications to call themselves Quicken, for example, and draw windows that request a Quicken password.\n\n    Petnames are our private bidirectional references to keys. There are many Mark Millers, but there is one specific Mark Miller that the name means to me, the Mark Miller who works with object-capabilities for secure cooperation. \"Mark Miller\" is Mark Miller's nickname; it also happens to be my petname for the same individual. My private pet name for my wife is not recognizably similar to the public nickname used by my wife. In the computer setting, for a specific person with a specific application, petnames are unique, each petname refers to exactly one key, and each key is represented by exactly one petname. In all places in the application where the app wants to designate the key, the petname is displayed -- which is to say, a true petname is a bidirectional one-to-one mapping to a key. All references to the key by the user interface are represented by petname. A key cannot have two petnames; if a single key had two petnames, under what circumstances would the user interface use petname1 as the representation of the key, and under what circumstances would it bring up petname2?\n\n\n\n## References\n\n- http://www.skyhunter.com/marcs/petnames/IntroPetNames.html","n":0.041}}},{"i":1441,"$":{"0":{"v":"Multithreading","n":1}}},{"i":1442,"$":{"0":{"v":"Multiple Inheritance","n":0.707},"1":{"v":"\n## [[c.summary.bot]]\n\n    C++: C++ is one of the most well-known languages that supports multiple inheritance. It allows a class to inherit from multiple base classes, and it uses a combination of virtual inheritance and access specifiers to handle potential issues like the diamond problem.\n\n    Python: Python supports multiple inheritance, and it uses a method resolution order (MRO) algorithm called C3 Linearization to determine the order in which methods are inherited from multiple base classes. This helps avoid ambiguities and the diamond problem.\n\n    Eiffel: Eiffel is a statically typed object-oriented language that supports multiple inheritance through its \"multi-parent\" mechanism, allowing a class to have multiple parents.\n\n    Perl: Perl, a dynamic programming language, supports multiple inheritance. It allows classes to inherit from multiple base classes, and the order in which base classes are used is determined by the order in which they are listed.\n\n    Common Lisp: Common Lisp, a dialect of Lisp, supports multiple inheritance using its CLOS (Common Lisp Object System) with the defclass and :metaclass options.\n\n    Ruby: Ruby supports multiple inheritance, although it employs a single inheritance mechanism by allowing a class to inherit from one class while including modules that provide additional behavior. This is a form of mixin-based multiple inheritance.","n":0.07}}},{"i":1443,"$":{"0":{"v":"Multi-Agent System","n":0.707},"1":{"v":"\n\n\n\n\n## Implementations\n\n### javascript\n\n- [[prdct.agentframework]]\n- [[prdct.js-son]]\n- [[prdct.js-simulator]]\n\n\n### #python\n\n- [[prdct.spade]]\n- [[prdct.pade]]\n- [[Mesa|prdct.Mesa]]\n\n\n### java\n\n- [[prdct.jade]]\n  - [[prdct.bdi4jade]]\n- [[prdct.jadex]]\n- [[prdct.astra]]\n- [[prdct.gama]]\n\n### [[t.cs.languages.c-sharp]]\n\n- [[prdct.actress-mas]]\n- [[prdct.jade.leap]]\n- [[prdct.jas-mine]]\n\n## Implementations\n\n- https://learn.microsoft.com/en-us/archive/msdn-magazine/2016/july/csharp-applying-ai-to-a-multi-agent-mini-basketball-game\n\n## [[c.resource.list]]\n\n- [Overview of Software Agent Platforms Available in 2023](https://www.mdpi.com/2078-2489/14/6/348)\n- [A Review of Platforms for the Development of Agent Systems](https://arxiv.org/ftp/arxiv/papers/2007/2007.08961.pdf)\n\n\nse two relations, maker and produces, are called inverse relations. Storing the information “in both directions” is redundant. When we know that a wine is produced by a winery, an application using the knowledge base can always infer the value for the inverse relation that the winery produces the wine. However, from the knowledge-acquisition perspective it is convenient t o have both pieces of information explicitly available. This approach allows users to fill in the wine in one case and the winery in another. The knowledge-acquisition system could then automatically fill in the value for the inverse relation insuring consistency of the knowledge base.","n":0.083}}},{"i":1444,"$":{"0":{"v":"Machine Learning","n":0.707}}},{"i":1445,"$":{"0":{"v":"graph representation learning","n":0.577},"1":{"v":"\n\n\n- resources: \n  - https://towardsdatascience.com/introduction-to-graph-representation-learning-a51c963d8d11\n","n":0.447}}},{"i":1446,"$":{"0":{"v":"Mixed Reality","n":0.707},"1":{"v":"\n- [[c.comparable]]\n  - [[t.cs.augmented-reality]]\n  - Mixed reality similarly augments the physical world, but it takes it a step further, incorporating the ability to interact with digital renderings using eye and hand tracking technology.\n\n","n":0.174}}},{"i":1447,"$":{"0":{"v":"Metaverse","n":1},"1":{"v":"\n## **Metaverse**:\n\nAn interconnected digital world where users can interact, socialize, and create. Often associated with [[VR|t.cs.virtual-reality]], [[AR|t.cs.augmented-reality]], and digital economies. It’s essentially **shared digital spaces**.\n\n\n## Thoughts\n\n- I do not like the term 'metaverse'! \n  - Besides the Facebook connotations and the [[user.neal-stephensen]]-esque geekiness of it, it's not a universe about the universe. It's just a set of alternate universes.  ^pdbekjzfr2l0\n    - although some see it, and it was originally conceived as a monolithic alternate reality\n- \"Some envision the metaverse as an augmented reality or virtual reality experience, where users can immerse themselves in a computer-generated environment. Others envision the metaverse as a platform like Roblox or Unreal Engine, where users can Create and share their own virtual worlds. There are also those who see the metaverse as a blockcHain-Based system, where users can buy, sell, and trade virtual assets... [[game-system.dungeons-and-dragons]] can be conSidered the first real metaverse.\" [^1]\n- \"a honeypot trap for [[idea.architecture-astronaut]]\" - @John-Carmack\n  \n## References\n\n\n- [[vs.metaverse-vs-multiverse]]\n[^1]: [[ar.toolify.the-future-of-game-development-ai-and-megatrends]]\n","n":0.079}}},{"i":1448,"$":{"0":{"v":"Metaprogramming","n":1},"1":{"v":"\n\n\n\n- [[p.hasSense]]\n  - code generation\n  - runtime program manipulation\n- [[p.isRelated]] [[t.cs.languages.JavaScript.metaprogramming]]\n\n## Resources\n\n- https://www.oreilly.com/library/view/programming-scala-3rd/9781492077886/ch24.html\n  - \"Dynamically typed languages like Python and Ruby make it easy to manipulate the program with other code, sometimes derisively called monkey patching. In statically typed languages like Java and Scala, metaprogramming is more constrained and less common. It’s still useful for solving many advanced design problems, but more formality is required to separate compile-time versus runtime manipulation.\"\n- https://www.quora.com/What-programming-language-has-the-best-support-for-metaprogramming\n  - [[c.summary]] Python\n- https://news.ycombinator.com/item?id=19718015\n  - [[c.summary]] #julia\n- ![[Java|t.cs.languages.java#^ef3ln38s331c]]","n":0.112}}},{"i":1449,"$":{"0":{"v":"Dynamic Object Generation","n":0.577},"1":{"v":"\n## Resources\n\n- https://stackoverflow.com/questions/42061706/how-to-create-object-dynamically javascript\n- https://learn.microsoft.com/en-us/dotnet/csharp/advanced-topics/interop/walkthrough-creating-and-using-dynamic-objects c#\n","n":0.408}}},{"i":1450,"$":{"0":{"v":"Logging","n":1}}},{"i":1451,"$":{"0":{"v":"LLM","n":1}}},{"i":1452,"$":{"0":{"v":"Live Coding","n":0.707},"1":{"v":"\n- aka: on-the-fly programming, just in time programming, conversational programming\n- different_from: [[t.cs.sd.interactive-programming]]\n\n## Representation and manipulation of time\n\nThe specific affordances of time-based media and live interaction with code has led to a number of novel developments and uses in programming language design. Through mutual embedding of imperative and declarative subsystems, the programming language [SuperCollider](https://en.wikipedia.org/wiki/SuperCollider \"SuperCollider\")<sup id=\"cite_ref-12\" class=\"reference\"><a href=\"https://en.wikipedia.org/wiki/Live_coding#cite_note-12\">[12]</a></sup> permitted to build a library that allows incomplete and provisional specifications which can be rewritten at runtime.<sup id=\"cite_ref-13\" class=\"reference\"><a href=\"https://en.wikipedia.org/wiki/Live_coding#cite_note-13\">[13]</a></sup>\n\nThe [ChucK](https://en.wikipedia.org/wiki/ChucK \"ChucK\") language introduced an approach to \"strongly timed\" programming in 2002, embedding precision timing into control flow through a concise syntax.\n\n\"Temporal recursion\" was a term initially coined in relation to the [Impromptu](https://en.wikipedia.org/wiki/Impromptu_(programming_environment) \"Impromptu (programming environment)\") programming environment. Technical elements within a programming environment continue to locate compressors and recursion solutions, but timing had been a major issue. While the general form of a temporal recursion, being any asynchronous function recursion through time, is available to any event driven system, Impromptu has placed a special emphasis on this particular design pattern,<sup id=\"cite_ref-14\" class=\"reference\"><a href=\"https://en.wikipedia.org/wiki/Live_coding#cite_note-14\">[14]</a></sup> making it the centre piece of the concurrency architecture on that platform. Temporal recursion had repeatedly been used in [SuperCollider](https://en.wikipedia.org/wiki/SuperCollider \"SuperCollider\") and has since been implemented in the [Fluxus](https://en.wikipedia.org/wiki/Fluxus_(programming_environment) \"Fluxus (programming environment)\") environment.\n\nAnother functional approach to the representation of time is shown in the [Tidal](https://en.wikipedia.org/wiki/Tidal_(livecoding) \"Tidal (livecoding)\") pattern [DSL](https://en.wikipedia.org/wiki/Domain-specific_language \"Domain-specific language\"),<sup id=\"cite_ref-15\" class=\"reference\"><a href=\"https://en.wikipedia.org/wiki/Live_coding#cite_note-15\">[15]</a></sup> which represents patterns as combinators operating over functions of time, similar to techniques in [functional reactive programming](https://en.wikipedia.org/wiki/Functional_reactive_programming \"Functional reactive programming\").<sup id=\"cite_ref-16\" class=\"reference\"><a href=\"https://en.wikipedia.org/wiki/Live_coding#cite_note-16\">[16]</a></sup>\n\n## Implementations\n\n- [[prdct.fluxus]] #dead\n- [[prdct.gideros]]\n- [[t.cs.languages.clojure]]\n\n## References\n\n- https://github.com/toplap/awesome-livecoding/\n- https://clojure.org/guides/repl/annex_community_resources","n":0.063}}},{"i":1453,"$":{"0":{"v":"Programming Language","n":0.707},"1":{"v":"\n## Resources\n\n- https://tomassetti.me/category/language-engineering/\n- ","n":0.577}}},{"i":1454,"$":{"0":{"v":"TypeScript","n":1}}},{"i":1455,"$":{"0":{"v":"Type Assertions","n":0.707}}},{"i":1456,"$":{"0":{"v":"Cpp","n":1}}},{"i":1457,"$":{"0":{"v":"C++/CLI","n":1}}},{"i":1458,"$":{"0":{"v":"Wasp","n":1},"1":{"v":"\n- https://wasp-lang.dev/\n- built-on: [[prdct.React]] [[prdct.node]] [[prdct.prisma]]\n\n## Description\n\n- Given a simple .wasp configuration file that describes the high-level details of your web app, and .js(x)/.css/..., source files with your unique logic, Wasp compiler generates the full source of your web app in the target stack: front-end, back-end and deployment.","n":0.144}}},{"i":1459,"$":{"0":{"v":"Typed","n":1},"1":{"v":"![](/assets/images/2023-10-04-14-48-39.png)","n":1}}},{"i":1460,"$":{"0":{"v":"Strongly-Typed Languages","n":0.707},"1":{"v":"\nStrongly typed means that there are restrictions between conversions between types. ","n":0.302}}},{"i":1461,"$":{"0":{"v":"Statically-Typed Languages","n":0.707},"1":{"v":"\nStatically typed means that the types are not dynamic - you can not change the type of a variable once it has been created.\n\n## Resources\n\n- https://www.solwey.com/posts/static-vs-dynamic-typing-choosing-the-right-approach-for-your-programming-needs","n":0.196}}},{"i":1462,"$":{"0":{"v":"Dynamically-Type Languages","n":0.707},"1":{"v":"\n## Resources\n\n- https://www.quora.com/Why-do-dynamic-languages-make-it-more-difficult-to-maintain-large-codebases","n":0.577}}},{"i":1463,"$":{"0":{"v":"Smalltalk","n":1},"1":{"v":"\n## Resources\n\n- [[ar.design-principles-behind-smalltalk]]\n  - Personal Mastery. If a system is to serve the creative spirit, it must be entirely comprehensible to a single individual.\n\nReactive Principle. Every component accessible to the user should be able to present itself in a meaningful way for observation and manipulation\n\n### Learning Resource\n\n- [[course.learn-smalltalk-with-profstef]]","n":0.144}}},{"i":1464,"$":{"0":{"v":"Pharo","n":1},"1":{"v":"\n\n\n- [[p.hasApplication]] [[prdct.lepiter]] \n\n","n":0.5}}},{"i":1465,"$":{"0":{"v":"Cuis","n":1},"1":{"v":"\n## Historical Context\n\nCuis is a kernel Smalltalk system which is still rather close to Smalltalk-80. The Cuis-Smalltalk goal is to be a small, coherent Smalltalk development environment that, with study, is comprehensible to a single person.\n\nAs we experiment with and evolve Cuis, this goal is carried out by removing everything possible from the base system which is not essential, and by having a composition strategy which allows one to write or add any features as needed. As one gains understanding of the software kernel or core, one only has to read and learn from each additional feature at a time to understand the whole.\n\nModern, open software environments are highly complex. Cuis is an attempt to remain oriented and able to discover patterns without being lost in a large wealth of possibilities which one does not completely grasp","n":0.085}}},{"i":1466,"$":{"0":{"v":"Amber","n":1},"1":{"v":"\n- url: https://amber-lang.net/\n- #license MIT\n- [[p.compatibleWith]] [[prdct.babylon-js]]","n":0.378}}},{"i":1467,"$":{"0":{"v":"Scala","n":1},"1":{"v":"\n\n## Resources\n\n- [[ar.scala-for-game-server-development]]\n- https://gist.github.com/jackcviers/a7e74a3ad0a57f6ab97afd25c940f2b4\n  - \" I reccomend you use ZIO or Typelevel, and to build small simple projects that asynchronously communicate via a queing system fronted by a simple REST api powered by http4s, and front ends built out of scalajs-react. \"\n- https://news.ycombinator.com/item?id=26539508\n  - a new language, beyond certain level, does not increase productivity tangibly for a large enough team. Specifically, Scala does not necessarily offer more productivity than Java. It is a pleasure to write program in a language with more powerful features, for sure. It's just that bottlenecks of project are usually not language features, but core algorithms, system designs, meticulous testing, conflicting requirements that demand careful trade-offs, availability of robust libraries and frameworks, maintainability of the most complex part of the system, and availability of qualified engineers. Few of such bottlenecks can be removed by switching to a language like Scala.\n  - It's too hard to recruit and the tooling isn't mature enough","n":0.08}}},{"i":1468,"$":{"0":{"v":"Rust","n":1},"1":{"v":"\n- [[p.coreferences.main]] #rust\n\n- [[p.hasApplication]]\n  - [[t.cs.ui.cli]] \n  - [[t.cs.application.webapp]] \n    - Use Rust to supercharge your JavaScript, one module at a time with [[prdct.webassembly]]. Publish to npm, bundle with webpack, and you’re off to the races.\n    - resources:  https://www.rust-lang.org/what/wasm\n    - [[p.hasLearningResource]] https://rustwasm.github.io/docs/book/\n  - [[t.cs.application.service.network]] \n\n## Features\n\n- [traits](https://doc.rust-lang.org/book/ch10-02-traits.html)\n- [DSLs](https://doc.rust-lang.org/rust-by-example/macros/dsl.html)\n\n\n## Resources\n\n- [[ar.rustconf-talk]] goes into detail about why to design a game with [[c.software.entity-component-system]]\n- [Effective Learning through 2D Game Development and Play](https://pragprog.com/titles/hwrust/hands-on-rust/)\n- [[prdct.petgraph]]","n":0.12}}},{"i":1469,"$":{"0":{"v":"Ruby","n":1}}},{"i":1470,"$":{"0":{"v":"Prolog","n":1},"1":{"v":"\n\n\n## References\n\n- https://stackoverflow.com/questions/22600209/have-any-commercial-video-games-ever-used-prolog\n  - highlights:\n    - \"Everything is on rail, scripted and controlled. Artists are very uncomnfortable with algorithmical rules, and game designers are artists. In my programmer's opinion, games with sophisticated AI must have beneficiated from a high ranking programmer in the company to push for it\n","n":0.144}}},{"i":1471,"$":{"0":{"v":"PHP","n":1}}},{"i":1472,"$":{"0":{"v":"Ocaml","n":1},"1":{"v":"\n- https://ocaml.org/\n\n## Features\n\n- [[t.cs.multiple-inheritance]]\n\n","n":0.5}}},{"i":1473,"$":{"0":{"v":"Lisp","n":1}}},{"i":1474,"$":{"0":{"v":"Linden","n":1},"1":{"v":"\n- #aka lsl\n- url: https://wiki.secondlife.com/wiki/LSL_Portal\n","n":0.447}}},{"i":1475,"$":{"0":{"v":"Kotlin","n":1},"1":{"v":"\n- [[p.publishedBy]] [[org.jetbrains]]\n\n## Features\n\n- compatibility with Java\n  - \"Kotlin seamlessly interacts with Java classes and methods, and vice versa, allowing for a smooth transition to the new language without the need to rewrite existing code.\"\n- extensions allow adding new functions to existing classes without modifying them\n\n\n### Coroutines\n\n- \"2. Conceptually Coroutines are very similar to VirtualThreads. The identical parts are: lightweight threads and structured concurrency. But there are also some differences:\n  - Coroutines are more feature rich than what Loom offers now, namely:\n\n    - context propagation (meaning let the same context, like a MDC, Transaction etc. be propagated across several Coroutines) is fully embedded in Coroutines. Loom is still experimenting with this part, which they call scope variables.\n\n    - Cancellation: Part of the Contract Coroutines offer is cancellation, no matter how nested a process tree might be. This is and will not be available in Loom. In certain use-cases this is a big omission for Loom.\"[^1]\n\n\n### Nullable Types\n\nIn Java, you need to explicitly check for null before accessing an object to avoid `NullPointerException`. This often leads to verbose null-checking code.\n\n```kotlin\nval name: String? = null\nprintln(name?.length ?: \"Name is null\")\n```\n\nKotlin uses the safe call operator `(?.)` and the Elvis operator `(?:)` to handle nullables concisely. This line safely accesses the length if `name` is not null, or otherwise prints `\"Name is null\"`. In Kotlin, the safe call operator, `?.`**,**  and the `?:` operator are used for default values, simplifying null handling.\n\n## Related\n\n- [[prdct.arrow-kt]]\n\n## References\n\n- [^1]: https://spring.io/blog/2022/10/11/embracing-virtual-threads\n- https://itnext.io/kotlin-coroutines-vs-java-virtual-threads-a-good-story-but-just-that-91038c7d21eb\n- https://dzone.com/articles/migrating-microservices-from-java-to-kotlin","n":0.065}}},{"i":1476,"$":{"0":{"v":"Julia","n":1},"1":{"v":"\n- [[p.coreferences.main]] #julia","n":0.577}}},{"i":1477,"$":{"0":{"v":"JavaScript","n":1},"1":{"v":"\n\n\n\n- [[p.instanceOf]] [[c.programminglanguage]]\n\n## Strict equality and null !== undefined \n\n```\nconsole.log(null === undefined) // false (not the same type)\nconsole.log(null == undefined) // true (but the \"same value\")\nconsole.log(null === null) // true (both type and value are the same)\n```\n\n## Resources\n\n- https://stackoverflow.com/questions/73297947/how-to-type-an-object-with-optional-and-default-values\n- https://stackoverflow.com/questions/5076944/what-is-the-difference-between-null-and-undefined-in-javascript\n- \n\n### Learning Resources\n\n- https://madza.hashnode.dev/21-github-repositories-to-become-a-javascript-master\n- https://medium.com/@kubiak.maciej/3-tips-i-wish-someone-had-given-me-when-i-started-my-adventure-with-typescript-ddec0073862a\n  - 1. Use the types property retrieving option\n  - 2. Narrow down your argument types\n  - 3. Use predefined types\n- https://docs.microsoft.com/en-us/learn/certifications/exams/98-382\n- https://hackr.io/blog/best-javascript-certification\n- https://javascript.plainenglish.io/28-javascript-skills-a-qualified-intermediate-front-end-engineer-needs-to-master-ffed93de3f38\n\n### async\n\n- https://medium.com/@ajmeyghani/async-javascript-a-pocket-reference-2bb16ac40d21\n","n":0.12}}},{"i":1478,"$":{"0":{"v":"JavaScript Testing","n":0.707},"1":{"v":"\n\n\n## Resources\n\n- https://dimitr.im/testing-nodejs-tape\n","n":0.577}}},{"i":1479,"$":{"0":{"v":"Symbol","n":1}}},{"i":1480,"$":{"0":{"v":"javascript reflection","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://javascript.plainenglish.io/using-the-reflection-and-reflection-metadata-apis-with-typescript-decorators-c56ba9c690c7\n","n":0.577}}},{"i":1481,"$":{"0":{"v":"naming-convention","n":1},"1":{"v":"\n## #resources\n\n- https://www.syncfusion.com/blogs/post/10-javascript-naming-conventions-every-developer-should-know.aspx","n":0.577}}},{"i":1482,"$":{"0":{"v":"metaprogramming in javascript","n":0.577},"1":{"v":"\n\n\n- resources: \n  - https://www.freecodecamp.org/news/what-is-metaprogramming-in-javascript-in-english-please/\n  - https://stackoverflow.com/questions/73662417/how-can-i-do-typed-metaprogramming-with-typescript\n","n":0.378}}},{"i":1483,"$":{"0":{"v":"global-object","n":1},"1":{"v":"\n\n\n- resources:  https://developer.mozilla.org/en-US/docs/Glossary/Global_object\n  -   In a web browser, any code which the script doesn't specifically start up as a background task has a [`Window`](https://developer.mozilla.org/en-US/docs/Web/API/Window) as its global object. This is the vast majority of JavaScript code on the Web.\n  -   Code running in a [`Worker`](https://developer.mozilla.org/en-US/docs/Web/API/Worker) has a [`WorkerGlobalScope`](https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope) object as its global object.\n  -   Scripts running under [Node.js](https://developer.mozilla.org/en-US/docs/Glossary/Node.js) have an object called [`global`](https://nodejs.org/api/globals.html#globals_global) as their global object.\n","n":0.122}}},{"i":1484,"$":{"0":{"v":"javascript decorators","n":0.707},"1":{"v":"\n\n## [[p.hasLearningResource]]\n\n- https://techsparx.com/nodejs/typescript/decorators/","n":0.577}}},{"i":1485,"$":{"0":{"v":"Idris","n":1},"1":{"v":"\n- url: https://www.idris-lang.org/","n":0.577}}},{"i":1486,"$":{"0":{"v":"Haskell","n":1}}},{"i":1487,"$":{"0":{"v":"Groovy","n":1}}},{"i":1488,"$":{"0":{"v":"Go (Language)","n":0.707},"1":{"v":"\n- [[p.coreferences.main]] #go \n\n## Resources\n\n- Does Go support [[t.cs.multiple-inheritance]]? https://groups.google.com/g/golang-nuts/c/x8GEbutPhuc\n- [Golang concepts from an OOP point of view](https://github.com/luciotato/golang-notes/blob/master/OOP.md)\n\n## Issues\n\n- No ability to dynamically import symbols from shared libraries. \"Go applications are always single binaries that contain all of the code needed to run that program. The application may read external configuration or files or whatnot, but no code is read from external files. This makes a lot of sense if you’re writing self-contained applications like web apps, but anything that requires extensibility suddenly requires you perform some insane workarounds. The most common workaround is for the main process to spawn a subprocess running a whole other application and for the two to communicate via RPC.\"\n\n## References\n\n- https://peterfraedrich.medium.com/its-time-for-a-new-programming-language-f04e24704101","n":0.092}}},{"i":1489,"$":{"0":{"v":"GDScript","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.programminglanguage]]\n- [[p.vs]] #python\n  - \"Unlike Python, GDScript is optimized for Godot's scene-based architecture and can specify strict typing of variables.\"\n    - [[p.hasSource]] https://www.reddit.com/r/godot/comments/cj9xcv/is_gdscript_better_than_c/\n","n":0.2}}},{"i":1490,"$":{"0":{"v":"F Sharp","n":0.707},"1":{"v":"\n\n\n## Resources\n\n- https://news.ycombinator.com/item?id=16166800\n- [[book.domain-modeling-made-functional]]\n- https://dev.to/7sharp9/applied-meta-programming-with-myriad-and-falanx-7l4 mentions [[prdct.myriad]]","n":0.378}}},{"i":1491,"$":{"0":{"v":"Erlang","n":1}}},{"i":1492,"$":{"0":{"v":"Elm","n":1},"1":{"v":"\n- url: https://elm-lang.org/\n- ","n":0.577}}},{"i":1493,"$":{"0":{"v":"Datalog","n":1}}},{"i":1494,"$":{"0":{"v":"Dart","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://dart.dev/\n","n":0.577}}},{"i":1495,"$":{"0":{"v":"Clojure","n":1},"1":{"v":"\n## Resources\n\n- https://clojure.org/about/state\n  - \"Identities are mental tools we use to superimpose continuity on a world which is constantly, functionally, creating new values of itself.\"\n- [Which functional language has the best ecosystem for a web backend?](https://news.ycombinator.com/item?id=16166800)\n  - \"F#.. I didn't mention clojure as I don't consider dynamic languages a good fit for building large codebase backend systems\" ^vhfvmr4nos53\n- https://www.reddit.com/r/Clojure/comments/vh2k42/what_web_framework_do_you_use/\n  - mentions [[prdct.kit]], [[prdct.luminus]] and [[prdct.reframe]]\n- https://calva.io/get-started-with-clojure/ #excellent\n  - mentions \n    - [ ] [[prdct.rich4clojure]]\n- [[prdct.aristotle]] - Jena wrapper\n\n### Learning Resources\n\n- https://gist.github.com/ssrihari/0bf159afb781eef7cc552a1a0b17786f","n":0.111}}},{"i":1496,"$":{"0":{"v":"C","n":1}}},{"i":1497,"$":{"0":{"v":"C#","n":1},"1":{"v":"\n\n## Tips\n\n### public fields\n\n- - \"no fields should ever be non-private. I'll make a small exception for static readonly fields such as string.Empty, but that's (nearly) all.\"\n\n\n### settable properties and public fields\n\n- A property communicates the idea of \"I will make a value available to you, or accept a value from you.\" It's not an implementation concept, it's an interface concept. A field, on the other hand, communicates the implementation - it says \"this type represents a value in this very specific way\".\n\n## Resources\n\n- https://itnext.io/getting-functional-with-c-6c74bf279616\n\n## Referebces\n\n- https://csharpindepth.com/articles/PropertiesMatter\n","n":0.107}}},{"i":1498,"$":{"0":{"v":"C++","n":1}}},{"i":1499,"$":{"0":{"v":"Bosque","n":1},"1":{"v":"\n- written-in: typescript #c++\n\n## [[c.vision]]\n\n- \"mechanization and automated reasoning, along with human and AI agents that leverage them, are the ideas that will define the next era of software development.\"\n","n":0.183}}},{"i":1500,"$":{"0":{"v":"Ballerina","n":1},"1":{"v":"\nurl: https://ballerina.io/\n\n- [[p.wasBuiltBy]] [[org.wso2]]","n":0.5}}},{"i":1501,"$":{"0":{"v":"APL","n":1}}},{"i":1502,"$":{"0":{"v":"Agda","n":1},"1":{"v":"\n- docs: https://agda.readthedocs.io\n- ","n":0.577}}},{"i":1503,"$":{"0":{"v":"Abl","n":1},"1":{"v":"\n- url: https://www.progress.com/openedge/features/abl\n- [[p.supports]] [[prdct.vscode]]","n":0.447}}},{"i":1504,"$":{"0":{"v":"Python","n":1},"1":{"v":"\n\n- [[p.coreferences.main]] #python\n\n## Resources\n\n### Learning Resources\n\n- https://www.techwithtim.net/tutorials/python-online-game-tutorial/client uses [[prdct.pygame]]","n":0.333}}},{"i":1505,"$":{"0":{"v":"Java","n":1},"1":{"v":"\n## References\n\n- https://levelup.gitconnected.com/a-deep-dive-into-classloader-reflection-dynamic-typing-and-runtime-modifiable-classes-in-java-c83d6d689b2 ^ef3ln38s331c\n\n\n","n":0.5}}},{"i":1506,"$":{"0":{"v":"Virtual Threads","n":0.707},"1":{"v":"\n## Use cases\n\n- \"If your application frequently performs heavy computation for very long durations, then virtual threads may be a bad fit to begin with because your system may easily become overcommitted by orders of magnitude.\"\n- \"If you're using SQLite or RocksDB, think carefully before adopting virtual threads.\"\n- \"We have had a quick glimpse at using virtual threads with Groovy and [[prdct.gpars]]\"\n\n## Solutions\n\n- [[prdct.helidon]] is the first Java microservices framework based on virtual threads.\n\n## Comparisons\n\n### vs Deno/Web Workers\n\n- \"Performance Management and Scalability:\n\n    Java Virtual Threads: They are designed to be lightweight and highly scalable, especially for IO-bound tasks. The JVM manages these threads efficiently, allowing for the creation of thousands to millions of concurrent threads with a much lower memory footprint compared to traditional threads.\n    Deno Web Workers: While powerful for CPU-bound tasks and parallel processing, each worker is a heavier construct compared to a Virtual Thread. This means that while they're excellent for offloading intensive tasks, they might not be as scalable as Virtual Threads for handling many small, concurrent tasks.\n\n  Concurrency Model:\n\n    Java Virtual Threads: They offer a straightforward model for writing concurrent code, similar to traditional threading but with a much lower overhead. This makes them ideal for applications with a large number of concurrent, mostly idle tasks.\n    Deno Web Workers: They follow a message-passing model which can be more robust in terms of avoiding shared state problems, but it might require a different way of thinking about problem-solving, particularly for those used to shared-state concurrency models.\"\n      - @chatgpt.4\n\n## Resources\n\n- https://spring.io/blog/2022/10/11/embracing-virtual-threads\n- https://dev.to/devsegur/java-virtual-threads-vs-kotlin-coroutines-4ma8\n- https://itnext.io/kotlin-coroutines-vs-java-virtual-threads-a-good-story-but-just-that-91038c7d21eb\n","n":0.063}}},{"i":1507,"$":{"0":{"v":"Immutability","n":1},"1":{"v":"\n- aligns well with pure functions","n":0.408}}},{"i":1508,"$":{"0":{"v":"Host Monitoring","n":0.707}}},{"i":1509,"$":{"0":{"v":"Human-computer interaction","n":0.707}}},{"i":1510,"$":{"0":{"v":"Experimental Interface Design","n":0.577}}},{"i":1511,"$":{"0":{"v":"Graph","n":1},"1":{"v":"\n\n\n- resources: \n  - https://medium.com/tebs-lab/types-of-graphs-7f3891303ea8\n    - Directed edges have a subtle impact on the use of the term neighbors. If an edge goes from A to B, then B is said to be A’s neighbor; but the reverse is not true. A is not a neighbor of B unless there is an edge from B to A. In other words, a node’s neighbors are the set of nodes that can be reached from that node.\n  - https://www.javatpoint.com/graph-theory-types-of-graphs\n    - trivial graph: one point\n","n":0.11}}},{"i":1512,"$":{"0":{"v":"Visualization","n":1},"1":{"v":"\n## Proposals\n\n- [[ar.justin2004.intuitive-graph-viz]]\n\n## Solutions\n\n- [[prdct.graph-explorer]]\n\n","n":0.447}}},{"i":1513,"$":{"0":{"v":"Temporal Joins","n":0.707},"1":{"v":"\n## Example\n\nExample 1: Employee Salary History\n\nImagine a database with two tables: Employees and SalaryHistory.\n\n    Employees table contains EmployeeID, Name, and other details.\n    SalaryHistory table contains EmployeeID, Salary, StartDate, and EndDate (indicating the period for which a particular salary was valid).\n\nA temporal join can be used to find out what salary each employee was earning on a specific date. For example, to find the salary of each employee on January 1, 2023, you would perform a temporal join between these tables where the join condition checks if January 1, 2023, falls between the StartDate and EndDate of the salary records.\n\n## Description\n\n- \"\n\nA temporal join is a join operation on two temporal relations, in which each tuple has additional attributes indicating a time interval. The temporal join predicates include conventional join predicates as well as a temporal constraint that requires the overlap of the intervals of the two joined tuples. The result of a temporal join is a temporal relation.\n\nBesides binary temporal joins that operate on two temporal relations, there are n-ary temporal joins that operate on more than two temporal relations. Besides temporal overlapping, there are other temporal conditions such as “before” and “after” [1]. This entry will concentrate on the binary temporal joins with overlapping temporal condition since most of the previous work has focused on this kind of joins.\n\"\n\n## References\n\n- https://link.springer.com/referenceworkentry/10.1007/978-0-387-39940-9_401 ","n":0.067}}},{"i":1514,"$":{"0":{"v":"Semantic Hypergraph","n":0.707},"1":{"v":"\n\n\n- [[p.similarTo]] [[t.cs.graph.metagraph]]\n- [[p.hasSolution]]\n  - [[prdct.graphbrain]]\n    - resources:  https://graphbrain.net/overview/hypergraph.html\n  - [[prdct.atomspace]]\n  - [[idea.text-as-graph]]\n  - [[prdct.typedb]]","n":0.258}}},{"i":1515,"$":{"0":{"v":"Semantic Graph","n":0.707}}},{"i":1516,"$":{"0":{"v":"Property Graph","n":0.707},"1":{"v":"\n\n\n\n\n- [[p.hasSpecification]] [[prdct.ngsi-ld]]\n- [[p.hasVariant]] [[t.km.knowledge-graph.lpg]]\n\n## Tips\n\n- \"What should be a Property... Any data element that isn’t frequently used to access the graph directly, has no internal object complexity/multiplicity, and/or needs to always return with the rest of the data in the node is a good candidate for a Property.\"\n\n## vs [[prdct.rdf]]\n\n- http://www.snee.com/bobdc.blog/2018/04/reification-is-a-red-herring.html\n  - In RDF, \"if you want to keep track of separate instances of a particular relationship, declare a class for that relationship and then create instances of it.\"\n\n## vs [[prdct.rdf-star]]\n\n- https://opencredo.com/blogs/making-sense-of-data-with-rdf-vs-lpg/\n  - \"In property graphs, attribute values are just strings not linked to any other nodes in the graph. They can only represent literal values, rather than relationships and things. In contrast, values of RDF* properties can be both literal values (RDF literals) or nodes connected to other nodes in the graph.\"\n  -   **Capacity to represent edge attributes as nodes**. As we mentioned above, unlike attributes in LPGs, RDF\\* edge attributes can be represented as nodes in the graph, allowing them to be treated as individual entities.\n  -   **Better expressivity**. RDF\\* allows every LPG to be efficiently converted into an RDF model. On the other hand, LPGs cannot fully represent RDF\\* because of the rich expressivity of the latter. \n  -   **Arbitrarily complex edge descriptions**. With RDF\\*, graph developers can attach complex descriptions to edges that represent connections to other nodes, literal values (strings), and inter-attribute relationships. In contrast, with LPG, edge properties can only be represented as literal key-value pairs.\n- https://stackoverflow.com/questions/38034049/is-optionality-mandatory-optional-and-participation-total-partial-are-same/38035173#38035173\n  - \"Application with Cross-Domain Knowledge: RDF*\"\n  - \"Applications that Require Fast Search: LPG\"\n  - \"Data Provenance: RDF*\"Representing Temporal Dimension: RDF*\n  - \"Data Analytics: RDF*\"[[prdct.asyncapi]]\n\n## Resources\n\n### Learning Resources\n\n- https://www.asyncapi.com/blog/designing_your_apis_with_asyncapi_part_1\n\n## References\n\n- [[ar.postgresql-oracle-graph-query-language-standards-adoption-green]]\n- [Graph databases don't provide a significant advantage over well-architected relational DBs for most use cases](https://www.linkedin.com/pulse/graph-relational-enemies-alastair-green/?trackingId=5xrQz85vQRaoTnQv%2BO3bPA%3D%3D)\n- https://www.researchgate.net/publication/342956606_Linked_Data_for_Smart_Homes_Comparing_RDF_and_Labeled_Property_Graphs\n- https://bigbear.ai/blog/property-graphs-is-it-a-node-a-relationship-or-a-property/\n\n\n","n":0.059}}},{"i":1517,"$":{"0":{"v":"Metagraph","n":1},"1":{"v":"\n\n\n## Implementations\n\n- [[prdct.metagraph]]\n\n## Resources\n\n- [[ar.opencog.graphs-metagraphs-ram-cpu]]\n- https://towardsdatascience.com/knowledge-hypergraphs-object-role-modeling-ef0f58f38066\n- [[ar.using-metagraph-approach-for-the-big-data-based-graph-processing]]\n- [[ar.thinkmind.the-typed-graph-model]]","n":0.354}}},{"i":1518,"$":{"0":{"v":"Hypergraph","n":1},"1":{"v":"\n#aka [[prdct.hode.rslt]]\n- likely many definitions, but I like TypeDB's:\n  - [[p.hasSource]] [[Modelling Data with Hypergraphs|ar.medium.modelling-data-with-hypergraphs]]\n    - a hypergraph consists of a non-empty set of vertices and a set of hyperedges;\n    - a hyperedge is a finite set of vertices (distinguishable by specific roles they play in that hyperedge);\n    - a hyperedge is also a vertex itself and can be connected by other hyperedges.\n\n\n![](/assets/images/2022-12-10-13-25-23.png)\n\n- [[p.hasRelatedTopic]]\n  - [[t.cs.graph.hyperedge]]\n\n## Implementations\n\n- https://www.angioi.com/visualizing-hypergraphs-networkx/\n  - \"edges should really be Python frozensets, so that a collection of them can also be a set, and the node set should also be a frozenset or a set\"\n- [[prdct.typedb]]\n- \n\n## Thoughts\n\n- ![[daily.journal.2023.06.28#^vnkm9vka0yb7]]\n- \"hyperedges are isomophic to Lisp S-expressions\" [1]\n\n\n## Resources\n\n- [[ar.thinkmind.the-typed-graph-model]]\n- [[Modelling Data with Hypergraphs. A closer look at the TypeDB hypergraph|ar.medium.modelling-data-with-hypergraphs]]\n- https://news.ycombinator.com/item?id=32283022\n- https://people.csail.mit.edu/jshun/6827-s22/lectures/lecture10-2.pdf\n- [[ar.opencog.graphs-metagraphs-ram-cpu]]\n  - \"The naive representation for the hypergraph is a straight-forward extension of the edge table...\n![](/assets/images/2023-05-19-16-20-39.png)\n  - \"The vertex list may be empty, may hold one, or more vertexes. It is necessarily ordered (and thus not a set) and may contain repeated entries (a vertex may appear more than once in the list)\"\n- [Two monads for graphs](https://arxiv.org/pdf/1804.09408.pdf) has some interested visualizations\n  - ![](/assets/images/2023-07-01-06-45-50.png)\n- https://gitlab.com/graphviz/graphviz/-/issues/1911 talks about visualization, has this cool thing: ![](/assets/images/2023-07-01-07-06-16.png)\n- https://medium.com/@lee.papa/a-brief-history-of-the-hypergraph-1d8f79fd72e5\n  - mentions: [[t.cs.blockchain.constellation]]\n- https://medium.com/vaticle/knowledge-graph-representation-grakn-ai-or-owl-506065bd3f24\n\n## References\n\n[1]: https://graphbrain.net/overview/hypergraph.html#as-knowledge-modelsh.a","n":0.07}}},{"i":1519,"$":{"0":{"v":"Hyperedge","n":1}}},{"i":1520,"$":{"0":{"v":"Half Edge","n":0.707}}},{"i":1521,"$":{"0":{"v":"Graph Dynamical System Model","n":0.5}}},{"i":1522,"$":{"0":{"v":"Graph Query Language","n":0.577},"1":{"v":"\n\n\n\n- resources:  https://en.wikipedia.org/wiki/Graph_Query_Language#The_GQL_property_graph_data_model {2021-12-01 01:29}\n  - [[p.hasHighlight]]\n    - GQL is a query language specifically for property graphs. A property graph closely resembles a conceptual data model, as expressed in an entity–relationship model or in a UML class diagram (although it does not include n-ary relationships linking more than two entities). Entities or concepts are modelled as nodes, and relationships as edges, in a graph. Property graphs are multigraphs: there can be many edges between the same pair of nodes. GQL graphs can be mixed: they can contain directed edges, where one of the endpoint nodes of an edge is the tail (or source) and the other node is the head (or target or destination), but they can also contain undirected (bidirectional or reflexive) edges.\n    - [[p.vs]] [[prdct.tinkerpop]] [[prdct.neo4j]]\n      - Current graph database products and projects often support a limited version of the model described here. For example, Apache Tinkerpop forces each node and each edge to have a single label; Cypher allows nodes to have zero to many labels, but relationships only have a single label (called a reltype). Neo4j's database supports undocumented graph-wide properties, Tinkerpop has graph values which play the same role, and also supports \"metaproperties\" or properties on properties. \n\n\n## References\n\n- [[ar.postgresql-oracle-graph-query-language-standards-adoption-green]]","n":0.07}}},{"i":1523,"$":{"0":{"v":"Data Models","n":0.707},"1":{"v":"\n\n\n- resources: \n  - https://web.stanford.edu/class/cs520/2020/notes/What_Are_Graph_Data_Models.html\n    - [[p.hasHighlight]]\n      - A graph data model is not the most appropriate choice when the application contains primarily numeric data, and the reliance on only binary relationships is limiting. For example, the relational model is more effective in capturing timeseries data such as evolution of the population of a country. Even though we can represent such data using a graph, but it results in a huge number of triples without necessarily giving us advantages of better conceptual understanding and/or faster query performance through graph traversals. There are many relationships that cannot be naturally represented using binary relations. For example, between relation that captures that an object A is between two other objects B and C is inherently a ternary relationship. A ternary relationship can be transformed into a set of binary relationships using the reification technique, but by doing so, we lose the advantage of better conceptual understanding that we get from the graph data model. Graphs are also not the most natural representation for mathematical equations and chemical reactions where easy to understand domain specific representations exist.\n","n":0.074}}},{"i":1524,"$":{"0":{"v":"Compound Graphs","n":0.707}}},{"i":1525,"$":{"0":{"v":"Bipartite Graphs","n":0.707},"1":{"v":"\n\n- resources:  https://mathworld.wolfram.com/BipartiteGraph.html\n","n":0.577}}},{"i":1526,"$":{"0":{"v":"Grains","n":1},"1":{"v":"\n- [[org.microsoft]]'s [[t.cs.primitive]]","n":0.577}}},{"i":1527,"$":{"0":{"v":"Goose Typing","n":0.707},"1":{"v":"\n- [[p.attributedTo]] @alex-martelli\n\n## Resources\n\n- https://devopedia.org/duck-typing\n  - [[p.hasHighlight]]\n    - With [[t.cs.goose-typing]], the interface or protocol is made explicit. This is done using an Abstract Base Class (ABC). In the call isinstance(obj, cls), the second argument must be an ABC. The ABC class itself can't be instantiated but another class provides an implementation of the expected interfaces. However, this other class is simply registered (via a decorator) as conforming to the ABC's interface; that is, it's not explicitly derived from the ABC. For this reason, we call goose typing as \"virtual subclassing of Python ABCs.\" ","n":0.104}}},{"i":1528,"$":{"0":{"v":"Geographic Information Systems (GIS)","n":0.5}}},{"i":1529,"$":{"0":{"v":"Projections","n":1}}},{"i":1530,"$":{"0":{"v":"Quadrilateralized Spherical Cube","n":0.577}}},{"i":1531,"$":{"0":{"v":"Geospatial Querying","n":0.707}}},{"i":1532,"$":{"0":{"v":"Computer Game","n":0.707},"1":{"v":"\n- [[p.alsoKnownAs]] video games;\n- [[p.hasSubClass]] [[c.game.sandbox]]\n\n\n## Resources\n\n- https://every.to/p/a-short-history-of-video-games","n":0.354}}},{"i":1533,"$":{"0":{"v":"If","n":1}}},{"i":1534,"$":{"0":{"v":"Multiplayer Interactive Fiction","n":0.577},"1":{"v":"\n- resources: \n  - https://www.ifwiki.org/Multiplayer_IF\n    - An IF game where two or more players adopt the roles of multiple PCs simultaneously is referred to as strong multiplayer IF or true multiplayer IF.\n    - [[p.hasHighlight]]\n      - To date, there's been very little true multiplayer IF. Some of the problems are:\n        -   **How to put IF and chat together.** Wedding an IF game to any of the available chat environments is not obvious, and most authors would not want to invent their own chat systems -- just writing IF can be challenging enough!\n        -   **Multiple output text streams.** True multiplayer IF must display different text to different players. They shouldn't all see the same thing when they're playing different characters within the game.\n        -   **Multiplayer puzzle design.** Many standard IF puzzles can't be used as is in multiplayer games without inviting [deadlock](https://www.ifwiki.org/Deadlock \"Deadlock\").\n        -   **Getting people to play it.** Getting IF players together at the same time can itself be a challenge, especially when they are accustomed to playing solo.\n  - http://bluerenga.wordpress.com/2005/02/17/designing-multiplayer-puzzles/","n":0.077}}},{"i":1535,"$":{"0":{"v":"World","n":1},"1":{"v":"\n## Resources\n\n- [[ar.sciencedirect.a-quadtree-based-synchronization-protocol-for-inter-server-game-state-synchronization]]","n":0.577}}},{"i":1536,"$":{"0":{"v":"Quad Tree Synchronization Protocol","n":0.5}}},{"i":1537,"$":{"0":{"v":"User Generated Content","n":0.577},"1":{"v":"\n#aka ugc\n\n","n":0.707}}},{"i":1538,"$":{"0":{"v":"User Acquisition","n":0.707}}},{"i":1539,"$":{"0":{"v":"Temporality","n":1},"1":{"v":"\n- [[p.similarReferentTo]] [[t.cs.data.temporality]]","n":0.577}}},{"i":1540,"$":{"0":{"v":"Shoot Em Up","n":0.577}}},{"i":1541,"$":{"0":{"v":"Server","n":1},"1":{"v":"\n## Resources\n\n### Learning Resource\n\n- http://underpop.online.fr/j/java/help/multi-player-game-server-framework-multi-player-games-java.html.gz","n":0.447}}},{"i":1542,"$":{"0":{"v":"Serious Games","n":0.707}}},{"i":1543,"$":{"0":{"v":"Sandbox Games","n":0.707},"1":{"v":"\n- [[p.alsoKnownAs]]  non-games; software toys\n\n","n":0.447}}},{"i":1544,"$":{"0":{"v":"RPG video games","n":0.577},"1":{"v":"\n- different-from: [[t.roleplaying.games]]\n\n## Thoughts\n\n- RPG video games have somehow become a cliche that involves very little role-playing. If you can't express yourself, you can't play a role. There's a hazy difference between consuming a choice and expressing a preference or making something happen.\n\n## Resources\n\n- https://libregamewiki.org/Role-playing_games\n","n":0.149}}},{"i":1545,"$":{"0":{"v":"Jrpg","n":1}}},{"i":1546,"$":{"0":{"v":"Rollback","n":1},"1":{"v":"\n\n\n- https://antsstyle.medium.com/web3-a-terrible-idea-that-is-ignorant-of-history-and-technology-92398ee66c3f?p=b76ee54ac2bb\n- https://arstechnica.com/gaming/2019/10/explaining-how-fighting-games-use-delay-based-and-rollback-netcode/\n","n":0.577}}},{"i":1547,"$":{"0":{"v":"Roguelike","n":1},"1":{"v":"\n- uses: [[prdct.simpleecs]]\n\n## Resources\n\n- https://github.com/proc-gen/rogue-tutorial does the Rust tutorial in c#\n","n":0.302}}},{"i":1548,"$":{"0":{"v":"Procedural Generation","n":0.707},"1":{"v":"\n## [[c.resource.list]]\n\n- https://wiki.secretgeek.net/random-dungeon-generators","n":0.577}}},{"i":1549,"$":{"0":{"v":"Persistent Room","n":0.707},"1":{"v":"\n- this isn't the right term for the multiplayer reality-breaking of \"everyone can get the unique item/same quest\" issue with game design\n","n":0.213}}},{"i":1550,"$":{"0":{"v":"Pay to Win","n":0.577},"1":{"v":"\n- aka p2w\n- ","n":0.577}}},{"i":1551,"$":{"0":{"v":"Netcode","n":1},"1":{"v":"\n## Resources\n\n- https://meseta.medium.com/netcode-concepts-part-1-introduction-ec5763fe458c","n":0.577}}},{"i":1552,"$":{"0":{"v":"Delta Snapshots","n":0.707},"1":{"v":"\n- \"messages that are custom-tailored to each player\"\n- \"If deltas are absolute, there is no need for clients to store past states. The server can calculate the delta from the last acknowledged state\"\n\n## Process\n\n- first snapshot is the Gamestate in its entirety\n- each snapshot has a sequence number. If the client receives a snapshot that has an older sequence number than the last received, it is discarded,\n- When the client receives a snapshot, it also acknowledges the receipt to the server by sending the sequence number.\n- The server now knows what the client knows. It can generate custom-tailored snapshots based on the last acknowledged sequence number, sending the client only the data that has changed. This is what’s called a delta snapshot.\n\n## Caveat\n\n- Snapshots aren’t suitable for all games. They’re great for non-deterministic physics-based games that require frequent synchronization on a limited amount of entities. If you have a fully deterministic game (meaning the same inputs will produce the exact same result each time) such as a fighting game, input rollback systems are a better, more efficient way to go, with no need for positional deltas. If you’re making an RTS with hundreds or thousands of entities, you’ll need a different network model altogether.\n\n## References\n\n- https://medium.com/@geretti/netcode-series-part-2-data-channels-c12e9a238800\n  - \"Is the data latency important?— Is the data essential to game state?\"\n  - \"Projectile hits, however, are not entities. They don’t spawn, carry changing properties, or despawn. They are discrete events. Snapshots can tell the client that the enemy health was reduced by 30hp, but they can’t inform if it was caused by a single 30hp hit, or 3x10hp hits.\n    - thought: \n      - snapshotting < events;\n      - clients are going to have to be \"dumb\" in the sense that they don't have the data/assets built in. almost everything gets computed on the server side\n      - using deltas is useful with [[t.cs.distributed.crdt]], \n\n      - see [[t.cs.graph]]","n":0.057}}},{"i":1553,"$":{"0":{"v":"Matchmaking","n":1},"1":{"v":"\n## Resources\n\n- [Skill, Matchmaking, and Ranking Systems Design - YouTube](https://www.youtube.com/watch?v=-pglxege-gU)\n","n":0.316}}},{"i":1554,"$":{"0":{"v":"Ludology","n":1},"1":{"v":"\n\n## References\n\n- https://www.reddit.com/r/changemyview/comments/1wu9bx/ludology_is_a_useless_area_of_research_and_anyone/\n- [[ar.atlantic.video-games-are-better-without-stories]]","n":0.5}}},{"i":1555,"$":{"0":{"v":"Game Loop","n":0.707},"1":{"v":"\n- [[p.hasLearningResource]] \n  - [-] https://gameprogrammingpatterns.com/game-loop.html","n":0.408}}},{"i":1556,"$":{"0":{"v":"Recurisve Game Loop","n":0.577},"1":{"v":"\n## Resources\n\n- https://stackoverflow.com/questions/12070404/functional-programming-recursing-a-game-state-loop\n- https://stackoverflow.com/questions/71909776/how-can-i-get-typescript-to-perform-tail-recursion-optimization\n- https://javascript.plainenglish.io/javascript-optimizations-tail-call-optimization-tco-471b4f8e4f37\n  - [[p.hasHighlight]] \n    - [[prdct.v8]] had [[t.cs.recursion.tail-call-optimization]] but took it out","n":0.25}}},{"i":1557,"$":{"0":{"v":"Lighting","n":1}}},{"i":1558,"$":{"0":{"v":"Hash Grid","n":0.707},"1":{"v":"\n- [[c.implementation]]\n  - https://github.com/hmans/ingrid\n- [[p.hasLearningResource]]\n  - https://www.youtube.com/watch?v=oewDaISQpw0","n":0.378}}},{"i":1559,"$":{"0":{"v":"Game Graphics","n":0.707}}},{"i":1560,"$":{"0":{"v":"Quaternion","n":1},"1":{"v":"\n## @chatgpt.4\n\nThe representation of rotation with four components — x, y, z, w — typically refers to a quaternion. Quaternions are a mathematical concept used in 3D programming, including graphics, physics, and game development, for efficiently handling rotations. Here's why quaternions use four components:\n\n    Complex Numbers Extension: A quaternion extends the concept of complex numbers. While a complex number has a real part and an imaginary part (i.e., a + bi), a quaternion has one real part and three imaginary parts, leading to four components in total (a + bi + cj + dk).\n\n    3D Rotation Representation: In 3D space, rotations occur around an axis. A quaternion uses the x, y, z components to represent the axis of rotation (in vector form), and the w component to represent the angle of rotation. This is based on the formula:\n    Quaternion=cos⁡(θ/2)+isin⁡(θ/2)x^+jsin⁡(θ/2)y^+ksin⁡(θ/2)z^Quaternion=cos(θ/2)+isin(θ/2)x^+jsin(θ/2)y^​+ksin(θ/2)z^\n    where θθ is the rotation angle, and x^x^, y^y^​, z^z^ are the normalized components of the rotation axis.\n\n    Avoiding Gimbal Lock: One significant advantage of quaternions over other rotation representations (like Euler angles) is their ability to avoid gimbal lock. Gimbal lock occurs when two of the three rotation axes align, causing a loss of one degree of freedom in rotation. Quaternions, by nature of their mathematical properties, do not suffer from this problem.\n\n    Interpolation Smoothness: Quaternions are particularly useful for smooth interpolations in rotations (slerp - spherical linear interpolation). This is crucial in graphics and animations where smooth transitions between different orientations are needed.\n\n    Numerical Stability: Quaternions are less susceptible to numerical errors over multiple operations compared to other methods like rotation matrices. This is particularly important in real-time 3D applications, where many rotations are applied successively.\n\n    Compact and Efficient: Despite having four components, quaternions are more compact than rotation matrices (which require nine components for 3D rotations). They are also computationally efficient for many operations, such as combining rotations.\n\nUnderstanding and working with quaternions can be more complex than dealing with traditional Euler angles or matrices, but their advantages in 3D computations make them a preferred choice in many applications.","n":0.054}}},{"i":1561,"$":{"0":{"v":"General Game Playing","n":0.577},"1":{"v":"\n\n## References\n\n- http://ggp.stanford.edu/notes/overview.html","n":0.577}}},{"i":1562,"$":{"0":{"v":"Game Time","n":0.707}}},{"i":1563,"$":{"0":{"v":"Game Geometry","n":0.707},"1":{"v":"\n## Implementations\n\n- [[prdct.earth-system-modeling-framework]]\n\n## #resources\n\n- https://tvtropes.org/pmwiki/pmwiki.php/Main/VideoGameGeography\n  - #highlight\n    - Type 1: map types include toruses, cylinders, flat-and-rectangular, flat-and-country-shaped\n      - [[p.hasJustification]] spheres are hard\n    - Type 2: screwing with geography for the [[idea.rule-of-fun]]\n- https://www.redblobgames.com/x/1938-square-tiling-of-sphere/\n- https://www.redblobgames.com/x/1932-sphere-healpix/ which mentions:\n  -   [Dimitrijević, A., Lambers, M., & Rančić, D. (2016): Comparison of spherical cube map projections used in planet-sized terrain rendering](https://www.semanticscholar.org/paper/COMPARISON-OF-SPHERICAL-CUBE-MAP-PROJECTIONS-USED-Dimitrijevic-Lambers/8cf18f4813589713b5b61af9a646141eb9a75156)\n  -   [Lambers, M.: Survey of Cube Mapping Methods in Interactive Computer Graphics (2019)](https://marlam.de/publications/cubemaps/lambers2019cubemaps.pdf)\n- https://earthsystemmodeling.org/regrid/#coordinate-systems\n","n":0.12}}},{"i":1564,"$":{"0":{"v":"Field of View","n":0.577},"1":{"v":"\n## Resources\n\n- https://www.quora.com/What-would-be-a-realistic-FOV-field-of-view-for-1st-person-video-games\n\n","n":0.577}}},{"i":1565,"$":{"0":{"v":"Entity Interpolation","n":0.707},"1":{"v":"\n## c.Resource\n\n- https://www.gabrielgambetta.com/entity-interpolation.html\n- https://ruoyusun.com/2019/03/28/game-networking-1.html","n":0.5}}},{"i":1566,"$":{"0":{"v":"Economy","n":1},"1":{"v":"\n## Best Practices\n\n## Overview\n\nSteam provides world class support for in game purchases, whether that is items, in-game currency, or anything else that you can think up, you can use the Steam Microtransaction APIs to provide customers with more choices.\n\nIf you are working to bring your title with in-game purchases to Steam, we've got a few suggestions, best practices, and resources to help you get started. Whether you have a Free to Play game, or a game that is purchased upfront, there are common elements with any game that has in-game purchases that are useful to consider when working toward your launch on Steam.\n\n## In-Game Purchase Requirements\n\nFor any in-game purchases, you'll need to use the microtransaction API so Steam customers can only make purchases from the Steam Wallet. You can learn more about how to complete this integration in the [Microtransactions Implementation Guide](https://partner.steamgames.com/doc/features/microtransactions/implementation).\n\nYou can use the Steam Wallet to purchase individual items or to purchase your in-game currency.\n\n## Anticipating Fraud\n\nYou run a risk of fraud any time you offer something of value that can be purchased. For your in-game store, Steam is providing services as a payment processor – Steam runs fraud checks, but the context in which a user makes a purchase in your game is something that only your game servers can understand.\n\nYour game is especially vulnerable if the in-game purchases are part of an economy where virtual goods and services can be traded or gifted. If fraud is allowed to run rampant and unchecked, it can devalue the items in the economy or create game imbalance that ruins the gameplay experience of legitimate users.\n\nFraud often involves a user purchasing high-value currency and items with a stolen payment method (such as a credit card). The fraudsters’ goal is to move those virtual goods to other accounts, either owned by the fraudster or a player who is paying for those goods outside of the system. Alternatively, fraudsters may attempt to sell the entire account, again while being paid outside of the system.\n\nYour team will need to find a balance within your economy that blocks bad users, yet does not impact your legitimate users. Here are some general suggestions as starting points for basic protection against easy forms of fraud:\n\n1.  Use in-game knowledge of a user’s history to limit actions that can contribute to fraud. For example, if you know the player is really new, then it’s generally a good idea to limit purchase of high-value items or currency. It’s unlikely that a brand-new legitimate user is interested in buying $200 worth of items or currency. To accomplish this, it’s useful to incorporate a number of points of data about the user.  \n    -   Has the user leveled up in your game to some minimum level?  \n        \n    -   Has the user made past purchases? Does their behavior look legitimate?  \n        \n    -   What are typical average purchase amounts across your game for a month? Is this transaction suspiciously far outside that range?  \n        \n    -   How many transactions do your typical paying customers make in a month? Is this user making a suspiciously large number of transactions?  \n        \n    -   Does this user have a history of trading that looks legitimate?  \n        \n2.  Use Steam’s knowledge of a user’s history to inform your concern about a specific transaction or user. You can get information from Steam to help you determine what actions a user should be allowed to perform. Call [GetUserInfo()](https://partner.steamgames.com/doc/webapi/ISteamMicroTxn) in the ISteamMicroTxn API to get information about the user. Three main responses may be useful in determining how much you trust the user:  \n    -   Country – returns the country where the user is connecting from to make their purchase. By itself it isn’t very informative, but can be useful in conjunction with Currency.  \n        \n    -   Currency – returns the currency code of the user’s Steam Wallet. Commonly, this is used to determine what pricing information should be displayed to the user, but by checking the currency against the country where the request is coming from, you can see whether the currency matches what is expected for a user from that country. This doesn’t necessarily indicate fraud--users can login and make purchases while traveling, but performing this check gives you more information when looking for patterns in fraudulent activity.  \n        \n    -   Status – returns either ‘Active’, ‘Trusted’, or ‘Locked’.  \n        1.  An account is Active by default.  \n            \n        2.  Trusted accounts have a transaction over 90 days old without any chargebacks associated with the Steam account. It is important to note that a Trusted account may still be hijacked or ‘baked’ with a low value purchase to appear legitimate. This status should not be the sole determining factor to accept or reject a purchase.  \n            \n        3.  A Locked account cannot make purchases in Steam because of fraud, chargeback, a hijack, or a violation of the Steam Terms of Service. This status is not always permanent, especially in the case of hijacking or accidental chargebacks by banks.\n3.  Catching fraudulent transactions before they can impact the economy is important.  \n    -   Steam catches most fraudulent transactions within 48 hours of the initial purchase. Call the [GetReport()](https://partner.steamgames.com/doc/webapi/ISteamMicroTxn#GetReport) API at least once each day to reconcile changes to transactions according to their updated [status](https://partner.steamgames.com/doc/features/microtransactions/implementation#status_values).  \n        \n    -   You should prevent trading or gifting of the newly purchased items for at least 72 hours from the time of purchase. This will not impact the majority of your players since most players will use funds and items purchased for themselves while fraudsters must move their fraudulent goods to profit.  \n        \n    -   When purchases are refunded, an automatic ‘claw-back’ system removing the funds and items purchased on the fraudulent account deters further behavior. Combined with the detection time and trade restriction, the fraudster will not have profited from the fraudulent account.\n4.  Don't display a product key for in-game purchases that could be harvested for another account. There are Steam APIs for granting packages or unlocking content without needing to display a key to customers that can potentially be duplicated.  \n    \n5.  Don't allow users to change the linked accounts that are described in the next section: Linking Accounts.\n\nUsing the Steam Inventory Service incorporates many of these suggestions.\n\n## Linking Accounts\n\nDo you have your own account system? If so, we strongly encourage you to use Steamworks API to automatically create or link the Steam customer's account with your system, rather than requiring the customer to manually create an account through your game or website. Creating a new account through another service can be a huge hurdle for some customers, and can significantly impact your potential audience.\n\nLinking a user’s Steam account to your own system can be done by retrieving and verifying a user’s SteamID, which is a unique identifier for a Steam account.\n\nIdeally, it shouldn't be possible for a customer to disassociate their Steam account from your account system and then re-link another Steam account.\n\nFor more information on account linking, please see the \"Account Linking\" section in the [User Authentication and Ownership](https://partner.steamgames.com/doc/features/auth) documentation.\n\n## Considerations for in-game economies and best practices\n\nSteamworks provides a variety of opportunities to integrate microtransactions and in-game economies. There are a few things to consider on the topic.\n\nWatch Kyle Davis’s presentation from Steam Dev Days for more detailed information.\n\n![](https://img.youtube.com/vi/RHC-uGDbu7s/0.jpg)\n\nYouTube™ Video: In-Game Economies in Team Fortress 2 and Dota 2 (Steam Dev Days 2014) \n\nViews: 102,767\n\nA look at the multi-year history and development of the in-game economies and microtransaction systems in Team Fortress and Dota, including some of the surprises we encountered and some of the...\n\n1.  #### Use your in-game economy to improve your product and make customers happier, not as a means to extract revenue from unhappy customers.\n    \n    Artificial barriers to progress and virtual currencies that obfuscate value tend to make customers regret their purchases over the long term. If you’re viewing in-game transactions as an opportunity to halt your customer’s enjoyment to ask for money, they’ll be inclined to abandon the product over time. Paying money to eliminate frustration is not a sustainable business model, and the marketplace is competitive enough that customers have lots of better alternatives for their time and money.  \n    \n2.  #### Build systems wherein customer purchases make your game better for other customers.\n    \n    Many free to play products, especially multiplayer games, rely on systems where the more money one player spends, the worse the game gets for the other players. Avoid building systems where players have the ability to negatively impact other players’ experiences, and focus instead on products and items that create positive externalities within your game. We cite specific examples in the Steam Dev Days presentation, but a good starting point is a product designed around a simple concept: \"I celebrate when the player next to me makes a purchase.\" This is feasible for games of all genres and styles, and we encourage you to run experiments around such products in your own games.  \n    \n3.  #### Allow your users to create value for one another.\n    \n    The Steam Workshop consists of tools that allow your customers to create content and value for one another. Customers can create models, maps, mods, or other valuable components for your game. Depending on your product and your goals, you can choose between an open or curated Workshop. In either case, the creativity and passion of your customers can greatly expand the value of your product and provide you with a great source of additional content. Check out the [Steam Workshop](https://partner.steamgames.com/doc/features/workshop) documentation and [Steamworks Developer Discussions](http://steamcommunity.com/groups/steamworks/discussions/9/) for more information about the Steam Workshop.\n\nOverall, being a slave to metrics like revenue-per-day or per-user can drive short-term decisions that harm your players and the longevity of your product. Watch the full Steam Dev Days talk above for specific examples and additional insights.\n\n## Getting The Most From Updates\n\nUpdates are an important part of your product's lifecycle and a critical form of communication with customers. You'll need to make updates to fix bugs and address issues, but major updates are also a huge opportunity to add new content, new modes of play, or new features to help keep customers engaged and attract new audiences.\n\nCheck out [Best Practices, Marketing](https://partner.steamgames.com/doc/marketing/bestpractices) documentation for suggestions and best practices around getting the most from your product updates.\n\n\n## References\n\n- https://partner.steamgames.com/doc/features/microtransactions#4\n- ","n":0.024}}},{"i":1567,"$":{"0":{"v":"Game Design","n":0.707},"1":{"v":"\n## Commandments\n\n-   Always Show the Goal\n    \n-   Problems not Puzzles\n    \n-   No Forced Failure\n    \n-   It’s About Varied Character Interaction\n    \n-   Players Do; NPC’s Watch\n    \n-   Reward Players Regularly\n    \n-   Players Get Smarter and the Game Will Get More Challenging\n    \n-   Think 3D - Geometry will contribute to gameplay\n    \n-   Routes Will Be Interconnected - Locations will be reachable in several ways\n    \n-   Problems Will Have Multiple Solutions\n    \n-   Players Will Surprise Themselves AND Us\n\n### IMMERSE PLAYERS IN THE GAME WORLD\n\nThis one’s simple – don’t throw too much game-iness at players... Build UI and metagame elements into the gameworld itself. Don’t insert a bunch of cutscenes.\n\nNever remind players they’re just playing a game. You want them thinking it’s THEM in the world you’ve created, responding to things – causing things – that make sense to them in the context of your world.\n\nThere’s a reason I work in a genre called IMMERSIVE simulation.\n\n#### and yet...\n\n- D&D is immersive theater of the mind. Everything sensory is game-y.\n- wandering around [[game.odyssey]] is fun, at least for me\n\n\n## Resources\n\n- [[book.game-programming-patterns]]\n- [[ar.gamedeveloper.what-i-ve-learned-about-designing-multiplayer-games-so-far]]\n\n## References\n\n- https://www.gamedeveloper.com/design/thoughts-to-live-by","n":0.075}}},{"i":1568,"$":{"0":{"v":"Blockchain","n":1},"1":{"v":"\n\n## Resources\n\n- https://www.gate.io/learn/articles/annual-summary-of-omnichain-games-in-2023/1684\n- https://ogpetya.medium.com/the-power-of-secrets-zero-knowledge-proofs-in-game-development-a5308f857505\n- ","n":0.5}}},{"i":1569,"$":{"0":{"v":"Finite State Machine","n":0.577}}},{"i":1570,"$":{"0":{"v":"ECS","n":1},"1":{"v":"\n## Definition\n\n### @sander-mertens\n\n#### Entities & Components\n\n-   An entity is a unique identifier\n-   A component can optionally be associated with a plain old datatype\n-   A component identifier is an entity\n-   An entity can have 0 .. N components\n-   A component can be annotated with a role\n-   An <entity, component> tuple can have 0 .. N components\n\n#### Systems\n\n-   A system is logic matched with entities based on their components\n-   A system is invoked as result of an event\n-   A component mutation is an event\n-   Computing a simulation frame is an event\n-   A frame is divided into N phases\n-   Each system is assigned to a phase\n\n### https://forums.coregames.com/t/advanced-code-architecture-for-core-part-2-entity-component-system/3194\n\n- ECS game object is a DDD Entity; an ECS Entity is a DDD Identity; an ECS Component is a DDD Domain Model; and an ECS System is a DDD Service or Aggregate Root. ^h56imtf2ip3n\n  - [[c.thought]] i.e., an \"ECS game object\" is the entity (which is just an ID + list of components) + the functionality and data given by components?\n\n## Implementations\n\n- [[prdct.unity]]\n  - docs:  https://docs.unity3d.com/Packages/com.unity.entities@0.1/manual/index.html\n- [[prdct.arch]] (C#)\n- [[prdct.bitecs]] (Javacript)\n  - \"Strings are expensive and usually unnecessary to have the ECS handle. Instead, create a mapping of integers to strings, and store the integers in the component data as a reference to a string. This makes string serialization minimal and fast.\" ^34ftr5hv1m8u\n- [[prdct.data-oriented-pyglet]]\n- [[prdct.bevy]]\n\n### other implementations\n\n- [[prdct.tick-knock]]\n- [[prdct.a-frame]]\n  - docs:  https://aframe.io/docs/1.3.0/introduction/entity-component-system.html\n  - https://stackoverflow.com/questions/43944365/how-to-do-multiuser-in-a-frame\n  - [[p.supports]] [[prdct.networked-aframe]]\n\n## Wish List\n\n### Entity Relations\n\n- [[prdct.flecs]] has 'em\n- [[prdct.bevy]] doesn't seem to\n  - see https://github.com/bevyengine/bevy/issues/3742\n  - \n\n## Issues\n\n- https://medium.com/@rdolivo/ecs-for-gamedev-with-typescript-5a1204f594bc\n  - Systems are highly dependent on the order in which they are added because their logic works out consistently. Adding new systems between existing ones can be a difficult task.\n    - [[p.provokedThoughts]]\n      - what if you required every system to be executable in any order. something like [[idempotence|t.cs.idempotence]], but for ordering\n  - Changing the content of components can potentially break down many systems.\n- \"Anything that needs a dynamic ordering of execution is not very intuitive in ECS\" \n  - https://forum.unity.com/threads/why-vanilla-ecs-is-not-enough\n    - \"Why not put the 'timer' in each component ? Yes you'll need to have one system to update the timer of each type of component having a time... it would be better to have a timmer logic that store the next tick time instead of storing aremaining time that you update every frame. It would allow to make use of the DidChange filtering. Also you could probably define a ITimer interface that your ComponentData would implement and taht should allow you to stream line the timer update systems a bit through generics.\"\n- \"One of the biggest \"obstacles\" (questions) I see is that there will always inevitably be the need to interface with long-running \"continuous\" processes (maybe because of networking with a much different frequency than the one ECS pipeline of systems is being executed with, maybe because devs will want to use an already written external library spawing own threads without any poll-like API, maybe because there will be a separate event loop system which will not easily integrate with the ECS event loop, etc.).\"\n  - https://github.com/traffaillac/traffaillac.github.io/issues/1\n- Spatial Storage\n  - \"How to store spatial data in ECS?\n\nSpatial data structures like quadtrees and octrees are usually not directly stored in an ECS, as their layout does not match well with the typical ECS layout.\n\nOne approach that works well for narrow-phase spatial queries in combination with an ECS is to create a query that iterates relevant entities and stores them in a spatial structure at the beginning (or end) of each frame.\n\nFor broad-phase spatial queries an application could leverage runtime tags (if the ECS supports it) where a tag corresponds with a cell in a spatial grid. Combined with queries that match the tag, an application can quickly discard large groups of entities that are not in a certain area.\"\n\n### Scripting\n\n- https://www.reddit.com/r/gameenginedevs/comments/13dd4k9/scripts_in_ecs/ has two suggestions, moved toward #2: \n  - \"create a special script component and then a system to process these script components.\"\n  - \"store a reference to the script (function pointer in the example, but could be a function name or id if the script is something like Lua) in components and then have that components system call the script.\"\n    - scripts get queued and my scripting engine is decoupled from the ECS.\n\n\n## Resources\n\n- https://github.com/SanderMertens/ecs-faq #cool\n- https://maxwellforbes.com/posts/typescript-ecs-why/\n  - [[p.hasHighlight]]\n    - \"the idea isn’t that there’s a fixed target called a “game engine” that you go out and build, and then you build the game on top of it. For my case at least, the engine is the broader codebase that evolves around the game as you build it.\"\n    - \"People like building shit. It’s fun. It’s really fun.\"\n- [[course.gamedev-patterns-ts]]\n- [[ar.medium.ajmmertens.why-vanilla-ecs-is-not-enough]] \n  - \"Consider creating a “Timer” component that removes a component after N seconds, for example to remove a buff from an entity. An entity can have multiple buffs at the same time, yet I can only add the Timer component once. Solutions to this problem get unwieldy (storing a map in the component value or creating a Timer component for each buff component). This is a serious limitation when applications want to implement generic systems.\"\n  - \"Any design language that does not allow me to specify the preconditions for something to work correctly is in my humble opinion flawed.\"\n- https://conferences.oreilly.com/software-architecture/sa-ny/public/schedule/detail/79975.html\n- https://gamedev.stackexchange.com/questions/56937/how-to-avoid-blob-systems-in-an-entity-component-system\n  - \"There's no reason to have fine-grained components like 'movement'. There is no generic movement in your game. You have paddles, whose movement is tightly tied to input or AI (and don't really use velocity, acceleration, restitution, etc.), and you have the ball, which has a well-defined movement algorithm. Just have a PaddleController component and a BouncingBall component or something along those lines. If/when you get a more complicated game then you can worry about having a more generic PhysicsBody component (which in 'real' engines is basically just a link between the game object and whatever internal API object is used by Havok/PhysX/Bullet/Box2D/etc.) that handles a wider variety of situations.\"\n- [[ar.medium.ajmmertens.why-it-is-time-to-start-thinking-of-games-as-databases]]\n  - mentions: \n  - also https://ajmmertens.medium.com/a-roadmap-to-entity-relationships-5b1d11ebb4eb\n- https://www.reddit.com/r/gamedev/comments/nb093f/netcode_ecs_data_organization/\nsh\n- https://moonside.games/posts/archetypal-ecs-considered-harmful/ \n- https://www.reddit.com/r/gameenginedevs/comments/1abdisc/practices_for_managing_systems_order_in_ecs/ has some interesting suggested for ordering systems runs\n- https://www.reddit.com/r/gamedev/comments/yctgea/ecs_rules_dos_and_donts_and_best_practices_for/\n\n### [[c.resource.list]]\n\n- https://github.com/Chillu1/CSharpECSComparison\n","n":0.032}}},{"i":1571,"$":{"0":{"v":"End User Programming","n":0.577}}},{"i":1572,"$":{"0":{"v":"Durable Execution","n":0.707},"1":{"v":"\n## Story\n\n- After Amazon (one of the first large adopters of microservices) decided that using message queues to communicate between services was not the way to go (hear the story first-hand [here](https://www.youtube.com/watch?v=wIpz4ioK0gI)), they started using orchestration. And once they realized defining orchestration logic in YAML/JSON wasn’t a good developer experience, they created [AWS Simple Workfow Service](https://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-welcome.html) to define logic in code. This technique of backing code by an orchestration engine is called durable execution, and it spread to [Azure Durable Functions](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp-inproc), [Cadence](https://cadenceworkflow.io/) (used at Uber for [\\> 1,000 services](https://www.uber.com/blog/announcing-cadence/)), and [Temporal](https://temporal.io/) (used by Stripe, Netflix, Datadog, Snap, Coinbase, and many more).\n\n## References\n\n- https://temporal.io/blog/time-travel-debugging-production-code","n":0.099}}},{"i":1573,"$":{"0":{"v":"Duck Typing","n":0.707},"1":{"v":"\n## Resources\n\n- https://devopedia.org/duck-typing\n  - [[p.hasHighlight]]\n    - What really matters is if the object has the particular methods/attributes at run time. Duck typing is therefore often supported by [[t.cs.languages.typed.dynamically]].","n":0.189}}},{"i":1574,"$":{"0":{"v":"DSL","n":1},"1":{"v":"\n## Resources\n\n- https://tomassetti.me/category/language-engineering/domain-specific-languages/\n- http://voelter.de/data/books/markusvoelter-dslengineering-1.0.pdf\n- [[c.resource.list]] http://dsl-course.org/language-workbenches/\n- https://medium.com/@dslmeinte/are-language-workbenches-dead-4b05d1698d3c\n  - \"even though MPS is a standalone product, it comes with Git support for DSL prose, and DSL implementation can be exported as plugins for IntelliJ/IDEA. Xtext, Spoofax, and Rascal are firmly ensconced in the Eclipse ecology\"\n\n### c#\n\n- https://learn.microsoft.com/en-us/archive/msdn-magazine/2010/january/patterns-in-practice-internal-domain-specific-languages\n  - \"it has been extremely helpful to separate the runtime behavior into a “semantic model,” defined by Martin Fowler as “The domain model that’s populated by a DSL” (https://martinfowler.com/dsl.html).\"","n":0.115}}},{"i":1575,"$":{"0":{"v":"Distributed Computing","n":0.707}}},{"i":1576,"$":{"0":{"v":"Lamport Clock","n":0.707},"1":{"v":"\n- similar: [[t.cs.data.temporality.hybrid-time]]\n\n## Resources\n\n- https://www.oreilly.com/library/view/patterns-of-distributed/9780138222246/ch22.xhtml","n":0.447}}},{"i":1577,"$":{"0":{"v":"Distributed Hash Table","n":0.577},"1":{"v":"\n## Examples\n\n- [Noosphere Name System](https://github.com/subconsciousnetwork/noosphere/blob/main/design/name-system.md)","n":0.447}}},{"i":1578,"$":{"0":{"v":"CRDT","n":1},"1":{"v":"\n## Summary\n\n-   The application can update any replica independently, [concurrently](https://en.wikipedia.org/wiki/Concurrent_computing \"Concurrent computing\") and without [coordinating](https://en.wikipedia.org/wiki/Concurrency_control \"Concurrency control\") with other replicas.\n-   An algorithm (itself part of the data type) automatically resolves any inconsistencies that might occur.\n-   Although replicas may have different state at any particular point in time, they are guaranteed to eventually converge.\n  \n## Description\n\n- objects can’t be destroyed but disabled. Moreover operations that impact the model must follow 3 constraints: they can be applied in any order (commutative and associative) and as many times as needed (idempotent, meaning that you can apply an operation twice and still have the same result as if you apply it once). The great thing is conflicts are then impossible: if you move an object that has just been “destroyed”, you’ll in fact move a “hidden” object. But as a result, your model will be monotonically growing, and designing operations with such constraints becomes quickly difficult with a part of research and risk associated with it.\n\n\n## Resources\n\n- https://irisate.com/collaborative-editing-solutions-round-up/","n":0.078}}},{"i":1579,"$":{"0":{"v":"Digital Twin","n":0.707},"1":{"v":"\n## History\n\nIn the mid-2000s, a manufacturing expert named Michael Grieves started to spitball ways to make factories more efficient. Instead of a manager peering down on the factory floor from above, trying to sense how things were going, Grieves thought there should be an exact virtual replica of every physical nook, cranny, machine, forklift and worker that the manager could analyze on a computer screen. Create an endless stream of data from a network of sensors and cameras that flowed from the real factory to the virtual one, and you’d get an ever-changing real-time representation of its brick-and-mortar counterpart. Anything that changed in the factory would change in the model, instantly: the physical and the virtual locked together in what the French philosopher Jean Baudrillard might have called an “ecstasy of communication.” \n\nWhat power this would give a factory manager! Perhaps they wanted to see how a change to one of the production lines would impact the entire operation. Run a simulation to see how it might play out. Should anything go wrong, rewind it back, find out what the hell happened. Heck, the manager wouldn’t even need to be anywhere near the physical factory — they could be off in a beach house on some idyllic island. \n\nGrieves, along with a NASA researcher named John Vickers who had been mulling over a very similar idea, called this a “digital twin.” “Not only the factory manager, but everyone associated with factory production could have that same virtual window to not only a single factory, but to all the factories across the globe,” he wrote in 2014. Here at last was Hamlet’s king of infinite space.\n\n## References\n\n- https://www.noemamag.com/a-digital-twin-might-just-save-your-life/","n":0.06}}},{"i":1580,"$":{"0":{"v":"Differential Synchronization","n":0.707},"1":{"v":"\n## Implementations\n\n- [[prdct.git]]\n\n## Description\n\n- as it doesn’t provide merging solution for every complex conflict situation and relies on manual conflict management, we can’t consider it as a real solution for Real Time Collaboration as defined above","n":0.167}}},{"i":1581,"$":{"0":{"v":"Debugging","n":1}}},{"i":1582,"$":{"0":{"v":"Reverse Debugging","n":0.707},"1":{"v":"\n## History\n\nIt all started with Smalltalk-76, developed in 1976 at [Xerox PARC](https://en.wikipedia.org/wiki/PARC_(company)). ([Everything](https://en.wikipedia.org/wiki/Graphical_user_interface) [started](https://en.wikipedia.org/wiki/Computer_mouse) [at](https://en.wikipedia.org/wiki/Ethernet) [PARC](https://en.wikipedia.org/wiki/WYSIWYG) 😄.) It had the ability to retrospectively inspect checkpointed places in execution. Around 1980, MIT added a “retrograde motion” command to its [DDT debugger](https://en.wikipedia.org/wiki/Dynamic_debugging_technique), which gave a limited ability to move backward through execution. In a 1995 paper, MIT researchers released ZStep 95, the first true reverse debugger, which recorded all operations as they were performed and supported stepping backward, reverting the system to the previous state. However, it was a research tool and not widely adopted outside academia.\n\nODB, the [Omniscient Debugger](https://omniscientdebugger.github.io/ODBUserManual.html), was a Java reverse debugger that was introduced in 2003, marking the first instance of time-travel debugging in a widely used programming language. [GDB](https://en.wikipedia.org/wiki/GNU_Debugger) (perhaps the most well-known command-line debugger, used mostly with C/C++) added it in 2009.\n\nNow, time-travel debugging is available for [many](https://github.com/rr-debugger/rr/wiki/Related-work) languages, platforms, and IDEs, including:\n\n-   [Replay](https://www.replay.io/) for JavaScript in Chrome, Firefox, and Node, and [Wallaby](https://wallabyjs.com/docs/intro/time-travel-debugger.html) for tests in Node\n-   [WinDbg](https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/time-travel-debugging-overview) for Windows applications\n-   [rr](https://rr-project.org/) for C, C++, Rust, Go, and others on Linux\n-   [Undo](https://undo.io/) for C, C++, Java, Kotlin, Rust, and Go on Linux\n-   Various extensions (often rr- or Undo-based) for Visual Studio, VS Code, JetBrains IDEs, Emacs, etc.\n\n## References\n\n- https://temporal.io/blog/time-travel-debugging-production-code","n":0.07}}},{"i":1583,"$":{"0":{"v":"dApp","n":1},"1":{"v":"\n\n- [[p.hadDefinition]] a program that resides and executes on a blockchain or peer-to-peer network\n\n## Resources\n\n- https://blog.suhailkakar.com/what-are-dapps-a-complete-guide-to-decentralized-applications?source=newsletter\n","n":0.25}}},{"i":1584,"$":{"0":{"v":"Collaboration","n":1}}},{"i":1585,"$":{"0":{"v":"Casing","n":1},"1":{"v":"\n\nsentie","n":1}}},{"i":1586,"$":{"0":{"v":"snake_case","n":1},"1":{"v":"\n## Pros\n\n- works with javascript properties","n":0.408}}},{"i":1587,"$":{"0":{"v":"camelCase","n":1}}},{"i":1588,"$":{"0":{"v":"Authorization","n":1}}},{"i":1589,"$":{"0":{"v":"Macaroons","n":1},"1":{"v":"\n## References\n\n- [[ar.macaroons-cookies-with-contextual-caveats-for-decentralized-authorization-in-the-cloud]] ","n":0.577}}},{"i":1590,"$":{"0":{"v":"Capability Based","n":0.707},"1":{"v":"\n- implementations: [[prdct.e]]\n- related: [[t.cs.authorization.macaroons]] [[prdct.storj]]\n\n## Description\n\n- \"In capability systems, a subject corresponds to an instance of a software component, such as an object (an instance of a class, as in a capability language) or a process (an instance of an executable program, as in a capability operating system).\"\n- \"By tying access to key, rather than a centralized control system, Capability-based models push security to edge, decentralizing large attack vectors known as honeypots.\"\n\n## References\n\n- [[ar.capability-myths-demolished]]\n- https://medium.com/@kleffew/what-is-capability-based-security-227c6e5483a5\n- https://github.com/bytecodealliance/wasmtime/blob/main/docs/WASI-capabilities.md\n- http://erights.org/elib/capability/index.html","n":0.113}}},{"i":1591,"$":{"0":{"v":"Authentication","n":1},"1":{"v":"\n\n\nthe attempt to ensure that an agent's actions originate from the agent\n","n":0.289}}},{"i":1592,"$":{"0":{"v":"Augmented Reality","n":0.707}}},{"i":1593,"$":{"0":{"v":"Simultaneous Localization and Mapping","n":0.5}}},{"i":1594,"$":{"0":{"v":"API","n":1},"1":{"v":"\n## Design\n\n### Prototype First\n\n- designs (of any kind) only improve when meaningful feedback is possible. API designs can be inspected, and some useful feedback results from this, but they can’t be used.\n\n\n## References\n\n- https://nordicapis.com/prototype-first-api-design/\n\n","n":0.171}}},{"i":1595,"$":{"0":{"v":"Hypermedia APIs","n":0.707},"1":{"v":"\n## Related\n\n\n- [[t.cs.web.hateoas]]\n\n## Everything as a Resource\n\n-   **Data model as a resource**: Describing the data model as a resource could help build forms for entering data or interactive user interfaces. One vocabulary to assist here is the SHACL Shapes Constraint Language for describing graph data structures.\n-   **Hypermedia as a resource**: The API itself can be described as a resource too. One way to do this is using [Hydra](https://nordicapis.com/hydra-for-hypermedia-apis-benefits-components-and-examples/), a vocabulary for describing APIs with RDF. This sort of self-documentation is similar to OpenAPI but could make the API discoverable at runtime.\n-   **Access control as a resource**: The [Basic Access Control ontology](https://lov.linkeddata.es/dataset/lov/vocabs/acl) is another shared vocabulary for describing access control that was [proposed by none other than Tim Berners-Lee](https://dig.csail.mit.edu/2009/Papers/ISWC/rdf-access-control/paper.pdf).\n\n## Solutions\n\n- [[prdct.hydra]]\n- [[prdct.json.hyper-schema]]\n- [[prdct.siren]]\n- [[prdct.HAL]]\n\n## Comparisons\n\n### Hypermedia APIs vs. Data APIs\n\nHypermedia APIs:\n\n-   Will be trivially [REST-ful](https://en.wikipedia.org/wiki/Representational_state_transfer), since they are simply what [Roy Fielding was describing](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm).\n-   Should be driven by the needs of the underlying hypermedia application\n-   May change dramatically _without_ versioning information, because hypermedia utilizes [self describing messages](https://en.wikipedia.org/wiki/Representational_state_transfer#Uniform_interface)\n-   Should be passed directly to humans, to maximize the flexibility of the system\n\nData APIs, on the other hand:\n\n-   Will not benefit dramatically from REST-fulness, beyond perhaps [Level 2 of the Richardson Maturity Model](https://en.wikipedia.org/wiki/Richardson_Maturity_Model)\n-   Should strive for both regularity and expressiveness due to the arbitrary data needs of consumers\n-   Should be versioned and should be very stable within a particular version of the API\n-   Should be consumed by code, processed and then potentially presented to a human\n\nCan you have both? Of course! See https://hypermedia.systems/json-data-apis/\n\n## References\n\n- https://nordicapis.com/exploring-the-hidden-powers-of-hypermedia/\n- https://htmx.org/essays/hypermedia-apis-vs-data-apis/\n- https://sookocheff.com/post/api/on-choosing-a-hypermedia-format/\n- https://medium.com/@cheron.antoine/which-technologies-should-you-use-to-build-hypermedia-apis-5047f2964cc4","n":0.063}}},{"i":1596,"$":{"0":{"v":"AI","n":1},"1":{"v":"\n\n## References\n\n- [[t.cs.synthetic-intelligence]]","n":0.577}}},{"i":1597,"$":{"0":{"v":"Neural Net","n":0.707}}},{"i":1598,"$":{"0":{"v":"Graph Neural Network","n":0.577},"1":{"v":"\n\n- [[p.hasLearningResource]] https://neptune.ai/blog/graph-neural-network-and-some-of-gnn-applications\n- [[p.hasRelatedTopic]] [[t.cs.ai.graph-autoencoder]]","n":0.447}}},{"i":1599,"$":{"0":{"v":"Utility AI","n":0.707},"1":{"v":"\n- #aka Infinite Axis Utility System\n\n## Interesting\n\n- \"Utility AI can be used as a Behavior Tree and implement the exact same branch structure as the Behavior Tree above - if desired.\"\n\n## Solutions\n\n- [[prdct.apex-utility-ai]] dead\n- [[prdct.infinite-axis-utility-system]]\n\n\n## Resources\n\n- https://www.tomlooman.com/unreal-engine-utility-ai-part1/ \n- https://www.gdcvault.com/play/1012410/Improving-AI-Decision-Modeling-Through #video\n- https://www.reddit.com/r/gameai/comments/cnxzt9/best_approach_to_implementdesign_response_curves/\n- https://www.gamedeveloper.com/programming/are-behavior-trees-a-thing-of-the-past-\n\nBehavior","n":0.154}}},{"i":1600,"$":{"0":{"v":"Spatial Intelligence","n":0.707},"1":{"v":"\nSpatial intelligence in AI teaches systems to interpret, navigate, and manipulate aspects of the physical world.\n\n### why spatial Intelligence is a challenge for AI?\n\n-   **Ambiguity and Uncertainty**: Real-world environments contain uncertainties and variations in lighting, object appearances, and occlusions. AI systems must account for errors, inconsistencies, and missing data commonly found in real-world spatial datasets.\n    \n-   **Dynamic Nature:** The world is in constant flux, requiring AI models to adapt to changes in real time. Applications like self-driving cars or real-time drone navigation demand fast and accurate spatial data processing.\n    \n-   **Multimodal Data and its Complexity:** Spatial understanding often requires integrating information from sources like images, depth sensors, and maps. Spatial datasets can be incredibly large and complex, posing challenges for storage, processing, and efficient analysis.\n\n## Resources\n\n- https://www.theatlantic.com/magazine/archive/2023/07/generative-ai-human-culture-philosophy/674165\n\n\n\n\n## References\n\n### What Is Spatial Intelligence\n\nhttps://www.turingpost.com/p/cvhistory5\n\n#### mentions\n\n-   “[GeoAI: spatially explicit artificial intelligence techniques for geographic knowledge discovery and beyond](https://www.tandfonline.com/doi/pdf/10.1080/13658816.2019.1684500)” by Krzysztof Janowicz et al. (2019)\n    \n    -   This paper explores the evolution and importance of spatial intelligence in AI, highlighting its significance in navigating the physical world and enhancing AI applications, despite traditional assessments' focus on linguistic abilities.\n        \n-   “[Combining Deep Learning and Qualitative Spatial Reasoning to Learn Complex Structures from Sparse Examples with Noise](https://arxiv.org/pdf/1811.11064” by Nikhil Krishnaswamy et al. (2019)\n    \n    -   This paper demonstrates a novel AI method to learn and generate complex spatial structures from sparse and noisy examples, leveraging deep learning and heuristic search to address the challenges of qualitative spatial reasoning.\n        \n-   “[Neuro-Symbolic Spatio-Temporal Reasoning](https://arxiv.org/pdf/2211.15566)” by Jae Hee Lee et al. (2023)\n    \n    -   In this paper, the authors explore the integration of ML with sym","n":0.061}}},{"i":1601,"$":{"0":{"v":"Selective State Space Model","n":0.5},"1":{"v":"\n## References\n\n- https://medium.com/towards-artificial-intelligence/is-mamba-the-end-of-chatgpt-as-we-know-it-a2ce57de0b02","n":0.577}}},{"i":1602,"$":{"0":{"v":"Retrieval Augmented Generation","n":0.577},"1":{"v":"\n- similar: [[t.cs.data.collaborative-customer-facing-data]]\n\n## RAG helps bridge the gap for Small Language Models (SLMs)\n\n- While SLMs inherently manage other key aspects such as language generation and understanding, RAG equips them to perform comparably to their larger counterparts by enhancing their knowledge base.\n- This makes RAG a critical equalizer in the realm of AI language models, allowing smaller models to function with the robustness of a full-scale LLM.\n\n## Structured Output in Evaluation Frameworks\n\n- \"As the field of Retrieval Augmented Generation continues to evolve, the adoption of structured output in evaluation frameworks will play a crucial role in advancing the state of the art.\"\n\n## References\n\n- https://medium.com/the-modern-scientist/logical-retrieval-with-knowledge-graphs-the-key-to-contextual-and-intelligent-information-seeking-9fc51cc04ead [[t.km.knowledge-graph]]\n- https://generativeai.pub/lets-ditch-rag-f63faed1b96f\n- https://ai.plainenglish.io/the-iterative-dance-of-the-rag-framework-for-knowledge-grounded-language-ai-e22a880b7159\n- https://ai.plainenglish.io/elevating-rag-evaluation-the-synergy-of-faaf-and-ares-through-structured-output-be2e2556dfdd\n- https://cobusgreyling.medium.com/an-ai-agent-architecture-framework-is-emerging-addae3804f23  ","n":0.096}}},{"i":1603,"$":{"0":{"v":"GraphRAG","n":1},"1":{"v":"\n\n## References\n\n- https://ai.gopubby.com/microsofts-graphrag-autogen-ollama-chainlit-fully-local-free-multi-agent-rag-superbot-61ad3759f06f","n":0.577}}},{"i":1604,"$":{"0":{"v":"Prompt Engineering","n":0.707},"1":{"v":"\n\n## References\n\n- https://martinfowler.com/articles/2023-chatgpt-xu-hao.html\n  - references [[prdct.konva]]","n":0.408}}},{"i":1605,"$":{"0":{"v":"Path Planning","n":0.707}}},{"i":1606,"$":{"0":{"v":"Neuro Symbolic","n":0.707},"1":{"v":"\n![](/assets/images/2024-04-03-09-24-25.png)\n\n- hybrid\n- The \"sub-symbolic\" approach doesn't seem adequate to get us to AGI\n- \n\n## References\n\n- [[event.2024.04.03.ontology-summit-synthesis]]","n":0.25}}},{"i":1607,"$":{"0":{"v":"Machine Learning","n":0.707}}},{"i":1608,"$":{"0":{"v":"Human in the Loop","n":0.5}}},{"i":1609,"$":{"0":{"v":"Graph Generation","n":0.707},"1":{"v":"\n## References\n\n- https://ai.plainenglish.io/exploring-the-potential-of-large-language-models-for-graph-generation-d8fa00887d75\n  - mentions:\n    - [[ar.py-graft-configurable-generation-of-synthetic-schemas-and-knowledge-graphs-at-your-fingertips]]\n    - [[ar.exploring-the-potential-of-large-language-models-in-graph-generation]]","n":0.333}}},{"i":1610,"$":{"0":{"v":"GAE","n":1},"1":{"v":"\n\n- reduces dimensionality, which is a big goal of data science\n- doesn't require labelled data\n- [[p.hasRelatedTopic]] [[t.cs.ai.graph-autoencoder.vgae]]","n":0.243}}},{"i":1611,"$":{"0":{"v":"Variational Graph AutoEncoder","n":0.577},"1":{"v":"\n\n- [[p.hasLearningResource]] https://paperswithcode.com/method/vgae","n":0.577}}},{"i":1612,"$":{"0":{"v":"Generative AI","n":0.707}}},{"i":1613,"$":{"0":{"v":"Frame","n":1},"1":{"v":"\n## Features\n\n- unlike semantic networks, they allow for exceptions in particular instances. This gives frames an amount of flexibility that allows representations of real-world phenomena to be reflected more accurately.\n  - https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)#Frame_language\n-  a semantic classification is applied to an utterance based upon recognizable templates of syntax parse trees and morphological lexicon, with word-sense ambiguity resolved by context and world-knowledge. You can think of this classification as akin to a large collection of \"dialog acts\" that capture the general gist of the utterance meaning.\n   -  https://www.linkedin.com/pulse/semantics-mans-search-computational-meaning-joshua-reuben/\n\n\n## Implementations\n\n- [[prdct.amr]]\n- ","n":0.107}}},{"i":1614,"$":{"0":{"v":"Facts as a Function","n":0.5},"1":{"v":"\n- similar: [[t.cs.ai.ares]]\n\n## References\n\n- https://arxiv.org/abs/2403.03888#:~:text=Factual%20recall%20from%20a%20reference,of%20both%20retrieval%20and%20generation.\n- https://ai.plainenglish.io/elevating-rag-evaluation-the-synergy-of-faaf-and-ares-through-structured-output-be2e2556dfdd","n":0.408}}},{"i":1615,"$":{"0":{"v":"Cognitive Architecture","n":0.707},"1":{"v":"\n- \"Cognitive architectures can be symbolic, connectionist, or hybrid.[7] Some cognitive architectures or models are based on a set of generic rules, as, e.g., the Information Processing Language (e.g., Soar based on the unified theory of cognition, or similarly ACT-R). Many of these architectures are based on the-mind-is-like-a-computer analogy. In contrast subsymbolic processing specifies no such rules a priori and relies on emergent properties of processing units (e.g. nodes). Hybrid architectures combine both types of processing (such as CLARION). A further distinction is whether the architecture is centralized with a neural correlate of a processor at its core, or decentralized (distributed). The decentralized flavor, has become popular under the name of parallel distributed processing in mid-1980s and connectionism, a prime example being neural networks. A further design issue is additionally a decision between holistic and atomistic, or (more concrete) modular structure.\"\n\n## [[c.resource.list]]\n\n- https://sites.google.com/site/drronsun/arch?authuser=0\n\n","n":0.084}}},{"i":1616,"$":{"0":{"v":"Causal Science","n":0.707}}},{"i":1617,"$":{"0":{"v":"Bender Test","n":0.707},"1":{"v":"\n- is this someone I want to play with?\n- deeply flawed:","n":0.302}}},{"i":1618,"$":{"0":{"v":"Automated Reasoning","n":0.707}}},{"i":1619,"$":{"0":{"v":"ARES","n":1},"1":{"v":"\nAutomated RAG Evaluation System, for evaluating RAG systems along the dimensions of context relevance, answer faithfulness, and answer relevance. By creating its own synthetic training data, ARES finetunes lightweight LM judges to assess the quality of individual RAG components. To mitigate potential prediction errors, ARES utilizes a small set of human-annotated datapoints for prediction-powered inference (PPI)\n\n## References\n\n- [ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2311.09476)","n":0.123}}},{"i":1620,"$":{"0":{"v":"Agents","n":1},"1":{"v":"\n\n## Resources\n\n- [[ar.c2.actor-vs-agent]]\n- [Overview of Software Agent Platforms Available in 2023](https://www.mdpi.com/2078-2489/14/6/348)","n":0.302}}},{"i":1621,"$":{"0":{"v":"Sense Plan Act","n":0.577},"1":{"v":"\n## Resources\n\n- https://www.semanticscholar.org/paper/Rethinking-the-Sense-Plan-Act-Abstraction%3A-A-Model-Wong/6877f3892609a285312bfa1b572037f0667c657f\n  - \"For robots whose ultimate mission is to complete tasks, only variables that are relevant to successful completion should be estimated. I propose to initially only track a minimal set of directly-relevant variables (attention), and gradually increase the sophistication of models on-demand (refinement), in a local fashion. This estimator refinement process is triggered by violations in expectations of task success (mismatch)\"","n":0.125}}},{"i":1622,"$":{"0":{"v":"Reinforcement Learning","n":0.707},"1":{"v":"\n## Solutions\n\n- [[prdct.pysc2]]\n","n":0.577}}},{"i":1623,"$":{"0":{"v":"Pomdp","n":1},"1":{"v":"\n- related: [[prdct.pomdp-solve]]\n\n## References\n\n- https://www.reddit.com/r/haskell/comments/16zg4g/project_idea_build_a_fipa_multiagent_system_in/","n":0.447}}},{"i":1624,"$":{"0":{"v":"Multi Agent Oriented Programming","n":0.5},"1":{"v":"\n## References\n\n- [[book.multi-agent-oriented-programming]]\n- [[ar.easss23-maop-tutorial]]","n":0.5}}},{"i":1625,"$":{"0":{"v":"BEN Architecture","n":0.707},"1":{"v":"\n![](/assets/images/2023-09-14-09-30-57.png)\n\n## Resources\n\n- [[ar.jasss.ben-an-architecture-for-the-behavior-of-social-agents]]\n  - [[p.mentioned]] [[prdct.clarion]] \n- https://github.com/gama-platform/gama/wiki/Using-BEN-simple-bdi\n ","n":0.354}}},{"i":1626,"$":{"0":{"v":"Belief, Desire, Intention","n":0.577},"1":{"v":"\n## Implementations\n\n- https://learn.microsoft.com/en-us/archive/msdn-magazine/2019/january/machine-learning-leveraging-the-beliefs-desires-intentions-agent-architecture\n  - written-in: c#\n\n### Simplified BDI Algorithm\n\n- [[p.hasSource]] https://www.inf.ed.ac.uk/teaching/courses/masws/lectures-14/16-full.pdf\n\n![](/assets/images/2022-12-08-14-19-28.png)\n\n## Resources\n\n- https://academic.oup.com/mind/advance-article-abstract/doi/10.1093/mind/fzac047/6765183\n  - \"A traditional Humean view about motivation says that only desires motivate action. This theory meshes with the familiar ‘directions of fit’ metaphor: while beliefs aim to fit the world, desires aim to change it. In this way, desires and beliefs appear to be different types of mental state. But such appearances may be misleading. The central aim of Alex Gregory’s Desire as Belief is to defend the unorthodox thesis that desires (or equivalently, wants) are nothing more than beliefs with a particular normative content, an idea with Aristotelian and Stoic roots (see p. 20). In particular, the proposal is that to desire something amounts to believing that you have a reason to bring it about. It is beliefs of this sort, combined with instrumental beliefs, that explain motivation. Gregory’s book is a consistently impressive defence of what he calls desire-as-belief.\n\n  Chapter 1 clarifies desire-as-belief by way of an analogy with the mental state of disbelieving. To talk of disbelief, on a straightforward analysis, is to talk jointly of an attitude and a content. That is, disbelieving that p doesn’t seem to refer to a sui generis attitude of disbelieving but rather a belief, namely a belief that not-p. In similar fashion, desire-as-belief says that my desiring that p consists of an attitude – belief – with a certain content – that I have a reason to bring about p. Such first-personal beliefs about reasons are special in that they have both aforementioned directions of fit. They aim to conform to the world insofar as they are correct just in case the belief is true; and they aim to change it insofar as such beliefs dispose the desirer to act according to the relevant reasons.\"\n\n\n## References\n\n- [[ar.the-bdi-model-of-agency-and-bdi-logics]]","n":0.058}}},{"i":1627,"$":{"0":{"v":"Intent","n":1}}},{"i":1628,"$":{"0":{"v":"Desire","n":1}}},{"i":1629,"$":{"0":{"v":"Belief","n":1}}},{"i":1630,"$":{"0":{"v":"Agent Based Simulation","n":0.577},"1":{"v":"\n## [[c.resource.list]]\n\n- https://github.com/topics/agent-based-simulation\n","n":0.577}}},{"i":1631,"$":{"0":{"v":"Agent Based Modeling","n":0.577},"1":{"v":"\n- #aka ABM\n- [[p.similarTo]] [[t.cs.agents.agent-based-simulation]]\n\n## Resources\n\n### Comparison\n\n- [[ar.acm.an-initial-comparison-of-selected-agent-based-simulation-tools-in-the-context-of-industrial-health-and-safety-management]]\n- [[ar.jasss.participatory-modeling-and-simulation-with-the-gama-platform]] https://www.jasss.org/22/2/3.html\n- [[ar.lesswrong.where-do-selfish-values-come-from]]\n\n### Learning Resource\n\n- https://caam37830.github.io/book/09_computing/agent_based_models.html [[game.game-of-life]]\n- ","n":0.258}}},{"i":1632,"$":{"0":{"v":"Actors","n":1},"1":{"v":"\n- [[prdct.orleans]] [[p.invented]] [[t.cs.actors.virtual]]\n\n## Implementations\n\n- [[prdct.comedy]] javascript\n- [[prdct.orleans]] c# \n- [[prdct.akka]]\n- [[prdct.pykka]]\n- [[prdct.akka-net]]\n- [[prdct.ptolemy]]\n- [[prdct.dapr]] c#\n- [[prdct.proto-actor]]\n- [[prdct.tarant]]  \n\n## Features\n\n- \"Actor model services are stateless and reactive\"\n  - https://medium.com/nerd-for-tech/the-power-of-message-orchestration-b28f18da603a\n    - \"Actor instances pass messages to other actor instances when they need them to do something.\"\n    - \"Actor instances publish events when they need to tell interested subscribers about something.\"\n## Ideas\n\n- Primary actors initiate a use case and hence are somewhat independent. Secondary actors, on the other hand, are used by the system but they do not interact with the system on their own.\n  - \"The distinction between ‘’primary ‘’and’’ secondary ‘’lies in who triggers or is in charge of the conversation.\"\n\n## Resources\n\n- [43 years of actors: a taxonomy of actor models and their key properties](https://dl.acm.org/doi/abs/10.1145/3001886.3001890)\n- https://github.com/GetTech-io/awesome-actor\n- https://forums.ni.com/t5/Actor-Framework-Documents/Justifying-The-Actor-Framework/ta-p/4207018\n- https://clojure.org/about/state\n  - \"the actor model was designed to address the problems of distributed programs. And the problems of distributed programs are much harder - there are multiple worlds (address spaces), direct observation is not possible, interaction occurs over possibly unreliable channels, etc... I chose not to use the actor model for same-process state management in Clojure for several reasons:\n\n    -   It is a much more complex programming model, requiring 2-message conversations for the simplest data reads, and forcing the use of blocking message receives, which introduce the potential for deadlock. Programming for the failure modes of distribution means utilizing timeouts etc. It causes a bifurcation of the program protocols, some of which are represented by functions and others by the values of messages.\n        \n    -   It doesn’t let you fully leverage the efficiencies of being in the same process. It is quite possible to efficiently directly share a large immutable data structure between threads, but the actor model forces intervening conversations and, potentially, copying. Reads and writes get serialized and block each other, etc.\n        \n    -   It reduces your flexibility in modeling - this is a world in which everyone sits in a windowless room and communicates only by mail. Programs are decomposed as piles of blocking switch statements. You can only handle messages you anticipated receiving. Coordinating activities involving multiple actors is very difficult. You can’t observe anything without its cooperation/coordination - making ad-hoc reporting or analysis impossible, instead forcing every actor to participate in each protocol.\"\n\n","n":0.052}}},{"i":1633,"$":{"0":{"v":"Virtual Actor abstraction","n":0.577}}},{"i":1634,"$":{"0":{"v":"Grain","n":1}}},{"i":1635,"$":{"0":{"v":"Actor Model","n":0.707},"1":{"v":"\n## Resources\n\n- [[ar.taxonomy-of-actors]]\n- [[Actor Vs Agent|ar.c2.actor-vs-agent]]\n- http://thorium.github.io/FSharpAzure/2-AgentModel/AgentModelEng.html","n":0.378}}},{"i":1636,"$":{"0":{"v":"Communication","n":1},"1":{"v":"\n## Definition\n\n- The three components of a communication, from a pragmatic point of view, are: Locution--the semantic or literal significance of the utterance; Illocution--the intention of the speaker; and. Perlocution--how it was received by the listener.","n":0.167}}},{"i":1637,"$":{"0":{"v":"Utterances","n":1},"1":{"v":"\n\n\n## quotes\n\n- > In many ways the Stream is best seen through the lens of Bakhtin’s idea of the utterance. Bakhtin saw the utterance, the conversational turn of speech, as inextricably tied to context. To understand a statement you must go back to things before, you must find out what it was replying to, you must know the person who wrote it and their speech context. To understand your statement I must reconstruct your entire stream. \n  - [[p.hasSource]] [[ar.hapgood.the-garden-and-the-stream-a-technopastoral]]\n\n","n":0.112}}},{"i":1638,"$":{"0":{"v":"Tetrad of Media Effects","n":0.5},"1":{"v":"\n![](/assets/images/2023-04-20-22-18-39.png)\n\n- ","n":1}}},{"i":1639,"$":{"0":{"v":"Signal","n":1},"1":{"v":"\n- [[p.hadDefinition]] an act, event, or watchword that is used to convey information or instructions\n- [[p.hasRelatedTopic]] [[t.mktg.buying-signals]]","n":0.243}}},{"i":1640,"$":{"0":{"v":"Media","n":1},"1":{"v":"\n## The Medium is the Message\n\n![[ar.atlantic.video-games-are-better-without-stories#^vcp7i03sguei]]","n":0.408}}},{"i":1641,"$":{"0":{"v":"Social","n":1},"1":{"v":"\n\nA cacophpony of utterances made semi-intelligible by the limits of our attention and the algorithms that feed it.\n\n- [[p.hasSameReferantAs]] [[t.cs.web.social]] \n","n":0.218}}},{"i":1642,"$":{"0":{"v":"Epistemic Status","n":0.707}}},{"i":1643,"$":{"0":{"v":"Epistemic Effort","n":0.707},"1":{"v":"\n## References\n\n- https://www.lesswrong.com/posts/oDy27zfRf8uAbJR6M/epistemic-effort\n- ","n":0.577}}},{"i":1644,"$":{"0":{"v":"Superworks","n":1},"1":{"v":"\n## Examples\n\n- [[superwork.dungeons-and-dragons.rime-of-the-frostmaiden]]\n\n## References\n\n- [[t.library-science.superwork]]\n- [[ar.reconceptualizing-superwork-for-improved-access-to-popular-cultural-objects]]","n":0.408}}},{"i":1645,"$":{"0":{"v":"Twilight Zone","n":0.707}}},{"i":1646,"$":{"0":{"v":"Dungeons and Dragons","n":0.577},"1":{"v":"\n## References\n\n- [[game.dungeons-and-dragons]]\n- [[game-system.dungeons-and-dragons]]","n":0.5}}},{"i":1647,"$":{"0":{"v":"Storm Kings Thunder","n":0.577}}},{"i":1648,"$":{"0":{"v":"Rime of the Frostmaiden","n":0.5}}},{"i":1649,"$":{"0":{"v":"Alien","n":1}}},{"i":1650,"$":{"0":{"v":"Semantic Flow","n":0.707},"1":{"v":"\n\n\n## Requirements\n\n- for [[dereference pages|sflow.concepts.dereference-pages]] you don't want all assertions, only some of the most useful ones, perhaps with links to where you can get more\n- mapping of templates to facets, namespaces, datasets, sparql queries\n\n\n## Relationship with Kosmion\n\n- kosmion is a relator-based\n\n\n## References\n\n- [[ar.base-platform-for-knowledge-graphs-with-free-software]]\n- https://www.rockyourcode.com/how-to-deploy-eleventy-to-github-pages-with-github-actions/","n":0.149}}},{"i":1651,"$":{"0":{"v":"Similar","n":1},"1":{"v":"\n- [[prdct.trifid]] (server-side)\n- ","n":0.577}}},{"i":1652,"$":{"0":{"v":"Requirements","n":1},"1":{"v":"\n## IRI minting\n\n- ","n":0.577}}},{"i":1653,"$":{"0":{"v":"Now (Semantic Flow)","n":0.577},"1":{"v":"\n## *[Semantic Flow](https://djradon.github.io/wiki/notes/ggw3ek46ptgebsgxgihr1dh/)* Static Site Generator\n\n* host ontologies and linked data on github or gitlab\n* directory structure; distributions\n* how do you create semantic data that conforms to an ontology\n* client-side features: pull raw RDF files into the resource HTML pages\n","n":0.158}}},{"i":1654,"$":{"0":{"v":"Semantic Flow Log","n":0.577},"1":{"v":"\n## t.2024.10.01.09\n\n### chatgpt memory\n\n- dave: Remember: I'm trying to develop a static-site generator called \"Semantic Flow\" that takes ontologies defined in RDF and/or conforming RDF data files and generates a static site to be hosted on GitHub pages that includes HTML-based index files (that can be based on a template or customized as necessary) that describe identified resources and link to raw RDF data files (possibly in multiple formats) that can be access by semantically-aware applications.\n- ","n":0.115}}},{"i":1655,"$":{"0":{"v":"Concepts","n":1}}},{"i":1656,"$":{"0":{"v":"Scanner","n":1},"1":{"v":"\n- scans dataset sources, which can be:\n  - local folders\n  - git repos\n  - compliant URLs\n  - SPARQL data sources\n- can filter which subfolders to include/exclude\n- ","n":0.196}}},{"i":1657,"$":{"0":{"v":"Published Dataset","n":0.707},"1":{"v":"\n- a dataset can be held in memory and manipulated there. When it is published/serialized, it gets a version. ","n":0.229}}},{"i":1658,"$":{"0":{"v":"Namespace Repo","n":0.707},"1":{"v":"\n- datasets across multiple repos can have IRIs detected for them, so the namespace repo is a top down \"which datasets to download and scan for contained IRIs\"\n- can either be root (correspond to github username or org name, e.g. djradon.github.io) or 2nd-level (corresponding to an owned repo)\n\n## Questions\n\n- should repos be able to include HTML templates and entity-to-template mappings?\n  - yes? but can be overridden at the namespace repo","n":0.12}}},{"i":1659,"$":{"0":{"v":"Dereference Pages","n":0.707},"1":{"v":"\n- primarily for humans\n\n### Dynamic Client-Side\n\n- the HTML (mostly index.html) for each entity/graph/dataset/catalog might access a text-based data source that specifies which template to use, which data to incorporate (via catalog processing), and then write the response dynamically. \n  - maybe the data source is the default graph for the entity, or a special dereference-page graph\n- Users could also customize their views and save those setting in a cookie, that would be integrated into the page\n","n":0.115}}},{"i":1660,"$":{"0":{"v":"Settings","n":1}}},{"i":1661,"$":{"0":{"v":"Scp Foundation","n":0.707},"1":{"v":"\n- url: https://scp-wiki.wikidot.com\n- ","n":0.577}}},{"i":1662,"$":{"0":{"v":"Paradis","n":1},"1":{"v":"\n- [[c.fantasy-setting]]\n- url: https://paradisichronicles.wordpress.com/\n\n\n## Resources\n\n- https://worldbuilding.stackexchange.com/questions/1396/are-there-any-free-science-fiction-world-settings","n":0.408}}},{"i":1663,"$":{"0":{"v":"Orions Arm","n":0.707},"1":{"v":"\n- [[c.fantasy-setting]]\n- url: https://www.orionsarm.com/\n- ","n":0.5}}},{"i":1664,"$":{"0":{"v":"Metamor Keep","n":0.707},"1":{"v":"\n- [[c.fantasy-setting]]\n- url: http://metamorkeep.com/\n\n## Description\n\nThe setting is named after a strategically located castle which is a vital part of the military defense of the Good peoples against the forces of Evil. The Keep itself has no fixed floor plan, as it's inhabited by a powerful (and benevolent) spirit which tends to relocate the internal walls and such without notice.\n\nOne day, the local forces of Evil mounted a serious attack on the Keep -- including a set of curses which ought to have completely neutralized the defenders, transforming each one into either a helpless baby, a grossly oversexed member of the opposite sex, or a dumb animal. Fortunately, the Keep's own mages were able to blunt the force of this magickal assault. While the Evil curses failed to achieve their intended results, they were not fully neutralized, and their effect is felt even to this day. Ever since that battle, any person who remains within a day's ride of the Keep for more than 10-14 days will fall victim to a weakened version of one of the three curses. Some become children (but not babies); others become normal members of the opposite sex (without being carnally obsessed bimbos); still others become human/animal hybrid creatures (who usually retain the intelligence, manipulatory capacity, voice, etc, of their former body). \n\n## Resources\n\n- http://tsat.transform.to/i.32/rtc.okane.1.html\n- http://tsat.transform.to/tsat/settings/setting.mk.html\n- http://mkworld.wikidot.com/events:timeline\n- http://mk2k.wikidot.com/\n","n":0.067}}},{"i":1665,"$":{"0":{"v":"Forgotten Realms","n":0.707}}},{"i":1666,"$":{"0":{"v":"Fifth World","n":0.707},"1":{"v":"\n- url: https://www.thefifthworld.com/\n- license: [[lic.by-sa-4-0]]","n":0.447}}},{"i":1667,"$":{"0":{"v":"Ember","n":1},"1":{"v":"\n- related: [[game-system.crucible]]\n\n## Description\n\n- Ember is an enthralling new fantasy setting - created exclusively for and by [[prdct.Foundry-VTT]]. In conjunction with Crucible - our own game system - we have a powerful trinity of VTT platform, game system, and campaign setting that together construct a foundation for a lifetime of roleplaying gaming content.","n":0.137}}},{"i":1668,"$":{"0":{"v":"Recipes","n":1}}},{"i":1669,"$":{"0":{"v":"Secret Ingredients","n":0.707},"1":{"v":"\n\n- https://www.buzzfeed.com/hannahloewentheil/home-cooks-sharing-favorite-secret-ingredients\n","n":0.707}}},{"i":1670,"$":{"0":{"v":"A NYC Chef’s Flavor-Building Pantry Staples, None of Which Are Olive Oil","n":0.289},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.domino.com/content/dan-kluger-pantry-staples/\n- [[p.attributedTo]] @Dan-Kluger klug\n- [[usesIngredients]] miso; butternut squash; kombu; elderflower-syrup\n","n":0.289}}},{"i":1671,"$":{"0":{"v":"Cornell Chicken","n":0.707},"1":{"v":"\n- https://www.cnet.com/home/kitchen-and-household/a-cornell-professor-invented-what-many-consider-the-best-bbq-chicken-recipe-ever/?utm_source=pocket-newtab-en-us\n","n":0.707}}},{"i":1672,"$":{"0":{"v":"Public","n":1}}},{"i":1673,"$":{"0":{"v":"Question Log","n":0.707}}},{"i":1674,"$":{"0":{"v":"2024","n":1}}},{"i":1675,"$":{"0":{"v":"07","n":1}}},{"i":1676,"$":{"0":{"v":"11","n":1}}},{"i":1677,"$":{"0":{"v":"What Are the Restrictions of Owl2 Rl","n":0.378},"1":{"v":"\nOWL 2 RL is designed for scalable reasoning using rule-based systems and thus imposes certain restrictions to ensure that reasoning can be efficiently implemented. Here are the key restrictions of OWL 2 RL:\n\n### 1. **Restrictions on Classes and Class Expressions**\n- **No Universal Quantification**: OWL 2 RL does not support universal quantification (i.e., `owl:allValuesFrom`). This means you cannot specify that all values of a property must belong to a certain class.\n- **Limited Use of Intersection and Union**: While OWL 2 RL supports intersection (using `owl:intersectionOf`), it restricts the use of unions (using `owl:unionOf`) to class expressions where one of the operands is an `owl:Thing` or `owl:Nothing`.\n- **No Complement Classes**: OWL 2 RL does not support complement classes (`owl:complementOf`).\n\n### 2. **Restrictions on Property Axioms**\n- **No Property Chains**: OWL 2 RL does not allow the use of property chains (i.e., `owl:propertyChainAxiom`). This restricts the ability to infer new properties from existing ones through chains of relationships.\n- **No Complex Subproperty Chains**: You cannot define complex subproperty chains where a property is a subproperty of a chain of other properties.\n\n### 3. **Restrictions on Datatype Properties**\n- **Limited Datatype Restrictions**: OWL 2 RL supports a limited set of datatype restrictions. Complex datatype expressions involving operations like intersection, union, and complement of datatypes are not allowed.\n- **No Custom Datatypes**: Only predefined XML Schema datatypes are supported. Custom datatypes or user-defined datatypes are not allowed.\n\n### 4. **Restrictions on Cardinality**\n- **No Qualified Cardinality Restrictions**: OWL 2 RL does not support qualified cardinality restrictions, such as specifying that exactly three values of a property must be of a certain class.\n- **Limited Cardinality**: Simple cardinality constraints (e.g., `owl:minCardinality`, `owl:maxCardinality`, and `owl:cardinality`) are supported but cannot be used with complex class expressions.\n\n### 5. **Restrictions on Individuals**\n- **No Negative Property Assertions**: OWL 2 RL does not support negative property assertions (i.e., statements that a certain relationship does not hold between individuals).\n\n### 6. **No Advanced Class Expressions**\n- **No Disjoint Union**: OWL 2 RL does not support `owl:disjointUnionOf`, which allows specifying that a class is the disjoint union of several other classes.\n- **No Complex Class Axioms**: Complex axioms such as property disjointness or advanced class constructors are not allowed.\n\n### Example OWL 2 RL Syntax:\nHere's an example of an OWL 2 RL ontology with some of the allowed constructs:\n\n```xml\n<rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n         xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\n         xmlns:owl=\"http://www.w3.org/2002/07/owl#\"\n         xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\n\n    <!-- Define the Person class -->\n    <owl:Class rdf:about=\"#Person\"/>\n    \n    <!-- Define the hasChild object property -->\n    <owl:ObjectProperty rdf:about=\"#hasChild\">\n        <rdfs:domain rdf:resource=\"#Person\"/>\n        <rdfs:range rdf:resource=\"#Person\"/>\n    </owl:ObjectProperty>\n    \n    <!-- Define the hasAge data property -->\n    <owl:DatatypeProperty rdf:about=\"#hasAge\">\n        <rdfs:domain rdf:resource=\"#Person\"/>\n        <rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#integer\"/>\n    </owl:DatatypeProperty>\n    \n    <!-- Define the Parent class with restrictions -->\n    <owl:Class rdf:about=\"#Parent\">\n        <rdfs:subClassOf rdf:resource=\"#Person\"/>\n        <owl:equivalentClass>\n            <owl:Class>\n                <owl:intersectionOf rdf:parseType=\"Collection\">\n                    <rdf:Description rdf:about=\"#Person\"/>\n                    <owl:Restriction>\n                        <owl:onProperty rdf:resource=\"#hasChild\"/>\n                        <owl:someValuesFrom rdf:resource=\"#Person\"/>\n                    </owl:Restriction>\n                </owl:intersectionOf>\n            </owl:Class>\n        </owl:equivalentClass>\n    </owl:Class>\n    \n    <!-- Define some individuals -->\n    <rdf:Description rdf:about=\"#John\">\n        <rdf:type rdf:resource=\"#Person\"/>\n        <hasAge rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">30</hasAge>\n    </rdf:Description>\n    \n    <rdf:Description rdf:about=\"#Jane\">\n        <rdf:type rdf:resource=\"#Person\"/>\n        <hasAge rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">25</hasAge>\n    </rdf:Description>\n    \n    <rdf:Description rdf:about=\"#John\">\n        <hasChild rdf:resource=\"#Jane\"/>\n    </rdf:Description>\n\n</rdf:RDF>\n```\n\n### Conclusion:\nOWL 2 RL is designed to be efficiently implementable using rule-based systems, which means it imposes several restrictions on the expressiveness of the language. These restrictions ensure that reasoning can be performed in a scalable and efficient manner, making OWL 2 RL suitable for applications involving large datasets where performance is critical.\n\nIf you have further questions or need more specific examples, feel free to ask!","n":0.043}}},{"i":1678,"$":{"0":{"v":"10","n":1}}},{"i":1679,"$":{"0":{"v":"22","n":1}}},{"i":1680,"$":{"0":{"v":"Edtf","n":1},"1":{"v":"\n## On https://id.loc.gov/datatypes/EDTFScheme.html why don't they have a scheme for level 3?\n\nThe Library of Congress does not define a scheme for EDTF Level 3 in their linked data service because the existing EDTF implementation only supports Levels 0, 1, and 2. These levels focus on progressively more complex features, such as uncertain or approximate dates, and partial unspecified dates. However, Level 3 in EDTF introduces more advanced and flexible features, like fuzzy time intervals and indefinite time spans, which are not as widely adopted or implemented in various systems.\n\nThis might explain why they chose not to include Level 3—likely due to its complexity and the fact that not all systems are prepared to handle such flexible or imprecise data representations. In practice, Levels 0 through 2 are often sufficient for most cataloging and metadata needs, especially for libraries and linked data services like the one offered by the Library of Congress【22†source】【23†source】【25†source】. \n\nFor your use case, if you want to support Level 3, you'll need to define your datatype independently, given that it's not handled by the LOC scheme.\n\n## I want to do a datatype for EDTF. EDTF has 4 levels, but I don't think there are any semantic incompatibilities between the levels. Any reason to define different data types for different levels? \n\nIf the four levels of EDTF (Extended Date/Time Format) don’t introduce semantic incompatibilities between the levels, there might not be a strong reason to define separate datatypes for each level. Here’s a breakdown of considerations to help decide:\n\n### 1. **Consistency Across Levels:**\n   If the four levels of EDTF represent increasing specificity or additional features without fundamentally changing the interpretation of the format (e.g., level 0 is a simple date, while level 1 adds support for uncertain dates, etc.), then a single datatype can handle all levels. You can define one `EDTF` datatype and rely on validation mechanisms (such as SHACL) to ensure that the literal conforms to the appropriate EDTF level.\n\n### 2. **Validation and Parsing:**\n   One argument for splitting datatypes would be if different processing or validation logic is required for each level. For example, if the constraints (such as regex or structural validation) differ significantly for each level, defining separate datatypes would make it easier to enforce level-specific rules. However, if all levels can be parsed and validated with a shared approach (like a broader regex pattern that matches all levels), then one datatype might suffice.\n\n### 3. **Tooling and Interoperability:**\n   Some RDF tools might behave better with more granular datatypes if there are processing rules or validators that need to differentiate between levels. But if you plan to handle the EDTF logic internally (e.g., with SHACL validation), a single datatype is simpler and easier to maintain.\n\n### 4. **Future Flexibility:**\n   If there’s a chance that different levels might diverge semantically in the future, or you foresee needing specific level-aware logic, you could preemptively define separate datatypes now. This would give you flexibility but at the cost of added complexity.\n\n### Conclusion:\nGiven that there’s no immediate semantic conflict between the levels and that validation could likely be handled with a single mechanism, defining a single datatype for `EDTF` seems like the simplest and most efficient approach. You can still rely on regex patterns or SHACL rules to enforce the proper format for specific use cases.\n\nWould you like to see an example of how you might define an EDTF datatype in RDF and SHACL?\n\n\n## namespace design\n\n- @dave:\n\nI'm going to use github to host a namespace for EDTF and define the datatype. I've created an organization \"edtf-datatype\", and I'll use a repo called edtf-datatype.github.io to host a dereferencable site on github pages. So the namespace will start with \"https://edtf-datatype.github.io/\". Should I add \"/ns\" to that path, so the IRI for the datatype would be \"https://edtf-datatype.github.io/ns/edtf\"? Or something else? Or just \"https://edtf-datatype.github.io/edtf\"\n\n- chatgpt:\n\nAdding `/ns` to your namespace path is a common practice, as it clearly distinguishes the namespace itself from other resources (like documentation or other public assets) that might be hosted under the same domain. This separation helps keep the namespace clean and easily recognizable.\n\nHowever, it's not strictly necessary. You could go with either:\n\n- **With `/ns`:**\n  - Namespace: `https://edtf-datatype.github.io/ns/`\n  - Datatype IRI: `https://edtf-datatype.github.io/ns/edtf`\n  - This approach keeps the option open to define multiple namespaces in the future, and it's clearer that this part of the URL is dedicated to RDF/ontology content.\n\n- **Without `/ns`:**\n  - Namespace: `https://edtf-datatype.github.io/`\n  - Datatype IRI: `https://edtf-datatype.github.io/edtf`\n  - This approach is simpler and might be more lightweight for a small project if you're sure that the repository will only focus on this single datatype or related vocabularies.\n\n### Considerations:\n1. **Scalability**: If you might expand the project later to include additional vocabularies or resources, having `/ns` could help you organize things better.\n2. **Clarity**: The `/ns` in the path helps signal that this is an RDF/ontology namespace and avoids potential collisions if you use the base path for other purposes (e.g., serving an HTML site).\n3. **Simplicity**: If you're sure the project scope will remain small, skipping `/ns` results in a cleaner, shorter IRI.\n\n### Recommendation:\nIf there's any possibility that you'll host multiple namespaces or related resources in the future, using `https://edtf-datatype.github.io/ns/edtf` would be more scalable and organized. Otherwise, if it's only for a single datatype, keeping it simple with `https://edtf-datatype.github.io/edtf` is perfectly fine.\n\n\n## Are there any EDTF implementations that support level 3?\n\nThere are a few implementations of EDTF that partially support Level 3 features, but it's less commonly implemented compared to Levels 0 through 2. \n\nFor example, the **Python EDTF2 library** supports parsing most of the EDTF levels, including some Level 3 features like season intervals and extended ranges, which are particularly useful for bibliographic applications. However, Level 3 is not fully standardized across tools, so some implementations may support it in a limited or experimental capacity [^32] [^33].\n\nAdditionally, **EDTF.js** offers partial support for Level 3, particularly for advanced features like season intervals, which are important for certain use cases. The creators of the library have mentioned that Level 3 features require careful handling in validation, and their approach is to allow for some flexibility by combining levels where appropriate (e.g., Level 0 + Level 3) [^33] [^34].\n\nHowever, there is no comprehensive validation service or tool that fully supports Level 3 across all features. The University of North Texas (UNT) provides a validation service for Levels 0, 1, and 2, but it explicitly does not support Level 3 [^35].\n\nIf you're planning to work with Level 3 in an EDTF context, you may need to extend or customize existing libraries depending on your specific needs.\n\n## Interestingly, the Library of Congress ontologies all define their subjects as datatypes, classes, AND individuals. \n\nYes, it's quite interesting that many Library of Congress ontologies define subjects as **datatypes**, **classes**, and **individuals** simultaneously. This is an unusual modeling choice that reflects the desire for **multi-faceted descriptions** of terms in linked data.\n\n1. **Datatypes**: The Library of Congress (LOC) might define a subject as a datatype to support the notion that specific literal values can be associated with it, enabling the use of the subject in places where typed literal values are required (e.g., for metadata encoding or validation).\n\n2. **Classes**: Defining the subject as a class allows it to be used as a general category for grouping resources or entities. This means that other entities can be classified under this subject, establishing broader and more abstract relationships.\n\n3. **Individuals**: Defining a subject as an individual allows it to be treated as a concrete, identifiable entity, which is useful in contexts where specific references or assertions about that entity are required.\n\nThis approach reflects a certain flexibility in RDF modeling that allows the same entity to play different roles depending on the context. It’s particularly useful in the cultural heritage and bibliographic domains where the same concept may need to function as both a classifying category (class) and a specific instance of something (individual) for different types of metadata or use cases【22†source】【24†source】【26†source】.\n\nWould you like more details on how this impacts the design of ontologies?\n\n## Another interesting thing in those EDTF ontologies is this:\n\n- @dave: \n  \n[ rdf:type owl:Ontology\n ] .\n\nat the top of the file. What's the purpose of that?\n\n- chatgpt:\n\nThe statement `[ rdf:type owl:Ontology ] .` at the top of an RDF or OWL file is a declaration that the document or graph itself is of the type `owl:Ontology`. This serves several important purposes:\n\n### 1. **Ontology Identification**:\n   By declaring that the file is of type `owl:Ontology`, it clearly marks the document as being an OWL ontology. This is useful for tools that process RDF/OWL, as they can recognize and handle the file as an ontology instead of some other type of RDF data (e.g., instance data or a different kind of schema).\n\n### 2. **Metadata Declaration**:\n   The `owl:Ontology` element allows you to provide metadata about the ontology itself, such as:\n   - **Versioning information** (`owl:versionIRI`)\n   - **Creators** (`dc:creator` or `dc:contributor`)\n   - **License** (`cc:license`)\n   - **Imports** of other ontologies (`owl:imports`)\n   This can help in managing the ontology lifecycle, version control, and ensuring proper attribution and reuse.\n\n### 3. **Consistency with OWL Semantics**:\n   OWL provides specific reasoning capabilities and semantic rules that apply to ontologies. Declaring the document as an ontology ensures that it will be processed with OWL semantics in mind, which can affect how inferencing, consistency checking, and other reasoning tasks are performed.\n\n### 4. **Tool Compatibility**:\n   Many ontology editing and reasoner tools (such as Protégé, OWL API, or other RDF processors) expect an explicit `owl:Ontology` declaration. It ensures that these tools can handle the file properly, recognizing it as a formal description of concepts, classes, properties, and relationships rather than a set of instance data or a different type of RDF structure.\n\nIn summary, the purpose of `[ rdf:type owl:Ontology ] .` is to formally declare that the file defines an ontology, enabling proper processing, identification, and management of the ontology metadata across different systems and tools.\n\n\n## What is the purpose of owl:NamedIndividual\n\nThe purpose of `owl:NamedIndividual` in OWL (Web Ontology Language) is to explicitly declare an entity as a **named individual** within the ontology. Here's how it fits into OWL:\n\n### 1. **Distinguishing Individuals from Classes and Properties**:\n   `owl:NamedIndividual` is used to clearly indicate that a particular entity is an **instance** of one or more classes, not a class or a property. In RDF, individuals are just entities (resources), but OWL uses `owl:NamedIndividual` to emphasize that an entity is a unique, concrete individual as opposed to an abstract class or property.\n\n   Example:\n   ```ttl\n   :John rdf:type owl:NamedIndividual ;\n         rdf:type :Person .\n   ```\n   This example states that `:John` is an individual of type `Person`.\n\n### 2. **Facilitating Reasoning**:\n   OWL reasoners use `owl:NamedIndividual` to infer facts about individuals and perform logical operations. Declaring individuals in this way helps reasoners differentiate between individuals and classes, ensuring they apply appropriate logic for individual-based reasoning.\n\n   For instance, OWL can infer relationships between individuals (e.g., that two individuals are distinct, or that they have certain properties) when they're marked as `owl:NamedIndividual`.\n\n### 3. **Disjointness of Classes and Individuals**:\n   OWL’s semantics treat classes and individuals differently. By marking an entity as `owl:NamedIndividual`, you signal that the entity should not be confused with a class or property. For example, a person like `John` is an individual, while `Person` is a class. This distinction helps avoid incorrect inferences or modeling errors.\n\n### 4. **Named vs. Anonymous Individuals**:\n   `owl:NamedIndividual` specifically refers to **named individuals** (those with an IRI). In contrast, OWL also allows for **anonymous individuals** (or blank nodes), which don’t have a globally unique identifier but can still participate in relationships in the ontology. Using `owl:NamedIndividual` ensures that the individual has a distinct identity within the ontology.\n\nIn summary, `owl:NamedIndividual` serves to clearly indicate that an entity is a concrete, distinct individual within an OWL ontology, which is important for reasoning, distinguishing individuals from classes, and ensuring correct semantic interpretation of relationships.\n\n\n## It seems a little redundant to distinguish something as having an IRI. That can be surmised from the context. Is there an example where owl:NamedIndividual is useful?\n\n\n\n## In my Kosmion ontology, where I want to minimize use of Classes and embrace things that are individuals and classes, owl:NamedIndividual would be useful. Can you think of any places it could be useful. Remember, EDTF datatypes are classes and individuals\n\n## References\n\n- \n\n[^32]: https://pypi.org/project/edtf2/\n[^33]: https://github.com/citation-style-language/schema/issues/421 \n[^34]: https://www.librarianshipstudies.com/2016/05/extended-date-time-format-edtf.html\n[^35]: https://digital2.library.unt.edu/edtf/","n":0.022}}},{"i":1681,"$":{"0":{"v":"12","n":1}}},{"i":1682,"$":{"0":{"v":"Kv012","n":1},"1":{"v":"\n\n## What's the best way to specify a \"backup URI\" for an ontology\n\n- paraphrase: rdfs:isDefinedBy or owl:seeAlso\n\n## could I just specify multiple owl:versionIRIs ?\n\nIn RDF/OWL, each ontology version can only have one `owl:versionIRI` property. It uniquely identifies that specific version of the ontology. Specifying multiple `owl:versionIRIs` would break the principle of having a clear and unambiguous version identifier.\n\nHowever, you can use other properties to specify additional URIs for the ontology, such as:\n- **`rdfs:seeAlso`** to link to related URIs or backups.\n- **`owl:priorVersion`** for linking to previous versions, effectively creating a chain.\n- **Custom properties** like `:backupURI` if you want a dedicated property.\n\nFor example:\n```turtle\n<https://kosmion.github.io/ont/v0/kosmion-v0.ttl> a owl:Ontology ;\n    owl:versionIRI <https://kosmion.github.io/ont/v0/kosmion-v0.1.2.ttl> ;\n    rdfs:seeAlso <https://kosmion.github.io/ont/backup/kosmion-backup.ttl> .\n```\n\nThis allows you to point to a backup without conflicting with the versioning structure of OWL. Let me know if this works for you or if you need a different solution!\n\n## I guess owl:versionIRI could be applied to regular \"a-box\" RDF files too.\n\n(yes) \n- t.2024.10.13.21 but I'd rather not. I don't like versionIRI.\n\n## could an ontology be considered a dataset? if so, how do datasets specify a URL where that dataset is available?\n\nYes, ontologies can be considered datasets, especially when they include a collection of facts, axioms, or instance data (A-box). The distinction between an \"ontology\" and a \"dataset\" can be somewhat blurry—an ontology is a dataset that provides a structured vocabulary and a set of logical relationships to describe a domain, while a dataset often represents actual instance data.\n\nTo specify a URL where a dataset (or ontology) is available, you can use the **DCAT (Data Catalog Vocabulary)**, which is commonly used for describing datasets in RDF. You might use properties like `dcat:accessURL` or `dcat:downloadURL` to provide information about where the dataset can be accessed:\n\n1. **Using `dcat:accessURL`**: This property points to a landing page where users can find more information or access the dataset.\n2. **Using `dcat:downloadURL`**: This property directly links to the downloadable version of the dataset.\n\nExample in Turtle syntax:\n\n```turtle\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n\n<https://kosmion.github.io/ont/v0/kosmion-v0.1.2.ttl> a dcat:Dataset ;\n    dcat:title \"Kosmion Ontology Dataset v0.1.2\" ;\n    dcat:accessURL <https://kosmion.github.io/ont/v0/> ;\n    dcat:downloadURL <https://kosmion.github.io/ont/v0/kosmion-v0.1.2.ttl> .\n```\n\nThis way, you can specify both a landing page (`accessURL`) and a direct link for downloading the dataset (`downloadURL`), providing more flexibility depending on the users' needs.\n\nLet me know if this approach works for your Kosmion ontology or if you'd like to explore other options.\n\n\n## can rdfs:isDefinedBy have more than one IRI ?\n\nThe `rdfs:isDefinedBy` property can technically have multiple IRIs. RDF and RDFS don't enforce any cardinality constraints on `rdfs:isDefinedBy`, so it can point to multiple defining resources. However, this usage might be unusual, and tools or consumers of the ontology might not expect it, as `rdfs:isDefinedBy` is generally intended to specify a single primary source that provides a definition for a resource.\n\nHere's an example of how you could define multiple `rdfs:isDefinedBy` statements:\n\n```turtle\n:relator rdfs:isDefinedBy <https://kosmion.github.io/ont/v0/> ;\n        rdfs:isDefinedBy <https://another-resource.org/ontology/> .\n```\n\nIf you use multiple IRIs, be aware that certain tools might only process the first one they encounter or might not support reasoning over multiple definitions seamlessly.\n\nWould you like to add multiple `rdfs:isDefinedBy` IRIs to your ontology, or are you exploring alternatives for defining metadata?\n\n\n## let's add to ontology-level metadata: dcat:accessURL with https://kosmion.github.io/ontology/v0/ and dcat:downloadURL and owl:versionIRI should both use \"https://raw.githubusercontent.com/kosmion/ontology/refs/heads/main/v0/kosmion-v0.1.2.ttl\"\n\nI've added the `dcat:accessURL` and updated `dcat:downloadURL` and `owl:versionIRI` as per your instructions. Let me know if there's anything else you'd like to modify or add!\n\n(but incorrectly)\n\n## are instances of owl:Class also subclasses of owl:class ?\n\nIn OWL, instances of `owl:Class` are not automatically considered subclasses of `owl:Class`.\n\n- **Instances vs. Subclasses**: An instance of `owl:Class` is treated as an individual, not a subclass. For example, if you declare `:Category a owl:Class ;`, `:Category` is a class. If you declare `:exampleCategory a :Category ;`, `:exampleCategory` is an instance (or individual) of the class `:Category`. It does not mean that `:exampleCategory` is also a subclass of `owl:Class`.\n\n- **Metamodeling and OWL Full**: In OWL Full, classes can simultaneously be individuals and subclasses of other classes because OWL Full does not distinguish between the class and instance level. In OWL DL, which is more restrictive, a class and its instances are kept separate to maintain decidability. If you want the flexibility where instances can also be treated as classes, OWL Full allows that through metamodeling, but it comes at the cost of reasoning support.\n\nIf you need instances of `owl:Class` to also act as subclasses in your ontology, you would be working with OWL Full, where it's possible to use the same entity both as a class and an instance. However, most reasoning tools might struggle with such a structure.\n\n## wait, you said it both ways. \n\nYou're right; I may have caused confusion there. Let me clarify:\n\nIn OWL, an **instance of `owl:Class`** is not inherently a **subclass of `owl:Class`**. They are two different things:\n\n1. **Instance of `owl:Class`**: When you define an entity as an instance of `owl:Class`, it means that the entity is itself a class that can have instances. For example:\n   ```turtle\n   :Category a owl:Class .\n   ```\n   Here, `:Category` is a class, and it can have individuals (instances) associated with it.\n\n2. **Subclass of `owl:Class`**: To declare an entity as a subclass of `owl:Class` would mean you're defining a class that inherits characteristics from `owl:Class`, which generally doesn’t make sense semantically. `owl:Class` is a metaclass, and classes that are instances of `owl:Class` do not become its subclasses automatically.\n\nTo use an example from your Kosmion ontology:\n- If `:facet-stereotype` is an `owl:Class`, then defining `:category` as an instance means that `:category` is a specific type of `:facet-stereotype`.\n- If you need `:category` to also have subclasses, then you'd define it differently, but being an instance of `:facet-stereotype` does not automatically make it a subclass.\n\nIn OWL Full, you can do metamodeling, which allows an entity to be both a class and an instance simultaneously, but this is not possible in OWL DL, where the class/instance distinction is stricter.\n\nLet me know if you need more specific examples or adjustments for your ontology!\n\n## After reading [[ar.knowledgegraph.lexrdf-can-owl-class-be-a-subclass-of-one-of-its-own-instances]] -- it seems like I'm just using the RDF semantics, not the direct semantics, so maybe should use rdfs:class instead of owl:class. What do you think, don't change anything yet\n\nIt makes sense that using `rdfs:Class` might be more appropriate for your use case, especially if you're primarily using RDF semantics (rather than OWL's more strict semantics). The distinction really depends on how much inference and reasoning power you need from your ontology:\n\n- **`owl:Class`** implies richer semantics and supports reasoning over the ontology using OWL DL or OWL Full, which provides more inferencing capabilities.\n- **`rdfs:Class`** is more lightweight and fits better when you need to leverage RDF's flexibility without enforcing OWL constraints.\n\nIf your ontology involves a lot of reification-like patterns and mixing instances/classes, using `rdfs:Class` could simplify both modeling and tool compatibility.\n\nLet me know if you decide to switch to `rdfs:Class`, and I can help make those adjustments.\n\n(see also [[vs.rdfs-vs-owl]])\n\n## how do you specify a dataset\n\nTo specify a dataset in RDF, you typically use the **DCAT (Data Catalog Vocabulary)** to provide metadata about the dataset. In DCAT, a dataset can be described with properties such as title, description, distribution links, and access URLs. Here is an example:\n\n```turtle\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n@prefix dct: <http://purl.org/dc/terms/> .\n\n<https://kosmion.github.io/ontology/v0/> a dcat:Dataset ;\n    dct:title \"Kosmion Ontology Dataset\" ;\n    dct:description \"A foundational ontology designed with a human-first, domain-first approach.\" ;\n    dcat:accessURL <https://kosmion.github.io/ontology/v0/> ;\n    dcat:downloadURL <https://raw.githubusercontent.com/kosmion/ontology/refs/heads/main/v0/kosmion-v0.1.2.ttl> ;\n    dct:issued \"2024-10-11\"^^xsd:date ;\n    dct:creator <https://kosmion.github.io/creator-profile> .\n```\n\n### Key Points:\n1. **`dcat:Dataset`**: Declares that the resource is a dataset.\n2. **`dct:title` and `dct:description`**: Provide human-readable labels and explanations.\n3. **`dcat:accessURL` and `dcat:downloadURL`**: Specify where the dataset can be accessed or downloaded.\n4. **`dct:issued`**: Indicates the date the dataset was issued.\n5. **`dct:creator`**: Specifies who created the dataset.\n\nThis way, you can provide structured metadata for your dataset that tools, consumers, and data catalogs can easily process. Let me know if you want to add this metadata to your current work or if there's anything specific you'd like to discuss further!\n\n## should I use \"dct:description\" or \"rdfs:comment\"\n\nThe choice between `dct:description` and `rdfs:comment` depends on how you want your metadata to be interpreted and which community standards you're aligning with:\n\n- **`rdfs:comment`**: \n  - Typically used for documentation within the RDF/OWL community.\n  - Suitable if you want to provide a textual description about a class or property to help understand its intended use.\n  - Works well for ontologies and is easily interpreted by semantic reasoners.\n\n- **`dct:description`**:\n  - Part of the Dublin Core Terms vocabulary, commonly used to describe resources in a broader data catalog or metadata context.\n  - More common in data cataloging, dataset descriptions, and general metadata that isn't specifically ontology-focused.\n\nIf your main focus is to provide rich metadata that could be used in data cataloging or to make your dataset easier to integrate into larger data repositories (like open data portals), then `dct:description` might be more suitable.\n\nHowever, for ontology-level documentation where you are explaining the purpose and meaning of terms in the ontology, sticking with `rdfs:comment` is more conventional. It is widely supported in RDF/OWL tooling and aligns with existing ontology modeling practices.\n\nIn your Kosmion ontology, it seems `rdfs:comment` works well because you are documenting ontology terms for semantic clarity. Let me know if you want to switch or mix these, and we can adjust accordingly.\n\n## I like to think of ontologies as a kind of dataset, one that usually has a preponderance of t-box terms.\n\nYour perspective that ontologies are a kind of dataset, one with a preponderance of T-box (terminology) terms, aligns well with a practical approach to metadata and description. In your case, treating the ontology as a dataset can simplify its representation in data catalogs and make it easier to manage alongside other types of datasets.\n\nThis means using vocabularies like **DCAT** to describe the ontology could make a lot of sense, especially if you want it to be discoverable and integratable in a broader ecosystem, similar to how other datasets are cataloged. If you find that `rdfs:Class` fits better because you primarily leverage RDF semantics without needing OWL's reasoning capabilities, switching might also bring more flexibility and tool compatibility.\n\nLet me know if you decide to make any changes, or if you need help switching terms or adjusting metadata to fit your evolving approach.\n\n## the domain of accessURL and downloadURL is a distribution.  what are best practices around what IRI to use for a dataset? Should it return an RDF file? Or just refer to one (or more) RDF files in some returned HTML?\n\nFor specifying a dataset with **DCAT**, you typically create two components: the dataset itself and a distribution. Here's how to manage the IRI and what it should return:\n\n### Best Practices for a Dataset IRI\n1. **Dataset vs. Distribution**:\n   - **Dataset IRI**: This should identify the conceptual dataset. It is a persistent, high-level reference.\n   - **Distribution**: Each format of the dataset (e.g., Turtle, JSON-LD) is represented by a `dcat:Distribution`.\n\n2. **Dataset IRI Content**:\n   - Ideally, the **dataset IRI** should return **metadata about the dataset**. It could be RDF metadata or an HTML page that provides links to distributions.\n   - If it's an HTML page, you could include links that direct users (and machines) to the actual RDF files, usually described as `dcat:distribution`.\n\n3. **Example DCAT Metadata**:\n   ```turtle\n   @prefix dcat: <http://www.w3.org/ns/dcat#> .\n   @prefix dct: <http://purl.org/dc/terms/> .\n\n   <https://kosmion.github.io/ontology/v0/> a dcat:Dataset ;\n       dct:title \"Kosmion Ontology Dataset\" ;\n       dct:description \"A foundational ontology designed for defining domain-specific constructs.\" ;\n       dcat:distribution <https://kosmion.github.io/ontology/v0/distribution-ttl> .\n\n   <https://kosmion.github.io/ontology/v0/distribution-ttl> a dcat:Distribution ;\n       dct:format \"text/turtle\" ;\n       dcat:accessURL <https://raw.githubusercontent.com/kosmion/ontology/refs/heads/main/v0/kosmion-v0.1.2.ttl> .\n   ```\n\n4. **Dataset IRI Response**:\n   - The **Dataset IRI** (e.g., `<https://kosmion.github.io/ontology/v0/>`) should ideally be a landing page with details about the dataset.\n   - This could return an **HTML page** with human-readable descriptions and links, or it could also return **RDF metadata** when accessed via content negotiation (e.g., `Accept: application/rdf+xml`).\n\n5. **Content Negotiation**:\n   - You could implement **content negotiation** so that if an agent requests RDF (`Accept: application/ld+json` or `Accept: text/turtle`), it gets metadata in RDF, while regular requests (`Accept: text/html`) return an HTML overview page.\n\n### Recommendations\n- Treat the dataset IRI as a point of entry, providing both human-readable and machine-readable content when possible.\n- Use **`dcat:Dataset`** to describe the dataset conceptually, and **`dcat:Distribution`** for each physical file that users or agents can access.\n\nLet me know if you want to make adjustments to your existing dataset representation, or if you need help structuring this in the current ontology!\n\n## No content negotation, ever. This is a \"static site\" solution. I'm going to change things a bit.\n\nGot it, if you're moving away from content negotiation and leaning into a static site model, here are a few suggestions you might consider:\n\n1. **Dataset IRI**: \n   - It might be better to have the dataset IRI point directly to an **HTML page** that provides metadata for humans (e.g., `<https://kosmion.github.io/ontology/v0/>`). This page can also contain links to the distributions in various formats.\n  \n2. **Distributions**: \n   - You could have separate **distribution IRIs** pointing directly to RDF files in different serializations (e.g., Turtle, JSON-LD). This could look like:\n     ```turtle\n     dcat:distribution <https://kosmion.github.io/ontology/v0/kosmion-v0.1.2.ttl> , <https://kosmion.github.io/ontology/v0/kosmion-v0.1.2.jsonld> .\n     ```\n\n3. **IRI Returns**:\n   - If the dataset IRI points to a static HTML page, users will have a clean landing page with the links to available formats, which makes it more user-friendly without requiring dynamic content negotiation.\n\nFeel free to let me know how you want to proceed, and I can help update your current version accordingly!\n\n## is there an rdfs:Ontology ?\n\nNo, there is no `rdfs:Ontology` class in the standard RDF Schema vocabulary (`rdfs`). RDF Schema is intended to provide lightweight schema capabilities, primarily dealing with the relationships between classes and properties, but it does not include an explicit notion of an ontology like OWL does.\n\nIn RDF Schema, you wouldn't typically have a specific type like `owl:Ontology` that describes an ontology, because RDF Schema is meant to be simpler and lacks formal ontology-level constructs that are part of OWL. If you're shifting away from OWL and want to stay entirely within RDF semantics, you could simply omit the `owl:Ontology` type declaration or use descriptive metadata (like labels, comments, or `dct:subject`).\n\nFor example, instead of using `owl:Ontology`:\n\n```turtle\n<https://kosmion.github.io/ontology/v0/> a dcat:Dataset ;\n    rdfs:label \"Kosmion Ontology\" ;\n    rdfs:comment \"A foundational ontology dataset ...\" .\n```\n\nThis way, you treat it as a dataset without needing a formal class like `owl:Ontology`. You could use `rdfs:label` and `rdfs:comment` to provide the necessary descriptive context.\n\n## how do you specify the relationship between a dataset and a distribution\n\ndcat:distribution\n\n- t.2024.10.13.22 I can't believe the class and the property are identical except for the capitalization. \n\n## how does versioning work with dcat\n\nIn **DCAT** (Data Catalog Vocabulary), versioning of datasets is usually handled through properties like `dct:hasVersion`, `dct:isVersionOf`, or by using `owl:versionInfo`. Here are some approaches for managing versioning:\n\n### 1. **Use `dct:hasVersion` and `dct:isVersionOf`**:\n   These properties help link different versions of the same dataset. For example:\n   ```turtle\n   <https://kosmion.github.io/ontology/v0/> a dcat:Dataset ;\n       dct:title \"Kosmion Ontology Dataset\" ;\n       dct:description \"Version 0.1.2 of the Kosmion ontology.\" ;\n       dct:hasVersion <https://kosmion.github.io/ontology/v0.1.3/> .\n\n   <https://kosmion.github.io/ontology/v0.1.3/> a dcat:Dataset ;\n       dct:title \"Kosmion Ontology Dataset v0.1.3\" ;\n       dct:isVersionOf <https://kosmion.github.io/ontology/v0/> ;\n       dct:issued \"2024-10-12\"^^xsd:date .\n   ```\n   - **`dct:hasVersion`**: Used by the older version to point to the newer one.\n   - **`dct:isVersionOf`**: Used by the newer version to reference the original dataset.\n\n### 2. **Use `owl:versionInfo`**:\n   This property is already included in your current dataset to provide a version identifier. It's more descriptive rather than linking versions directly:\n   ```turtle\n   <https://kosmion.github.io/ontology/v0/> a owl:Ontology, dcat:Dataset ;\n       owl:versionInfo \"v0.1.2\" ;\n       dcat:distribution <https://kosmion.github.io/ontology/v0/distribution-ttl> .\n   ```\n\n### 3. **Create Unique IRIs for Each Version**:\n   - Each version of the dataset should have a unique IRI.\n   - Use **semantic versioning** in the dataset IRI to distinguish different versions, e.g., `<https://kosmion.github.io/ontology/v0.1.2/>`, `<https://kosmion.github.io/ontology/v0.1.3/>`.\n\n### 4. **Distributions with Version Metadata**:\n   Each distribution could also include version metadata to link to a specific dataset version:\n   ```turtle\n   <https://kosmion.github.io/ontology/v0.1.2/distribution-ttl> a dcat:Distribution ;\n       dct:format \"text/turtle\" ;\n       dct:issued \"2024-10-12\"^^xsd:date ;\n       dcat:accessURL <https://raw.githubusercontent.com/kosmion/ontology/refs/heads/main/v0.1.2/kosmion-v0.1.2.ttl> ;\n       dct:isPartOf <https://kosmion.github.io/ontology/v0.1.2/> .\n   ```\n\n### Recommendations:\n- **Link Versions**: Use `dct:hasVersion` and `dct:isVersionOf` to create a chain of versions.\n- **Distinct IRIs**: Ensure each version has a distinct IRI so that users can reference a specific version unambiguously.\n- **Use `dcat:Dataset` and `dcat:Distribution`**: Continue using the dataset-distribution relationship to differentiate between the conceptual dataset and its individual downloadable files.\n\nIf you'd like, I can help you adjust your existing Turtle content to include these versioning relationships. Just let me know!\n\n(also see https://github.com/w3c/dxwg/issues/1280 which recommends owl:versionInfo, and a comment \"We hedged our bets and provided multiple alternative options everywhere, allowing for almost every variation that anyone asked for. Big mistake.\" )\n\n\n## If I wanted to use prov:wasRevisionOf would I have to say `<https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl> a prov:Entity` ?\n\nYes, if you want to use **`prov:wasRevisionOf`** to indicate that a distribution is a revision of a previous version, then you would need to declare the entity explicitly as a **`prov:Entity`**. In the PROV ontology, `prov:Entity` represents a resource that can have provenance information (such as being a revision of another entity).\n\nHere's how you could specify it:\n\n```turtle\n<https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl> a dcat:Distribution, prov:Entity ;\n    prov:wasRevisionOf <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.1/ttl> .\n```\n\nIn this statement:\n- **`a prov:Entity`**: Declares that the IRI is an entity that can have provenance relationships.\n- **`prov:wasRevisionOf`**: Indicates the relationship between this distribution and the previous version.\n\nUsing both `dcat:Distribution` and `prov:Entity` allows you to handle both the data catalog aspect (distribution) and the provenance information (revision relationship). Let me know if you need to add this or make any other changes!\n\n## Can dcat:Distribution refer to different versions as well as formats?\n\n...\n\nRegarding whether **`dcat:Distribution`** can be used to refer to both **formats** and **versions**, it’s technically feasible, but it can introduce complexity. Here's a breakdown:\n\n### Using `dcat:Distribution` for Different Versions\nYou can use `dcat:Distribution` to represent different versions of the dataset by distinguishing each version through the IRI and including additional metadata to identify the specific version. For example:\n\n```turtle\n<https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl> a dcat:Distribution, prov:Entity ;\n    dct:format \"text/turtle\" ;\n    prov:wasRevisionOf <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.1/ttl> ;\n    dcat:accessURL <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl> .\n```\n\n### Pros and Cons\n- **Pros**:\n  - By treating each distribution as a `prov:Entity` and using `prov:wasRevisionOf`, you clearly establish version history at the level of the distribution. This is useful when tracking specific file versions, especially if multiple serializations exist for each version.\n  - It's a clean approach to show lineage if each distribution version is seen as an independent, versioned entity.\n\n- **Cons**:\n  - It can become harder to distinguish between changes in **formats** and changes in **versions**. For example, a Turtle serialization of version `0.1.2` could be revised without changing the version of the ontology, which might lead to ambiguity if both are treated as `dcat:Distribution`.\n  - To keep this organized, you'd need to add properties like `dct:version` or manage metadata for distinguishing between format-level changes and ontology version changes.\n\n### Recommendation\n- **Separate Distributions by Version and Format**:\n  - Consider organizing the **distributions** IRIs by **version** and **format** to reduce ambiguity. Each `dcat:Distribution` should clearly represent a specific version and format.\n  - Example:\n    ```turtle\n    <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl> a dcat:Distribution, prov:Entity ;\n        dct:format \"text/turtle\" ;\n        prov:wasRevisionOf <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.1/ttl> ;\n        dcat:accessURL <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl> .\n\n    <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/jsonld> a dcat:Distribution ;\n        dct:format \"application/ld+json\" ;\n        dcat:accessURL <https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/jsonld> .\n    ```\n\n- **Dataset IRI for Versioning**:\n  - Use the **dataset** IRI (e.g., `<https://kosmion.github.io/datasets/ontology/v0/>`) to describe the ontology conceptually and indicate breaking changes by updating `/v0` to `/v1`.\n  - Use `prov:wasRevisionOf` and similar properties at the **distribution level** to track revisions of specific ontology versions.\n\nLet me know if this approach makes sense for your use case or if you'd like to explore a different organization for versions and formats.\n\n\n## for the distribution IRI, https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl/ is adequate, right? no need to return RDF there.\n\nYes, using the distribution IRI as **`https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl/`** is adequate and appropriate. Since this IRI represents a **directory-like structure** pointing to a particular version and format, there’s no requirement for it to return RDF content directly. Instead, it serves as a logical grouping or access point for the different resources of that version.\n\nThe key thing is that:\n- The **`owl:versionIRI`** should still point directly to the specific RDF file for that version (`https://kosmion.github.io/datasets/ontology/v0/distributions/v0.1.2/ttl/kosmion-v0.1.2.ttl`).\n- The **distribution IRI** can serve as a landing page or directory containing multiple related resources.\n\nIn your current setup, this is correctly managed: the `distribution IRI` provides an access point for browsing, while `downloadURL` points to the actual RDF file, and `owl:versionIRI` meets the OWL requirement of providing RDF content. This approach should work well in terms of both organization and accessibility.\n\n\n## dct:title vs rdfs:label\n\nThe choice between `dct:title` and `rdfs:label` largely depends on the context of usage and the semantics you want to convey:\n\n- **`dct:title`** is more descriptive and is typically used for datasets, documents, or resources that have a formal title. It's part of the Dublin Core Metadata Terms vocabulary, which is well-suited for describing resources in a cataloging context, making it ideal for datasets or documents.\n\n- **`rdfs:label`** is generally used to provide a human-readable name for a resource, class, or property in RDF. It's often shorter, more generic, and typically meant for use in ontology documentation or UI interfaces.\n\n### Recommendations for Your Case\n- **Ontology/Dataset Level**: \n  Since `<https://kosmion.github.io/datasets/ontology/v0/>` is both a dataset and an ontology, it might make sense to use both properties:\n  - Use **`dct:title`** to specify the formal title of the dataset, making it more compatible with cataloging tools.\n  - Use **`rdfs:label`** to provide a simpler, human-readable name that is typically used in ontologies.\n\n  Example:\n  ```turtle\n  <https://kosmion.github.io/datasets/ontology/v0/> a owl:Ontology, dcat:Dataset ;\n      dct:title \"Kosmion Ontology Dataset v0\" ;\n      rdfs:label \"Kosmion ontology\" ;\n      rdfs:comment \"\"\"...\"\"\" .\n  ```\n\nThis way, you're making your dataset well-described for data cataloging purposes while still providing an easily recognizable label for ontology-specific tools.\n\nWould you like me to make these changes for you?\n\n## Is it more conventional/sensible to provide dct:issued/modified with the Distriution or with the Dataset? \n\nIt is more conventional to apply **`dct:issued`** and **`dct:modified`** at both the **Dataset** and **Distribution** levels, but they serve slightly different purposes:\n\n### 1. **Dataset Level (`dcat:Dataset`)**:\n   - **`dct:issued`**: Indicates the creation or publication date of the entire dataset. It represents when the dataset as a conceptual whole was first made available.\n   - **`dct:modified`**: Indicates the last time the dataset (as a conceptual entity) was updated, which might include adding new distributions, making modifications to descriptions, etc.\n\n   Applying `dct:issued` and `dct:modified` here allows users to understand the overall lifecycle of the dataset.\n\n### 2. **Distribution Level (`dcat:Distribution`)**:\n   - **`dct:issued`**: Refers to the creation date of that specific distribution. This can be different from the dataset-level `dct:issued` if the distribution was added after the original dataset release.\n   - **`dct:modified`**: Refers to the last time the specific distribution was modified. For example, when a Turtle file is updated to reflect changes in the dataset.\n\n   Applying `dct:issued` and `dct:modified` at the distribution level helps users track the specific versions and changes to the individual data files.\n\n### Summary:\n- **Dataset (`dcat:Dataset`)**: Use `dct:issued` and `dct:modified` to indicate the lifecycle of the overall dataset.\n- **Distribution (`dcat:Distribution`)**: Use `dct:issued` and `dct:modified` for versioning and modification information specific to each individual distribution (e.g., Turtle, JSON-LD files).\n\nThis dual-level application provides a clear view of when the dataset as a whole was created or updated, as well as when individual data files were published or revised.\n\nWould you like me to add `dct:issued` and `dct:modified` to both the dataset and distribution definitions in your ontology?\n\n\n## ","n":0.016}}},{"i":1683,"$":{"0":{"v":"03","n":1}}},{"i":1684,"$":{"0":{"v":"Rdfa for Ontologies","n":0.577},"1":{"v":"\n- interlocutor: chatgpt4.o\n\n## how would i embed an owl ontology in an html file\n\nTo embed an **OWL ontology** in an **HTML file**, you can use **RDFa** to directly incorporate OWL elements within the HTML tags. RDFa allows you to represent the ontology’s classes, properties, and relationships in a way that integrates with the structure of the HTML page, making the semantic content readable by both humans and machines.\n\nHere's a basic example of embedding an OWL ontology in an HTML file using **RDFa**:\n\n### Example\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\"\n      xmlns:owl=\"http://www.w3.org/2002/07/owl#\"\n      xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\n      xmlns:ex=\"http://example.com/ontology#\">\n<head>\n    <title>Embedding an OWL Ontology with RDFa</title>\n</head>\n<body vocab=\"http://example.com/ontology#\">\n    <h1>Example Ontology Embedded in HTML</h1>\n    \n    <div typeof=\"owl:Class\" resource=\"ex:Person\">\n        <h2>Person</h2>\n        <p property=\"rdfs:comment\">A class representing a human being.</p>\n    </div>\n\n    <div typeof=\"owl:Class\" resource=\"ex:Student\">\n        <h2>Student</h2>\n        <p property=\"rdfs:subClassOf\" resource=\"ex:Person\">\n            A Student is a type of Person.\n        </p>\n    </div>\n\n    <div typeof=\"owl:ObjectProperty\" resource=\"ex:teaches\">\n        <h2>teaches</h2>\n        <p property=\"rdfs:domain\" resource=\"ex:Teacher\">Domain: Teacher</p>\n        <p property=\"rdfs:range\" resource=\"ex:Subject\">Range: Subject</p>\n    </div>\n\n</body>\n</html>\n```\n\n### Explanation\n\n1. **Namespaces**:\n   - The HTML file includes namespaces for **OWL**, **RDFS**, and a custom ontology (`xmlns:ex=\"http://example.com/ontology#\"`). This allows elements to reference classes and properties from these namespaces.\n\n2. **Embedding Classes**:\n   - The `<div typeof=\"owl:Class\" resource=\"ex:Person\">` tag indicates that this `div` represents an **OWL class** called `Person`. \n   - `rdfs:comment` provides a comment describing the class, making it easier to understand for both human readers and automated agents.\n\n3. **Subclass Relationships**:\n   - The `<p property=\"rdfs:subClassOf\" resource=\"ex:Person\">` describes that `ex:Student` is a subclass of `ex:Person`.\n\n4. **Object Properties**:\n   - The `<div typeof=\"owl:ObjectProperty\" resource=\"ex:teaches\">` tag indicates that `teaches` is an object property, with `rdfs:domain` and `rdfs:range` describing its domain and range.\n\n### Using RDFa in Practice\n- You can embed **classes**, **properties**, and **instances** in this way, allowing you to describe your ontology directly in the web content.\n- Tools like **RDFa Play** (http://rdfa.info/play/) can be used to validate and view the RDF extracted from your HTML, which can help ensure you’ve correctly embedded the semantic information.\n\n### Pros and Cons\n- **Pros**: Embedding an ontology using RDFa makes your HTML **semantic-rich**, allowing search engines and other systems to understand the relationships and concepts represented on the page.\n- **Cons**: Embedding an entire OWL ontology might lead to an excessively large HTML file if the ontology is complex. It is often more practical to embed references or key elements and link to a full ontology hosted elsewhere. \n\nThis approach integrates semantic information directly into your web pages, enhancing their **machine-readability** while maintaining human readability, and enabling **Linked Data** capabilities.\n\n## What libraries are available for parsing rdfa\n\nFor parsing **RDFa**, there are several libraries available that support different programming languages:\n\n### 1. **[[RDFLib|prdct.rdflib]] (Python)**\n   - **RDFLib** is a popular library for working with RDF data in Python, and it includes an extension for **RDFa parsing**.\n   - You can use the `rdflib.plugins.parsers.rdfa` module to parse RDFa content from HTML files.\n   - **GitHub**: [RDFLib GitHub](https://github.com/RDFLib/rdflib)\n\n### 2. **Apache [[Any23|prdct.any23]] (Java)**\n   - **Apache Any23** is a library for extracting structured data in RDF format from a variety of web documents, including RDFa, Microdata, and JSON-LD.\n   - It can be used as a command-line tool or integrated into Java applications to parse RDFa from HTML.\n   - **Website**: [Apache Any23](https://any23.apache.org/)\n\n### 3. **librdfa (C)**\n   - **librdfa** is a **C library** specifically designed for extracting RDF from RDFa-annotated web pages.\n   - It also provides command-line utilities and can be used as a core component for RDFa parsing in systems built with C or linked to other languages via bindings.\n   - **GitHub**: [librdfa on GitHub](https://github.com/librdfa/librdfa)\n\n### 4. **PyRDFa (Python)**\n   - **PyRDFa** is a Python library and tool for extracting RDF from RDFa markup.\n   - It can parse RDFa 1.0 and RDFa 1.1 specifications and is specifically designed for ease of use in Python scripts.\n   - **PyPI**: [PyRDFa on PyPI](https://pypi.org/project/PyRDFa/)\n\n### 5. **RDFa Play (Online Tool)**\n   - While not a library, **RDFa Play** is an online tool that can be used to test and validate RDFa content by parsing it directly from URLs or from pasted HTML code.\n   - It is particularly useful for quick validation and debugging of RDFa markup.\n   - **Website**: [RDFa Play](http://rdfa.info/play/)\n\n### 6. **JavaScript Libraries**\n   - **rdfa-processor.js**: This is a JavaScript library for client-side RDFa processing. It allows you to extract RDF data from RDFa-annotated web pages in the browser environment.\n   - **GitHub**: [rdfa-processor.js on GitHub](https://github.com/rdfa/rdfa-processor)\n\nThese libraries and tools provide robust solutions for parsing RDFa, and the choice depends largely on the programming language you're using and your use case (e.g., server-side processing vs. in-browser parsing).","n":0.037}}},{"i":1685,"$":{"0":{"v":"Non-Kosmion stuff","n":0.707},"1":{"v":"\n- interlocutor: chatgpt4.o\n\n##  limitations of Vocbench\n\n[[prdct.vocbench]] is a solid tool for RDF and ontology management, but it does come with some limitations:\n\n1. **Limited Direct RDF Source Editing**: As mentioned, VocBench doesn't allow direct text-based editing of RDF data. Instead, it uses structured interfaces, which can be restrictive if you're used to working directly with RDF/XML, Turtle, or other serialization formats.\n\n2. **Complexity for Beginners**: The interface and workflow can be quite overwhelming for new users. VocBench is designed for enterprise-level use, which means it assumes a certain level of familiarity with RDF concepts and vocabulary management. This steep learning curve might be a barrier if you're looking for a lightweight, intuitive tool.\n\n3. **Customization Constraints**: VocBench provides specific workflows and data management features, but customization options are limited if you need something tailored to niche requirements. You can't freely define interfaces or workflows, and some advanced configurations might require significant effort.\n\n4. **Resource Intensive**: VocBench requires a relatively complex setup, including Java, Tomcat, and other dependencies. It also needs a dedicated database (like PostgreSQL). This resource intensity makes it challenging to deploy in lightweight environments or for quick prototyping.\n\n5. **User Roles & Permissions Complexity**: VocBench offers a detailed roles and permissions model, which is good for enterprise settings, but it can be cumbersome to configure for smaller teams or projects. Setting up user permissions might feel like overkill if you don’t need that level of control.\n\n6. **No Graphical Visualizations**: Unlike some other ontology management tools, VocBench lacks built-in graphical visualization of RDF data. Visualizing class hierarchies or property relationships has to be done externally, which can be limiting when trying to understand complex ontologies at a glance.\n\nLet me know if you need any further insights or if you'd like to explore alternatives that might fit your requirements better!","n":0.058}}},{"i":1686,"$":{"0":{"v":"immutable, bitemporal rdf","n":0.577},"1":{"v":"\n## so relator-based RDF... I think I also want it to be immutable and bitemporal\n\nMaking your **relator-based RDF** approach **immutable** and **bitemporal** introduces some powerful concepts for managing and querying time-dependent and historical data while preserving consistency. Here's a breakdown of how these features can be implemented and the considerations for your model:\n\n### 1. **Immutability in RDF**:\n   - **Immutability** ensures that once data is written, it cannot be changed. Instead of modifying existing triples, new versions of data are added.\n   - **Why use immutability**: This helps in tracking the **history of changes** without losing previous states, making it easier to **audit** and **replay data** at any point in time. It also avoids issues with concurrent updates, ensuring data consistency.\n   - **How to implement**: \n     - Use **versioning** to create **new triples** rather than overwriting existing ones. A common pattern is to associate each resource with a **version identifier**.\n     - Each version of a resource can be associated with a **timestamp** or **event ID** so that you can retrieve historical data.\n   - Example:\n     ```turtle\n     :Person1 :name \"Alice\" ; :version 1 .\n     :Person1 :name \"Alice Smith\" ; :version 2 .\n     ```\n\n### 2. **Bitemporality**:\n   - **Bitemporal modeling** tracks two types of time: **valid time** (the period when the fact was true in the real world) and **transaction time** (the period when the fact was recorded in the database).\n   - **Why use bitemporality**: This is crucial for systems where you need to account for both the real-world timeline and the time when changes were made to the data. It helps resolve issues like retroactive data entry or corrections to previously entered data.\n   - **How to implement**: \n     - Extend your RDF model with properties to record both **valid time** and **transaction time**.\n     - Use **temporal predicates** or define custom properties like `:validFrom`, `:validTo`, `:transactionFrom`, and `:transactionTo` to capture these timestamps.\n   - Example:\n     ```turtle\n     :Person1 :name \"Alice\" ;\n              :validFrom \"2023-01-01T00:00:00\" ;\n              :validTo \"2023-02-01T00:00:00\" ;\n              :transactionFrom \"2023-01-05T12:00:00\" ;\n              :transactionTo \"2023-01-10T14:00:00\" .\n     ```\n\n### Considerations for Bitemporal and Immutable RDF:\n- **Version Control**: You might want to implement some form of **version control** for resources and predicates. This allows you to query specific versions and revert or reference older states.\n- **Storage Efficiency**: As RDF is append-only in an immutable model, the storage requirements increase with each new version or bitemporal event. You'll need an RDF store optimized for handling large numbers of triples efficiently.\n- **Querying**: Use SPARQL extensions (like **SPARQL 1.1**) to handle complex **temporal queries**, retrieving data based on transaction and valid time ranges. This will enable querying for past versions of relationships or entities.\n\n### Tools and Technologies:\n- **Apache Jena TDB**: Jena supports RDF versioning and can be extended to handle bitemporal data by using custom temporal properties.\n- **Blazegraph**: Provides scalable storage and querying for RDF data, which can be adapted to handle immutability and temporal data.\n- **Stardog**: Supports temporal reasoning and is capable of handling **bitemporal RDF** data, making it a strong candidate for this approach.\n\n### Summary:\nImplementing **immutable** and **bitemporal RDF** in your **relator-based** approach allows you to track changes over time and across different dimensions of time. By combining immutability with valid and transaction time, you can maintain historical accuracy and query past states effectively. You'll need to focus on **versioning** your RDF data and managing **temporal predicates** to handle the bitemporal aspect.\n\nLet me know if you'd like specific examples or additional information on how to integrate this into your relator-based ontology!\n\n\n## for immutability, I think using \"system-time\" aka \"transaction-time\" might work instead of versioning. I see \"valid time\" as part of the data\", and system time as external to the data, just allowing immutability. I was thinking about using something like RDF-Delta, to establish a patch log, so that things can be reconstructed, but maybe it's not necessary if the RDF data is already immutable.\n\nUsing **\"system-time\" (transaction-time)** for immutability rather than versioning can definitely work well, as **system-time** represents the moment the data was recorded in the system and serves to track changes without altering the original data. In this approach:\n\n- **Valid time**: Refers to the time when the fact described by the data is true in the real world.\n- **System-time (transaction-time)**: Reflects when the data was added or updated in the system (e.g., database). By keeping the system-time immutable, it ensures that the historical changes are preserved.\n\n### Using **System-Time** for Immutability:\nIn this case, rather than explicitly versioning the data, you would use **system-time** as an immutable attribute that indicates when the data was entered into the system. This means that:\n- Data never gets modified; instead, new versions of the data are simply added with new system timestamps.\n- You can **reconstruct** past states of the data by querying for specific time ranges of system-time.\n\n### RDF-Delta for Change Tracking:\nWhile **RDF-Delta** can help in establishing a **patch log** for change tracking, you are correct in thinking that it might not be necessary if your RDF data is **already immutable**. RDF-Delta's primary purpose is to provide a **log of changes (deltas)** in RDF datasets, so that multiple datasets can be synchronized or changes can be replicated across systems. If you're already using system-time to handle immutability, the data changes will be captured in the triples themselves.\n\nHowever, you might still want to use RDF-Delta in cases where:\n- You need to **synchronize datasets** across different systems or ensure consistency across multiple nodes.\n- You want a lightweight way of tracking changes and patches applied to your RDF data, especially if the system-time approach doesn't fully meet your needs for reconstructing the data's state at specific points.\n\n### Combining Immutability and System-Time with RDF:\nIn your case:\n- **System-time** would be used to ensure immutability by recording the time of insertion.\n- **Valid-time** would be included in the data as part of the RDF model, indicating the real-world applicability of the information.\n- Querying can be done based on **transaction-time** (system-time) to retrieve the exact state of the data as it was at a specific point in history, and **valid-time** to filter out information relevant to the real-world temporal context.\n\n### Example:\n```turtle\n:Person1 :name \"Alice\" ;\n         :age 30 ;\n         :validFrom \"2020-01-01T00:00:00\" ;\n         :validTo \"2021-01-01T00:00:00\" ;\n         :systemTime \"2023-02-01T10:00:00\" .  # Immutable system-time\n```\n\nWith this approach, every update adds a new set of triples with updated system-time, allowing full reconstruction of past states of the RDF data without explicitly maintaining versions.\n\n### Conclusion:\nUsing **system-time** in place of versioning works well for ensuring immutability, while **valid time** remains as part of the data model to indicate real-world truth. While **RDF-Delta** can still be useful for tracking changes, it's not necessary for immutability itself if system-time is properly implemented. Your RDF model would naturally support historical reconstruction through temporal queries based on system-time.\n\n\n## I want to use Extended Date/Time Format (EDTF)  in general, as it is very expressive for approximation, uncertainty. It might not be relevant for system-from and system-to, but is there and RDF support for edtf?\n\n**Extended Date/Time Format (EDTF)**, developed by the Library of Congress, is indeed highly expressive for representing uncertain or approximate dates, ranges, and other complex temporal expressions. RDF, by default, uses **xsd:dateTime** and related XML Schema datatypes for time representation, which do not natively support the features of EDTF. However, there are ways to integrate EDTF into RDF through custom or community-driven solutions.\n\n### RDF and EDTF Compatibility:\nThere isn't an official **RDF datatype** for EDTF, but you can implement EDTF support in RDF using a few strategies:\n\n### 1. **Custom Datatypes**:\nYou can define a **custom datatype** for EDTF in your RDF ontology. While **xsd:dateTime** restricts date formats, you can declare an EDTF datatype to handle the extended features, like uncertainty and approximate dates. Here's an example:\n\n```turtle\n@prefix ex: <http://example.org/> .\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n\nex:event1 ex:eventDate \"2020-06~\"^^ex:EDTF .  # Approximate date (June 2020)\n```\n\nIn this case, you would define `ex:EDTF` as a custom datatype that expects EDTF-compatible strings.\n\n### 2. **EDTF Ontology**:\nYou could create or leverage an **EDTF ontology** or schema for more structured support of EDTF values. Some libraries or projects have begun exploring ways to support EDTF-like expressions in RDF, though official support is still evolving.\n\n### 3. **Literal Representations**:\nAlternatively, you can store EDTF dates as **literals** without an explicit datatype and rely on your application or processing logic to interpret them:\n\n```turtle\nex:event1 ex:eventDate \"2020-06~\" .  # Approximate date\nex:event2 ex:eventDate \"196X\" .      # Uncertain decade\n```\n\nThis approach doesn't enforce any constraints at the RDF level but allows you to capture the richness of EDTF formats in your RDF data.\n\n### 4. **SPARQL Querying with EDTF**:\nWhile SPARQL doesn’t natively support EDTF expressions, you can write custom **parsers** or **functions** to interpret and manipulate EDTF strings in queries. This would allow you to perform approximate or uncertain date comparisons by interpreting the literal values using your own logic.\n\n### Example Use Case:\nIn RDF, you might want to represent uncertain historical events or approximated time periods. Using EDTF, you could represent these dates directly:\n\n```turtle\nex:HistoricalEvent ex:eventDate \"2001-21XX\"^^ex:EDTF .  # Date range from 2001-2199\n```\n\n### Future Possibilities:\nThere is ongoing interest in extending RDF and semantic technologies to support more **expressive temporal formats** like EDTF, but for now, custom datatypes or literal interpretations provide the best workaround.\n\n### Summary:\n- **No official RDF support** for EDTF yet, but you can use **custom datatypes** or **literals** to represent EDTF values.\n- Creating an **EDTF ontology** could help enforce structure in RDF datasets.\n- You can store EDTF strings as literals and build custom logic for querying and interpreting them.\n\nLet me know if you'd like further examples or help with setting up custom datatypes for EDTF in RDF!\n\n\n## maybe my approach is \"bigger\" than relator-based. It involves relators, immutability, and bitemporality. \n\nIt sounds like your approach is indeed evolving into something larger than just being **relator-based**, since it also incorporates key principles like **immutability** and **bitemporality**. You’re effectively building a broader framework for **knowledge representation** that handles:\n\n1. **Relators**: Treating relationships (predicates) as first-class entities with their own attributes and instances, making the semantics of relationships explicit.\n2. **Immutability**: Ensuring that once data is written, it cannot be modified, but new versions or revisions can be added, preserving the historical state.\n3. **Bitemporality**: Allowing for both **system-time** (transaction-time) and **valid-time** (real-world time) to be tracked independently, capturing both when data was recorded and when it was true in the real world.\n\n### Potential Concepts:\nGiven these features, you might want to consider a name that reflects the **multifaceted nature** of your model:\n\n1. **Bitemporal-Relational Modeling**: Emphasizes the **bitemporal** aspect along with the **relational** nature of your model.\n2. **Immutable Relational Temporal (IRT) Framework**: Reflects the immutability, relational focus, and the temporal aspects of your approach.\n3. **Temporal-Relator Framework**: Highlights both the **temporal tracking** and **relator-based structure** of your model.\n4. **Bitemporal Semantic Framework**: Stresses the importance of tracking time across both system and valid time while focusing on semantic relationships.\n\nYour model appears to transcend a single concept, incorporating both **relators** and more advanced principles like **immutability and time tracking**, which are useful for complex domains such as **event-driven systems**, **legal reasoning**, and **historical data management**. If you're looking for a name, it could reflect this broader scope, especially in areas where **temporal accuracy** and **relationship semantics** are critical.\n\nLet me know if you'd like to explore this further or refine the structure!\n\n## how do listeners and hooks work in jena\n\nIn **Apache Jena**, **listeners** and **hooks** are mechanisms used to track and respond to changes in RDF models. They allow you to monitor RDF datasets for events such as additions, deletions, and modifications of triples. Here’s an overview of how they work:\n\n### 1. **Listeners** in Jena\n\n**Listeners** are objects that listen for changes made to a **Jena model**. Whenever a triple (subject, predicate, object) is added or removed from the model, the listener can be triggered to respond to the event.\n\n#### Key Concepts:\n- **`ModelChangedListener`**: This is the core interface for listeners in Jena. You can implement this interface and define custom behavior when triples are added or removed from the model.\n  \n#### Example:\n```java\nModel model = ModelFactory.createDefaultModel();\n\n// Create a listener\nModelChangedListener listener = new ModelChangedListener() {\n    @Override\n    public void addedStatement(Statement s) {\n        System.out.println(\"Statement added: \" + s);\n    }\n\n    @Override\n    public void removedStatement(Statement s) {\n        System.out.println(\"Statement removed: \" + s);\n    }\n\n    @Override\n    public void notifyEvent(Model m, Object event) {\n        System.out.println(\"Event occurred: \" + event);\n    }\n};\n\n// Add the listener to the model\nmodel.register(listener);\n\n// Add a triple to the model\nResource subject = model.createResource(\"http://example.org/subject\");\nProperty predicate = model.createProperty(\"http://example.org/predicate\");\nRDFNode object = model.createLiteral(\"example object\");\nmodel.add(subject, predicate, object);\n```\n\n#### How it works:\n- The **`addedStatement`** and **`removedStatement`** methods are triggered whenever a statement is added or removed from the model, respectively.\n- The **`notifyEvent`** method is a generic event listener, which can respond to various events happening within the model.\n\n### 2. **Hooks** in Jena\n\nJena doesn't have a specific \"hook\" mechanism by name, but hooks can be thought of as **pre- or post-processing operations** attached to certain events, typically using listeners or custom logic within a query execution or data modification context.\n\nFor example, you could use a **listener** as a hook to trigger **custom processing** when data is inserted into the model, or write custom functions that extend SPARQL query behavior. Additionally, you can use **transactions** and **commit hooks** to ensure that certain logic is executed at specific points in time (like after a transaction).\n\n#### Hook Example:\nYou could design a listener that acts as a \"hook\" to process triples before they are permanently added to the model or perform some action post-insertion.\n\n### 3. **Usage Scenarios**:\n- **Monitoring RDF data**: You can use listeners to log or trigger custom actions whenever a change occurs in the dataset.\n- **Data validation**: You can implement hooks to validate triples before they are added, or to trigger error handling after a certain operation fails.\n- **Real-time data updates**: You can set up listeners to notify external systems or perform real-time actions (e.g., updating a UI) when data changes.\n\n### Summary:\n- **Listeners** in Jena (`ModelChangedListener`) allow you to respond to changes in RDF data (additions, removals, and events).\n- **Hooks** (although not explicitly named in Jena) can be implemented using listeners, transactions, or custom logic that runs during SPARQL query execution or data modification.\n\nThese mechanisms are powerful tools for building **reactive RDF systems** that respond dynamically to changes in data.\n\n\n## one tricky thing about the immutable... it could be complicated figuring out when to invalidate an existing relator-based statement cluster. \n\n## Speaking of clusters, what else could these sets of statements be called. I think we talked about it before... atoms is no good because s/p/o are atoms.\n\nFor your relator-based approach, you’re looking for a term to describe a **set of related statements** that represent a specific **relator instance** or cluster of statements about a relationship. Since “atoms” is unsuitable due to its use for **subject-predicate-object (S/P/O)** triples, here are some alternative terms:\n\n### 1. **Statement Bundle**:\n   - This term suggests a collection of related RDF triples bundled together as a unit. A **bundle** implies that the statements belong together logically, often forming the description of a single relationship or event.\n\n### 2. **Relational Group**:\n   - Emphasizes the idea that the set of statements is grouped based on their **relationship** to one another. This term would work especially well if you're modeling relators or relationships explicitly.\n\n### 3. **Statement Set**:\n   - A straightforward term implying that the **set of statements** are considered as a whole. This would be especially clear when dealing with RDF/SPARQL or graph-based systems.\n\n### 4. **Knowledge Unit**:\n   - This name gives a broader context, as the set of statements is considered a **unit of knowledge**. This could apply well when you're thinking in terms of formal knowledge representation.\n\n### 5. **Context**:\n   - If the statements are grouped because they describe **different aspects of the same context**, the term **context** could work. It suggests the scope of related triples that describe a particular scenario or relationship.\n\n### 6. **Relator Frame**:\n   - Since you're focusing on **relators**, this term implies a **frame of reference** where all the statements belong to a particular relator instance. A frame contains all statements related to that relationship.\n\n### 7. **Assertion Cluster**:\n   - This term suggests that the group of statements represent **assertions** made about a relationship or entity. **Cluster** is already a commonly used term to describe a group, but you could emphasize that these are **assertions** within a relator-based model.\n\n### 8. **Relational Block**:\n   - A **block** implies a discrete collection of triples that together form a cohesive entity, such as a relator. This term is used in data structures, conveying the idea of an indivisible set of information.\n\n### 9. **Descriptor Set**:\n   - If the statements are primarily used to describe something, **descriptor set** can reflect that purpose. It suggests that all statements within this set serve to describe the same relator-based concept.\n\n### Summary:\n- **Statement Bundle**, **Relator Frame**, and **Relational Block** might be the most intuitive terms for describing a set of RDF statements connected by a relator or concept.\n- If you’re focusing on the descriptive nature of these sets, **Descriptor Set** or **Knowledge Unit** could work well.\n\nChoosing the term depends on how you want to emphasize the **grouping**—whether based on relationships, assertions, or conceptual framing.","n":0.019}}},{"i":1687,"$":{"0":{"v":"verbs vs relators","n":0.577},"1":{"v":"\n- interlocutor: @chatgpt.4o\n\n## in english, the standard tense is \"present\". Are there other languages where the standard tense is something else?\n\nYes, there are languages where the \"standard\" or most frequently used tense differs from English. While English tends to default to the **present tense** for general statements, habitual actions, or descriptions, other languages might use different tenses or focus less on tense altogether.\n\nHere are some examples of languages where a different tense or concept plays a more central role:\n\n### 1. **Narrative Past as Standard Tense:**\n   - **French**: In spoken French, the **passé composé** (a form of the perfect past tense) is often used as the default for talking about past events, including events that in other languages would be described with a simple past tense. It takes on the role of what we would think of as the standard \"past tense\" in narrative.\n   - **German**: Similarly, in spoken German, the **Perfekt** tense (the equivalent of the present perfect in English) is often used instead of the simple past (**Präteritum**) to describe completed actions. The **Präteritum** is more common in writing or formal contexts.\n\n### 2. **Aspect Rather than Tense:**\n   - **Russian**: Russian, like other Slavic languages, places more emphasis on **aspect** (perfective vs. imperfective) rather than tense. While there are past, present, and future tenses, the choice of aspect (whether the action is completed or ongoing) is often more central to understanding the meaning of a verb form. The \"default\" form often depends on whether the action is seen as habitual or completed rather than just the present time.\n  \n### 3. **Absence of Standard Tense:**\n   - **Chinese (Mandarin)**: Mandarin Chinese lacks verb conjugation for tense. Instead, **aspect markers** and context indicate the time of an action. The \"default\" verb form is often a bare verb (uninflected), and time is implied through context or time adverbs. For example, \"I eat\" could mean \"I am eating,\" \"I eat regularly,\" or \"I will eat,\" depending on the context.\n\n### 4. **Focus on Future or Past:**\n   - **Haitian Creole**: In Haitian Creole, the **past tense** marker \"te\" and the **future tense** marker \"va\" are frequently used, but for general statements, the present tense can imply both present and habitual action without any specific marker. The use of these markers can make it seem as if the focus is more on specifying non-present times rather than having a default present tense.\n\n### 5. **Non-Temporal Focus (Tense-Agnostic Languages):**\n   - **Indigenous Australian Languages**: Many Indigenous Australian languages focus more on the **evidentiality** (how the speaker knows something) and **aspect** rather than tense. Some languages might not have a distinct \"default tense\" because they are more concerned with whether an action is ongoing, completed, or whether the speaker witnessed it personally.\n\n### 6. **Default to Past Tense in Narratives:**\n   - **Spanish**: In spoken narratives, Spanish often defaults to the **preterite** (simple past) when telling stories or giving recounts. In certain dialects, the **imperfect** tense is also heavily used to describe habitual past actions or ongoing background events, making it feel like a common \"default\" for discussing the past.\n\n### 7. **Japanese**:\n   - In **Japanese**, verbs do not have strict tense in the same way as English. Instead, verbs are marked for **past** and **non-past**, where \"non-past\" can refer to both present and future actions. The \"standard\" tense often depends on context, and the non-past form is quite versatile for expressing both current and future actions.\n\n**Summary**: In English, the **present tense** is the standard or default tense used for many general statements. However, other languages might default to a **past tense** (as in French or German for narratives), focus on **aspect** (as in Russian), or even lack tense distinctions entirely (as in Chinese). These differences reflect how cultures and languages structure their understanding of time and action.\n\n\n## what is aspect?\n\n**Aspect** is a grammatical category that describes the **temporal flow or nature of an action**, focusing on whether the action is completed, ongoing, habitual, repeated, or momentary. While **tense** tells us **when** an action occurs (past, present, future), **aspect** tells us more about **how** the action unfolds over time.\n\nThere are two main types of aspect in most languages:\n\n### 1. **Perfective vs. Imperfective Aspect**:\n   - **Perfective Aspect**: Describes an action as a **single, completed event** without focusing on its internal structure or progression. It presents an action as a whole, often with a clear beginning and end.\n     - Example: *She wrote a letter.* (the action is viewed as complete)\n   - **Imperfective Aspect**: Describes an action as **ongoing, habitual, or repeated**. It focuses on the process or continuity of the action, rather than seeing it as a finished event.\n     - Example: *She was writing a letter.* (the action is viewed as being in progress)\n     - Example: *She writes letters every day.* (habitual action)\n\n### 2. **Common Types of Aspect**:\n\n- **Progressive/Continuous Aspect**: Focuses on an action **in progress** at a particular time.\n  - Example: *I am eating.* (currently ongoing)\n  \n- **Habitual Aspect**: Refers to an action that occurs **regularly or habitually** over time.\n  - Example: *I eat breakfast at 7 a.m. every day.* (repeated over time)\n\n- **Perfect Aspect**: Expresses an action that is **completed** or that has relevance to a later time, often with consequences for the present.\n  - Example: *I have eaten.* (the action is complete, but it has present relevance, like feeling full now)\n\n### Examples Across Languages:\n\n- **English** uses a combination of **tense and aspect markers** to convey both time and nature of actions:\n  - **Present Continuous (Progressive Aspect)**: *I am reading* (action is ongoing now)\n  - **Present Perfect (Perfect Aspect)**: *I have read the book* (completed action with present relevance)\n\n- **Russian** and other Slavic languages** make a strong distinction between **perfective** and **imperfective** forms of verbs:\n  - Perfective verbs are used when focusing on the **completion** of an action: *Я написал письмо* (I wrote the letter — completed).\n  - Imperfective verbs focus on the **process or repetition**: *Я писал письмо* (I was writing the letter — ongoing or habitual).\n\n- **Mandarin Chinese** uses **aspect markers** rather than verb conjugation to indicate the nature of an action:\n  - The particle *了 (le)* indicates a **completed action**: *我吃了饭* (I have eaten).\n  - The particle *着 (zhe)* indicates an **ongoing state**: *他看着书* (He is reading a book — ongoing action).\n\n### Summary:\n- **Aspect** is about the **nature of an action in time**, focusing on its flow, completion, or repetition.\n- It works alongside **tense**, which indicates **when** an action happens.\n- Different aspects help describe whether an action is finished, ongoing, or habitual, providing a richer picture of the action in relation to time.\n\n## what is the term for past/present/future, given that tense varies from language to language. \n\nThe term you're looking for is **\"temporal reference\"** or simply **\"time reference\"**. This term is used to describe the **time frame** in which an action, event, or state occurs, without implying a specific grammatical mechanism like \"tense.\" Temporal reference helps capture the broader concept of **past, present, and future** as they apply across different languages and systems of expressing time.\n\n- **Temporal Reference**: Refers to the actual time context in which an event takes place—whether it is in the **past**, **present**, or **future**. Unlike tense, which is a grammatical feature, temporal reference is more about the conceptual timeline of the event.\n\nFor example:\n- In English, we use **tense** (e.g., past, present, future) to indicate temporal reference.\n- In other languages like **Mandarin Chinese**, temporal reference is often conveyed through context or temporal markers rather than changes in verb tense.\n\nUsing \"temporal reference\" makes it possible to discuss the timing of actions without assuming a specific grammatical form, accommodating the many different ways languages handle the expression of time.\n\n## what other features besides temporal reference and aspect are captured in tense\n\nBesides **temporal reference** and **aspect**, there are other features that are often expressed as part of a language's tense system or that interact with tense. These include:\n\n### 1. **Mood**:\n   - **Mood** conveys the speaker’s **attitude** toward the action or state described by the verb. This can include certainty, obligation, desire, or hypothetical situations.\n   - Common moods include:\n     - **Indicative**: Used to state facts or ask questions (e.g., *She is running*).\n     - **Subjunctive**: Used for wishes, doubts, or hypothetical situations (e.g., *If I were taller...*).\n     - **Imperative**: Used to give commands or make requests (e.g., *Run!*, *Please close the door*).\n\n### 2. **Voice**:\n   - **Voice** relates to the relationship between the **action** and the **subject** or **object** in a sentence.\n   - The main types of voice are:\n     - **Active Voice**: The subject performs the action (e.g., *She writes a letter*).\n     - **Passive Voice**: The subject receives the action (e.g., *A letter is written by her*).\n\n### 3. **Polarity**:\n   - **Polarity** indicates whether an action or state is **affirmed** (positive) or **negated** (negative).\n   - Positive polarity: *She is running*.\n   - Negative polarity: *She is not running*.\n\n### 4. **Evidentiality**:\n   - **Evidentiality** marks the **source of information** or **evidence** for a statement. It can indicate whether something is known through direct evidence, hearsay, inference, etc.\n   - In English, evidentiality is often expressed through phrases (e.g., *I heard that she is running*), but some languages like **Quechua** or **Turkish** have specific evidential markers in the verb system.\n\n### 5. **Person and Number**:\n   - **Person** indicates **who** is involved in the action (e.g., first person - *I run*, second person - *you run*, third person - *he/she/it runs*).\n   - **Number** expresses **whether** the action involves one person or more (singular vs. plural).\n   - Many languages, like Spanish, also inflect verbs to match the person and number of the subject.\n\n### 6. **Telicity**:\n   - **Telicity** indicates whether an action has a **defined endpoint** or **goal**.\n   - A **telic** action is one that naturally ends when its goal is achieved (e.g., *She wrote a book* implies completion).\n   - An **atelic** action does not have a natural endpoint and can continue indefinitely (e.g., *She ran* does not specify whether she finished running).\n\n### 7. **Iteration or Frequency**:\n   - Some verb systems include markers to express how **often** an action occurs.\n   - For example, a **frequentative** aspect or marker indicates repeated actions (e.g., in Finnish, adding specific suffixes can indicate habitual or repeated actions).\n\n### 8. **Modality** (closely related to mood):\n   - **Modality** is used to express **possibility, necessity, obligation, or ability**.\n   - Modal verbs in English (like *can*, *may*, *must*, *should*) help convey these meanings.\n\n### Summary:\nTense systems can incorporate many different features beyond just temporal reference and aspect, such as **mood**, **voice**, **polarity**, **evidentiality**, **person and number**, **telicity**, **iteration/frequency**, and **modality**. These features help provide a richer understanding of not just **when** an action takes place, but also the **nature** of the action, the **speaker's attitude**, and **how** the action relates to the participants.\n\n## could you call them relational categories?\n\n\"Relational categories\" might not be the most accurate term to describe features like **mood**, **voice**, **polarity**, and **evidentiality**. These features do not necessarily express relationships between entities, which is what the term \"relational\" typically implies. Instead, they modify the meaning of the verb by adding nuances about **how**, **why**, **who**, or **in what way** the action takes place, rather than defining relationships in a direct sense.\n\nFor example:\n\n- **Mood** conveys the speaker's attitude (e.g., factual, hypothetical).\n- **Voice** indicates whether the subject is acting or being acted upon.\n- **Polarity** expresses whether something is affirmed or negated.\n- **Evidentiality** relates to the source or type of evidence behind the statement.\n\nA more suitable term could be **\"verbal modality categories\"** or **\"verbal features\"**, as these terms capture the function of modifying the meaning or adding information to a verb in a general way.\n\n\"Relational\" is better suited for categories that express relationships explicitly, such as grammatical **case** (e.g., nominative, accusative) which shows the syntactic role of nouns in relation to verbs or other nouns.\n\n\n## OKay, so maybe \"relator-based ontologies\" might not be the best name for my approach to ontologies where instead of using predicates in the conventional way, predicates become classes, and expressions of those predicates are instances of the predicate classes.\n\nIn your case, \"relator-based\" might not quite capture the essence of the approach. Since your method involves treating **predicates as classes**, with **expressions of those predicates** as instances, it might be better to focus on terminology that reflects this shift from predicates as relations to predicates as **entities**.\n\nHere are some suggestions:\n\n1. **Predicate-Instance Ontologies**: This clearly describes that predicates are treated as **classes**, and their **instances** are specific relationships.\n\n2. **Relational Entity Ontologies**: Highlights the fact that the relationships themselves are treated as **entities** (or classes).\n\n3. **Predicate Reification Ontologies**: Since you are essentially reifying predicates—turning them into first-class objects or classes—this term reflects that approach well.\n\n4. **Meta-Predicate Ontologies**: Suggests that the predicates are elevated to a **meta** level, treated as classes.\n\n5. **Assertion-Centric Ontologies**: Since you're focusing on **assertions** as entities that can be instances, this emphasizes the expressive power of those assertions.\n\nThe term should ideally reflect the **shift of predicates from the role of relationships to concrete entities** and the **expressiveness** that comes with making statements about these instances.\n\n\n## I like \"predicate-instance\" better than something with \"verb\" because a verb has connotations of a single word. Remind me the difference between a predicate and a verb phrase?\n\nThe difference between a **predicate** and a **verb phrase** is in their roles within sentence structure:\n\n### **Predicate**:\n- The **predicate** is a grammatical term referring to the part of a sentence or clause that states **something about the subject**. It usually contains a **verb** and may also include objects, complements, and modifiers.\n- In simple terms, the predicate is **everything in the clause except the subject**.\n- Example: In the sentence \"*The cat is sleeping on the mat*\", the predicate is \"*is sleeping on the mat*\" because it describes what the subject (\"the cat\") is doing.\n\n### **Verb Phrase**:\n- A **verb phrase** is a part of the predicate that contains the **main verb** and any **auxiliary (helping) verbs**. It may also include modifiers or complements.\n- A verb phrase can be part of a larger predicate but doesn’t necessarily contain all the elements of the predicate.\n- Example: In \"*The cat is sleeping on the mat*\", the verb phrase is \"*is sleeping*\" because it includes the auxiliary verb \"is\" and the main verb \"sleeping\".\n\n### Summary of Differences:\n- **Predicate**: Everything that tells you something about the subject, often including the verb, objects, and other components.\n- **Verb Phrase**: The **main verb** and any auxiliary verbs within the predicate, which directly indicate the action or state.\n\nThe **predicate** is broader and contains all of the elements that provide information about the subject, while the **verb phrase** focuses specifically on the verb and related components.\n\n## for active vs passive voice, is \"the boat flipped\" active and \"the boat was flipped\" passive? It seems a subtle distinction\n\nYes, there's a subtle but important distinction between **\"the boat flipped\"** and **\"the boat was flipped\"** that relates to **voice**:\n\n### 1. **Active Voice: \"The boat flipped\"**:\n- This is **active voice**, even though it might not seem obvious because the **boat** is the subject and the action appears to have happened to it. In this context, the verb \"**flipped**\" is **intransitive** (meaning it doesn’t take a direct object), and it suggests that the action happened **on its own** or without explicitly stating an external agent. \n- There is no direct implication of someone or something causing the boat to flip. It just flipped.\n\n### 2. **Passive Voice: \"The boat was flipped\"**:\n- This is **passive voice**. The verb **\"was flipped\"** is a combination of a form of \"**to be**\" (in this case, \"was\") and the past participle \"**flipped**.\"\n- It implies that the boat was **acted upon by an external agent**, even if that agent isn’t explicitly mentioned. For instance, \"*The boat was flipped* (by a wave).\" \n- The passive voice emphasizes the action being done to the **subject** rather than focusing on what caused it.\n\n### Summary:\n- **\"The boat flipped\"** is **active** and focuses on the action happening to the boat on its own.\n- **\"The boat was flipped\"** is **passive** and suggests that something **acted upon** the boat.\n\nThe distinction lies in whether the subject **performs** the action (active) or **receives** the action from an external source (passive).\n\n\n## Is there any prior art or research papers around using RDF to represent knowledge/statements in a \"predicate-instance\" kind of way?\n\nThere is some prior art and related research in using **RDF** to represent knowledge/statements in a way that resembles the **\"predicate-instance\"** approach you're describing, often in the context of **reification**, **named graphs**, or **n-ary relations**. Here are some approaches that are somewhat similar and might be of interest to you:\n\n### 1. **RDF Reification**:\n   - **Reification** in RDF is a method of making statements **about statements**. It involves representing a triple (subject-predicate-object) as a **first-class entity** (essentially turning it into a resource), so you can add metadata or make assertions about it. \n   - Example: Reifying a statement like *\"Alice knows Bob\"* involves creating a new resource that represents this statement, and then you can add properties like *\"source\"* or *\"confidence\"* to this resource.\n   - This approach aligns somewhat with treating a **predicate-instance** as a **class** where the **statement** is treated as an instance.\n   - A significant limitation is that RDF reification is often cumbersome and requires many triples to represent a single statement, which can make the data model harder to work with.\n\n### 2. **N-ary Relations in RDF**:\n   - The **n-ary relation** pattern is used to represent relationships involving more than two entities or to provide additional context about a relationship (e.g., time, value, or other qualifiers).\n   - Instead of a simple predicate linking two entities, an **intermediate resource** is introduced that acts as the instance of the relationship, and attributes of this instance represent the additional context.\n   - This intermediate resource can be treated similarly to an **instance of a predicate**, adding more flexibility to model complex relationships.\n   - For example, to represent *\"Alice gave Bob a book on June 1st\"*, you can create an intermediate node representing the \"giving\" event and relate it to Alice, Bob, the book, and the date.\n\n### 3. **Named Graphs**:\n   - **Named graphs** allow you to group sets of RDF triples together and make statements about them as a whole (e.g., context, source, or provenance). In a sense, the named graph represents a **higher-level entity** that can be treated like an instance of a particular relationship or collection of statements.\n   - While not directly creating instances of predicates, named graphs can provide a mechanism for **grouping statements** and treating the entire collection as an entity for further description, which aligns with a \"predicate-instance\" type of approach for contextual information.\n\n### 4. **Singleton Property Pattern**:\n   - The **[[singleton property|t.cs.semantic-web.singleton-property]] pattern** is another approach that deals with adding metadata to a statement by creating a **unique property** for each instance of a triple.\n   - Instead of using a generic predicate, a **unique predicate** is created as a subclass or specialization of the original predicate, allowing you to make specific statements about that individual property.\n   - This can be thought of as treating each occurrence of a predicate in a particular statement as a **distinct instance** of that predicate.\n\n### 5. **Metamodeling with OWL**:\n   - **OWL Full** allows **classes to be instances** of other classes, which might align with your approach of having predicates as classes and specific statements as instances.\n   - In OWL, you can use a **metamodeling approach** to create **meta-classes** that represent predicates, and then create instances of these meta-classes to represent individual relationships or assertions. This offers a more flexible way to structure RDF graphs beyond simple triple patterns.\n\n### Relevant Research and Considerations:\n1. **Gruber, T. R. (1993). Toward Principles for the Design of Ontologies Used for Knowledge Sharing.** This paper laid the foundations for thinking about ontologies as modular representations of knowledge, which aligns with your approach of breaking down and treating predicates in a more instance-centric way.\n2. **Singleton Property Papers**: Research papers on the singleton property pattern discuss creating unique properties for each instance of a relationship and can provide a foundation for exploring predicate-instance approaches.\n3. **\"Named Graphs, Provenance, and Trust\" (Carroll et al., \n\n## i don't think traditional reification works because I want to represent the meaning, not the form, and so \"subject\" and \"object\" become arbitrary.\n\nGiven your goal to focus on **the meaning rather than the form** of statements, making the distinction between \"subject\" and \"object\" arbitrary, traditional reification indeed falls short, as it retains the structural components of RDF triples.\n\nInstead of traditional reification, here are some alternative approaches that could better align with your \"predicate-instance\" idea:\n\n### 1. **n-ary Relationships**\nRDF is generally built around **binary relations** (subject-predicate-object), but to represent more complex relationships—where the subject-object distinction is arbitrary or you need more expressive power—you could use **n-ary relationships**. In an n-ary approach, instead of treating relationships as simple binary links, you represent the whole relationship itself as an entity. For example, a relationship could be expressed as:\n\n```plaintext\n_:relationship rdf:type ex:PredicateClass .\n_:relationship ex:involves ex:Entity1 .\n_:relationship ex:involves ex:Entity2 .\n```\nHere, the relationship is treated as an instance of a class (`ex:PredicateClass`), and both entities involved are simply linked without strictly defining a subject or object role. This way, the meaning of the relationship is emphasized over its structure.\n\n### 2. **Higher-Order Logic and OWL Metamodeling**\nUsing **OWL metamodeling** techniques could be beneficial. In OWL, you can define classes for predicates and then have specific relationships as instances of those classes, thus abstracting away the rigid subject-object form. This is akin to treating relationships as **conceptual entities**, which can then be used to make further statements about the nature of these relationships.\n\nFor instance, if you want to represent a predicate as a class and have individual expressions of this predicate as instances:\n- Define a class like `ex:Friendship`.\n- Individual instances like `_:friendship1` or `_:friendship2` could represent specific expressions of that friendship, involving various entities (`ex:Person1` and `ex:Person2`), with different attributes or metadata about those instances.\n\n### 3. **Graph Databases and Property Graph Models**\nTraditional RDF might not provide enough flexibility for what you are trying to achieve, but some **graph databases** support **property graph models**, which allow edges (relationships) to have properties. This means you can attach more semantic meaning directly to relationships, treating them more as **first-class entities** that can be queried and manipulated with greater flexibility compared to RDF triples.\n\nFor example:\n- **Neo4j** is a popular graph database that uses the **property graph model**, allowing relationships to carry properties. Instead of a subject-predicate-object structure, you could define edges with rich, descriptive properties, better capturing the intended semantics without the constraints of RDF's binary nature.\n\n### 4. **RDF-Star and Embedded Triples**\n**RDF-Star** is an extension of RDF that allows **embedded triples**, giving more flexibility in representing relationships. Instead of reifying statements explicitly, RDF-Star lets you make statements about other triples directly within the triple notation. This could be used to describe predicate instances in a way that captures more meaning while minimizing the subject-object distinction.\n\nFor example:\n```plaintext\n<<ex:Entity1 ex:predicate ex:Entity2>> rdf:type ex:PredicateInstance .\n```\nThis lets you treat the triple itself as a **referential object** and make further statements about it, which could align more with your goal of capturing meaning.\n\n### Summary\nYour \"predicate-instance\" approach could be better realized using techniques that:\n- Treat relationships as **entities** (n-ary relationships or metamodeling).\n- Abstract away from the subject-object structure using **higher-order modeling**.\n- Use graph models like **property graphs** or **RDF-Star** to add more semantic meaning directly to relationships.\n\nThese approaches provide more flexibility and can help represent meaning in a way that isn’t bound to the rigid structure of traditional RDF triples.\n\n## property graph databases generally don't support resource-orientied properties on edges, i.e., only literals.\n\nGiven your need to support **resource-oriented properties on edges**, it's true that most property graph databases fall short, as they typically allow **only literal values** on relationship properties. However, there are some alternative modeling strategies and database technologies that might better meet your requirements:\n\n### Alternative Approaches to Representing Rich Relationships:\n\n1. **Hypergraph Models**:\n   - **Hypergraphs** extend the concept of traditional graphs by allowing edges (often called \"hyperedges\") to connect multiple nodes, and these hyperedges themselves can be treated as first-class entities. This provides greater flexibility for representing complex relationships involving multiple resources.\n   - Some graph databases, such as **HyperGraphDB**, are designed around the hypergraph concept, which might better accommodate resource-oriented properties for your use case.\n\n2. **Multi-Edge Support in RDF Databases**:\n   - Some RDF databases support **multi-edge** relationships and can add resource-oriented metadata to relationships through additional triples or through **reification** that uses custom classes to represent relationships. While reification might not be your preferred option, RDF databases like **Blazegraph** or **Stardog** offer richer modeling capabilities that go beyond basic property graphs.\n\n3. **TinkerPop with Gremlin**:\n   - **Apache TinkerPop** with **Gremlin** supports a more flexible way to define graph data. Although it still primarily focuses on property graphs, it allows complex traversal patterns that can effectively treat vertices (nodes) as holders of metadata for relationships. This can sometimes simulate richer semantics, though it won't inherently change the underlying restriction on edge properties.\n\n4. **Graph-Relational Hybrid Approaches**:\n   - A **hybrid approach** combining graph and relational databases might be useful. In this model, graph edges are modeled as separate entities in a relational table, allowing each edge to have resource-oriented properties. For example, **ArangoDB** supports both document and graph data models, potentially enabling more complex relationships to be represented.\n\n5. **Custom Modeling in RDF-Star**:\n   - **RDF-Star** (or **Triple-Star**) allows embedding RDF triples directly in other triples, giving more direct support for representing relationships that are richer than traditional edges. Using RDF-Star could be a way to model edges with resource-oriented properties without explicitly reifying the triple.\n   - Example:\n     ```\n     <<ex:Node1 ex:relatesTo ex:Node2>> ex:hasProperty ex:Node3 .\n     ```\n     This effectively treats the embedded triple as a **referential object** to which properties can be attached.\n\n### Limitations and Considerations:\n\n- **Query Complexity**: Adding **resource-oriented metadata** to edges, particularly through approaches like RDF reification or RDF-Star, can introduce **query complexity**. You may need more sophisticated query handling to work with these enriched relationships efficiently.\n\n- **Storage and Scalability**: Creating instances of relationships (predicate-instances) and modeling them as entities may lead to increased storage needs, depending on the granularity of your model and the scale of your data.\n\n### Conclusion:\nGiven the constraints of property graph models (supporting only literal properties on edges), your approach would benefit from looking into **RDF-based models like RDF-Star** or **graph-relational hybrids**, which offer more flexibility in treating relationships as first-class entities. Alternatively, exploring **hypergraph** databases may offer a more natural fit for modeling resource-oriented properties on relationships. Each of these approaches offers a different balance of **flexibility**, **complexity**, and **scalability** depending on your specific needs for managing and querying relationships in your ontology.\n\n\n## hypergraphdb is long dead, but maybe typedb could work. Any other hypergraph databases?\n\nTypeDB (formerly **Grakn**) is indeed a promising candidate for what you're aiming to achieve, as it offers **type-based** modeling with **hyper-relational capabilities**, allowing relationships to be treated as entities that can have attributes. Besides TypeDB, there are a few other databases and tools that support **hypergraph** or **hyper-relational** modeling, which might fit your needs:\n\n### Other Hypergraph and Hyper-Relational Databases:\n\n1. **Neo4j with Relationship Nodes**:\n   - Although **Neo4j** isn't a true hypergraph database, you can represent hypergraph-like relationships by creating **relationship nodes** explicitly. This approach makes relationships first-class citizens by modeling them as nodes, which can have their own relationships and properties, providing a similar effect to a hypergraph.\n\n2. **TigerGraph**:\n   - **TigerGraph** is a high-performance graph database that supports **multi-edge** relationships and **complex traversals**. While it primarily uses the property graph model, it allows extensive schema customization, which could be used to simulate hypergraph structures.\n\n3. **ArangoDB**:\n   - **ArangoDB** is a multi-model database that supports **graphs**, **documents**, and **key-value pairs**. By using its graph features, you can model hyperedges explicitly by creating collections of edges, each of which can be treated as a document with properties. This can provide the flexibility to add resource-oriented properties to edges.\n\n4. **Neo4j Hypergraph Extension**:\n   - There are some **extensions and plugins** for Neo4j that provide **hypergraph functionality**. These aren't official core features of Neo4j but can be helpful for exploring hypergraph-like modeling using Neo4j's underlying architecture.\n\n5. **JanusGraph**:\n   - **JanusGraph** is a distributed graph database that builds on top of existing technologies like **Apache Cassandra**, **HBase**, and **BerkeleyDB**. Although not a hypergraph database by default, it allows you to model rich relationships using property keys and multi-edge structures, which can approximate hypergraphs when implemented correctly.\n\n6. **TerminusDB**:\n   - **TerminusDB** is a knowledge graph and document-oriented database that supports **version control** and allows for **schema-rich, hyper-relational data modeling**. Its capability to handle complex relationships and its RDF-like approach might align well with your requirement for resource-oriented properties on edges.\n\n7. **Knowledge Graph-based Alternatives**:\n   - **Stardog** and **Blazegraph** are both RDF-based databases that can provide more flexibility in modeling complex relationships by representing them as first-class resources, with extensive support for OWL and advanced RDF features. These might be suitable if RDF extensions like **RDF-Star** or **n-ary modeling** could be adapted to your use case.\n\n### Summary\nWhile **HyperGraphDB** is no longer maintained, databases like **TypeDB**, **ArangoDB**, and extensions to **Neo4j** can help implement hypergraph-like functionality, where relationships are treated as fully modeled entities. If hypergraph support is crucial, **TypeDB** remains a strong candidate due to its emphasis on **hyper-relational modeling** and **semantic querying**.\n\nAnother option is to simulate hypergraph capabilities in databases that provide **rich schema modeling** for relationships, such as **ArangoDB** or **Neo4j** (using relationship nodes). If you lean toward more knowledge-graph-oriented approaches, **Stardog** or **Blazegraph** might also fit well, especially when paired with RDF's extended capabilities.\n\n## Can you give an example of how tinkerpop can treat vertices (nodes) as holders of metadata for relationships. \n\nIn **Apache TinkerPop**, you can model complex relationships by using **vertices (nodes) to represent metadata** about relationships, essentially making nodes act as relationship entities. This approach allows you to move beyond the typical edge representation, adding more context and richness to relationships.\n\nHere's how you can do this using **TinkerPop's Gremlin traversal language**:\n\n### Example Scenario: Representing Friendship Metadata\n\nSuppose you want to represent a **friendship** between two people, and you want to capture additional metadata about this friendship—like when it started and who initiated it.\n\nInstead of using a simple edge (e.g., `Person A -> \"is_friend_of\" -> Person B`), you can create a **friendship node** that acts as a holder of metadata for the relationship between two people.\n\n#### Step-by-Step Modeling:\n\n1. **Create Vertices for Persons**:\n   ```gremlin\n   // Create Person A and Person B\n   g.addV('Person').property('name', 'Alice').as('a').\n     addV('Person').property('name', 'Bob').as('b').\n     iterate()\n   ```\n\n2. **Create a Friendship Vertex**:\n   ```gremlin\n   // Create a vertex to represent the friendship relationship with metadata\n   g.addV('Friendship').property('startDate', '2023-01-15').property('initiator', 'Alice').as('f').\n     iterate()\n   ```\n\n3. **Connect Persons to the Friendship Vertex**:\n   ```gremlin\n   // Create edges between the persons and the friendship vertex\n   g.V().has('name', 'Alice').as('a').\n     V().has('name', 'Bob').as('b').\n     V().hasLabel('Friendship').as('f').\n     addE('friend_with').from('a').to('f').\n     addE('friend_with').from('b').to('f').\n     iterate()\n   ```\n\n#### Explanation:\n\n- **Friendship Vertex** (`f`): Represents the **relationship** itself and holds metadata about that relationship. In this case, the vertex has properties like `startDate` and `initiator`.\n  \n- **Edges (`friend_with`)**: Connect **Person A** and **Person B** to the **Friendship** vertex, creating a structure that indicates both people are part of the relationship while allowing you to treat the relationship itself as an entity with **attributes**.\n\n#### Benefits:\n\n- This allows you to **query the relationship** as an entity, add new metadata, or even link this relationship to other entities.\n- For example, if the friendship evolves into a **business partnership**, you could create additional edges from the **Friendship vertex** to another **Business Partnership** vertex, reflecting real-world complexity without altering the original person nodes.\n\n### Query Example:\n\nTo query the metadata of the friendship between **Alice** and **Bob**, you could write:\n\n```gremlin\n// Find the friendship between Alice and Bob and get its metadata\ng.V().has('Person', 'name', 'Alice').out('friend_with').\n  hasLabel('Friendship').as('f').\n  in('friend_with').has('name', 'Bob').\n  select('f').valueMap()\n```\n\nThis query retrieves the **friendship vertex** that connects **Alice** and **Bob** and fetches all its properties, allowing you to easily access metadata like `startDate` or `initiator`.\n\n### Summary:\n\nUsing **TinkerPop**, you can treat relationships as first-class entities by representing them with vertices. This approach allows you to add **rich metadata** to relationships, which is especially useful when modeling complex or evolving connections. The flexibility of using vertices to represent relationships, along with edges to link these vertices to their participants, enables richer semantic modeling compared to simple property graph edges.\n\n\n## You said \"in OWL, you can use a metamodeling approach to create meta-classes that represent predicates, and then create instances of these meta-classes to represent individual relationships or assertions.\" But are these really meta-classes? or just classes?\n\nYou're correct to question the terminology—whether these should be called **meta-classes** or just **classes** depends on the context in which they're used in OWL and the intent behind their creation.\n\n### Clarification: Meta-Classes vs. Classes in OWL\n\nIn OWL, the term **meta-class** refers to a **class whose instances are themselves classes**. When modeling something at a higher level of abstraction, where you want classes to describe other classes (essentially creating a class of classes), you enter the territory of meta-modeling.\n\nIn the scenario where you want to represent **predicates** as **classes** and then instantiate these classes to represent specific relationships or assertions, you're not necessarily dealing with meta-classes. Rather, you're using **ordinary OWL classes** to represent a level of abstraction for predicates, which then have **instances** that represent the individual assertions of those predicates.\n\nHere's a breakdown:\n\n- **Classes Representing Predicates**: In your model, each predicate becomes a class. For instance, if you have a predicate like \"knows,\" you would create a class called `Knows`.\n- **Instances Representing Assertions**: You then create instances of this class (`Knows`) to represent specific assertions (e.g., \"Alice knows Bob\").\n\nThese **predicate classes** are not inherently meta-classes, as they are not intended to classify other classes. Instead, they are used to categorize **instances** that represent relationships. Therefore, they are better understood simply as **ordinary classes**, albeit with a specific role in representing relationships instead of more conventional entity types.\n\n### Example in OWL:\n\n1. **Define a Class for the Predicate**:\n   ```turtle\n   :Knows rdf:type owl:Class .\n   ```\n\n2. **Create Instances of the Predicate Class to Represent Assertions**:\n   ```turtle\n   :knowsAliceBob rdf:type :Knows ;\n                  :subject :Alice ;\n                  :object :Bob .\n   ```\n\nIn this example:\n- `:Knows` is a **class** representing the concept of the \"knows\" relationship.\n- `:knowsAliceBob` is an **instance** of the class `:Knows`, representing the specific relationship between Alice and Bob.\n\nSince `:Knows` is simply categorizing instances (`:knowsAliceBob`), it functions as a **standard OWL class**. A **meta-class**, by contrast, would be a class whose instances are themselves other OWL classes.\n\n### Conclusion\n\nIn your \"predicate-instance\" approach, the **classes representing predicates** are better described as **ordinary classes** rather than meta-classes because they do not categorize other classes but instead **categorize instances** that represent specific relationships. This is an important distinction, as true meta-classes in OWL involve a different modeling purpose, typically to enable reasoning or organization of **classes themselves** as instances.\n\n## You mentioned OWL Full could be helpful with its allowing**classes to be instances**. I think we agree that the predicates are not metaclasses. But do you still see any benefits to using OWL Full for the \"predicate-instance\" approach?\n\nYes, **OWL Full** can still provide significant benefits for your \"predicate-instance\" approach, even if we agree that the predicates themselves are not meta-classes. The key advantages of using **OWL Full** in this context include its ability to be **less restrictive** and its support for treating entities as both **classes and instances**. Here are some specific ways in which OWL Full could be beneficial:\n\n### 1. **Class-Instance Flexibility**:\n   - In **OWL Full**, an entity can simultaneously be a **class** and an **instance**. This is highly beneficial for the \"predicate-instance\" approach because:\n     - **Predicates as Classes**: In your model, each predicate (like `ex:Knows`) can be treated as a **class** that groups all assertions of that predicate.\n     - **Predicate Instances**: Specific relationships (`ex:knowsAliceBob`) can be instances of that class, representing the individual occurrences of these relationships.\n   - OWL DL is more restrictive in this regard, as it requires a clear separation between classes, individuals, and properties, which could make it cumbersome for the flexible modeling you intend.\n\n### 2. **Expressive Power**:\n   - **OWL Full** provides greater **expressiveness** compared to **OWL DL**. It allows more complex constructs, such as treating properties themselves as instances, which can be beneficial when dealing with **predicate instances**.\n   - You could, for example, express that a certain predicate class (`ex:Knows`) has additional metadata or relationships without the strict limitations imposed by OWL DL. This added expressiveness helps in capturing **richer semantics** about the predicates, their instances, and how they interrelate.\n\n### 3. **Reification Alternative**:\n   - Traditional RDF **reification** is quite cumbersome, requiring four triples per statement to reify a relationship. In **OWL Full**, the ability to treat predicates as classes and create instances for specific relationships can offer a more natural and **compact way** of representing relationship instances while still enabling you to attach rich metadata.\n   - This avoids the reification structure that involves breaking a statement into multiple components (`rdf:subject`, `rdf:predicate`, `rdf:object`), which may not align well with your goal of focusing on the **meaning rather than the form** of statements.\n\n### 4. **Property Characteristics**:\n   - **OWL Full** allows properties to have characteristics such as **transitivity**, **symmetry**, and **inverse** relationships, even when these properties themselves are treated as classes or instances.\n   - For example, you could define a class `ex:Collaboration` and indicate that instances of this class have an **inverse relationship** with another class, like `ex:Supervision`. This enables a more nuanced representation of relationships and helps encode the logic of how these relationships interact without the constraints of typical property definitions.\n\n### 5. **Inference and Reasoning**:\n   - With OWL Full, you can leverage **inference capabilities** to derive new knowledge from existing relationships, thanks to the more relaxed class-instance modeling. If a predicate is modeled as a class with specific instances, reasoning can be used to infer new relationships between instances or to validate the logical consistency of how predicates are applied.\n   - For example, if `ex:Knows` is a class and instances of `ex:Knows` have properties that indicate a level of familiarity (`ex:acquaintance` or `ex:closeFriend`), an OWL Full reasoner can help infer additional facts about the relationships between entities based on the properties of those instances.\n\n### 6. **Handling Complex Relationships**:\n   - In your \"predicate-instance\" approach, predicates may themselves have **subclass relationships**, allowing for a hierarchy of predicates. In OWL Full, you can model a predicate class (`ex:Relationship`) with specific subclasses (`ex:Friendship`, `ex:BusinessPartnership`), and instantiate those subclasses with individual relationships (e.g., `ex:friendshipAliceBob`). This **hierarchical modeling** provides a richer framework for categorizing and reasoning about relationships compared to property graphs or RDF alone.\n\n### Summary:\n- **OWL Full** allows you to use **classes as instances**, providing the necessary flexibility for treating predicates as classes and individual relationships as instances.\n- It enables **richer expressiveness**, which helps model complex relationships and their interactions without the limitations of **OWL DL** or standard **RDF**.\n- It supports using **inference and reasoning** to derive additional information, providing added value over simple property graphs.\n- **Hierarchical modeling** of predicates and their instances can be effectively implemented, supporting nuanced ontological structures.\n\nWhile **OWL Full** comes with trade-offs like reduced computational efficiency for reasoning compared to **OWL DL**, it offers the flexibility and expressiveness required for implementing a **predicate-instance** approach effectively, especially when dealing with complex relationships and the need to attach additional semantics to these relationships.\n\n## I don't think #1 makes sense. Expressivity could be useful. For #3, I don't think my approach is much more compact, it still requires one statement to set up the predicate, and  would need a statement each for subject and object. So maybe saves a statement. For #4, can you really express transitivity, symmetry, etc. in the traditional way between classes? I mean, I guess OWL full allows you too, but reasoners probably wouldn't support that. #5 Inferencing, I think it mostly requires OWL DL. #6 I totally agree with.\n\n\nThanks for clarifying your thoughts. Based on your feedback, let's refine the evaluation of OWL Full for the \"predicate-instance\" approach:\n\n### Revised Evaluation:\n\n1. **Class-Instance Flexibility** (Initial Point Removed)\n   - Since you are not treating predicates as meta-classes, this point about flexibility was unnecessary. Instead, we can focus on **expressivity** as the key benefit, which you highlighted.\n\n2. **Expressive Power**\n   - **OWL Full** allows richer and more complex modeling than **OWL DL**, which could be useful for representing nuanced relationships and treating predicates as first-class entities. This flexibility can help in situations where relationships evolve or have multiple layers of meaning. This expressivity could make OWL Full a suitable choice for implementing a \"predicate-instance\" approach in a more **semantic and nuanced manner**, though it might come at the cost of **reduced computational efficiency** for inferencing.\n\n3. **Reification Alternative** (Modified)\n   - You’re correct that your approach might not be much more compact than traditional **RDF reification**—you still need a statement to set up the predicate and additional statements for each of the subject and object. While it could save one statement compared to standard reification, this is not necessarily the main advantage. Instead, the benefit might lie in the more **natural conceptualization** of predicates as entities and their instances, making the data model more intuitive for representing complex relationships.\n\n4. **Property Characteristics (Transitivity, Symmetry, etc.)** (Clarified)\n   - You raised a valid point about the feasibility of representing properties like **transitivity** and **symmetry** between classes. While **OWL Full** allows this level of expressiveness, it's true that most **reasoners** do not support inferencing on such characteristics between classes in OWL Full. Therefore, while it’s possible to model transitivity and symmetry at the class level in OWL Full, practical **reasoning support** might be limited. If automated inferencing is a requirement, then **OWL DL** is generally more suitable, albeit more restrictive in its expressiveness.\n\n5. **Inference and Reasoning** (Refined)\n   - **Inferencing** in OWL Full is theoretically possible, but as you mentioned, it is often **unsupported by practical reasoners**. Most reasoners are built with **OWL DL** in mind, given the tractable nature of reasoning in this subset of OWL. If **automated reasoning** is a core requirement of your model, OWL DL may be necessary, even though it would impose limitations on modeling flexibility compared to OWL Full.\n\n6. **Hierarchical Modeling of Relationships (Confirmed)**\n   - You agree that **OWL Full** provides an advantage for **hierarchical modeling** of predicates. In your \"predicate-instance\" approach, representing **predicates as classes** and building **subclass relationships** (e.g., different types of relationships like `Friendship`, `Collaboration`) provides a powerful framework for reasoning about different levels of abstraction. OWL Full allows you to freely model these classes and create instances for specific assertions, aligning with your intention to treat predicates as rich conceptual entities.\n\n### Summary of Changes:\n- **Expressivity** in OWL Full remains a key potential benefit for allowing nuanced and flexible representations of relationships, despite the limitations in reasoning support.\n- The compactness benefit over **RDF reification** is minimal; instead, the benefit lies more in the **conceptual clarity** of representing predicates as entities.\n- Representing **property characteristics like transitivity and symmetry** between classes is allowed in OWL Full, but practical support from reasoners is typically lacking.\n- For **inference** needs, **OWL DL** would be the more appropriate choice, as most reasoners support it effectively, though at the cost of reduced modeling flexibility.\n\nOWL Full provides a powerful and expressive framework, but practical limitations in terms of **reasoner support** need to be carefully considered based on your specific requirements for reasoning and modeling flexibility.\n\n\n## Maybe there's a better name than \"predicate-instance approach\". Like \"predicate-first\" or \"predicentric\" or ???\n\nHere are some alternative names that might better capture your approach to ontologies where predicates are central, represented as classes, and relationships as instances:\n\n1. **Predicate-Centric Modeling**: Emphasizes that **predicates** are at the core of your model, highlighting their central role. This name suggests that your model revolves around predicates as primary entities.\n\n2. **Predicate-First Approach**: Similar to \"predicate-centric,\" this highlights that **predicates** are prioritized first, making it clear that the model starts with defining and focusing on predicates.\n\n3. **Predicentric Ontology**: A creative play on \"centric\" and \"predicate,\" this term sounds cohesive and implies that predicates are the fundamental unit of organization.\n\n4. **Relational Entity Ontology**: Since your approach makes each predicate a **distinct entity** (or class) with instances, this name emphasizes that **relationships themselves are entities**.\n\n5. **Relator-Based Approach**: Though you've noted that \"relator-based\" might not fully capture your concept, the term could still be relevant, especially if the **relationships are central** to your model and the focus is on their instantiation as real entities.\n\n6. **Predicate Reification**: If you want to emphasize that your approach is related to giving **substance** to predicates, even if it's not traditional reification, this could be a fitting term.\n\n7. **Hyper-Relational Modeling**: Suggests a richer modeling of relationships that goes beyond simple predicates, treating them as **full-fledged entities**.\n\n8. **Predicate Realization**: Suggests the act of making predicates **explicit and concrete** by realizing them as distinct classes and instances.\n\nEach of these names provides a different nuance, focusing on either the centrality of predicates, their entity-like nature, or the unique modeling structure you're using. \"Predicate-Centric\" or \"Predicate-First\" might be especially clear and direct for your purpose.","n":0.012}}},{"i":1688,"$":{"0":{"v":"09","n":1}}},{"i":1689,"$":{"0":{"v":"22","n":1}}},{"i":1690,"$":{"0":{"v":"Iri Referent to Solve Httprange 1","n":0.408},"1":{"v":"\n- chatbot: claude\n\n## I think using the meta tag could be good just to assert \"the URI(s) that correspond to this document are intended to refer to something other than this document\". You could then optionally use the `link` tag to specify what is being referred to\n\nYou've made an excellent point. Using the `<meta>` tag to make a general assertion about the document's URI(s), and then optionally using `<link>` for specifics, is a smart and flexible approach. Let's explore how this could work:\n\n1. Using `<meta>` for the general assertion:\n\n```html\n<meta name=\"uri-reference\" content=\"external\">\n```\n\nThis succinctly states that the URI(s) associated with this document are intended to refer to something other than the document itself. It's a clear, document-level declaration addressing the httprange-14 issue.\n\n2. Optionally using `<link>` for specifics:\n\n```html\n<link rel=\"describes\" href=\"http://example.com/time\" title=\"The concept of time in physics\">\n```\n\nThis approach has several advantages:\n\n1. Clarity: The `<meta>` tag provides a clear, document-wide assertion about the nature of the document's URI(s).\n\n2. Flexibility: It allows for cases where you might not want or need to specify exactly what is being described.\n\n3. Extensibility: You can easily add multiple `<link>` elements if the document describes multiple external concepts or resources.\n\n4. Separation of Concerns: It separates the general assertion (via `<meta>`) from the specific descriptions (via `<link>`).\n\n5. Compatibility: This approach uses standard HTML elements and attributes, making it widely compatible.\n\nHere's a full example of how this might look in practice:\n\n```html\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"uri-reference\" content=\"external\">\n    <title>Document Describing Time in Physics</title>\n    <link rel=\"describes\" href=\"http://example.com/time\" title=\"The concept of time in physics\">\n    <link rel=\"describes\" href=\"http://example.com/relativity\" title=\"Theory of Relativity\">\n</head>\n```\n\nIn this example, the `<meta>` tag asserts that the document's URI refers to something external, while the `<link>` tags provide specific information about what's being described.\n\nThis approach elegantly solves the problem you initially presented. It addresses the httprange-14 issue at a document level, while still allowing for the specification of particular resources or concepts being described. It's a solution that balances simplicity, clarity, and flexibility, and could be easily adopted and understood by both humans and machines parsing the document.\n\n\n## ok, but let's use IRI instead of URI. What do you think of \"iri-referent\"\n\nYour suggestion to use \"IRI\" (Internationalized Resource Identifier) instead of \"URI\" (Uniform Resource Identifier) is astute and forward-thinking. IRIs are indeed a more modern and inclusive standard, supporting a wider range of Unicode characters. As for the term \"iri-referent\", it's an excellent choice. Let's break this down:\n\n\n\n1. \"iri\" instead of \"uri\":\n   This change acknowledges the broader scope of IRIs, which can include characters from the Universal Character Set (Unicode/ISO 10646), unlike URIs which are limited to ASCII characters. This is particularly important for internationalization.\n\n2. \"referent\" instead of \"reference\":\n   \"Referent\" is a more precise term in this context. In linguistics and philosophy, a referent is the thing in the world that a word or phrase denotes or stands for. By using \"referent\", we're clearly indicating that we're talking about what the IRI is pointing to or standing for, not just the act of referring.\n\nSo, putting this together, a `<meta>` tag using \"iri-referent\" could look like this:\n\n```html\n<meta name=\"iri-referent\" content=\"external\">\n```\n\nThis `<meta>` tag succinctly and accurately conveys that:\n1. We're dealing with IRIs (which includes URIs but is more comprehensive)\n2. The IRI associated with this document is intended to refer to something other than the document itself\n3. The thing being referred to (the referent) is external to the document\n\nThis approach has several advantages:\n- It's more internationally inclusive due to the use of IRI\n- It's more semantically precise with the use of \"referent\"\n- It maintains the simplicity and clarity of your original idea\n- It addresses the httprange-14 issue in a standards-compliant way\n\nYou could then still use the `<link>` tag for more specific descriptions if needed:\n\n```html\n<meta name=\"iri-referent\" content=\"external\">\n<link rel=\"describes\" href=\"http://example.com/时间\" title=\"The concept of time in physics\">\n```\n\nThis combination allows for a clear general statement about the document's IRI (using the `<meta>` tag) and specific details about what's being described (using the `<link>` tag), all while being internationalization-friendly.\n\nYour suggestion of \"iri-referent\" is a thoughtful and precise solution to the problem. It effectively addresses the httprange-14 issue while also considering modern web standards and international usage. Well done!","n":0.039}}},{"i":1691,"$":{"0":{"v":"06","n":1}}},{"i":1692,"$":{"0":{"v":"Types Vs Classes","n":0.577}}},{"i":1693,"$":{"0":{"v":"05","n":1}}},{"i":1694,"$":{"0":{"v":"Type Hierarchy Vs Meta Hierarchy","n":0.447},"1":{"v":"\n- interlocutor: [[user.chatgpt.4o]]\n\n## do you remember the multi-level modeling session where you provided me an example with \"the HR department of Company X\"?\n\nYes, I remember the multi-level modeling session. The example I provided involved the **HR Department of Company X** to illustrate how different levels in a multi-level model can be represented:\n\n- **M0 Level (Instance Level)**: This is where the specific, real-world instance resides, such as the **HR Department of Company X**.\n- **M1 Level (Class/Type Level)**: At this level, you would define the **HR Department class**, which generalizes the concept of HR departments that can be instantiated by companies.\n- **M2 Level (Meta-Class Level)**: This level could define **OrganizationalUnitType**, a more abstract class that generalizes types of organizational units, such as HR departments, finance departments, etc.\n- **M3 Level (Meta-Meta-Class Level)**: At this top level, you would deal with **Types** in a very general sense, abstracting further from specific organizational units.\n\nThe idea is to distinguish the different levels, where each level progressively abstracts away from specific instances toward more general, reusable concepts.\n\n## with the multi-level example, could m2 be a \"Department class\", m3 a OrganizationUnitType Class, and m4 just Types? \n\nYes, your proposed multi-level example with **M2 as a \"Department class\"**, **M3 as an \"OrganizationUnitType Class\"**, and **M4 as \"Types\"** makes sense and aligns with the principles of **multi-level modeling**. Let’s break it down:\n\n### Multi-Level Example:\n- **M0**: **HR Department of Company X** (a specific instance of an HR Department).\n  - This is the real-world instance, where you are modeling a specific HR department in a company.\n\n- **M1**: **HR Department** (a specific subclass of \"Department\" that specializes in HR-related functions).\n  - This is a more specific class (like a \"concrete\" department type) in which \"HR Department\" is a specialized type of department. This might also include departments like \"Finance Department,\" \"Marketing Department,\" etc.\n\n- **M2**: **Department class** (a meta-class that generalizes different kinds of departments).\n  - This is where you model the general idea of a department, which can specialize into HR, Finance, etc. This class could define common characteristics that all departments share, like having employees, roles, and organizational responsibilities.\n\n- **M3**: **OrganizationUnitType Class** (a meta-meta-class that generalizes different types of organizational units).\n  - This layer generalizes departments into broader organizational units. You might use this level to model abstract organizational structures, such as divisions, branches, departments, etc., all of which fall under the broader category of **OrganizationUnitType**.\n\n- **M4**: **Types** (the most abstract, meta-level that classifies even the meta-classes).\n  - At this level, you are dealing with abstract, fundamental types that classify other classes (such as \"OrganizationUnitType Class\"). This layer could be called **Types** or **Meta-types**, which define the most fundamental classifications that apply to all entities in the ontology.\n\n### How it Works:\n- **M0**: Real-world instances of entities, like \"HR Department of Company X.\"\n- **M1**: Specific classes like \"HR Department\" that represent concrete specializations.\n- **M2**: More abstract meta-classes like \"Department class\" that generalize multiple kinds of departments.\n- **M3**: A higher-level meta-meta-class like \"OrganizationUnitType Class\" that abstracts across different organizational units (not limited to departments).\n- **M4**: The most abstract level, **Types**, which provides the ultimate generalization for all entities, regardless of their domain.\n\n### Conclusion:\nYour proposed structure works well for a multi-level model. It provides a clear hierarchical layering of **specific instances**, **specialized classes**, **general organizational unit types**, and **abstract types**, each existing at a different meta-level. This hierarchy allows for flexibility and scalability, especially in complex domains like organizational structures, where many different levels of abstraction and generalization are needed.\n\n\n## I get confused on superclass vs metaclass. If M2 \"Department Class\" is a superclass of \"HR Department\" is it really a meta-class? \n\nYou're raising an important distinction between **superclass** and **meta-class**, and it's easy to get them confused in multi-level modeling contexts. Let me explain the difference clearly and how it applies to your case.\n\n### Superclass vs. Meta-Class:\n\n1. **Superclass**:\n   - A **superclass** is a **generalization** of a class in a hierarchy. It defines common properties and behaviors shared by all of its subclasses.\n   - **Example**: If \"Department Class\" is the superclass, then **\"HR Department\"** is a subclass of \"Department Class.\" The **Department Class** defines shared characteristics like having employees, a budget, and responsibilities, while **HR Department** adds specifics related to human resources functions.\n   - **Hierarchy**: The superclass/subclass relationship defines a **type hierarchy** within a single level of modeling (typically within one level, such as **M1** in your case).\n\n2. **Meta-Class**:\n   - A **meta-class** is a class that **classifies other classes**, not just individuals. Meta-classes exist at a **higher meta-level** compared to their instances (which are classes themselves).\n   - **Example**: If **M2 \"Department Class\"** is a **meta-class**, then **\"HR Department\"** (which is a class at M1) is an **instance** of the **meta-class**. In this case, the **Department Class** (M2) would describe what it means to be a \"class of departments,\" while \"HR Department\" (M1) would be a specific instance of this meta-class.\n\n### Superclass vs. Meta-Class in Your Example:\n\n#### Scenario 1: **\"Department Class\" as a Superclass**\n- If **M2 \"Department Class\"** is a **superclass** of **\"HR Department\"** (M1), it is **not** a meta-class.\n  - **\"Department Class\"** defines common features of all departments, and **\"HR Department\"** inherits those features while specializing its own.\n  - This is a **type hierarchy**: \"Department Class\" -> \"HR Department.\"\n  - **Hierarchy**: M2 and M1 are on the **same level of abstraction**, dealing with classes and subclasses that inherit properties, not with meta-level distinctions.\n\n#### Scenario 2: **\"Department Class\" as a Meta-Class**\n- If **M2 \"Department Class\"** is a **meta-class**, then **\"HR Department\"** (at M1) is not a subclass but an **instance** of the **meta-class**.\n  - In this case, **\"Department Class\"** (M2) represents a class of classes, and **\"HR Department\"** (M1) would be one example of a department class.\n  - **Hierarchy**: M2 -> M1 is a **meta-level hierarchy**, meaning that M2 **classifies classes**, while M1 **classifies instances**.\n\n### Key Differences:\n- **Superclass relationship** exists **within the same meta-level** (e.g., \"Department Class\" and \"HR Department\" are both classes, with one being more general).\n- **Meta-class relationship** crosses meta-levels, where a meta-class (M2) **classifies** another class (M1) instead of simply generalizing it.\n\n### In Summary:\n- **\"Department Class\" as a superclass**: It stays within the same level as its subclass (HR Department), and they exist at the **M1 level** together.\n- **\"Department Class\" as a meta-class**: It moves up a level of abstraction, existing at **M2**, where it classifies the class **\"HR Department\"** at **M1**.\n\nIf you’re looking at **multi-level modeling**, then **\"Department Class\"** at M2 should be treated as a **meta-class**, meaning that **\"HR Department\"** (M1) is an instance of that meta-class. But if you’re only interested in inheritance within a single level, you’d treat **\"Department Class\"** as a **superclass**.\n\nThe difference boils down to whether you're crossing **meta-levels** (meta-classification) or staying within the same level (superclass/subclass inheritance).\n\n## which makes more sense?\n\nIn the context of **multi-level modeling**, it typically makes more sense to treat **\"Department Class\" (M2)** as a **meta-class**, and **\"HR Department\" (M1)** as an **instance** of that meta-class. Here’s why:\n\n### Why Meta-Class (M2) Makes More Sense:\n1. **Multi-Level Modeling Framework**:\n   - In multi-level modeling, each level represents a different degree of abstraction, and meta-classes exist at a higher level to describe classes at a lower level. \n   - If you put \"Department Class\" at **M2**, it naturally fits the idea that it classifies **classes** like \"HR Department\" at **M1**. The HR Department is just one specific type of department, but it’s classified at a lower level of abstraction (M1), and **\"Department Class\"** defines the concept of what a department **class** is (M2).\n\n2. **Meta-Level Distinction**:\n   - If **M2** represents a **meta-class**, then the next level down, **M1**, is a class level where **HR Department** is an **instance** of a department class, not a subclass. This fits well with multi-level modeling's goal to separate **types of types** across different meta-levels.\n   - It aligns with your structure of progressively abstracting from **instances (M0)** to **types of classes (M3)**, and ultimately to **types in general (M4)**.\n\n3. **Clear Separation of Levels**:\n   - Multi-level modeling's strength lies in separating each level clearly. Treating **M2 as a meta-class** helps maintain this separation:\n     - **M2** (meta-class): \"Department Class\" describes the properties of department **classes** (at M1).\n     - **M1** (class): \"HR Department\" is an **instance** of a \"Department Class,\" defining what a specific type of department (HR) looks like.\n     - **M0** (instance): \"HR Department of Company X\" is a specific instance of the \"HR Department\" at the lowest level.\n\n4. **Avoiding Overlap Between Levels**:\n   - If you treat **\"Department Class\"** (M2) as a **superclass** rather than a **meta-class**, it would imply that **M2** and **M1** are at the same level of abstraction, which can make the structure more confusing and collapse the separation between levels. This would be more of a typical **type hierarchy**, not a multi-level hierarchy.\n\n### Conclusion:\nIn a multi-level model, treating **M2 \"Department Class\"** as a **meta-class** and **M1 \"HR Department\"** as an instance of it makes more sense because it preserves the intended abstraction hierarchy across different levels. This approach fits naturally with the goals of multi-level modeling, where each level represents a progressively more abstract concept.\n\n## In which case, it would be wrong to say that \"Department class\" generalizes multiple kinds of departments\n\nCorrect, if **\"Department class\"** at **M2** is treated as a **meta-class**, then it would indeed be **wrong** to say that it \"generalizes multiple kinds of departments\" in the traditional superclass-subclass sense. Here's why:\n\n### Meta-Class vs. Superclass Generalization:\n- **Meta-Class (M2)**: A meta-class **classifies classes**, not instances or subclasses. In your case, **\"Department class\"** at **M2** does not generalize or define a hierarchy of subclasses (like HR Department or Finance Department); instead, it defines **what it means to be a department class**. The **HR Department (M1)** is not a subclass but an **instance** of the meta-class \"Department class\" at M2.\n  - **Example**: \"Department class\" would define characteristics or constraints of department **classes** (like **HR Department** or **Finance Department**) at M1, but it would not generalize these departments as a superclass would.\n\n- **Superclass (Same level)**: A **superclass** exists at the **same level** of abstraction as its subclasses and generalizes them. If **\"Department class\"** were a **superclass**, it would generalize various **subclasses** like HR Department, Finance Department, etc., within the same level (e.g., M1). \n  - **Example**: If \"Department class\" were a superclass at M1, it could generalize specific types of departments such as HR and Finance departments, which would be its subclasses.\n\n### Summary:\n- If **\"Department class\"** is a **meta-class** at **M2**, it does not \"generalize\" multiple kinds of departments in the usual sense. Instead, it defines the characteristics that classes like **HR Department (M1)** must have.\n- A **superclass**, on the other hand, generalizes its subclasses at the **same level**. If you want to express that \"Department class\" generalizes HR and other department types, you would need to consider **Department class** as a superclass at the same level (M1), not a meta-class at M2.\n\nThus, in a multi-level modeling context, saying \"Department class\" **generalizes** multiple types of departments would be incorrect if you're treating it as a **meta-class**. The correct phrasing would be that it **classifies** department classes at M1.\n\n## Maybe it would be better to call M2 a \"Department type\" class. So then, how would you generalize a department. i..e, at the M1 level, could you just have a \"generic department\" superclass, to harness the power of a type hierarchy within a \"meta hierarchy\"\n\nYes, that approach makes sense! By calling **M2** a **\"Department type\" class**, you’re clearly distinguishing it as a meta-class that classifies different department types at **M1**. Then, within **M1**, you can introduce a **\"Generic Department\"** superclass to **generalize different kinds of departments** like HR, Finance, etc., while still leveraging the power of both the type hierarchy and the meta-hierarchy.\n\n### How This Would Work:\n\n1. **M2 - \"Department type\" Class (Meta-Class)**:\n   - At **M2**, you would have the **meta-class \"Department type\"**, which defines what it means to be a **class of departments**. This would classify any department class at **M1**, such as **HR Department** or **Finance Department**.\n   - **Example**: \n     - **Department type** (M2): Class that defines department types.\n\n2. **M1 - \"Generic Department\" Superclass (Type Hierarchy)**:\n   - At **M1**, you can introduce a **\"Generic Department\" superclass**, which generalizes specific kinds of departments like **HR Department**, **Finance Department**, etc. This is part of a **type hierarchy** within the M1 level.\n   - This allows you to organize specific department classes within a hierarchy for shared properties (such as departments having employees, budgets, etc.).\n   - **Example**:\n     - **Generic Department** (Superclass at M1): Generalizes common properties for all departments.\n     - **HR Department**, **Finance Department** (Subclasses at M1): Inherit from **Generic Department** and add specific characteristics.\n   \n3. **M0 - Real Instances**:\n   - At **M0**, you have specific **instances** of departments like **\"HR Department of Company X\"**, which are instances of **HR Department (M1)**.\n   - **Example**:\n     - **HR Department of Company X** (M0): An instance of **HR Department** at M1.\n\n### Power of Combining Type Hierarchy and Meta-Hierarchy:\n- By introducing a **type hierarchy** at M1, you can still benefit from **inheritance** and shared properties between different department types (through the **Generic Department superclass**). This allows you to avoid redundancy and manage common behaviors or attributes across specific department types.\n  \n- Meanwhile, the **meta-hierarchy** ensures that you can manage the classification of different **department classes** (like **HR Department** and **Finance Department**) through the **Department type (M2)**. This provides flexibility and abstraction across different meta-levels.\n\n### Example Breakdown:\n- **M2 - Department type class**:\n  - Defines what it means to be a department type.\n  \n- **M1 - Generic Department superclass**:\n  - Generalizes properties of all department types, such as having employees, a budget, and objectives.\n  - Specific subclasses, like **HR Department** and **Finance Department**, inherit from **Generic Department** and specialize those properties.\n\n- **M0 - Real-World Instances**:\n  - Instances like **HR Department of Company X** or **Finance Department of Company Y** exist at the real-world level.\n\n### Conclusion:\nThis structure works well for combining the strengths of a **type hierarchy** at M1 with a **meta-hierarchy** at M2. You get the benefit of generalization and inheritance at the class level while keeping clear distinctions between meta-levels. This makes your model both flexible and scalable, allowing you to handle different types of departments efficiently across different levels of abstraction.\n\n## It'd be nice to be able to visualize this clearly, but it feels like you'd need a 3D visualization... one axis for meta-hierarchy, and then two axes for any contained type hierarchies. I was also thinking likeC4 could be a good tool, with it's multi-level capabilities.\n\nYou’re absolutely right that **visualizing multi-level models** with both meta-hierarchy and type hierarchies can be complex, and a 3D approach could indeed help clarify the relationships.\n\n### Visualization Idea:\n- **Meta-Hierarchy Axis**: This could be the vertical axis, representing different levels of abstraction (e.g., M0 for instances, M1 for classes, M2 for meta-classes, and so on).\n- **Type Hierarchy Axes**: The other two axes could represent relationships within each level, showing inheritance and specialization among entities (like a type hierarchy for specific departments within the M1 level).\n\n### C4 as a Tool:\nThe **C4 model** (Context, Container, Component, Code) could indeed be useful for visualizing your multi-level model because it’s designed to handle multi-level systems and relationships. C4 is especially good at representing **architectural relationships** across different levels of abstraction. Although it’s often used in software architecture, you could potentially adapt its multi-level capabilities for your modeling needs.\n\n- **Context Level (C4)**: Could represent the broader system or domain context.\n- **Container/Component Levels (C4)**: Could represent specific departments or organizational units and how they relate within the meta- and type hierarchies.\n- **Code Level (C4)**: Could represent specific real-world instances (like an individual HR department).\n\n### 3D Visualization Tools:\nIf you’re thinking about creating a truly 3D visualization, you might consider tools that allow for **graph-based modeling** with 3D space:\n- **Neo4j (with 3D rendering)**: Great for relationships and hierarchies, though typically used for graph databases.\n- **Gephi**: A network visualization tool that could be adapted to multi-dimensional models.\n- **Blender or Three.js**: For custom 3D modeling if you want complete control over visualization.\n\n### Conclusion:\nYour idea of using a 3D visualization (with axes for meta-hierarchy and type hierarchies) makes a lot of sense, especially for complex, layered systems like multi-level models. Adapting tools like **C4** for its multi-level capabilities or even exploring 3D visualization options could give you the clarity and insight needed to represent both the abstraction and type relationships effectively.\n","n":0.019}}},{"i":1695,"$":{"0":{"v":"Saying Things about Literals","n":0.5},"1":{"v":"\n## OK, what do you call a node/entity (what's it's Class name) that just represents a datatype, e.g. a string, so that you can make statements about strings. \"datatype reifier\" seems less than ideal because reification is overloaded already and not obvious anyhow.\n\nA node or entity in RDF that represents a datatype (e.g., a string) and allows you to make statements about that datatype is typically referred to as a **\"value resource\"** or **\"literal proxy\"**. This kind of node serves as an intermediary resource that stands in for the literal so that additional properties can be attached to it. Since \"reifier\" is indeed a loaded term in RDF, these alternatives focus more on the role of representing a value as a resource in its own right.\n\nHere are some naming options you might consider:\n\n### 1. **Literal Proxy**:\n   - **Description**: A class that represents a proxy for a literal value, allowing the literal to be treated as a resource to which you can attach properties.\n   - **Why?**: This term emphasizes the idea that the literal is being \"proxied\" by a resource, making it clear that the value is being represented indirectly.\n   - **Example**: You could define a `LiteralProxy` class that wraps strings, numbers, or other literals, allowing you to make statements about them.\n\n### 2. **Value Resource**:\n   - **Description**: A resource that stands in place of a literal value and allows statements to be made about the value.\n   - **Why?**: \"Value resource\" suggests that the node is a resource representing a specific value (literal), which is a natural extension of how RDF resources work.\n   - **Example**: You could create instances of `ValueResource` to represent strings, numbers, or other literals that you want to describe in greater detail.\n\n### 3. **Data Entity**:\n   - **Description**: A class that represents a structured data entity, which allows literals to be treated as first-class citizens in the RDF graph.\n   - **Why?**: \"Data entity\" focuses on the idea that the literal is treated as a full-fledged entity in the graph, making it clear that it's not a raw literal but a representational object.\n   - **Example**: `DataEntity` could be used for strings or numbers where additional metadata or properties are needed.\n\n### 4. **Value Node**:\n   - **Description**: A node in the RDF graph that represents a literal value.\n   - **Why?**: This term captures the idea that the node is standing in for a literal, emphasizing its role as a point in the graph that connects the literal to other statements.\n   - **Example**: A `ValueNode` class could allow you to make additional statements about specific string literals, such as their language or context.\n\n### 5. **Literal Resource**:\n   - **Description**: A class that represents a literal value as a resource, enabling further properties to be attached to it.\n   - **Why?**: This term directly conveys that the literal is being represented as a resource, emphasizing its RDF role as something that can be linked to other entities.\n   - **Example**: `LiteralResource` could allow a string or number to be the subject of additional properties like source or format.\n\n### 6. **ValueWrapper**:\n   - **Description**: A wrapper class for values (literals), enabling them to be treated as full resources.\n   - **Why?**: \"Wrapper\" emphasizes that the node is encapsulating a literal, making it suitable for further description.\n   - **Example**: `ValueWrapper` instances could be used for numbers or strings when you need to describe their properties.\n\n### Example Use Case:\nIf you wanted to describe a specific string (e.g., \"Hello, world!\") and add properties to it, you might define a class `LiteralProxy` like this:\n\n```turtle\n_:string1 a :LiteralProxy ;\n          :hasValue \"Hello, world!\" ;\n          :language \"en\" ;\n          :source \"Generated by User\" .\n```\n\nIn this case, `_:string1` is an instance of `LiteralProxy` (or whichever term you prefer), and the actual string \"Hello, world!\" is attached as a property (`:hasValue`), along with other descriptive properties.\n\n### Conclusion:\nWhile \"datatype reifier\" might seem technically correct, it's not ideal due to the baggage around \"reification\" in RDF. Terms like **Literal Proxy**, **Value Resource**, or **Literal Resource** are cleaner, more intuitive alternatives that clearly communicate the idea of representing literals as resources for further description.\n\n\n## which do you like best? Literal Proxy might be my favorite\n\nI think **[[t.cs.semantic-web.literal-proxy]]** is a great choice! It's clear, intuitive, and communicates exactly what the node is doing—standing in for a literal in a way that allows you to make statements about it. It avoids the complexities and connotations of \"reification\" while emphasizing the role of the proxy as an intermediary resource. It strikes a balance between technical accuracy and ease of understanding. Let me know if you need any further refinements!","n":0.036}}},{"i":1696,"$":{"0":{"v":"08","n":1}}},{"i":1697,"$":{"0":{"v":"26","n":1}}},{"i":1698,"$":{"0":{"v":"Narratology","n":1},"1":{"v":"\n## what is Bal’s definition of presentation\n\nMieke Bal, a prominent cultural theorist and critic, has developed a framework for analyzing narratives that includes various elements such as focalization, time, and presentation. In her work, particularly in *Narratology: Introduction to the Theory of Narrative*, Bal discusses **presentation** as part of how narratives are structured and conveyed to the audience.\n\n### Bal's Definition of Presentation:\n\nIn the context of @mieke-bal's narratology, **presentation** refers to the way in which the story is conveyed to the audience through the narrative text. It encompasses the choices made in the narrative's discourse that affect how the story is perceived, including aspects of narration, focalization, and style. Presentation is concerned with the *how* of storytelling—how the events of the story are presented to the reader or viewer, rather than just what happens in the story (which is the *what* or the content).\n\n### Key Aspects of Presentation in Bal’s Framework:\n\n1. **Narration**:\n   - **Narrator**: The voice or entity through which the story is told. The presentation involves decisions about who the narrator is (first-person, third-person, etc.), their level of knowledge, and their reliability.\n   - **Narrative Voice**: The tone, style, and perspective through which the narrator conveys the story. This affects the mood and atmosphere of the narrative.\n\n2. **Focalization**:\n   - **Focalization**: The perspective through which the events of the story are presented. This involves whose perspective the story is filtered through, which can significantly affect how the story is interpreted. Presentation in this context includes how the focalizer's viewpoint shapes the narrative.\n\n3. **Temporal Presentation**:\n   - **Order and Duration**: Presentation also includes how time is managed in the narrative. This involves decisions about the sequence of events (whether they are presented chronologically or non-linearly) and the pacing of the narrative (how much time is devoted to different events).\n\n4. **Stylistic Choices**:\n   - **Language and Style**: The choice of language, literary devices, and stylistic elements are also part of presentation. These choices influence how the narrative is perceived, including the use of metaphor, symbolism, and other rhetorical techniques.\n\n### Summary:\n\nIn Mieke Bal’s narratology, **presentation** refers to the manner in which a narrative is constructed and delivered to the audience. It involves the choices related to narration, focalization, temporal structuring, and stylistic elements, all of which shape how the story is perceived and understood. Presentation is a critical aspect of narrative analysis because it influences the reader’s experience and interpretation of the story.","n":0.05}}},{"i":1699,"$":{"0":{"v":"20","n":1}}},{"i":1700,"$":{"0":{"v":"Zeebe Vs Activiti","n":0.577},"1":{"v":"\n## Zeebe vs Activit\n\n[[prdct.zeebe]] and [[prdct.activiti]] are both popular open-source workflow and business process management (BPM) engines, but they cater to slightly different use cases and have distinct architectures and features.\n\n### Zeebe:\n1. **Architecture**:\n   - **Microservices-Oriented**: Zeebe is designed with microservices in mind. It is a distributed, horizontally scalable workflow engine that can handle high throughput and large volumes of workflow instances.\n   - **Event-Driven**: Zeebe is built for event-driven architectures, making it well-suited for modern cloud-native applications where workflows are triggered by events.\n\n2. **Performance and Scalability**:\n   - **High Throughput**: Zeebe is designed to scale horizontally, meaning it can handle a large number of workflow instances concurrently, making it ideal for high-traffic applications.\n   - **Cloud-Native**: Zeebe is optimized for deployment in cloud environments like Kubernetes, where scalability and fault tolerance are critical.\n\n3. **Target Use Cases**:\n   - **Event-Driven Microservices**: Zeebe is particularly strong in scenarios where workflows need to be integrated into microservices architectures.\n   - **Large-Scale Process Automation**: It’s ideal for applications that require processing thousands or millions of workflow instances.\n\n4. **Supported By**:\n   - Zeebe is developed and supported by Camunda as part of the Camunda Cloud platform, which also includes advanced features like monitoring and analytics.\n\n### Activiti:\n1. **Architecture**:\n   - **Traditional BPMN Engine**: Activiti is a more traditional BPMN (Business Process Model and Notation) workflow engine. It has a monolithic architecture, although it can be deployed in a microservices architecture.\n   - **Java-Based**: Activiti is a lightweight BPMN engine built primarily in Java, making it easy to integrate with Java-based applications.\n\n2. **Performance and Scalability**:\n   - **Single Instance Deployment**: Activiti is designed for deployment in single-instance or clustered environments but doesn’t scale as naturally or horizontally as Zeebe.\n   - **Good for Mid-Sized Workflows**: While it performs well for moderate workflow loads, Activiti may face limitations when dealing with very high-throughput environments.\n\n3. **Target Use Cases**:\n   - **Traditional BPMN Workflows**: Activiti is well-suited for organizations looking to implement standard BPMN workflows in enterprise applications.\n   - **Integration with Java Applications**: Activiti integrates seamlessly with Java applications and is a good choice for Java-heavy environments.\n\n4. **Supported By**:\n   - Activiti was originally developed by Alfresco and is now maintained by the Activiti community. It has a large user base and many extensions available.\n\n### Comparison Summary:\n- **Zeebe**: Best for cloud-native, event-driven microservices architectures that require high scalability and throughput. It is the go-to option for modern, large-scale distributed systems.\n- **Activiti**: Best for traditional BPMN-based workflows, particularly in Java-centric environments. It’s more suited for medium-scale workflows and enterprise applications that don’t require the scale and distribution capabilities of Zeebe.\n\n### References:\n- [Zeebe Documentation](https://docs.camunda.io/docs/components/zeebe/zeebe-overview/)\n- [Activiti Documentation](https://www.activiti.org/documentation)\n- [Camunda Blog on Zeebe vs Activiti](https://camunda.com/blog/)","n":0.048}}},{"i":1701,"$":{"0":{"v":"Opencaesar and Closed World","n":0.5},"1":{"v":"\n## how does opencaesar/oml support closed-world reasoning?\n\nOML (Ontological Modeling Language), supported by the openCAESAR framework, provides mechanisms for both open-world and closed-world reasoning. Specifically, OML allows you to define \"closed-world model kinds\" within its framework, which are crucial for enabling closed-world reasoning. This is particularly useful when you need to make inferences based on the assumption that all relevant information is explicitly stated in the model, which contrasts with the open-world assumption where unknown facts are treated as possibly true.\n\nIn OML, the flexibility to specify closed-world semantics is achieved through careful scoping and the use of model kinds, which can be aggregated into viewpoints that encapsulate specific concerns of stakeholders. This approach allows for rigorous reasoning and validation processes, ensuring that your models behave as expected under closed-world assumptions. Additionally, OML supports integrating these closed-world definitions into broader workflows that include automated analysis and consistency checking, making it a robust choice for complex systems engineering projects.\n\nThis capability is particularly useful in scenarios where you need to enforce strict constraints and ensure that certain conditions hold without ambiguity, which is often required in safety-critical systems and other domains where comprehensive validation is essential.\n\nFor more details on how OML supports these features, you can refer to resources provided by the openCAESAR project【148†source】【149†source】.\n\n\n\n","n":0.069}}},{"i":1702,"$":{"0":{"v":"16","n":1}}},{"i":1703,"$":{"0":{"v":"Pragmatics","n":1},"1":{"v":"\n## \"how can we express potentially complex sets of statements with different “change semantics” or, as we can now more precisely say, with different pragmatics using triple compounds?\" What does pragmatics mean in this context?\n\n- @chatgpt.4o: \n\nIn the context of the passage from the OntoGen introduction, the term **\"pragmatics\"** refers to the practical aspects of how RDF triples (or sets of RDF triples, referred to as \"triple compounds\") are used to convey meaning, especially in relation to the context, usage, or intention behind the data. Pragmatics in this sense goes beyond the mere structure of the data (syntax) or the direct meaning of the individual statements (semantics) to consider how these statements are interpreted or intended to be interpreted in specific situations.\n\n### Explanation:\n\n1. **Syntax**: This refers to the structure or format of the RDF triples. For example, RDF syntax dictates that each triple consists of a subject, predicate, and object.\n\n2. **Semantics**: This involves the meaning of each individual triple. For instance, the triple `:John :hasFriend :Jane` conveys the idea that John has a friend named Jane.\n\n3. **Pragmatics**: In this context, pragmatics relates to the broader interpretation and use of these triples in real-world situations, including:\n   - **Change Semantics**: How the interpretation of the triples might change over time or in different contexts. For example, if a person’s status or role changes, the meaning of the relationships expressed in the RDF data might also shift.\n   - **Contextual Interpretation**: How the meaning of triples might depend on additional context, such as the time at which the data was recorded, the authority or trustworthiness of the source, or the intentions behind creating the data.\n   - **Usage Scenarios**: How the triples are used to achieve particular goals, such as decision-making, information retrieval, or communication between systems or people.\n\n### Example:\n\nImagine you have a set of triples that describe an employee's role in a company:\n\n```turtle\n:John :hasRole :Manager .\n:John :hasRole :Consultant .\n```\n\n- **Semantics**: These triples simply state that John has the roles of Manager and Consultant.\n- **Pragmatics**: Pragmatics would consider the context: Is John currently active in both roles, or has he transitioned from Manager to Consultant? Is this information being used to make decisions about John's current responsibilities? If the data is being interpreted in the context of a specific time frame, pragmatics would account for how this data should be understood or acted upon at that time.\n\n### In Summary:\n\nIn this context, **pragmatics** refers to how the meaning of RDF triples or compounds might vary based on the circumstances, intentions, and context of their use. It involves understanding the implications of the data in a more nuanced, real-world setting, particularly when dealing with \"change semantics\" or how information evolves over time or in different contexts.","n":0.047}}},{"i":1704,"$":{"0":{"v":"Ontogen Vs Relator Based Rdf","n":0.447},"1":{"v":"\n## Ontogen is interesting, but how does it fit in with immutable RDF/event-driven/relator-based RDF?\n\n- @chatgpt.4o:\n\nOntoGen, with its focus on RDF Triple Compounds, can integrate with concepts like immutable RDF, event-driven RDF, and relator-based RDF in the following ways:\n\n1. **Immutable RDF**: OntoGen's approach of creating triple compounds aligns with the idea of immutability by grouping related triples, allowing historical tracking without altering original data.\n\n2. **Event-Driven RDF**: Triple compounds can represent events or changes over time, making OntoGen suitable for event-driven models where state changes are documented in a compound structure.\n\n3. **Relator-Based RDF**: OntoGen's structure supports complex relationships (relators) by organizing associated triples, facilitating the representation of intricate connections between entities. \n\nThis approach allows for modeling complex data interactions, temporal changes, and relational contexts within a unified RDF framework.  ","n":0.089}}},{"i":1705,"$":{"0":{"v":"23","n":1},"1":{"v":"\n## how does ontouml work with owl?\n\nOntoUML and OWL (Web Ontology Language) are both used in the field of ontology engineering, but they serve different purposes and operate at different levels of abstraction. **OntoUML** is primarily a conceptual modeling language grounded in ontological principles, designed to create semantically rich and precise models. **OWL**, on the other hand, is a formal language used for defining and reasoning about ontologies on the Semantic Web. Integrating OntoUML with OWL involves translating OntoUML's rich conceptual models into OWL's formal, logical framework.\n\n### How OntoUML Works with OWL:\n\n1. **Conceptual Modeling in OntoUML**:\n   - **High-Level Modeling**: OntoUML is used to create high-level conceptual models that capture the semantics of a domain using ontologically well-founded distinctions. These models include stereotypes like kinds, roles, phases, mixins, and categories, which help ensure the model aligns with ontological principles, such as identity, rigidity, and dependency.\n\n2. **Translation to OWL**:\n   - **Model Transformation**: The rich OntoUML models are translated into OWL for formal representation and reasoning. This translation involves mapping OntoUML constructs to OWL classes, properties, and axioms. However, this translation is non-trivial due to the differences in expressiveness between OntoUML and OWL.\n   - **Stereotype Mapping**: OntoUML stereotypes (e.g., kinds, roles, phases) are mapped to OWL classes and properties. For example:\n     - **Kinds**: Mapped to OWL classes, representing rigid, essential types.\n     - **Roles**: Mapped to OWL classes with restrictions, representing context-dependent classifications.\n     - **Phases**: Mapped to OWL classes with temporal constraints, representing states that entities can go through.\n   - **Constraints**: OntoUML's ontological constraints, like rigidity, identity, and dependence, must be approximated in OWL. Some constraints might be directly translatable, while others require creative workarounds or custom OWL axioms.\n\n3. **Handling Ontological Complexity**:\n   - **Multiple Inheritance and Meta-Modeling**: OWL supports some of the features needed for OntoUML, like multiple inheritance, but it lacks direct support for meta-modeling (e.g., classes of classes). This requires careful modeling strategies, such as using OWL Full (which allows classes to be both classes and instances) or using punning in OWL 2 to simulate meta-level structures.\n   - **Temporal and Contextual Phases**: OntoUML's handling of phases (temporal states) and roles (context-dependent classifications) needs to be carefully modeled in OWL, often using OWL’s built-in temporal reasoning capabilities or by defining custom properties and axioms to simulate these aspects.\n\n4. **Tool Support**:\n   - **OntoUML Tools**: Tools like **OntoUML Editor** and **Menthor Editor** are used to create OntoUML models. These tools often include support for exporting the OntoUML models to OWL.\n   - **Transformation Tools**: There are tools and methodologies developed specifically to aid the transformation of OntoUML models into OWL ontologies, such as the **OntoUML2OWL** transformation approach. These tools automate the mapping process, ensuring that the resulting OWL ontology preserves as much of the OntoUML model’s semantics as possible.\n   - **Verification and Validation**: Once translated into OWL, the ontology can be verified and validated using OWL reasoners like **HermiT** or **Pellet**. These tools check the consistency of the ontology and infer additional knowledge based on the OWL axioms.\n\n5. **Use Cases in OWL**:\n   - **Ontology-Based Applications**: Once an OntoUML model is transformed into OWL, it can be used in ontology-based applications on the Semantic Web, such as reasoning engines, knowledge graphs, and intelligent agents.\n   - **Interoperability**: OWL ontologies derived from OntoUML models can be shared and reused across different systems, enhancing interoperability and data integration in Semantic Web applications.\n\n### Summary:\n\n- **OntoUML** is used for high-level, ontologically sound conceptual modeling, capturing rich semantics with stereotypes and constraints.\n- **OWL** provides a formal framework for representing these models in a machine-interpretable way, enabling reasoning and interoperability.\n- **Transformation Process**: OntoUML models are translated into OWL through a process that maps OntoUML constructs to OWL classes, properties, and axioms, often requiring careful handling of complex ontological concepts.\n- **Tool Support**: Various tools facilitate the creation, transformation, and validation of OntoUML models into OWL ontologies, enabling their use in Semantic Web applications.\n\nThis integration allows you to leverage the strengths of both OntoUML and OWL, combining rich conceptual modeling with the formal reasoning capabilities of the Semantic Web.","n":0.039}}},{"i":1706,"$":{"0":{"v":"21","n":1},"1":{"v":"\n## are there published ontologies, similar to ontomedia or abc ontology, that describe fictional universes?\n\nOntologies specifically designed to describe fictional universes are relatively rare but have garnered interest in the academic and cultural heritage communities. These ontologies aim to capture the complex relationships, entities, and events within fictional narratives, allowing for structured analysis and data interoperability. Here are some notable examples:\n\n### 1. **OntoMedia Ontology**\n   - **Focus**: OntoMedia is designed to describe narratives, especially those in media and cultural contexts. It can be applied to fictional universes by modeling characters, events, places, and other narrative elements.\n   - **Use Case**: It has been used in projects that involve the analysis and annotation of stories, particularly in media studies and digital humanities.\n\n### 2. **ABC Ontology**\n   - **Focus**: The ABC ontology was developed for managing multimedia resources and can be adapted to describe events, agents, and objects within fictional narratives.\n   - **Use Case**: It’s been applied in digital library contexts but can be extended to model the structure and relationships within fictional worlds.\n\n### 3. **Narrative Ontology (NOnt)**\n   - **Focus**: NOnt is an ontology designed to represent narrative structures, including those found in fictional works. It focuses on events, characters, and their interactions within a story.\n   - **Use Case**: NOnt can be used to model story arcs, character development, and plot structures in fictional narratives.\n\n### 4. **LODE (Linking Open Descriptions of Events)**\n   - **Focus**: LODE is an ontology designed to describe events, which can be adapted to describe events in fictional universes.\n   - **Use Case**: It’s often used in cultural heritage projects to model historical events, but its structure is flexible enough to model fictional events in narratives.\n\n### 5. **Fanfic Ontology**\n   - **Focus**: Developed specifically to describe fanfiction, the Fanfic Ontology models relationships between characters, settings, and plot elements within fan-created stories.\n   - **Use Case**: It captures the unique aspects of fan-created narratives, including the re-interpretation of existing fictional universes.\n\n### 6. **SIOC (Semantically-Interlinked Online Communities) Ontology**\n   - **Focus**: While not specifically designed for fictional universes, SIOC can be used to model online discussions, content, and communities that revolve around fictional works, including the relationships between characters, plots, and fan interpretations.\n   - **Use Case**: SIOC is often applied to social media and online community content, making it adaptable for studying fictional universes through the lens of community engagement and fan culture.\n\n### 7. **Storyspace Ontology**\n   - **Focus**: The Storyspace Ontology is designed to model narrative structures, especially in the context of digital storytelling and interactive narratives.\n   - **Use Case**: It can be applied to describe the structure of stories, including branching paths, character relationships, and narrative events in fictional universes.\n\n### 8. **Myth Ontology**\n   - **Focus**: This ontology is designed to describe mythological narratives, capturing the relationships between gods, heroes, and mythic events. While focused on mythology, it can be adapted to fictional universes with similar structures.\n   - **Use Case**: Used in cultural heritage and anthropology to model mythological stories, which often have similarities to fictional universes in their complexity and scope.\n\n### 9. **FOAF (Friend of a Friend) Ontology**\n   - **Focus**: FOAF is not specifically designed for fictional universes, but it can be adapted to describe the relationships between characters in fictional settings.\n   - **Use Case**: Commonly used to model social networks, FOAF can be applied to model the social relationships between characters in a fictional narrative.\n\n### Summary:\nWhile ontologies like OntoMedia and the ABC ontology are well-known for their application in narrative and multimedia contexts, other ontologies such as the Narrative Ontology, LODE, and even FOAF can be adapted to describe fictional universes. These ontologies provide structures for modeling events, characters, relationships, and other elements within fictional narratives, making them useful tools for projects that seek to analyze or manage fictional content.\n\n## similar to the httpRange-14 issue: in the context of work, expression, manifestation, item -- an IRI could refer to any of those things. I almost feel like the IRI should contain the (primary) class of the thing. \n\nYou're touching on a significant issue in the Semantic Web and digital humanities, especially in the context of the FRBR (Functional Requirements for Bibliographic Records) model, which introduces the concepts of Work, Expression, Manifestation, and Item (WEMI). This model is used to describe different levels of abstraction in bibliographic resources, but it can create ambiguity when using IRIs to identify these entities.\n\n### The httpRange-14 Issue Analogy:\nThe httpRange-14 issue dealt with the ambiguity of IRIs on the web, specifically whether an IRI identifies a document or a concept described by that document. Similarly, in the WEMI model, an IRI could be ambiguous if it doesn't clearly indicate whether it refers to a Work, Expression, Manifestation, or Item.\n\n### Should the IRI Contain the Class of the Thing?\nIncluding the class (or type) in the IRI could help clarify the level of abstraction the IRI is meant to identify, but this approach has both pros and cons:\n\n### **Pros of Including the Class in the IRI:**\n1. **Disambiguation**:\n   - Helps clarify what the IRI represents, reducing confusion about whether it refers to a Work, Expression, Manifestation, or Item.\n   - Makes it easier for humans and machines to understand the nature of the resource directly from the IRI.\n\n2. **Consistency**:\n   - Encourages a consistent naming convention, which can make large datasets easier to manage and navigate.\n   - Facilitates better data integration and linking across different datasets and ontologies.\n\n3. **Ease of Querying**:\n   - Improves the clarity of SPARQL queries, as the IRI itself provides hints about what kind of entity it identifies, potentially reducing the need for additional filtering or type checking.\n\n### **Cons of Including the Class in the IRI:**\n1. **Over-Specification**:\n   - Embedding the class in the IRI can lead to a rigid structure, which might become problematic if the classification of an entity changes over time.\n   - Limits flexibility in how entities are used or interpreted in different contexts.\n\n2. **IRI Longevity**:\n   - Best practices suggest that IRIs should be persistent and stable over time. If the class of an entity changes, having the class embedded in the IRI might necessitate changing the IRI, which could lead to issues with link rot or outdated references.\n\n3. **Namespace Management**:\n   - Managing namespaces with class-based IRIs could become cumbersome, especially in large and complex datasets where entities might belong to multiple classes or where class distinctions are not always clear-cut.\n\n### Alternative Approaches:\nInstead of embedding the class in the IRI, you could use other methods to disambiguate the entity type:\n\n1. **Explicit Typing**:\n   - Use RDF types (`rdf:type`) to explicitly declare the type of each entity. This keeps the IRI clean and allows for flexible classification.\n   - Example:\n     ```turtle\n     :exampleWork a frbr:Work .\n     :exampleExpression a frbr:Expression .\n     ```\n\n2. **Contextual Metadata**:\n   - Provide additional metadata or contextual information alongside the IRI to clarify what the IRI refers to.\n   - Use descriptive RDF properties that convey the specific nature of the resource (e.g., `dct:hasFormat`, `dct:isVersionOf`).\n\n3. **Hierarchical Naming**:\n   - Use a hierarchical or segmented naming convention within the IRI, which can suggest a broader context without strictly embedding the class.\n   - Example: `http://example.org/resource/work/12345` vs. `http://example.org/resource/expression/12345`\n\n4. **Use of URN/UUIDs**:\n   - Consider using URNs or UUIDs as IRIs to avoid the issue of embedding type information. The type can be handled through metadata rather than within the IRI itself.\n\n### Conclusion:\nIncluding the class in the IRI can be a helpful way to disambiguate references to different levels of abstraction, especially in complex models like WEMI. However, it also introduces rigidity and potential challenges with IRI management. The best approach often depends on the specific needs of your project, the stability of your classifications, and how the IRIs will be used and maintained over time. Balancing clarity with flexibility is key, and sometimes a combination of clear IRIs and rich metadata provides the best of both worlds.","n":0.028}}},{"i":1707,"$":{"0":{"v":"17","n":1},"1":{"v":"\n## could you call the preference for reified, relator-based relationship specification in RDF \"relator-based predication\"?\n\n@chatgpt.4o:\n\nYes, the term \"relator-based predication\" could be a suitable way to describe a preference for reified, relator-based relationship specification in RDF. In the context of RDF and ontologies, \"predication\" refers to the act of stating or asserting a property or relationship about a subject. By incorporating \"relator-based,\" the term specifically emphasizes the use of relators (or relationships modeled as intermediary entities) to express these assertions.\n\nThis approach aligns with ontological theories, such as those found in the OntoClean methodology or the Basic Formal Ontology (BFO), where relations (relators) are often treated as first-class entities that connect other entities. \"Relator-based predication\" would emphasize the use of these intermediary entities (relators) for more complex and explicit relationship modeling in RDF, as opposed to using simple direct predicates.\n\nSo, \"relator-based predication\" effectively conveys the method and philosophy behind using relators for relationship specification in RDF.\n\n","n":0.081}}},{"i":1708,"$":{"0":{"v":"15","n":1},"1":{"v":"\n## John Sowa claims \"There are many reasoning tools that are more expressive, more powerful, and easier to use than Protege.\" But what?\n\n- @chatgpt.4o\n\nJohn Sowa's statement likely refers to the limitations of **Protégé**, which is a widely used tool for creating and managing ontologies. Protégé is excellent for building OWL (Web Ontology Language) ontologies but has limitations in expressiveness and reasoning compared to more advanced systems. While he doesn't mention specific alternatives in this quote, we can infer that Sowa is pointing to reasoning tools or approaches that offer more flexibility or power in certain contexts.\n\nHere are some reasoning tools or approaches that may fit the criteria Sowa alludes to:\n\n### 1. **Cyc**\n   - **Expressiveness**: Cyc is an ontology-based AI that supports a wide range of reasoning, including commonsense reasoning. It contains a vast knowledge base and can reason using both declarative and procedural knowledge.\n   - **Power**: It goes beyond what OWL can express, handling richer forms of logic such as first-order logic (FOL), temporal reasoning, and more.\n   - **Ease of Use**: Although it has a steeper learning curve than Protégé, Cyc's reasoning capabilities allow for more complex and nuanced queries.\n\n### 2. **Conceptual Graphs (CGs)**\n   - **Expressiveness**: Sowa himself developed conceptual graphs, a formalism that maps natural language to logic in a more intuitive way. CGs can represent knowledge that involves temporal, modal, and other more complex relationships.\n   - **Power**: CGs are based on a subset of first-order logic but can be extended to higher-order logics. They are more flexible than OWL in terms of the types of relationships they can model.\n   - **Ease of Use**: CGs provide a more natural representation for many types of reasoning, especially in semantic networks and knowledge graphs.\n\n### 3. **Reasoners for First-Order Logic**\n   - **Expressiveness**: Tools such as **Vampire**, **Prover9**, and **E** offer reasoning capabilities for first-order logic, which is more expressive than the description logic that OWL is based on.\n   - **Power**: First-order logic allows for more complex relationships and quantification over variables that OWL cannot represent directly.\n   - **Ease of Use**: These reasoners can handle more complex problems, but they might not be as easy to use as Protégé for beginners. However, they allow for solving problems that require more sophisticated logical reasoning.\n\n### 4. **Logic Programming Languages (e.g., Prolog)**\n   - **Expressiveness**: Prolog and similar languages can handle a broader range of logic than description logics. They can express recursive relationships and can be extended with constraints and other features.\n   - **Power**: Prolog reasoners allow for nonmonotonic reasoning (i.e., reasoning that can retract conclusions when new information is available), which is not available in many OWL reasoners.\n   - **Ease of Use**: For users familiar with logic programming, Prolog can be more intuitive and flexible compared to OWL-based reasoning in Protégé.\n\n### 5. **Datalog Engines (e.g., RDFox, VLog)**\n   - **Expressiveness**: Datalog can handle a broader set of inferences compared to OWL, particularly in the realm of rules and recursion.\n   - **Power**: These engines are optimized for efficient large-scale reasoning, particularly with datasets in the billions of triples.\n   - **Ease of Use**: They can be more powerful in certain domains but may require more technical expertise than using Protégé with a reasoner like HermiT or Pellet.\n\n### 6. **Common Logic (CL)**\n   - **Expressiveness**: Common Logic is an ISO standard for a family of logic-based languages that can express a wide variety of logical constructs, including higher-order logics.\n   - **Power**: It's a superset of first-order logic and allows for interoperability between different logical systems. It’s far more expressive than OWL.\n   - **Ease of Use**: It provides a framework for multiple logics, making it flexible but possibly more complex to work with.\n\n### 7. **Frame-Based Systems (e.g., OpenCyc, Jena with Reasoners)**\n   - **Expressiveness**: Frame-based systems are often more intuitive for knowledge representation than description logics and can offer richer types of inferences.\n   - **Power**: They are particularly well-suited for integrating reasoning with machine learning and natural language processing.\n   - **Ease of Use**: These systems can offer higher-level abstractions for reasoning but may be more complex than OWL for simple applications.\n\n### 8. **Rule-Based Systems (e.g., Drools, Jess)**\n   - **Expressiveness**: Rule-based systems allow for complex, conditional logic that can handle nonmonotonic reasoning.\n   - **Power**: Such systems are often more flexible in business logic and can implement a wide range of reasoning strategies.\n   - **Ease of Use**: For those familiar with production rules, these tools can be more intuitive than OWL-based systems.\n\n### 9. **Graph Databases with Integrated Reasoning (e.g., Neo4j with APOC)**\n   - **Expressiveness**: Graph databases can represent relationships that are more complex than typical OWL axioms and are often used for knowledge graphs and semantic reasoning.\n   - **Power**: These databases allow for complex querying and reasoning over large-scale, interconnected data.\n   - **Ease of Use**: Tools like Cypher in Neo4j can be easier to use for graph-based reasoning than setting up ontologies in Protégé.\n\n### Conclusion:\nSowa’s critique may stem from the fact that OWL and Protégé, while user-friendly and effective for certain types of reasoning, are limited in terms of expressiveness compared to tools that handle first-order logic, nonmonotonic reasoning, and more complex forms of knowledge representation. Tools like Cyc, Prolog, and first-order logic reasoners provide broader reasoning capabilities but often require more expertise to use effectively.","n":0.034}}},{"i":1709,"$":{"0":{"v":"Now","n":1},"1":{"v":"\n## Other Happenings\n\n- Roleplaying: Wilson ([Alien RPG](https://djradon.github.io/wiki/notes/sldj64tb5d1ambhfmiife0p/))\n- Interactive Fiction: [Sentou Gakuen](https://djradon.github.io/wiki/notes/biseq9wr38cfa1ey6vqpsla/)\n- Garden: resuscitating the Kangaroo Paws, praying for the peas\n- Piano: [Hallelujah I Love Her So](https://en.wikipedia.org/wiki/Hallelujah_I_Love_Her_So), This Is Halloween","n":0.186}}},{"i":1710,"$":{"0":{"v":"Projects","n":1}}},{"i":1711,"$":{"0":{"v":"Art Apps","n":0.707},"1":{"v":"\n- inkscape + gimp + scribus + blender\n- [[prtdct.natron]] Compositing Software For\nVFX and Motion Graphics\n- [[prdct.krita]]\n\n## Learning Resources\n\nhttps://www.open-of-course.org/courses/course/view.php?id=102\n","n":0.236}}},{"i":1712,"$":{"0":{"v":"Products","n":1},"1":{"v":"\n- [[p.wasNamespaceFor]] `c.product`","n":0.577}}},{"i":1713,"$":{"0":{"v":"Java","n":1}}},{"i":1714,"$":{"0":{"v":"Jsr","n":1}}},{"i":1715,"$":{"0":{"v":"JSR94: Java Rules Engine API","n":0.447},"1":{"v":"\n- url: https://jcp.org/en/jsr/detail?id=94\n- related: [[prdct.drools]]","n":0.447}}},{"i":1716,"$":{"0":{"v":"223","n":1}}},{"i":1717,"$":{"0":{"v":"Xtdb2","n":1}}},{"i":1718,"$":{"0":{"v":"Sakila Playground","n":0.707}}},{"i":1719,"$":{"0":{"v":"Windows","n":1}}},{"i":1720,"$":{"0":{"v":"Wsl","n":1}}},{"i":1721,"$":{"0":{"v":"Ubuntu 22","n":0.707}}},{"i":1722,"$":{"0":{"v":"04","n":1}}},{"i":1723,"$":{"0":{"v":"Vocabulary","n":1}}},{"i":1724,"$":{"0":{"v":"Rico","n":1},"1":{"v":"\n\n\nInternational Council on Archives \"Records in Contexts\" Ontology\n\n- [[p.hasURL]] https://www.ica.org/standards/RiC/RiC-O_v0-2.html\n\n![](/assets/images/2021-10-02-18-34-45.png)\n\n#seems-interesting\n","n":0.316}}},{"i":1725,"$":{"0":{"v":"Thrift","n":1}}},{"i":1726,"$":{"0":{"v":"Rdf Binary","n":0.707},"1":{"v":"\n## References\n\n- https://afs.github.io/rdf-thrift/rdf-binary-thrift.html","n":0.577}}},{"i":1727,"$":{"0":{"v":"Srd","n":1}}},{"i":1728,"$":{"0":{"v":"5","n":1},"1":{"v":"\n## Implementations\n\n- [[prdct.open5e]]\n- [[prdct.5e-tools]]\n- [[prdct.OGL-SRD5]]\n- [[prdct.d20srd]]","n":0.408}}},{"i":1729,"$":{"0":{"v":"Systems Reference Document 5.1","n":0.5},"1":{"v":"\n- #license #CC-BY-4\n- url: https://media.wizards.com/2023/downloads/dnd/SRD_CC_v5.1.pdf\n- #related https://dnd.wizards.com/resources/systems-reference-document\n\n## Comparisons\n\n## vs D&D\n\n- lacks \"flavor\" elements\n  - no named gods, none of the spells have significant NPC names, there's no mention of Greyhawk or other copyrighted works by WotC\n    - \"Mordenkainen's Sword\" becomes \"Mage's Sword\"\n- no rules for character creation, for advancing characters in level, calculating experience, or anything else related to the topics forbidden by the d20 System License\n- does not include \"certain monsters - most notably Illithids (Mind Flayers) and Beholders\" [^1]\n- \"default setting... is a simplified version of the Greyhawk campaign setting\"\n\n## References\n\n[^1]: https://rpgresearch.fandom.com/wiki/System_Reference_Document\n","n":0.103}}},{"i":1730,"$":{"0":{"v":"Spring","n":1}}},{"i":1731,"$":{"0":{"v":"Modulith","n":1},"1":{"v":"\n- url: https://spring.io/projects/spring-modulith\n\n## Resources\n\n- https://medium.com/andamp/event-sourcing-with-spring-modulith-2b35b0569dbb\n- https://levelup.gitconnected.com/architecture-style-modulith-vs-microservices-90c7c75713db","n":0.408}}},{"i":1732,"$":{"0":{"v":"Spring Hateoas","n":0.707},"1":{"v":"\n- url: https://spring.io/projects/spring-hateoas\n\n## Resources\n\n- https://spring.io/guides/gs/rest-hateoas\n\n## References\n\n- https://docs.spring.io/spring-hateoas/docs/current/reference/html/","n":0.378}}},{"i":1733,"$":{"0":{"v":"Framework","n":1},"1":{"v":"\n- related: [[prdct.spring.boot]]\n## Features\n\n-   [Core technologies](https://docs.spring.io/spring-framework/reference/core.html): dependency injection, events, resources, i18n, validation, data binding, type conversion, SpEL, AOP.\n    \n-   [Testing](https://docs.spring.io/spring-framework/reference/testing.html#testing): mock objects, TestContext framework, Spring MVC Test, `WebTestClient`.\n    \n-   [Data Access](https://docs.spring.io/spring-framework/reference/data-access.html): transactions, DAO support, JDBC, ORM, Marshalling XML.\n    \n-   [Spring MVC](https://docs.spring.io/spring-framework/reference/web.html) and [Spring WebFlux](https://docs.spring.io/spring-framework/reference/web-reactive.html) web frameworks.\n    \n-   [Integration](https://docs.spring.io/spring-framework/reference/integration.html): remoting, JMS, JCA, JMX, email, tasks, scheduling, cache and observability.\n    \n-   [Languages](https://docs.spring.io/spring-framework/reference/languages.html): Kotlin, Groovy, dynamic languages.","n":0.125}}},{"i":1734,"$":{"0":{"v":"SpEL","n":1}}},{"i":1735,"$":{"0":{"v":"Spring Data","n":0.707},"1":{"v":"\n- related: [[prdct.rdf4j-spring]]\n\n## Resources\n\n- https://github.com/Tanzu-Solutions-Engineering/spring-modern-data-architecture","n":0.447}}},{"i":1736,"$":{"0":{"v":"Cloud","n":1}}},{"i":1737,"$":{"0":{"v":"Spring Cloud Stream","n":0.577},"1":{"v":"\n\n\n## Binder support\n\n- [[prdct.spring-nats]]\n-   [RabbitMQ](https://github.com/spring-cloud/spring-cloud-stream-binder-rabbit)\n    \n-   [Apache Kafka](https://github.com/spring-cloud/spring-cloud-stream-binder-kafka)\n    \n-   [Kafka Streams](https://github.com/spring-cloud/spring-cloud-stream-binder-kafka/tree/master/spring-cloud-stream-binder-kafka-streams)\n    \n-   [Amazon Kinesis](https://github.com/spring-cloud/spring-cloud-stream-binder-aws-kinesis)\n    \n-   [Google PubSub _(partner maintained)_](https://github.com/spring-cloud/spring-cloud-gcp/tree/master/spring-cloud-gcp-pubsub-stream-binder)\n    \n-   [Solace PubSub+ _(partner maintained)_](https://github.com/SolaceProducts/spring-cloud-stream-binder-solace)\n    \n-   [Azure Event Hubs _(partner maintained)_](https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/spring/spring-cloud-azure-stream-binder-eventhubs)\n    \n-   [Azure Service Bus _(partner maintained)_](https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/spring/spring-cloud-azure-stream-binder-servicebus)\n    \n-   [AWS SQS _(partner maintained)_](https://github.com/idealo/spring-cloud-stream-binder-sqs)\n    \n-   [AWS SNS _(partner maintained)_](https://github.com/idealo/spring-cloud-stream-binder-sns)\n    \n-   [Apache RocketMQ _(partner maintained)_](https://github.com/alibaba/spring-cloud-alibaba/wiki/RocketMQ-en)","n":0.14}}},{"i":1738,"$":{"0":{"v":"Boot","n":1},"1":{"v":"\n## Features\n\n-   Create stand-alone Spring applications\n-   Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)\n-   Provide opinionated 'starter' dependencies to simplify your build configuration\n-   Automatically configure Spring and 3rd party libraries whenever possible\n-   Provide production-ready features such as metrics, health checks, and externalized configuration\n-   Absolutely no code generation and no requirement for XML configuration","n":0.132}}},{"i":1739,"$":{"0":{"v":"Smol","n":1}}},{"i":1740,"$":{"0":{"v":"Developer","n":1},"1":{"v":"\n- repo: https://github.com/smol-ai/developer\n- related: [[prdct.smol.ai]]\n\n## Description\n\nThis is a \"junior developer\" agent (aka smol dev) that either:\n\n- scaffolds an entire codebase out for you once you give it a product spec\n- gives you basic building blocks to have a smol developer inside of your own app.\n\n## Resources\n\n- https://bit.kevinslin.com/p/leveraging-gpt-4-to-automate-the","n":0.146}}},{"i":1741,"$":{"0":{"v":"smol.ai","n":1},"1":{"v":"\n- https://smol.ai/\n- supports: javascript, typescript, python","n":0.408}}},{"i":1742,"$":{"0":{"v":"Singularity","n":1}}},{"i":1743,"$":{"0":{"v":"AI DSL","n":0.707},"1":{"v":"\n- repo: https://github.com/singnet/ai-dsl\n- written-in: [[t.cs.languages.idris]] #python","n":0.408}}},{"i":1744,"$":{"0":{"v":"Readwise","n":1}}},{"i":1745,"$":{"0":{"v":"Reader","n":1}}},{"i":1746,"$":{"0":{"v":"Moontools","n":1}}},{"i":1747,"$":{"0":{"v":"MoonTools.ECS","n":1},"1":{"v":"\n- repo: https://gitea.moonside.games/MoonsideGames/MoonTools.ECS\n\n## Features\n\n- \"MoonTools.ECS implements all the important parts of ECS, with two additions. the common one is entity relations, which we will talk about later in the tutorial. lots of ECS libraries include relations, which are basically components that are associated with two entities instead of just one.\n\nthe uncommon feature which i think makes MoonTools.ECS extremely special is messages. i explain this later in the tutorial as well, but messages are stores of data like components that can be sent by systems and read by other systems. messages are destroyed at the end of every frame. this allows systems to easily communicate in a loosely coupled way, i.e. without directly referencing each other. messages solve a huge number of problems that come up with the ECS architecture, and substantially reduce overall awkwardness.\"\n  - https://blood.church/posts/2023-09-25-shmup-tutorial\n\n## Limitations\n\n- \"you can't iterate over all the components attached to an entity in MoonTools.ECS (at least not in release mode) because it has performance implications: creating the iterators means boxing the components. you can however iterate over all the relationships a component has. so we instead need to model traits as entities and \"having a trait\" is a kind of relation between the character entity and the trait entity.\"\n\n\n## Resources\n\n- [[course.shmup-tutorial]] https://cohost.org/prophetgoddess/post/2964176-i-made-a-tutorial-on\n- https://cohost.org/prophetgoddess/post/845893-declarative-crusader\n  - mentions [[game.pentiment]]","n":0.069}}},{"i":1748,"$":{"0":{"v":"Meraki","n":1}}},{"i":1749,"$":{"0":{"v":"Meraki Mdm","n":0.707}}},{"i":1750,"$":{"0":{"v":"Mediawiki","n":1}}},{"i":1751,"$":{"0":{"v":"Semantic MediaWiki","n":0.707},"1":{"v":"\n\n\n- a beautiful relic that pointed the way to GraphDown\n","n":0.316}}},{"i":1752,"$":{"0":{"v":"Locus Map","n":0.707}}},{"i":1753,"$":{"0":{"v":"Locus Map 4","n":0.577},"1":{"v":"\n- silver (~$.87/mo) and gold ($2/mo) subscription for no ads and advanced functionality","n":0.277}}},{"i":1754,"$":{"0":{"v":"Locus Map Classic 3","n":0.5},"1":{"v":"\n- one-time purchase","n":0.577}}},{"i":1755,"$":{"0":{"v":"Kumuluz","n":1}}},{"i":1756,"$":{"0":{"v":"KumuluzAPI","n":1},"1":{"v":"\n- url: https://kumuluz.com/digital-components/api/\n\n## Description\n\nlightweight, open, standards-based solution for API Management, API Catalogue, API Gateway, API Marketplace with complete support for cataloguing API-related schemas, such as XML Schemas and JSON documents, providing full insight into APIs, their usage, relations, schemes and dependencies.","n":0.156}}},{"i":1757,"$":{"0":{"v":"Jira","n":1}}},{"i":1758,"$":{"0":{"v":"Product Discovery","n":0.707}}},{"i":1759,"$":{"0":{"v":"Google Cloud","n":0.707}}},{"i":1760,"$":{"0":{"v":"Eventarc","n":1},"1":{"v":"\n[[p.instanceOf]] [[t.cs.sd.architecture.event-driven.event-broker]]\n\n- [[p.similarTo]] [[prdct.aws.event-bridge]] [[prdct.azure.event-grid]]\n- [[p.supports]] [[prdct.cloudevents]]\n\n\n## docs: \n\n- https://cloud.google.com/eventarc/docs/event-driven-architectures\n- ","n":0.316}}},{"i":1761,"$":{"0":{"v":"Gcp","n":1}}},{"i":1762,"$":{"0":{"v":"Security Center","n":0.707}}},{"i":1763,"$":{"0":{"v":"Google Cloud Pub/Sub","n":0.577}}},{"i":1764,"$":{"0":{"v":"Frontend","n":1}}},{"i":1765,"$":{"0":{"v":"Semantic UI","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://semantic-ui-docs-gatsby.netlify.app/\n","n":0.577}}},{"i":1766,"$":{"0":{"v":"Foundry","n":1}}},{"i":1767,"$":{"0":{"v":"Phandelver_and_below_the_shattered_obelisk","n":1},"1":{"v":"\n- https://foundryvtt.com/packages/dnd-phandelver-below\n- manifest: https://foundryvtt.s3.us-west-2.amazonaws.com/modules/dnd-phandelver-below/module-1.1.0.json","n":0.5}}},{"i":1768,"$":{"0":{"v":"Dnd5e","n":1},"1":{"v":"\n- repo: https://github.com/foundryvtt/dnd5e/\n\" ","n":0.577}}},{"i":1769,"$":{"0":{"v":"Dotnet","n":1}}},{"i":1770,"$":{"0":{"v":".NET Interactive","n":0.707},"1":{"v":"\n- repo: https://github.com/dotnet/interactive\n- [[c.usecase]] While typically associated with notebook technologies such as Jupyter and the Polyglot Notebooks extension for Visual Studio Code, .NET Interactive has other uses as well, such as building REPLs and embedded script engines.\n- ","n":0.164}}},{"i":1771,"$":{"0":{"v":"Docusign","n":1}}},{"i":1772,"$":{"0":{"v":"Docusign Powerforms","n":0.707}}},{"i":1773,"$":{"0":{"v":"Diagrams","n":1}}},{"i":1774,"$":{"0":{"v":"Diagrams (sefless)","n":0.707},"1":{"v":"\n- dead\n- [[c.software.tools.diagramming]]\n- repo: https://github.com/seflless/diagrams#flowchart\n- written-in: javascript\n\n\n## Features\n\n-   [flowchart](https://github.com/seflless/diagrams#flowchart#flowchart)\n    -   [[p.basedOn]] [[prdct.flowchart-js]]\n-   [network sequence](https://github.com/seflless/diagrams#flowchart#sequence)\n    -   [[p.basedOn]] [[prdct.js-sequence-diagrams]]\n-   [graphviz's dot](https://github.com/seflless/diagrams#flowchart#dot)\n    -   [[p.basedOn]] [[prdct.graphviz.dot]]\n-   [railroad diagrams](https://github.com/seflless/diagrams#flowchart#railroad)l","n":0.204}}},{"i":1775,"$":{"0":{"v":"Datastax","n":1}}},{"i":1776,"$":{"0":{"v":"Astra Streaming","n":0.707},"1":{"v":"\n- built-on: [[prdct.pulsar]]\n- supports: [[prdct.kafka]] [[prdct.rabbitimq]]\n\n## pricing\n\n### free\n\n- One topic with up to 1 write and 1 read per second and 1GB of storage (using free $25/month credit)\n\n### pay as you go\n\n","n":0.177}}},{"i":1777,"$":{"0":{"v":"Aws","n":1}}},{"i":1778,"$":{"0":{"v":"Aurora","n":1}}},{"i":1779,"$":{"0":{"v":"Serverless V2","n":0.707},"1":{"v":"\nurl: https://aws.amazon.com/rds/aurora/serverless/\n#features \n  - automatically starts up, shuts down, and scales capacity up or down based on your application's needs\n    - minimum capicity of 0.5 ACU\n    - ","n":0.192}}},{"i":1780,"$":{"0":{"v":"Sns","n":1}}},{"i":1781,"$":{"0":{"v":"S3","n":1}}},{"i":1782,"$":{"0":{"v":"Neptune","n":1},"1":{"v":"\n- based_on: blazegraph\n\n## Features\n\n- supports tinkerpop, opencypher and sparql\n- [Capturing graph changes in real time using Neptune streams](https://docs.aws.amazon.com/neptune/latest/userguide/streams.html)\n\n## Cons\n\n- not cheap\n- can't use SPARQL/RDF and Gremlin/Property graph at the same time\n\n## Resources","n":0.177}}},{"i":1783,"$":{"0":{"v":"Amazon MSK","n":0.707},"1":{"v":"\n![[prdct.azure.event-hubs#^ls3s1l3vm1hl]]\nurl: https://aws.amazon.com/msk/\n","n":0.707}}},{"i":1784,"$":{"0":{"v":"Lambda","n":1}}},{"i":1785,"$":{"0":{"v":"Event Bridge","n":0.707},"1":{"v":"\n[[p.instanceOf]] [[t.cs.sd.architecture.event-driven.event-broker]]\n\n- [[p.similarTo]] [[prdct.azure.event-grid]] [[prdct.google-cloud.eventarc]] [[prdct.triggermesh]]\n\n## [[p.hasComparison]]\n\n- https://sjwiggers.com/2022/01/30/event-driven-services-in-the-cloud-azure-event-grid-aws-event-bridge-and-google-eventarc/","n":0.354}}},{"i":1786,"$":{"0":{"v":"EMR","n":1}}},{"i":1787,"$":{"0":{"v":"Arcgis","n":1}}},{"i":1788,"$":{"0":{"v":"Maps Sdk for Unity","n":0.5},"1":{"v":"\n\n- url: https://developers.arcgis.com/unity/\n- \n\nhttps://arcg.is/q1CXb","n":0.5}}},{"i":1789,"$":{"0":{"v":"Maps Sdk for JavaScript","n":0.5}}},{"i":1790,"$":{"0":{"v":"Apicurio","n":1}}},{"i":1791,"$":{"0":{"v":"Studio","n":1},"1":{"v":"\n- url: https://www.apicur.io/studio/\n- sponsored_by: [[org.redhat]]\n\n## Features\n\n- validate\n- generate Java project\n- can connect to git for API source control and publishing\n- ","n":0.224}}},{"i":1792,"$":{"0":{"v":"Data Models","n":0.707},"1":{"v":"\n- https://www.apicur.io/datamodels/\n\n\n## Features\n\n### Parsing into a formal model\n\nOpenAPI and AsyncAPI content, typically JSON or YAML, can be parsed into a formal, structured tree-like data model, much like XML or other structured content.\n\n### Visitor + Traverser patterns\n\nFull support for the [visitor design pattern](https://en.wikipedia.org/wiki/Visitor_pattern), for a single node in the model, and also an up or down traversal of the full or partial document.\n\n### Validation of the model\n\nValidate all or part of the data model against all of the rules defined in the OpenAPI or AsyncAPI specifications.\n\n### Supports both Java and TypeScript\n\nUse this library in your Java, Node.js, or browser-based applications! It works the same no matter how you use it.\n\n### Convert OpenAPI 2.0 to OpenAPI 3.0\n\nIncludes a built-in transformer for easily converting older Swagger documents into the newer OpenAPI 3 format.\n\n### Robust $ref support\n\nProvide your own $ref resolver so that the library can properly analyze or validate documents with external references. Also includes a built-in dereferencer, which can transform a document with external references into one without any by internalizing all of the refs!","n":0.076}}},{"i":1793,"$":{"0":{"v":"MASON","n":1}}},{"i":1794,"$":{"0":{"v":"MASON DES","n":0.707},"1":{"v":"\n- https://cs.gmu.edu/~eclab/projects/mason/extensions/des/docs/manual.pdf\n\n## Summary\n\nMASON’s DES classes may be roughly divided into four categories: Resources, Processes, Composed Processes, and Visualization Tools. \n\n### Resources \n\nMoney, love, gasoline, palettes of goods, cargo containers, water, and people waiting in line are all resources. They’re things handed off from process to process to make a DES simulation hum. The abstract superclass is **Resource**. A simple Resource is **Entity**, an atomic object like a skeeball ticket or a video game token. Entities can also serve as containers for collections of Resources, much like a cargo container, a truck of goods, or a palette of microwaves. these are called Eomposite Entities. **CountableResources** are Resources which can have have integer amounts greater than one (they’re not Entities) and cannot be infinitely subdivided. For example, you can have 1000 medicine pills, or 200 eggs, but you can’t have half an egg. Money is a CountableResource which prints nicely (like $ 4.32). UncountableResources are Resources which are infinitely subdivisible, like water or love or gasoline or time. You can make as many Resources as you like of various types, as members of these general classes. \n\n### Processes \n\n- Processes perform actions in response to events. In most cases, this action involves Processes handing off Resources to other Processes\n\nA Process is an object which hands resources to another process or receives the same. There are three major abstract kinds of Processes. A **Provider** provides resources. A **Receiver** receives resources from a Provider. A **Middleman** is both a Provider and a Receiver: it receives resources from Providers, and then provides them to downstream Receivers. MASON’s DES system is mostly a “push” system: providers generally offer resources to receivers (who may choose to accept or reject the offer). However in many cases it also has an optional “pull”: receivers can ask providers offer resources to them (or in some cases, to offer resources to other receivers), and providers may respond to these entreaties or ignore them. \n\nConsider a classic MM1 Queue: people arrive at a bank, then waiting in line at a bank teller. Here people are represented as Entities. They are generated by a **Source**, which produces the people entering the bank. Sources can produce resources (people) at random, via a schedule, and so on. The Source then hands its produced people to a **Queue**, which represents the line they have to wait in. A Queue can also be thought of as a warehouse of items waiting to be processed. The Queue then attempts to feed people through a **Lock**, which only allows people to pass if it can allocated a different Resource (let’s call it a Teller) from a **Pool** of Tellers. In our case there’s only a single Teller, so if the Pool doesn’t have one available for the Lock, the Lock refuses to let the next person move forward. when a Lock can allocate a Teller and let a person move forward, the person is handed off to a **SimpleDelay**, which holds the person for a fixed amount of time, representing the time the Teller needs to service the person. When the SimpleDelay lets go of the person, it is handed off to an **Unlock**, which places the Teller resource back in the Queue and informs the Lock that a Teller is available again. The person is then finally handed to a **Sink**, which is basically a black hole in which Resources disappear forever, and represents the end of the line for people in the model. There are actually three kinds of Delays available. A SimpleDelay delays resources for a fixed amount of time. A **Delay** delays them for a varying amounts of time (but is more costly). A **BoundedDelay** delays them for varying amounts of time as long as those times are integer values less than some number N (it’s cheaper than a Delay). Some more processes. An **If** receives incoming Resources and sends them to one or another of different downstream receivers based on some decision you specify. A Composer takes multiple different resources and packs them together into a **Composite Entity**. A **Decomposer** does the opposite. An **Extractor** is a kind of Source which produces resources by requesting them from another Provider. A **Transformer** is like a currency converter: it accepts Resources and produces (converts them into) different kinds of Resources. A **Probe** lets Resources pass through it, but records the amount and rate for statistical purposes. It can be used in combination with a **Lead**: together they can measure the amount and rate of Resource passing through a subgraph of processes. These Processes are all designed to be subclassed and customized to your heart’s content. \n\n### Composed Processes \n\nMASON provides two ways to compose Processes. First, there are **Macros**. A Macro wraps a subgraph of Processes in a neat little package and lets you repeat this subgraph over and over cleanly. It’s a useful abstraction tool. A **Service** is a commonly used Macro. \n\nSecond, there are **Multis**. Normally Processes deal with one incoming type of Resource and one outgoing type of Resource, often the same. But a Multi lets you have many incoming and outgoing types of Resources from different sources and destinations. You might use a Multi to model a bicycle factory: it takes steel, and bike components, and energy, and produces bicycles and trash. Muiltis are meant to be customized: they don’t do anything interesting on their own. \n\n\n### Visualization Facilities \n\nAll of the DES system’s processes, and their interconnections may be visualized and inspected using standard MASON facilities. To make this easy, the processes serve as their own Simple Portrayals, and DES system provides a variety of tools to display them and customize them.\n\n","n":0.033}}},{"i":1795,"$":{"0":{"v":"Bitbucket","n":1}}},{"i":1796,"$":{"0":{"v":"Bitbucket Premium","n":0.707},"1":{"v":"\n- [[p.instanceOf]] [[c.sku]]\n- [[p.hasFeature]] \n  - enforced merge checks\n  - ip allowlisting\n","n":0.289}}},{"i":1797,"$":{"0":{"v":"Zx","n":1},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/google/zx","n":0.577}}},{"i":1798,"$":{"0":{"v":"Zod","n":1},"1":{"v":"\n## Resources\n\n- https://medium.com/ekino-france/zod-why-youre-using-typescript-wrong-b0c1583df089\n\n```yaml\nurl: \n```","n":0.5}}},{"i":1799,"$":{"0":{"v":"Zjs","n":1},"1":{"v":"\n- repo: https://github.com/webaverse/zjs\n- written-in: javascript","n":0.447}}},{"i":1800,"$":{"0":{"v":"Zipkin","n":1},"1":{"v":"\n- [[p.hasComparison]] https://sematext.com/blog/jaeger-vs-zipkin-opentracing-distributed-tracers/\n  - [[p.hasComparand]] [[prdct.jaeger]]","n":0.408}}},{"i":1801,"$":{"0":{"v":"Zig","n":1},"1":{"v":"\n- url: https://ziglang.org/\n- repo: https://github.com/ziglang/zig","n":0.447}}},{"i":1802,"$":{"0":{"v":"Zeppelin","n":1}}},{"i":1803,"$":{"0":{"v":"Zenwave","n":1},"1":{"v":"\n- repo: https://github.com/ZenWave360/zenwave-sdk\n- written-in: java\n- supports: [[t.cs.sd.domain-driven-design]], [[t.cs.sd.architecture.event-driven]], [[prdct.jhipster.jdl]], [[prdct.karate]]\n\n\n## Description\n\n- ZenWave Domain Language started as an extended subset of JHipster Domain Language (JDL) that let you describe your entities and relationships.\n\n\n## Workflow\n\n-   Start by **Modeling your Domain** using the ZDL Domain Language including: entities, relationships, service commands and domain events.\n-   Generate a **draft OpenAPI definition from the ZDL model**. Edit collaboratively this OpenAPI document and then generate some more functional code and tests from that definition.\n-   Generate a **draft AsyncAPI definition** for consuming async request commands and publishing domain events. Now use zenwave maven plugin to generate strongly typed business interfaces implementing some Enterprise Integration Patterns like: transactional outbox, business dead letter queue...\n-   Generate a **complete Backend Application** from your Domain Definition Model.\n-   Connect (by hand) your Backend Application to other systems using the generated OpenAPI and AsyncAPI definitions.\n-   Generate **E2E, Integration tests and Consumer Contracts** for the public APIs you just produced.","n":0.081}}},{"i":1804,"$":{"0":{"v":"Zen Engine","n":0.707},"1":{"v":"\n- url: https://gorules.io/docs/\n- repo: ","n":0.5}}},{"i":1805,"$":{"0":{"v":"Zeebe","n":1},"1":{"v":"\n- #docs https://docs.camunda.io/docs/components/zeebe/zeebe-overview/\n\n![[prdct.infinitic#similar]]\n\n## Resources\n\n- https://a.com/blog/2020/08/orchestrating-cloud-events-with-zeebe/","n":0.447}}},{"i":1806,"$":{"0":{"v":"Zedux","n":1},"1":{"v":"\n- [[c.software.state-store]]\n- repo: https://github.com/omnistac/zedux\n\n## Philosophy\n\n- \"Zedux takes the unique approach of separating the state layer (stores) from the architecture layer (atoms).\"\n\n## Resources\n\n- https://hackernoon.com/how-atoms-fixed-flux","n":0.209}}},{"i":1807,"$":{"0":{"v":"Zealy","n":1},"1":{"v":"\n- free?\n- ","n":0.707}}},{"i":1808,"$":{"0":{"v":"Zazuko Rdf Sketch","n":0.577},"1":{"v":"\n- https://sketch.zazuko.com/\n- [[c.software.visualization.semantic]]","n":0.577}}},{"i":1809,"$":{"0":{"v":"Zazuko Prefix Server","n":0.577},"1":{"v":"\n- [[p.hasURL]] https://prefix.zazuko.com/\n- [[c.registry.ontology]]\n- [[p.alsoKnownAs]] Resolve RDF Terms\n- [[p.vs]] prefix.cc; LOV \n- published-by: [[org.zazuko]]\n","n":0.267}}},{"i":1810,"$":{"0":{"v":"Zazuko Ontology Manager","n":0.577},"1":{"v":"\n- https://zazuko.com/products/ontology-manager/\n- repo: https://github.com/zazuko/ontology-manager\n- published-by: [[org.zazuko]]\n- depends-on: postgres\n\n## Issues\n\n- more a \"schema.org\" ontology than a Protégé ontology. So I would probably rather call it a \"schema\" than an ontology, as we use little to no OWL, just RDFS. And we use the schema.org domainIncludes/rangeIncludes by default as well.\n- without community, the software is pretty much pointless.\n\n\n## References\n\n- https://github.com/zazuko/ontology-manager/discussions/75\n  - mentions [[prdct.plow]]","n":0.128}}},{"i":1811,"$":{"0":{"v":"Zazuko Graph Explorer","n":0.577},"1":{"v":"\n- https://github.com/zazuko/graph-explorer\n- [[c.software.semantic.browser]]\n- \n\n## Features\n\n-   Visual navigation and diagramming for extensive graph data sets\n-   Engaging graph visualization and context-aware navigation capabilities\n-   Diagram storage and retrieval functionality\n-   User-friendly design, no graph query language or schema knowledge needed\n-   Customizable UI (by adjusting node and link templates) and data storage back-end","n":0.144}}},{"i":1812,"$":{"0":{"v":"Yunohost","n":1},"1":{"v":"\n- url: https://yunohost.org/en/apps\n- ","n":0.577}}},{"i":1813,"$":{"0":{"v":"Yuka Ai","n":0.707},"1":{"v":"\n- [[c.software.agent-framework]] [[c.software.game-engine]]\n- url: https://mugen87.github.io/yuka/\n- [[p.hadDependancy]]\n  - [[prdct.three-js]] or [[prdct.babylon-js]]\n- [[community.discord.yuka]]\n- https://mugen87.github.io/yuka/docs \n  - not exactly friendly\n- [[c.publisher]] [[org.human-interactive]]\n\n## Features\n\n- standalone library and independent of a particular 3D engine. The idea is to implement the actual game logic with Yuka and the visual representation with your preferred JavaScript 3D library\n- A task is an isolated unit of work that is processed in an asynchronous way. Tasks are managed within a task queue.\n\n## Resources\n\n- https://forum.babylonjs.com/t/how-to-get-yuka-js-working-in-node-environment/36510/13\n\n## Examples\n\n- https://mugen87.github.io/yuka/showcases/\n  - https://github.com/Mugen87/kickoff\n  - ","n":0.113}}},{"i":1814,"$":{"0":{"v":"YUI","n":1},"1":{"v":"\n- [[c.software.web.toolkit]]\n![[prdct.dojo_toolkit#^tmacjwe8emtq]]\n\n## Description\n\nYUI is developed in-house at Yahoo and features extensive, high-quality documentation and examples. Designed for speed and targeted at a population of professional PHP developers, YUI is designed with the needs of Yahoo-scale applications in mind. A growing list of controls is available with the toolkit as are useful CSS normalizing and layout style sheets. No package system is available, but “roll up” files of common functionality are distributed and documentation makes clear what order to load files in. No CSS query or markup-driven widget construction system is available in YUI. YUI has an active community and liberal licensing but external committers are not allowed on the project and Yahoo has not clarified the code lineage and other IP rights around the toolkit. No source control access of any sort is available. YUI is edge-cached on Yahoo’s CDN for use by all.","n":0.083}}},{"i":1815,"$":{"0":{"v":"Yoshinon","n":1}}},{"i":1816,"$":{"0":{"v":"Yjs","n":1},"1":{"v":"\n- url: https://yjs.dev/\n- repo: https://github.com/yjs/yjs\n- [[p.usedBy]] [[prdct.legend-keeper]]","n":0.378}}},{"i":1817,"$":{"0":{"v":"Yggdrasil","n":1},"1":{"v":"\n- https://interactions-hsg.github.io/yggdrasil/\n- repo: https://github.com/Interactions-HSG/yggdrasil\n- related: [[prdct.agents-and-artifacts-metamodel]] [[prdct.hyperagents]]\n- built_on: [[prdct.vertx]] [[prdct.websub]]\n- written_in: java\n- similar: [[prdct.FIPA]]\n  \n## Architecture\n\n![](/assets/images/2024-04-11-12-47-47.png)\n\nThere are four main modules at play in this project. Each contains a component running in its own \"event loop,\" capable of receiving information from others via \"events\" - read \"messages\" - onto an \"event bus.\" An event bus is then a shared communication channel between all event loops. Architecture invariant: all the modules must be as decoupled as possible so they cannot communicate directly and synchronously via method calls. They must communicate in an indirect, asynchronous fashion using message passing.\n\nhttp package\n\nThis package contains the \"HTTP Server\" module, so the HTTP Server that external Web Clients can contact. It exposes the functionalities of the web service through dedicated routes. The routes are in the \"HttpServerVerticle\" class, while their associated behavior is in the \"HttpEntityHandler\" class. The server allows the client to create, update, delete, and get environments, workspaces in those environments, and artifacts in those workspaces. For each request, it issues the corresponding operation on the \"CArtAgO\" component. After its completion, it can create, serialize, and send the representation of the involved entity to the \"RDF Store\" component. Between the other functionalities, there is one for registering for notifications through the \"WebSub\" protocol, registration aptly notified from the HTTP Server to the \"HTTP Notification\" component.\n\ncartago package\n\nThis package contains the \"[[prdct.cartago]]\" module, handling the interactions with the CArtAgO platform to allow compatible agents and frameworks to interact with Yggdrasil. An example is the \"JaCaMo\" platform, which can connect to remote CArtAgO nodes, such as the one managed by this module, and let its agents interact with it. The \"CartagoEntityHandler\" handles all the CArtAgO requests coming from the \"HTTP Server\" module, forwarding them appropriately to the \"CartagoVerticle\" class. This last one effectively implements the interplay between Yggdrasil and CArtAgO. This class allows workspace creation, artifact creation, and action invocation on artifacts: the operations part of CArtAgO. These entities' construction also means generating their semantic representation as a response to the request to do it, which the \"HTTP Server\" component then routes to the \"RDF Store.\" All the artifacts created by Yggdrasil are instances of the \"HypermediaArtifact\" class. It exposes some methods to retrieve and set properties that are proper of \"thing descriptions,\" such as their action affordances, security schemes, et cetera. To keep track of all the artifacts created without passing from CArtAgO, a \"HypermediaArtifactRegistry\" is used. This registry also handles all the secondary operations, such as getting and setting prefixes, names, and API keys for different entities. This module is also capable of handling the percepts observation. The module continually listens to the CArtAgO platform for new signals or observable property updates and forwards them to the \"HTTP Notification\" module to inform its subscribers. The only thing this module does not handle is the environment creation because this is not a CArtAgO feature but is an extension brought by Yggdrasil.\nstore package\n\nThis package contains the \"RDF Store\" module. It is responsible for storing the semantic representations of the environments, the workspaces, and the artifacts. Yggdrasil uses the \"Thing Description\" ontology to represent these entities. This \"knowledge\" representation and storage allows agents to crawl the MAS semantically, realizing the \"semantic relations\" and the single entry-point principle described above. The \"RdfStoreVerticle\" activates in response to events from the \"HTTP Server\" module, which events ask to get, create, update, or delete their designated entity. The class forwards the requests to the store, effectively represented by the \"RdfStore\" interface and its \"Rdf4jStore\" implementation. After a creation, update, or deletion operation succeeds, the store sends an event to the \"HTTP Notification\" module to alert all its subscribers. It is also responsible for generating the IRIs of the resources stored and serializing and deserializing the knowledge graphs kept inside of itself.\n\nwebsub package\n\nThis package contains the \"HTTP Notification\" module. It sends real-time notifications about artifacts' observable property updates or signal firings, as requested by the CArtAgO component. It also sends alerts about changes in the system state, such as entity creations, deletions, and updates, as requested by the HTTP Server component. The class implementing this functionality is the \"HttpNotificationVerticle\" one. This module implements the \"WebSub\" protocol for sending notifications to subscribers, a web recommendation for publish-subscribe communication over the Web. A registry of all subscribers is then needed, and the \"NotificationSubscriberRegistry\" class contains it.\n\n## the name\n\n-  In Norse mythology, Yggdrasil is the tree that connects multiple realms.\n\n## References\n\n- [[ar.engineering-world-wide-multi-agent-systems-with-hypermedia]]\n- [[ar.environment-programming-in-multi-agent-systems-an-artifact-based-perspective]]","n":0.037}}},{"i":1818,"$":{"0":{"v":"Yed","n":1},"1":{"v":"\n- https://www.yworks.com/yed-live/\n- [[c.Software.Tools.Diagramming]]","n":0.577}}},{"i":1819,"$":{"0":{"v":"Year Zero Engine","n":0.577}}},{"i":1820,"$":{"0":{"v":"Ycombinator","n":1}}},{"i":1821,"$":{"0":{"v":"Yasgui","n":1},"1":{"v":"\n- https://github.com/TriplyDB/Yasgui\n- repo: https://github.com/TriplyDB/Yasgui\n- written-in: typescript","n":0.408}}},{"i":1822,"$":{"0":{"v":"Yarn","n":1},"1":{"v":"\n- ","n":1}}},{"i":1823,"$":{"0":{"v":"Yarn Spinner","n":0.707},"1":{"v":"\n- url: https://yarnspinner.dev/)\n- repo: https://github.com/YarnSpinnerTool/YarnSpinner\n- similar: [[prdct.yarn-spinner-rust]]\n- written_in: c#\n- #great_name\n\n## Cons\n\n- Node names cannot contain a . (period).","n":0.236}}},{"i":1824,"$":{"0":{"v":"Yarn Spinner Rust","n":0.577},"1":{"v":"\n- repo:  https://github.com/YarnSpinnerTool/YarnSpinner-Rust\n- fun, but for dialog to be a smooth integration, non-dialog options need to be present.","n":0.236}}},{"i":1825,"$":{"0":{"v":"Yantra","n":1},"1":{"v":"\n- repo: https://github.com/yantrajs/yantra\n- ","n":0.577}}},{"i":1826,"$":{"0":{"v":"Yaml","n":1},"1":{"v":"\n## Features\n\n- \"YAML 1.2 is a valid superset of JSON\"\n\n## Comparison\n\n### vs [[prdct.json]]\n\n- YAML has overcome JSON’s limitations (e.g., namespace, comment, attribute, and complex configuration).\n  - @chatgpt.3.5: \" you can create structures in YAML that help organize data in a way that resembles namespaces or scopes in other systems.\"\n\n## Issues\n\n- YAML lacks protections from corrupted YAML files. [^1]\n- why not just assume that if the values don't start with a single or double quote, it should just be interpretted as the whole line is quoted\n\n## Example\n\n![](/assets/images/2023-12-11-11-24-46.png)\n![](/assets/images/2023-12-11-11-25-10.png)\n![](/assets/images/2023-12-11-11-27-05.png)\n\n## Resources\n\n- https://developers.redhat.com/blog/2020/11/25/how-to-configure-yaml-schema-to-make-editing-files-easier#yaml_schema\n- https://yaml-multiline.info/\n\n\n## References\n\n- [^1]: https://www.nclouds.com/blog/what-is-yaml-data-serialization/\n- https://dev.to/this-is-learning/- yaml-collections-sequences-and-mappings-4meb\n- https://stackoverflow.com/questions/19109912/yaml-do-i-need-quotes-for-strings-in-yaml","n":0.103}}},{"i":1827,"$":{"0":{"v":"Frontmatter","n":1},"1":{"v":"\n\nresources:  \n\n- https://www.11ty.dev/docs/data-frontmatter/\n","n":0.577}}},{"i":1828,"$":{"0":{"v":"yaml-ld","n":1},"1":{"v":"\n- spec: https://json-ld.github.io/yaml-ld/spec/\n\n![](/assets/images/2024-04-01-16-50-20.png)\n  ","n":0.577}}},{"i":1829,"$":{"0":{"v":"Yaml JS","n":0.707},"1":{"v":"\n- repo: https://github.com/eemeli/yaml\n\n## Comparison\n\n### vs [[prdct.js-yaml]]\n\n","n":0.408}}},{"i":1830,"$":{"0":{"v":"Yamato","n":1},"1":{"v":"\n- implemented_in: [[prdct.hozo]]\n- url: https://drive.google.com/open?id=1-Q72r3Nhdc0XC6Z9Xcml-ATGbJnTwdlU&usp=drive_fs\n  - what as mess! diarrhea_value_2.large <http://www.hozo.jp/owl/YAMATO20210808.miz.owl#diarrhea_value_2.large>\n\n![](/assets/images/2024-03-23-21-27-42.png)\n\n## Highlights\n- YAMATO adopts single inheritance to make the taxonomic structure clean like BFO and DOLCE\n  - t.2024.03.23.21 (not a good sign) How does it make all the \"basic distinction\" without multiple inheritance?\n  - \"Many of the multiple context-dependencies are covered using roles (Mizoguchi 2007). For the cases where genuine multiple inheritance is necessary, Hozo (Kozaki 2010) prepares IS-A relation which is nothing to do with identity problem of instances but only with property inheritance\"\n- Many of the existing upper ontologies are too simple to explain the reality and to guide domain people to build their ontologies. What they need are not only distinction between objects and qualities but also that between quality and quantity and that between quality and description of quality, not only that between objects and representation but also that between a copy of book and book and that between a novel and a musical score, and not only that between process and event but also that between a pulse and a sequence of pulses and that between to grow and to cut, etc. They also need to know how much similar a procedure and a piece of music are in what sense, why events cannot change while processes can, etc\n\n\n## Basic distinctions\n\n(1) Substrate and entity\nSpace and time are indispensable for things to exist in the world, while these two can exist independently of entities. Such independence is essential and differentiates the two from entities that inherently need these two to exist in the real world. Matters are less basic than space and time, but it still is very substrate-like because every physical individual is made of/from matter.\n\n(2) Entity and property\n\n(3) Physical and abstract\n\n(4) Continuant vs Occurent\n\n(5) Entity and relation\n\nRelation is sometimes considered as abstract. But it is not true, though it is something in the higher order than an entity, that is, entities first exist and relations are something found between entities. An example is the marital-relation with Mr. A and Ms. B that is time-dependent and hence cannot be abstract... People sometimes confuse relation as a formalism with relation as an existing thing. Typical examples are action and attribute that are sometimes formalized as a relation because an action is often formalized as one between an actor and an object and an attribute as one between an object and a value. But, of course, they are not relations ontologically. They are intrinsically entities included in an ontology.\n\n(6) Informational object vs. non-informational object (Representation and non-representation) \nInformational object and symbols are usually dealt with in semiotics rather than in ontology. However, from the real-world modeling point of view, we need to deal with informational object in our ontology, since there apparently exist music, novels, texts, symbols and so on in the real world. Informational object and non-informational object (object, process, relation, attribute, etc.) are very different from each other. For the informational object, it is not easy to identify what their instances are. For example, what an instance of a piece of music is, what an algorithm is, how both are similar ontologically, etc. need some in-depth consideration.\n\n## References\n- [[ar.foundational-ontologies-in-action]]\n- http://www.hozo.jp/onto_library/YAMATO101216.pdf","n":0.044}}},{"i":1831,"$":{"0":{"v":"Yago","n":1},"1":{"v":"\n- https://yago-knowledge.org/","n":0.707}}},{"i":1832,"$":{"0":{"v":"4","n":1}}},{"i":1833,"$":{"0":{"v":"5","n":1},"1":{"v":"\n- related: [[prdct.yago]]","n":0.577}}},{"i":1834,"$":{"0":{"v":"Xtext","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n- url: https://eclipse.dev/Xtext/\n\n\n\n## Resources\n\n- https://stackoverflow.com/questions/2603134/what-are-the-main-differences-between-jetbrains-mps-and-eclipse-xtext","n":0.408}}},{"i":1835,"$":{"0":{"v":"Xtdb","n":1},"1":{"v":"\n## RDF\n\n- not directly supported\n- [Improve RDF suitability](https://github.com/xtdb/xtdb/issues/317)\n\n## Resources\n\n### Learning Resources\n\n- https://fiddle.xtdb.comp\n\n## References\n\n- [[ar.xtdb.strength-of-the-record]]","n":0.267}}},{"i":1836,"$":{"0":{"v":"Xtql","n":1},"1":{"v":"\n## Resources\n\n\n### Learning Resources\n\n- https://docs.xtdb.com/static/learn-xtql-today-with-clojure.html (uses [[prdct.clerk]])\n- https://nextjournal.com/learn-xtdb-datalog-today/learn-xtdb-datalog-today","n":0.354}}},{"i":1837,"$":{"0":{"v":"XTDB V2","n":0.707},"1":{"v":"\n\n- docs: https://docs.xtdb.com/\n\n## vs xtdb\n\n- \"Where XTDB has previously been optimized for point-in-time historical queries, v2 now supports ‘cross-time’ queries, e.g. temporal joins and temporal range scans. This unlocks the complete history of data for rich analysis.\"\n\n## Features\n\n### Full Bitemporal\n\n- bitemporal support (point-in-time querying and full bi-[[t.cs.graph.temporal-joins]]\n)\n  - \"Where XTDB has previously been optimized for point-in-time historical queries, v2 now supports ‘cross-time’ queries, e.g. temporal joins and temporal range scans. This unlocks the complete history of data for rich analysis.\n  - We support the SQL:2011 standard for bitemporal functionality, and it’s built into the heart of XTQL too.\"\n\n- \"XTDB 2 will compute and maintain incremental indexes on-the-fly based on the raw data, so index updates will present far less operational impact. This also means the transaction log is now ~ephemeral in the new architecture (no more event-sourcing-style replays required, ever).\"\n","n":0.085}}},{"i":1838,"$":{"0":{"v":"xtdb V1","n":0.707}}},{"i":1839,"$":{"0":{"v":"XState","n":1},"1":{"v":"\n- repo: https://github.com/statelyai/xstate\n- url: https://stately.ai/docs/xstate\n- written_in: typescript","n":0.378}}},{"i":1840,"$":{"0":{"v":"XSB","n":1},"1":{"v":"\n- repo: https://sourceforge.net/projects/xsb/","n":0.577}}},{"i":1841,"$":{"0":{"v":"Xmppdotnet","n":1},"1":{"v":"\n- repo: https://github.com/agnauck/XmppDotNet\n- ","n":0.577}}},{"i":1842,"$":{"0":{"v":"Xmpp Web","n":0.707},"1":{"v":"\n- [[c.software.xmpp-client.web]]\n- repo: https://github.com/nioc/xmpp-web\n\n- written-in: javascript [[prdct.vue]]\n\n## [[p.builtOn]]\n\n-   [xmpp.js](https://github.com/xmppjs/xmpp.js) (ISC)\n-   [Vue.js](https://vuejs.org/) (MIT)\n-   [Pinia](https://pinia.vuejs.org/) (MIT)\n-   [Vue Router](https://router.vuejs.org/) (MIT)\n-   [Day.js](https://day.js.org/) (MIT)\n-   [Bulma](https://bulma.io/) (MIT)\n-   [Oruga](https://oruga.io/) (MIT)\n-   [Fork Awesome](https://forkaweso.me) (SIL OFL 1.1)","n":0.189}}},{"i":1843,"$":{"0":{"v":"Xklaim","n":1},"1":{"v":"\n- [[c.software.agent-framework]]\n- #dead\n- #related klava2\n- ","n":0.447}}},{"i":1844,"$":{"0":{"v":"Xjaf","n":1},"1":{"v":"\n- ","n":1}}},{"i":1845,"$":{"0":{"v":"Wundergraph","n":1},"1":{"v":"\nurl:  https://wundergraph.com/\n#docs https://docs.wundergraph.com/\nrepo: https://github.com/wundergraph/wundergraph","n":0.5}}},{"i":1846,"$":{"0":{"v":"Wrangler","n":1}}},{"i":1847,"$":{"0":{"v":"Wp Engine","n":0.707}}},{"i":1848,"$":{"0":{"v":"WoT","n":1},"1":{"v":"\n## Highlights\n\n- \"The Interaction Model of W3C WoT introduces an intermediate abstraction that formalizes the mapping from application intent to concrete protocol operations and also narrows the possibilities how Interaction Affordances can be modeled.\"\n  - [Interaction Affordance](https://www.w3.org/TR/wot-architecture/#dfn-interaction-affordance) is a lot like REST's [[t.cs.web.hateoas]]\n\n\n## Resources\n\n- https://www.w3.org/TR/wot-architecture/#dfn-interaction-affordance","n":0.149}}},{"i":1849,"$":{"0":{"v":"Wot Scripting API","n":0.577},"1":{"v":"\nurl: https://www.w3.org/TR/wot-scripting-api/","n":0.707}}},{"i":1850,"$":{"0":{"v":"World Engine","n":0.707},"1":{"v":"\n- [[c.software.entity-component-system]] [[c.software.web3]]\n- url: https://world.dev/\n- repo: https://github.com/argus-labs/world-engine\n- written-in: #go [[prdct.solidity]]\n- dependancy: [[prdct.nakama]]\n\n## Examples\n\n- https://github.com/Argus-Labs/agar-shooter\n\n## Resources\n\n- https://blog.argus.gg/world-engine/","n":0.25}}},{"i":1851,"$":{"0":{"v":"WorkspaceONE","n":1}}},{"i":1852,"$":{"0":{"v":"Workflow Core","n":0.707},"1":{"v":"\n- [[c.software.business-process-management]]\n- url: https://github.com/danielgerlag/workflow-core\n- written_in: c# \n\n## Features\n\n-  supports pluggable persistence and concurrency providers to allow for multi-node clusters.\n-  Fine-grain security and permission control of all aspects of cases and processes","n":0.18}}},{"i":1853,"$":{"0":{"v":"Workbox","n":1},"1":{"v":"\n- repo: https://github.com/GoogleChrome/workbox\n\n## Resources\n\n- https://developer.chrome.com/docs/workbox/what-is-workbox/","n":0.447}}},{"i":1854,"$":{"0":{"v":"WordPress","n":1},"1":{"v":"\n\n\n## References\n\n- https://wordpress.org/plugins/tags/rdf/","n":0.577}}},{"i":1855,"$":{"0":{"v":"Lh Tools","n":0.707},"1":{"v":"\n- dead\n- url: https://wordpress.com/plugins/lh-tools","n":0.5}}},{"i":1856,"$":{"0":{"v":"Wordnet","n":1},"1":{"v":"\n- [[c.software.semantic.network]] [[c.ontology.lexical]]\n\n## Description\n\n- synset is a set of cognitively equivalent synonyms, plus a gloss, organized into a semantic network with relations like hyponymy, meronymy, and entailment.\n\n## Issues\n\n- type-instance distinction is valuable, but no distinction between what kind of types, e.g., dwarf and architect are kinds of Person. ","n":0.144}}},{"i":1857,"$":{"0":{"v":"WOQL","n":1},"1":{"v":"\n## References\n\n- https://terminusdb.com/blog/the-power-of-web-object-query-language/","n":0.577}}},{"i":1858,"$":{"0":{"v":"Wonderdraft","n":1},"1":{"v":"\n- [[c.software.rpg.map-maker]]\n- similar: [[prdct.Dungeon-Draft]]\n- creator: @megasploot\n- supports: [[prdct.universal-vtt]]","n":0.354}}},{"i":1859,"$":{"0":{"v":"Wolverine","n":1},"1":{"v":"\n- [[c.software.message-bus]]\n- url: https://wolverine.netlify.app/\n- similar_to: [[prdct.masstransit]]\n- requires: [[prdct.lamar]] [[prdct.oakton]]\n- [[p.workedWith]] [[prdct.marten]]\n- [[p.supports]] [[prdct.rabbitimq]]\n\n## Description\n\n- Wolverine is a framework built around the idea of message processing where “messages” could be coming from inline invocation like MediatR or local in process queues or external message brokers through asynchronous messaging ala the much older MassTransit or NServiceBus frameworks.\n- Wolverine was largely rescued off the scrap heap and completely rebooted specifically to work in conjunction with Marten as a full blow event driven architecture stack.\n\n## Features\n\n- the message handlers are found by default through naming conventions. But if you hate that, no worries, there are options to use much more explicit approaches.\n  - Wolverine happily lets you eschew any of the conventional magic and write explicit code where you would be completely in charge of all the EF Core usage. The importance of being able to immediately bypass any conventions and drop into explicit code as needed was an important takeaway from my earlier FubuMVC failure.\n\n## Issues\n\n- Some folks complain that Wolverine forces you to use Lamar as the DI container for your application, but doing so enabled Wolverine to do the codegen the way that it is.\n  - \"the fasted DI container is “no DI container”\"\n\n## Resources\n\n- https://www.dotnetrocks.com/details/1823\n\n## References\n\n- https://jeremydmiller.com/2024/02/15/answering-some-concerns-about-wolverine/\n  - ","n":0.069}}},{"i":1860,"$":{"0":{"v":"Wolf Ecs","n":0.707},"1":{"v":"\n- dead\n- repo: https://github.com/EnderShadow8/wolf-ecs","n":0.5}}},{"i":1861,"$":{"0":{"v":"Windy App","n":0.707},"1":{"v":"\n- https://windy.app/","n":0.707}}},{"i":1862,"$":{"0":{"v":"Windmill","n":1},"1":{"v":"\n- https://www.windmill.dev/\n\n\n## Issues\n\n- free self-hosted version doesn't support github syncing","n":0.316}}},{"i":1863,"$":{"0":{"v":"Wildlife Ontology Wo","n":0.577},"1":{"v":"\n- https://www.bbc.co.uk/ontologies/wildlife-ontology/","n":0.707}}},{"i":1864,"$":{"0":{"v":"Wilco","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://www.trywilco.com/\n","n":0.577}}},{"i":1865,"$":{"0":{"v":"Wikidata","n":1},"1":{"v":"\n\n## Qualifiers\n\n\"Statements can also be expanded upon, annotated, or contextualized with the addition of value optionals (qualifiers, references, and rank). The core part of a statement without references and ranks is also called claim.\"\n\n### Snaks\n\n- \"A claim without qualifiers is also referred to as snak.\"\n","n":0.149}}},{"i":1866,"$":{"0":{"v":"Wikibase","n":1},"1":{"v":"\n\n\n2021-12-07 21:24\n\n- has [[c.datamodel]] \n  - [[p.hasURL]] https://www.mediawiki.org/wiki/Wikibase/DataModel\n  - Item:: \"thing\" represented  \n    - \"Wikidata Item for Berlin would represent the thing that the Wikipedia article is about, not the Wikipedia article itself.  For example, the size of Berlin is very different from the size of the Wikipedia page, and Wikidata only aims at collecting the former, not the latter\"\n      - graphdown should be able to collect both \n","n":0.12}}},{"i":1867,"$":{"0":{"v":"Widoco","n":1},"1":{"v":"\n- [[c.software.semantic.publishing.site-generator]]\n- url: https://dgarijo.github.io/Widoco/\n- depends_on: [[prdct.lode]]\n- similar: [[prdct.parrot]] \n\n## Demo\n\n- https://dgarijo.github.io/Widoco/doc/gallery/index.html\n- https://fair-impact.github.io/MOD/index-en.html#Thesaurus\n\n## Issues\n\n","n":0.277}}},{"i":1868,"$":{"0":{"v":"Wicket","n":1},"1":{"v":"\n\n## Alternatives\n\n- Wicket is not the only component oriented framework available in the Java ecosystem. Among its competitors we can find [[prdct.gwt]] (from Google), [[prdct.jsf]] (from Oracle), [[prdct.vaadin]] (from Vaadin Ltd.)","n":0.18}}},{"i":1869,"$":{"0":{"v":"Whole","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n- #dead since 2020.11.16\n- url: https://whole.sourceforge.io/\n- ","n":0.378}}},{"i":1870,"$":{"0":{"v":"Westwind Scripting","n":0.707},"1":{"v":"\n- [[c.software.library.metaprogramming]]\n- repo: https://github.com/RickStrahl/Westwind.Scripting","n":0.5}}},{"i":1871,"$":{"0":{"v":"Webviz","n":1}}},{"i":1872,"$":{"0":{"v":"WebTransport","n":1},"1":{"v":"\n## References\n\n- https://socket.io/get-started/webtransport","n":0.577}}},{"i":1873,"$":{"0":{"v":"Websubhub","n":1},"1":{"v":"\n- dead\n- https://websubhub.com/\n- repo: https://github.com/clone1018/WebSubHub\n- written-in: elixir\n- ","n":0.378}}},{"i":1874,"$":{"0":{"v":"WebSub","n":1},"1":{"v":"\n- url: https://www.w3.org/TR/websub/\n\n## Similar \n- [[prdct.websub]] [[t.cs.web.webhooks]] [[prdct.linked-data-notifications]]\n\n## Implementations\n\n- [[prdct.websubhub]]\n\n## Issues\n\n- \"Hubs push the contents to all the subscribers who have subscribed to the topics and publishers share their content with Hubs, so here publishers and subscribers are completely unknown to each other. Private information shared by publishers may reach hundreds of unknown subscribers.\"\n  - t.2024.05.02.06 but really, isn't that true of all pubsub messaging? \n\n## Comparison\n\n### WebSub vs Mercure\n\n- WebSub is a server-to-server only protocol, while Mercure is also a server-to-client and client-to-client protocol.\n\n- Mercure has been heavily inspired by WebSub, and we tried to make the protocol as close as possible from the WebSub one.\n\n- Mercure uses Server-Sent Events to dispatch the updates, while WebSub use POST requests. Also, Mercure has an advanced authorization mechanism, and allows to subscribe to several topics with only one connection using URI templates.\n\n## WebSub vs Linked Data Notification\n\n-   **WebSub:**\n    \n    -   Prioritize simplicity and established usage.\n    -   Need immediate distribution of content updates without a focus on detailed structure.\n    -   Primarily concerned with human-readable content.\n    \n-   **LDN:**\n    -   Require structured notifications that can be easily integrated with other Semantic Web systems.\n    -   Want notifications themselves discoverable and queryable.\n    -   Machine interpretability is a strong requirement.\n\n## References\n\n- https://ably.com/topic/websub\n- https://ayesh9303.medium.com/learning-websub-part-1-introduction-to-websub-94ee99a09a70\n- https://mercure.rocks/docs/spec/faq","n":0.07}}},{"i":1875,"$":{"0":{"v":"Webstrates","n":1},"1":{"v":"\n- dead\n- url: https://webstrates.net/\n- written_in: javascript\n- repo: https://github.com/Webstrates/Webstrates\n- depends_on: [[prdct.sharedb]]\n\n## Description\n\n- \"This mechanism can be used to create sophisticated web applications where there basically is no server logic beyond synchronizing and storing data.\"\n\n## Resources\n\n- https://webstrates.net/project/a-brief-overview/","n":0.169}}},{"i":1876,"$":{"0":{"v":"Websocket","n":1}}},{"i":1877,"$":{"0":{"v":"Webrtc","n":1},"1":{"v":"\n## Resources\n\n- [SFU, MCU, or P2P: What’s the Difference Between These WebRTC Architectures?](https://getstream.io/blog/what-is-a-selective-forwarding-unit-in-webrtc/)","n":0.277}}},{"i":1878,"$":{"0":{"v":"Webrpc","n":1},"1":{"v":"\n\n\n- [[p.inspiredBy]] [[prdct.grpc]] [[prdct.twirp]]\n- [[p.hasRepository]] https://github.com/webrpc/webrpc\n- [[p.hasRelatedSolution]] https://github.com/petomalina/xrpc\n","n":0.354}}},{"i":1879,"$":{"0":{"v":"Webidl","n":1},"1":{"v":"\n\n## References\n\n- https://developer.mozilla.org/en-US/docs/Glossary/WebIDL","n":0.577}}},{"i":1880,"$":{"0":{"v":"Webgpu","n":1}}},{"i":1881,"$":{"0":{"v":"Webfinger","n":1},"1":{"v":"\n- https://swicg.github.io/activitypub-webfinger/\n- ","n":0.707}}},{"i":1882,"$":{"0":{"v":"Webcontainers","n":1},"1":{"v":"\nrepo: https://github.com/stackblitz/webcontainer-core\n\n\n\n## [[p.hasLearningResource]]\n\n- https://blog.logrocket.com/stackblitz-webcontainers-nextjs-browser/","n":0.5}}},{"i":1883,"$":{"0":{"v":"Webaverse","n":1},"1":{"v":"\n- #dead ?\n- repo: https://github.com/webaverse-studios/webaverse\n- written-in: #c++\n- [[p.used]] [[prdct.three-js]]","n":0.333}}},{"i":1884,"$":{"0":{"v":"WebAssembly","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] wasm\n","n":0.577}}},{"i":1885,"$":{"0":{"v":"WebAC","n":1},"1":{"v":"\n- spec: https://solid.github.io/web-access-control-spec/\n- related: [[prdct.fedora]]\n\n## features:\n\n- The resources are identified by URLs, and can refer to any web documents or resources.\n- It is declarative -- access control policies live in regular web documents, which can be exported/backed easily, using the same mechanism as you would for backing up the rest of your data.\n- Users and groups are also identified by URLs (specifically, by WebIDs)\n- It is cross-domain -- all of its components, such as resources, agent WebIDs, and even the documents containing the access control policies, can potentially reside on separate domains. In other words, you can give access to a resource on one site to users and groups hosted on another site.","n":0.094}}},{"i":1886,"$":{"0":{"v":"Web Push","n":0.707},"1":{"v":"\n- https://developer.mozilla.org/en-US/docs/Web/API/Push_API\n\n\n## Description\n\n- For an app to receive push messages, it has to have an active service worker. When the service worker is active, it can subscribe to push notifications, using PushManager.subscribe().","n":0.177}}},{"i":1887,"$":{"0":{"v":"Web Annotations","n":0.707},"1":{"v":"\n- https://www.w3.org/TR/annotation-model/","n":0.707}}},{"i":1888,"$":{"0":{"v":"WeaKG-MF","n":1},"1":{"v":"\n\n## References\n\n- [[ar.weakg-mf-a-knowledge-graph-of-observational-weather-data]]","n":0.577}}},{"i":1889,"$":{"0":{"v":"Wayne","n":1},"1":{"v":"\nrepo: https://github.com/jcubic/wayne\n#demo https://jcubic.github.io/wayne/demo/\n  - #broken","n":0.447}}},{"i":1890,"$":{"0":{"v":"Watson","n":1},"1":{"v":"\nhttps://kmi.open.ac.uk/technologies/name/watson/\n- [[c.software.semantic.search-engine]]\n\n## Features\n\n- 1) collects the available semantic content on the Web, \n- 2) analyzes it to extract useful metadata and indexes, \n- 3) implements efficient query facilities to access these data","n":0.177}}},{"i":1891,"$":{"0":{"v":"Watermelondb","n":1},"1":{"v":"\n- repo: https://github.com/Nozbe/WatermelonDB\n- [[p.supports]] [[prdct.react]] [[prdct.react.native]]","n":0.408}}},{"i":1892,"$":{"0":{"v":"Waterfowl","n":1},"1":{"v":"\n- vapor?\n\n## References\n\n- [[ar.water-fowl-a-compact-self-indexed-rdf-store-with-inference-enabled-dictionaries]]","n":0.5}}},{"i":1893,"$":{"0":{"v":"Wasmtime","n":1},"1":{"v":"\n- repo: https://github.com/bytecodealliance/wasmtime\n\n## [[p.supports]]\n\n-   **[Rust](https://bytecodealliance.github.io/wasmtime/lang-rust.html)** - the [`wasmtime` crate](https://crates.io/crates/wasmtime)\n-   **[C](https://bytecodealliance.github.io/wasmtime/examples-c-embed.html)** - the [`wasm.h`, `wasi.h`, and `wasmtime.h` headers](https://bytecodealliance.github.io/wasmtime/c-api/), [CMake](https://github.com/bytecodealliance/wasmtime/blob/main/crates/c-api/CMakeLists.txt) or [`wasmtime` Conan package](https://conan.io/center/wasmtime)\n-   **C++** - the [`wasmtime-cpp` repository](https://github.com/bytecodealliance/wasmtime-cpp) or use [`wasmtime-cpp` Conan package](https://conan.io/center/wasmtime-cpp)\n-   **[Python](https://bytecodealliance.github.io/wasmtime/lang-python.html)** - the [`wasmtime` PyPI package](https://pypi.org/project/wasmtime/)\n-   **[.NET](https://bytecodealliance.github.io/wasmtime/lang-dotnet.html)** - the [`Wasmtime` NuGet package](https://www.nuget.org/packages/Wasmtime)\n-   **[Go](https://bytecodealliance.github.io/wasmtime/lang-go.html)** - the [`wasmtime-go` repository](https://pkg.go.dev/github.com/bytecodealliance/wasmtime-go)\n-   **[Ruby](https://bytecodealliance.github.io/wasmtime/lang-ruby.html)** - the [`wasmtime` gem](https://rubygems.org/gems/wasmtime)","n":0.136}}},{"i":1894,"$":{"0":{"v":"Wasm","n":1},"1":{"v":"\n- url: https://webassembly.org/\n- [[p.isRelated]] [[prdct.wasi]]\n\n## Goals\n\n- One of WebAssembly (and Wasmtime's) main goals is to execute untrusted code in a safe manner inside of a sandbox.\n","n":0.196}}},{"i":1895,"$":{"0":{"v":"Wasi","n":1},"1":{"v":"\n- url: https://wasi.dev/\n- [[c.implementation]] [[prdct.wasmtime]]","n":0.447}}},{"i":1896,"$":{"0":{"v":"Wart Layers","n":0.707},"1":{"v":"http://akkartik.name/post/wart-layers","n":1}}},{"i":1897,"$":{"0":{"v":"Warpstream","n":1},"1":{"v":"\n- https://www.warpstream.com/\n- related: [[prdct.kafka]] [[prdct.aws.s3]]\n- ","n":0.447}}},{"i":1898,"$":{"0":{"v":"Wardley Maps","n":0.707},"1":{"v":"\n## Resources\n\n### [[On Being Lost|https://medium.com/wardleymaps/on-being-lost-2ef5f05eb1ec]]\n\nSun Tzu’s five factors are:\n\n**Purpose** is your moral imperative, it is the scope of what you are doing and why you are doing it. It is the reason why others follow you.\n\n**Landscape** is a description of the environment that you’re competing in. It includes the position of troops, the features of the landscape and any obstacles in your way.\n\n**Climate** describes the forces that act upon the environment. It is the patterns of the seasons and the rules of the game. These impact the landscape and you don’t get to choose them but you can discover them. It includes your competitors actions.\n\n**Doctrine** is the training of your forces, the standard ways of operating and the techniques that you almost always apply. These are the universal principles, the set of beliefs that appear to work regardless of the landscape that is faced.\n\n**Leadership** is about the strategy that you choose considering your purpose, the landscape, the climate and your capabilities. It is to “the battle at hand”. It is context specific i.e. these techniques are known to depend upon the landscape and your purpose.","n":0.074}}},{"i":1899,"$":{"0":{"v":"Walnats","n":1},"1":{"v":"\n- repo: https://github.com/orsinium-labs/walnats\n- written-in: python","n":0.447}}},{"i":1900,"$":{"0":{"v":"W3id","n":1},"1":{"v":"\n- url: https://w3id.org/\n- similar: \n  - [[prdct.w3id]] [[prdct.purl]] [[prdct.prefix-cc]] [[prdct.obolibrary]]  ^985zh371a5ph","n":0.302}}},{"i":1901,"$":{"0":{"v":"Vvvv","n":1},"1":{"v":"\n- [[c.software.live-programming]]\n- url: https://visualprogramming.net/\n- [[p.builtOn]] [[prdct.stride3d]]\n\n## Features\n\n- vvvv programs are compiled and run on the .NET virtual machine. As such they are as fast as if you’d write them in C#.\n  - Modify your program while it is running, compilation happens in the background.\n- vvvv can be extended with custom nodes written in pure C#. No proprietary plugin-wrapping boilerplate code is needed.","n":0.127}}},{"i":1902,"$":{"0":{"v":"Vue","n":1},"1":{"v":"\nurl: https://vuejs.org/\n\n\n## Pros\n\n- \"Vue combines the best of Angular, with the best of React and the healthiest, most farsighted community. Especially with vue3, everything just freaking works. DX is phenomenal and rapid. Every primitive I've needed, as well as assisting utils, to build from 500+ cmp corporate apps to ~20 cmp internal apps is there, opinionated, boilerplate-free, ready for me to convert ideas into results with little in-between. Performance is the default with little to no footguns. Spectacular docs. There's the official, robust, helpful linter config and style guide. Has the cleanest reactivity model based on native js primitives (Proxy API). Has spawned the best build tooling (vite) and were cool and smart enough to colab with everyone, \"competitors\" or not, to help them switch to it too (!). Has spawned the best testing tooling (vitest), 10x better than anything before it, and again working with the community to make it usable for all and migration a breeze.\"","n":0.08}}},{"i":1903,"$":{"0":{"v":"Vtrdf Valid Time Rdf","n":0.5},"1":{"v":"\n## Issues\n","n":0.707}}},{"i":1904,"$":{"0":{"v":"VSCode","n":1},"1":{"v":"\n- https://code.visualstudio.com/\n- [[c.software.ide]] [[c.software.text-editor]]\n\n## tips\n\n- \"join lines\" when copying from pdf\n\n## Issues\n\n- Why doesn't vscode have underlined shortcut accelerator keys in context menus? \n\n## Wanted\n\n- [[wanted.vscode-frontmatter-single-quote-warning]]\n\n## Resources\n\n- [Writing a Visual Studio Code Completion Provider](https://blog.dendron.so/notes/IThOx1Oag1r0JAglpiDLp/)  ^xgE2QepxX0Cy\n","n":0.169}}},{"i":1905,"$":{"0":{"v":"Webview UI Toolkit","n":0.577},"1":{"v":"\n\n\n## Resources\n\n- [release party](https://www.youtube.com/watch?v=G4jjCN8uQAg&t=858s)\n","n":0.5}}},{"i":1906,"$":{"0":{"v":"djradon‘s vscode keybindings","n":0.577},"1":{"v":"\n\n\nKeep getting overwritten by Settings Sync!\n\n\n```\n// Place your key bindings in this file to override the defaults\n[\n    {\n        \"key\": \"ctrl+;\",\n        \"command\": \"workbench.action.terminal.focus\"\n    },\n    {\n        \"key\": \"ctrl+;\",\n        \"command\": \"workbench.action.focusActiveEditorGroup\",\n        \"when\": \"terminalFocus\"\n    },\n    {\n        \"key\": \"ctrl+shift+v\",\n        \"command\": \"-markdown.showPreview\",\n        \"when\": \"!notebookEditorFocused && editorLangId == 'markdown'\"\n    },\n    {\n        \"key\": \"ctrl+shift+v\",\n        \"command\": \"dendron.showPreviewV2\",\n        \"when\": \"!notebookEditorFocused && editorLangId == 'markdown'\"\n    },\n    {\n        \"key\": \"ctrl+k\",\n        \"command\": \"dendron.insertNoteLink\"\n    },\n    {\n        \"key\": \"ctrl+'\",\n        \"command\": \"dendron.gotoNote\",\n        \"when\": \"editorFocus\"\n    },\n    {\n        \"key\": \"ctrl+enter\",\n        \"command\": \"-dendron.gotoNote\",\n        \"when\": \"editorFocus\"\n    },\n    {\n        \"key\": \"ctrl+m\",\n        \"command\": \"-markdown.extension.editing.toggleMath\",\n        \"when\": \"editorTextFocus && !editorReadonly && editorLangId == 'markdown'\"\n    },\n    {\n        \"key\": \"ctrl+m\",\n        \"command\": \"-editor.action.toggleTabFocusMode\"\n    },\n    {\n        \"key\": \"ctrl+m\",\n        \"command\": \"dendron.moveNote\",\n        \"when\": \"editorLangId == 'markdown'\"\n\n    }\n]\n```\n","n":0.097}}},{"i":1907,"$":{"0":{"v":"vscode.dev","n":1},"1":{"v":"\n\n\n- [[hasAnnouncement]] https://code.visualstudio.com/blogs/2021/10/20/vscode-dev 2021-10-20\n  - [[p.hasHighlight]] \n    - the CodeTour extension lets you create guided walkthroughs of a code base and the WikiLens extension turns VS Code and your repository into a powerful note taking tool (with bi-directional linking). To make it easy to access your code in GitHub, VS Code for the Web comes with the GitHub Repositories, Codespaces, and Pull Request extensions built in. You can make quick edits, review PRs, and Continue on to a local clone or even better, to a GitHub Codespace\n    - vscode.dev URLs are a powerful way for us to deliver new, lightweight experiences\n    - Live Share guest sessions will also be available in the browser through the https://vscode.dev/liveshare\n    - the CodeTour extension lets you create guided walkthroughs of a code base and the [[prdct.wikilens]] turns VS Code and your repository into a powerful note taking tool\n","n":0.083}}},{"i":1908,"$":{"0":{"v":"Vscode Reveal","n":0.707},"1":{"v":"\n- [[p.hasURL]] https://marketplace.visualstudio.com/items?itemName=evilz.vscode-reveal\n","n":0.577}}},{"i":1909,"$":{"0":{"v":"Demo","n":1},"1":{"v":"\n---\ntheme : \"night\"\ntransition: \"slide\nTheme: \"monokai\"\nlogoImg: \"logo.png\"\nslideNumber: false\ntitle: \"VSCode Reveal intro\"\n---\n\n::: block\n*here be dragons* {style=background:red;width:500px}\n::: \n\n---\n\n// @[vine](etVpwB7uHlw)\n\n---\n\n### Solar System Exploration, 1950s – 1960s\n\n- [ ] Mercury\n- [x] Venus\n- [x] Earth (Orbit/Moon)\n- [x] Mars\n- [ ] Jupiter\n- [ ] Saturn\n- [ ] Uranus\n- [ ] Neptune\n- [ ] Comet Haley\n\n---\n\n# some Table\n\n|             |          Grouping           ||\nFirst Header  | Second Header | Third Header |\n ------------ | :-----------: | -----------: |\nContent       |          *Long Cell*        ||\nContent       |   **Cell**    |         Cell |\n                                              \nNew section   |     More      |         Data |\nAnd more      | With an escaped '\\\\|'       ||\n[Prototype table]                             \n\n--\n\nFirst header | Second header\n-------------|---------------\nList:        | More  \\\n- over       | data  \\\n- several    |       \\\n- lines      | \n\n--\n\nFirst header | Second header\n-------------|---------------\nMerged       | Cell 1\n^^           | Cell 2\n^^           | Cell 3\n\n--\n\n\n\n---\n\n<div class=\"mermaid\">\nsequenceDiagram\n    participant Alice\n    participant Bob \n    Alice->>John: Hello John, how are you?\n    loop Healthcheck\n        John->>John: Fight against hypochondria\n    end\n    Note right of John: Rational thoughts <br/>prevail!\n    John-->>Alice: Great!\n    John->>Bob: How about you?\n    Bob-->>John: Jolly good!\n</div> \n\n---\n\n<div class=\"mermaid\">\ngraph LR;\n  A(AAAA)==> B(B node);\n  B==> C(SEE SEE);\n\n  class A diag-a-styles;\n  class B diag-b-styles\n  class C diag-c-styles;\n</div>\n\n---\n\n# vscode-reveal\n\n Awesome VS code extension using The HTML Presentation Framework Revealjs\n\n<small>Created by [Vincent B.](https://www.evilznet.com) / [@Evilznet](https://twitter.com/Evilznet)</small>\n\n---\n\n## Hello There\n\nreveal.js enables you to create beautiful interactive slide decks using HTML. This presentation will show you examples of what it can do.\n\n---\n\n## Vertical Slides\n\nSlides can be nested inside of each other.\n\nUse the _Space_ key to navigate through all slides.\n\n<a href=\"#\" class=\"navigate-down\">\n    <img width=\"178\" height=\"238\" data-src=\"https://s3.amazonaws.com/hakim-static/reveal-js/arrow.png\" alt=\"Down arrow\">\n</a>\n\n--\n\n## Basement Level 1\n\nNested slides are useful for adding additional detail underneath a high level horizontal slide.\n\n--\n\n## Basement Level 2\n\nThat's it, time to go back up.\n\n<a href=\"#/2\">\n    <img width=\"178\" height=\"238\" data-src=\"https://s3.amazonaws.com/hakim-static/reveal-js/arrow.png\" alt=\"Up arrow\" style=\"transform: rotate(180deg); -webkit-transform: rotate(180deg);\">\n</a>\n\n---\n\n## Point of View\n\nPress **ESC** to enter the slide overview.\n\nHold down alt and click on any element to zoom in on it using [zoom.js](http://lab.hakim.se/zoom-js). Alt + click anywhere to zoom back out.\n\n> Use ctrl + click in Linux\n\n---\n\n## Touch Optimized\n\nPresentations look great on touch devices, like mobile phones and tablets. Simply swipe through your slides.\n\n---\n\n## Markdown support\n\n```\n  ## Markdown support\n\n  Write content using inline or external Markdown.\n  Instructions and more info available in the \n  [readme](https://github.com/hakimel/reveal.js#markdown).\n```\n\n---\n\n## Fragments\n\nHit the next arrow...\n\n... to step through ...\n<span class=\"fragment\">... a</span> <span class=\"fragment\">fragmented</span> <span class=\"fragment\">slide.</span>\n\nNote:\nThis slide has fragments which are also stepped through in the notes window.\n\n--\n\n## Fragment Styles\n\nThere's different types of fragments, like:\n\ngrow {.fragment .grow}\n\nshrink {.fragment .shrink}\n\nfade-out {.fragment .fade-out}\n\nfade-right{.fragment .fade-right}\n\nfade-up{.fragment .fade-up}\n\nfade-down{.fragment .fade-down}\n\nfade-left{.fragment .fade-left}\n\n--\n\n## Fragment Styles\n\nfade-in-then-out{.fragment .fade-in-then-out}\n\nfade-in-then-semi-out {.fragment .fade-in-then-semi-out\"}\n\ncurrent-visible {.fragment .current-visible}\n## Highlight **red**{.fragment .highlight-red} **blue**{.fragment .highlight-blue} **green**{.fragment .highlight-green}\n\n---\n\n## Transition Styles\n\nYou can select from different transitions, like:\n[None](?transition=none#/transitions) - [Fade](?transition=fade#/transitions) - [Slide](?transition=slide#/transitions) - [Convex](?transition=convex#/transitions) - [Concave](?transition=concave#/transitions) - [Zoom](?transition=zoom#/transitions)\n\n---\n\n## Themes\n\nreveal.js comes with a few themes built in:\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/black.css'); return false;\">Black (default)</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/white.css'); return false;\">White</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/league.css'); return false;\">League</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/sky.css'); return false;\">Sky</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/beige.css'); return false;\">Beige</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/simple.css'); return false;\">Simple</a> <br>\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/serif.css'); return false;\">Serif</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/blood.css'); return false;\">Blood</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/night.css'); return false;\">Night</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/moon.css'); return false;\">Moon</a> -\n<a href=\"#\" onclick=\"document.getElementById('theme').setAttribute('href','libs/reveal.js/3.8.0/css/theme/solarized.css'); return false;\">Solarized</a>\n\n---\n\n<!-- .slide: data-background=\"#dddddd\" -->\n## Slide Backgrounds\n\nSet `data-background=\"#dddddd\"` on a slide to change the background color. All CSS color formats are supported.\n\n[![Down arrow](https://s3.amazonaws.com/hakim-static/reveal-js/arrow.png =178x238)](#){.navigate-down}\n\n\n--\n\n<!-- .slide: data-background=\"default-thumbnail.jpg\" -->\n\n## Image Backgrounds\n\n```markdown\n<!-- .slide: data-background=\"default-thumbnail.jpg\" -->\n```\n\n--\n\n<!-- .slide: data-background=\"default-thumbnail.jpg\" data-background-repeat=\"repeat\" data-background-size=\"100px\" -->\n\n## TILED BACKGROUNDS\n\n```markdown\n<!-- .slide: data-background=\"default-thumbnail.jpg\" data-background-repeat=\"repeat\" data-background-size=\"100px\" -->\n```\n\n--\n\n<!-- .slide: data-background-video=\"https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.mp4,https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.webm\" data-background-color=\"#000000\" -->\n\n## Video Backgrounds\n\n```markdown\n<!-- .slide: data-background-video=\"https://upload.wikimedia.org/wikipedia/commons/transcoded/c/c0/Big_Buck_Bunny_4K.webm/Big_Buck_Bunny_4K.webm.480p.vp9.webm\" data-background-color=\"#000000\" -->\n```\n\n--\n\n<!-- .slide: data-background=\"http://i.giphy.com/90F8aUepslB84.gif\" -->\n\n## ... and GIFs!\n\n```markdown\n<!-- .slide: data-background=\"http://i.giphy.com/90F8aUepslB84.gif\" -->\n```\n\n---\n\n<!-- .slide: data-transition=\"slide\" data-background=\"#4d7e65\" data-background-transition=\"zoom\" -->\n\n## Background Transitions\n\nDifferent background transitions are available via the backgroundTransition option. This one's called \"zoom\".\n\n---\n\n<!-- .slide: data-transition=\"slide\" data-background=\"#b5533c\" data-background-transition=\"zoom\" -->\n\n## Background Transitions\n\nYou can override background transitions per-slide.\n\n---\n\n## Pretty Code\n\n```js\nfunction linkify( selector ) {\n  if( supports3DTransforms ) {\n\n    var nodes = document.querySelectorAll( selector );\n\n    for( var i = 0, len = nodes.length; i &lt; len; i++ ) {\n      var node = nodes[i];\n\n      if( !node.className ) {\n        node.className += ' roll';\n      }\n    }\n  }\n}\n```\n\nCode syntax highlighting courtesy of [highlight.js](http://softwaremaniacs.org/soft/highlight/en/description/).\n\n---\n\n## Marvelous List\n\n*   No order here\n*   Or here\n*   Or here\n*   Or here\n\n---\n\n## Fantastic Ordered List\n\n1.  One is smaller than...\n2.  Two is smaller than...\n3.  Three!\n\n---\n\n## Tabular Tables\n\n| Tables        | Are           | Cool  |\n|-------------|:-----------:|----:|\n| col 3 is      | right-aligned | $1600 |\n| col 2 is      | centered      | $12   |\n| zebra stripes | are neat      | $1    |\n\n---\n\n{.slide id=\"ClevQuot\"}\n## Clever Quotes\n\nThese guys come in two forms, inline: <q cite=\"http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations\">\"The nice thing about standards is that there are so many to choose from\"</q> and block:\n\n> \"For years there has been a theory that millions of monkeys typing at random on millions of typewriters would reproduce the entire works of Shakespeare. The Internet has proven this theory to be untrue.\"\n\n---\n\n## Intergalactic Interconnections\n\nYou can link between slides internally, [like this](#/2/3).\n\nLink to slides by an ID, e.g., [Clever Quotes](#ClevQuot).  \nHowever, you must have set the ID at the destination slide using:  \n`{.slide id=\"UniqueID\"}`\n\n---\n\n## Speaker View\n\nThere's a [speaker view](https://github.com/hakimel/reveal.js#speaker-notes). It includes a timer, preview of the upcoming slide as well as your speaker notes.\n\nPress the _S_ key to try it out.\n\n<aside class=\"notes\">Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open the speaker notes window (hit 's' on your keyboard).</aside>\n\n---\n\n## Export to PDF\n\nPresentations can be [exported to PDF](https://github.com/hakimel/reveal.js#pdf-export), here's an example:\n\n<iframe data-src=\"https://www.slideshare.net/slideshow/embed_code/42840540\" width=\"445\" height=\"355\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:3px solid #666; margin-bottom:5px; max-width: 100%;\" allowfullscreen=\"\"></iframe>\n\n---\n\n## Global State\n\nSet `data-state=\"something\"` on a slide and `\"something\"` will be added as a class to the document element when the slide is open. This lets you apply broader style changes, like switching the page background.\n\n---\n\n<!-- .slide: data-state=\"customevent\" -->\n\n## State Events\n\nAdditionally custom events can be triggered on a per slide basis by binding to the `data-state` name.\n```js\nReveal.addEventListener( 'customevent', function() {\n\tconsole.log( '\"customevent\" has fired' );\n} );\n```\n\n---\n\n## Take a Moment\n\nPress B or . on your keyboard to pause the presentation. This is helpful when you're on stage and want to take distracting slides off the screen.\n\n---\n\n## Much more\n\n*   Right-to-left support\n*   [Extensive JavaScript API](https://github.com/hakimel/reveal.js#api)\n*   [Auto-progression](https://github.com/hakimel/reveal.js#auto-sliding)\n*   [Parallax backgrounds](https://github.com/hakimel/reveal.js#parallax-background)\n*   [Custom keyboard bindings](https://github.com/hakimel/reveal.js#keyboard-bindings)\n\n---\n\n## Plugins\n\n--\n\n## search\n\nHandles finding a text string anywhere in the slides and showing the next occurrence to the user by navigatating to that slide and highlighting it.\n\n**Shortcut : `CTRL + SHIFT + F`**\n\n\n--\n\n## Zoom\n\nZoom anywhere on your presentation\n\n**Shortcut : `alt + click`: Zoom in. Repeat to zoom back out.**\n\n--\n\n## Notes\n\nAdd note to speaker view.\n\nDefault markdown syntaxe is\n\n```text\nnote: a custom note here\n```\n\n--\n\n## Chalkboard\n\nHave you ever missed the traditional classroom experience where you can quickly sketch something on a chalkboard?\n\nJust press 'b' or click on the pencil button to open and close your chalkboard.\n\n--\n\n## Chalkboard\n\n- Click the `left mouse button` to write on the chalkboard\n- Click the `right mouse button` to wipe the chalkboard\n- Click the `DEL` key to clear the chalkboard\n\n--\n\n## MAKE NOTES ON SLIDES\n\nDid you notice the <i class=\"fa fa-pencil\"></i> button?\n\nBy pressing 'c' or clicking the button you can start and stop the notes taking mode allowing you to write comments and notes directly on the slide.\n\n--\n\n## Chart\n\nAdd chart from simple string\n\n--\n\n### Line chart from JSON string\n<canvas class=\"stretch\" data-chart=\"line\">\n<!--\n{\n \"data\": {\n  \"labels\": [\"January\",\" February\",\" March\",\" April\",\" May\",\" June\",\" July\"],\n  \"datasets\":[\n   {\n    \"data\":[65,59,80,81,56,55,40],\n    \"label\":\"My first dataset\",\"backgroundColor\":\"rgba(120,120,255,.8)\"\n   },\n   {\n    \"data\":[28,48,40,19,86,27,90],\n    \"label\":\"My second dataset\",\"backgroundColor\":\"rgba(255,120,120,.8)\"\n   }\n  ]\n }, \n \"options\": { \"responsive\": true }\n}\n-->\n</canvas>\n\n--\n\n### Line chart with CSV data and JSON configuration\n\n<canvas class=\"stretch\" data-chart=\"line\">\nMy first dataset,  65, 59, 80, 81, 56, 55, 40\n<!-- This is a comment -->\nMy second dataset, 28, 48, 40, 19, 86, 27, 90\n<!-- \n{ \n\"data\" : {\n\t\"labels\" : [\"Enero\", \"Febrero\", \"Marzo\", \"Avril\", \"Mayo\", \"Junio\", \"Julio\"],\n\t\"datasets\" : [{ \"borderColor\": \"#0f0\", \"borderDash\": [\"5\",\"10\"] }, { \"borderColor\": \"#0ff\" } ]\n\t}\n}\n-->\n</canvas>\n\n--\n\n### Bar chart with CSV data\n\n<canvas class=\"stretch\" data-chart=\"bar\">\n,January, February, March, April, May, June, July\nMy first dataset, 65, 59, 80, 81, 56, 55, 40\nMy second dataset, 28, 48, 40, 19, 86, 27, 90\n</canvas>\n\n--\n\n<!-- .slide: data-background=\"#aaaaaa\" -->\n### Stacked bar chart from CSV file with JSON configuration\n<!-- By default, chart axes don't \"beginAtZero\", so set it to true below -->\n<!-- Hover events are broken inside reveal https://github.com/chartjs/Chart.js/issues/7178 so \"events\" : [\"\"] turns it off-->\n<canvas class=\"stretch\" data-chart=\"bar\" data-chart-src=\"https://rajgoel.github.io/reveal.js-demos/chart/data.csv\">\n<!-- \n{\n  \"data\" : {\n    \"datasets\" : [\n      {\"backgroundColor\": \"#0f0\"}, \n      {\"backgroundColor\": \"#0ff\" }\n    ]\n  },\n  \"options\": {\n    \"events\": [\"\"],\n    \"animation\": {\"easing\": \"easeOutElastic\"},\n    \"legend\": {\n      \"display\": true,\n      \"labels\": {\n        \"fontColor\": \"rgb(200, 0, 0)\"\n      }\n    },\n    \"responsive\": true, \n    \"scales\": { \n      \"xAxes\": [{\n        \"ticks\": {\n          \"fontColor\" : \"rgba(100,100,255,.8)\"\n        },\n        \"gridLines\" : {\n          \"color\" : \"rgba(100,100,255,.8)\",\n          \"zeroLineColor\": \"transparent\"\n        },\n        \"stacked\": true\n        }],\n      \"yAxes\": [{\n        \"ticks\": {\n          \"beginAtZero\": true,\n          \"fontColor\" : \"rgba(100,100,255,.8)\"\n        },\n        \"stacked\": true,\n        \"gridLines\" : {\n          \"color\" : \"rgba(100,100,255,.8)\",\n          \"zeroLineColor\": \"transparent\"\n        }\n      }] \n    }\n  }\n}\n-->\n</canvas>\n\n--\n\n### Pie chart\n\n<canvas class=\"stretch\" data-chart=\"pie\">\n,Black, Red, Green, Yellow\nMy first dataset, 40, 40, 20, 6\nMy second dataset, 45, 40, 25, 4\n</canvas>\n\n--\n\n## EMBEDDING A TWEET\nTo embed a tweet, simply determine its URL and include the following code in your slides:\n\n```html\n<div class=\"tweet\" data-src=\"TWEET_URL\"></div>\n```\n\n--\n\n<div class=\"tweet\"  data-src=\"https://twitter.com/Evilznet/status/1086984843056107525\"></div>\n\n--\n\n## menu\n\nA SLIDEOUT MENU FOR NAVIGATING REVEAL.JS PRESENTATIONS\n\n--\n\nSee the  <i class=\"fa fa-bars\"></i>  in the corner?\n\nClick it and the menu will open from the side.\n\nClick anywhere on the slide to return to the presentation,\nor use the close button in the menu.\n\n--\n\nIf you don't like the menu button,\nyou can use the slide number instead.\n\nGo on, give it a go.\n\nThe menu button can be hidden using the options, \nbut you need to enable the slide number link.\n\n--\n\nOr you can open the menu by pressing the m key.\n\nYou can navigate the menu with the keyboard as well. \nJust use the arrow keys and <space> or <enter> to change slides.\n\nYou can disable the keyboard for the \nmenu in the options if you wish.\n\n--\n\n## LEFT OR RIGHT\nYou can configure the menu to slide in from the left or right\n\n--\n\n### MARKERS\nThe slide markers in the menu can be useful to show \nyou the progress through the presentation.\n\nYou can hide them if you want.\n\nYou can also show/hide slide numbers.\n\n--\n\n### SLIDE TITLES\nThe menu uses the first heading to label each slide\nbut you can specify another label if you want.\n\nUse a data-menu-title attribute in the section element to give the slide a custom label, or add a menu-title class to any element in the slide you wish.\n\nYou can change the titleSelector option and use\nany elements you like as the default for labelling each slide.\n\n--\n\n## MathSVG\n\nAn extension of the math.js plugin allowing to render LaTeX in SVG.\n\n--\n\n### The Lorenz Equations\n\n<span>\n\\[\\begin{aligned}\n\\dot{x} &amp; = \\sigma(y-x) \\\\\n\\dot{y} &amp; = \\rho x - y - xz \\\\\n\\dot{z} &amp; = -\\beta z + xy\n\\end{aligned} \\]\n</span>\n\n--\n\n### The Cauchy-Schwarz Inequality\n\n<script type=\"math/tex; mode=display\">\n  \\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)\n</script>\n\n--\n\n### Custom footer\n\nIncludes a footer in all the slides of a Reveal.js presentation (with optional exclusion of some slides) that will show the title of the presentation.\n\n\n\n--\n\n## code-focus\n\nA plugin that allows focusing on specific lines of code blocks.\n\n--\n\n### Code Focus Demo\n\n\n```html\n<section>\n  <pre><code>\n  // Useless comment.\n  alert('hi');\n  </pre></code>\n  <p class=\"fragment\" data-code-focus=\"1\">\n    This focuses on the comment.\n  </p>\n  <p class=\"fragment\" data-code-focus=\"1-2\">\n    Another fragment.\n  </p>\n</section>\n```\n\nThis section is a slide. {.fragment .current-only data-code-focus=1-12}\n\nThis will be highlighted by `highlight.js`. {.fragment .current-only data-code-focus=2-5}\n\nThis fragment focuses on the first line. {.fragment .current-only data-code-focus=6-8}\n\nThis fragment focuses on lines 1 and 2. {.fragment .current-only data-code-focus=9-11}\n\nSee the next slide for a demo with the contents of this code block. {.fragment .current-only data-code-focus=1-12}\n\n---\n\n<!-- .slide: style=\"text-align: left;\" -->\n# THE END\n\n- [Try the online editor](http://slides.com)\n- [Source code & documentation](https://github.com/hakimel/reveal.js)\n","n":0.023}}},{"i":1910,"$":{"0":{"v":"vPenTest","n":1},"1":{"v":"\n- hosted in AWS\n- manual report available after two days\n- can do MITM attacks\n- pricing is based on IPs and then how often\n  - ![](/assets/images/2023-05-17-08-27-12.png)","n":0.2}}},{"i":1911,"$":{"0":{"v":"Voyager","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://magnetargames.com/\n- web-based collaborative sandbox, game, and simulation player\n","n":0.316}}},{"i":1912,"$":{"0":{"v":"Voyage","n":1},"1":{"v":"\n\n\n- [[p.hasVision]] https://voyage.latitude.io/voyage-vision\n  - inspiring vision, but it's very AI-focused, not enough \"tools for humans\"\n- resources:  \t[The Verge: AI Dungeon’s creator Latitude launches new Voyage game platform.](https://www.theverge.com/2021/12/19/22836418/latitude-ai-dungeon-voyage-ai-powered-game-platform-launch)\n","n":0.192}}},{"i":1913,"$":{"0":{"v":"Vowl","n":1},"1":{"v":"\n- url: http://vowl.visualdataweb.org/","n":0.577}}},{"i":1914,"$":{"0":{"v":"WebVOWL","n":1},"1":{"v":"\n- url: http://vowl.visualdataweb.org/webvowl.html\n- [[c.software.visualization.semantic]]\n- repo: https://github.com/VisualDataWeb/WebVOWL\n- written_in: javascript","n":0.354}}},{"i":1915,"$":{"0":{"v":"Vorpal","n":1},"1":{"v":"\n#dead\nrepo: https://github.com/dthree/vorpal","n":0.707}}},{"i":1916,"$":{"0":{"v":"Voip.ms","n":1}}},{"i":1917,"$":{"0":{"v":"Void Vocabulary of Interlinked Datasets","n":0.447},"1":{"v":"\n- https://www.w3.org/TR/void/\n\n## Features\n\n- Links are sometimes published as part of a larger dataset. For example, many of the resources described in the DBpedia dataset are linked via owl:sameAs to other datasets. In other cases, [[linksets|t.cs.web.w3c.rdf.linkset]] are handled as stand-alone sets of triples, independently from either of the two linked datasets. For example, link generation tools such as Silk [SILK] can discover new links between two existing datasets. Both cases—linksets published as part of a larger dataset, and linksets that are independent from the linked datasets—can be described in VoID.\n\n## Definitions\n\n### Datasets\n\n- A dataset is a set of RDF triples that are published, maintained or aggregated by a single provider.\n- Unlike RDF graphs, which are purely mathematical constructs [RDF-CONCEPTS], the term dataset has a social dimension: we think of a dataset as a meaningful collection of triples, that deal with a certain topic, originate from a certain source or process, are hosted on a certain server, or are aggregated by a certain custodian. ^2i30z3o7shd9\n\n\n## References\n\n- [[ar.w3.void]]\n- [[sh.question-log.2024.07.20.void-vs-dcat]]\n- ","n":0.078}}},{"i":1918,"$":{"0":{"v":"VoCol","n":1},"1":{"v":"\n- https://github.com/vocol/vocol\n- dead\n- written-in: javascript","n":0.447}}},{"i":1919,"$":{"0":{"v":"VocBench","n":1},"1":{"v":"\n- https://vocbench.uniroma2.it/\n- [[c.software.semantic.authoring]]\n- repo: https://bitbucket.org/art-uniroma2/vocbench3/src/master/\n- built-on: [[prdct.semantic-turkey]]\n- supports: [[prdct.GraphDB]], in-memory, native store\n\n![[prdct.protege#similar]]\n\n## Features\n\n- history, validation, undo\n\n## Issues\n\n![[pub.question-log.2024.10.16#limitations-of-vocbench]]\n\n## Docs\n\n### Namespaces and Imports section\n\nThe imports panel in the Namespace and Imports section allows the authorized user to owl:import ontology vocabularies into the current project. The menu offers five options:\n\n-   Web: imports the ontology by looking on the web for it, using the URI of the ontology for localization\n-   Local file: imports the ontology from a local file available in the hard disk\n-   Ontology mirror: imports the ontology directly from the ontology mirror\n-   Dataset catalog: imports the ontology exploiting the [Dataset Catalog](https://vocbench.uniroma2.it/doc/user/namespaces_imports.jsfdataset_catalogs.jsf)\n-   Local project: imports the ontology from a local project\n\n### Dataset Catalogs\n\n-   [Linked Open Vocabularies](https://lov.linkeddata.es/) (LOV): this is a catalog of vocabularies (OWL ontologies and RDFS schemas), which is curated by human editors to assure the quality of its content and accompanying metadata. Individual entries in LOV are associated with an URL to download a cached copy of the vocabulary, but no SPARQL endpoint is provided (since vocabularies are generally intended for the description of the content of other datasets and are thus made available as files).\n-   [The Linked Open Data Cloud](https://lod-cloud.net/): this is the home of the repository behind the famous diagram depicting the datasets being published and interconnected using the [Linked Data](https://www.w3.org/DesignIssues/LinkedData.html) best practices and made available as [open data](https://opendefinition.org/). Actually, the documentation of the catalog does not prescribe anything on the license, beyond stating that \"Access of the entire dataset must be possible via RDF crawling, via an RDF dump, or via a SPARQL endpoint.\" (more about technical openness than legal concerns about reusability).\n-   [data.europa.eu](https://data.europa.eu): The official portal for European data, providing access to a collection of open dataset metadata harvested from international, EU, national, regional, local and geo data portals. It replaces the EU Open Data Portal and the European Data Portal.\n-   [ShowVoc](http://showvoc.uniroma2.it/): an open-source software for creating data portals. Initially developed in the context of the [ISA<sup>2</sup>](https://ec.europa.eu/isa2/) action [Public Multilingual Knowledge Management Infrastructure for the Digital Single Market (PMKI)](https://ec.europa.eu/isa2/actions/overcoming-language-barriers), ShowVoc can be used to set up data portals for specific institutions, companies, etc. ShowVoc is based on the RDF service platform [Semantic Turkey](http://semanticturkey.uniroma2.it/), which also supports VocBench. ShowVoc stores a copy of [stable contributions](http://showvoc.uniroma2.it/doc/user/contributions_submission.jsf#stable_resource_contribution) in projects alike the ones used in VocBench. Moreover, ShowVoc adopts a dedicated policy to grant anyone access to _public datasets_, whereas in VocBench users must be [assigned to projects](https://vocbench.uniroma2.it/doc/user/dataset_catalogs.jsfprojects_adm.jsf#project-users_management). Furthermore, faceted search is based on [project facets](https://vocbench.uniroma2.it/doc/user/dataset_catalogs.jsfuser/projects.jsf#project_facets), both standard ones (e.g. _model_ and _lexicalization model_) and custom ones (decided for each ShowVoc installation).\n-   [[prdct.ontoportal]]: an open-source software for creating data portals based on the code originally written for the [BioPortal](https://bioportal.bioontology.org/) ontology repository. In addition to the latter, which has become a reference with respect to biomedical ontologies, other installations cover different domains, such agriculture and environment, which are addressed by [AgroPortal](http://agroportal.lirmm.fr/) and [EcoPortal](https://ecoportal.lifewatch.eu/), respectively. VocBench provides a general configuration targeting any OntoPortal installation, together with one specific for EcoPortal.\n-   \n\n## References\n\n- [[ar.voc-bench-3-a-collaborative-semantic-web-editor-for-ontologies-thesauri-and-lexicons]]","n":0.045}}},{"i":1920,"$":{"0":{"v":"Vocab Owl Time Agg","n":0.5}}},{"i":1921,"$":{"0":{"v":"Vivus","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n- url: https://maxwellito.github.io/vivus/","n":0.5}}},{"i":1922,"$":{"0":{"v":"Visual Paradigm","n":0.707}}},{"i":1923,"$":{"0":{"v":"OpenLink Virtuoso","n":0.707},"1":{"v":"\n- [[c.Software.Database.Graph]] [[c.software.database.graph.rdf]] [[c.software.semantic.browser]]\n- has OpenSource and Enterprise/commerical versions\n- url: https://virtuoso.openlinksw.com/\n- features_comparison: https://virtuoso.openlinksw.com/features-comparison-matrix/","n":0.277}}},{"i":1924,"$":{"0":{"v":"Sponger","n":1},"1":{"v":"\n- http://uriburner.com/sponger_architecture.vsp","n":0.707}}},{"i":1925,"$":{"0":{"v":"Vintage Story","n":0.707},"1":{"v":"\n- [[c.game.sandbox]]\n- url: https://www.vintagestory.at/\n- written-in: c#\n- [[c.license]] pro\n\n\n## Features\n\n- fully and believably simulates seasons, soil fertility, rock strata, localized weather patterns, rain, snowfall & snow accumulation, hail, realistic climate distributions, food spoilage, body temperature, animal husbandry, farming, block physics, inspiring sunsets and nightskies, mineralogy, knapping, clayforming, metallurgy, smithing, microblock editing and more\n- ","n":0.139}}},{"i":1926,"$":{"0":{"v":"Video Game Ontology","n":0.577},"1":{"v":"\n- dead since 2015\n- url: http://vocab.linkeddata.es/vgo/\n- [[c.ontology.fictional]]\n- repo: https://github.com/dgarijo/VideoGameOntology\n- uses: [[prdct.lode]]\n\n![](/assets/images/2024-04-04-11-41-00.png)\n\n## Overview\n\nClasses\n\n    Achievement Character Collection Completion Curiosity Fandom Feature Gain event Game Game event Game Product Genre Hard mode In-app purchase event Instantaneous event Item Leaderboard Lose event Loyalty Luck Menu event Minigame Multiplayer Paragon Player Player event Playing area Session Special play style Tutorial Veteran Virtuosity \n\nProperties\n\n    creator has feature has game genre has leaderboard has playing area is achieved in session is achievement in game is character in game is character in session is event associated to player is event in game is event in session is event related to item is event triggered by character is friend with player is item in game is player in session is session in game lives in owns achievement owns character owns item plays game purchases game offering unlocks achievement \n\nData Properties\n\n    end Time event Time event Name release Date start Time username \n\n## Issues\n\n- http://purl.org/net/VideoGameOntology#Item does differentiate between abstract items from one that is actually encountered\n  - the example of \"Potion\" is more like ItemType\n- http://purl.org/net/VideoGameOntology#LoseEvent doesn't differentiate between an agent losing something and a character losing something. \n  - superclasse GameEvent says \"GameEvent describes an event that takes place in a game without straight player interaction\" but a LoseEvent example is \"a player can lose a character due to trade with another player\"\n- http://vocab.linkeddata.es/vgo/#purchasesGameOffering and GameProduct: \"Basically a Game Product can be anything, a character, an item or an achievement.\" but has no domain specified... \n\n## References\n\n- [[ar.an-ontology-for-videogame-interoperability]]","n":0.063}}},{"i":1927,"$":{"0":{"v":"Vert.x","n":1},"1":{"v":"\n## Pros\n\n- Pick the best asynchronous programming model for your problem domain\n\nWe know that asyn­chro­nous pro­gram­ming re­quires more ef­forts. At the core of Vert.x, we sup­port call­backs and promises/fu­tures, the lat­ter being a sim­ple and el­e­gant model for chain­ing asyn­chro­nous op­er­a­tions.\n\nAd­vanced re­ac­tive pro­gram­ming is pos­si­ble with Rx­Java, and if you pre­fer some­thing closer to tra­di­tional im­per­a­tive pro­gram­ming, then we are happy to pro­vide you with first-​class sup­port of Kotlin corou­tines.\n\n","n":0.12}}},{"i":1928,"$":{"0":{"v":"Velocitydb","n":1},"1":{"v":"\n- url: http://velocitydb.com/","n":0.577}}},{"i":1929,"$":{"0":{"v":"Vega","n":1},"1":{"v":"\n- url: https://vega.github.io/vega/\n- repo: https://github.com/vega/vega\n- ","n":0.447}}},{"i":1930,"$":{"0":{"v":"Vantage","n":1},"1":{"v":"\n#dead\nrepo: https://github.com/dthree/vantage","n":0.707}}},{"i":1931,"$":{"0":{"v":"Vanta","n":1},"1":{"v":"\n- url: vanta.com\n- ","n":0.577}}},{"i":1932,"$":{"0":{"v":"Vanjs","n":1},"1":{"v":"\n- https://blog.stackademic.com/vanjs-the-ultra-lightweight-react-alternative-55c0f380376f","n":0.707}}},{"i":1933,"$":{"0":{"v":"Vampire","n":1},"1":{"v":"\n- [[c.Software.Reasoner]]\n- ","n":0.707}}},{"i":1934,"$":{"0":{"v":"Vaadin","n":1},"1":{"v":"\n- url: https://vaadin.com/\n- similar: [[prdct.wicket]] \n\n## Pros\n\n- With Vaadin Collaboration Kit you can help the users of your application work together in real-time\n\n## Cons\n\n- [[prdct.vaadin.collaboration-kit]] is free for 50 users/mo\n- ","n":0.183}}},{"i":1935,"$":{"0":{"v":"Collaboration Kit","n":0.707},"1":{"v":"\n- url: https://vaadin.com/collaboration\n- similar: [[c.Software.real_time_framework]]","n":0.447}}},{"i":1936,"$":{"0":{"v":"V8","n":1}}},{"i":1937,"$":{"0":{"v":"Uuid","n":1},"1":{"v":"\n## Resources\n\n- https://uuidgenerator.dev/uuid-v8","n":0.577}}},{"i":1938,"$":{"0":{"v":"V8","n":1},"1":{"v":"\n## Comparisons\n\n### UUIDv7 vs UUIDv8\n\nUUID v8 is a open format, where just the version and variant bits are fixed. This custom implementation is similar to UUID v7 with two major changes:\n\n    The time granularity has been increased from 1 millisecond to 20 microseconds. With UUID v7 you can create a sortable UUID every ~250 ns, with this implementation of UUID v8 sorting will work up to a creation rate of ~5 ns. The UUID v7 will overflow in ~8900 years, this UUID v8 implementation will overflow in ~120 years.\n\n    The CSPRNG random number generation has been replaced for the xoshiro256++ algorithm, which is not cryptographically secure. Therefore, this implementation should NOT be used for generation of cryptographic keys. UUID v4 is still the best option for cryptographic key generation due to its 122 pseudo-random bits. However, for creating unique identifiers where security is not important, such as database identifiers, this scheme is more performant, sortable, and a higher bit variety than UUID v7 due to the incread time granularity as mentioned above.\n\n\n## References\n\n- https://www.ietf.org/archive/id/draft-peabody-dispatch-new-uuid-format-01.html#name-uuidv8-node-usage","n":0.076}}},{"i":1939,"$":{"0":{"v":"V7","n":1},"1":{"v":"\n## References\n\n- https://www.reddit.com/r/golang/comments/10bg0rn/which_uuid_package_do_you_use_and_why/","n":0.577}}},{"i":1940,"$":{"0":{"v":"V6","n":1}}},{"i":1941,"$":{"0":{"v":"Utterances","n":1},"1":{"v":"\n\n\n\n\n- [[p.hasURL]] https://utteranc.es/\n#static-site-revolution\n\n","n":0.577}}},{"i":1942,"$":{"0":{"v":"Urbit","n":1},"1":{"v":"\n\n- \"Your name is generated for you as a solution to [[Zooko's triangle|idea.zookos-triangle]]\"\n  - [[p.hasSource]] https://urbit.org/faq\n\n- [[p.builtWith]] [[prdct.hoon]]\n\n## [[p.provokedThoughts]]\n\n- maybe their date format could work for gd? ~2022.2.8..16.48.20..b53a ","n":0.189}}},{"i":1943,"$":{"0":{"v":"Upstreet Ai","n":0.707},"1":{"v":"\n- [[c.software.metaverse-platform]]\n- #docs https://docs.upstreet.ai/\n- repo: https://github.com/UpstreetAI/upstreet-sdk\n- written-in: #python javascript\n\n## Highlights\n\n-  [[prdct.zjs]] purpose-built adaptation of [[prdct.yjs]]","n":0.258}}},{"i":1944,"$":{"0":{"v":"Upstash","n":1}}},{"i":1945,"$":{"0":{"v":"Unrival Protocol","n":0.707},"1":{"v":"\n- [[p.hasRepository]] https://github.com/unrival-protocol/protocol\n- [[p.vs]] [[prdct.rdf]]\n- [ ] #analyze https://github.com/unrival-protocol/protocol/blob/main/object/object.md\n","n":0.333}}},{"i":1946,"$":{"0":{"v":"Unreal","n":1},"1":{"v":"\n[[c.software.game-engine]]\n\n## Cons\n\n- \"Voxels or procedural mesh are the only things that sort of work at runtime.\" \n  - https://forums.unrealengine.com/t/dynamic-terrain-generation/253516/2\n- no good scripting?\n  - [ ] what are the limitations of [[prdct.unreal.blueprints]]\n  - \"Unreal has blueprint problem. If you're a sufficiently skilled coder, you cannot utilize your strength properly in unreal, because you're forced to deal with the damnable blueprints at every turn. That thing along with inheritance-based design instead of component based design is a good enough reason NOT to use unreal engine regardless of all the other features it has.\"\n    - https://forum.unity.com/threads/open-world-unity-and-unreal.1283942/\n    - but \n      - \"I do not recall any unreal game where you could model things from scratch while in the game. It has been done with unity, though. [[game.planet-explorers]]. Despite all its flaws. We also have [[game.anyland]], which is also unity.\"\n      - \"    unreal engine is that it does not empower small teams or individual developers. Unity does give you infinite cosmic power during prototyping phase even if you're one man army. It is efficient to the point where some people use unity to prototype and unreal for the final run. With Unreal, this is not the case. You can make something pretty. But you can't make something unusual easily. The engine will fight back.\"\n    - and last word:\n      - \"[[game.astroneer]] If you want some game with terrain modification. It was made in ue4, by a tiny team, released in early access, and finished within some budget. The game is fun, looks good, and has some innovative gameplay.\"\n     \n\n## Issues\n\n- could we create a generic Unreal client that connects to arbitrary game servers?\n  - https://stackoverflow.com/questions/44793090/how-to-pass-information-into-unreal-engine-from-outside-source","n":0.061}}},{"i":1947,"$":{"0":{"v":"UEFN","n":1},"1":{"v":"\n- #related [[game.fortnite]]\n","n":0.577}}},{"i":1948,"$":{"0":{"v":"glTFRuntime","n":1},"1":{"v":"\n- repo https://github.com/rdeioris/glTFRuntime","n":0.577}}},{"i":1949,"$":{"0":{"v":"Blueprints","n":1}}},{"i":1950,"$":{"0":{"v":"Unreal JS","n":0.707},"1":{"v":"\n- [[p.hasURL]] https://www.unrealengine.com/marketplace/en-US/product/unrealjs\n- [[p.hasRepository]] https://github.com/ncsoft/Unreal.js/\n- [[p.hasLearningResource]] \n  - https://itnext.io/getting-started-with-typescript-in-unreal-engine-f1a70adb624","n":0.333}}},{"i":1951,"$":{"0":{"v":"Unpoly","n":1},"1":{"v":"\n```yaml\nurl: https://unpoly.com/\nwritten_in: ruby\n```","n":0.577}}},{"i":1952,"$":{"0":{"v":"Universal Vtt","n":0.707},"1":{"v":"\n- related: [[prdct.arkenforge]]\n- creator: @megasploot\n\n## Solutions\n\n### Creation\n\n- [[prdct.arkenforge]]\n- [[prdct.dungeon-fog]]\n- [[prdct.Dungeon-Draft]]\n\n### Import\n\n- https://github.com/moo-man/FVTT-DD-Import/\n- \n\n## Issues\n\n- UVTT files can not contain animated content, nor individually selectable map images/tokens. The map itself is a single flat image.\n- \"I'm sure megasploot had input from other VTT developers to get the file type suitable for everyone's needs, but a lot of the data is quite specific and useful to Foundry, but not so much for other systems. \"\n\n## References\n\n- https://arkenforge.com/universal-vtt-files/\n- https://www.reddit.com/r/FoundryVTT/comments/t2wprs/format_of_universal_vtt_map_file/","n":0.115}}},{"i":1953,"$":{"0":{"v":"Universal Scene Description","n":0.577},"1":{"v":"\n## Comparison\n\n### [[p.vs]] [[prdct.gltf]]\n\n- glTF is designed for fast performance and low overhead, making it ideal for use in real-time graphics and gaming. USD, on the other hand, is designed to support large-scale, complex productions, and may have a higher overhead compared to glTF.\n  - https://www.ec4labs.io/post/universal-scene-description-gltf-what-is-the-deal-here","n":0.147}}},{"i":1954,"$":{"0":{"v":"Unity Lua","n":0.707},"1":{"v":"\n- repo: https://github.com/Semaeopus/Unity-Lua\n- [[p.supports]] [[game.off-grid]]","n":0.447}}},{"i":1955,"$":{"0":{"v":"Unist","n":1},"1":{"v":"\n- url: https://github.com/syntax-tree/unist\n- ","n":0.577}}},{"i":1956,"$":{"0":{"v":"Unified","n":1},"1":{"v":"\n\n- [[p.hasURL]] unifiedjs.com\n- [[p.hasLearningResource]]\n  - https://unifiedjs.com/learn/guide/introduction-to-unified/","n":0.408}}},{"i":1957,"$":{"0":{"v":"Unified Foundational Ontology","n":0.577},"1":{"v":"\n\n\n- [[c.ontology.upper]]\n- url: \n  - https://nemo.inf.ufes.br/en/projetos/ufo/\n  - http://dev.nemo.inf.ufes.br/seon/UFO.html\n- similar: [[prdct.unified-foundational-ontology.gentle]] [[prdct.sumo]] [[prdct.gfo]] [[prdct.dolce]]\n- related: [[prdct.ontouml]] [[prdct.unified-foundational-ontology.eUFO]] [[prdct.seon-software-engineering-ontology-network]]\n- based_on: [[prdct.dolce]] [[prdct.gfo]] [[prdct.ontoclean]]\n- repo: https://github.com/unibz-core/ufo-formalization\n- docs: [[ar.a-first-order-logic-formalization-of-the-unified-foundational-ontology]]\n\n![](/assets/images/2024-04-18-11-24-08.png)\n\n \n## Issues\n\n- no OWL or any other machine-readable represenation\n  - but [[prdct.unified-foundational-ontology.gUFO]]\n- [[ar.github.nemo-ufes.gufo.are-all-relations-instances-of-either-material-relationship-type-or-comparative-relationship-type]]\n\n## Features\n\n- ![[prdct.unified-foundational-ontology.gUFO#^io6179ll2dle]]\n\n### Relations\n\n- \"We divide relations into two broad categories, called Material and Formal relations.\"\n  - Formal relations hold between two or more entities directly without any further intervening individual. Examples of formal relations are:\n    - 5 is greater than 3\n    - this day is part of this month\n    - N is subset of Q\n  - but also the relations of instantiation, inherence, quale of a quality, association, existential dependence, among others – … relations that form the mathematical superstructure of our framework. _Material relations,_ conversely, have material structure on their own and include examples such as:\n    -   employments\n    -   kisses\n    -   enrollments\n    -   flight connections\n    -   commitments\n   \n\n\n## Composition\n\n-   **UFO-A**: An Ontology of Endurants dealing with aspects of structural conceptual modeling. It is organized as a [[t.km.ontology.four-category]] ontology comprising theories of Types and Taxonomic Structures connected to a theory of object identifiers (including a formal semantics in a Sortal Quantified Modal Logics), Part-Whole Relations, Particularized Intrinsic Properties, Attributes and Attribute Value Spaces (including a theory of Datatypes as Measure Structures), Particularized Relational Properties and Relations and Roles;\n  \n\n-   **UFO-B**: An Ontology of Perdurants (Events, Processes) dealing with aspects such as Perdurant Mereology, Temporal Ordering of Perdurants, Object Participation in Perdurants, Causation, Change and the connection between Perdurants and Endurants via Dispositions;\n   \n\n-   **[[UFO-C|prdct.unified-foundational-ontology.ufo-c]]:** An Ontology of Simple Intentional and Social Entities, which is constructed on top of UFO- A and UFO-B, and which addresses notions such as Beliefs, Desires, Intentions, Goals, Actions, Commitments and Claims, Social Roles and Social Particularized Relational Complexes (Social Relators), among others.\n\n- **[[UFO-S|prdct.unified-foundational-ontology.ufo-b]]:** Services\n\n\n\n\n## Resources\n\n\n\n## References\n\n- https://ontouml.readthedocs.io/en/latest/intro/ufo.html\n- [A Unified Foundational Ontology and some\nApplications of it in Business Modeling](https://ceur-ws.org/Vol-125/paper2.pdf)\n- [[ar.ontological-foundations-for-structural-conceptual-models]]\n- [[ar.towards-ontological-foundations-for-agent-modeling-concepts-using-ufo]]\n- [[ar.towards-ontological-foundations-for-conceptual-modeling-the-unified-foundational-ontology-ufo-story]]\n- [[ar.ufo-unified-foundational-ontology]]\n- [[ar.endurant-types-in-ontology-driven-conceptual-modeling-towards-onto-uml-2-0]]\n- https://dev.nemo.inf.ufes.br/seon/UFO.html\n  - t.2024.08.27.09 finally made the connection of the MLT sub-ontology with  [[t.km.ontology.multi-level-theory]] ","n":0.056}}},{"i":1958,"$":{"0":{"v":"Ufo S","n":0.707},"1":{"v":"\n## References\n\n- [[ar.a-commitment-based-reference-ontology-for-services]]","n":0.577}}},{"i":1959,"$":{"0":{"v":"UFO-MLT","n":1},"1":{"v":"\n- related: [[prdct.groove]]\n\n## References\n\n- [[ar.multi-level-ontology-based-conceptual-modeling]]\n- ","n":0.447}}},{"i":1960,"$":{"0":{"v":"UFO-C","n":1},"1":{"v":"\n![](/assets/images/2024-07-16-13-02-21.png)\n\n- \"UFO-C [ 24] differentiates between Agents and Objects as subtypes of Substantial Individuals. Agents are Agentive Substantial Individuals that are classified as Physical Agents (e.g., a person) or Social Agents. Objects are Non-agentive Substantial Individuals that are classified as Physical Objects (e.g., a car) and Social Objects, like languages or norms. A Normative Description defines one or more rules acknowledged by at least one Social Agent, like organizations or communities. A Plan Description is a specialization of a Normative Description that describes Complex Action Universals (such as Processes). Action Universals are Event Universals (Perdurants) as described in UFO-B. Intentional Moments reside in Agents, and can be mental or social. Intentions are Mental Moments, and prompt the Agent to perform Actions, which can be complex or atomic. Social Moments are types of Intentional Moments that are generated by Social Actions.\"\n- \n\n## References\n\n- https://ontouml.org/ontouml/metamodel-definitions/\n- https://www.utwente.nl/en/eemcs/fois2024/resources/papers/magagna-et-al-ontological-analysis-of-fair-implementation-profiles.pdf\n- [[ar.a-commitment-based-reference-ontology-for-services]]\n- [[book.agent-oriented-constructivist-knowledge-management]]\n- [[ar.socially-grounded-analysis-of-knowledge-management-systems-and-processes]]\n- [[ar.towards-ontological-foundations-for-agent-modeling-concepts-using-ufo]]","n":0.082}}},{"i":1961,"$":{"0":{"v":"UFO-B","n":1},"1":{"v":"\n![](/assets/images/2024-07-16-13-02-44.png)\n\n## References\n\n- [[ar.a-commitment-based-reference-ontology-for-services]]\n- [[ar.towards-ontological-foundations-for-the-conceptual-modeling-of-events]]","n":0.5}}},{"i":1962,"$":{"0":{"v":"UFO-A","n":1},"1":{"v":"\n![](/assets/images/2024-07-16-13-03-10.png)","n":1}}},{"i":1963,"$":{"0":{"v":"gUFO","n":1},"1":{"v":"\n- url: https://nemo-ufes.github.io/gufo/\n- repo: https://github.com/nemo-ufes/gufo/\n- related: [[prdct.ufo-protege-plugin]] [[prdct.ontouml-vp-plugin]]\n\n## Features\n\n- \"A key feature of UFO (and hence, gUFO) is that it includes two taxonomies: one with classes whose instances are individuals (classes in this taxonomy include gufo:Object, gufo:Event) and another with classes whose instances are types (classes in this taxonomy include gufo:Kind, gufo:Phase, gufo:Category).\"\n- UFO distinguishes Endurant Types into Substantial Types and Moment\nTypes.\n\n## Classes\n\n- Individual\n  - AbstractIndividual: evil, chaos\n    - Instant\n    - QualityValue \n      - Use this class only for quality values (qualia) that are to be reified in the A-box and associated with a gufo:ConcreteIndividual through the object property gufo:hasReifiedQualityValue. Otherwise, use the gufo:hasQualityValue data property and a literal to determine the quality value.\n        - i.e., it's a type for quality values that are part\n  - ConcreteIndividual\n    - Endurant\n      - Aspect\n        - ExtrinsicAspect\n          - ExtrinsicMode\n          - Relator\n        - IntrinsicAspect\n          - IntrinsicMode\n          - Quality\n      - Object: e.g. Gunaar, Shadow Keep\n        - Collection: \n          - FixedCollection: Gunaar and Tserro together\n          - VariableCollection: The Shadows. \"If various roles for the parts of a fleet were envisioned (such as \"cargo airplane\", \"passenger airplane\"), then a fleet would be best understood as a gufo:FunctionalComplex.\"\n        - FunctionalComplex: complicated to differentiate from VariableCollection\n        - Quantity\n    - Event\n      - Participation \"John's participation in the meeting encompasses all events that are part of the meeting and that depend solely on him\"\n    - Situation\n      - QualityValueAttributionSituation\n      - TemporaryConstitutionSituation\n      - TemporaryInstantiationSituation\n      - TemporaryParthoodSituation\n      - TemporaryRelationshipSituation\n- Type\n  - AbstractIndividualType\n  - ConcreteIndividualType\n    - EndurantType\n      - NonRigidType\n        - Phase\n        - PhaseMixin\n        - Role\n        - RoleMixin\n      - SemiRigidType\n        - Mixin\n      - NonSortal\n        - Category \"Non-sortals do not provide a uniform principle of identity for their instances; instead, they just classify things that share common properties but which obey different principles of identity.\"\n        - Mixin \"A gufo:EndurantType that is both non-sortal and semi-rigid. As a semi-rigid type, it applies necessarily to some of its instances and contingently to some others. As a non-sortal, it captures properties shared by instances of different kinds. For example, the type \"FemaleAnimal\" may be considered a gufo:Mixin as it applies necessarily to animals of certain species, e.g., lions and sharks, while it applies contingently to animals of other species such as clownfish and mushroom corals (which may change sex given certain conditions).\"\n        - PhaseMixin\n        - RoleMixin\n      - RigidType\n        - Category\n        - Kind\n        - Subkind\n      - Sortal\n        - Kind\n        - Phase\n        - Role\n        - SubKind\n    - EventType\n    - SituationType\n  - RelationType\n    - ComparativeRelationshipType\n    - MaterialRelationshipType\n\n## Resources\n\n- https://github.com/nemo-ufes/gufo/blob/master/docs/overview.md","n":0.05}}},{"i":1964,"$":{"0":{"v":"gUFO","n":1},"1":{"v":"\n- https://nemo-ufes.github.io/gufo/\n- similar: [[prdct.unified-foundational-ontology.eUFO]]\n\n## Issues\n\n- not OWL-DL because powerclasses? (punning)\n- doesn't support [[t.km.ontology.multi-level-theory]], see [[community.nemo-ufes.gufo.issues-37-multi-level]] \n- abstract and concrete are disjoint, but e.g. wemi... things are a blend\n\n## Features\n\n- Treating aspects as endurants (i.e., reifying aspects) allows us to consider the properties of aspects themselves, and track their change in time.\n- temporal aspects of concrete individuals can be captured with the data properties gufo:hasBeginPointInXSDDate, gufo:hasBeginPointInXSDDateTimeStamp, gufo:hasEndPointInXSDDate and gufo:hasEndPointInXSDDateTimeStamp\n\n- A key feature of UFO (and hence, gUFO) is that it includes two taxonomies: one with classes whose instances are individuals (classes in this taxonomy include gufo:Object, gufo:Event) and another with classes whose instances are types (classes in this taxonomy include gufo:Kind, gufo:Phase, gufo:Category). ^io6179ll2dle\n\n### Taxonomy\n\n-   Individual\n    -   AbstractIndividual\n    -   ConcreteIndividual\n        -   Endurant\n            -   Object\n            -   Aspect\n        -   Event\n        -   Situation\n-   Type\n    -   AbstractIndividualType\n    -   ConcreteIndividualType\n        -   EndurantType\n            -   Sortal\n                -   Kind\n                -   Phase\n                -   Role\n                -   SubKind\n            -   NonSortal\n                -   Category\n                -   PhaseMixin\n                -   RoleMixin\n                -   Mixin\n        -   EventType\n        -   SituationType\n    -   RelationshipType\n\n### Usage Scenarios\n\nConsidering these two taxonomies, the following usage scenarios are envisioned and discussed in this document where appropriate:\n\n1.  A UFO-based ontology _instantiates_ gUFO classes in the taxonomy of individuals  \n    For example, `:Earth rdf:type gufo:Object` and `:WorldCup1970Final rdf:type gufo:Event`.\n2.  A UFO-based ontology _specializes_ gUFO classes in the taxonomy of individuals  \n    For example, `:Planet rdfs:subClassOf gufo:Object` and `:SoccerMatch rdfs:subClassOf gufo:Event`.\n3.  A UFO-based ontology _instantiates_ gUFO classes in the taxonomy of types  \n    For example, `:Planet rdf:type gufo:Kind`, `:Child rdf:type gufo:Phase`.\n4.  A UFO-based ontology _specializes_ gUFO classes in the taxonomy of types  \n    For example, `:PersonPhase rdfs:subClassOf gufo:Phase`.\n\nUsers may combine the various scenarios discussed. For example, users will often employ scenarios 2 and 3 in combination as shown in the following fragment, which defines a \"Person\" class that specializes gufo:Object and instantiates gufo:Kind:\n\n```turtle\n:Person rdf:type owl:Class ;\n        rdfs:subClassOf gufo:Object ;\n        rdf:type gufo:Kind .\n```\n\n## Questions\n\n- \"Every gufo:Endurant instantiates one and only one gufo:Kind\" - so no flying cars?\n  - @chatgpt: define a new kind, or use a generalization\n\n## Resources\n\n- [[ar.ontology-implementation-with-g-ufo-a-hands-on-tutorial]]\n- ","n":0.055}}},{"i":1965,"$":{"0":{"v":"eUFO","n":1},"1":{"v":"\n- dead\n- similar: [[prdct.unified-foundational-ontology.gentle]]\n\n![](/assets/images/2024-04-17-11-23-06.png)\n\n![](/assets/images/2024-04-17-11-22-46.png)\n\n\n## Terms\n\n- **substance individuals**: things with spatio-temporal qualities, founded on matter\n- **trope individuals**: things that inhere in substance-individual bearers\n  - **intrinsic**: qualities\n    - non-migration (or non-transferability) principle: it is not possible for a particular quality q to inhere in two different individuals a and b\n    - distinguish between the color of a particular apple (its quality) and the ‘color data value’ that we associate with this quality in an **attribution** (with the help of an **attribute**)\n      - we may associate more than one attribute with a particular quality universal, each of them based on a different datatype. E.g., the quality universal “hair color” could be captured by an attribute with the range of RGB byte triples or by an attribute with the range of natural language color names. \n  - **relators**: things that depend on two or more substance-individuals\n\n### Relators, Material Relationships and Reference Properties\n\n- in general, relators are founded on events ^atf1q0pprmmt\n  - e.g. a particular marriage is founded on a marriage ceremony\n- material relationships depend on relators to exist; (i.e., a particular marriage depends on the relator \"marriage\"?)\n\n### Events\n\n- Events are ontologically dependent entities in the sense that they existentially depend on their participants in order to exist.\n- Events may change the real world by changing the state of affairs from one (pre-state) situation to a (post-state) situation.\n  - Each situation is determined by a set of associated object snapshots and a set of associated material relationships holding between the involved objects, \n- Being atomic and being instantaneous are orthogonal notions in this framework, i.e., an atomic event can be time-extended and an instantaneous event can be composed of multiple (instantaneous) events.\n- All spatial properties of events are defined in terms of the spatial properties of their participants. In contrast, all temporal properties of objects are defined in terms of the events in which they participate.\n- The temporal attributes of events have values from special temporal datatypes. We assume that these da- tatypes support the concept of Time Intervals, which are composed of Time Points. Time points could be represented as real numbers and Time Intervals as sets of real numbers. However, they could also be de- fined in other ways (we avoid making unnecessary ontological commitments at this point). Additionally, we admit: (i) intervals that are delimited by begin and end points as well as open intervals; (ii) continuous and non-continuous intervals; (iii) intervals with and without duration (instants). In particular, this model allows a diversity of temporal structures such as linear, branching, parallel and circular time\n\n#### Universals\n\n- Universals classify individuals, which are said to be their instances. The set of all instances of a universal\nis called its extension. We consider five kinds of universals: event types, object types, quality universals,\nattributes, relator universals, reference properties and material relationship types.\n![](/assets/images/2024-04-17-11-29-15.png)\n\n##### Kinds of Object Types\n\n\n![](/assets/images/2024-04-17-11-36-55.png)\n\n\n- **sortal types** carry a principle of identity for\ntheir instances\n  - **principle of application** allows to judge whether an individual is an instance of that object type\n  - a **principle of identity** allows to judge whether two individuals are the same\n  - **base types**: Within the category of sortal types, we make a further distinction based on the formal notions of rigidity and anti-rigidity: A sortal type U is rigid if for every instance x of U, x is necessarily (in the modal sense) an instance of U. In other words, if x instantiates U in a given world w, then x must instantiate U in every possible world w’.\n  - **role types**: involves extrinsic (relational) properties of R\n    - For any role type (e.g. Student) there is an underlying binary material relationship type or refer- ence property (e.g. students) such that the extension of the role type (e.g. the set of current students of an educational institution) is the range of that reference property.\n  - **phase types**: a condition that involves only intrinsic properties of P.\n- Non-sortal types, such as RedThing, are called **mixin types**\n\n##### Object type principles\n\n1. Every object must instantiate exactly one ultimate base type.\n2. A rigid object type cannot be a subtype of an anti-rigid object type (e.g., Person cannot specialize\nStudent).\n3. A mixin type cannot be specialized by a sortal type (e.g., Person cannot specialize Customer).\n4. A mixin type cannot have direct instances.\n\n##### Quality Universals\n\n- A quality universal classifies individual qualities of the same type. A quality universal can be associated with one or more datatypes, such that any particular quality corresponds to a specific data value from the value space of the datatype. The association between qualities of some quality universal and the corres- ponding data value from an associated datatype is provided by an attribute.\n\n##### Relator Universals, Material Relationship Types and Reference Properties\n\n- A relator universal classifies individual relators of the same type. The material relationship type R induced by a relator universal R classifies all material relationships induced by relators from R.\n- A reference property represents a binary material relationship type, corresponding to a relator universal whose instances mediate exactly two objects.\n\n## Thoughts\n\n- why separate design-time and run-time?\n- \"Notice that in conceptual modelling, and in simulation modelling, we are not really interested to consider all the things that constitute a real-world system. We call those things, in which we are interested, entities, including: physical objects, events and certain material relationships. This choice implies that we do not want to include amounts of matter, relators or qualities in a simulation model.\"\n  - relators: a kiss, a covalent bond, a medical treatment, a purchase order, or a social commitment.\n  - why wouldn't you want to include relators and qualities in a simulation model?\n    - e.g. an attack; an equipped weapon?\n- Sortal types are confusing... two Apples are the same?\n  - t.2024.07.10.12 No, the class \"Apples\" is sortal because its members are countable and have identity\n- Base types: Person, but... in a fantasy world, even a creature could be transformed into a lamp\n  \n\n## References\n\n- [[ar.towards-an-ontological-foundation-of-discrete-event-simulation]]\n- [[ar.can-bpmn-be-used-for-making-simulation-models]]","n":0.032}}},{"i":1966,"$":{"0":{"v":"Underscore.js","n":1}}},{"i":1967,"$":{"0":{"v":"Umple","n":1},"1":{"v":"\n- repo: https://github.com/umple/umple","n":0.577}}},{"i":1968,"$":{"0":{"v":"Umodel","n":1}}},{"i":1969,"$":{"0":{"v":"Ulid","n":1},"1":{"v":"\n- repo: https://github.com/ulid/spec\n\n## Implementations\n\n- https://github.com/ulid/javascript (dead)\n-   Python: `ulid` package ([https://github.com/mdangear/ulid](https://github.com/mdangear/ulid))\n-   Go: `github.com/oklog/ulid`\n-   Java: `de.huxhorn.sulky.ulid` ([https://github.com/huxi/sulky/tree/master/sulky-ulid](https://github.com/huxi/sulky/tree/master/sulky-ulid))\n-   C#: `Ulid` package ([https://github.com/RobThree/Ulid](https://github.com/RobThree/Ulid))\n\n\n![[prdct.newid#similar]]\n\n## Features\n\n- 128-bit UUID compatible, with 48 bits timestamp, 80 bits random.\n\n## References\n\n- https://brandur.org/fragments/k-sorted-ids","n":0.177}}},{"i":1970,"$":{"0":{"v":"Ufo Protege Plugin","n":0.577},"1":{"v":"\n- [[c.software.plugin.protege]]\n- https://github.com/nemo-ufes/ufo-protege-plugin\n\n\n## Resources\n\n- https://www.youtube.com/channel/UCrO83sDDZ7q4ymI76bwB-bg","n":0.447}}},{"i":1971,"$":{"0":{"v":"UCAN","n":1},"1":{"v":"\n- url: https://ucan.xyz/\n- repo: https://github.com/ucan-wg\n- created_by: [[org.fission]]\n- [[p.hasImplementation]] \n  - [[prdct.noosphere]]\n- description: distributed authorization for offline-first apps and distributed systems\n\n\n## FAQ\n\n### Is UCAN secure against person-in-the-middle attacks?\n\nUCAN does not have any special protection against person-in-the-middle (PITM) attacks.\n\nWere a PITM attack successfully performed on a UCAN delegation, the proof chain would contain the attacker's DID(s). It is possible to detect this scenario and revoke the relevant UCAN but does require special inspection of the topmost iss field to check if it is the expected DID. Therefore, it is strongly RECOMMENDED to only delegate UCANs to agents that are both trusted and authenticated and over secure channels.\n\n## References\n\n- [[ar.capability-myths-demolished]]","n":0.097}}},{"i":1972,"$":{"0":{"v":"TypeScript","n":1},"1":{"v":"\n- alternatives: [[prdct.jsdoc]]\n\n## Features\n\n- \"it is possible and common to use TypeScript for type definitions while still writing the actual functionality in JavaScript.\"\n\n## Cons\n\n- compilation\n- code polluted with type programming\n\n\n## Resources\n\n- https://medium.com/codex/why-are-javascript-pros-saying-goodbye-to-typescript-8c4bc8ec82a1\n\n### Learning Resource\n\n- https://szaranger.medium.com/typescript-features-you-should-no-longer-use-82ede931243\n- https://javascript.plainenglish.io/advanced-typescript-generics-1b30d6b5dd49\n- https://docs.microsoft.com/en-us/learn/modules/typescript-get-started/2-typescript-overview\n- https://code.visualstudio.com/docs/typescript/typescript-tutorial\n- https://blog.devgenius.io/typescript-is-not-a-programming-language-f5b7e0fce01\n  - \"inform the dev time language server and the compiler about the valid shapes\"\n\n## References\n\n- https://levelup.gitconnected.com/is-it-not-that-typescript-is-unaffordable-but-rather-that-jsdoc-has-a-better-cost-performance-4a933bb1e076","n":0.135}}},{"i":1973,"$":{"0":{"v":"Barrel Files","n":0.707},"1":{"v":"\n- someone said \"don't use em everywhere, maybe just at the top folder in hierarchy\"\n  - https://adrianfaciu.dev/posts/barrel-files/\n- [-] feels like probably shouldn't use 'em, but jury is still out\n\n## Resources\n\n- https://javascript.plainenglish.io/avoiding-import-issues-in-typescript-monorepos-d5a4b21f90ef\n- https://dev.to/luispa/how-to-create-barrels-in-typescript-or-javascript-59ma","n":0.177}}},{"i":1974,"$":{"0":{"v":"TypeScript Website","n":0.707},"1":{"v":"\n\nThe docs for TypeScript are a living example of how to make a beautiful educational site\n\n- [[p.hasURL]] https://github.com/microsoft/TypeScript-Website\n- [[p.isRelated]] [How the new TypeScript website works](https://www.youtube.com/watch?v=HOvivt6B7hE)\n","n":0.2}}},{"i":1975,"$":{"0":{"v":"TypeQL","n":1},"1":{"v":"\n\n- [[p.alsoKnownAs]] graql\n- [[p.hasRepository]] https://github.com/vaticle/typeql\n","n":0.447}}},{"i":1976,"$":{"0":{"v":"TypeManager.TS","n":1},"1":{"v":"\n- [[c.software.serializer]]\n- repo: https://github.com/dipscope/TypeManager.TS\n- related: [[prdct.entity-store]]","n":0.408}}},{"i":1977,"$":{"0":{"v":"TypedJSON","n":1},"1":{"v":"\n- [[c.software.serializer]]\n- dead: since 2021\n- repo: https://github.com/JohnWeisz/TypedJSON","n":0.378}}},{"i":1978,"$":{"0":{"v":"TypeDB","n":1},"1":{"v":"\n- [[c.software.database.graph]] [[c.Software.Database.graph.hypergraph]]\n- [[p.alsoKnownAs]] grakn\n- [[p.ownedBy]] [[org.vaticle]]\n- [[p.hasRepository]] https://github.com/vaticle/typedb\n- [[p.hasRelatedSolution]] [[prdct.typeql]] [[prdct.blitz-orm]]\n- written-in: java\n- [[p.builtOn]] \n  - [[prdct.rocksdb]]\n  - [[prdct.grpc]]\n    - [[p.hasSource]] https://docs.vaticle.com/docs/client-api/new-client\n  - [[prdct.janusgraph]] (https://graphsandnetworks.com/typedb-previously-grakn-ai/)\n  - [[prdct.speedb]]\n\n## [[p.hasConcept]]\n\n- \"Concept Architecture\"\n  - ![](/assets/images/2022-03-14-14-26-10.png)\n  - ![](/assets/images/2023-09-21-22-03-51.png)\n  - ![](/assets/images/2023-09-21-22-19-16.png)\n\n### Thoughts\n\n- a little unusual for a thing to be a concept. My water bottle is not really a concept.\n  - https://hydeandrugg.wordpress.com/2016/01/24/things-concepts-and-words/\n\n## Use Cases\n\n- [[prdct.typedb-data-cti]]\n\n## Tips\n\n- When inserting instances of a relation, it is not necessary to define all of its role players. But this represents an incomplete information state, such as a marriage in which only one of the spouses is known.\n- \n\n\n## Issues\n\n- [Run TypeDB Studio in a web browser](https://github.com/vaticle/typedb-studio/issues/118)\n  - we have recently rewritten Workbase as Studio, and it is no longer an Electron app\n- how do you establish order?\n  - use a property\n    - https://forum.vaticle.com/t/how-to-best-represent-the-order-of-nodes-on-an-edge/279\n\n## Modelling\n\n- entity: \n  - anything physical\n  - anything that exists logically but doesn't require involvement of other things\n  - concrete\n  - /proper/common/abstract/collective\n  - relations should be \"abstract nouns\" or \"transitive verbs that can accept 2 or more argument\"\n- no equivalanet of blank node (no open world), but you could do \"entity with no URI is unspecified\"\n- \"GRAKN.AI uses “hypergraphs” instead of vanilla digraphs to model their knowledge, although under the hood, they map these hypergraphs to digraphs before persisting to whatever vendor DB using Apache TinkerPop.\"\n  - https://discuss.dgraph.io/t/hypergraphql-query-language/2123\n\n### Temporal Modelling\n\n- [[ar.medium.vaticle.modelling-time-within-a-strongly-typed-database]]\n- t.2024.01.15: \"expressions don't have datetime computation functionality yet\" \n\n\n## Resources\n\n- https://victormorgante.medium.com/query-generation-for-typedb-67c7b4a88ee2\n  - \"TypeDB approaches the database market conceptualised as both a database and a rules-based knowledge graph combined as one. Operating over a key/value store the database encompasses the same sort of architecture used by FactEngine to effectively turn any compatible database into a natural language/\n- https://graphsandnetworks.com/typedb-previously-grakn-ai/\n- [[ar.towardsdatascience.an-enterprise-data-stack-using-typedb]]\n- https://blog.vaticle.com/what-is-a-knowledge-graph-5234363bf7f5\n- https://forum.typedb.com/t/rdf-uris-as-attributes-of-all-types/433\n\n- https://medium.com/vaticle/modelling-data-with-hypergraphs-edff1e12edf0\n  - mentions [Knowledge Graph Representation: TypeDB or OWL?](https://medium.com/vaticle/knowledge-graph-representation-grakn-ai-or-owl-506065bd3f24)\n- [Comparing Semantic Web Technologies to TypeDB](https://www.youtube.com/watch?v=LFgV7sCnOrE)\n- [[ar.medium.vaticle.modelling-time-within-a-strongly-typed-database]]\n- [How do actors enable and elegant and scalable reasoning engine](https://www.youtube.com/watch?v=fQ1faqMFq9E)\n- https://typedb.com/blog/inference-in-typedb\n- https://typedb.com/blog/modeling-collections-in-databases-relational-sql-vs-typedb ","n":0.056}}},{"i":1979,"$":{"0":{"v":"Typedb Data Cyber Threat Intelligence","n":0.447},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/typedb-osi/typedb-data-cti\n- [[p.builtOn]] \n  - [[prdct.typedb]]\n  - [[prdct.stix]]\n- [[p.begsQuestion]] if STIX is specified as a regular (non-hypergraph) graph, does TD-CTI use any ternary+ relations?","n":0.2}}},{"i":1980,"$":{"0":{"v":"Typed Rpc","n":0.707},"1":{"v":"\n- url: https://github.com/fgnass/typed-rpc\n- [[p.instanceOf]]  [[c.software.rpc]]\n- written-in: [[prdct.typescript]]","n":0.378}}},{"i":1981,"$":{"0":{"v":"Tye","n":1},"1":{"v":"\n- repo: https://github.com/dotnet/tye","n":0.577}}},{"i":1982,"$":{"0":{"v":"Twingate","n":1}}},{"i":1983,"$":{"0":{"v":"Twine","n":1},"1":{"v":"\n- [[p.instanceOf]] [[c.software.game-framework.interactivefiction]]\n- [[p.hasLearningResource]] \n  - [[p.hasHighlight]] \n    - A passage is a way of thinking about different parts of a story. They can be rooms in a house, different time periods, or compartments for storage. ","n":0.167}}},{"i":1984,"$":{"0":{"v":"Turtle Formatter","n":0.707},"1":{"v":"\n- https://github.com/atextor/turtle-formatter\n- [[c.software.semantic.utility]]\n- input: \n  - formatting style \n  - Apache Jena Model\n\n## References\n\n- [[email.public-rdf-star.diff-ing-rdf-files]]","n":0.258}}},{"i":1985,"$":{"0":{"v":"Turf JS","n":0.707},"1":{"v":"\n- url: https://turfjs.org/\n- ","n":0.577}}},{"i":1986,"$":{"0":{"v":"Tupper","n":1},"1":{"v":"\n- [[c.ontology.upper]]\n- ","n":0.707}}},{"i":1987,"$":{"0":{"v":"Tui Calendar","n":0.707},"1":{"v":"\nrepo: https://github.com/nhn/tui.calendar\n\n-   [✨ Monthly, Weekly, Daily and Various View Types](https://github.com/nhn/tui.calendar#-features#-monthly-weekly-daily-and-various-view-types)\n-   [Easy to Use: Dragging and Resizing a Schedule](https://github.com/nhn/tui.calendar#-features#easy-to-use-dragging-and-resizing-a-schedule)\n-   [Ready to Use: Default Popups](https://github.com/nhn/tui.calendar#-features#ready-to-use-default-popups)\n\n## ","n":0.209}}},{"i":1988,"$":{"0":{"v":"Tucson","n":1},"1":{"v":"\n- [[c.software.agent-framework]]\n- #dead\n- repo: https://github.com/TuCSoN-Coord/TuCSoN\n- [[p.supportedBy]] [[prdct.tucson.respect]]\n\n## [[c.resource.list]]\n\n- https://apice.unibo.it/xwiki/bin/view/TuCSoN/Publications/","n":0.333}}},{"i":1989,"$":{"0":{"v":"ReSpecT","n":1},"1":{"v":"\n- url: https://apice.unibo.it/xwiki/bin/view/ReSpecT/\n","n":0.577}}},{"i":1990,"$":{"0":{"v":"TTRpg","n":1},"1":{"v":"\n- [[c.ontology]] [[c.ontology.domain]] [[c.ontology.domain.rpg]]\n- author: @ruben-wambacq\n- ontology:\n  - https://github.com/rwambacq/TTRpg/blob/master/TTRpg.ttl\n  - https://github.com/rwambacq/DnD5eCharacter/blob/master/DnD5eCharacter.ttl\n- related: [[prdct.DnD5eCharacter]]\n\n## Issues\n\n- small\n- no sample data, although [[prdct.DnD5eCharacter]] \n- items, creatures, and locations don't have a common superclass\n- \"knows\" only refers to spells, i.e., bad predicate naming\n- \"type\" is overloaded for characters, spells, and items\n  - `CharacterType` isn't really used, except as the range of `type`\n\n- \"hasItem\" has domain World\n- `Player` is subclass of `foaf:Person` instead of `foaf:Agent`\n- `Weapon` is a subclass of `ItemType` which might work out okay if its sense is WeaponType,","n":0.108}}},{"i":1991,"$":{"0":{"v":"Tab-Separted Values","n":0.707}}},{"i":1992,"$":{"0":{"v":"tsoa","n":1},"1":{"v":"\n- repo: https://github.com/lukeautry/tsoa\n- docs: https://tsoa-community.github.io/docs\n- supports: [[prdct.hapi]] [[prdct.koa]]\n\n## Features\n\n- autogenerate OpenAPI specs based on your TypeScript model definitions","n":0.236}}},{"i":1993,"$":{"0":{"v":"Try .NET","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://devblogs.microsoft.com/dotnet/creating-interactive-net-documentation/","n":0.577}}},{"i":1994,"$":{"0":{"v":"tRPC","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://trpc.io/\n- [[p.solvesProblem]]\n  - [[t.cs.api]]\n- [[p.compatibleWith]] \n  - [[Connect|prdct.connect]]\n  - [[prdct.express]]\n  - [[prdct.nextjs]]\n\n## [[p.hasLearningResource]]\n\n- https://javascript.plainenglish.io/stop-building-rest-apis-for-your-next-js-apps-use-trpc-instead-4b78e8f4d331\n","n":0.25}}},{"i":1995,"$":{"0":{"v":"Trowl","n":1},"1":{"v":"\n- dead\n- repo: https://github.com/TrOWL/core\n\n## References\n\n- [[ar.tr-owl-tractable-owl-2-reasoning-infrastructure]]","n":0.408}}},{"i":1996,"$":{"0":{"v":"Trld","n":1},"1":{"v":"\n- https://github.com/niklasl/trld\n- written-in: typed python\n- transpiles-to: javascript java\n\n","n":0.354}}},{"i":1997,"$":{"0":{"v":"Trizbort","n":1},"1":{"v":"\n- [[c.software.game-framework.interactivefiction.mapper]]\n- url: http://trizbort.genstein.net/\n- similar: [[prdct.ifm]]","n":0.408}}},{"i":1998,"$":{"0":{"v":"Triplydb","n":1},"1":{"v":"\n- publisher: [[org.triply]]\n\n","n":0.577}}},{"i":1999,"$":{"0":{"v":"TriplyDB.js","n":1},"1":{"v":"\n- docs: https://docs.triply.cc/triplydb-js/","n":0.577}}},{"i":2000,"$":{"0":{"v":"Triple Data Fragments","n":0.577},"1":{"v":"\n## Issues\n\n- requires server\n\n## References\n\n- https://linkeddatafragments.org/concept/#tpf","n":0.408}}},{"i":2001,"$":{"0":{"v":"Trinity Rdf","n":0.707},"1":{"v":"\n- dying or dead\n- url: https://trinity-rdf.net/\n- repo: https://github.com/semiodesk/trinity-rdf\n- built_on: [[prdct.dotnetrdf]] [[prdct.relinq]]\n- !built_on: [[prdct.graph-engine]], just a naming coincidence\n- related: [[prdct.olga]]\n\n## Features\n\n- compatible with [[prdct.virtuoso]]\n\n\n## Resources\n\n- [A Distributed Graph Engine for Web Scale RDF Data](http://www.vldb.org/pvldb/vol6/p265-zeng.pdf)\n\n### Learning Resources\n\n- https://trinity-rdf.net/doc/tutorials/firstSteps.html","n":0.167}}},{"i":2002,"$":{"0":{"v":"Triggermesh","n":1},"1":{"v":"\n[[t.cs.sd.architecture.event-driven.event-broker]]\n\n- url: https://www.triggermesh.com/\n- written_in: go\n- [[p.supports]] [[prdct.cloudevents]]\n- [[p.similarTo]] [[prdct.aws.event-bridge]]\n\n\n- \"TriggerMesh abstracts event brokers, event sources and event sinks. For brokers, you can swap whichever message streaming technology you want. You can use Kinesis, Kafka, Google PubSub, ~~[[NATS|prdct.nats]]~~, and/or others.\"\n  - https://thenewstack.io/supercharging-event-driven-integrations-using-apache-kafka-and-triggermesh/\n  - t.2024.03.31.12 can't find any references to NATS\n- \"FaaS can be thought of as the glue that connects cloud services together and that gets executed when certain events happen. Serverless enables developers to focus on applications that consist of event-driven functions that respond to a variety of triggers.\"\n  - \"https://www.triggermesh.com/blog/what-every-cio-needs-to-know-about-serverless-part-2\"","n":0.105}}},{"i":2003,"$":{"0":{"v":"Trifid","n":1},"1":{"v":"\n- https://zazuko.com/products/trifid/\n- [[c.software.semantic.browser]] [[c.software.semantic.publishing.site-generator]]\n- repo: https://github.com/zazuko/trifid\n- written_in: javascript\n- published-by: [[org.zazuko]]\n- built_on: [[prdct.node]]\n![[prdct.pubby#^4ldbidz2j6c8]]\n\n## Requirements\n\n- SPARQL endpoint, or\n- triple in a local file (uses built-in in-memory store)\n\n## Features\n\n-   Provides a Linked Data interface to SPARQL protocol servers\n-   Provides an in-memory store suitable for smaller data sets and testing environments\n-   Provides a simple HTML interface showing the data available about each resource\n-   Support for multiple HTML templates based on namespace patterns\n-   HTML view is providing embedded JSON-LD, which is rendered by client-side JavaScript\n-   Takes care of content-negotiation\n-   Runs well behind HTTP reverse proxies like Varnish\n-   Provides a SPARQL proxy and [YASGUI](http://about.yasgui.org/)\n","n":0.101}}},{"i":2004,"$":{"0":{"v":"Trellis Ldp","n":0.707},"1":{"v":"\n- [[c.software.semantic.linked-data-platform]]\n- https://www.trellisldp.org\n- [[c.software.semantic.linked-data-platform]]\n- repo: https://github.com/trellis-ldp/trellis/\n- related: [[t.cs.semantic-web.linked-data-platform]]\n- uses: [[prdct.webac]] [[prdct.quarkus]]\n\n## Standards\n\nThe Web standards implemented by Trellis include:\n\n-   [RFC 7089](https://tools.ietf.org/html/rfc7089) (HTTP Framework for Time-Based Access to Resource States\n-   [RFC 7519](https://tools.ietf.org/html/rfc7519) (JSON Web Tokens)\n-   [SOLID WebAC](https://github.com/solid/solid-spec#authorization-and-access-control) (Authorization and Access Control)\n-   [W3C Activity Streams](https://www.w3.org/TR/activitystreams-core/)\n-   [W3C JSON-LD](https://www.w3.org/TR/json-ld/)\n-   [W3C Linked Data Notifications](https://www.w3.org/TR/ldn/)\n-   [W3C Linked Data Platform](https://www.w3.org/TR/ldp/)\n-   [W3C RDF 1.1 Concepts and Abstract Syntax](https://www.w3.org/TR/rdf11-concepts/)\n-   [W3C Web Annotation Protocol](https://www.w3.org/TR/annotation-protocol/)\n-   [W3C WebID](https://www.w3.org/2005/Incubator/webid/spec/identity/) \n-   [W3C WebSub](https://www.w3.org/TR/websub/) [[prdct.websub]]","n":0.12}}},{"i":2005,"$":{"0":{"v":"Tptp","n":1}}},{"i":2006,"$":{"0":{"v":"Tpfancontrol","n":1},"1":{"v":"\n- for when BIOS isn't so smart","n":0.378}}},{"i":2007,"$":{"0":{"v":"TOQL","n":1},"1":{"v":"\n\n## References\n\n- [[ar.the-toql-system]]","n":0.577}}},{"i":2008,"$":{"0":{"v":"TopoJSON","n":1},"1":{"v":"\n- repo: https://github.com/topojson/topojson-specification\n- [[p.extends]] [[prdct.geojson]]\n\n\n## Resources\n\n- https://fenixfox-studios.com/content/leaflet_geojson_&_topojson/","n":0.378}}},{"i":2009,"$":{"0":{"v":"Topbraid EDG","n":0.707}}},{"i":2010,"$":{"0":{"v":"Topbraid Composer","n":0.707},"1":{"v":"\n- https://franz.com/agraph/tbc/\n- [[c.software.semantic.ontology-editor]] [[c.software.semantic.authoring]]\n- download: https://archive.topquadrant.com/topbraid-composer-install/\n- based-on: [[prdct.eclipse]]\n![[prdct.protege#similar]]\n\n## Versions\n\n- Free\n  - supports RDF/OWL and running SPARQL\n  - define business rules/integrity constraints using SPARQL rules (SPIN)\n\n## vs EDG\n\n- \"It's also much easier to deal with files in Git with Composer than with [[Studio|prdct.topbraid-edg]].\"\n\n## References\n\n- https://semantrix.com.au/pages/products-platforms/topquadrant/topbraid-composer/\n- [[vs.tbox-vs-abox-vs-mbox]]\n- https://www.mail-archive.com/topbraid-users@googlegroups.com/msg12100.html","n":0.147}}},{"i":2011,"$":{"0":{"v":"Sorted Turtle","n":0.707},"1":{"v":"\n- proprietary\n- also has sorted turtle+","n":0.408}}},{"i":2012,"$":{"0":{"v":"Tone JS","n":0.707},"1":{"v":"\n- repo: https://github.com/Tonejs/Tone.js","n":0.577}}},{"i":2013,"$":{"0":{"v":"Todoist","n":1}}},{"i":2014,"$":{"0":{"v":"Tlon Network","n":0.707},"1":{"v":"\n- url: https://lommur-nampet.tlon.network/","n":0.577}}},{"i":2015,"$":{"0":{"v":"Tinybase","n":1},"1":{"v":"\n\n\n- resources:  https://javascript.plainenglish.io/an-open-source-javascript-library-for-structured-state-ea1e5865566a\n- [[p.hasSite]] https://tinybase.org/\n  - [[p.hasSummaryPoints]] Using plain old JavaScript objects to manage data gets old very quickly. It's error-prone, tricky to track changes efficiently, and easy to mistakenly incur performance costs.\n","n":0.174}}},{"i":2016,"$":{"0":{"v":"Tinkerpop","n":1}}},{"i":2017,"$":{"0":{"v":"Timeshift","n":1},"1":{"v":"\n- repo: https://github.com/linuxmint/timeshift","n":0.577}}},{"i":2018,"$":{"0":{"v":"Timescale","n":1},"1":{"v":"\n- url: https://www.timescale.com\n- [-] Is Timescale the product from that conference a while ago? maybe check onenote?","n":0.243}}},{"i":2019,"$":{"0":{"v":"TimeML","n":1},"1":{"v":"\n\n\n- [[p.hasSpecification]] https://www.cs.brandeis.edu/~cs112/cs112-2004/annPS/TimeML12wp.htm \n- related: [[t.cs.data.temporality.transaction-time]]\n","n":0.408}}},{"i":2020,"$":{"0":{"v":"Timeliner JS","n":0.707},"1":{"v":"\n- https://technotarek.com/timeliner/\n- [[c.software.visualization.temporal]]","n":0.577}}},{"i":2021,"$":{"0":{"v":"Timelinejs","n":1},"1":{"v":"\n- https://timeline.knightlab.com/\n- [[c.software.visualization.temporal]]","n":0.577}}},{"i":2022,"$":{"0":{"v":"Tiktok","n":1},"1":{"v":"\n- encourage creativity","n":0.577}}},{"i":2023,"$":{"0":{"v":"Tiger","n":1},"1":{"v":"\n\n\n- resources:  https://javascript.plainenglish.io/rest-is-dying-get-rid-of-it-d43e6ef80cbe\n","n":0.577}}},{"i":2024,"$":{"0":{"v":"Tigase","n":1},"1":{"v":"\n- [[c.software.xmpp-server]]\n- repo: https://github.com/tigase/tigase-server\n- written-in: java [[t.cs.languages.groovy]]","n":0.378}}},{"i":2025,"$":{"0":{"v":"Tidio","n":1},"1":{"v":"\n- [[c.software.ai.bot-framework]]","n":0.707}}},{"i":2026,"$":{"0":{"v":"Tick Knock","n":0.707},"1":{"v":"\n- repo: https://github.com/mayakwd/tick-knock\n- - [[p.implements]] [[t.cs.entity-component-system]]\n\n## [[p.hasConcept]]\n\n- `tag` for marking attributes of an entity instead of a no-data component\n- `LinkedComponent` for attaching multiple identical components, e.g.\n  - damage\n    - [[p.provokedThoughts]] seems unusual \n- `Snapshot` a container that displays the difference between the current state of Entity and its previous state\n- `sharedConfig` \n\n\n## [[p.hasLearningResource]]\n\n- https://medium.com/@rdolivo/ecs-for-gamedev-with-typescript-5a1204f594bc\n- [[p.implements]] [[t.cs.entity-component-system]]","n":0.134}}},{"i":2027,"$":{"0":{"v":"Thyseus","n":1},"1":{"v":"\n- [[c.software.entity-component-system]]\n- repo: https://github.com/JaimeGensler/thyseus\n\n## Cons\n\n- \n\n\n## Examples\n\n- [[game.pizza-legends-thyseus]]","n":0.354}}},{"i":2028,"$":{"0":{"v":"Thymeleaf","n":1},"1":{"v":"url: https://www.thymeleaf.org/\nworks with: [[prdct.spring.framework]], [[prdct.play-framework]]\nwritten in: java \n\n\n## Goals\n\n- elegant natural templates\n  - HTML that can be correctly displayed in browsers and also work as static prototypes, allowing for stronger collaboration in development teams","n":0.171}}},{"i":2029,"$":{"0":{"v":"Thunder Client","n":0.707},"1":{"v":"\n- [[c.software.tools.testing.api]]","n":0.707}}},{"i":2030,"$":{"0":{"v":"ThreeDWorld","n":1},"1":{"v":"\n- aka: TDW\n- url: https://www.threedworld.org/\n- repo: https://github.com/threedworld-mit/tdw\n\n## Description\n\n- A TDW simulation consists of two components: a) the Build, a compiled executable running on the Unity3D Engine, which is responsible for image rendering, audio synthesis and physics simulations; and b) the Controller, an external Python interface to communicate with the build.\n\n## Features\n\n- \"Every object in the model librarian has been semantically tagged by category: the wcategory and wnid parameters are the object's WordNet category and ID values.\"\n- \"In order to use keyboard and mouse controls, the TDW build window must be focused (i.e. be the selected window). This means that keyboard controls will only work on personal computers.\"\n  - \"When a key press or key hold occurs, Keyboard can either send a command to the controller, or trigger a function.\"","n":0.088}}},{"i":2031,"$":{"0":{"v":"three.js","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n\n## Resources\n\n- https://dev.to/covenantwest/building-a-3d-bakery-shop-with-threejs-a-step-by-step-guide-5ep0?context=digest\n\n### Learning Resources\n\n- https://udemy.com/course/threejs-tutorials/\n","n":0.378}}},{"i":2032,"$":{"0":{"v":"Thirdweb","n":1}}},{"i":2033,"$":{"0":{"v":"Third Room","n":0.707},"1":{"v":"\n- #dead due to lack of funding See [](https://matrix.to/#/!rzmCByrDIhEbURWmyW:matrix.org/$Ma0FH-hEbXdTSdTFNCH5m-LhJ8zKgznnSi91g0K78dE?via=matrix.org&via=thirdroom.io&via=element.io)\n- [[c.software.metaverse-platform]]\n\n- url: https://thirdroom.io/\n- repo: https://github.com/matrix-org/thirdroom\n\n- written-in: #c typescript\n- [[p.builtOn]] [[prdct.matrix]]\n- [[p.builtWith]] [[prdct.bitecs]] [[prdct.three-js]]\n- [[p.supports]] [[prdct.gltf]] [[prdct.unity]]\n- [[p.similarTo]] [[prdct.hubs]]\n\n## Resources\n\n- https://matrix.org/blog/2023/06/07/introducing-third-room-tp-2-the-creator-update/\n  - in this update we’ve focused on building out the scripting, editing and authoring capabilities of Third Room to provide a solid platform for building and running collaborative 3D apps of any kind.","n":0.127}}},{"i":2034,"$":{"0":{"v":"WebSG","n":1},"1":{"v":"\n- [[p.used]] [[prdct.quickjs]]\n\n## Resources\n\n### Learning Resource\n\n- https://thirdroom.io/docs/guides/websg/basketball/part-1.html","n":0.378}}},{"i":2035,"$":{"0":{"v":"Thinkific","n":1},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.edu.courseware]] [[t.soc.online-community]]\n","n":0.5}}},{"i":2036,"$":{"0":{"v":"Thingweb","n":1},"1":{"v":"\n- url: https://www.thingweb.io/\n\n## Features\n\n-   **Describe devices:** information, capabilities, and data schemas in a standardized format\n-   **Integrate devices:** connectivity via various IoT protocols under a uniform interface\n-   **Validate device descriptions:** consistent metadata for your devices and across directories\n-   **Develop applications:**Web browser-like runtime for (headless) portable IoT apps","n":0.147}}},{"i":2037,"$":{"0":{"v":"Things (app)","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://culturedcode.com/things/\n- [[p.addressed]] [[t.tm]]\n","n":0.447}}},{"i":2038,"$":{"0":{"v":"thi.ng","n":1},"1":{"v":"\n- url: https://thi.ng/","n":0.577}}},{"i":2039,"$":{"0":{"v":"thi.ng/ecs","n":1},"1":{"v":"\n- #alpha\n- [[c.software.entity-component-system]]\n- repo: https://github.com/ecsyjs/ecsy","n":0.447}}},{"i":2040,"$":{"0":{"v":"Thi-Ng Date","n":0.707},"1":{"v":"\n- [[c.software.library.temporal]]\n- repo: https://github.com/thi-ng/umbrella/tree/develop/packages/date","n":0.5}}},{"i":2041,"$":{"0":{"v":"The Sample","n":0.707},"1":{"v":"\n- created_by: @jacob-obryant","n":0.577}}},{"i":2042,"$":{"0":{"v":"The Root Network","n":0.577},"1":{"v":"\n- https://www.therootnetwork.com/\n\n## Description\n\n- the underlying blockchain infrastructure that supports many of the experiences, protocols, and applications developed by [[Futureverse|org.futureverse]]\n\n## Features\n\n- Build dynamic games or level up existing assets with powerful interoperability, unlocking true player ownership.\n- Leverage our cutting-edge framework built on Substrate, integrated EVM, and custom runtimes.\n- enable interoperable AI experiences for your metaverse assets on demand with our Non-Fungible Intelligence (NFI) Protocol.\n- ","n":0.126}}},{"i":2043,"$":{"0":{"v":"The Only Sheet","n":0.577}}},{"i":2044,"$":{"0":{"v":"The Matrix ABM","n":0.577},"1":{"v":"\n- #dead\n- repo: https://github.com/NSSAC/matrixabm\n- [[p.builtOn]] [[prdct.rabbitimq]] [[prdct.act-r]]\n\n![](/assets/images/2023-09-22-14-20-42.png)\n\n## Resources\n\n- https://parantapa.net/mypapers/bhattacharya-aamas19.pdf\n  - [[p.mentioned]] [[t.cs.graph.graph-dynamical-system-model]]","n":0.289}}},{"i":2045,"$":{"0":{"v":"The Guild","n":0.707},"1":{"v":"\n\n## Features\n\n- supports [[prdct.server-sent-events]]","n":0.5}}},{"i":2046,"$":{"0":{"v":"The Graph","n":0.707},"1":{"v":"\n\n\n- [[p.hasSite]] https://thegraph.com\n","n":0.577}}},{"i":2047,"$":{"0":{"v":"The Forge","n":0.707},"1":{"v":"\n- [[c.software.rpg.hosting]] for [[prdct.foundry-vtt]]\n- https://forge-vtt.com/\n\n## Features\n\n- Assets Library\n\n- Patreon linkage is cool","n":0.289}}},{"i":2048,"$":{"0":{"v":"Thanos","n":1},"1":{"v":"\n- https://thanos.io/","n":0.707}}},{"i":2049,"$":{"0":{"v":"TextX","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n- repo: http://textx.github.io/textX/\n- [[p.inspiredBy]] [[prdct.xtext]]\n- written-in: #python\n\n## Resources\n\n- https://tomassetti.me/domain-specific-languages-in-python-with-textx/\n- ","n":0.316}}},{"i":2050,"$":{"0":{"v":"Textile","n":1},"1":{"v":"\n\n- [[p.hasLearningResource]] https://docs.filecoin.io/build/textile-buckets/\n","n":0.577}}},{"i":2051,"$":{"0":{"v":"Text Encoding Initiative (TEI)","n":0.5},"1":{"v":"\n- https://tei-c.org/","n":0.707}}},{"i":2052,"$":{"0":{"v":"Text as Graph","n":0.577},"1":{"v":"\n## [[c.abstract]]\n\nOver the past decades, the question of what text really is has been addressed by a large number of conferences, workshops, articles, and blog posts. If there is one thing that, taken together, those contributions illustrate, it is that our understanding of text is—and has been—constantly in flux and open to many interpretations. Still, there is often a gap between how an editor conceptualizes a source text and how this text is encoded and stored on a computer: using TEI XML, editors are compelled to model their text as a single tree (a hierarchy), whether this structure corresponds with their intellectual understanding or not. Textual features that do not fit naturally into the XML data model require additional layers of code, which hinders processing, querying, and interchange.\n\nThe Text-As-Graph (TAG) data model and the associated syntax [[prdct.tagml]] are developed to express and store textual information as a network. To this end, TAG implements a hypergraph model. In the present contribution, we illustrate the benefits of TAG’s hypergraph for the modeling of features like nonlinearity, discontinuity, and overlap. In contrast to a tree model, a hypergraph accommodates these nonhierarchical structures naturally. By making them part of the data model and the syntax, a TAGML processor can process the features without having to resort to workarounds or schema-aware tools. This lowers the difficulty of working with digital editions and facilitates querying and interchange.\n\n## Summary\n\n- The regular edges in the TAG hypergraph model are directed; the hyperedges are undirected. Nodes in the hypergraph can be connected with either a hyperedge or a regular edge.\n- The TAG hypergraph consists of five types of nodes:\n  - One Document node. This node serves as the root of the graph. Via a directed edge, the Document node is connected to zero or more Text nodes, Markup nodes, Branching nodes, or Annotation nodes.\n  - One or more Text nodes. A Text node contains textual content (UTF-8-encoded), and may be connected to one or more Markup nodes with hyperedges. It is connected to other Text nodes or Branching nodes with directed edges.\n  - Zero or more Markup nodes. A Markup node is connected to one or more Text nodes, and has zero or more Annotation nodes.\n  - Zero or more Annotation nodes. The Annotation node is connected to one or more Markup nodes or another Annotation node.\n  - Zero or more Branching nodes. A Branching node is connected to a Text node or another Branching node with a directed edge. It is used to mark the beginning and end of a nonlinear structure.\n\n\n## Resources\n\n- [[ar.texts-as-hypergraphs-an-intuitive-representation-of-interpretations-of-text]]\n- [[t.cs.graph.hypergraph]]","n":0.048}}},{"i":2053,"$":{"0":{"v":"Terrastruct","n":1},"1":{"v":"\n- [[c.pricing]] $20 month/user\n- [[p.supports]] [[prdct.d2]]","n":0.408}}},{"i":2054,"$":{"0":{"v":"Terraform","n":1},"1":{"v":"\n- similar_to: [[prdct.pulumi]] [[prdct.crossplane]]","n":0.5}}},{"i":2055,"$":{"0":{"v":"Terminal Link","n":0.707},"1":{"v":"\nrepo: https://github.com/sindresorhus/terminal-link","n":0.707}}},{"i":2056,"$":{"0":{"v":"Terasology","n":1},"1":{"v":"\n- [[c.software.game-maker]]\n- [[c.game.voxel]] [[c.game.sandbox]]\n- url: https://terasology.org/\n- written-in: java\n- [[p.similarTo]] [[prdct.minecraft]] [[prdct.minetest]] [[prdct.vintage-story]]\n\n## Description\n\nTerasology is a game that pays ample tribute to Minecraft in initial look and origin, but stakes out its own niche by aiming for the NPC-helper and caretaker focus from such games as Dwarf Fortress and Dungeon Keeper, while striving for added depth and sophistication.","n":0.132}}},{"i":2057,"$":{"0":{"v":"Temporal","n":1},"1":{"v":"\nhttps://temporal.io/\n- [[c.Software.Workflow]]\n- pronunciation: tem-POR-al\n- fork_of: [[prdct.cadence]]\n- related: [[prdct.iwf]]\n\n![[prdct.n8n#^xnxaubd7sqiw]]\n \n![[prdct.infinitic#similar]]\n\n## Features\n\n- time-travel debugging aka [[t.cs.debugging.reverse]]\n- [[t.cs.durable-execution]]\n\n## Notes\n\n- uses gRPC for all interprocess communication.\n\n## vs [[prdct.cadence]]\n\n- Temporal allows associating metadata with every payload. It enables features like dynamically pluggable serialization mechanisms, seamless compression, and encryption.\n- Temporal supports typescript and python via SDKs\n\n## References\n\n- https://www.youtube.com/watch?v=wIpz4ioK0gI\n  - \"queues are not a good way to communicate among services when you have complex transactions\" @9:34\n- https://stackoverflow.com/questions/61157400/temporal-workflow-vs-cadence-workflow","n":0.12}}},{"i":2058,"$":{"0":{"v":"Tekton","n":1},"1":{"v":"\n- [[t.cs.sd.architecture.orchestration]] vs [[t.cs.sd.architecture.choreography]]\n\n## [[c.component]]\n\n-   **Pipeline:** Pipeline defines a set of Kubernetes [Custom Resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) that act as building blocks you use to assemble your CI/CD pipelines.\n-   **Triggers:** Triggers is a Kubernetes Custom Resource that allows you to create pipelines based on information extracted from event payloads. For example, you can trigger the instantiation and execution of a pipeline every time a merge request gets opened against a Git repository.\n-   **CLI:** CLI provides a command-line interface called `tkn` that allows you to interact with Tekton from your terminal.\n-   **Dashboard:** Dashboard is a web-based graphical interface for Tekton pipelines that displays information about the execution of your pipelines.\n-   **Catalog:** Catalog is a repository of high-quality, community-contributed Tekton building blocks (tasks, pipelines, and so on) ready for use in your own pipelines.\n-   **Hub:** Hub is a web-based graphical interface for accessing the Tekton catalog.\n-   **Operator:** Operator is a Kubernetes [Operator pattern](https://operatorhub.io/what-is-an-operator) that allows you to install, update, upgrade, and remove Tekton projects on a Kubernetes cluster.\n-   **Chains:** Chains is a Kubernetes Custom Resource Definition (CRD) controller that allows you to manage your supply chain security in Tekton. It is currently a work-in-progress.\n-   **Results:** Results aims to help users logically group CI/CD workload history and separate out long-term result storage away from the pipeline controller.\n\n## [[c.term]]\n\n  -   **Step:** A step is the most basic entity in a CI/CD workflow, such as running some unit tests for a Python web app or compiling a Java program. Tekton performs each step with a provided container image.\n-   **Task:** A task is a collection of steps in a specific order. Tekton runs a task in the form of a [Kubernetes pod](https://kubebyexample.com/en/concept/pods), where each step becomes a running container in the pod.\n-   **Pipelines:** A pipeline is a collection of tasks in a specific order. Tekton collects all tasks, connects them in a directed acyclic graph (DAG), and executes the graph in sequence. In other words, it creates a number of Kubernetes pods and ensures that each pod completes running successfully as desired.  \n    \n    ![Tekton pipelines](https://opensource.com/sites/default/files/uploads/tekton-pipelines.png \"Tekton pipelines\")\n    \n    \n-   **PipelineRun:** A PipelineRun, as its name implies, is a specific execution of a pipeline.\n-   **TaskRun:** A TaskRun is a specific execution of a task. TaskRuns are also available when you choose to run a task outside a pipeline, with which you may view the specifics of each step execution in a task.\n\n## Resources\n\n- https://www.redhat.com/en/blog/tekton-vs-jenkins-whats-better-cicd-pipelines-red-hat-openshift\n  - \"the notion of formal dev, test and UAT type environments is largely an old-world concept.\"\n\n## Comparison\n\n- https://platform9.com/blog/argo-cd-vs-tekton-vs-jenkins-x-finding-the-right-gitops-tooling/","n":0.051}}},{"i":2059,"$":{"0":{"v":"Tawny-OWL","n":1},"1":{"v":"\n- repo: https://github.com/phillord/tawny-owl\n- [[c.software.semantic.ontology-editor]] [[c.software.semantic.authoring]] \n- written-in: clojure\n- created-by: @phil-lord\n\n## Resources\n\n- https://vimeo.com/89782389\n  - @phil-lord: \"Protege is the Excel of the ontology world\" ^m1l0lh2seh0h","n":0.209}}},{"i":2060,"$":{"0":{"v":"Tasksboard","n":1},"1":{"v":"\n\nmulti-list \"Google Tasks\" management with offline option (as a Chrome App)\n","n":0.302}}},{"i":2061,"$":{"0":{"v":"Tarql","n":1}}},{"i":2062,"$":{"0":{"v":"Tarant","n":1},"1":{"v":"\n- url: https://github.com/tarantx\n- repo: https://github.com/tarantx/tarant\n- written-in: typescript\n- ","n":0.378}}},{"i":2063,"$":{"0":{"v":"Talespire","n":1},"1":{"v":"\n- https://talespire.com/\n- devlog: https://bouncyrock.com/news","n":0.5}}},{"i":2064,"$":{"0":{"v":"Tales from the Loop","n":0.5}}},{"i":2065,"$":{"0":{"v":"Tailwind CSS","n":0.707},"1":{"v":"\n- url: https://tailwindcss.com/\n- ","n":0.577}}},{"i":2066,"$":{"0":{"v":"Tads","n":1}}},{"i":2067,"$":{"0":{"v":"Tabletopia","n":1},"1":{"v":"\nurl: https://tabletopia.com/\n","n":0.707}}},{"i":2068,"$":{"0":{"v":"Workshop","n":1},"1":{"v":"\n[[c.software.game-maker]]\n\nurl: https://tabletopia.com/workshop\n","n":0.707}}},{"i":2069,"$":{"0":{"v":"Tabletop Simulator Tts","n":0.577},"1":{"v":"\n- https://store.steampowered.com/app/286160/Tabletop_Simulator/\n- [[c.software.rpg.virtual-tabletop]]","n":0.577}}},{"i":2070,"$":{"0":{"v":"Tables Generator","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.tablesgenerator.com/markdown_tables\n","n":0.577}}},{"i":2071,"$":{"0":{"v":"Tableplop","n":1}}},{"i":2072,"$":{"0":{"v":"Tab Stash","n":0.707},"1":{"v":"\n- url: https://addons.mozilla.org/en-US/firefox/addon/tab-stash/","n":0.577}}},{"i":2073,"$":{"0":{"v":"T5c","n":1},"1":{"v":"\n- [[c.software.game-engine]]\n- repo: https://github.com/orion3dgames/t5c\n- [[t.edu.learning-in-public]]\n- written-in: [[prdct.typescript]]\n- [[p.coreferences]] [[sh.review.t5c]]","n":0.333}}},{"i":2074,"$":{"0":{"v":"System Initiative","n":0.707},"1":{"v":"\n- url: https://www.systeminit.com\n- repo: https://github.com/systeminit/si\n\n\n## Resources\n\n- https://thenewstack.io/system-initiative-a-devops-makeover-by-ex-chef-adam-jacob/\n- https://www.techtarget.com/searchitoperations/feature/Chef-founders-new-venture-IT-infrastructure-digital-twins","n":0.354}}},{"i":2075,"$":{"0":{"v":"SysML","n":1},"1":{"v":"\n- https://github.com/Systems-Modeling/SysML-v2-Release\n\n\n## References\n\n- ","n":0.577}}},{"i":2076,"$":{"0":{"v":"Sysend","n":1},"1":{"v":"\nrepo: https://github.com/jcubic/sysend.js\n\n\"The new version has the #RPC like mechanism that allows calling methods between browser Tabs.\"\n\n## Resources\n\n- https://itnext.io/how-to-create-web-server-in-browser-ffaa371d2b53s\n  - [[p.used]] [[prdct.wayne]]","n":0.218}}},{"i":2077,"$":{"0":{"v":"Syrinscape","n":1},"1":{"v":"\n- https://syrinscape.com/","n":0.707}}},{"i":2078,"$":{"0":{"v":"Apache Syncope","n":0.707},"1":{"v":"\n- https://syncope.apache.org\n- repo: https://github.com/apache/syncope\n\n\n## Resources\n\n- https://syncope.apache.org/docs/3.0/getting-started.html","n":0.408}}},{"i":2079,"$":{"0":{"v":"Synapse Repository","n":0.707},"1":{"v":"\n- https://www.synapse.org/\n- [[c.software.repository]]\n- different-from: [[prdct.synapse-matrix-server]]","n":0.447}}},{"i":2080,"$":{"0":{"v":"Synapse Matrix Server","n":0.577},"1":{"v":"\n- repo: https://github.com/matrix-org/synapse\n- ","n":0.577}}},{"i":2081,"$":{"0":{"v":"Syn Virtual Assistant Framework","n":0.5},"1":{"v":"\n- https://developer.syn.co.in/tutorial/va/index.html\n- related: [[prdct.oscova]]\n\n## Features\n\n\n* Natural Language Understanding\n* 3D Avatar System\n* Speech Recognition\n* Plugin Mechanism\n* Response Generation\n* Message Processing\n* Event Handling\n* GUI Settings System\n","n":0.204}}},{"i":2082,"$":{"0":{"v":"Symfony","n":1},"1":{"v":"\n- https://symfony.com/\n- ","n":0.707}}},{"i":2083,"$":{"0":{"v":"Swrlapi Drools Engine","n":0.577},"1":{"v":"\nhttps://github.com/protegeproject/swrlapi-drools-engine\n- written-in: java","n":0.577}}},{"i":2084,"$":{"0":{"v":"Swrl","n":1},"1":{"v":"\n\n- related: [[prdct.datalog]] [[prdct.ruleml]] [[prdct.sqwrl]]\n- spec: https://www.w3.org/submissions/SWRL/\n\n\n## Issues\n\n- SWRL shares OWL’s open world assumption so certain types of rules that assume a closed world may be difficult or impossible to write in SWRL\n\n## Resources\n\n- http://dior.ics.muni.cz/~makub/owl/\n\n## References\n\n- https://www.michaeldebellis.com/post/drools-vs-pellet-for-swrl-rules by @michael-debellis\n  - the difference between using [[prdct.drools]] and using the [[prdct.pellet]] reasoner and why using Pellet is usually the better option\n  - Another excellent use of DROOLS is that it is used to extend SWRL's time built-ins to implement the [[t.cs.time.allens-interval-algebra]]  for reasoning about time.\n- https://github.com/protegeproject/swrlapi/wiki/ModellingTime\n\n","n":0.109}}},{"i":2085,"$":{"0":{"v":"Sword and Source","n":0.577},"1":{"v":"\n- url: https://swordandsource.ca/\n- #related [[prdct.storycraft]]","n":0.447}}},{"i":2086,"$":{"0":{"v":"Swoop","n":1},"1":{"v":"\n- dead\n- https://www.w3.org/2001/sw/wiki/SWOOP\n- repo: https://github.com/ronwalf/swoop","n":0.447}}},{"i":2087,"$":{"0":{"v":"Swoogle","n":1},"1":{"v":"\n- [[c.software.semantic.search-engine]]\n- url: https://ebiquity.umbc.edu/project/html/id/53/Swoogle","n":0.5}}},{"i":2088,"$":{"0":{"v":"Swift","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/swift/swift\n- written-in: #c++","n":0.408}}},{"i":2089,"$":{"0":{"v":"SwellRT","n":1},"1":{"v":"\n- dead\n- url: https://swellrt.org/\n- ","n":0.5}}},{"i":2090,"$":{"0":{"v":"SwaggerHub","n":1},"1":{"v":"\n## Pricing\n\n- free, public APIs, 1 user\n\n## Support\n\n- [[prdct.asyncapi]], but\n  - \"There is no support for Codegen for AsyncAPI APIs.\"\n  - \"There is no support for API Mocking for AsyncAPI APIs.\"","n":0.18}}},{"i":2091,"$":{"0":{"v":"Swagger Editor","n":0.707},"1":{"v":"\n- url: https://editor-next.swagger.io/\n- support: [[prdct.asyncapi]]","n":0.447}}},{"i":2092,"$":{"0":{"v":"Svg","n":1}}},{"i":2093,"$":{"0":{"v":"Svg JS","n":0.707},"1":{"v":"\n- docs: https://svgjs.dev/docs/3.0/\n- repo: https://github.com/svgdotjs/svg.js","n":0.447}}},{"i":2094,"$":{"0":{"v":"Svelto.ECS","n":1},"1":{"v":"\n\n- [[c.software.entity-component-system]]\n- written-in: [[t.cs.languages.c-sharp]]\n- [[p.hasRepository]] https://github.com/sebas77/Svelto.ECS\n- [[p.hasCreator]] @sebas77\n- [[p.supports]] [[prdct.stride3d]]\n- resources:  \n  - [[ar.sebaslab.the-quest-for-maintainable-code-and-the-path-to-ecs]]\n  - [[ar.sebaslab.whats-new-in-svelto-ecs-3-0]]\n  - https://levelup.gitconnected.com/a-beginners-guide-to-svelto-ecs-3-0-with-unity-e9dbc88a2145\n  - https://www.sebaslab.com/ecs-abstraction-layers-and-modules-encapsulation/\n\n\n## Interesting\n\n- In Gamecraft, all the game logic is written with Svelto.ECS, but the physic is simulated with the DOTS ECS physic library with all the performance benefits that come with it.\n\n## Cons\n\n- The main difference compared to any other Archetype-b\n- components must be structs, and they cannot hold reference type of any kind. Or you cannot dynamically add or remove component from any entity at runtime. (It means the form/design of an entity is static/immutable.)\n\n## Resources\n\n- ","n":0.102}}},{"i":2095,"$":{"0":{"v":"Sveltekit","n":1},"1":{"v":"\n\n- [[p.hasFeature]]\n  - [[p.hasSource]] https://www.smashingmagazine.com/2021/10/real-time-multi-user-game/\n    -   Svelte is a UI framework _and_ a compiler and therefore ships minimal code without a client runtime;\n    -   Svelte has an expressive templating language and component system (personal preference);\n    -   Svelte includes global stores, transitions and animations out of the box, which means: no decision fatigue choosing a global state management toolkit and an animation library;\n    -   Svelte supports scoped CSS in single-file-components;\n    -   SvelteKit supports SSR, simple but flexible file-based routing and server-side routes for building an API;\n    -   SvelteKit allows for each page to run code on the server, e.g. to fetch data that is used to render the page;\n    -   Layouts shared across routes;\n    -   SvelteKit can be run in a serverless environment.\n- [[p.hasExample]]\n  - https://github.com/sveltejs/realworld","n":0.089}}},{"i":2096,"$":{"0":{"v":"Svelte","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[prdct.solid-js]]\n- [[p.hasFeature]] [[t.cs.reactive]]\n  - \"No more complex state management libraries — Svelte brings reactivity to JavaScript itself\"\n- [[p.hasCriticism]] Svelte’s originality and the way it introduces new behaviors in basic JavaScript syntax have whet my appetite. But by the same measure, I’m wary of putting this in the hands of junior developers, who might end up believing that Svelte is how javascript actually works in the wild.\n  - [[p.hasSource]] https://javascript.plainenglish.io/svelte-from-a-react-perspective-its-weird-but-fun-d9cc9ba242d7\n  \n\n## Resources\n\n- https://javascript.plainenglish.io/svelte-from-a-react-perspective-its-weird-but-fun-d9cc9ba242d7\n","n":0.116}}},{"i":2097,"$":{"0":{"v":"SurrealDB","n":1},"1":{"v":"\n- url: https://surrealdb.com/\n- repo: https://github.com/surrealdb/surrealdb\n- written_in: rust\n- supports: C#, javascript, rust, python, go, java\n\n## Features\n\n- live query\n- graph support via \"edge tables\" [[t.cs.graph]]\n  - https://surrealdb.com/docs/surrealql/statements/relate\n  - Offer bi-directional querying.\n  - Offer referential integrity.\n  - Allow you to store data alongside the relationship. (edges get their own tables)\n- [[prdct.geojson]] geometries\n- seems to take care of ORM/OGM mapping natively? https://docs.surrealdb.com/docs/integration/sdks/dotnet/\n\n## Issues\n\n- no RDF support\n\n## References\n\n- https://github.com/Laragear/Surreal/blob/master/README.md\n- [In Search of an Efficient Data Structure\nfor a Temporal-Graph Database](https://surrealdb.com/static/whitepaper.pdf)\n- https://surrealdb.com/blog/unlocking-streaming-data-magic-with-surrealdb-live-queries-and-change-feeds","n":0.115}}},{"i":2098,"$":{"0":{"v":"SurrealKV","n":1},"1":{"v":"\n- repo: https://github.com/surrealdb/surrealkv","n":0.577}}},{"i":2099,"$":{"0":{"v":"Supertokens","n":1},"1":{"v":"\n- url: https://supertokens.com/","n":0.577}}},{"i":2100,"$":{"0":{"v":"Superserial","n":1},"1":{"v":"\n- [[c.software.serializer]]\n- repo: https://github.com/denostack/superserial","n":0.5}}},{"i":2101,"$":{"0":{"v":"SUO-KIF","n":1},"1":{"v":"\n- related: [[prdct.sumo]] [[prdct.kif-vampire]]\n- simplified version of original [[prdct.knowledge-interchange-format]]\n\n## Description\n\n- \"=>\" for implication\n- \"<=>\" bi-implication\n- \"forall\" for universal quantification, i.e., every\n- \"exists\" for existential quantification, ie. at least one\n- by convention, relations are written with an initial lowercase, and functions, non-relational instances and classes are written with inital caps\n- ","n":0.143}}},{"i":2102,"$":{"0":{"v":"Sunsama","n":1},"1":{"v":"\n\n\nElegant, guided solution to time and task management with decent integrations and an opinionated but human approach; but ultimately, isn't it a walled garden?\n\n## features\n\n- tells me how much work I did (assuming you account for everything)\n  - but ultimately these days, I just work all day\n- encourages planning and reflection\n  - but [[ar.aaronlynn.how-to-set-up-your-personal-task-management-system]] can support it in a more flexible way\n- syncs with multiple Jira instances\n\n## personal fit\n\n- pulling in all the schedules is good, but Google Calendar can do that\n- if I cancel a Sunsama task, it just disappears\n","n":0.105}}},{"i":2103,"$":{"0":{"v":"Sumo","n":1},"1":{"v":"\n- [[c.ontology.upper]] [[c.ontology.mid]]\n- url: https://raw.githubusercontent.com/abrahaj/SUMO.owl/master/SUMO.owl\n- similar: [[prdct.milo]]\n- related: [[prdct.sigmakee]] \n\n## Issues\n\n- the OWL representation mixes EVERYTHING together, it's not really an upper ontology\n\n## Implementations\n\n- [[prdct.grammatical-framework]] see https://publications.lib.chalmers.se/records/fulltext/116606.pdf\n  - The representation of SUMO in GF preserves the expressivity of the original ontology, adding to this the advantages of a type system and built-in support for natural language generation.\n\n### Confusing representation with implementation\n\n- It is important not to confuse representation with implementation. Performing representation in the same language as the implementation risks using a language that makes it impossible (or at least very difficult or awkward) to capture certain kinds of information. For example if your implementation language doesn't allow for stating if..then rules, then you won't be able to capture that kind of information. But such rules are almost certainly needed to define each term precisely. A better approach is to capture the information and then decide how, and how much, of that knowledge can be expressed and used efficiently in your application. At least you'll have documented carefully what your concepts mean. Just because implementations can't directly reason with English, doesn't mean we shouldn't have English definitions in our data dictionaries.\n\n## Comparisons\n\n### vs Cyc\n\n- the only product truly comparable to SUMO in terms of size, scope and degree of formal definition is [[prdct.cyc]]\n\n### WordNet\n\n- [[prdct.wordnet]] is lexical\n\n### Dolce\n\n- [[prdct.dolce]] uses classes and properties in the service of describing particulars and has a set of metaproperties that aren't defined in DOLCE itself\n- \"SUMO's positions are not well-defined, hence the interpretation of their stance varies from author to author.\"\n\n\n### BFO\n\n- [[prdct.basic-formal-ontology]] - limited in scope\n\n### OWL\n\n- \"a logical language with a simplistic upper ontology\"\n\n## Conceptual Model\n\n![](/assets/images/2024-03-06-21-42-31.png)\n\n![](/assets/images/2024-03-06-21-42-47.png)\n\n![](/assets/images/2024-03-06-21-43-01.png)\n\n## Resources\n\n- [[book.ontology-a-practical-guide]]\n- [[ar.semantic-modeling-with-sumo]]\n- https://www.ontologyportal.org/FAQ.html","n":0.06}}},{"i":2104,"$":{"0":{"v":"Subtext","n":1},"1":{"v":"\n- [[p.hadSummary]] \n  - [[p.hasHighlight]]\n    - Blocks are [thought legos](https://subconscious.substack.com/p/thought-legos).\n- [[p.hasRepository]] https://github.com/subconsciousnetwork/subtext \n\n## [[p.similarTo]]\n\n- [[prdct.markdown.dendron-flavored-markdown]]\n- [[prdct.markdown]]\n  - [[p.hasComparison]]\n    - Why not Markdown?\n\n      I took a deep breath before thinking about the jump from Markdown. If you’re a programmer, Markdown is a de-facto standard for formatted text. For many, it is the first obvious choice for this kind of thing. So why Subtext?\n\n      Subtext has evolved out personal experiments with plain-text note-taking, spanning 10 years and 12k notes. Many of these notes are written in Markdown. However, over time, I noticed that my markup needs for note-taking were different from my markup needs for publishing. My note-taking style organically converged on a tiny subset of Markdown's features: text, links, lists, quotes, and one level of heading. To have more may be useful for publishing, but is often overkill for note-taking.\n\n      At the same time, I began to write small generative programs that worked with this collection of notes, little scripts that would combine ideas, remix notes, algorithmically generate new notes… these were the seeds that would later become Subconscious.\n\n      Here, I started to run into limitations with Markdown and HTML. As a complex publishing format, it is unclear how to meaningfully decompose or merge Markdown/HTML documents. When you combine documents, heading levels may need to be changed, lists may need to be flattened or nested. Because the document format is complex, foreknowledge of the meaning of the document is necessary to make meaningful changes. That limits what you can do with software.\n\n      Subtext is an attempt to resolve the problem by radically simplifying it. Paradoxically, by limiting the format to a flat list of blocks, we radically expand what software can usefully do with it. Blocks are easy to parse, easy to work with, and you can do all sorts of interesting generative algorithmic things with them.\n\n      The syntax is also simple, and hard to mess up, and I’m happy about that, too.\n","n":0.056}}},{"i":2105,"$":{"0":{"v":"Substack","n":1},"1":{"v":"\n## References\n\n- https://www.theatlantic.com/technology/archive/2024/01/substack-exodus-social-media-moderation/677113/","n":0.577}}},{"i":2106,"$":{"0":{"v":"Subconscious","n":1},"1":{"v":"\n- t.2024.05.16.09 deadas\n- [[p.similarTo]] [[prdct.dendron]]\n- [[p.hasCreator]] @gordan-brander\n- [[p.hasLayers]]\n  - [[prdct.ipfs]]\n  - [[prdct.noosphere]]\n  - [[prdct.subtext]]","n":0.267}}},{"i":2107,"$":{"0":{"v":"Stych","n":1},"1":{"v":"\n- url: https://stytch.com\n- [[c.software.authentication]] [[c.software.iam]]","n":0.447}}},{"i":2108,"$":{"0":{"v":"stSPARQL","n":1}}},{"i":2109,"$":{"0":{"v":"Structurizr","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://structurizr.org/\n\n## Similar\n\n  - [[prdct.plantuml]]\n  - [[prdct.mermaid]]\n  - [[prdct.ilograph]]\n  - [[prdct.d2]]\n  - [[prdct.terrastruct]]\n  - [[prdct.structurizr]]\n\n## Pricing\n  - free\n    - 10 diagrams, 3 most recent versions, no sharing, 1 workspace\n  - $5/workspace/month, minimum of 5 workspaces so minimum $25/mo\n- language_support: \n  - c# (via [[prdct.structurizr.dotnet]])\n    - but [[prdct.structurizr.dsl]] \n  - java\n\n## features\n\n- export to [[prdct.plantuml]] [[prdct.c4-plantuml]] [[prdct.mermaid]] [[prdct.ilograph]] [[prdct.graphviz.dot]]\n\n## Resources\n\n- [[book.the-c4-model-for-visualising-software-architecture]]\n- https://www.baeldung.com/structurizr (creating diagrams with java API)\n- https://blog.dornea.nu/2023/11/02/documentation-as-code-for-cloud-c4-model-structurizr/\n  - mentions: [[prdct.ilograph]]","n":0.119}}},{"i":2110,"$":{"0":{"v":"Structurizr DSL","n":0.707},"1":{"v":"\n- url: https://docs.structurizr.com/dsl","n":0.577}}},{"i":2111,"$":{"0":{"v":"Dotnet","n":1},"1":{"v":"\n- repo: https://github.com/structurizr/dotnet","n":0.577}}},{"i":2112,"$":{"0":{"v":"StrongDM","n":1},"1":{"v":"\n\n- @elizabeth-zalman\n","n":0.707}}},{"i":2113,"$":{"0":{"v":"Strimzi Kafka Operators","n":0.577},"1":{"v":"\nrepo: https://github.com/strimzi/strimzi-kafka-operator/releases/tag/0.32.0","n":0.707}}},{"i":2114,"$":{"0":{"v":"Strimzi Kafka Bridge","n":0.577},"1":{"v":"\nrepo: https://github.com/strimzi/strimzi-kafka-bridge\n\n## [[p.supports]]\n\n- [[prdct.opentelemetry]]\n- ","n":0.5}}},{"i":2115,"$":{"0":{"v":"Stride3d","n":1},"1":{"v":"\n- [[c.software.game-engine]]\n- [[p.alsoKnownAs]] Xenko\n- url: https://www.stride3d.net/\n- repo: https://github.com/stride3d/stride\n- [[c.comparable]] [[prdct.unity]] [[prdct.monogame]]\n- written-in: c#\n- [[p.usedBy]] [[prdct.vvvv]]\n\n## Features\n\n- [[t.cs.entity-component-system]]\n- [[p.isTopicOfDiscussion]] https://community.monogame.net/t/did-you-know-that-stride-is-basically-monogame-with-a-3d-editor/12250/4 \n\n## Cons\n\n- no game-server / server-authoritative out of the box.\n  - \"Stride works fine for building the client, but you will want a specialized and dedicated server on the back end.\"\n    - https://forums.stride3d.net/t/mmorpg-networking-noob-questions/2270/2\n- no web support\n  https://github.com/stride3d/stride/issues/70\n\n## Examples\n\n- https://github.com/xen2/Xenko.ClientServerSample #dead\n\n## [[p.vs]] [[prdct.godot]]\n\n- \"Godot is just older and more established, but Stride has a better render engine, software architecture and is a pure .NET project. So the engine and the scripting use the same technology. Godot has a C++ core and only \"interprets\" the scripting languages, which is conceptually quite different.\"\n  - https://news.ycombinator.com/item?id=32300785\n\n## Resources\n\n- https://www.sebaslab.com/svelto-miniexample-7-stride-engine-demo/\n  - [[p.isRelated]] [[prdct.svelto-ecs]]\n\n## References\n\n- [Code-Only Approach](https://github.com/stride3d/stride/issues/1295)\n- [Stride3D - Life beyond Unity?](https://www.i-programmer.info/news/144-graphics-and-games/16120-stride3d-life-beyond-unity.html)","n":0.09}}},{"i":2116,"$":{"0":{"v":"Streamr","n":1},"1":{"v":"\n\n- [[c.software.web3.protocol]] \n- url: https://streamr.network\n- [[p.supports]] [[prdct.typescript]]\n  - [[prdct.mqtt]] (via Broker node)\n- [[c.solution.related]] [[prdct.monoplasma]]\n- [[p.similarTo]] [[prdct.iota]]\n\n## Resources\n\n- https://www.disk91.com/2022/technology/blockchain/streamr-network-a-web3-topic-based-publish-subscribe-system/\n  - \"Usually when you design solutions with MQTT you have stream named like this: application_name/device_id/temperature it means, for the device 1234 in the application tempApp: tempApp/1234/temperature. MQTT allows a dynamic creation of flows. With StreamR it seems complicated to have a such dynamic creation. Flows definition is static. The CLI allow to dynamically create flow, so it can be automated but not free... stream creation cost has been 0.016 MATIC ( about $0.01 )\"\n\n- [[c.Software.real_time_framework]]","n":0.104}}},{"i":2117,"$":{"0":{"v":"Streamnative","n":1},"1":{"v":"\n- https://streamnative.io\n- pricing:\n  - hosted for $1,000/month\n  - byoc for $2500/mo","n":0.302}}},{"i":2118,"$":{"0":{"v":"Stream","n":1},"1":{"v":"\n- [[c.software.communication-server]]\n- [[c.Software.real_time_framework]]\n![[prdct.pubnub#^mbnq0t6yrz45]]\n\n## Use Cases\n\n- Gaming Chat\n  - analytics, typing indicators, group, reactions, presence, moderation\n- Chat Bots\n  - \"To build your own chat bot you can use the following 3 features of the Stream Chat API:\n    Webhooks\n    Attachments, Fields and Actions\n    Custom Attachments\"\n    - https://getstream.io/chat/docs/react/chat_bots/\n- Video API\n  - livestream, audio rooms, video calling\n\n","n":0.137}}},{"i":2119,"$":{"0":{"v":"Strava","n":1}}},{"i":2120,"$":{"0":{"v":"Straits","n":1},"1":{"v":"\n- url: https://straits.github.io\n- ","n":0.577}}},{"i":2121,"$":{"0":{"v":"Strabon","n":1},"1":{"v":"\n- https://strabon.di.uoa.gr/\n- repo: https://github.com/AI-team-UoA/Strabon\n- related: [[prdct.stsparql]]\n\n\n\n## Issues\n\n- Strabon has been implemented by extending Sesame 2.6.3 and using an RDBMS as a backend\n\n## Resources\n\n- https://strabon.di.uoa.gr/files/stSPARQL_tutorial.pdf\n\n## References\n\n- [[ar.representation-and-querying-of-valid-time-of-triples-in-linked-geospatial-data]]","n":0.196}}},{"i":2122,"$":{"0":{"v":"Storyspace","n":1},"1":{"v":"\n- http://www.eastgate.com/storyspace/\n- [[c.Software.Game-Framework.InteractiveFiction]]","n":0.577}}},{"i":2123,"$":{"0":{"v":"Storynexus","n":1},"1":{"v":"\n- http://storynexus.com/\n- [[c.Software.Game-Framework.InteractiveFiction]]\n\n## Issues\n\n- \n\n## References\n\n- https://www.ifwiki.org/StoryNexus\n","n":0.378}}},{"i":2124,"$":{"0":{"v":"Storycraft","n":1},"1":{"v":"\n- [[c.software.rpg]]\n- url: https://www.storycraft.gg/\n- description: Our product is an AI-Generated-Content (AIGC) gaming platform that reimagines how story driven video games are created, by letting creators deliver daily, episodic game content to their player base. Storycraft uses generative AI to create maps, characters, in-game objects, and to power a new type of creative gameplay where truly anything can happen.\n- written-in: typescript\n\n- The co-founders Andy and Adam are serial AI and gaming entrepreneurs. For Storycraft they have partnered with and raised capital from some of the best regarded firms in both gaming ([LVP](https://www.google.com/url?q=https://londonvp.com/&sa=D&source=editors&ust=1682025499373691&usg=AOvVaw0jN7nle42ygQcASTea5zBg) - investors of Supercell, Unity, etc) and consumer products ([SignalFire](https://www.google.com/url?q=https://signalfire.com/&sa=D&source=editors&ust=1682025499374013&usg=AOvVaw1TAAs-Pz5OaGoB6lI3BJi5) - investors in Grammarly, Clubhouse, etc). We are currently hiring the founding team and are looking for folks who are keen to innovate at the intersection of generative AI, social gaming, and storytelling.","n":0.087}}},{"i":2125,"$":{"0":{"v":"Storybook","n":1},"1":{"v":"\nrepo: https://github.com/storybookjs/storybook/\n\n- [[p.supports]]\n  - [[prdct.component-story-format]]\n\n## Resources\n\n- https://www.componentdriven.org/","n":0.378}}},{"i":2126,"$":{"0":{"v":"Story Map Building and Visualising Tool (SMBVT)","n":0.378},"1":{"v":"\n- https://dlnarratives.eu/tool.html\n- repo: https://github.com/EmanueleLenzi92/SMBVT\n- succeed: NBVT\n\n## Features\n\n### Entity types\n\n- people\n- orgs\n- objects\n- concepts\n- places\n- works\n- other\n\n### Event Types\n\n- historical\n- natural\n- valorisation\n- descriptive","n":0.213}}},{"i":2127,"$":{"0":{"v":"Story Grid","n":0.707},"1":{"v":"\n- url: https://storygrid.com/\n\n## Principles\n\n-   Stories are made up of distinct parts, or units.\n-   Stories are about change.\n-   The change that happens in stories concerns Universal Human Values, the things that most people would say are necessary to survive and thrive in the world—or alternatively, the things that keep us from surviving and thriving.\n-   Each unit of story has a Story Event, a one-sentence distillation of what’s happening and what value is changing.\n-   Within each story unit we find a pattern of change we call the Five Commandments of Storytelling.\n-   \n\n### [[idea.the-five-commandments-of-storytelling]] \n\n- The Inciting Incident, which kicks off the action; ^zyftpukzkst0\n- The Turning Point Complication, which turns the Universal Human Value at stake in the scene;\n- The Crisis, which is a big question or dilemma for one of the characters;\n- The Climax, which is the decision and action a character takes in response to the Crisis\n- The Resolution, which is theoutcome of the action that happens in the Climax ^yrwhvvxp4y9r\n","n":0.079}}},{"i":2128,"$":{"0":{"v":"Storj","n":1},"1":{"v":"\n- https://www.storj.io/\n\n## Details\n\n- In the Tardigrade Network, [[t.cs.authorization.macaroons]] are referred to as API Keys, and enable users to granularly restrict and delegate access to object data in a way that is decentralized and more secure than existing cloud solutions.","n":0.16}}},{"i":2129,"$":{"0":{"v":"Stoplight","n":1},"1":{"v":"\n- [[c.software.tools.design.api]]\n- url: https://stoplight-site.webflow.io/\n- repo: https://github.com/stoplightio\n- supports: [[prdct.openapi]]\n- similar: [[prdct.bump-sh]] [[prdct.swaggerhub]]\n- pricing:\n  - individual: $39/mo annual, $49/mo monthly\n  - startup: $99/mo","n":0.218}}},{"i":2130,"$":{"0":{"v":"Stmux","n":1},"1":{"v":"\nurl: https://www.npmjs.com/package/stmux","n":0.707}}},{"i":2131,"$":{"0":{"v":"Stl","n":1}}},{"i":2132,"$":{"0":{"v":"STIX","n":1},"1":{"v":"\n\n- [[p.hadDescription]] a language and serialization format used to exchange cyber threat intelligence \n- [[p.hasURL]] https://oasis-open.github.io/cti-documentation/stix/intro.html\n- [[p.hasSpecification]] https://docs.oasis-open.org/cti/stix/v2.1/os/stix-v2.1-os.html","n":0.236}}},{"i":2133,"$":{"0":{"v":"Stimulus","n":1},"1":{"v":"\n- url: https://stimulus.hotwired.dev/","n":0.577}}},{"i":2134,"$":{"0":{"v":"Steamworks","n":1},"1":{"v":"\n- docs: https://partner.steamgames.com/doc/home\n- ","n":0.577}}},{"i":2135,"$":{"0":{"v":"Statery","n":1},"1":{"v":"\n- repo: https://github.com/hmans/statery\n- ","n":0.577}}},{"i":2136,"$":{"0":{"v":"Starvers","n":1},"1":{"v":"\n- https://github.com/GreenfishK/starvers\n- written-in: python","n":0.5}}},{"i":2137,"$":{"0":{"v":"Stardog","n":1},"1":{"v":"\n- [[c.software.database.graph.rdf]]","n":0.707}}},{"i":2138,"$":{"0":{"v":"Stardog Studio","n":0.707},"1":{"v":"\n- https://www.stardog.com/studio/\n- [[c.software.semantic.authoring]] \n\n## Thoughts\n\n- beautiful UI!","n":0.378}}},{"i":2139,"$":{"0":{"v":"Stardog RDF Grammars vscode extension","n":0.447},"1":{"v":"\n- https://marketplace.visualstudio.com/items?itemName=stardog-union.stardog-rdf-grammars\n- [[c.software.IDE.Extension.VSCode]]\n- repo: https://github.com/stardog-union/stardog-vsc/\n\n## Support\n\n### RDF language support:\n\n-   SPARQL (`.rq`)\n-   Turtle (`.ttl`)\n-   Trig (`.trig`)\n-   SHACL (`.shacl`)\n\n### Stardog language support:\n\n-   Stardog Mapping Syntax 2 (`.sms`, `.sms2`)\n-   Stardog Rules Syntax (`.srs`)","n":0.183}}},{"i":2140,"$":{"0":{"v":"Stardog Cloud","n":0.707},"1":{"v":"\n- https://cloud.stardog.com/\n- [[c.software.database.graph.rdf]]","n":0.577}}},{"i":2141,"$":{"0":{"v":"Stackstorm","n":1},"1":{"v":"\n- https://stackstorm.com/","n":0.707}}},{"i":2142,"$":{"0":{"v":"StackEdit","n":1},"1":{"v":"\n\nopen-source dual-pane markdown editor with good support for rich-text paste\n\n- [[p.hasURL]] https://stackedit.io/\n- [[p.hasApplication]] [[pi.dendron-online]] [[gd]]\n- [[isA]] [[t.markdown.Editors]] \n","n":0.236}}},{"i":2143,"$":{"0":{"v":"Stacked Pages","n":0.707},"1":{"v":"\n- [[p.hasExample]] \n  - https://github.com/mathieudutour/gatsby-digital-garden","n":0.447}}},{"i":2144,"$":{"0":{"v":"Ssdf","n":1}}},{"i":2145,"$":{"0":{"v":"SROIQ","n":1},"1":{"v":"\n- related: \n\n## Cons\n\n- some conditions must be placed on ontology structures in order to ensure that they can be translated into a SROIQ knowledge base\n  - transitive properties cannot be used in number restrictions\n\n\n## References\n\n- https://www.w3.org/TR/owl2-overview/","n":0.164}}},{"i":2146,"$":{"0":{"v":"SQWRL","n":1},"1":{"v":"\n## Solutions\n\n- [[prdct.drools.swrlapi]]\n\n## Description\n\n- All SWRL built-ins [40] are included for SQWRL, so complex temporal queries can be formed. These include queries that require complex closure, negation, or complex aggregation and grouping.\n\n## References\n\n- https://www.igi-global.com/dictionary/using-semantic-web-rule-language/28069\n- [[ar.valid-time-rdf]]\n- https://stackoverflow.com/questions/41179592/combining-reasoners-in-owl-api-for-owl-dl-sqwrl-support","n":0.167}}},{"i":2147,"$":{"0":{"v":"Square Ecs","n":0.707},"1":{"v":"\n- repo: https://github.com/harshdoesdev/square\n- dead: since 2022","n":0.408}}},{"i":2148,"$":{"0":{"v":"Sqlite","n":1},"1":{"v":"\n## [[c.cool]]\n\n- [How Pikchr Generates the SQLite Syntax Diagram]https://pikchr.org/home/doc/trunk/doc/sqlitesyntax.md\n\n","n":0.333}}},{"i":2149,"$":{"0":{"v":"Spatialite","n":1},"1":{"v":"\n- url: https://www.gaia-gis.it/fossil/libspatialite/index","n":0.577}}},{"i":2150,"$":{"0":{"v":"Sql Server","n":0.707}}},{"i":2151,"$":{"0":{"v":"sql.js","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://sql.js.org/\n","n":0.577}}},{"i":2152,"$":{"0":{"v":"spring-nats","n":1},"1":{"v":"\n- repo: https://github.com/nats-io/spring-nats","n":0.577}}},{"i":2153,"$":{"0":{"v":"Spork","n":1},"1":{"v":"\n- [[c.software.simulation-framework.discrete-event]]\n [[c.software.simulation-framework]] [[c.Software.Entity-Component-System]]\n- [[t.cs.sd.literate-programming]] [[t.cs.immutability]]\n- repo: https://github.com/joinr/spork\n\n## Description\n\n- SPORK.sim presents a significant departure from traditional Discrete Event Simulations, since the architecture embraces functional programming and persistent data structures wholly, rather than focusing on mutation.\n\n## Features\n\n-   building the simulation transition functions (or step functions) as a composition of smaller functions\n    -   (as opposed to OOP-based classes or imperative mutation)\n-   Optionally persistent, lazily computed stream of simulation history\n-   a database layer based on the Component-Entity-System paradigm\n-   Maintains the ability to have a classic observable/observer simulation model without sacrificing functional purity.\n    -   Where convenient (i.e. for logging, visualization, other side-effects).\n-   Event-step (i.e. variable-width time-step) simulation.\n-   High-level transforms on the simulation history.\n    -   Familiar idioms like map, filter, reduce work out of the box, since history is merely a time-indexed stream of simulation contexts.\n    -   Allows for precise reasoning about causality, tracing, debugging, etc.\n-   Entity behaviors based on Behavior Trees, but can be as simple as a 2-line function.\n\n## References\n\n- https://www.reddit.com/r/Clojure/comments/15b81ch/xx_clojure_entity_component_system_working_on/","n":0.08}}},{"i":2154,"$":{"0":{"v":"Spoofax","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n\n## Resources\n\n### Learning Resource\n\n- https://tomassetti.me/spoofax-a-language-workbench/","n":0.408}}},{"i":2155,"$":{"0":{"v":"Spoke","n":1},"1":{"v":"\n- #docs https://hubs.mozilla.com/docs/spoke-creating-projects.html\n- repo: https://github.com/mozilla/Spoke","n":0.447}}},{"i":2156,"$":{"0":{"v":"Splunk","n":1}}},{"i":2157,"$":{"0":{"v":"Spline","n":1},"1":{"v":"\n- [[c.software.3d.generator]]","n":0.707}}},{"i":2158,"$":{"0":{"v":"Spiral","n":1},"1":{"v":"\n- publisher: [[org.every-media-inc]]\n- \n","n":0.5}}},{"i":2159,"$":{"0":{"v":"Spin","n":1},"1":{"v":"\n- https://spinrdf.org/\n- similar: [[prdct.shacl]]\n- aka: SPARQL rules\n\n## Implementations\n\n- [[prdct.allegrograph]]\n- [[prdct.rdf4j]] but \"The use of SPIN is no longer recommended.\"\n- [[prdct.topbraid-composer]]\n\n## Uses\n\n- Calculate the value of a property based on other properties - for example, area of a geometric figure as a product of its height and width, age of a person as a difference between today's date and person's birthday, a display name as a concatenation of the first and last names\n- Isolate a set of rules to be executed under certain conditions - for example, to support incremental reasoning, to initialize certain values when a resource is first created, or to drive interactive applications\n- SPIN offers a way to do constraint checking with closed world semantics and automatically raise inconsistency flags when currently available information does not fit the specified integrity constraints. Constraints are specified using SPARQL ASK or CONSTRUCT queries, or corresponding SPIN Templates.\n\n\n## Comparisons\n\n### SPIN vs SHACL\n\n- SHACL offers much greater flexibility w.r.t. the application target of constraints (and rules). While SPIN is limited to classes, SHACL shapes can be applied to either classes or sets of nodes derived by other means. See the various [target mechanisms](https://www.w3.org/TR/shacl/#targets) in SHACL, including the [custom targets](https://www.w3.org/TR/shacl-af/#targets) from the Advanced Features document.\n- \"SHACL should be regarded as the next generation of SPIN. Learn how they compare.\"\n\n### SPIN vs SWRL\n\n- \"However, we believe that SPIN is superior to SWRL in almost every respect, mainly because SPIN is based on SPARQL. SPARQL is well established and supported by numerous engines and databases. This means that SPIN rules can be directly executed on the databases and no intermediate engines with communication overhead need to be introduced. Also, SPIN is more expressive than SWRL, because SPARQL has various features such as UNIONs and FILTER expressions. SPIN has an object-oriented model that arguably leads to better maintainable models than SWRL's flat rule lists. Finally, SPIN goes far beyond being just a rule language, and also provides means to express constraints and to define new functions and templates.\"\n\n\n## References\n\n- https://spinrdf.org/spin-shacl.html\n- https://medium.com/virtuoso-blog/virtuoso-8-0-creating-a-custom-inference-rules-using-spin-vocabulary-d7a060f859ef\n- https://spinrdf.org/faq.html","n":0.055}}},{"i":2160,"$":{"0":{"v":"Sphn","n":1},"1":{"v":"\n- docs: https://sphn-semantic-framework.readthedocs.io","n":0.577}}},{"i":2161,"$":{"0":{"v":"Spel","n":1},"1":{"v":"\n## References\n\n- https://docs.spring.io/spring-framework/docs/3.0.x/reference/expressions.html","n":0.577}}},{"i":2162,"$":{"0":{"v":"SpeeDB","n":1},"1":{"v":"\n- url: https://www.speedb.io/","n":0.577}}},{"i":2163,"$":{"0":{"v":"Spectre Console","n":0.707},"1":{"v":"\n- url: https://spectreconsole.net/\n- ","n":0.577}}},{"i":2164,"$":{"0":{"v":"Specs","n":1},"1":{"v":"\n- [[c.software.entity-component-system]]\n- url: https://github.com/amethyst/specs\n- written-in: #rust","n":0.408}}},{"i":2165,"$":{"0":{"v":"Spatialos","n":1},"1":{"v":"\n- published-by: [[org.improbable]]","n":0.577}}},{"i":2166,"$":{"0":{"v":"Sparql","n":1},"1":{"v":"\n## Features\n\n-  SPARQL, the standard query language for RDF graphs, uses CWA (as do all common query languages). ^sjsxjl2oyczk\n- BGP (Basic Graph Pattern) Matching refers to the process of finding matching sets of triples (subject-predicate-object) in an RDF dataset based on a basic graph pattern specified in a SPARQL query.\nUnderstanding BGP:\n    - A Basic Graph Pattern (BGP) is essentially a collection of triple patterns.\n    - Each triple pattern in the BGP can consist of variables, IRIs (Internationalized Resource Identifiers), or literals in the subject, predicate, and object positions.\n    - The task of BGP matching is to identify all sets of RDF triples in the dataset that correspond to the given patterns in the query.\n\n### Property Paths\n\n@chatgpt: Property paths in SPARQL are a powerful feature that allows you to write queries that navigate through RDF graphs in more complex ways than simple triple patterns. Property paths can be used to traverse multiple relationships, specify optional or alternative paths, and query over arbitrary lengths of paths.\n\n### Key Property Path Operators:\n\n1. **Concatenation (`/`)**:\n   - Specifies a sequence of properties.\n   - Example: `:parent/:child` retrieves all grandchildren by following a `:parent` relationship and then a `:child` relationship.\n\n2. **Alternatives (`|`)**:\n   - Specifies a choice between properties.\n   - Example: `:spouse|:partner` retrieves relationships where either `:spouse` or `:partner` applies.\n\n3. **Zero or More (`*`)**:\n   - Matches a property path of any length, including zero.\n   - Example: `:ancestor*` finds any number of `:ancestor` relationships, including direct and indirect ancestors.\n\n4. **One or More (`+`)**:\n   - Matches a property path of at least one step.\n   - Example: `:ancestor+` retrieves all direct and indirect ancestors, but not the individual itself.\n\n5. **Zero or One (`?`)**:\n   - Matches a property path of zero or one step.\n   - Example: `:spouse?` retrieves relationships where the `:spouse` property exists or matches no property.\n\n6. **Inverse (`^`)**:\n   - Inverts the direction of the property.\n   - Example: `^:parent` retrieves all entities that are children of a given individual.\n\n### Examples of SPARQL Queries Using Property Paths:\n\n#### 1. Find All Descendants:\n```sparql\nPREFIX : <http://example.org/>\n\nSELECT ?descendant WHERE {\n  :John :parent+ ?descendant .\n}\n```\n- **Explanation**: This query finds all descendants of `:John` by following the `:parent` property one or more times.\n\n#### 2. Find Direct or Indirect Ancestors:\n```sparql\nPREFIX : <http://example.org/>\n\nSELECT ?ancestor WHERE {\n  ?ancestor :parent* :John .\n}\n```\n- **Explanation**: This query finds all direct or indirect ancestors of `:John`, including `:John` itself.\n\n#### 3. Find Individuals Related by Spouse or Partner:\n```sparql\nPREFIX : <http://example.org/>\n\nSELECT ?related WHERE {\n  :John (:spouse|:partner) ?related .\n}\n```\n- **Explanation**: This query finds individuals related to `:John` by either the `:spouse` or `:partner` relationship.\n\n#### 4. Query for Connections through Multiple Properties:\n```sparql\nPREFIX : <http://example.org/>\n\nSELECT ?person WHERE {\n  :John (:knows/:friendOf) ?person .\n}\n```\n- **Explanation**: This query finds all individuals who are friends of people that `:John` knows.\n\n## Resources\n\n- https://medium.com/wallscope/constructing-sparql-queries-ca63b8b9ac02\n- https://www.reddit.com/r/semanticweb/comments/1dqh8zw/code_injection_into_sqarql_is_this_done_somehow/\n\n## References","n":0.047}}},{"i":2167,"$":{"0":{"v":"Star","n":1}}},{"i":2168,"$":{"0":{"v":"SPARQL-MM","n":1}}},{"i":2169,"$":{"0":{"v":"GeoSPARQL","n":1},"1":{"v":"\n- published_by: [[org.open-geospatial-consortium]]\n- similar: [[prdct.stsparql]]\n\n## Implementations\n\n-   [Apache Jena Fuseki](https://jena.apache.org/documentation/fuseki2/): Apache Jena is an open source framework for the Semantic Web and Linked Data Part of Jena is the Fuseki triple store, which can [support GeoSPARQL](https://jena.apache.org/documentation/geosparql/geosparql-fuseki).\n    \n- [[prdct.rdf4j]]  [Eclipse RDF4J](https://rdf4j.org/about/) is a Java framework for working with RDF data. It can use its own data stores or data stores from other parties. [GeoSPARQL is supported](https://rdf4j.org/documentation/programming/geosparql/).\n  - see https://rdf4j.org/documentation/programming/geosparql/\n    \n-   [Ontop-spatial](http://ontop-spatial.di.uoa.gr/): [Ontop](https://ontop-vkg.org/guide/) is a system that can be used to expose the content of arbitrary relational databases as knowledge graphs. Ontop-spatial is an extension of Ontop that offers support for GeoSPARQL.\n    \n-   [Ontotext GraphDB](https://www.ontotext.com/products/graphdb/) is a semantic graph database. It offers a [GeoSPARQL plugin](http://graphdb.ontotext.com/documentation/standard/geosparql-support.html).\n    \n-   [Openlink Virtuoso](https://virtuoso.openlinksw.com/): Virtuoso Universal Server is a data storage system that supports mutliple interfaces. It offers partial support of GeoSPARQL.\n    \n-   [Oracle Spatial and Graph](https://www.oracle.com/database/technologies/spatialandgraph.html) is a component in Oracle databases that offers support for both graph data and spatial data. It supports the GeoSPARQL standard.\n    \n-   [Parliament](https://github.com/SemWebCentral/parliament) is a triplestore and reasoner with support for GeoSPARQL.\n    \n-   [Strabon](http://www.strabon.di.uoa.gr/) is a RDF store that specializes in spatiotemporal data. It has partial support for GeoSPARQL.\n    \n-   [Stardog](https://www.stardog.com/) is a platform for knowledge graphs and it [supports GeoSPARQL](https://www.stardog.com/docs/#_geospatial_query).","n":0.071}}},{"i":2170,"$":{"0":{"v":"SPARQL Composite Datatypes (CDTS)","n":0.5},"1":{"v":"\n## References\n\n- https://awslabs.github.io/SPARQL-CDTs/spec/latest.html","n":0.577}}},{"i":2171,"$":{"0":{"v":"Sparql Web Pages (UISPIN)","n":0.5},"1":{"v":"\n- dead\n- https://uispin.org/\n- [[c.software.semantic.publishing]] \n\n## References\n\n- http://composing-the-semantic-web.blogspot.com/2010/04/charts-and-business-reports-with-uispin.html","n":0.378}}},{"i":2172,"$":{"0":{"v":"Sparql Ex","n":0.707}}},{"i":2173,"$":{"0":{"v":"Sparql Anything","n":0.707},"1":{"v":"\n- https://sparql-anything.readthedocs.io\n\n## Features\n\n- supports querying a variety of non-RDF data sources as RDF via facade-x\n  - e.g., excel, csv, \n  - **[markdown](https://sparql-anything.readthedocs.io/stable/formats/Markdown/)!!!**\n- supports [query native RDF](https://sparql-anything.readthedocs.io/stable/formats/RDF_Files/)","n":0.196}}},{"i":2174,"$":{"0":{"v":"Apache Spark","n":0.707},"1":{"v":"\n- [[c.software.database.distributed]]  [[c.software.data-framework]]\n- similar-to: [[prdct.ignite]] [[prdct.flink]]\n\n## Comparisons\n\n### vs flink and ignite (@chatgpt.3.5)\n\n- \"For real-time streaming with strong consistency and low latency, Flink might be preferred. Spark is excellent for a wide range of use cases due to its ease of use and versatility. Ignite shines when you need distributed in-memory storage and processing capabilities with SQL querying.\"\n\n\n\n","n":0.132}}},{"i":2175,"$":{"0":{"v":"Spar Ontologies","n":0.707},"1":{"v":"\n- http://www.sparontologies.net/\n- creators: @silvio-peroni @david-shotton\n- mentions: [[ar.distributed-engineering-of-ontologies-diligent]]\n\n\n## Examples\n\n- ","n":0.354}}},{"i":2176,"$":{"0":{"v":"Spacy","n":1},"1":{"v":"\n- url: https://spacy.io/","n":0.577}}},{"i":2177,"$":{"0":{"v":"Spaced Repetition","n":0.707},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] distributed practice\n- [[p.hasApplication]] [[t.km]] \n- [[p.hasLearningResource]] \n  - https://ncase.me/remember/\n  - https://numinous.productions/timeful/\n    - [[p.hasAuthor]] @andy-matuschak\n    - [[p.hasHighlight]]\n      - \"regular review sessions didn’t just build detailed retention: the ongoing practice also changed readers’ relationship to the material by maintaining their contact with it over time... If you found the prompt useful, it would recur in another week; if not, perhaps it would reappear in a few months.","n":0.122}}},{"i":2178,"$":{"0":{"v":"Space Time","n":0.707},"1":{"v":"\n\n![](/assets/images/2024-09-23-14-09-52.png)\n\n- [[ar.spacetime-a-two-dimensions-search-and-visualisation-engine-based-on-linked-data]]","n":0.707}}},{"i":2179,"$":{"0":{"v":"Sowas Ontology","n":0.707},"1":{"v":"\n- url: https://www.jfsowa.com/ontology/","n":0.577}}},{"i":2180,"$":{"0":{"v":"Sonyflake","n":1},"1":{"v":"\n- https://github.com/sony/sonyflake\n- [[c.software.tools.id-generator]]\n- written-in: go\n\n![[prdct.newid#similar]]","n":0.447}}},{"i":2181,"$":{"0":{"v":"Solidity","n":1}}},{"i":2182,"$":{"0":{"v":"Solid","n":1},"1":{"v":"\n- [[p.hasSite]] https://solidproject.org/\n- supports: [[prdct.nextcloud]] via [[prdct.solid-nextcloud]]\n\n## Vision\n\n-  data is decoupled from applications, meaning users are no longer locked into specific platforms simply because their data is held there\n\n## Features\n\n- use [[t.cs.semantic-web.n3-patch]]\n\n## Implementations\n\n- [[prdct.node-solid-server]]\n\n## Issues\n\n- doesn't inherently support version control\n  - t.2024.05.03.12 but many support [[prdct.memento]]\n\n## References\n\n- https://indico.cern.ch/event/979244/attachments/2150378/3668572/JanSchill_20201225-Solid-specs-and-implemenations-report.pdf","n":0.144}}},{"i":2183,"$":{"0":{"v":"Solid Nextcloud","n":0.707},"1":{"v":"\n- [[c.software.semantic.solid-server]]\n- repo: https://github.com/pdsinterop/solid-nextcloud\n- written_in: php\n\n![[prdct.node-solid-server#similar]]","n":0.408}}},{"i":2184,"$":{"0":{"v":"Solid JS","n":0.707},"1":{"v":"\n- url: https://www.solidjs.com/\n- [[p.builtOn]] [[prdct.react]]\n","n":0.447}}},{"i":2185,"$":{"0":{"v":"Solflare","n":1}}},{"i":2186,"$":{"0":{"v":"Solace","n":1},"1":{"v":"\n- #closed-source\n- url: https://solace.com\n- [[c.pricing]]\n    - standard edition is free\n    - enterprise edition \"contact sales\", but developer version avail\n    - cloud hosting \n\n- [[p.similarTo]] [[prdct.azure.event-grid]]\n- [[p.supports]] [[t.cs.sd.rest]]\n\n\n## Features\n\n- PubSub+ Event Broker enables event streaming that is fast, reliable and secure, and includes features like topic hierarchy and fine grained filtering, so users can easily publish and subscribe to specific subsets of data.\n- PubSub+ Event Portal gives architects and developers an easy-to-use tool to design, discover, catalog and visualize EDA components (events, schemas, and applications and APIs). It also provides role-based access controls and supports the creation of “event-API products”, so event streams can be exposed and accessed by internal and external parties, as desired.\n\n## Resources\n\n### Learning Resources\n\n- https://www.marcd.dev/s1p-codelab-2019/","n":0.093}}},{"i":2187,"$":{"0":{"v":"Software Requirements Reference Ontology Srro","n":0.447},"1":{"v":"\n- http://web.archive.org/web/20171008152212/http://www.menthor.net/srro.html\n- [[c.ontology.domain]] [[c.ontology.creative-work]]\n- domain: [[t.cs.sd.requirements]]","n":0.408}}},{"i":2188,"$":{"0":{"v":"Softtouch Ecs","n":0.707},"1":{"v":"\n- https://github.com/ykafia/SoftTouch.ECS\n- ","n":0.707}}},{"i":2189,"$":{"0":{"v":"Socketcluster","n":1},"1":{"v":"\nurl: https://socketcluster.io/\n#contributors @jonathan-gros-dubois \n\n## [[p.comparableTo]]\n\n- [[prdct.webrpc]]\n  - \"\n  - https://github.com/sinclairzx81/smoke\n- [[prdct.socket-io]]\n\n## [[p.hasComparison]]\n\n- https://blog.kalob.net/posts/2020-04-05/socket-io-vs-socket-cluster\n\n## [[p.hasLearningResource]]\n\n- https://dev.to/harperdb/using-socketcluster-for-distributed-computing-in-a-unique-way-1cia\n  - [[p.hadDependancy]] [[prdct.harperdb]]","n":0.236}}},{"i":2190,"$":{"0":{"v":"Socket.IO","n":1},"1":{"v":"\n## Features\n\n- Socket.IO is a library built on WebSockets. It adds features you would certainly need to implement yourself anyway, like a heartbeat and auto-reconnect, as well as features you will probably need - like multiplexing, rooms, and the ability to fallback to long polling","n":0.149}}},{"i":2191,"$":{"0":{"v":"Socialhub","n":1}}},{"i":2192,"$":{"0":{"v":"Soar","n":1},"1":{"v":"\n- [[c.software.cognitive-architecture]]\n- url: http://soar.eecs.umich.edu/ \n- repo: https://github.com/SoarGroup/Soar\n- written-in: #c++ \n\n\n## [[c.documentation]]\n\n### https://soar.eecs.umich.edu/downloads/Documentation/SoarManual.pdf\n\n#### Ch. 1\n\n- all deliberate goal -oriented behavior can be cast as the selection and application of operators to a state\n- Working memory is organized as objects. \n  - Objects are described in terms of their attributes; the values of the attributes may correspond to sub-objects, so the description of the state can have a hierarchical organization\n- A Soar program contains the knowledge to be used for solving a specific task \n\n##### Types of Procedural Knowledge\n1. Inference Rules\nIn Soar, we call these state elaborations. This knowledge provides monotonic inferences\nthat can be made about the state in a given situation. The knowledge created by such\nrules are not persistent and exist only as long as the conditions of the rules are met.\n1. Operator Proposal Knowledge\nKnowledge about when a particular operator is appropriate for a situation. Note\nthat multiple operators may be appropriate in a given context. So, Soar also needs\nknowledge to determine which of the candidates to choose:\n1. Operator Selection Knowledge:\nKnowledge about the desirability of an operator in a particular situation. Such knowl-\nedge can be either in terms of a single operator (e.g. never choose this operator in this\nsituation) or relational (e.g. prefer this operator over another in this situation).\n1. Operator Application Rules\nKnowledge of how a specific selected operator modifies the state. This knowledge\ncreates persistent changes to the state that remain even after the rule no longer matches\nor the operator is no longer selected.\n\n\n### https://arxiv.org/ftp/arxiv/papers/2205/2205.03854.pdf\n\n### \n\n- \"The ultimate in intelligence would be complete rationality which would imply the ability to use all available knowledge for every task that the system encounters. Unfortunately, the complexity of retrieving relevant knowledge puts this goal out of reach as the body of knowledge increases, the tasks are made more diverse, and the requirements in system response time more stringent.\"  ^jxijnmn32t8u\n- \"Through Soar 8, there has been a single framework for all tasks and subtasks (problem spaces), a single representation of permanent knowledge (productions), a single representation of temporary knowledge (objects with attributes and values), a single mechanism for generating goals (automatic subgoaling), and a single learning mechanism (chunking). We have revisited this assumption as we attempt to ensure that all available knowledge can be captured at runtime without disrupting task performance. This is leading to multiple learning mechanisms (chunking, reinforcement learning, episodic learning, and semantic learning), and multiple representations of long-term knowledge (productions for procedural knowledge, semantic memory, and episodic memory).\"\n\n\n## Comparisons\n\n- https://advancesincognitivesystems.github.io/acs2021/data/ACS-21_paper_6.pdf\n  - ","n":0.05}}},{"i":2193,"$":{"0":{"v":"Rosie","n":1},"1":{"v":"\n- repo: https://soargroup.github.io/rosie/\n- ","n":0.577}}},{"i":2194,"$":{"0":{"v":"Jsoar","n":1},"1":{"v":"\n- repo: https://github.com/soartech/jsoar\n- written-in: java\n- wiki: https://github.com/soartech/jsoar/wiki\n\n## Features\n\n- JSoar has built-in support for implementing simple environments by embedding JavaScript, Python, or Ruby code directly in Soar source files. (via [[prdct.java.jsr.223]])\n  - \"you can source these URLs directly in the JSoar debugger\"","n":0.156}}},{"i":2195,"$":{"0":{"v":"Snowflake","n":1},"1":{"v":"\n- [[p.mentionedOn]] https://interviewnoodle.com/how-discord-stores-billions-of-messages-big-surprises-in-system-design-e48fa07a2665 d\n\n## Features\n\n- tens of thousands of ids per second in a highly available manner. This naturally led us to choose an uncoordinated approach.\n\nThese ids need to be roughly sortable, meaning that if tweets A and B are posted around the same time, they should have ids in close proximity to one another since this is how we and most Twitter clients sort tweets.[1]\n\nAdditionally, these numbers have to fit into 64 bits.\n\n## Implementations\n\n- https://github.com/AkashRajpurohit/snowflake-id javascript\n- ","n":0.114}}},{"i":2196,"$":{"0":{"v":"Snap.svg","n":1},"1":{"v":"\n- #dead\n- url: http://snapsvg.io/\n- repo: https://github.com/adobe-webplatform/Snap.svg","n":0.408}}},{"i":2197,"$":{"0":{"v":"Snakeyaml","n":1},"1":{"v":"\n- repo: https://bitbucket.org/snakeyaml/snakeyaml\n  \n## Features\n\n- high-level API for serializing and deserializing native Java objects.\n\n## Comparison\n\n### vs [[prdct.snakeyaml-engine]]","n":0.243}}},{"i":2198,"$":{"0":{"v":"Snakeyaml Engine","n":0.707},"1":{"v":"\n- repo: https://github.com/snakeyaml/snakeyaml-engine\n\n## Features\n\n- Low-level API for serializing and deserializing native Java objects.","n":0.277}}},{"i":2199,"$":{"0":{"v":"Smee.io","n":1},"1":{"v":"\nurl: https://smee.io/\n","n":0.707}}},{"i":2200,"$":{"0":{"v":"Smartfoxserver","n":1},"1":{"v":"\n-  https://www.smartfoxserver.com/showcase/projects\n","n":0.707}}},{"i":2201,"$":{"0":{"v":"Smallry","n":1},"1":{"v":"\n- ","n":1}}},{"i":2202,"$":{"0":{"v":"Smallrye Reactive Messaging","n":0.577},"1":{"v":"\n- https://smallrye.io/smallrye-reactive-messaging/latest/\n- used-in: [[prdct.quarkus]] [[prdct.openliberty]]","n":0.447}}},{"i":2203,"$":{"0":{"v":"slugify-vscode","n":1}}},{"i":2204,"$":{"0":{"v":"Skosmos","n":1},"1":{"v":"\n\n- https://skosmos.org/\n- written-in: php\n\n## UI Complaints\n\n- nobody is going to look at that tree. how about hiding everything except parents, the (most popular) children, and the (maybe first and last) sibling, and maybe optionall grandparents\n![](/assets/images/2024-05-23-23-30-59.png)","n":0.169}}},{"i":2205,"$":{"0":{"v":"Skosify","n":1},"1":{"v":"\n- docs: https://skosify.readthedocs.io/en/latest/\n- repo: https://github.com/NatLibFi/Skosify\n- written-in: python\n- demo: http://demo.seco.tkk.fi/skosify/skosify\n\n## Description\n\nThis program accepts a thesaurus-like vocabulary expressed as RDFS, OWL or SKOS as input. It produces a clean SKOS representation, which attempts to represent the input data losslessly using SKOS best practices. When given SKOS as input, it will be cleaned up, validated and enriched to follow the SKOS specification and related best practices.\n\n\n## References\n\n-   Osma Suominen and Christian Mader: Assessing and Improving the Quality of SKOS Vocabularies. Journal on Data Semantics, vol. 3, no. 1, pp. 47-73, June, 2014 ([PDF](https://seco.cs.aalto.fi/publications/2014/suominen-mader-skosquality.pdf))\n-   Osma Suominen and Eero Hyvönen: Improving the Quality of SKOS Vocabularies with Skosify. Proceedings of the 18th International Conference on Knowledge Engineering and Knowledge Management (EKAW 2012), Springer-Verlag, Galway, Ireland, October, 2012 ([PDF](https://seco.cs.aalto.fi/publications/2012/suominen-hyvonen-skosify-2012.pdf))","n":0.09}}},{"i":2206,"$":{"0":{"v":"SKOS","n":1},"1":{"v":"\n## Description\n\n- designed for representation of thesauri, classification schemes, taxonomies, subject-heading systems, or any other type of structured controlled vocabulary.\n- SKOS has been designed to provide a low-cost migration path for porting existing organization systems to the Semantic Web. SKOS also provides a lightweight, intuitive conceptual modeling language for developing and sharing new KOSs. It can be used on its own, or in combination with more-formal languages such as the Web Ontology Language (OWL) [OWL]. SKOS can also be seen as a bridging technology, providing the missing link between the rigorous logical formalism of ontology languages such as OWL and the chaotic, informal and weakly-structured world of Web-based collaboration tools, as exemplified by social tagging applications.\n\n\n## Topics\n\n### Concept Scheme vs Collection \n\n- SKOS collections are intended to represent groupings of closely-related concepts within a particular thesaurus.\n- Concept Schemes... are intended to capture/identify a single complete thesaurus/taxonomy, which is useful in a situation where several such thesauri/taxonomies co-exist. Items in a ConceptScheme are not necessarily a \"grouping\" of closely-related terms, but are all part of the same overall hierarchy of terms.\n\n### Intransitive vs Not Transitive\n\n- the SKOS model does not state that skos:broader and skos:narrower are transitive. Yet this does not imply that these properties are intransitive.\n\n### Compositionality and Concept Typing\n\n- start with a common vocabulary for the whole enterprise, but have customizations of it for each line of business... SKOS defines a class called skos:Concept, for any vocabulary concept. Users of SKOS are encouraged to extend SKOS by creating their own subclasses of skos:Concept; each vocabulary will do this in a different way (e.g., defining subdomains in their own vocabularies), while adhering to the basic structure of SKOS.\n  - A good example of this is the structure of the [GACS Agricultural Vocabulary](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6751214/), which uses several subclasses of skos:Concept to provide organizational structure to the vocabulary.\n    - \"GACS Core distinguishes five types of concept: Chemical, Geographical, Organism, Product, and Topic—a minimal set of generic types for exploring the benefits of concept typing before committing to anything more granular.\"\n\n#### AGROVOC use case\n\n- maintainers re-engineered thesaurus to “fully fledged ontology” but a study of users 6 years later found little support for the use of these custom relation properties.13 In the absence of specific tools and requirements for reasoning, it was unclear to some users what purpose they served.\n\n### SKOS and OWL\n\n- \"crossing the streams\" results in OWL Full\n\n## Solutions\n\n- [[prdct.skosmos]]\n\n## Examples\n\n- [[prdct.redaktor-vocab]]\n\n\n## References\n\n- https://medium.com/@dallemang/jug-o-cool-things-i-do-with-rdf-3cdb5b059192\n- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6751214/\n- https://www.w3.org/TR/skos-primer/\n- [[ar.common-slips-in-skos-vocabularies]]\n- https://stackoverflow.com/questions/32573812/whats-the-difference-between-skosconceptscheme-and-skoscollection\n- https://www.w3.org/2006/07/SWD/SKOS/skos-and-owl/master.html","n":0.05}}},{"i":2207,"$":{"0":{"v":"Skookumscript","n":1},"1":{"v":"\n- https://skookumscript.com/\n- built-on: [[prdct.unreal]]","n":0.5}}},{"i":2208,"$":{"0":{"v":"Skohub","n":1},"1":{"v":"\n- https://skohub.io/\n- [[c.software.web.ssg]]\n- written-in: javascript\n- uses: [[prdct.gatsby]]","n":0.378}}},{"i":2209,"$":{"0":{"v":"Sketchpad","n":1}}},{"i":2210,"$":{"0":{"v":"Sketchfab","n":1},"1":{"v":"\n- url: https://sketchfab.com/\n- ","n":0.577}}},{"i":2211,"$":{"0":{"v":"Site","n":1},"1":{"v":"\n- repo: https://github.com/juxt/site\n\n\n## Learning Resources\n\n- https://juxtsite.netlify.app/learn/kanban","n":0.408}}},{"i":2212,"$":{"0":{"v":"SirixDB","n":1},"1":{"v":"\n![](/assets/images/2024-01-22-16-09-16.png)\n- [[c.software.database.bitemporal]] [[c.software.database.embedded]]\n- repo: https://github.com/sirixdb/sirix\n- written_in: java\n- built-with: [[prdct.brackit]]\n\n## Resources\n\nArticles published on Medium:\n\n-   [Asynchronous, Temporal REST With Vert.x, Keycloak and Kotlin Coroutines](https://medium.com/hackernoon/asynchronous-temporal-rest-with-vert-x-keycloak-and-kotlin-coroutines-217b25756314)\n-   [Pushing Database Versioning to Its Limits by Means of a Novel Sliding Snapshot Algorithm and Efficient Time Travel Queries](https://medium.com/sirixdb-sirix-io-how-we-built-a-novel-temporal/why-and-how-we-built-a-temporal-database-system-called-sirixdb-open-source-from-scratch-a7446f56f201)\n-   [How we built an asynchronous, temporal RESTful API based on Vert.x, Keycloak and Kotlin/Coroutines for Sirix.io (Open Source)](https://medium.com/sirixdb-sirix-io-how-we-built-a-novel-temporal/how-we-built-an-asynchronous-temporal-restful-api-based-on-vert-x-4570f681a3)\n-   [Why Copy-on-Write Semantics and Node-Level-Versioning are Key to Efficient Snapshots](https://hackernoon.com/sirix-io-why-copy-on-write-semantics-and-node-level-versioning-are-key-to-efficient-snapshots-754ba834d3bb)\n\n## Features\n\n- JVM-embeddable\n- XML-oriented, but support JSON","n":0.115}}},{"i":2213,"$":{"0":{"v":"Sirius","n":1},"1":{"v":"\n- [[c.software.tools.modeling]]\n- url: https://eclipse.dev/sirius/","n":0.5}}},{"i":2214,"$":{"0":{"v":"Siren","n":1},"1":{"v":"\n- dead since 2000\n- repo: https://github.com/kevinswiber/siren\n\n![[prdct.hydra#similar]]\n\n## Features\n\n- Actions show available behaviors an entity exposes.\n- Siren also has a concept of \"class.\" The class attribute may contain multiple descriptors of the current representation. I've avoided calling these \"type descriptors.\" They act more like \"mixin descriptors\" (i.e., if an entity is of a certain class, it may have properties, actions, sub-entities, or links associated with it). When layering a UI on top of Siren, I've also used the class attribute to act as a view router (e.g., When a representation comes back with an \"error\" class, route to the error view or when a representation contains a \"home\" class, route to the home view... or some combination... When a representation has both the \"home\" and \"error\" classes, display the error alongside the home view.) \n\n## Comparisons\n\n### Siren vs Hydra\n\n- \"Before Hydra, Siren was perceived as being the most complex JSON-based hypermedia format.  And now, I think, Hydra has taken over that label.\"\n- \n\n\n## References\n\n- https://lists.w3.org/Archives/Public/public-hydra/2016Jan/0026.html\n- https://github.com/kevinswiber/siren/issues/15","n":0.078}}},{"i":2215,"$":{"0":{"v":"Singularitynet","n":1},"1":{"v":"\n- url: https://singularitynet.io/\n\n## Features\n\n- [[prdct.singularity.ai-dsl]]","n":0.447}}},{"i":2216,"$":{"0":{"v":"Simulation","n":1},"1":{"v":"\nurl: https://www.npmjs.com/package/simulation\nrepo: https://github.com/scottfr/simulation\n\n- [[p.compatibleWith]] [[prdct.insight-maker]]\n\n## [[p.hadDescription]]\n\n### Primitives\n\n`simulation` models are composed out of building blocks called \"primitives\" In this model we're going to use three primitives:\n\n-   A **Stock** to store the number of people in the world population. Generally, stocks store things like people, dollars, water, or anything else\n-   A **Flow** to define the change in the population stock. Flows model the movement of material between stocks.\n-   A **Variable** to define the net growth rate for the population. In this model, that will be a constant value, but it could also be a dynamic equation.","n":0.103}}},{"i":2217,"$":{"0":{"v":"Simulation Ontology","n":0.707},"1":{"v":"\n- https://br0ast.github.io/simulationontology/\n- RDF: http://www.ontologydesignpatterns.org/ont/simul/ontwithkg_rev.owl\n- repo: https://github.com/br0ast/simulationontology","n":0.408}}},{"i":2218,"$":{"0":{"v":"SimScript","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/Bernardo-Castilho/SimScript\n\n## Demos\n\n- https://bernardo-castilho.github.io/xwlk-anim\n\n## Issues\n\n- the demos tend to slow to a crawl after a while\n- \"","n":0.229}}},{"i":2219,"$":{"0":{"v":"SimpleECS","n":1},"1":{"v":"\n- repo: https://github.com/PeteyChan/SimpleECS","n":0.577}}},{"i":2220,"$":{"0":{"v":"Simple Event Model Ontology","n":0.5},"1":{"v":"\n- [[c.ontology.events]] \n- url: https://semanticweb.cs.vu.nl/2009/11/sem/\n\n![[prdct.event-ontology#related]]\n\n## Issues\n\n![[ar.linked-data-and-time-modeling-researcher-life-lines-by-events#^hfr5g0mqkqkk]]\n","n":0.408}}},{"i":2221,"$":{"0":{"v":"Siml","n":1},"1":{"v":"\n- url: https://simlbot.com/\n- similar: [[prdct.aiml]]\n\n## Thoughts\n\n- example at https://github.com/SynHub/oscova-smalltalk-base/blob/master/English/Oscova-SmallTalk-Base/Agent.siml seems incredibly lame","n":0.289}}},{"i":2222,"$":{"0":{"v":"Simcluster","n":1},"1":{"v":"\n- https://simcluster.ai/","n":0.707}}},{"i":2223,"$":{"0":{"v":"Sim4edu","n":1},"1":{"v":"\n- https://sim4edu.com/","n":0.707}}},{"i":2224,"$":{"0":{"v":"SIM.JS","n":1},"1":{"v":"\n- [[c.software.simulation-framework.discrete-event]]\n- repo: https://github.com/mvarshney/simjs-source\n- url: https://simjs.z5.web.core.windows.net/\n\n## Design Principles \n\n- [ ] https://simjs.z5.web.core.windows.net/basics.html#basics-design","n":0.289}}},{"i":2225,"$":{"0":{"v":"Sim Francisco","n":0.707}}},{"i":2226,"$":{"0":{"v":"Silex","n":1},"1":{"v":"\n- deprecated, use [[prdct.symfony]]\n- repo: https://github.com/silexphp/Silex","n":0.408}}},{"i":2227,"$":{"0":{"v":"Signoz","n":1},"1":{"v":"\n\n- \"[[Prometheus|prdct.prometheus]] is good if you want to do just metrics. But if you want to have a seamless experience between metrics and traces, then current experience of stitching together Prometheus & Jaeger is not great. Grafana is making some efforts in this direction with Trace viewer - but we think this is just stitching 2 disparate systems.\"\n","n":0.131}}},{"i":2228,"$":{"0":{"v":"SignalR","n":1},"1":{"v":"\n- [[c.overview]] https://learn.microsoft.com/en-us/aspnet/core/signalr/introduction?view=aspnetcore-7.0","n":0.577}}},{"i":2229,"$":{"0":{"v":"SigmaREST","n":1},"1":{"v":"\n- https://github.com/ontologyportal/SigmaRest\n- related: [[prdct.sigmanlp]]","n":0.5}}},{"i":2230,"$":{"0":{"v":"SigmaNLP","n":1},"1":{"v":"\n- https://github.com/ontologyportal/sigmanlp\n\n## References\n\n- https://www.youtube.com/watch?v=alGmrI8umsM","n":0.5}}},{"i":2231,"$":{"0":{"v":"Sigmakee","n":1},"1":{"v":"\n- [[c.software.reasoner]]\n- repo: https://github.com/ontologyportal/sigmakee\n- written_in: java\n- related: [[prdct.sumo]] [[prdct.sigmarest]]\n- url: http://sigma.ontologyportal.org:8080/sigma/KBs.jsp","n":0.302}}},{"i":2232,"$":{"0":{"v":"Sigma JS","n":0.707},"1":{"v":"\n\n- [[p.hasSite]] https://www.sigmajs.org/\n","n":0.577}}},{"i":2233,"$":{"0":{"v":"Sigma Event Graph Simulation Modeling","n":0.447},"1":{"v":"\n- [[c.Software.Simulation-Framework.discrete-event]]\n- https://sigmawiki.com/\n\n## Features\n\n- simulation models can be created, enriched, and edited while they are running","n":0.25}}},{"i":2234,"$":{"0":{"v":"Siebog Lite","n":0.707},"1":{"v":"\n- related: [[prdct.SiebogJS]]","n":0.577}}},{"i":2235,"$":{"0":{"v":"Shiro","n":1},"1":{"v":"\n- https://shiro.apache.org/","n":0.707}}},{"i":2236,"$":{"0":{"v":"Shipyard","n":1},"1":{"v":"\n- [[c.software.entity-component-system]]\n- url: https://crates.io/crates/shipyard\n- repo: https://github.com/leudz/shipyard\n- #writtenIn #rust","n":0.354}}},{"i":2237,"$":{"0":{"v":"Shining Sword","n":0.707}}},{"i":2238,"$":{"0":{"v":"ShareDB","n":1},"1":{"v":"\n- repo: https://github.com/share/sharedb\n- written_in: javascript\n- supports: [[prdct.derbyjs]]\n\n## Summary\n\n- likely the most widely-used open-source [[t.cs.real-time_collaboration]] solution\n\n## Features\n\n-   Realtime synchronization of any JSON document\n-   Concurrent multi-user collaboration\n-   Synchronous editing API with asynchronous eventual consistency\n-   Realtime query subscriptions\n-   Simple integration with any database\n-   Horizontally scalable with pub/sub integration\n-   Projections to select desired fields from documents and operations\n-   Middleware for implementing access control and custom extensions\n-   Ideal for use in browsers or on the server\n-   Offline change syncing upon reconnection\n-   In-memory implementations of database and pub/sub for unit testing\n-   Access to historic document versions\n-   Realtime user presence syncing","n":0.103}}},{"i":2239,"$":{"0":{"v":"Shaperone","n":1},"1":{"v":"\n- repo: https://github.com/hypermedia-app/shaperone\n- written-in: typescript","n":0.447}}},{"i":2240,"$":{"0":{"v":"SHACL","n":1},"1":{"v":"\n![[prdct.rdf-js.shex#^1vgrpmk2ihl1]]\n\n## Implementations\n\n- [[prdct.shacl-api]]\n- [[prdct.shacl-engine]]\n\n\n## Examples \n\n- https://semantify.it/list/wS4r3c9hQ [[prdct.semantify]]\n\n## Features\n\n- \"SHACL uses CWA in its reasoning\" ^6uscvziiubke\n\n- \"SHACL uses RDFS subclassing mechanism. When you create SHACL models you define classes and more specific subclasses. Additionally, you can separate Node Shapes from classes to define application specific views.Take a look at [this blog](https://www.topquadrant.com/classes-and-node-shapes-when-to-separate/) to understand differences between classes and node shapes... With SHACL, you can deactivate constraints that you don’t need or can’t agree with. This is done declaratively, using the standard so it is unambiguously clear what aspects of the models you are using and what aspects you are not using.\"\n- \"SHACL is a semantic constraint language, which is quite useful as a guard for updates to a triple store. Because SHACL is less concerned with meaning and more concerned with structure, many object-oriented ontologists prefer it to OWL for defining their classes.\"\n- SHACL was strongly influenced by [[prdct.spin]] and can be regarded as its legitimate successor\n- \"Shacl popped up because people wanted to have something that operstes over their A-Boxes without slowly dragging their entire modeling and data storage into the T-Box. That's why they don't want the \"description logic perspective\", as it automatically leads down that \"no instances, just theories\" rabbit hole.\"\n\n\n## Examples\n\n- https://archive.topquadrant.com/edg-ontologies-overview/\n  - \"If a group of properties is reusable across assets that are not subclasses of each other (e.g., enterprise, technical and data assets are not subclasses of each other), EDG ontologies define an aspect class to hold or comprise this group of properties.\"\n  - mentions [[t.cs.semantic-web.class.aspect]]\n\n## Constraint Types\n\n-   **Structural Constraints**: Ensuring that data adheres to a specific schema or model, such as required properties, permissible property values, or specific class hierarchies.\n-   **Value Constraints**: Limiting the values that can be taken by properties, including data types, value ranges, and pattern matching.\n-   **Cardinality Constraints**: Defining the minimum and maximum occurrences of properties.\n-   **Logical Constraints**: Applying logical conditions to properties and values, such as equality or inequality, and combinations thereof through logical operators.\n\n## Comparisons\n\n![[prdct.rdf-js.shex#shex-vs-shacl]]\n\n![[prdct.spin#spin-vs-shacl]]\n\n## Resources\n\n- https://archive.topquadrant.com/shacl-blog/\n  - \"There are many ontologies in OWL which are really glossaries or taxonomies of terms. They do not define classes in terms of properties of their members. In other words, they do not contain schema or data definitions. They simply describe classes as vocabulary terms. You can easily identify such “ontologies” because you will see no OWL restrictions or domain/range statements. Instead, you will see synonyms and other annotation properties. In this case, recognize them for what they are and translate them to [[prdct.skos]] and/or develop a small ontology of your own to express this information. There is no value in keeping these terminologies in OWL nor in having them in SHACL.\"\n- https://archive.topquadrant.com/technology/shacl/\n\n## References\n\n- https://tdan.com/the-data-centric-revolution-best-practices-and-schools-of-ontology-design/31412\n- https://news.ycombinator.com/item?id=31890041\n- [[ar.topquadrant.why-i-dont-use-owl-anymore]]\n- https://www.ontotext.com/knowledgehub/fundamentals/what-is-shacl/\n- https://medium.com/fluree/what-is-shacl-with-examples-2697f659d465\n- https://connect-lokesh.medium.com/demystifying-shacl-guide-to-semantic-validation-part-1-016aa65d2070\n- [[ar.topquadrant.why-i-use-shacl-for-defining-ontology-models]]\n- [[ar.hackernews.semantic-web-is-like-the-guy-that-tells-everyone-that-he-is-an-asshole]]\n- [[ar.a-formal-approach-for-customization-of-schema-org-based-on-shacl]]\n- [[ar.linkedin.the-open-world-assumption-in-modeling-what-does-it-mean-to-you]]","n":0.047}}},{"i":2241,"$":{"0":{"v":"Shacl Engine","n":0.707},"1":{"v":"\n- repo: https://github.com/rdf-ext/shacl-engine","n":0.577}}},{"i":2242,"$":{"0":{"v":"Shacl API","n":0.707},"1":{"v":"\n- repo: https://github.com/TopQuadrant/shacl\n- publisher: [[org.topquadrant]]\n\n## description\n\n- based on Apache Jena. It covers SHACL Core and SHACL-SPARQL validation as well as SHACL Advanced Features, SHACL Javascript Extension and SHACL Compact Syntax. The same code is used in the TopBraid commercial products","n":0.158}}},{"i":2243,"$":{"0":{"v":"Session","n":1},"1":{"v":"\n- url: https://getsession.org/\n- ","n":0.577}}},{"i":2244,"$":{"0":{"v":"Servicestack","n":1},"1":{"v":"\n- url: https://servicestack.net/\n![](/assets/images/2024-03-13-16-26-01.png)\n\n## Features\n\n- Locode: provides a user-friendly interface to manage data using AutoQuery CRUD services, supporting 4 major RDBMS providers including PostgreSQL, SQL Server, MySQL and SQLite.\n\n\n## Issues\n\n- ","n":0.186}}},{"i":2245,"$":{"0":{"v":"Server Sent Events","n":0.577},"1":{"v":"\n\n## Cons\n\n- maximum 6 per browser + domain,\n- unidirectional, but\n  - \"When subscribing to an information source, you make one descriptive request in order to receive multiple responses. Specifically, when using GraphQL subscriptions or streaming operations (like with @defer and @stream directives), you do exactly this - you send one request and expect multiple responses (events) in return. Having said this, Server-Sent Events seem like a perfect fit!\"\n\n\n## Comparison\n\n### vs [[prdct.websocket]]\n\n- \"Built-in support for reconnection\"\n- You can only have six concurrent open SSE connections per browser at any one time. This can be especially painful when you want to open multiple tabs with SSE connections. See '[Server-Sent Events and browser limits](https://stackoverflow.com/questions/18584525/server-sent-events-and-browser-limits)' for more information and workaround suggestions.\n\n### References\n\n- https://ably.com/blog/websockets-vs-sse\n- https://the-guild.dev/blog/graphql-over-sse\n  - mentions: [[prdct.graphql-sse]]","n":0.09}}},{"i":2246,"$":{"0":{"v":"SeRQL","n":1}}},{"i":2247,"$":{"0":{"v":"Serilog","n":1},"1":{"v":"\n- url:\n\n## Resources\n\n- https://onloupe.com/blog/serilog-vs-mel/","n":0.5}}},{"i":2248,"$":{"0":{"v":"Seon Software Engineering Ontology Network","n":0.447},"1":{"v":"\n- https://dev.nemo.inf.ufes.br/seon/\n- [[c.ontology]]\n- based-on: [[prdct.unified-foundational-ontology]]","n":0.447}}},{"i":2249,"$":{"0":{"v":"Seneca","n":1},"1":{"v":"\nurl: https://senecajs.org/","n":0.707}}},{"i":2250,"$":{"0":{"v":"Sematext","n":1},"1":{"v":"\n## [[p.hadDescription]]\n\n-  production & performance issues with logs, metrics, synthetics and real user monitoring\n\n## [[p.supports]]\n\n\n## [[p.hasFeature]]\n\n- [[t.cs.logging]]\n- [[t.cs.host-monitoring]]\n- [[t.cs.ux-monitoring]]\n- [[t.cs.web.synthetics-monitoring]]\n- [[t.cs.tracing]]\n  - [[p.supports]]\n    - [[prdct.jaeger]]\n    - [[prdct.zipkin]]\n\n## Comparable\n\n- [[prdct.sematext]]\n\n## [[p.hasComparison]]\n\n- https://sematext.com/new-relic-alternative/\n- [[prdct.openapm]]\n","n":0.177}}},{"i":2251,"$":{"0":{"v":"Semaphore","n":1},"1":{"v":"\n- https://www.progress.com/semaphore/platform\n- [[c.software.Knowledge-Base]] [[c.software.semantic.linked-data-platform]]  \n- demo: https://trial.semaphore.marklogic.com/\n- published-by: [[org.progress-software]]","n":0.333}}},{"i":2252,"$":{"0":{"v":"Semantify","n":1},"1":{"v":"\n- https://semantify.it/","n":0.707}}},{"i":2253,"$":{"0":{"v":"Semanticscience Integrated Ontology Sio","n":0.5},"1":{"v":"\n## Hypotheticals\n\n- + entity\n    + attribute\n        + quality\n            + existence quality\n                + hypothetical\n                    - predicted\n                    - imaginary\n                    - fictional\n\n\n\n- https://ontobee.org/ontology/SIO\n- repo: https://github.com/MaastrichtU-IDS/semanticscience\n- owl: https://raw.githubusercontent.com/micheldumontier/semanticscience/master/ontology/sio/release/sio-release.owl","n":0.204}}},{"i":2254,"$":{"0":{"v":"Semantically Interlinked Online Communities (SIOC)","n":0.447},"1":{"v":"\n- spec: http://rdfs.org/sioc/spec/\n- rdf: http://rdfs.org/sioc/ns#","n":0.447}}},{"i":2255,"$":{"0":{"v":"Semantic Turkey","n":0.707},"1":{"v":"\n- https://semanticturkey.uniroma2.it/\n- published-by: [[org.artificial-intelligence-research-art-at-tor-vergata]]","n":0.5}}},{"i":2256,"$":{"0":{"v":"Semantic Synchrony","n":0.707},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/synchrony/smsn\n- [[p.builtOn]] [[prdct.neo4j]]\n- [[p.hasFeature]] Semantic Synchrony can use any graph backend, because it uses Gremlin, a meta-language for graph APIs. It currently supports Neo4j, but it would only takes a couple new Java classes to add support for Titan or something else.\n  - [[p.hasSource]] https://github.com/synchrony/smsn-why/blob/master/scale-speed-and-robustness.md\n","n":0.146}}},{"i":2257,"$":{"0":{"v":"Semantic Obsidian","n":0.707},"1":{"v":"\n\n#tools-for-thought #pkm\n\nhttps://juggl.io/Semantic+Obsidian\n\nIn Semantic Obsidian, notes are the main entities. They have both loose associations through inline wikilinks and backlinks, and strong links through Link Types with properties. They can be used to provide cues for files that are related. \n","n":0.158}}},{"i":2258,"$":{"0":{"v":"Semantic Objects Modeling Language","n":0.5},"1":{"v":"\n- repo: https://github.com/VladimirAlexiev/soml\n","n":0.577}}},{"i":2259,"$":{"0":{"v":"2023-10-05","n":1},"1":{"v":"\n\n## t.2023.10.05\n\n- [[p.discovered]] [[prdct.hyperfiddle]]\n- [[p.joined]] [[community.matrix.third-room]]\n- [[sh.use-case.a-good-dm-turns-off-auto-follow-if-players-are-taking-advantage-of-it]]\n- [[p.discovered]] [[prdct.pikchr]] [[prdct.diagrams.seflless]]","n":0.316}}},{"i":2260,"$":{"0":{"v":"Second Brain","n":0.707},"1":{"v":"\n## Resources\n\n- https://dev.to/shaan_alam/how-i-built-my-second-brain-using-nextjs-56e7 [[prdct.nextjs]]","n":0.5}}},{"i":2261,"$":{"0":{"v":"SDL","n":1},"1":{"v":"\n- url https://www.libsdl.org/","n":0.577}}},{"i":2262,"$":{"0":{"v":"Scriptaculous","n":1},"1":{"v":"\n- http://script.aculo.us/\n- [[c.software.web.javascript-toolkit]]","n":0.577}}},{"i":2263,"$":{"0":{"v":"Scriban","n":1},"1":{"v":"\n- repo: https://github.com/scriban/scriban\n- written_in: c#\n","n":0.447}}},{"i":2264,"$":{"0":{"v":"Screenplays in Xml Six","n":0.5},"1":{"v":"\n\n## References\n\n- [[ar.annotation-of-heterogenous-media-using-onto-media]]","n":0.577}}},{"i":2265,"$":{"0":{"v":"Scratch","n":1},"1":{"v":"\n- url: [[https://scratch.mit.edu]]\n- repo: \n\n## Resources\n\n- https://webcache.googleusercontent.com/search?q=cache:SfvCNXHXGPYJ:https://scratch.mit.edu/discuss/topic/509008/&cd=10&hl=en&ct=clnk&gl=us&client=firefox-b-1-d\n  - [[p.mentioned]] [[prdct.sb3-commit]]\n\n## Ideas\n\n- \"If Scratch 4 ever rolls around, the Scratch Team should absolutely base it on a Javascript-based Smalltalk, one with a live visual environment like Squeak has. This would bring back everything I loved about the 1.x versions of Scratch and their pedagogical value while maintaining Scratch 3's support for phones and tablets.\"\n  - https://webcache.googleusercontent.com/search?q=cache:YaQwmLQ5HGMJ:https://scratch.mit.edu/discuss/topic/667973/&cd=10&hl=en&ct=clnk&gl=us&client=firefox-b-1-d\n","n":0.124}}},{"i":2266,"$":{"0":{"v":"Schema.org","n":1},"1":{"v":"\n## Overview\n\n- There are three kinds of schema.org term in the schema.org data model: types, properties and enumerated values\n\n## Thoughts\n\n### \"reservationFor\" rdf:object schema:Thing\n\n- in common language, this property could imply \"who is the reservation for\" instead of \"what is being reserved\"\n- 'underName' takes a Person or Organization... so I guess you just re-use that property to list all the people. But in a programmatic domain model, you'd use a collection, ideally a typed collection... I guess a weakness of RDF, not schema.org\n- what's the point of specifying 'schema:rangeIncludes\": { \"@id\": \"schema:Thing\" }'\n\n## Style Guide\n\n### Naming conventions\n\n-   Do not give the same name to a type and a property.\n    -   Note that schema.org has some legacy cases where this was done in the past. This practice should be avoided.\n    -   E.g. Avoid creating both [ContactPoint](https://schema.org/ContactPoint) and [contactPoint](https://schema.org/contactPoint).\n-   _Term names should use Singular naming only_, even if the semantics call for a plural.\n    -   E.g. [parent](https://schema.org/parent) and not parents, even though for each type, there will always be multiple values for the property [parent](https://schema.org/parent).\n-   _Prepositions_ should come after the type or property name.\n    -   E.g. [reservationFor](https://schema.org/reservationFor).\n-   _Abbreviations_: When creating new types, spell out abbreviations, unless the result is painfully verbose.\n    -   Due to legacy entries, sometimes certain words may be abbreviated, or not, in schema.org. Due to lack of consistency, should search for both when looking for a schema term.\n    -   E.g. [numTracks](https://schema.org/numTracks) exists in schema.org as a legacy property. If we were creating this property now, it would be _numberOfTracks_ (or better yet, name it _trackCount_ to be semantically aligned with other counting properties).\n-   _Spelling_: US spellings must be used.\n    -   E.g. [color](https://schema.org/color) and not colour.\n\n#### Thoughts on Naming Conventions\n\n- it's a red flag that types and properties could have the same name. I've grappled with this for [[gd]]... if you're going to say \"has <type>\", having a separate property seems redundant\n\n## Resources\n\n- https://schema.org/docs/styleguide.html","n":0.057}}},{"i":2267,"$":{"0":{"v":"Scalego","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/GiGurra/scalego","n":0.5}}},{"i":2268,"$":{"0":{"v":"Scala JS","n":0.707},"1":{"v":"\n- url: https://www.scala-js.org/\n- repo: \n\n## Resources\n\n### [[c.resource.list]]\n\n- https://www.scala-js.org/doc/tutorial/index.html","n":0.354}}},{"i":2269,"$":{"0":{"v":"SBVR","n":1},"1":{"v":"\n## References\n\n- https://en.wikipedia.org/wiki/Semantics_of_Business_Vocabulary_and_Business_Rules","n":0.577}}},{"i":2270,"$":{"0":{"v":"Sb3 Commit","n":0.707},"1":{"v":"\n- repo: https://github.com/rokcoder-scratch/sb3-commit","n":0.577}}},{"i":2271,"$":{"0":{"v":"Satori","n":1},"1":{"v":"\n- [[p.wasBuiltBy]] [[org.heroic-labs]]\n\n","n":0.577}}},{"i":2272,"$":{"0":{"v":"Sass","n":1},"1":{"v":"\n- url: https://sass-lang.com/","n":0.577}}},{"i":2273,"$":{"0":{"v":"Sarl","n":1},"1":{"v":"\n\n- url: http://www.sarl.io/\n- repo: https://github.com/sarl/sarl\n- [[p.supports]] [[prdct.janus-project]]","n":0.378}}},{"i":2274,"$":{"0":{"v":"Sapphire","n":1},"1":{"v":"\n- probably dead, never published?\n- [[c.Software.object-graph-mapper]]\n- similar: [[prdct.RDFReactor]] , OntoJava (dead), Owl2Java (dead),  the work of Kalayanpur et al \n- built-on: [[prdct.jena.ng4j]]","n":0.213}}},{"i":2275,"$":{"0":{"v":"Saphiredb","n":1},"1":{"v":"\n\n- [[p.hasClientSupport]]\n  - javascript \n  - [[prdct.node]]\n  - [[prdct.react]]\n  - [[prdct.svelte]]\n- [[c.implementation]]\n  - [[prdct.asp-net]]\n","n":0.267}}},{"i":2276,"$":{"0":{"v":"Sante","n":1},"1":{"v":"\n- [[c.software.semantic.search-engine]]\n- repo: https://github.com/aksw/sante\n- related: [[prdct.kbox]] [[prdct.nspm]] [[prdct.quit]]\n- written-in: java\n- ","n":0.316}}},{"i":2277,"$":{"0":{"v":"Sandra","n":1},"1":{"v":"\n\n## References\n\n- [[ar.arxiv.sandra-a-neuro-symbolic-reasoner-based-on-descriptions-and-situations]]","n":0.577}}},{"i":2278,"$":{"0":{"v":"Apache Samza","n":0.707},"1":{"v":"\n- topics: [[t.cs.data.materialized-view]]\n\n## Description\n\n- If you use Kafka to implement the log, how do you implement these materialized views? That’s where Apache Samza comes in. It’s a stream processing framework that is designed to go well with Kafka. With Samza, you write jobs that consume the events in a log, and build cached views of the data in the log. When a job first starts up, it can build up its state by consuming all the events in the log. And on an ongoing basis, whenever a new event appears in the stream, it can update the view accordingly. The view can be any existing database or index — Samza just provides the framework for processing the stream.\n\n\n\n## References\n\n- https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/","n":0.091}}},{"i":2279,"$":{"0":{"v":"Samsung Care Plus","n":0.577},"1":{"v":"\n\n## [[c.term]]\n\n- https://us.servify.tech/termsandconditions/samsung/samsung-b2c/samsungcareplusnew t.2023.08.21\n\n Your Plan Summary\n\t\nPlan Benefits: \thttps://www.samsung.com/us/support/samsung-care-plus/\nContract ID: \tUSA23H0618695379\nName: \tDavid Richardson\nMobile Number: \t+1 9175260509\nPlan Name: \tSamsung Care+\nPlan Purchase Date: \t08/22/2023\nCoverage Start Date: \t08/29/2023\nCoverage Ends Midnight: \t08/21/2026\nDevice Purchase Date: \t08/19/2023\nDevice Model: \tSM-S918UZGAATT\nIMEI/Serial Number: \t358163260140664\nTerms and Conditions: \thttps://us.servify.tech/termsandconditions/samsung/samsung-b2c/\n","n":0.162}}},{"i":2280,"$":{"0":{"v":"Samod Methodology","n":0.707},"1":{"v":"\n- https://essepuntato.it/samod/\n\n## Terms\n\n- Motivating Scenario\n- ","n":0.447}}},{"i":2281,"$":{"0":{"v":"Salesforce","n":1}}},{"i":2282,"$":{"0":{"v":"Sade","n":1},"1":{"v":"\n- [[c.software.cli-framework]]\n- repo: https://github.com/lukeed/sade\n","n":0.5}}},{"i":2283,"$":{"0":{"v":"Sacred Capital","n":0.707},"1":{"v":"\n\n\n- [[p.hasVision]] \n  - a Wix-like environment where non-techie community activators can bundle together the tools they need to shift their communities from, say, an awkward mish-mash of GSuite, Facebook, and Discord to the crypto web.\n- [[p.hasConcept]]\n  - We prefer to think in terms of “neighbourhoods” because, unlike platforms, neighbourhoods are not burdened by: ^1uVLS5bphpiF\n    - vendor lock-in\n    - algorithms whose obscure operations dictate what we stumble upon\n    - corporate-driven community guidelines\n    - centralized storage of sensitive, interpersonal data and communication\n      - (although to make a game fair, you can submit your information to a trustworty MCP)\n  \n## [[p.hasLearningResource]]\n\n- https://sacred-capital.gitbook.io/sacred-capital/\n","n":0.1}}},{"i":2284,"$":{"0":{"v":"Reputation Vault","n":0.707},"1":{"v":"\n\n\n- [[p.hasComponent]]\n  - 1. Reputation Libraries\n    - Reputation Data represents the most fundamental building blocks of our reputation system. To facilitate computations with and access to these building blocks, we package them as pluggable, swappable libraries that allow communities to articulate and iterate on their culture with ease. Such structures also allow for computation on reputation data across contexts. \n  - 2. The Reputation Interchange\n    - The interchange co-ordinates cross-membrane access to reputation data through a consent driven process. In other words, a neighbourhoods, or micro-community can articulate their culture using reputation data that is being generated across neighbourhoods as well as their own community. \n    - From an agents perspective the interchange serves as a switchboard that allows them to control their reputation data as they hop across micro-collectives. More details about the process, and the channels that data is ported through are outlined in subsequent sections.\n  - 3. Reputation Scores\n    - Reputation data from across contexts is computed within a neighbourhood to generate what is known as a 'Reputation Score'. Reputation scores are calculated locally, in a specific neighbourhood, which means they are contextual, and not universally imposed as absolute snapshots of reality. \n","n":0.071}}},{"i":2285,"$":{"0":{"v":"rep_lang DSL","n":0.707},"1":{"v":"\n- url: https://www.sacred.capital/technology\n- #docs https://neighbourhooods.gitbook.io/sacred-capital/ \n- [[p.instanceOf]] [[c.dsl]]\n","n":0.354}}},{"i":2286,"$":{"0":{"v":"Saaskit","n":1},"1":{"v":"\nbuilt_on: [[prdct.deno-fresh]]\nrepo: https://github.com/denoland/saaskit\n","n":0.577}}},{"i":2287,"$":{"0":{"v":"S2 Geometry","n":0.707},"1":{"v":"\n- url: https://s2geometry.io\n- #topic [[t.math.geometry]] \n\n## Resources\n\n- https://s2geometry.io/resources/earthcube\n\n## Highlights\n\n- In S2, points are represented internally as unit-length vectors (points on the surface of a three-dimensional unit sphere) as opposed to traditional (latitude, longitude) pairs. This is for two reasons:\n\nUnit vectors are much more efficient when working with geodesic edges. Using (latitude, longitude) pairs would require constantly evaluating trigonometric functions (sin, cos, etc), which is slow even on modern CPU architectures.\n\nUnit vectors allow exact geometric predicates to be evaluated efficiently. To do this with (latitude, longitude) pairs, you would essentially need to convert them to the unit vector representation first.\n","n":0.101}}},{"i":2288,"$":{"0":{"v":"S/4hana","n":1},"1":{"v":"\n- [[c.publisher]] [[org.sap]]","n":0.577}}},{"i":2289,"$":{"0":{"v":"Rya","n":1},"1":{"v":"\n- https://rya.apache.org/","n":0.707}}},{"i":2290,"$":{"0":{"v":"Rxdb","n":1},"1":{"v":"\n- [[c.software.database.document]]\n#similar [[prdct.rxdb]] [[prdct.rethinkdb]] [[prdct.supabase]] [[prdct.pouchdb]] [[prdct.lokijs]] [[prdct.gundb]] [[prdct.dexiejs]] ^pnjx84u9yrqy\n- url: https://rxdb.info/\n- author: @daniel-meyer\n\n- [[p.hasComparison]]\n  - https://rxdb.info/alternatives.html\n\n## Features\n\n- RxDB supports replication with a [[prdct.couchdb]] server or any custom [[prdct.graphql]] endpoint\n- you can use the replication primitives plugin to create custom replications over any protocol like HTTP, Websocket, WebRTC or Firestore.\n- [[t.cs.offline-first]]","n":0.14}}},{"i":2291,"$":{"0":{"v":"RulesEngine","n":1},"1":{"v":"\n- [[c.software.rules-engine]]\n- url: https://microsoft.github.io/RulesEngine/\n- repo: https://github.com/microsoft/RulesEngine\n- written-in: c#\n\n## Cons\n\n- methods that a lambda expression can do are limited to System namespace of .Net framework. BUT\n  - you can create custom classes that can be used in the lambda expressions\n\n## Resources\n\n- https://betterprogramming.pub/rule-engine-a-new-library-that-eradicates-if-else-statements-60e362a1ddb0","n":0.156}}},{"i":2292,"$":{"0":{"v":"RulesEngine Editor","n":0.707},"1":{"v":"\n- repo: https://github.com/alexreich/RulesEngineEditor","n":0.577}}},{"i":2293,"$":{"0":{"v":"Ruleml","n":1},"1":{"v":"\n- url: \n- spec: https://www.w3.org/2005/rules/wg/wiki/RuleML\n- related: [[prdct.jess]]","n":0.378}}},{"i":2294,"$":{"0":{"v":"Rule Book","n":0.707},"1":{"v":"\n- dead since 2000\n- [[c.Software.Rules-Engine]]\n- repo: https://github.com/deliveredtechnologies/rulebook\n![[prdct.jess.rules-language#^cmcaoqsy0ccx]]\n\n## description\n\n- RuleBook makes use of the concept of “Facts”, which is data supplied to rules. RuleBook allows rules to modify the state of facts, which then can be read and modified by rules further down the chain. For those rules that read in data (Facts) of one type and output a result of a different type, RuleBook has Decisions.\n\n\n## References\n\n- https://www.baeldung.com/java-rule-engines\n- ","n":0.121}}},{"i":2295,"$":{"0":{"v":"RTC.ex","n":1},"1":{"v":"\n- written-in: [[prdct.elixir]]\n\n## Example\n\n```elixir\n# create a new compound with a couple triples\nvirtual_graph =  \n  [  \n    {EX.Employee38, EX.firstName(), \"John\"},  \n    {EX.Employee38, EX.familyName(), \"Smith\"},  \n    {EX.Employee38, EX.jobTitle(), \"Assistant Designer\"},  \n  ] \n  |> RTC.Compound.new(EX.Compound, prefixes: [ex: EX])  \n\n# add some triples to the compound\nvirtual_graph =  \n  RTC.Compound.add(virtual_graph,   \n    EX.Employee39  \n    |> EX.firstName(\"Jane\")  \n    |> EX.familyName(\"Doe\")  \n    |> EX.jobTitle(\"HR Manager\")  \n  )  \n\n# add some statements about the compound itself\nvirtual_graph =  \n  RTC.Compound.add_annotations(virtual_graph,  \n    %{EX.dataSource() => EX.DataSource}  \n  )\n```\n\n- With the RTC.Compound.graph(virtual_graph) function, the pure set of statements can be produced as an RDF.Graph at any time, which in this case generates this graph:\n\n```turtle\n@prefix ex: <http://example.com/> .\n\nex:Employee38\n    ex:familyName \"Smith\" ;\n    ex:firstName \"John\" ;\n    ex:jobTitle \"Assistant Designer\" .\n\nex:Employee39\n    ex:familyName \"Doe\" ;\n    ex:firstName \"Jane\" ;\n    ex:jobTitle \"HR Manager\" .\n```\n\nWhereas RTC.Compound.to_rdf(virtual_graph) provides the complete RDF-star graph with the RTC annotations for the compounds.\n\n```turtle\n@prefix ex: <http://example.com/> .\n@prefix rtc: <https://w3id.org/rtc#> .\n\nex:Compound\n    ex:dataSource ex:DataSource .\n\nex:Employee38\n    ex:familyName \"Smith\" {| rtc:elementOf ex:Compound |} ;\n    ex:firstName \"John\" {| rtc:elementOf ex:Compound |} ;\n    ex:jobTitle \"Assistant Designer\" {| rtc:elementOf ex:Compound |} .\n\nex:Employee39\n    ex:familyName \"Doe\" {| rtc:elementOf ex:Compound |} ;\n    ex:firstName \"Jane\" {| rtc:elementOf ex:Compound |} ;\n    ex:jobTitle \"HR Manager\" {| rtc:elementOf ex:Compound |} .\n```\n\n\n## References\n\n- [[ar.ontogen.introducing-ontogen]]","n":0.072}}},{"i":2296,"$":{"0":{"v":"Rstudio","n":1},"1":{"v":"\n- url: https://posit.co/\n- [[c.publisher]]: [[org.posit]]\n- supports: [[prdct.jupyter]]","n":0.378}}},{"i":2297,"$":{"0":{"v":"Rot.js","n":1},"1":{"v":"\n\n\n- [[p.hasLearningResource]]\n  - http://roguebasin.com/index.php/Rot.js_tutorial,_part_1\n  - https://blog.logrocket.com/building-a-roguelike-game-with-rot-js/","n":0.408}}},{"i":2298,"$":{"0":{"v":"Roslyn","n":1},"1":{"v":"\n## Resources\n\n- https://subscription.packtpub.com/book/programming/9781787286832/7/ch07lvl1sec54/using-the-roslyn-scripting-api-to-execute-c-code-snippets","n":0.577}}},{"i":2299,"$":{"0":{"v":"Romulus","n":1},"1":{"v":"\n- [[c.software.semantic.library]]\n- url: http://www.thezfiles.co.za/ROMULUS/\n- related: [[prdct.onset]]\n\n\n## References\n\n- https://keet.wordpress.com/2013/04/04/release-of-the-beta-version-of-the-foundational-ontology-library-romulus/\n- [[ar.foundational-ontologies-in-action]]","n":0.333}}},{"i":2300,"$":{"0":{"v":"Roll20","n":1},"1":{"v":"\n\n- [[c.software.rpg.virtual-tabletop]]\n- [[p.hasApplication]] [[t.roleplaying.campaign-management]]\n\n## Similar\n\n- [[prdct.owlbear-rodeo]] [[prdct.astral-tabletop]] \n\n## User Stories\n\n### player/group discovery\n\n- The only other thing Roll20 has going for it is some aspect of \"player/group discovery\", but dedicated communities for that will fare better as well.  ^kfuchjgdd76i","n":0.162}}},{"i":2301,"$":{"0":{"v":"Role","n":1},"1":{"v":"\n- https://www.playrole.com/\n- [[t.roleplaying.virtual-tabletop]]\n- integrates-with: [[prdct.owlbear-rodeo]]\n\n## Features\n\n- [Creators Program](https://playrole.notion.site/Role-Creators-Program-f7ce12ca90ca47f881e13f70f7857973)\n  - Creators retain ownership of ALL content and keep 75% of sales. That is the best rate for creators across all tabletop game platforms.","n":0.177}}},{"i":2302,"$":{"0":{"v":"RocksDB","n":1},"1":{"v":"\n\n- [[p.hasSite]] http://rocksdb.org/\n- written-in: #c++\n","n":0.447}}},{"i":2303,"$":{"0":{"v":"Robot","n":1},"1":{"v":"\n- http://robot.obolibrary.org/\n- [[c.software.semantic.utility]]\n- repo: https://github.com/ontodev/robot\n\n## Features\n\nannotate\ncollapse\nconvert\ndiff\nexpand\nexplain\nexport\nexport-prefixes\nextract\nfilter\nmaterialize\nmeasure\nmerge\nmirror\npython\nquery\nreason\nreduce\nrelax\nremove\nrename\nrepair\nreport\ntemplate\nunmerge\nvalidate-profile\nverify\n\n\n## References\n\n- [ROBOT: A Tool for Automating Ontology Workflows](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3002-3)","n":0.267}}},{"i":2304,"$":{"0":{"v":"Robocode","n":1},"1":{"v":"\n- url: https://robocode.sourceforge.io/\n- related: [[prdct.robocode.tank-royale]]\n![[game.screeps#^zwsvp7ab3c0e]]","n":0.447}}},{"i":2305,"$":{"0":{"v":"Tank Royale","n":0.707},"1":{"v":"\n- repo: https://github.com/robocode-dev/tank-royale\n- supports: \n  - jvm ( Java, Groovy, Kotlin, Scala, Jython, and Clojure )\n  - .net ( C#, F#, Visual Basic, and IronPython )","n":0.196}}},{"i":2306,"$":{"0":{"v":"Ro Core","n":0.707},"1":{"v":"\n- url: https://raw.githubusercontent.com/oborel/obo-relations/master/core.owl\n\n## References\n\n- https://github.com/oborel/obo-relations/wiki/ROCore","n":0.447}}},{"i":2307,"$":{"0":{"v":"Riskfirst_hateoas","n":1},"1":{"v":"\n- repo: https://github.com/riskfirst/riskfirst.hateoas","n":0.577}}},{"i":2308,"$":{"0":{"v":"Risingwave","n":1},"1":{"v":"\n- https://risingwave.com/\n\n## Features\n\n- wire-compatible with PostgreSQL,","n":0.408}}},{"i":2309,"$":{"0":{"v":"Rich4clojure","n":1},"1":{"v":"\n- repo: https://github.com/PEZ/rich4clojure\n- ","n":0.577}}},{"i":2310,"$":{"0":{"v":"Rhizomedb","n":1},"1":{"v":"\n- #related [[t.cs.distributed.crdt]]\n\n## Resources\n\n- https://fission.codes/blog/rhizomedb-querying-data/","n":0.447}}},{"i":2311,"$":{"0":{"v":"Reticulum","n":1},"1":{"v":"\n- repo: https://github.com/mozilla/reticulum\n- built_on: [[prdct.phoenix]]","n":0.447}}},{"i":2312,"$":{"0":{"v":"Rethinkdb","n":1},"1":{"v":"\n![[prdct.rxdb#^pnjx84u9yrqy]]\nurl: https://rethinkdb.com/\n","n":0.707}}},{"i":2313,"$":{"0":{"v":"reStructuredText","n":1},"1":{"v":"\n\n- \"The core Python documentation has been written in reST for quite a while, but only after the release of Sphinx has it seen serious uptake outside\"\n  - [[p.hasSource]] https://eli.thegreenplace.net/2017/restructuredtext-vs-markdown-for-technical-documentation/\n\n- [[p.similarTo]] [[prdct.markdown]]\n  - RST supports footnotes, tables, citations, tables of contents\n  - more standardized and uniform\n  - built-in support for extensions","n":0.14}}},{"i":2314,"$":{"0":{"v":"Rest Client","n":0.707},"1":{"v":"\n- url: https://marketplace.visualstudio.com/items?itemName=humao.rest-client","n":0.577}}},{"i":2315,"$":{"0":{"v":"ReSpec","n":1},"1":{"v":"\n\n\n- [[c.software.library]] \n- written-in: javascript\n- [[p.hasApplication]] [[gd.specifications]]\n- [[p.hasRepository]] https://github.com/w3c/respec\n- [[p.hasExample]] https://github.com/w3c/respec/blob/develop/examples/starter.html\n","n":0.302}}},{"i":2316,"$":{"0":{"v":"Resourceful","n":1},"1":{"v":"\n- https://github.com/jdesrosiers/resourceful\n- written-in: php\n- uses: [[prdct.silex]]","n":0.408}}},{"i":2317,"$":{"0":{"v":"Resource Description and Access (RDA)","n":0.447},"1":{"v":"\n- predecessors: [[prdct.anglo-american-cataloguing-rules-aacr2]]\n\n## References\n\n- http://palrap.org/ojs/index.php/palrap/article/download/106/494","n":0.447}}},{"i":2318,"$":{"0":{"v":"Repast4py","n":1},"1":{"v":"\n- [[c.software.agent-framework]] [[c.software.simulation-framework]]\n- repo: https://github.com/Repast/repast4py\n\n## Thoughts\n\n- \"distributed\" means that the simulation is spread over multiple computer processes none of which have access to each other’s memory, and communicate via message passing using the [[Message Passing Interface|prdct.mpi4py]].\n\n\n## Resources\n\n- [DISTRIBUTED AGENT-BASED SIMULATION WITH REPAST4PY](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9912342/)\n  - \"the user must implement a save method that returns the state of the agent as a tuple.\"\n    - hah! how about a reference to save state\n  - event scheduling\n    - \"events are scheduled to occur at a particular tick. Ticks do not represent clock-time but rather the priority of its associated event\"\n    - A floating point tick, together with the ability to order the priority of events scheduled for the same tick, provides for flexible scheduling.\n  - \"components are of three types: 1) agents and their environments; 2) logging and data collection; and 3) simulation utility functions (e.g., random number management, input parameter parsing, and so on)\"","n":0.082}}},{"i":2319,"$":{"0":{"v":"Repast Simphony","n":0.707},"1":{"v":"\n- repo: https://github.com/Repast/repast.simphony\n- written-in: java\n\n## Features\n\n- Repast Simphony models can be developed in several different forms including the ReLogo dialect of Logo, point-and-click statecharts, [[t.cs.languages.groovy]], or Java, all of which can be fluidly interleaved.","n":0.171}}},{"i":2320,"$":{"0":{"v":"Reo","n":1},"1":{"v":"\n- https://www.cwi.nl/en/groups/computer-security/software/extensible-coordination-tools-plug-ins-for-the-eclipse-platform/\n\n## Implementations\n\n- [[prdct.extensible-coordination-tools]]\n\n## References\n\n- https://en.wikipedia.org/wiki/Reo_Coordination_Language","n":0.408}}},{"i":2321,"$":{"0":{"v":"Remote.It","n":1},"1":{"v":"\n\n- similar to [[prdct.twingate]] or [[prdct.strongdm]] ?\n  - they're relay-based\n- contractors shouldn't get full subnet access, so it's down to the service\n- no whitelisting of endpoint\n- jumphost is cloud host\n- pricing model is $25/user/mo, endpoints are unlimited; contractors etc are \"shared\" for free\n- has \"openvpn\" use case, when you don't want publicly available VPN endpoint.\n- most customers looking to get off public endpoint\n- support the relay use case, but p2p is a differentiator","n":0.117}}},{"i":2322,"$":{"0":{"v":"Remix","n":1},"1":{"v":"\n- [[c.Software.Web-Framework]]\n- url: https://remix.run/\n- works_with: [[prdct.hono]]\n\n## Pros\n\n- built on the Web Fetch API instead of Node.js. This enables Remix to run in any Node.js server like Vercel, Netlify, Architect, etc. as well as non-Node.js environments like Cloudflare Workers and Deno Deploy.\n- Remix’s “loaders” are particularly powerful, allowing the server to gather all necessary data for a route before it’s rendered. This differs from Next.js, where an application might load the JavaScript first, then realize it needs to fetch additional data via APIs, potentially slowing down initial load times. By using Remix’s loaders, OpenAI ensures that the initial page load is faster and smoother, as all required data is pre-fetched and delivered in a single step.\n\n\n## Issues\n\n### What About Server-Side Rendering and SEO?\n\nGiven the popularity of server-side rendering for SEO and performance reasons, some might wonder why OpenAI chose to move away from Next.js’s SSR features. The answer is simple: ChatGPT doesn’t require the typical SEO benefits that come with SSR. Since the application is primarily a tool rather than a content-driven website, SEO is less of a concern. Instead, OpenAI focuses on fast, smooth client-side interactions, which Remix handles efficiently.\n\n\n## Resources\n\n- [remix project template for deno](https://github.com/remix-run/remix/discussions/2207)\n\n## References\n\nhttps://medium.com/@lbq999/why-openai-moved-from-next-js-to-remix-a-closer-look-114732b28eb9","n":0.071}}},{"i":2323,"$":{"0":{"v":"Remark","n":1},"1":{"v":"\nurl: https://remark.js.org/\n\n- written-in: javascript\n\n## Resources\n\n- [Stackoverflow: How to parse markdown to json using remark](https://stackoverflow.com/questions/68647885/how-to-parse-markdown-to-json-using-remark)","n":0.267}}},{"i":2324,"$":{"0":{"v":"Relinq","n":1},"1":{"v":"\n- repo: https://github.com/re-motion/Relinq","n":0.577}}},{"i":2325,"$":{"0":{"v":"Reldens","n":1},"1":{"v":"\n\n- written-in: javascript\n- [[p.builtOn]] [[prdct.colyseus]]\n- [[p.hasURL]] https://npm.io/package/reldens\n- [ ] review Reldens","n":0.302}}},{"i":2326,"$":{"0":{"v":"Relations Ontology","n":0.707},"1":{"v":"\n- repo: https://github.com/oborel/obo-relations\n- docs: \n  - https://github.com/oborel/obo-relations/wiki/Menu\n  - https://oborel.github.io/obo-relations/\n\n## Highlights\n\n- causal agent in process: A relationship between a material entity and a process where the material entity has some causal role that influences the process\n- has exposure stimulus:  A relationship between an exposure event or process and any agent, stimulus, activity, or event that causally effects an organism and interacts with an exposure receptor during an exposure event. \n- causally upstream of: etc\n\n\n## Resources\n\n- https://ontobee.org/ontology/catalog/RO?iri=http://www.w3.org/2002/07/owl%23ObjectProperty\n\n## References\n\n- https://www.ebi.ac.uk/ols4/ontologies/ro\n- https://oborel.github.io/obo-relations/","n":0.113}}},{"i":2327,"$":{"0":{"v":"re-frame","n":1},"1":{"v":"\n- repo: https://github.com/day8/re-frame\n\n## Features\n\n- \"Although re-frame leverages React (via Reagent), it only needs React to be the V in MVC, and no more. re-frame takes a different road to the currently-pervasive idea that Views should be causal (colocated queries, ComponentDidMount, hooks, etc). In re-frame, events are causal, and views are purely reactive.\"","n":0.139}}},{"i":2328,"$":{"0":{"v":"Redwood","n":1},"1":{"v":"\n- #dead\n\n- [[p.hasRepository]] https://github.com/redwood/redwood\n- written-in: #go","n":0.408}}},{"i":2329,"$":{"0":{"v":"Redux JS","n":0.707},"1":{"v":"\n- [[c.software.state-store]]\n- [[p.vs]] [[prdct.react]]\n  - [[p.hasSource]] \n    - https://www.fireup.pro/blog/redux-vs-react-context-which-should-you-use\n    - https://changelog.com/posts/when-and-when-not-to-reach-for-redux\n- [[p.compatibleWith]] [[prdct.svelte]]\n- [[p.integratesWith]] [[prdct.svelte]]\n- similar-to: [[prdct.mobx]]\n\n## Use Cases\n\n- server-side state, see https://github.com/mobxjs/mobx/issues/1922\n\n## Principles\n\n- \"Instead of mutating the state directly, you specify the mutations you want to happen with plain objects called actions. Then you write a special function called a reducer to decide how every action transforms the entire application's state... It also enables very powerful developer tools, because it is possible to trace every mutation to the action that caused it. You can record user sessions and reproduce them just by replaying every action.\"\n  - https://redux.js.org/introduction/getting-started\n\n## Resources\n\n- https://svelte.dev/repl/b41141c04f1140b687ce5f1bb3c036b9?version=3.48.0\n- http://orta.io/notes/games/phaser-redux\n- http://orta.io/notes/games/phaser-redux","n":0.099}}},{"i":2330,"$":{"0":{"v":"Redpanda","n":1},"1":{"v":"\n## Similar\n\n- [[prdct.kafka]] \n- [[prdct.pulsar]]\n- [[prdct.nats.jetstream]]\n- [[prdct.memphis]]\n\n## Comparison\n\n### [[prdct.kafka]]\n\n- Simplicity. Redpanda is deployed as a self-contained, single binary. A typical Kafka cluster may consist of a set of data brokers, an auxiliary ZooKeeper cluster (or KRaft consensus plane), and separately deployed resources for REST proxy and schema registry services. [^1]\n\n\n## Resources\n\n- [1^]: https://thenewstack.io/data-streaming-when-is-redpanda-better-than-apache-kafka/","n":0.137}}},{"i":2331,"$":{"0":{"v":"Redisgraph","n":1},"1":{"v":"\n- #dead\n- [[c.software.database.graph.property]]\n- repo: https://github.com/RedisGraph/RedisGraph\n  ","n":0.447}}},{"i":2332,"$":{"0":{"v":"Redis","n":1}}},{"i":2333,"$":{"0":{"v":"Redaktor Vocab","n":0.707},"1":{"v":"\n- https://github.com/redaktor/vocab","n":0.707}}},{"i":2334,"$":{"0":{"v":"Recutils","n":1}}},{"i":2335,"$":{"0":{"v":"Recallgraph","n":1},"1":{"v":"\n- repo: https://github.com/RecallGraph/RecallGraph\n- written_in: javascript\n- built_on: [[prdct.arangodb]]","n":0.378}}},{"i":2336,"$":{"0":{"v":"Rebus","n":1},"1":{"v":"\n- repo: https://github.com/rebus-org/Rebus\n- similar_to: [[prdct.masstransit]]\n- supports\n  - message bus: \n\n## Cons\n\n- does not lend itself very well to the streaming nature of event brokers like NATS Streaming and Kafka – I think Topos is a better fit for that.\n\n## Questions\n\n- @dave: I'm so curious why Rebus does not lend itself to the streaming nature of some event brokers.\n\nMessaging with streams is just different from messaging with queues.\n\nQueues generally have the property that a message can be consumed by one recipient only, and then it gets ACKed (i.e. deleted from the queue). Event streams generally have the property that they can be read, sequentially, by any number of clients, all of whom simply keep track of how far they have come.\n\nWhen consuming messages from queues, you generally can't make too many assumptions about the ORDER of messages, ESPECIALLY if a message could potentially be a re-delivered message that has been sitting in a dead-letter queue for a while. OTOH when working with log-based brokers, you CAN make assumptions about ordering, as messages withing a given partition of a specific topic will be ordered.\n\nThe properties mentioned so far probably is the explanation why messages from queues tend to model isolated items of work, whereas messages in streams generally tend to be connected to their \"neighbors\" (i.e. must be consumed in the context of the stream they're in).\n\nThe APIs in Rebus are designed to be good at working with queue-based messaging, so when your message handler is invoked, there's no built-in way to know if the message is a part of a stream or to figure out the context. In fact, if processing your message takes just a tiny bit of time (or especially if it happens to await something), Rebus will most likely be processing its neighboring message concurrently. This makes the order of processing non-deterministic, which can be a great scaling trick if your messages can be handled in parallel (which they should) - but if you were working with a stream of messages, you could never have parallelism greater than the number of partitions.\n\nQueues tend to be quick to connect to - log-based brokers tend to have much more protocol associated with producing/consuming messages, because it might need to distribute partitions within topic between a number of consumers withing a consumer group.\n\nI know this wasn't a very well-structured reply 😓 but hopefully you can get an impression why there's a pretty big impedance mismatch between the queue-based and the log-based messaging worlds.\n\n## vs MassTransit\n\n- https://code-maze.com/rebus-dotnet/\n- Rebus aims to be more lightweight and easier to configure than MassTransit. It also supports some queuing systems that MassTransit does not, such as Azure Storage Queues and MSMQ, and even relational databases such as SQL Server, PostgreSQL, and MySQL.","n":0.047}}},{"i":2337,"$":{"0":{"v":"Reason Ml","n":0.707},"1":{"v":"\n- url: https://reasonml.github.io/\n- [[p.supports]] [[t.cs.languages.ocaml]]","n":0.447}}},{"i":2338,"$":{"0":{"v":"Realms Mud","n":0.707},"1":{"v":"\n- repo: https://github.com/realms-mud/core-lib\n- written-in: #c","n":0.447}}},{"i":2339,"$":{"0":{"v":"Realm Works","n":0.707},"1":{"v":"\n\n- [[p.hasApplication]] [[t.roleplaying.campaign-management]]\n","n":0.577}}},{"i":2340,"$":{"0":{"v":"Reactivex","n":1},"1":{"v":"\n- description: ReactiveX is a combination of the best ideas from\nthe Observer pattern, the Iterator pattern, and functional programming\n- [[p.hasSite]] https://reactivex.io/\n- [[p.supports]] java scala c# #c++ #clojure javascript #python #groovy #python\n\n\n## Learning Resource\n\n- https://manu.ninja/functional-reactive-game-programming-rxjs-breakout/ javascript\n- https://github.com/ibaca/rxbreakout-gwt/ java","n":0.164}}},{"i":2341,"$":{"0":{"v":"react-three-fiber","n":1},"1":{"v":"\n\n- [[p.similarTo]] [[prdct.a-frame]]\n- docs:  https://docs.pmnd.rs/react-three-fiber/getting-started/introduction\n- [[p.supports]] https://codesandbox.io/s/vfx-space-just-the-nebulae-xv9bqm?file=/src/App.js","n":0.378}}},{"i":2342,"$":{"0":{"v":"React Spring","n":0.707},"1":{"v":"\n- [[c.software.web.animation-library]]\n- url: https://www.react-spring.dev/\n\n\n## Highlights\n\n- “Animation APIs parameterized by duration and curve are fundamentally opposed to continuous, fluid interactivity.”\n  - @andy-matuschak","n":0.218}}},{"i":2343,"$":{"0":{"v":"React Map Gl","n":0.577}}},{"i":2344,"$":{"0":{"v":"React Flow","n":0.707},"1":{"v":"\n- url: https://reactflow.dev/\n- ","n":0.577}}},{"i":2345,"$":{"0":{"v":"React Ecs","n":0.707},"1":{"v":"\n- [[c.software.entity-component-system]]\n- url: https://react-ecs.ldlework.com/\n- repo: https://github.com/dustinlacewell/react-ecs","n":0.408}}},{"i":2346,"$":{"0":{"v":"RDFUnit","n":1},"1":{"v":"\n- https://github.com/AKSW/RDFUnit\n- ","n":0.707}}},{"i":2347,"$":{"0":{"v":"Rdfstore JS (dead)","n":0.577},"1":{"v":"\n- dead since 2016\n- repo: https://github.com/antoniogarrote/rdfstore-js\n![[prdct.n3-js#^gxsdwqmu5a84]]\n","n":0.408}}},{"i":2348,"$":{"0":{"v":"RDFSharp","n":1},"1":{"v":"\n- docs: file:///C:/Users/drichardson/Downloads/RDFSharp.Model-3.10.0.pdf\n- similar: [[prdct.owlsharp]]\n\n\n## Features\n\n-  support for 22 LinkedData namespaces:DC (and DCAM,DCTERMS,DCTYPE), FOAF, GEO, GEOSPARQL (and SF,GEOF), OWL, RDF, RDFS, SHACL, SKOS (and SKOSXL), SWRL (and SWRLB), TIME (and GREG,THORS), XML, XSD\n\n## Issues\n\n- doesn't seem to support JSON-LD","n":0.16}}},{"i":2349,"$":{"0":{"v":"Rdfs","n":1},"1":{"v":"\n\n- RDFS is NOT about specifying what values class instances should have, it is ONLY about classifying resources based on the values they do have.\n  - \"I recommend using domains and ranges only if you want to discover class membership of your resources based on their data. And, of course, if the environment you use the ontology in offers RDFS reasoning.\" [[ar.topquadrant.why-i-use-shacl-for-defining-ontology-models]]","n":0.127}}},{"i":2350,"$":{"0":{"v":"Rdfox","n":1},"1":{"v":"\n- https://www.oxfordsemantic.tech/rdfox\n- commercial\n- supports: [[prdct.datalog]]\n- [[c.software.reasoner]]\n- url: https://www.oxfordsemantic.tech/rdfox\n\n## Features\n\n- rule language extends [[prdct.datalog]] with non-monotonic negation-as-failure and aggregation\n\n## Resources\n\n- https://aws.amazon.com/blogs/database/use-semantic-reasoning-to-infer-new-facts-from-your-rdf-graph-by-integrating-rdfox-with-amazon-neptune/","n":0.224}}},{"i":2351,"$":{"0":{"v":"Rdflib","n":1},"1":{"v":"\n\n- written-in: python\n- docs: [[public-notes\\prdct.rdf-canonize.md]]\n\n## Features\n\n-   **Parsers & Serializers**\n    \n    -   for RDF/XML, N3, NTriples, N-Quads, Turtle, TriX, JSON-LD, HexTuples, RDFa and Microdata\n        \n-   **Store implementations**\n    \n    -   memory stores\n        \n    -   persistent, on-disk stores, using databases such as BerkeleyDB\n        \n    -   remote SPARQL endpoints\n        \n-   **Graph interface**\n    \n    -   to a single graph\n        \n    -   or to multiple Named Graphs within a dataset\n        \n-   **SPARQL 1.1 implementation**\n    \n    -   both Queries and Updates are supported","n":0.115}}},{"i":2352,"$":{"0":{"v":"Rdflib JS","n":0.707},"1":{"v":"\n- repo: https://github.com/linkeddata/rdflib.js/\n![[prdct.n3-js#^gxsdwqmu5a84]]","n":0.577}}},{"i":2353,"$":{"0":{"v":"Rdfine","n":1},"1":{"v":"\n- https://github.com/tpluscode/rdfine/tree/master/packages/core#readme\n- [[c.software.serializer]] [[c.software.semantic]]\n- repo: https://github.com/tpluscode/rdfine\n- \n\n## Features\n\n- RDFine greatly simplifies the manipulation of data in RDF graph (RDF/JS datasets) by wrapping low-level node handling of triples in plain JavaScript objects.\n- While plain JS objects are the preferred way to access the graphs, they do not completely replace the underlying RDF/JS dataset. Both RDFine objects and the dataset can be modified simultaneously, with changes to one immediately reflected in the other.\n- RDFine makes it super easy to bootstrap a triple-backed project without the need to drink up the RDF Kool-Aid. Novices will use the idiomatic JS interface to get the job done quickly, while power users still can take advantage of seamless integration with @rdfjs libraries.\n- because JavaScript [[mixins|t.cs.sd.mixin]] are used, \"multiple inheritance\" is possible","n":0.089}}},{"i":2354,"$":{"0":{"v":"Rdfa Streaming Parser JS","n":0.5},"1":{"v":"\n- https://github.com/rubensworks/rdfa-streaming-parser.js/","n":0.707}}},{"i":2355,"$":{"0":{"v":"Rdf4j","n":1},"1":{"v":"\n- https://rdf4j.org/\n- similar: [[prdct.jena]]\n- [[c.software.database.graph.rdf]]\n\n## Comparison\n\n### rdf4j vs jena\n\n- ~~\"offers SparqlBuilder which is safe, builder-pattern way of constructing a query, which has no (mature) alternative in native Apache Jena-land.~~ Jena's [QueryBuilder](https://jena.apache.org/documentation/extras/querybuilder/)\n- RDF4J has no direct equivalent to Jena's Ontology API (which contains the OntClass class). Instead, in RDF4J you always work with RDF only. Models are pure RDF graphs.\n\n## Integrations\n\n### Spring Data\n\n- [[prdct.rdf4j-spring]]\n\n\n## References\n\n- https://www.donaldmcintosh.net/blog/fuseki-commentary\n- https://www.youtube.com/watch?v=u_Hf50-3wZY\n- https://rdf4j.org/documentation/programming/spring/","n":0.122}}},{"i":2356,"$":{"0":{"v":"rdf4j Workbench","n":0.707},"1":{"v":"\n- works-with: [[prdct.aws.neptune]]\n\n![](/assets/images/2024-10-17-12-06-02.png)\n\n## References\n\n- https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-sparql-rdf4j-workbench.html","n":0.447}}},{"i":2357,"$":{"0":{"v":"Rdf4j Spring","n":0.707},"1":{"v":"\n- dead since 2021\n- repo: https://github.com/CarbonLDP/rdf4j-spring\n- docs: https://rdf4j.org/documentation/programming/spring/","n":0.354}}},{"i":2358,"$":{"0":{"v":"Rdf3x","n":1},"1":{"v":"\n- repo: https://gitlab.db.in.tum.de/dbtools/rdf3x\n- ","n":0.577}}},{"i":2359,"$":{"0":{"v":"Rdf2vec","n":1},"1":{"v":"\n- http://rdf2vec.org/\n\n## Resources\n\n- [[book.embedding-knowledge-graphs-with-rd-f2vec]]\n\n\n## References\n\n- ","n":0.447}}},{"i":2360,"$":{"0":{"v":"Rdf2dot","n":1},"1":{"v":"\n- https://github.com/giacomociti/rdf2dot\n- [[c.software.visualization.semantic]]","n":0.577}}},{"i":2361,"$":{"0":{"v":"RDF","n":1},"1":{"v":"\n- related: [[prdct.rdf-processing-toolkit]] [[prdct.spin]]\n- [[p.instanceOf]] [[c.specification]]\n\n## Features\n\n- \"has the aesthetics of steampunk, of some technology for some futuristic Semantic Web1 in a toolset that feels about as lightweight and modern as iron dreadnought.\"\n\n### Properties\n\n- Properties are used for specifying information about entities like :Polar_Bear or :Knut. \n  - Datatype properties like :birthDate or :population relate to literal values like strings, numbers or dates\n  - Object properties like conservation_status relate to other entities\n\n### Objects\n\n- can be either\n  - literal values\n  - [ ] individuals? entity objects? need a better name here\n\n### Blank Nodes\n\n- Blank (or anonymous) nodes are RDF resources with identifiers that exist only locally. In other words, their identifiers are not URLs. They are sometimes also called anonymous nodes. They make life easier for data producers, who can easily create (nested) resources without having to mint all the URLs. In most non-RDF data models, blank nodes are the default. For example, we nest JSON object without thinking twice.\n- @chatgpt.4: \"While you can avoid using blank nodes, it often results in more verbose RDF graphs and might require additional effort to manage URIs for entities that do not need global identification. If your use case involves a lot of ephemeral, intermediary, or context-specific data, blank nodes can be very useful. However, for datasets that require high interoperability and ease of querying, minimizing the use of blank nodes and favoring URIs might be beneficial.\"\n\n## Namespaces\n\n### Namespace Prefixes\n\n- \"The XML Namespaces specification (Namespaces in XML 1.0) states that a prefix must be a valid XML name, which means it must conform to the following constraints:\n\n- It must start with a letter or underscore (_).\n- It cannot start with a number.\n- Subsequent characters can be letters, digits, hyphens (-), underscores (_), or periods (.).\"\n\n## Datasets\n\n- An RDF dataset is a collection of RDF graphs, and comprises:\n\n  - Exactly one default graph, being an RDF graph. The default graph does not have a name and MAY be empty.\n  - Zero or more named graphs. Each named graph is a pair consisting of an IRI or a blank node (the graph name), and an RDF graph. Graph names are unique within an RDF dataset.\n- \"We informally use the term RDF source to refer to a persistent yet mutable source or container of RDF graphs.\"\n\n### Dataset Thoughts\n\n- [-] [[p.summarized]] [RDF datasets](https://www.w3.org/TR/rdf11-datasets/)\n  - the concept of the \"unnamed default graph\"/master-graph is interesting; \n    - resources:  [The unnamed/default graph should have a standard name](https://github.com/w3c/sparql-12/issues/43)\n\n## Typed Literals\n\n- RDF does not place any limits on what datatypes might be associated with a literal. The model recommends using a standard type library, like XML Schema, wherever possible but the only real constraint is that datatypes should be identified by a URI. Creating a new URI for an application or domain specific datatype allows the type system to be easily extended. The datatype URI can be annotated with additional RDF statements, e.g. a label or description, to describe its usage.\n- The key limitation to custom datatypes is that SPARQL query engines will not understand how to compare values of that type. Some SPARQL query processors may provide support for understanding the range of types it understands.\n- Note that a typed literal with a custom datatype can also be modelled as a sub-property.\n  - Advantages\n    - Simpler querying of data by allowing the use of triple patterns, rather than FILTERs for extracting data of a common type.\n    - More explicit, fine-grained semantics\n  - Disadvantages\n    - Increases the number of very similar properties, requiring redundancy of data or reasoning to allow applications to treat them generically\n    - Doesn't address the core requirement to indicate the lexical form of a structured value\n- Recommendation:\n  - Use a custom datatype to label particular types of structured value that share a common lexical form. These values may be associated with a broad range of different properties. Processing applications may want to implement a common set of type conversions or display options for the values.\n  - Use a sub-property in all other cases\n  - Note that these options aren't always mutually exclusive. It might be useful in some scenarios to have an explicit property for associating a general class of code, identifier, or other Literal Key with a resource, but also assign a specific datatype to the identifier as a cue for applications and reasoners\n\n## Highlights\n\n- the property \"a\" is used to indicate the \"type\" or \"class\" of a resource. It is a shorthand notation for the \"rdf:type\" predicate.\n\n\n## Issues\n\n- \"RDF is a shitty data model. It doesn’t have native support for lists.\"\n\n### n-ary relations\n\n- aka [[t.cs.semantic-web.relationship-to-entity-conversion]]\n  - although you can also express multiple \"arguments\" as a list, see http://www.ninebynine.org/RDFNotes/RDFFactsAndRules.html#xtocid-75600719\n- sure you can use a class per relation, but...\n- \"Considerations when introducing a new class for a relation\n\n    - In our example, we did not give meaningful names to instances of properties or to the classes used to represent instances of n-ary relations, but merely label them _:Temperature_Observation_1, Purchase_1, etc. In most cases, these individuals do not stand on their own but merely function as auxiliaries to group together other objects. Hence a distinguishing name serves no purpose. Note that a similar approach is taken when reifying statements in RDF.\n    \n    - Creating a class to represent an n-ary relation limits the use of many OWL constructs and creates a maintenance problem. The problem arises when we want to have local range or cardinality restrictions on some role in the n-ary relation that depend on the class of some other role. For example, we might want to say that we buy only instances of a class Book from companies in the category Bookseller (cf. use case 3). Expressing this constraint requires a special subclass of the n-ary relation class that represents the combination of restrictions. For instance, we will have to create a class Book_Purchase with the corresponding range restrictions for the property seller (allValuesFrom Bookseller) and object (allValuesFrom Book). We end up having to build an explicit lattice of classes to represent all the possible combinations.   \n    \n      - OWL allows definition of inverse properties. Defining inverse properties with n-ary relations, using any of the patterns above, requires more work than with binary relations. In order to specify inverse properties for n-ary relations, we must specify an inverse for each of the properties participating in the n-ary relation (with the proper constraints). Consider the example of John buying the Lenny_The_Lion book. We may want to have an instance of an inverse relation pointing from the Lenny_The_Lion book to the person who bought it. If we had a simple binary relation John buys Lenny_The_Lion, defining an inverse is simple: we simply define a property is_bought_by as an inverse of buys:\n\n    :is_bought_by\n          a       owl:ObjectProperty ;\n          owl:inverseOf :buys .\n\n    With the purchase relation represented as an instance, however, we need to add inverse relations between participants in the relation and the instance relation itself:\"\n\n- t.2024.06.10.22 \"Moreover, the use of cardinality re-\nstrictions becomes limiting on some roles that depend on the class of some other roles\"\n\n\n### Ordering\n\n- [ordering](https://ontola.io/blog/ordered-data-in-rdf), although maybe [[prdct.hydra]] collections could help\n\n### Other Issues\n\n- contrary to [some claims](https://www.ontotext.com/knowledgehub/fundamentals/what-is-rdf/), RDF and OWL are not fluent, at least compared to GraphDown\n- calls verbs properties / predicates\n- confuses properties and predicates\n- can't easily express intransitive relations (properties)\n- [[Resources That Refer Vs Resources That Are|vs.resources-that-refer-vs-resources-that-are]] \n  - aka \"indicator vs subject\"\n- [punning](https://www.w3.org/2007/OWL/wiki/Punning): also a solution\n  - @chatgpt.4: \n    - **Class-Individual Punning**: This is where the same URI is used to denote a class in one context and an individual in another. For example, you might have a class `:Person` and also use `:Person` as an individual to represent the generic concept of a person. In RDF and OWL, this is legal because classes in OWL are also individuals in the sense of RDF.\n      - t.2024.05.24.11 see [[vs.class-vs-individual]]\n    - **Class-Property Punning**: Similarly, the same URI can be used to denote a class in one context and a property in another. This can be useful for modeling certain kinds of relationships in a more flexible way.\n- Class vs Individual\n  - see [[book.semantic-modeling-for-data#class-or-individual]]\n  - \n\n### temporal problems\n\n- see [[ar.a-temporal-rdf-model-for-multi-grained-time-information-modeling]]\n- https://blog.iandavis.com/2009/08/representing-time-in-rdf-part-1/\n- [Temporal RDF](http://www.dcc.uchile.cl/~cgutierr/papers/temporalRDF.pdf) introduces a fourth time component to the triple. \"I chose not to cover this approach in a lot of detail because it extends the RDF model in a way that no current triple store implements\"\n\n### Ordering\n\nThere are no arrays in RDF, and don't use the order in which serialized triples appear.\n\nRDF Containers:\n\n- Come in three forms: rdf:Seq (ordered), rdf:Bag (unordered), rdf:Alt (alternatives with default)\n- You can add new items by simply adding RDF triples\n- Inserting items is hard: requires rewriting many statements\n- Must be stored in a single graph / machine / server (centralized)\n- Have a formally unknown ending (open world assumption)\n\nRDF Collections:\n\n- An ordered chain of rdf:List resources\n- You have to edit / remove statements before you can add new items\n- Inserting items is easy: requires changing just a few statements\n- Can span many graphs / machines / servers (decentralized)\n- Have a known ending (the rdf:nil)\n  \nPagination:\n\n- Use ActivityStreams collections\n\nConverting to arrays:\n\n- Use a library, such as @rdfdev/collections\n\n\n## Abstract Model\n\n\n### 1.5 RDF and Change over Time\n\nThe RDF data model is atemporal: RDF graphs are static snapshots of information.\n\nHowever, RDF graphs can express information about events and about temporal aspects of other entities, given appropriate vocabulary terms.\n\nSince RDF graphs are defined as mathematical sets, adding or removing triples from an RDF graph yields a different RDF graph.\n\nWe informally use the term RDF source to refer to a persistent yet mutable source or container of RDF graphs. An RDF source is a resource that may be said to have a state that can change over time. A snapshot of the state can be expressed as an RDF graph. For example, any web document that has an RDF-bearing representation may be considered an RDF source. Like all resources, RDF sources may be named with IRIs and therefore described in other RDF graphs.\n\nIntuitively speaking, changes in the universe of discourse can be reflected in the following ways:\n\n  - An IRI, once minted, should never change its intended referent. (See URI persistence [WEBARCH].)\n  - Literals, by design, are constants and never change their value.\n  - A relationship that holds between two resources at one time may not hold at another time.\n  - RDF sources may change their state over time. That is, they may provide different RDF graphs at different times.\n  - Some RDF sources may, however, be immutable snapshots of another RDF source, archiving its state at some point in time.\n\n## History\n\n- [[ar.the-rdf-net-challenge]]\n\n\n## can be expressed as \n\n- [[prdct.rdf.aref]]\n- [[prdct.rdf.turtle]]\n- [[prdct.hextuples]]\n- [[prdct.JSON-LD]]\n\n## Solutions\n\n- [[prdct.rdfsharp]]\n- [[prdct.bitrdf]]\n\n## Resources\n\n- https://www.w3.org/TR/rdf11-datasets/\n  - [[p.begsQuestion]] [-] What is [[the difference betwee the union of the graphs and their merge|tasks.rdf.the-difference-betwee-the-union-of-the-graphs-and-their-merge]]? Is the distinction meaningful for [[prdct.dendron]]?\n- https://www.w3.org/TR/rdf-concepts\n- https://www.w3.org/TR/rdf-schema/\n- [Predefined Namespace Prefixes](https://www.orpha.net/sparql?nsdecl)\n- https://ontola.io/blog/rdf-serialization-formats\n  - mentions [[prdct.json-ad]]\n\n### [[p.hasLearningResource]]\n\n- https://www.w3.org/TR/rdf11-primer/\n- https://open.hpi.de/\n\n### [[p.hasWishList]]\n\n- https://lists.w3.org/Archives/Public/semantic-web/2009Nov/0040.html\n\n## References\n\n- https://patterns.dataincubator.org/book/custom-datatype.html\n- https://www.w3.org/TR/swbp-n-aryRelations/\n- https://cran.r-project.org/web/packages/rdflib/vignettes/rdf_intro.html","n":0.024}}},{"i":2362,"$":{"0":{"v":"RDF/XML","n":1},"1":{"v":"\n- fast for Virtuoso, Blazegraph or Stardog, but RDF/XML is not suitable for streaming.\n\n## References\n\n- [[ar.medium.comparing-linked-data-triplestores]]","n":0.25}}},{"i":2363,"$":{"0":{"v":"RDF Turtle","n":0.707},"1":{"v":"\n\n\n- [[p.hasSpecification]] https://www.w3.org/TR/turtle/\n\n\n## Pros\n\n-   **Turtle is the Language of the Semantic Web.** There have been, over the years, a fair number of different representations of semantics, some very minimal (n3), some tied into the rdfs model (XML-RDF), some using different functional representations such as Manchester notation. Yet none of them have achieved the adoption of Turtle within this space by those who have focused on using RDF as a descriptive framework.\n-   **Turtle Underlies SPARQL, SHACL and other languages.** The Turtle language informed the shape of SPARQL, SHACL and many other RDF stack languages, and as such has become something of a unifying linguistic design.\n-   **Turtle is Human Readable.** In so far as any data serialization format is human readable while at the same time being terse (indeed, it is more compact than JSON while simultaneously being more precise). It should be noted that the Terseness of JSON vs. XML was one of the primary reasons that developers walked away from the XML toolset in favor of JSON. However Turtle is even terser, while still being able to be more expressive than the JSON language.\n-   **Turtle Is A True Streaming Language.** JSON ironically suffers much the same issue with regard to streaming that XML does – when you transport JSON, before you can do anything with it you have to reparse it. If the JSON structure is larger, you have to wait until you reach a nature breakpoint (the end of an array or object definition). Turtle, on the other hand, is normalized, which means that the functional parsing boundary for Turtle typically is far smaller than it is for JSON. This in turn translates into the ability to load content into the database considerably faster, and in many cases to perform validation against _existing_ data, meaning that Turtle is a natural language for master data management.\n-   **RDF automatically deduplicates.** JSON, because it is a denormalized structure, implicitly requires that duplication exists. RDF in general and Turtle in particular, are representations of content that will end up in a triple store index, and the index need only make an assertion about a given statement once. This makes queries very fast, considerably faster than can be achieved with JSON, especially when powered by Graph Processing Units (GPUs) for parallel processing. JSON gains no real advantage when parallel processing is involved.\n-   **Turtle is unambiguous, JSON is not.** JSON-LD emerged as a standard to work with the semantic web, but it currently has four different profiles, is surprisingly difficult to write well for larger data structures, and as often as not is rejected primarily because it fails to conform to any of the profiles. Turtle has two profiles that have very clear syntax (Turtle and Turtle-Star), with Turtle-star being only slightly less clear because of a few edge cases that haven’t been fully resolved. Additionally, when people refer to Turtle, they are usually actually talking about TRIG, which extends the turtle language to incorporate named graphs (TRIG is backwards compatible with Turtle).\n-   **Semantics Matter.** JSON requires local knowledge to be useful. Turtle does not, because there are in general enough core conventions in place (RDF, RDFS and perhaps minimal OWL) that meaning can be extracted very quickly through the application of known rules, even without deep contextual knowledge. Because Turtle is built around namespaces, those namespaces can also provide additional bootstrapped metadata to achieve semantic awareness in the data, while JSON requires manual intervention to provide a pale copy of this capability.\n-   **Turtle represents complex structures better than JSON.** While the Turtle breakdown in the previous section shows a normalized structure, a Turtle parser could reconstruct a fully denormalized Javascript or Python object or JSON document in any number of ways, depending upon what kind of structure is desired. Both Python and Javascript have libraries for parsing Turtle as well (check out FrogCat’s ttl2jsonld at [https://github.com/frogcat/ttl2jsonld](https://github.com/frogcat/ttl2jsonld) for just one of many examples). It is this dual nature of RDF – as data documents and normalized data records – that makes RDF so compelling as services become more declarative and end up with less intervention on the part of programmers.\n\n## Cons\n\n- no support for quads/named graphs \n\n## References\n\n- https://www.datasciencecentral.com/why-json-users-should-learn-turtle/\n- https://www.datasciencecentral.com/why-graphql-will-rewrite-the-semantic-web/","n":0.038}}},{"i":2364,"$":{"0":{"v":"Trig","n":1},"1":{"v":"\n- https://www.w3.org/TR/trig/\n\n## Description\n\n- A TriG document allows writing down an RDF Dataset in a compact textual form. It consists of a sequence of directives, triple statements, graph statements which contain triple-generating statements and optional blank lines. \n- Graph statements are a pair of an IRI or blank node label and a group of triple statements surrounded by {}. The IRI or blank node label of the graph statement may be used in another graph statement which implies taking the union of the tripes generated by each graph statement. An IRI or blank node label used as a graph label may also reoccur as part of any triple statement. Optionally a graph statement may not not be labeled with an IRI. Such a graph statement corresponds to the Default Graph of an RDF Dataset.\n\n## References\n\nhttps://www.w3.org/TR/rdf11-concepts/","n":0.086}}},{"i":2365,"$":{"0":{"v":"Rtc","n":1},"1":{"v":"\n\n## [[p.provokedThoughts]]\n- [[c.specification]] https://rtc-org.github.io/spec/\n\n- [[gd]] could use something like this, for grouping together lines to say something about them! ^uphgyk5m6aay","n":0.224}}},{"i":2366,"$":{"0":{"v":"RDFa","n":1},"1":{"v":"\n## Description\n\n- RDFa is a way to embed triples into an HTML document. It can be confusing for beginners, but some software tools generate valid RDFa which is fine, but don't try to create it by hand until you get some experience!\n\n- To decode RDFa in an HTML page, just put the URL into http://graphite.ecs.soton.ac.uk/browser/ \n\n## Examples\n\n```html\n<div about=\"/alice/posts/trouble_with_bob\">\n    <h2 property=\"dc:title\">The trouble with Bob</h2>\n    <h3 property=\"dc:creator\">Alice</h3>\n    ...\n</div>\n```\n\n## Questions\n\n- is <a href> the only way to specify a object resource\n\n```html\n<div about=\"http://dbpedia.org/resource/Albert_Einstein\">\n  <span property=\"foaf:name\">Albert Einstein</span>\n  <span property=\"dbp:dateOfBirth\" datatype=\"xsd:date\">1879-03-14</span>\n  <div rel=\"dbp:birthPlace\" resource=\"http://dbpedia.org/resource/German_Empire\">\n    <span property=\"dbp:conventionalLongName\">the German Empire</span>\n    <span rel=\"dbp-owl:capital\" resource=\"http://dbpedia.org/resource/Berlin\" />\n  </div>\n</div>\n```\n\n## Cons\n\n-   adding inline semantic markup to existing web pages can be tricky and time-consuming when it is necessary to understand the existing page structure and the hierarchical nesting of various `<div>` and `<span>` elements - and care must be taken to check that the RDF triples that can be extracted from the page are as intended, without mis-connected nodes or dangling nodes. Sometimes it is necessary to re-assert the `Subject` of a set of RDF triples using the about attribute.\n-   inline semantic markup can break very easily if further HTML edits are made to a semantically annotated page, without involving the semantic annotator in the discussion. A simple example of this is that the person adding the inline semantic annotations might use an attribute such as `property=\"schema:image\"` or `itemprop=\"schema:image\"` to indicate that a specific image on the page is a depiction of the `Subject`. Now if someone else wraps an `<a href>` hyperlink around the annotated image, then the image is then considered to be a `schema:image` property of the thing identified by the URL of the new hyperlink, rather than the `schema:image` of the original `Subject`. The original triple can be restored by inserting an `about` attribute within the `<img>` image tag - but it seems undesirable that this kind of defensive coding must be used merely to ensure that another web editor cannot easily break the RDF triples that were originally intended to be present.\n  - t.2024.10.03.21 you could get around this issue but not saying anything about any other resources\n  - ensure machine-only modification could help too. \n  - compare \"single block markup using [[prdct.JSON-LD]]\": \n    - the single block of JSON-LD markup is decoupled from the human-readable HTML markup appearing in the <body> of the page, which means that if changes are made to the structure of the <body> section, there is much less risk of breaking or misconnecting the collection of RDF triples that can be extracted from the page.\n\n## Libriaries\n\n- [[prdct.rdfa-streaming-parser-js]]\n\n## Resources\n\n- https://www.w3.org/2006/07/SWD/RDFa/primer/\n\n## References\n\n- [[ar.linked-data-basics-for-techies]]","n":0.048}}},{"i":2367,"$":{"0":{"v":"Rdf Mapping Language","n":0.577},"1":{"v":"\n\n[[p.hasLearningResource]] https://rml.io/docs/rml/introduction/\n","n":0.707}}},{"i":2368,"$":{"0":{"v":"N3","n":1},"1":{"v":"\n\n## vs Trig\n\n- N3 is not directly compatible with [[prdct.rdf.trig]] as it does not support [the trig] graph statement notation.\n- Nevertheless, since N3 supports graph terms as part of regular N3 statements, authors can use the N3 Named Graphs extension; this extension allows associating names or identifiers with graph terms.\n\n\n## References\n\n- https://w3c.github.io/N3/spec/","n":0.139}}},{"i":2369,"$":{"0":{"v":"N3 Named Graphs Extension","n":0.5},"1":{"v":"\n- dead?\n- repo: https://github.com/IDLabResearch/N3NamedGraphSemantics","n":0.5}}},{"i":2370,"$":{"0":{"v":"Datasets","n":1},"1":{"v":"\n- \"it is sometimes desirable to work with multiple RDF graphs while keeping their contents separate. RDF datasets support this requirement.\"\n\n- \"We informally use the term RDF source to refer to a persistent yet mutable source or container of RDF graphs. An RDF source is a resource that may be said to have a state that can change over time. A snapshot of the state can be expressed as an RDF graph. For example, any web document that has an RDF-bearing representation may be considered an RDF source. Like all resources, RDF sources may be named with IRIs and therefore described in other RDF graphs.\"\n\n- \"An RDF dataset is a collection of RDF graphs. All but one of these graphs have an associated IRI or blank node. They are called named graphs, and the IRI or blank node is called the graph name. The remaining graph does not have an associated IRI, and is called the default graph of the RDF dataset.\"\n\n- \"There are many possible uses for RDF datasets. One such use is to hold snapshots of multiple RDF sources.\"\n\n- \"An RDF document is a document that encodes an RDF graph or RDF dataset in a concrete RDF syntax, such as Turtle\"\n\n\n## Issues\n\n- [ ] Dataset iris are different? Are they closed? \n\n## Terms\n\n- **[dataset series](https://www.w3.org/TR/vocab-dcat-3/#dataset-series)**: data, somehow interrelated, that are published separately\n  - analogous to ontology series\n\n## Example\n\n```turtle\n@prefix ex: <http://example.org/> .\n\n# Default graph\n{\n  ex:subject1 ex:predicate1 ex:object1 .\n}\n\n# Named graph\nex:graph1 {\n  ex:subject2 ex:predicate2 ex:object2 .\n}\n\nex:graph2 {\n  ex:subject3 ex:predicate3 ex:object3 .\n}\n```\n\n## References\n\n- https://www.ateam-oracle.com/post/rdf-datasets-named-and-default-graphs-concepts-and-how-to-query-them\n- https://www.w3.org/TR/rdf11-concepts/","n":0.063}}},{"i":2371,"$":{"0":{"v":"Containers Vs Collections","n":0.577},"1":{"v":"\n## References\n\n","n":0.707}}},{"i":2372,"$":{"0":{"v":"aREF","n":1},"1":{"v":"\n\n\n\n\n- [[p.hasSpecification]] https://gbv.github.io/aREF/aREF.html\n- [[p.hasAuthor]] @jakob-voss\n","n":0.447}}},{"i":2373,"$":{"0":{"v":"Rdf Urdna","n":0.707},"1":{"v":"\n- https://github.com/setl/rdf-urdna\n\n## Issues\n\n- [vastly different claims but have absolutely identical digital signatures.](https://github.com/setl/rdf-urdna/tree/master/jsonld-warnings)","n":0.289}}},{"i":2374,"$":{"0":{"v":"Rdf Triple Compounds","n":0.577}}},{"i":2375,"$":{"0":{"v":"Rdf Toolkit","n":0.707},"1":{"v":"\n- repo: https://github.com/edmcouncil/rdf-toolkit\n- [[c.software.semantic]]\n- written-in: java\n\n\n## Rationale\n\n### Minimize the ontology review effort\n\nFor the purposes of git-based version control of ontology files, we want to have as few differences between commits as possible. Most ontology editors can encode RDF graphs, including OWL ontologies, in several formats, including the W3C normative RDF exchange formats (syntaxes): RDF/XML and Turtle. However, even these normative formats are not canonical. Therefore, an editor tool may change many aspects of how ontology entities are serialized every time the ontology is saved (such as adding/changing comments or changing the order and organization of statements) leading to difficulties in analyzing actual changes in the underlying semantics.\n\n### Handle intelligent IRIs\n\nWe want to be able to include actionable information as part of IRIs, e.g., git tags, and then deference them from ontology tools like Protege.\n\n### Recommended output format\n\nThe recommended output format at this time is RDF/XML because that is the format that the OMG requires for submissions. The EDM Council develops the FIBO Ontologies and submits them as RDF/XML, serialized by the RDF Toolkit to the OMG. So that is why we also use RDF/XML in Github itself.","n":0.073}}},{"i":2376,"$":{"0":{"v":"Rdf Thrift","n":0.707},"1":{"v":"\n- https://afs.github.io/rdf-thrift/\n\n## Implementations\n\n- [[prdct.jena]] via https://jena.apache.org/documentation/io/rdf-binary.html","n":0.408}}},{"i":2377,"$":{"0":{"v":"Rdf Surveyor","n":0.707},"1":{"v":"\n- dead since 2021\n- repo: https://github.com/guiveg/rdfsurveyor","n":0.408}}},{"i":2378,"$":{"0":{"v":"Rdf Shape","n":0.707},"1":{"v":"\n- https://rdfshape.weso.es/\n- [[c.software.visualization.semantic]]\n- similar: [[prdct.zazuko-rdf-sketch]] [[prdct.rdf2dot]]\n\n## Features\n\n- RDF conversion between different formats like Turtle and JSON-LD\n- RDF validation using ShEx (Shape Expressions) and SHACL (Shapes Constraint Language)\n- RDF querying with SPARQL\n- RDFS and OWL inference\n\n\n## References\n\n- https://www.bobdc.com/blog/visualizing-rdf/","n":0.164}}},{"i":2379,"$":{"0":{"v":"Rdf Pub","n":0.707},"1":{"v":"\n- https://rdfpub.org/\n- [[c.software.semantic.activity-pub]]\n- repo: https://gitlab.com/linkedopenactors/rdf-pub\n- implements: [[prdct.activitypub]]","n":0.378}}},{"i":2380,"$":{"0":{"v":"Rdf Processing Toolkit","n":0.577},"1":{"v":"\n- repo: https://github.com/SmartDataAnalytics/RdfProcessingToolkit","n":0.577}}},{"i":2381,"$":{"0":{"v":"Rdf JS","n":0.707},"1":{"v":"\n- https://rdf.js.org/\n\n## Solutions\n\n- [[prdct.m-ld]]\n\n## References\n\n- https://rdf.js.org/stream-spec/","n":0.408}}},{"i":2382,"$":{"0":{"v":"Shex","n":1},"1":{"v":"\n\n- https://rdfjs.dev/shex\n- spec: http://shexspec.github.io/primer/ShExJ#schema\n- similar: [[prdct.rdf-js.shex]] [[prdct.shacl]] [[prdct.spin]]  ^1vgrpmk2ihl1\n\n## Introduction\n\nShEx describes RDF graph [RDF11-CONCEPTS] structures as sets of potentially connected Shapes. These constrain the triples involving nodes in an RDF graph. Node Constraints constrain RDF nodes by constraining their node kind (IRI, blank node or Literal), enumerating permissible values in value sets, specifying their datatype, and constraining value ranges of Literals. Additionally, they constrain lexical forms of Literals, IRIs and labeled blank nodes.\n\n## Notation\n\nThe ShExJ structure is a sublanguage of JSON. consists of lists and maps of typed objects and values. These are represented as definitions in the following grammar. The content of some constructs involve many choices. These are represented as declarations.\n\n    typeName - a JSON object with a type property with the value \"typeName\" and the attributes listed to the right of the \":\"\n    Each attribute is followed by a \":\" identifying its type. \"[typeName]\" identifies a list of objects with a type \"typeName\". \"[type1->type2] identifies a map from type1 to type2.\n    declName - a hierarchical representation of choices in the grammar similar to BNF. Declarations don't directly produce JSON objects; instead they capture the possible choices of defined objects or terminals.\n\n## Comparison\n\n### ShEx vs SHACL\n\n- ShEx has the operators | to represent “oneOf” while SHACL has xone to represent exactly one.\n- ShEx has been implemented in a variety of programming languages and RDF libraries: Apache Jena, Ruby, Javascript, Haskell, and Python (see section 4.3). In the case of SHACL, most implementations are based on Apache Jena and there is an implementation based on Javascript (see section 5.2) although there are some implementations appearing in other systems like rdf4j. Most ShEx implementations are non-commercial and have been developed mainly by individual projects. SHACL has a mature commercial implementation, bundled with the TopBraid suite of products, which offers a rich user interface for editing SHACL-based data models. Although TopBraid is a commercial product, SHACL’s implementation is based on a separate open source library maintained by TopQuadrant. SHACL is also integrated in the free edition of TopBraid Composer.\n\n#### Schema vs Constraints\n\n- The designers of ShEx intended the language to be like a grammar or schema for RDF graphs. This design was inspired by languages such as Yacc, RelaxNG, and XML Schema. The main goal was to describe RDF graph structures so they could be validated against those descriptions.\n\nIn contrast, the designers of SHACL aimed at providing a constraint language for RDF. The main goal of SHACL is to verify that a given RDF graph satisfies a collection of constraints. In this sense, SHACL follows the Schematron approach, applied to RDF: it declares constraints that RDF graphs must fulfill. Just as Schematron relies strongly on XPath, SHACL relies strongly on SPARQL\n\n\n\n## References\n\n- https://book.validatingrdf.com/bookHtml013.html","n":0.047}}},{"i":2383,"$":{"0":{"v":"RDF-Ext","n":1},"1":{"v":"\n- https://rdf-ext.org/\n- related: [[prdct.grapoi]] \n\n## Scope\n\nThe scope of this project is to provide a flexible standard developer kit based on the RDF/JS specification for working with RDF data in various environments. The primary focus is on supporting Node.js and browsers, but it's also designed to work with other JavaScript runtimes. Features are implemented in a modular fashion. Individual libraries can be used without the core RDF-Ext library together with other standard RDF/JS libraries. The following use cases are covered:\n\n-   Parse and serialize RDF standard formats such as Turtle, N-Triples, and JSON-LD.\n-   Read and write RDF data:\n    -   File system: Load and save RDF data from files and handle file and folder structures representing Named Graphs.\n    -   SPARQL: Handle requests and parse results.\n    -   SPARQL Graph Store: Handle requests, parse, and serialize RDF data.\n    -   HTTP: Send and receive RDF data over plain HTTP and handle parsing and serialization.\n-   Validation:\n    -   SHACL: An extendable SHACL engine is provided.\n-   Fluent interface traversing: Traverse and manipulate RDF data using a fluent interface.\n-   Object RDF Mapper (ORM): Read and manipulate RDF data using object-oriented programming techniques.\n-   Frontend: Generic components for showing and editing RDF data.\n    -   Tables for triples and resources: The toolset includes components for displaying RDF data in tables, making it easy to visualize and work with RDF data in a tabular format.\n    -   Network diagram: The toolset includes a component for displaying RDF data as a network diagram, making it easy to visualize the relationships between different resources in the data.\n\nOverall, RDF-Ext aims to provide all features one would expect from an RDF SDK for JavaScript.","n":0.061}}},{"i":2384,"$":{"0":{"v":"Rdf Ex","n":0.707},"1":{"v":"\n- https://rdf-elixir.dev/rdf-ex/\n- related: [[prdct.sparql-ex]]","n":0.5}}},{"i":2385,"$":{"0":{"v":"Rdf Edtf","n":0.707},"1":{"v":"\n- dead\n- https://github.com/no-reply/rdf-edtf\n- written-in: ruby","n":0.447}}},{"i":2386,"$":{"0":{"v":"Rdf Delta","n":0.707},"1":{"v":"\n- https://afs.github.io/rdf-delta/\n- different-from: [[ar.delta-an-ontology-for-the-distribution-of-differences-between-rdf-graphs]]\n- supports: [[prdct.rdf-thrift]]\n\n## Summary\n\n- RDF patch is a format for recording changes to an RDF Dataset\n- an evolution of the original RDF Patch described in https://afs.github.io/rdf-delta/rdf-patch.html\n- Abort, TA is provided so that changes can be streamed, not obliging the application to buffer change and wait to confirm the action is committed.\n\n### Two aspects\n\nDistributing changes to a dataset has two aspects: the format used to record changes and the mechanism used to propagate changes.\n\nRDF Delta provides these into two parts:\n\n    RDF Patch - a format to record changes that is easy to generate and consume.\n    RDF Patch Logs - a protocol for distributing change files.\n\n## Issues\n\n- There is only a single copy of the patch store and any file storage may be lost so it is better to highly reliable file system where possible.\n  - The patch store can be backed up by backing up the PatchStore directory when the server is not in-use.\n\n## References\n\n","n":0.08}}},{"i":2387,"$":{"0":{"v":"rdf-canonize","n":1},"1":{"v":"\n- https://github.com/digitalbazaar/rdf-canonize\n- written-in: javascript\n\n## Features\n\n- See the [RDF Dataset Canonicalization](https://w3c.github.io/rdf-canon/spec/) specification for details on the specification and algorithm this library implements.","n":0.218}}},{"i":2388,"$":{"0":{"v":"Rdf and Sparql extension","n":0.5},"1":{"v":"\n- https://plugins.jetbrains.com/plugin/13838-rdf-and-sparql\n- https://rdfandsparql.com/\n- published-by: [[org.sharedvocabs]]\n- [[c.software.ide.extension.jetbrains]]\n\n## Features\n\n- query local RDF files with SPARQL\n- ","n":0.277}}},{"i":2389,"$":{"0":{"v":"Rdb Model","n":0.707},"1":{"v":"\n- repo: \n- url: https://rdbmodel.github.io/\n- #demo https://rdbmodel.github.io/#/editor/main\n- [[p.provokedThoughts]] it's a web-app only, no source available?","n":0.258}}},{"i":2390,"$":{"0":{"v":"Rcc8","n":1},"1":{"v":"\n- 8 basic relations possible between two regions:\n  -   disconnected (DC)\n  -   externally connected (EC)\n  -   equal (EQ)\n  -   partially overlapping (PO)\n  -   tangential proper part (TPP)\n  -   tangential proper part inverse (TPPi)\n  -   non-tangential proper part (NTPP)\n  -   non-tangential proper part inverse (NTPPi)\n\n![](/assets/images/2024-03-14-10-20-27.png)","n":0.151}}},{"i":2391,"$":{"0":{"v":"Ravendb","n":1},"1":{"v":"\n- [[c.comparison]] https://ravendb.net/comparison\n\n## Cons\n\n- doesn't scale to zero, although AWS free tier eligible\n  - $0.01/hr is reasonable tho (dev tier), data to internet is $0.10/GB\n\n## Resources\n\n- https://ravendb.net/articles/cqrs-and-event-sourcing-made-easy-with-ravendb","n":0.192}}},{"i":2392,"$":{"0":{"v":"Rational Rhapsody","n":0.707}}},{"i":2393,"$":{"0":{"v":"Rascal","n":1},"1":{"v":"\n- [[p.supports]] [[prdct.vscode]]\n- [[c.software.language-workbench]]\n- ","n":0.5}}},{"i":2394,"$":{"0":{"v":"Rapidclipse","n":1},"1":{"v":"\n- url: https://rapidclipse.com/en/\n- built-on: [[prdct.eclipsestore-microstream]]","n":0.447}}},{"i":2395,"$":{"0":{"v":"Ranvier","n":1},"1":{"v":"\n- [[c.software.game-platform.multi-user-dungeon]]\n- repo: https://github.com/RanvierMUD/ranviermud\n- url: https://ranviermud.com/","n":0.408}}},{"i":2396,"$":{"0":{"v":"RAML","n":1},"1":{"v":"\n- [[c.software.tools.design.api]]\n- related: [[prdct.aml]] [[prdct.amf]]\n\n## Comparison\n\n### vs [[prdct.oas]]\n\n- Although RAML was \"created with REST APIs in mind, it’s flexible enough that it can be used to model other architectural styles, including RPC and even GraphQL.\"\n- Although RAML focuses on modeling APIs and OAS on describing them, the truth is that either format can be used for either purpose\n- \"“If I had to pick one aspect in which RAML excels, I would say it is the ”re-usability“ aspect. RAML ships with its own type system that helps model data structures using features like inheritance and even multiple inheritance, which helps make schema and API definitions very dry, making them much easier to read (and understand); RAML also has the ”security schemes,“ ”resource types“ and ”traits“ concepts that allow one to model, only once, the most common characteristics of HTTP resources and methods.” – Jonathan Stoikovitch\"\n\n## References\n\n- https://nordicapis.com/oas-vs-raml-whats-the-difference/","n":0.083}}},{"i":2397,"$":{"0":{"v":"Ramda","n":1}}},{"i":2398,"$":{"0":{"v":"Raindrops","n":1}}},{"i":2399,"$":{"0":{"v":"Radigost","n":1},"1":{"v":"\n- repo: https://github.com/ElsevierKnowledgeBasedSystems/KNOSYS-D-15-01003\n- built_on: [[prdct.jason]]\n\n## Features\n\n-   _Radigost_ is a purely web-based multi-agent platform, built using modern _HTML5_ technologies.\n    \n-   _Radigost_ agents and parts of the system itself are implemented in _JavaScript_ and executed inside the client's web browser.\n    \n-   The system is standards-compliant and interoperable, capable of interacting with third-party multi-agent solutions.\n    \n-   _Radigost_ is platform-independent, and supports a wide variety of hardware and software platforms.\n    \n-   Performance evaluation results demonstrate that the runtime performance of _Radigost_ is comparable to that of a desktop-based implementation.\n\n## References\n\n- [Radigost: Interoperable web-based multi-agent platform](https://www.sciencedirect.com/science/article/abs/pii/S0164121214000028)","n":0.105}}},{"i":2400,"$":{"0":{"v":"Racket","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n- url: https://racket-lang.org/\n- [[c.software.ide]] [[prdct.racket.dr-racket]] \n- [[p.supportedBy]] [[prdct.racket.scribble]]","n":0.333}}},{"i":2401,"$":{"0":{"v":"Scribble","n":1},"1":{"v":"\n- url: https://docs.racket-lang.org/scribble/","n":0.577}}},{"i":2402,"$":{"0":{"v":"Dr Racket","n":0.707},"1":{"v":"\n- url: https://docs.racket-lang.org/drracket/","n":0.577}}},{"i":2403,"$":{"0":{"v":"Racer","n":1},"1":{"v":"\n- dead\n- repo: https://github.com/ha-mo-we/Racer\n\n## References\n\n- https://franz.com/agraph/racer/Racer_presentation.pdf","n":0.408}}},{"i":2404,"$":{"0":{"v":"RabbitiMQ","n":1},"1":{"v":"\n## Use Cases\n\n-   Applications that need to support legacy protocols, such as STOMP, MQTT, AMQP, 0-9-1.\n-   Granular control over consistency/set of guarantees on a per-message basis\n-   Complex routing to consumers\n-   Applications that need a variety of publish/subscribe, point-to-point request/reply messaging capabilities.","n":0.156}}},{"i":2405,"$":{"0":{"v":"Quit","n":1},"1":{"v":"\n- repo: https://github.com/AKSW/QuitStore\n\n\n- SPARQL queries from and updates to GIT repos. \n\n## References\n\n- [[ar.decentralized-collaborative-knowledge-management-using-git]]","n":0.267}}},{"i":2406,"$":{"0":{"v":"Quill","n":1},"1":{"v":"\n- url: http://quil.info/\n- repo: https://github.com/quil/quil","n":0.447}}},{"i":2407,"$":{"0":{"v":"QuickJS","n":1},"1":{"v":"\n- url: https://bellard.org/quickjs/\n- repo: https://github.com/bellard/quickjs","n":0.447}}},{"i":2408,"$":{"0":{"v":"QuestJS","n":1},"1":{"v":"\n- [[p.instanceOf]] [[c.software.game-framework.interactivefiction]]\n- [[p.alsoKnownAs]] Quest6\n- [[p.hasLearningResource]]\n  - https://github.com/ThePix/QuestJS/wiki\n- [[p.hasExample]] \n  - [[game.the-house-of-highfield-lane]]\n  - [[game.internal-audit]]\n- [[p.provokedThoughts]]\n  - it'd be great if some suggestions were pre-highlighted, like a hybrid of parser and hypertext\n  - ","n":0.177}}},{"i":2409,"$":{"0":{"v":"Questforge","n":1},"1":{"v":"\n- url: https://www.questforge.app/\n- ","n":0.577}}},{"i":2410,"$":{"0":{"v":"Quest","n":1},"1":{"v":"\n- [[p.hasURL]] http://textadventures.co.uk/quest\n- [[p.hasRepository]] https://github.com/textadventures/quest\n- [[p.instanceOf]] [[c.software.game-framework.interactivefiction]]\n- [[p.hasIssue]]\n  - Quest is focused on specific verb/noun interactions\n- [[p.similarTo]] [[prdct.questjs]]","n":0.236}}},{"i":2411,"$":{"0":{"v":"Quest Portal","n":0.707},"1":{"v":"\n- https://www.questportal.com/\n- [[c.software.rpg.virtual-tabletop]]\n\n## Features\n\n- Write notes for yourself or collaborate with your group without taking focus away from the game.","n":0.224}}},{"i":2412,"$":{"0":{"v":"Qudt Quantity Unit Dimension Type Ontologies","n":0.408},"1":{"v":"\n- https://qudt.org/\n- [[c.ontology.domain]]\n\n## References\n\n- https://fairsharing.org/1198\n- https://www.semanticarts.com/the-abcs-of-qudt/","n":0.408}}},{"i":2413,"$":{"0":{"v":"Quartz.NET","n":1}}},{"i":2414,"$":{"0":{"v":"Quarkus","n":1},"1":{"v":"\n- built_on: [[prdct.vertx]]\n\n## Pros\n\n- \"For Quarkus RESTEASY Reactive extension, you can also use the dependency \"quarkus-resteasy-reactive-links\" which gives you support for Web links ([[t.cs.web.hateoas]]). See the [official documentation](https://quarkus.io/guides/resteasy-reactive#web-links-support) about this dependency.\" Supports [[prdct.hal]]\n\n## References\n\n- https://quarkus.io/blog/mutiny-vertx/\n- https://quarkus.io/blog/virtual-thread-1/\n","n":0.167}}},{"i":2415,"$":{"0":{"v":"Qualreas","n":1},"1":{"v":"\n- [[c.Software.Reasoner]]\n- repo: https://github.com/alreich/qualreas\n- docs: https://qualreas.readthedocs.io/en/latest/\n- examples: https://github.com/alreich/qualreas?tab=readme-ov-file#examples\n- related: [[prdct.rcc8]]\n- written-in: pythong / [[prdct.jupyter]]","n":0.267}}},{"i":2416,"$":{"0":{"v":"Quadstore","n":1},"1":{"v":"\n- related: [[prdct.quadstore.comunica]]\n- written-in: javascript\n- repo: https://github.com/jacoscaz/quadstore\n\n## Issues\n\n- no [[prdct.rdf-star]] support, but maybe for clients that's not so important\n\n\n## References\n\n","n":0.224}}},{"i":2417,"$":{"0":{"v":"Quadstore Comunica","n":0.707},"1":{"v":"\n- related: [[prdct.comunica]]\n- written-in: typescript","n":0.447}}},{"i":2418,"$":{"0":{"v":"QLDB","n":1},"1":{"v":"\n- url: https://aws.amazon.com/qldb/\n\n## Use Cases\n\n- ","n":0.447}}},{"i":2419,"$":{"0":{"v":"PySC2","n":1},"1":{"v":"\n- repo: https://github.com/google-deepmind/pysc2\n- url: https://www.deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-as-an-ai-research-environment ","n":0.447}}},{"i":2420,"$":{"0":{"v":"PyReason","n":1},"1":{"v":"\n- url: https://neurosymbolic.asu.edu/pyreason/\n- repo: https://github.com/lab-v2/pyreason\n- written-in: #python\n- [[p.supports]] [[prdct.graphml]] [[prdct.afsim]]\n\n## Resources\n\n- https://medium.com/towards-nesy/pyreason-software-for-open-world-temporal-logic-d67de751830e\n- https://neurosymbolic.asu.edu/wp-content/uploads/sites/28/2023/02/Shakarian_AAAI_tutorial.pdf","n":0.277}}},{"i":2421,"$":{"0":{"v":"pyLODE","n":1},"1":{"v":"\n\n## Features\n\n- supermodel mode supports documentation for both standalone models and multi-part models, with a particular emphasis on addressing the documentation requirements of modules and profiles within multi-part models.","n":0.186}}},{"i":2422,"$":{"0":{"v":"Pykka","n":1},"1":{"v":"\n- url: https://pykka.readthedocs.io\n- repo: https://github.com/jodal/pykka","n":0.447}}},{"i":2423,"$":{"0":{"v":"Pykg2vec","n":1},"1":{"v":"\n- repo: https://github.com/Sujit-O/pykg2vec\n- #docs https://pykg2vec.readthedocs.io/en/latest/\n  - \"previously, we built pykg2vec using TensorFlow. We switched to Pytorch as we found that more authors use Pytorch to implement their KGE models.\"\n  - ","n":0.183}}},{"i":2424,"$":{"0":{"v":"PyGraft","n":1},"1":{"v":"\n- repo: https://github.com/nicolas-hbt/pygraft\n- uses: [[prdct.hermit]]\n","n":0.447}}},{"i":2425,"$":{"0":{"v":"Pygame","n":1},"1":{"v":"\n- [[p.basedOn]] [[prdct.sdl]]","n":0.577}}},{"i":2426,"$":{"0":{"v":"Pyecs","n":1},"1":{"v":"\n- repo: https://github.com/SudoOmbro/PyECS","n":0.577}}},{"i":2427,"$":{"0":{"v":"Pusher","n":1},"1":{"v":"\n![[prdct.pubnub#^mbnq0t6yrz45]]","n":1}}},{"i":2428,"$":{"0":{"v":"Purl","n":1},"1":{"v":"\n- url: https://purl.archive.org/\n- similar:\n  ![[prdct.w3id#^985zh371a5ph]]\n\n\n## Issues\n\n- Each domain has a single maintainer who can add new PURLs to the domain and make changes to existing PURLs within the domain.\n  - ","n":0.183}}},{"i":2429,"$":{"0":{"v":"Pure Pwa","n":0.707},"1":{"v":"\n- repo: https://github.com/mvneerven/pure-pwa\n- url: https://app.pure-pwa.com/\n\n## Description\n\n- hybrid MPA, which means that we have multiple app pages, each one in its own folder.\n\n## References\n\n- https://medium.com/@neerventure/purepwa-a-radical-u-turn-in-web-development-a386c0dc092e","n":0.204}}},{"i":2430,"$":{"0":{"v":"Pumla","n":1},"1":{"v":"\n- repo: https://github.com/DrMarkusVoss/pumla\n- [[p.hadDependancy]] [[prdct.plantuml]]","n":0.447}}},{"i":2431,"$":{"0":{"v":"Pulumi","n":1},"1":{"v":"\n## Cons\n\n- \"based on webhooks so forget them... Crossplane.io does a continious job\"\n\n## Resources\n\n- https://www.pulumi.com/blog/organizing-aws-accounts-with-pulumi/\n- https://www.pulumi.com/docs/using-pulumi/testing/property-testing/\n- \n\n## References\n\n- https://www.reddit.com/r/devops/comments/11ebjis/terraform_vs_pulumi_vs_others/\n- https://eightify.app/summary/technology-and-software/comparing-terraform-pulumi-and-crossplane-iac-tools-for-kubernetes\n\n```yaml\nurl: https://www.pulumi.com/\nsimilar:\n  - [[prdct.terraform]]\n  - [[prdct.crossplane]]\n```\n","n":0.2}}},{"i":2432,"$":{"0":{"v":"Apache Pulsar","n":0.707},"1":{"v":"\n- url: https://pulsar.apache.org/\n- managed_services: [[prdct.streamnative]] [[prdct.datastax.astra-streaming]] [[prdct.clevercloud]]\n\n\n## Comparisons\n\n### ","n":0.354}}},{"i":2433,"$":{"0":{"v":"PubNub","n":1},"1":{"v":"\n- [[c.Software.real_time_framework]]\n- similar: [[prdct.ably]] [[prdct.stream]] [[prdct.pusher]] [[prdct.pubnub]] [[prdct.centrifugo]] [[prdct.mercure]] ^mbnq0t6yrz45","n":0.316}}},{"i":2434,"$":{"0":{"v":"Pubby","n":1},"1":{"v":"\n- [[c.software.semantic.browser]]\n- similar: [[prdct.lodview]] [[prdct.trifid]] [[prdct.pubby]] ^4ldbidz2j6c8","n":0.378}}},{"i":2435,"$":{"0":{"v":"Ptolemy","n":1},"1":{"v":"\n- [[c.software.simulation-framework.discrete-event]]\n- url: https://ptolemy.berkeley.edu/ptolemyII/index.htm\n\n## Resources\n\n- https://ptolemy.berkeley.edu/books/Systems/chapters/DiscreteEventModels.pdf\n\n","n":0.408}}},{"i":2436,"$":{"0":{"v":"PROV-O","n":1},"1":{"v":"\n- https://www.w3.org/TR/prov-o/\n- [[c.ontology.creative-work]] [[c.ontology.domain]]\n- rdfs:isDefinedBy http://www.w3.org/ns/prov# \n- implicit accessURL of https://www.w3.org/ns/prov-o\n- versionIRI http://www.w3.org/ns/prov-o-20130430\n\n\n## Thoughts\n\n- ontology IRI is http://www.w3.org/ns/prov although that houses other things too, seems like it should be https://www.w3.org/TR/prov-o/\n- can't re-use :category because it's an annotation property\n\n\n## References\n\n- https://www.w3.org/TR/prov-o/#description-starting-point-terms","n":0.158}}},{"i":2437,"$":{"0":{"v":"Prototype","n":1},"1":{"v":"\n- [[c.software.web.toolkit]]\n![[prdct.dojo_toolkit#^tmacjwe8emtq]]","n":0.707}}},{"i":2438,"$":{"0":{"v":"PROTON","n":1},"1":{"v":"\n- https://lov.linkeddata.es/dataset/lov/vocabs/ptop\n- [[c.ontology.upper]]\n- produced_by: [[org.ontotext]]\n\n![](/assets/images/2024-06-11-13-37-20.png)\n\n\n## Issues\n\n- weirdly specific in some upper classes like \"contact information\" and \"nationality\"\n- mainLabel instead of skos:prefLabel\n- agents include (web) services\n- person subclasses: man, woman, fictional character\n  - I guess with multiple inheritance, that could make some sense, but Dino is a fictional character\n\n## References\n\n- https://ontotext.com/documents/proton/Proton-Ver3.0B.pdf","n":0.141}}},{"i":2439,"$":{"0":{"v":"Protoculture","n":1},"1":{"v":"\n- https://github.com/atrauzzi/protoculture-dotnet-postgres","n":0.707}}},{"i":2440,"$":{"0":{"v":"Protobuf","n":1}}},{"i":2441,"$":{"0":{"v":"Proto.Actor","n":1},"1":{"v":"\n- [[c.software.distributed-systems-runtime]] [[c.software.actor-framework]]\n- url: https://proto.actor\n- [[p.similarTo]] [[prdct.orleans]] [[prdct.akka-net]] \n- [[c.implementation]]\n  -  https://github.com/asynkron/protoactor-go #go \n  -  https://github.com/asynkron/protoactor-dotnet c#\n  -  https://github.com/asynkron/protoactor-kotlin #kotlin\n- uses: gRPC with protobuf\n\n## Features\n\n- migration -> local affinity https://proto.actor/docs/local-affinity/\n- \"Proto.Actor uses Protobuf for serialization, a decision that vastly simplifies the way Proto.Actor works. Message based systems should be about passing information, not passing complex OOP object graphs or code.\" \n- \"Proto.Actor also uses gRPC, leveraging HTTP/2 streams for network communication.\"\n- Proto.Persistence module allows an actor to recover its state when it is started and supports three modes of operation:\n  - Event Sourcing\n  - Snapshotting\n  - Event Sourcing with Snapshotting \n    - snapshotting becomes a performance optimisation for cases when you have large numbers of events to replay to rebuild the state of your actor\n- \"Just like everything else in Proto.Actor where we have re-used proven technologies such as Protobuf and gRPC, we do the same for clustering, we do not reinvent the wheel and create our own cluster mechanics. Instead, we leverage proven technologies such as Consul, ETCD or Kubernetes to power our Cluster member management.\"\n\n### Behaviors\n\n- Actors can change their behavior at any time. This is achieved through the Behavior class included with the core Proto.Actor library.\n\n## Thoughts\n\n- \"Message based systems should be about passing information, not passing complex OOP object graphs or code.\" [1]\n\n## Examples\n\n- https://github.com/asynkron/realtimemap-dotnet\n\n## Resources\n\n- https://proto.actor/docs/what-is-protoactor/\n\n### Learning Resource\n\n- https://proto.actor/docs/bootcamp/\n\n## References\n\n- [1]: https://proto.actor/docs/what-is-protoactor/","n":0.066}}},{"i":2442,"$":{"0":{"v":"Protégé","n":1},"1":{"v":"\n\n- [[c.software.semantic.ontology-editor]] [[c.software.semantic.authoring]]\n- url: https://protege.stanford.edu/\n- written_in: java\n- aka: \"Protege 2000\"\n\n## Features\n\n- supports [[prdct.identitas]]\n\n## Similar\n\n- [[prdct.protege]] [[prdct.vocbench]] [[prdct.topbraid-composer]] [[prdct.hozo]]\n\n## References\n\n- [[ar.identitas-semantics-free-and-human-readable-identifiers]]","n":0.224}}},{"i":2443,"$":{"0":{"v":"Web Protege","n":0.707},"1":{"v":"\n- [[c.software.semantic.ontology-editor]]\n- url: https://webprotege.stanford.edu\n\n## Features\n\n- [ ] addresses canonization?","n":0.333}}},{"i":2444,"$":{"0":{"v":"Prompt","n":1},"1":{"v":"\n- https://protegewiki.stanford.edu/wiki/PROMPT\n- [[c.software.plugin.protege]]\n- ","n":0.577}}},{"i":2445,"$":{"0":{"v":"Prosody","n":1},"1":{"v":"\n- [[c.software.xmpp-server]]\n- repo: https://github.com/bjc/prosody (mirror)\n- written-in: [[prdct.lua]]","n":0.378}}},{"i":2446,"$":{"0":{"v":"Property Graph Queries","n":0.577},"1":{"v":"\n\n\n### [[c.resource.list]]\n\n- https://github.com/szarnyasg/gql-sql-pgq-pointers\n- https://www.linkedin.com/pulse/postgresql-oracle-graph-query-language-standards-adoption-green/\n  - \"knowledge tree\": \"I have proposed an approach to introducing metaproperties into the nested record model that is based on a generalization of XML's idea of \"mixed content\", and can be seen in the data structures of existing OSS tree-data libraries for e.g. C++ and C#.\"\n- ","n":0.141}}},{"i":2447,"$":{"0":{"v":"Proofpoint","n":1}}},{"i":2448,"$":{"0":{"v":"Prometheus","n":1}}},{"i":2449,"$":{"0":{"v":"Proletarian Wizard","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]]\n- [[p.extends]] [[prdct.vscode]]\n- [[p.hasApplication]] [[t.tm]] \n- [[p.inspiredBy]] [[t.tm.getting-things-done]]\n- [[p.hasBlogEntry]] https://www.feval.ca/posts/pw/\n  - [[p.hasHighlight]] \"for the personal stuff that I want to have “on the go” (mostly reading notes or random notes), I use [[notion|prdct.notion]] - but mostly as a staging space.\"\n- [[p.hasFeature]]\n  - Organized file management, helping to quickly create projects, notes from templates, and archive these projects neatly. It also helps the navigation using keyboard only.\n  - To-do management, collecting todos from project notes, extend them with attributes, and summarizing these into flexible groups and sortings\n-","n":0.107}}},{"i":2450,"$":{"0":{"v":"Proj4","n":1},"1":{"v":"\n- [[c.software.gis]]\n- url: https://proj4.org/\n- description: started purely as a cartography application letting users convert geodetic coordinates into projected coordinates using a number of different cartographic projections. Over the years, as the need has become apparent, support for datum shifts has slowly worked its way into PROJ as well. Today PROJ supports more than a hundred different map projections and can transform coordinates between datums using all but the most obscure geodetic techniques.","n":0.118}}},{"i":2451,"$":{"0":{"v":"Profwiz","n":1},"1":{"v":"\n- turn your domain account into a local account\n- ","n":0.333}}},{"i":2452,"$":{"0":{"v":"Processing","n":1},"1":{"v":"\nurl: https://processing.org/\n- [[c.publisher]] [[org.processing]]\n- written-in: java\n- [[p.similarTo]] [[prdct.p5-js]]","n":0.354}}},{"i":2453,"$":{"0":{"v":"Process Specification Language (PSL)","n":0.5},"1":{"v":"\n- PSL-Core is the set of axioms written in [[prdct.clif]]\n\n## Commitments\n\nIntuition 1:\n\nThere are four kinds of entities required for reasoning about processes -- activities, activity occurrences, timepoints, and objects.\n\nIntuition 2:\n\nActivities may have multiple occurrences, or there may exist activities that do not occur at all.\n\nIntuition 3:\n\nTimepoints are linearly ordered, forwards into the future, and backwards into the past.\n\nIntuition 4:\n\nActivity occurrences and objects are associated with unique timepoints that mark the begin and end of the occurrence or object.   \n\n## Resources\n\n- https://www.nist.gov/services-resources/software/20-questions-psl\n\n## References\n\n- http://ontologydesignpatterns.org/wiki/Ontology:Process_Specification_Language_%28PSL%29","n":0.11}}},{"i":2454,"$":{"0":{"v":"Probot","n":1},"1":{"v":"\nurl: https://probot.github.io\n","n":0.707}}},{"i":2455,"$":{"0":{"v":"Prisma","n":1},"1":{"v":"\n- used_by: [[prdct.blitz]]","n":0.577}}},{"i":2456,"$":{"0":{"v":"Prezi","n":1}}},{"i":2457,"$":{"0":{"v":"Prevayler","n":1},"1":{"v":"\n- url: https://prevayler.org/","n":0.577}}},{"i":2458,"$":{"0":{"v":"Presto Ontology","n":0.707},"1":{"v":"\n- based-on: [[prdct.dolce]]\n\n## References\n\n- [[ar.an-ontology-for-supporting-the-evolution-of-virtual-reality-scenarios]]","n":0.447}}},{"i":2459,"$":{"0":{"v":"Pressoo","n":1},"1":{"v":"\n- https://www.ifla.org/g/cataloguing/pressoo/\n- extends: [[prdct.frbroo]] \n- related: [[prdct.lrmoo]]\n\n\n\n## References\n\n- https://www.ifla.org/wp-content/uploads/2019/05/assets/cataloguing/PRESSoo/pressoo_v1-3.pdf","n":0.333}}},{"i":2460,"$":{"0":{"v":"Prepar3d","n":1},"1":{"v":"\n\n- [[p.providedBy]] [[org.lockheed-martin]]\n- [[p.supports]] [[prdct.enterprise-simulation-platform]]\n- [[p.hasVariant]] professional plus\n  - [[p.supports]] [[prdct.hla]]\n","n":0.302}}},{"i":2461,"$":{"0":{"v":"Premis Ontology","n":0.707},"1":{"v":"\n- url: https://id.loc.gov/ontologies/premis-3-0-0.html\n- repo: https://github.com/lcnetdev/PREMIS/\n\n## Class List\n\n\n    Action     \n    + Agent     \n    Bitstream     \n    Copyright     \n    Dependency     \n    EnvironmentCharacteristic     \n    Event     \n    File     \n    Fixity     \n    HardwareAgent     \n\n    Identifier     \n    Inhibitor     \n    InstitutionalPolicy     \n    IntellectualEntity     \n    License     \n    + Object     \n    Organization     \n    OutcomeStatus     \n    Person     \n    + PreservationPolicy     \n\n    Representation     \n    + RightsBasis     \n    RightsStatus     \n    Rule     \n    Signature     \n    SignatureEncoding     \n    SignificantProperties     \n    SoftwareAgent     \n    Statute     \n    StorageLocation     \n    StorageMedium","n":0.118}}},{"i":2462,"$":{"0":{"v":"prefix.cc","n":1},"1":{"v":"\n- url: http://prefix.cc/\n- similar:  ","n":0.5}}},{"i":2463,"$":{"0":{"v":"Prefect","n":1},"1":{"v":"\n![[prdct.n8n#^xnxaubd7sqiw]]\n- url: https://www.prefect.io\n- repo: https://github.com/PrefectHQ/prefect\n- written-in: python\n\n## Description\n\nPrefect is an orchestration and observability platform for building, observing, and triaging workflows. It's the simplest way to transform Python code into an interactive workflow application.\n\nPrefect allows you to expose your workflows through an API so teams dependent on you can programmatically access your pipelines, business logic, and more. Prefect also allows you to standardize workflow development and deployment across your organization.\n\nWith Prefect, you can build resilient, dynamic workflows that react to the world around them and recover from unexpected changes. With just a few decorators, Prefect supercharges your code with features like automatic retries, distributed execution, scheduling, caching, and much more.","n":0.096}}},{"i":2464,"$":{"0":{"v":"Powergate","n":1},"1":{"v":"\n\n- [[p.hasLearningResource]] https://docs.filecoin.io/build/powergate/\n","n":0.577}}},{"i":2465,"$":{"0":{"v":"PouchDB","n":1},"1":{"v":"- ![[prdct.rxdb#^pnjx84u9yrqy]]\n- url: https://pouchdb.com/\n\n## [[p.supports]]\n\n- [[prdct.deno]] via https://github.com/aaronhuggins/pouchdb_deno\n- [[t.cs.web.browser]]","n":0.333}}},{"i":2466,"$":{"0":{"v":"Postman","n":1}}},{"i":2467,"$":{"0":{"v":"Posthog","n":1},"1":{"v":"\n\n## Features\n\n- [[t.pdm.analytics]]\n- [[t.pdm.session-replay]]\n- [[t.cs.sd.feature-flag]]\n- [[t.cs.sd.a-b-testing]]\n\n## [[c.pricing]]\n\n- free and pay per use\n  - both plans get 1M events/mo and 15k session recordings/mo\n\n\n\n## Resources\n\n- https://memphis.dev/blog/how-to-integrate-posthog-with-memphis-dev/ ([[p.integratesWith]] [[prdct.memphis]])","n":0.196}}},{"i":2468,"$":{"0":{"v":"Portable Text","n":0.707},"1":{"v":"\n- url: https://github.com/portabletext/portabletext","n":0.577}}},{"i":2469,"$":{"0":{"v":"Port","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/urbit/port\n- ","n":0.577}}},{"i":2470,"$":{"0":{"v":"Popmotion","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n- url: https://popmotion.io/\n- ","n":0.5}}},{"i":2471,"$":{"0":{"v":"Pool Party","n":0.707},"1":{"v":"\n- https://www.poolparty.biz/\n- commercial, from  $28,900 / year\n- supports: [[prdct.graphrag]]\n","n":0.333}}},{"i":2472,"$":{"0":{"v":"pomdp-solve","n":1},"1":{"v":"\n- repo: https://github.com/cassandra/pomdp-solve\n- written_in: c\n- url: https://www.pomdp.org/code/","n":0.378}}},{"i":2473,"$":{"0":{"v":"Polynote","n":1},"1":{"v":"\n- url: https://polynote.org\n- repo: https://github.com/polynote/polynote\n- [[p.supports]] [[prdct.vega]] scala #python\n\n## [[prdct.windows.wsl]]\n\n- https://github.com/polynote/polynote/issues/671 : change listen host to 0.0.0.0\n\n## [[p.vs]]\n\n- Current notebook solutions, like Jupyter and Zeppelin, are lacking in some fundamental features:\n\n    Code editing – the code editing capabilities in most notebook tools leave plenty to be desired. Why can't a notebook tool have modern editing capabilities like those you'd find in an IDE? Polynote provides useful autocomplete, parameter hints, and more – we're planning to add even more features, like jump-to-definition.\n    Text editing – you can use the WYSIWYG editor for composing text cells, so you'll know what the text will look like as you're writing. TeX equations are also supported.\n    Multi-language support – Polynote allows you to mix multiple languages in one notebook, while sharing definitions seamlessly between them.\n    Runtime insight – Polynote tries to keep you informed of what's going on at runtime:\n        The tasks area shows you what the kernel is doing at any given time.\n        The symbol table shows you what variables and functions you've defined, so you don't have to scroll around to remind yourself.\n        Compile failures and runtime exceptions are highlighted in the editor (for supported languages), so you can see exactly what's going wrong.\n","n":0.071}}},{"i":2474,"$":{"0":{"v":"Poly Pizza","n":0.707},"1":{"v":"\n- url: https://poly.pizza/ ","n":0.577}}},{"i":2475,"$":{"0":{"v":"Polly","n":1},"1":{"v":"\n- url: https://www.thepollyproject.org/","n":0.577}}},{"i":2476,"$":{"0":{"v":"PodSpaces","n":1},"1":{"v":"\n- related: [[prdct.solid]]\n- url: https://start.inrupt.com\n- username: djradon\n- WebID: https://id.inrupt.com/djradon\n- pod storage: https://storage.inrupt.com/a3a289b6-9574-4493-9836-7eed9f043641/","n":0.289}}},{"i":2477,"$":{"0":{"v":"Plutonium","n":1},"1":{"v":"\n- [[c.software.rpg.virtual-tabletop.utilities]]\n- [[c.feature]] allowing players and Dungeon Masters to easily import [[prdct.5e-tools]] content\n- related: [[prdct.Foundry-VTT]]\n\n## Resources\n\n- https://wiki.tercept.net/en/Plutonium","n":0.243}}},{"i":2478,"$":{"0":{"v":"Plow","n":1},"1":{"v":"\n- https://plow.pm\n- [[c.software.semantic]] [[c.registry.ontology]]\n- \n\n## Description\n\n_Plow_ consists of a few distinct core components:\n\n-   the official registry (https://registry.field33.com/)\n-   the website for the official registry\n-   the Command Line Interface (CLI)\n\nThe official registry is a database of packages (called _fields_ in Plow) that is controlled via a JSON API. It allows anyone to publish packages for public or private consumption for any knowledge domain.\n\nThe [registry website (opens in a new tab)](https://registry.field33.com/) allows for discovery of packages via search, categories and keywords. It also provides an overview of relevant metadata (ontology project website, license, dependencies, etc.) for all versions of all packages.\n\nThe CLI allows for interacting with the registry from the terminal. It allows for e.g. publishing new fields, resolving dependencies of an ontology project and/or opening an ontology with dependencies in Protege.\n","n":0.088}}},{"i":2479,"$":{"0":{"v":"Playfab","n":1},"1":{"v":"\n- [[c.software.game-engine]]\n- [[p.supports]]\n  - javascript\n  - [[prdct.node]] \n  - [[prdct.deno]] \n    - [[p.hasSource]] https://deno.land/x/playfab_sdk@210511.0\n  - java https://learn.microsoft.com/en-us/gaming/playfab/sdks/java/\n\n## [[c.limitation]]\n\n- no/bad browser support\n\n## [[c.pricing]]\n\n- https://playfab.com/pricing :\n  - $0/month before your title passes 100K users\n\n## Features\n\n- [Cloudscript](https://learn.microsoft.com/en-us/gaming/playfab/features/automation/cloudscript/) : build server-side logic and functionality that scales to meet your demand, without worrying about servers or infrastructure.","n":0.139}}},{"i":2480,"$":{"0":{"v":"Playerio","n":1},"1":{"v":"\n[[c.software.game-platform]]\n- url: https://playerio.com/\n- similar: https://github.com/OpenPlayerIO\n- [[p.hasClientSupport]] [[prdct.unity]] java javascript c#\n- [[p.supports]] [[prdct.dotnet]]\n  - [[p.hasSource]] \"Serverside code can be written in any .Net language such as C# or VB.Net\"\n- [[p.hadLimitation]]\n  - [[p.hasSource]] https://playerio.com/documentation/services/multiplayer/essentials\n    - Serverside code cannot run for longer than 100ms. ^prgi8bdivq2m\n    - A single room can hold up to 45 players simultaneously.\n  - ","n":0.136}}},{"i":2481,"$":{"0":{"v":"PlayCanvas","n":1},"1":{"v":"\n- repo: https://github.com/playcanvas/engine\n- resources:  [[ar.real-time-multiplayer-colyseus]]\n- written-in: javascript\n\n## Cons\n\n- despite https://github.com/playcanvas/playcanvas-sync it's not really local-first development\n\n","n":0.258}}},{"i":2482,"$":{"0":{"v":"Play Framework","n":0.707},"1":{"v":"\n- url: https://www.playframework.com/\n- [[p.basedOn]] [[prdct.akka]]\n\n## History\n\n- Play 3.0 introduces a significant update in the platform's development - the shift from Akka to Apache Pekko. Apache Pekko is a branch of Akka 2.6.x that has already experienced some evolution and brought in some unique ideas. Play 3.0 employs Pekko and its HTTP components, indicating a further direction in the modernisation of the framework's infrastructure... There's been a new wave of solutions in the Java world, like Micronaut and Quarkus, that have effectively dominated the market for those seeking an alternative to Spring.\n\n## References\n\n- https://vived.substack.com/p/play-framework-is-reborn-like-a-phoenix\n- ","n":0.104}}},{"i":2483,"$":{"0":{"v":"play-cljc","n":1},"1":{"v":"\n- #repo: https://github.com/oakes/play-cljc\n- written_in: clojure\n- similar: [[prdct.arcadia]]\n- supports: [[prdct.lwjgl]]\n\n## Examples\n\n- https://github.com/oakes/play-cljc-examples","n":0.302}}},{"i":2484,"$":{"0":{"v":"Platform9","n":1}}},{"i":2485,"$":{"0":{"v":"Planhat","n":1}}},{"i":2486,"$":{"0":{"v":"Pixi.js","n":1},"1":{"v":"\n- [[c.software.web.animation-library]] [[c.software.game-platform]]\n\n","n":0.577}}},{"i":2487,"$":{"0":{"v":"Pixel","n":1},"1":{"v":"\n- repo: https://github.com/gopxl/pixel","n":0.577}}},{"i":2488,"$":{"0":{"v":"Piqnic","n":1},"1":{"v":"\n- https://qweb.cs.aau.dk/piqnic/\n\n## References\n\n- [[ar.a-decentralized-architecture-for-sharing-and-querying-semantic-data]]","n":0.5}}},{"i":2489,"$":{"0":{"v":"Pino","n":1},"1":{"v":"\nurl:  https://getpino.io/\nrepo: https://github.com/pinojs/pino\n\n\n## Resources\n\n- https://www.nearform.com/blog/pino-the-fastest-node-js-logger-for-production/","n":0.447}}},{"i":2490,"$":{"0":{"v":"Pingboard","n":1}}},{"i":2491,"$":{"0":{"v":"Pikchr","n":1},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- url: https://pikchr.org\n- [[p.supportedBy]] [[prdct.vscode]] ","n":0.408}}},{"i":2492,"$":{"0":{"v":"Phratch","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/janniklaval/phratch\n- a visual programming language based on [[prdct.scratch]] on top of [[prdct.pharo]]","n":0.258}}},{"i":2493,"$":{"0":{"v":"Photon","n":1},"1":{"v":"\n![](/assets/images/2024-02-06-21-11-49.png)","n":1}}},{"i":2494,"$":{"0":{"v":"Realtime","n":1},"1":{"v":"\n- url: https://www.photonengine.com/realtime\n\n## Features\n\n- Sync and Async Games: Freely switch between synchronous and asynchronous turn-based game modes. Keep rooms alive: let players rejoin rooms in case of disconnects or in case of resurrecting a game.\n","n":0.169}}},{"i":2495,"$":{"0":{"v":"Quantum","n":1},"1":{"v":"\n- [[t.cs.entity-component-system]]\n- written-in: [[t.cs.languages.c-sharp]] c#\n\n## Features\n\n- no unity dependancy","n":0.333}}},{"i":2496,"$":{"0":{"v":"Fusion","n":1},"1":{"v":"\n- url: https://www.photonengine.com/fusion\n\n\n## Features\n\n- [[t.cs.game.netcode.delta-snapshots]] ","n":0.447}}},{"i":2497,"$":{"0":{"v":"Phoenix","n":1},"1":{"v":"\n- repo: https://www.phoenixframework.org/\n- written_in: [[prdct.elixir]]\n\n## Features\n\n- pub/sub system called Phoenix Channels.","n":0.302}}},{"i":2498,"$":{"0":{"v":"Phaser","n":1},"1":{"v":"\n\n- [[p.hasSite]] http://phaser.io/\n- repo: https://github.com/photonstorm/phaser\n- [[p.hasScriptingLanguage]] javascript\n- [[p.hasLearningResource]] http://phaser.io/shop/books/make-games-with-phaser\n\n## Resources\n\n- https://blog.ourcade.co/posts/2023/building-phaser-3-ecs-game-with-reactjs/","n":0.302}}},{"i":2499,"$":{"0":{"v":"Pharo","n":1},"1":{"v":"\n- [[c.software.live-programming]]\n- url: https://www.pharo.org/\n- repo: https://github.com/pharo-project\n- written-in: [[t.cs.languages.smalltalk]]\n- [[p.similarTo]] [[prdct.lively]]\n\n## Features\n\n- https://www.pharo.org/features\n  - Pharo is a simple meta-language where the programmer has all features required for the writing of custom readable domain-specific languages.\n  - Pharo classes use single inheritance, but they can use stateful traits for sharing of behavior with other classes.\n\n## [[c.solution.related]]\n\n- [[prdct.glamorous-toolkit]]\n  - https://lepiter.io/feenk/glamorous-toolkit-and-pharo-9q25tavxwfq6z1drwvegd5u9o/\n- [[prdct.phratch]]\n- http://forum.world.st/Memory-mapped-files-and-Pharo-aka-Unreal-Engine-4-integration-with-Pharo-td4872049.html\n\n## Resources\n\n- https://pavel-krivanek.github.io/famix/\n  - \"The need for meta-model unification lead sometimes to bizarre design decisions that had no sense in particular languages.\"\n- https://richardeng.medium.com/python-vs-pharo-2c2c1a3b1afe\n  - https://pharo.org/success/UXadvancedAtThales.html\n  - [[p.references]] [[t.cs.languages.smalltalk.amber]]\n  - https://pharoweekly.wordpress.com/2016/11/13/scripting-unreal-with-pharo/ #looks-complicated\n\n\n### [[c.resource.list]]\n\n- http://books.pharo.org/\n","n":0.105}}},{"i":2500,"$":{"0":{"v":"pg-mem","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/oguimbal/pg-mem\n- [[p.hasFeature]] \n  - [[t.cs.data.restore-point]]","n":0.378}}},{"i":2501,"$":{"0":{"v":"pg_bitemporal","n":1},"1":{"v":"\n- repo: https://github.com/hettie-d/pg_bitemporal\n- ","n":0.577}}},{"i":2502,"$":{"0":{"v":"Pettingzoo","n":1},"1":{"v":"\n- [[c.software.ai]]\n- url: https://pettingzoo.farama.org\n- related: [[t.cs.ai.machine-learning]]","n":0.408}}},{"i":2503,"$":{"0":{"v":"Petgraph","n":1},"1":{"v":"\n- url: https://docs.rs/petgraph/0.5.0/petgraph/\n\n## References\n\n- https://depth-first.com/articles/2020/02/03/graphs-in-rust-an-introduction-to-petgraph/","n":0.447}}},{"i":2504,"$":{"0":{"v":"Perplexity","n":1},"1":{"v":"\n- [[c.software.ai.assistant]]\n- url: https://www.perplexity.ai\n- ","n":0.5}}},{"i":2505,"$":{"0":{"v":"Permutive","n":1},"1":{"v":"\n\n- audience clustering of activities on site\n  - needs multiple impressions per user","n":0.277}}},{"i":2506,"$":{"0":{"v":"Periodo","n":1},"1":{"v":"\n- https://perio.do/en/\n- related: [[prdct.edtf-ontology]]","n":0.5}}},{"i":2507,"$":{"0":{"v":"Pellet","n":1},"1":{"v":"\n- [[c.Software.Reasoner]] [[c.software.reasoner.tableau]]\n\n## Features\n\n- Pellet can \"accept all the definitions for the URI but treat them differently for query answer-ing. For example, if the same URI is defined both as a class and as a property, Pellet will create both a class and a property and associate the axioms with the corresponding definition. Depending on the queries, asking subclasses vs. asking sub properties, the appropriate definition will be used.\n- ![[ar.bobdc.using-owlincludes#^hjoz18cgiza1]]\n\n## References\n\n- https://stackoverflow.com/questions/17357836/using-swrl-with-jena-and-pellet\n- [[ar.pellet-an-owl-reasoner]]","n":0.117}}},{"i":2508,"$":{"0":{"v":"Pekko","n":1},"1":{"v":"\n- [[c.software.actor-framework]]\n- url: https://pekko.apache.org/\n- [[p.similarTo]] [[prdct.gpars]]\n","n":0.408}}},{"i":2509,"$":{"0":{"v":"Pathom","n":1},"1":{"v":"\n- https://pathom3.wsscode.com/\n- docs: https://pathom3.wsscode.com/docs/","n":0.5}}},{"i":2510,"$":{"0":{"v":"Patch Manager Plus","n":0.577}}},{"i":2511,"$":{"0":{"v":"Partial Mixins","n":0.707},"1":{"v":"\n- repo: https://github.com/LokiMidgard/PartialMixins\n- [[c.dependancy]] [[prdct.roslyn]]","n":0.447}}},{"i":2512,"$":{"0":{"v":"Parrot","n":1},"1":{"v":"\n- dead\n- [[c.software.semantic.publishing.site-generator]]\n- repo: https://github.com/dayures/parrot\n- example: https://www.ontotext.com/proton/protontop.html\n- similar: [[prdct.ontoology]] [[prdct.pubby]]","n":0.316}}},{"i":2513,"$":{"0":{"v":"Parliament","n":1},"1":{"v":"\n- https://github.com/raytheonbbn/parliament","n":0.707}}},{"i":2514,"$":{"0":{"v":"Parcel","n":1},"1":{"v":"\n\n- https://parceljs.org/\n- docs: https://parceljs.org/docs/\n- repo: https://github.com/parcel-bundler/parcel\n- written-in: javascript #rust\n\n## Features\n\n-   😍 **Zero config** – Parcel supports many languages and file types out of the box, from web technologies like HTML, CSS, and JavaScript, to assets like images, fonts, videos, and more. It has a built-in dev server with hot reloading, beautiful error diagnostics, and much more. No configuration needed!\n-   ⚡️ **Lightning fast** – Parcel's JavaScript compiler is written in Rust for native performance. Your code is built in parallel using worker threads, utilizing all of the cores on your machine. Everything is cached, so you never build the same code twice. It's like using watch mode, but even when you restart Parcel!\n-   🚀 **Automatic production optimization** – Parcel optimizes your whole app for production automatically. This includes tree-shaking and minifying your JavaScript, CSS, and HTML, resizing and optimizing images, content hashing, automatic code splitting, and much more.\n-   🎯 **Ship for any target** – Parcel automatically transforms your code for your target environments. From modern and legacy browser support, to zero config JSX and TypeScript compilation, Parcel makes it easy to build for any target – or many!\n-   🌍 **Scalable** – Parcel requires zero configuration to get started. But as your application grows and your build requirements become more complex, it's possible to extend Parcel in just about every way. A simple configuration format and powerful plugin system that's designed from the ground up for performance means Parcel can support projects of any size.","n":0.064}}},{"i":2515,"$":{"0":{"v":"Panda3d","n":1},"1":{"v":"\n- [[c.software.game-engine]]\n- url: https://www.panda3d.org/\n- repo: https://github.com/panda3d/panda3d\n- written-in: #c++ #python","n":0.333}}},{"i":2516,"$":{"0":{"v":"Pagic","n":1}}},{"i":2517,"$":{"0":{"v":"Pagefind","n":1},"1":{"v":"\n- https://pagefind.app/\n- [[c.software.web.static-search]]\n\n## Similar\n\n- [[prdct.pagefind]] [[prdct.lunr]]\n\n## Features\n\n-   Zero-config support for multilingual websites\n-   Rich filtering engine for knowledge bases\n-   Custom sort attributes\n-   Custom metadata tracking\n-   Custom content weighting\n-   Return results for sections of a page\n-   Search across multiple domains\n-   Index **anything** (e.g. PDFs, JSON files, or subtitles) with the NodeJS indexing library\n-   All features available with the same low-bandwidth footprint\n\n## References\n\n- https://rknight.me/blog/using-pagefind-with-eleventy-for-search/","n":0.128}}},{"i":2518,"$":{"0":{"v":"Packup","n":1},"1":{"v":"\n- similar-to: [[prdct.parcel]]\n- docs:\n  - https://packup.deno.dev/guides/static-dir/","n":0.408}}},{"i":2519,"$":{"0":{"v":"p5.js","n":1},"1":{"v":"\nurl: https://p5js.org/\nrepo: https://github.com/processing/p5.js\n- [[c.publisher]] [[org.processing]]\n- [[p.similarTo]] [[prdct.processing]]\n\n","n":0.378}}},{"i":2520,"$":{"0":{"v":"Oxo","n":1},"1":{"v":"\n- [[c.software.semantic]]\n- url: https://www.ebi.ac.uk/spot/oxo/\n- similar: [[prdct.ontology-lookup-service]]","n":0.408}}},{"i":2521,"$":{"0":{"v":"Oxigraph","n":1},"1":{"v":"\n- repo: https://github.com/oxigraph/oxigraph\n- written-in: rust\n- related: [[prdct.plow]]","n":0.378}}},{"i":2522,"$":{"0":{"v":"OWLSharp","n":1},"1":{"v":"\n- repo: https://github.com/mdesalvo/OWLSharp\n\n![](/assets/images/2024-02-27-16-06-04.png)\n\n## Features\n\n- OWLSharp is built atop [RDFSharp](https://github.com/mdesalvo/RDFSharp) with the goal of providing ontology expressivity for:\n\n-   Creating **OWL2 ontologies** (classes, restrictions, properties, individuals, assertions, annotations, ...)\n-   Exporting them using standard **OWL2 formats** (OWL2/Xml)\n-   Validating and Reasoning through extensible sets of intelligent **RDFS/OWL-DL/OWL2** semantic rules\n\nIn addition to the [core ontology features](https://github.com/mdesalvo/OWLSharp/releases/download/v3.10.2/OWLSharp-3.10.2.pdf), it integrates a set of extensions providing expressivity for:\n\n-   Creating reasoners building business-logic inference rules in a fluent and natural way ([SWRL](https://github.com/mdesalvo/OWLSharp/releases/download/v3.10.0/OWLSharp.Extensions.SWRL-3.10.0.pdf)) \n    -   \"infers complex relations between classes\nand between properties (driven by feature-\nparity with Pellet, HermiT and Fact++\"\n-   Creating schemes describing, documenting and organizing vocabularies of concepts ([SKOS](https://github.com/mdesalvo/OWLSharp/releases/download/v3.10.0/OWLSharp.Extensions.SKOS-3.10.0.pdf))\n-   Modeling and relating features having a spatiotemporal representation ([GeoSPARQL](https://github.com/mdesalvo/OWLSharp/releases/download/v3.10.0/OWLSharp.Extensions.GEO-3.10.0.pdf), [OWL-TIME](https://github.com/mdesalvo/OWLSharp/releases/download/v3.10.0/OWLSharp.Extensions.TIME-3.10.0.pdf))","n":0.095}}},{"i":2523,"$":{"0":{"v":"OWL2 RL Python","n":0.577},"1":{"v":"\n- https://github.com/RDFLib/OWL-RL\n\n\n\n","n":0.707}}},{"i":2524,"$":{"0":{"v":"Owlready2","n":1},"1":{"v":"\n- \n- #docs https://owlready2.readthedocs.io/\n- written-in: #python\n- [[p.supports]] [[prdct.owl]]\n- [[p.builtOn]] [[prdct.hermit]]\n\n## Features\n\n-   Import OWL 2.0 ontologies in NTriples, RDF/XML or OWL/XML f\n    \n-   Export OWL 2.0 ontologies to NTriples or RDF/XML\n    \n-   Manipulates ontology classes, instances and properties transparently, as if they were normal Python objects\n    \n-   Add Python methods to ontology classes\n    \n-   Perform automatic classification of classes and instances, using the HermiT or Pellet reasoner (included)\n    \n-   Load DBpedia or UMLS (for medical terminology, using the integrated PyMedTermino2 submodule)\n    \n-   Native support for optimized SPARQL queries\n    \n-   Tested up to 1 billion of RDF triples! (but can potentially support more)\n    \n-   In addition, the quadstore is compatible with the RDFlib Python module\n    \n-   Finally, Owlready2 can also be used as an ORM (Object-Relational mapper) – as a graph/object database, it beats Neo4J, MongoDB, SQLObject and SQLAlchemy in terms of performances","n":0.084}}},{"i":2525,"$":{"0":{"v":"Owlbear Rodeo","n":0.707},"1":{"v":"\n- [[c.software.rpg.virtual-tabletop]]\n- url: https://www.owlbear.rodeo/\n\n## [[c.model.conceptual]]\n\n- Rooms: a space to connect to your players\n- Scenes: A scene is an infinite space for you to lay out images, drawings, fog and more. \n\n## Features\n\n- [[c.extension]]SDK! \n  - [[c.requirement]] [[prdct.node]]\n\n## User Stories\n\n### simple map sharing is enough\n\n(with a good DM)\n\n![[prdct.dndbeyond#dndbeyond-works-with-owlbear]]","n":0.146}}},{"i":2526,"$":{"0":{"v":"OWLAx","n":1},"1":{"v":"\n- [[c.software.plugin.protege]]","n":0.707}}},{"i":2527,"$":{"0":{"v":"OWLAPI","n":1},"1":{"v":"\n- #writtenIn java\n- repo: https://github.com/owlcs/owlapi\n- ","n":0.447}}},{"i":2528,"$":{"0":{"v":"Owl","n":1},"1":{"v":"\n\n- url: https://www.w3.org/OWL/\n\n## description:\n\n- OWL 2 ontologies themselves are primarily exchanged as RDF documents\n  - i.e., the RDF-Based Semantics\n  - but there's also direct semantics, looks like `Declaration(Class(:Person))`\n- OWL-Lite is the least expressive sub-langauge. OWL-Full is the most expressive sub-language. The expressiveness of OWL-DL falls between that of OWL-Lite and OWL-Full. \n \n### Semantics\n\n- The Direct Semantics [OWL 2 Direct Semantics] and the RDF-Based Semantics [OWL 2 RDF-Based Semantics] provide two alternative ways of assigning meaning to OWL 2 ontologies, with a correspondence theorem providing a link between the two.\n  - The Direct Semantics assigns meaning directly to ontology structures, resulting in a semantics compatible with the model theoretic semantics of the [[prdct.sroiq]] description logic\n\n## Highlights\n\n- OWL ontologies can use the preexisting OWL attribute owl:versionInfo to store version information.\n\n## Cons\n\n- since OWL does not have dynamic classification, a person will be classified as an employee regardless of whether they have a current or past employment. Temporal properties of the employment will reflect whether employment is past.\n  - related: [[ar.sapphire-generating-java-runtime-artefacts-from-owl-ontologies]]\n-  A second major feature that proves troublesome is the monotonic nature of the inheritance of imported information. The ability to import other ontologies is crucial to supporting reuse of information. But all such inheritance is monotonic—in other words, new information can be added, but none of the existing information can be retracted or overridden. This makes it imperative that one make sure that all assertions are made at the proper level in the inheritance structure. If assertions are added at too low a level, then no sharing takes place. If made too high up, then the information cannot be removed, which can limit the ability to share knowledge and settings. It is difficult, even for experienced users, to decide where new knowledge should be created.\n   -  The monotonic requirement also makes it impossible to have actual default values, since any such value could not be removed. We are able to avoid that problem through the use of meta-annotations that associate default values not with the individuals, but instead attach them to the properties themselves.\n- [[ar.topquadrant.why-i-dont-use-owl-anymore]]\n\n## Related\n\n- [[prdct.mod-ontology]]\n- [[prdct.shacl]]\n\n## References\n\n- [When owl:sameAs isn’t the Same: An Analysis of Identity\nLinks on the Semantic Web](https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=B68E7B90BD3F8C5DAA756255722B7E78?doi=10.1.1.451.7903&rep=rep1&type=pdf)\n- [[ar.enterprise-knowledge.top-5-tips-for-managing-and-versioning-an-ontology]]\n- https://www.w3.org/TR/owl2-profiles/\n- [[ar.a-common-ground-for-virtual-humans]]\n- https://www.w3.org/TR/owl2-overview/","n":0.052}}},{"i":2529,"$":{"0":{"v":"tOWL","n":1},"1":{"v":"\n## Description\n\n- Fransincar et al. proposed an extension of the OWL-DL language, called tOWL [49], for representing time and changes in an ontology. tOWL uses a subset of OWL-DL whose foundation is the logic SHIN (D). This logic is sufficiently expressive and is decidable for a sound and complete reasoning algorithm [45]. The time domain of tOWL handles both instants and intervals that are modeled by rational numbers and a set of partial order relations over them. As a result, an actual time instant, an interval or Allen’s temporal relations [4] are all converted to rational number-based equivalent instants or relations.  ^927zza20f03z\n- For modeling changing values, tOWL employs the 4D Fluents model, i.e., perdurantist’s view [73]. tOWL is conceptualized as a layered approach. The foundation layer is OWL-DL and the extended concrete domain is the second layer. Time representation is at the third layer, which is defined by the concrete domain.\n- Figure 3.7 gives the running example in tOWL. Note that tOWL requires separate intervals for :John and :SW. Therefore, a restriction on the equivalence of towl:interval1 and towl:interval2 is enforced by a relation towl:equal in Figure 3.7 which is one more triple used compared to 4D Fluents model in [73].\n![](/assets/images/2024-10-25-02-30-44.png)\n- In tOWL, the time domain is based on rational numbers and relations over them. This approach makes tOWL more expressive in representing complex temporal relations. For instance, in Figure 3.7, a temporal constraint towl:interval1 equates towl:interval2 can be expressed with the equality of endpoints of the two intervals.\n- OWL reduces the proliferation of objects by differentiating types of fluents as FluentObjectProperty and FluentDatatypeProperty. For a Fluent- DatatypeProperty, which relates a time slice to a typed value, three triples can be saved due to that the time slice is not needed for a typed value. ^b8t2dt9958m2\n\n## References\n\n- [[ar.valid-time-rdf]]","n":0.058}}},{"i":2530,"$":{"0":{"v":"OWL RL","n":0.707},"1":{"v":"\n\n## Limitations\n\n- OWL 2 RL supports all axioms of OWL 2 apart from disjoint unions of classes (DisjointUnion) and reflexive object property axioms (ReflexiveObjectProperty).\n\n## References\n\n- https://www.w3.org/TR/owl2-profiles/#Feature_Overview_3","n":0.196}}},{"i":2531,"$":{"0":{"v":"OWL 2 QL","n":0.577},"1":{"v":"\n- https://www.w3.org/TR/owl2-profiles/#OWL_2_QL\n\n\n## Features\n\n- Basing OWL 2 QL on DL-LiteR avoids practical problems involved in the explicit axiomatization of Unique Naming Assumption. Other variants of DL-Lite can also be supported on top of OWL 2 QL, but may require additional restrictions on the structure of ontologies.\n\n## References\n\n- [[ar.temporalising-owl-2-ql]]","n":0.146}}},{"i":2532,"$":{"0":{"v":"Manchester Syntax","n":0.707},"1":{"v":"\n- https://www.w3.org/TR/owl2-manchester-syntax/\n","n":0.707}}},{"i":2533,"$":{"0":{"v":"OWL Full","n":0.707},"1":{"v":"\n\n\n## References\n\n- [[ar.pellet-an-owl-reasoner]]\n- [[vs.owl-vs-kif#cant-owl-full-accomodate-properties-of-properties-classes-of-classes-and-classes-as-instances-of-other-classes-aka-metaclasses]]","n":0.5}}},{"i":2534,"$":{"0":{"v":"OWL-DL","n":1},"1":{"v":"\n## Gotachas\n\n- The sets of object properties, datatype properties, annotation properties and ontology properties must be mutually disjoint. Thus, in OWL DL dc:creator cannot be at the same time a datatype property and an annotation property.\n  - ? so you would use an alternate suffix? Guessing that prefixing can work for single resources\n  - lacks direct support for meta-modeling\n\n\n## Effective Use\n\n### Insight 1: Concept vs Aspect\n\nOWL defines a thing called Class; a Class is a set of individuals. We use Class to define things like Requirement and Interface. Although it’s implicit, what we mean when we define classes like Requirement and Interface is that nothing can be both a Requirement and an Interface. In OWL, if that’s what you mean, you have to say it, either explicitly\n\n```\nDisjointClasses(:Requirement :Interface)\n```\n\nor implicitly via incompatible constraints.\n\nWe also use Class to define things like IdentifiedThing and AggregatedThing. In this case we do not mean that nothing can be both; it makes perfect sense for an aggregate to have an identifier. OWL gives us the low-level tools to distinguish between these use cases, but in practice it is tedious and error-prone to manage large taxonomies with only low-level tools.\n\nIn our practice we distinguish between what we call a Concept (e.g., Requirement, Interface) and what we call an Aspect (e.g. IdentifiedThing, AggregatedThing). For Concepts we apply a disjointness management policy that generates disjointness axioms by machine reasoning. For Aspects we do not. Formalizing this distinction has dramatically reduced the effort and error risk of managing taxonomies.\n\nWe have five such distinct use cases for OWL Class.\n\n### Insight 2: Object Property Reification\n\nIn OWL we can say a camera acquires an image like this\n\n```\nObjectPropertyAssertion(:acquires :camera :image)\n```\n\nThe assertion itself has no identity, which means we can’t say anything about it. It would be useful, however to be able to express “Requirement _R.x.y_ specifies that the camera shall acquire an image”, i.e., to state a functional requirement. It’s possible, using a technique called reification, to create a named individual to represent the condition that the camera acquires an image in such a way that implies the assertion above–in which a reasoner will conclude that. Because the reification itself has an identity, and we can make that the target of another assertion like this\n\n```\nObjectPropertyAssertion(:specifies :R.x.y :camera_acquires_image)\n```\n\nThis reification technique is extremely useful and we have incorporated it into our practice; nearly every relationship is reified.\n\nThere’s nothing particularly deep about reification. It’s using the standard expressivity of OWL in a repeatable pattern to convey the meaning we want. But it is, again, tedious and error-prone to do manually.\n\n## References\n\n- https://www.opencaesar.io/blog/2021/06/19/OML-Origin-and-Rationale.html","n":0.049}}},{"i":2535,"$":{"0":{"v":"Owl Time","n":0.707},"1":{"v":"\n## Highlights\n\n- \"A set of ordered intervals (e.g. named dynasties, geological periods, geomagnetic reversals, tree rings) can make a simple form of temporal reference system that supports logical reasoning, known as an ordinal temporal reference system [iso19108].\" \n- Four classes in the ontology support an explicit description of temporal position. `[:TemporalPosition](https://www.w3.org/TR/owl-time/#time:nominalPosition#time:TemporalPosition)` is the common super-class, with a property `[:hasTRS](https://www.w3.org/TR/owl-time/#time:nominalPosition#time:hasTRS)` to indicate the temporal reference system in use. `[:TimePosition](https://www.w3.org/TR/owl-time/#time:nominalPosition#time:TimePosition)` has properties to alternatively describe the position using a number (i.e. a temporal coordinate), or a nominal value (e.g. geologic time period, dynastic name, archeological era)\n- [[prdct.vocab-owl-time-agg]]'s temporal aggregate seems like it could capture \n\n\n### Topological Temporal Relations\n\n- 'The basic structure of the ontology is based on an algebra of binary relations on intervals (e.g., meets, overlaps, during) developed by Allen \\[[al-84](https://www.w3.org/TR/owl-time/#topology#bib-al-84 \"Towards a general theory of action and time. Artificial Intelligence 23, pp. 123-154.\")\\], \\[[af-97](https://www.w3.org/TR/owl-time/#topology#bib-af-97 \"Actions and events in interval temporal logic In: Spatial and Temporal Reasoning. O. Stock, ed., Kluwer, Dordrecht, Netherlands, pp. 205-245.\")\\] for representing qualitative temporal information, and to address the problem of reasoning about such information.\n\nThe ontology starts with a class `[:TemporalEntity](https://www.w3.org/TR/owl-time/#topology#time:TemporalEntity)` with properties `[:hasBeginning](https://www.w3.org/TR/owl-time/#topology#time:hasBeginning)` and `[:hasEnd](https://www.w3.org/TR/owl-time/#topology#time:hasEnd)` that link to the temporal instants that define its limits, and `[:hasTemporalDuration](https://www.w3.org/TR/owl-time/#topology#time:hasTemporalDuration)` to describe its extent. There are two subclasses: `[:Interval](https://www.w3.org/TR/owl-time/#topology#time:Interval)` and `[:Instant](https://www.w3.org/TR/owl-time/#topology#time:Instant)`, and they are the only two subclasses of `[:TemporalEntity](https://www.w3.org/TR/owl-time/#topology#time:TemporalEntity)`. Intervals are things with extent. Instants are point-like in that they have no interior points, but it is generally safe to think of an instant as an interval with zero length, where the beginning and end are the same.\n\nThis idea - that time intervals are the more general case and time instants are just a limited specialization - is the first key contribution of Allen's analysis.\n\nThe class `[:Interval](https://www.w3.org/TR/owl-time/#topology#time:Interval)` has one subclass `[:ProperInterval](https://www.w3.org/TR/owl-time/#topology#time:ProperInterval)`, which corresponds with the common understanding of intervals, in that the beginning and end are distinct, and whose membership is therefore disjoint from `[:Instant](https://www.w3.org/TR/owl-time/#topology#time:Instant)`.'\n\n##  Issues\n\n- annotations only, no temporal reasoning intended [^1]\n- suffers from class-as-instance modelling confusion [^1]\n- ambiguity problems, see [[ar.modelling-time-within-a-strongly-typed-database#^rpdqex91m56q]]\n\n### what are OWL-Time's notorious ambiguity problems\n\n@chatgpt.4: \n\nOWL-Time, part of the Semantic Web technology stack, is an ontology for describing the temporal content of web pages and the temporal properties of web services. It's designed to facilitate the use of time and temporal relations in RDF (Resource Description Framework) and OWL (Web Ontology Language) applications. However, like many complex ontologies, OWL-Time has its share of ambiguity issues, which can cause problems in its implementation and interpretation. Some of these issues include:\n\n    Granularity and Precision: OWL-Time can represent time at various granularities, from years down to seconds or finer. However, ambiguities can arise when different parts of a system or dataset use different granularities or when there's a need to convert or compare times across different granularities. The precision of time representation can also be a source of ambiguity, especially in historical data or future projections.\n\n    Time Zones and Localization: Time zone handling is a complex aspect of time representation. OWL-Time does not inherently resolve issues related to time zones, daylight saving time, or localization. This can lead to ambiguities when interpreting the exact moment an event occurred, especially in systems that are distributed across multiple time zones.\n\n    Temporal Relations: OWL-Time defines a range of temporal relations (such as before, after, during, overlaps), but the interpretation of these relations can be ambiguous without clear context. For example, determining whether an event \"during\" another means it encompasses the entire duration of the other event or just a part of it can be unclear.\n\n    Open vs. Closed Intervals: In OWL-Time, an interval can be defined with start and end times. However, there can be ambiguity about whether these intervals are open (excluding the start and end points) or closed (including them). This distinction can be crucial in some applications.\n\n    Temporal Reference Systems: OWL-Time allows for the definition of various temporal reference systems (like Gregorian calendar, Julian days, etc.). However, ambiguities can arise when converting or comparing dates across different systems, or when systems have different ways of handling leap years, leap seconds, etc.\n\n    Vagueness in Temporal Descriptions: Natural language descriptions of time are often vague (e.g., \"in the morning,\" \"soon,\" \"recently\"). Representing these concepts in a structured format like OWL-Time can be challenging and lead to ambiguities in interpretation.\n\n    Integration with Non-temporal Data: Combining temporal data with non-temporal data can sometimes lead to ambiguities, especially when the temporal aspects are not explicitly defined or are defined using different standards or formats.\n\nAddressing these ambiguities often requires additional context, clear definitions of terms, and sometimes custom extensions or interpretations of the OWL-Time ontology to fit specific use cases. In many practical applications, it's crucial to document how these ambiguities are resolved to ensure consistent understanding and processing of temporal data.\n\n\n## References\n\n[^1]: [[book.an-introduction-to-ontology-engineering-keet#^k691d5r7ug82]]","n":0.036}}},{"i":2536,"$":{"0":{"v":"OWL-T,","n":1},"1":{"v":"\n- [[c.ontology.mid]]","n":0.707}}},{"i":2537,"$":{"0":{"v":"OWL-S","n":1},"1":{"v":"\n- related: [[prdct.fno]]","n":0.577}}},{"i":2538,"$":{"0":{"v":"Owl Rl Reasoner","n":0.577},"1":{"v":"\n- https://www.ldf.fi/service/owl-rl-reasoner\n- based-on: [[prdct.owlrl-python]]","n":0.5}}},{"i":2539,"$":{"0":{"v":"Owl Reasoner JS","n":0.577},"1":{"v":"\n- ","n":1}}},{"i":2540,"$":{"0":{"v":"Overseer","n":1},"1":{"v":"\n- [[t.cs.entity-component-system]]\n- repo: https://github.com/louisponet/Overseer.jl","n":0.5}}},{"i":2541,"$":{"0":{"v":"Overseer Jl","n":0.707},"1":{"v":"\n- ","n":1}}},{"i":2542,"$":{"0":{"v":"Ostrich","n":1},"1":{"v":"\n- https://github.com/rdfostrich/ostrich\n- [[c.software.database.graph.rdf]]\n- uses: [[prdct.hdt]]","n":0.447}}},{"i":2543,"$":{"0":{"v":"Oslc","n":1},"1":{"v":"\n- dead-ish\n- https://open-services.net/\n\n## References\n\n- https://open-services.net/resources/oslc-primer/","n":0.447}}},{"i":2544,"$":{"0":{"v":"Osds","n":1},"1":{"v":"\n- [[c.Software.Browser.Extension]]\n- https://osds.openlinksw.com/\n- keywords: [[prdct.rdf.rdfa]]\n- supports: [[t.cs.semantic-web.linked-data-platform]]","n":0.378}}},{"i":2545,"$":{"0":{"v":"Oscova","n":1},"1":{"v":"\n- [[c.software.ai.bot-framework]] [[c.software.ai.speech-recognition]]\n- related: [[prdct.siml]]\n- written_in: c#\n\n## Resources\n\n- https://developer.syn.co.in/tutorial/bot/oscova/index.html","n":0.333}}},{"i":2546,"$":{"0":{"v":"Osbrain","n":1},"1":{"v":"\n- [[c.software.agent-framework]]\n- #dead\n- #docs https://osbrain.readthedocs.io/\n- repo: https://github.com/opensistemas-hub/osbrain","n":0.378}}},{"i":2547,"$":{"0":{"v":"OSBP","n":1},"1":{"v":"\n- url: https://projects.eclipse.org/projects/technology.osbp\n- #related [[prdct.os-bee]]","n":0.447}}},{"i":2548,"$":{"0":{"v":"OS.bee","n":1},"1":{"v":"\n- url: https://www.osbee.org\n- [[p.builtOn]] [[prdct.vaadin]] [[prdct.birt]] [[prdct.mxgraph]]","n":0.378}}},{"i":2549,"$":{"0":{"v":"Ory","n":1},"1":{"v":"\n- pricing: from $70/mo\n\n## Architecture\n\n-   Ory Kratos is an identity management server.\n-   Ory Hydra is an OAuth 2.0 and OpenID Connect provider.\n-   Ory Oathkeeper is an Identity and Access Proxy.\n-   Ory Keto is an access control server.\n\n![](/assets/images/2024-04-14-12-32-07.png)\n\n## References\n\n- https://www.ory.sh/docs/ecosystem/projects","n":0.16}}},{"i":2550,"$":{"0":{"v":"Orleans","n":1},"1":{"v":"\n- [[c.software.distributed-systems-runtime]]\n- #summary https://learn.microsoft.com/en-us/dotnet/orleans/overview\n  - [[p.hasHighlight]]\n    - based on [[t.cs.actors]]\n- [[p.hasConcept]] \n  - [[t.cs.actors.virtual]]\n    - [[p.represented]] as [[t.cs.actors.grain]]\n  - [[prdct.orleans.silo]]\n- description: Instead of building a monolith, or a services-based architecture where the services are statically provisioned, it allows you to decompose your application into lots of small, stateful services that can be provisioned dynamically when you need them.\n\n## Use Cases\n\nOrleans should be considered when:\n\n-   Significant number (hundreds, millions, billions, and even trillions) of loosely coupled entities. To put the number in perspective, Orleans can easily create a grain for every person on Earth in a small cluster, so long as a subset of that total number is active at any point in time.\n    -   Examples: user profiles, purchase orders, application/game sessions, stocks.\n-   Entities are small enough to be single-threaded.\n    -   Example: Determine if the stock should be purchased based on the current price.\n-   Workload is interactive.\n    -   Example: request-response, start/monitor/complete.\n-   More than one server is expected or may be required.\n    -   Orleans runs on a cluster that is expanded by adding servers to expand the cluster.\n-   Global coordination is not needed or on a smaller scale between a few entities at a time.\n    -   Scalability and performance of execution are achieved by parallelizing and distributing a large number of mostly independent tasks with no single point of synchronization.\n\n## Examples\n\n- https://learn.microsoft.com/en-us/dotnet/orleans/tutorials-and-samples/\n\n## Resources\n\n- https://www.infoq.com/articles/project-orleans-actor-based/\n\n## [[p.hasLearningResource]]\n\n- [Adventure game sample project | Microsoft Learn](https://learn.microsoft.com/en-us/dotnet/orleans/tutorials-and-samples/adventure)\n- [stack overflow: Orleans slow with minimalistic use case](https://stackoverflow.com/questions/74310628/orleans-slow-with-minimalistic-use-case)\n- [Building a realtime server backend using the Orleans Actor system, Dotnet Core and Server-side Redux](https://medium.com/@MaartenSikkema/using-dotnet-core-orleans-redux-and-websockets-to-build-a-scalable-realtime-back-end-cd0b65ec6b4d)","n":0.063}}},{"i":2551,"$":{"0":{"v":"Silo","n":1}}},{"i":2552,"$":{"0":{"v":"Indexing","n":1},"1":{"v":"\n- url: https://github.com/OrleansContrib/Orleans.Indexing\n- [[c.timeperiod]]","n":0.5}}},{"i":2553,"$":{"0":{"v":"Orkes Conductor","n":0.707},"1":{"v":"\n- repo: https://github.com/orkes-io/orkes-conductor-community\n- different_from: https://github.com/danielgerlag/conductor\n- dependency: [[prdct.mongodb]]","n":0.378}}},{"i":2554,"$":{"0":{"v":"Orientdb","n":1},"1":{"v":"\n- [[p.forkedInto]] [[prdct.arcadedb]]","n":0.577}}},{"i":2555,"$":{"0":{"v":"Ordered Turtle Serializer","n":0.577},"1":{"v":"\n- https://github.com/scriptotek/otsrdflib\n- dead\n- written-in: python\n\n## Features\n\n- classes are ordered alphabetically by their URIs.\n  - custom order can be imposed by adding classes to the class_order attribute. For a SKOS vocabulary, for instance, you might want to sort the concept scheme first, followed by the other elements of the vocabulary\n- instances of a class are ordered alphabetically by their URIS.\n  - custom order can be imposed by defining functions that generate sort keys from the URIs. For instance, you could define a function that returns the numeric last part of an URI to be sorted numerically\n- ","n":0.103}}},{"i":2556,"$":{"0":{"v":"OrbitDB","n":1}}},{"i":2557,"$":{"0":{"v":"Opus","n":1},"1":{"v":"\n- url: https://opus.ai/\n- ","n":0.577}}},{"i":2558,"$":{"0":{"v":"OpenXR","n":1},"1":{"v":"\n- [[p.publishedBy]] [[org.khronos-group]]\n- [[p.supportedBy]]\n  - [[prdct.godot]]\n    - https://github.com/GodotVR/godot_openxr\n  - [[prdct.unity]] \n  - [[prdct.unreal]] \n  - [[prdct.blender]]","n":0.25}}},{"i":2559,"$":{"0":{"v":"openWEMI","n":1},"1":{"v":"\n- https://github.com/kcoyle/openWEMI\n#awesome\n- [[c.ontology.creative-work]]\n- aka: Created Work Ontology, CWO\n\n## Background\n\n-   **Work**: The idea or concept plane (“has concept/is concept”)\n-   **Expression**: The plane of signs or signifiers (“has signs/is signs”)\n-   **Manifestation**: The physical plane (“has physicality/is physical”)\n-   **Item**: The location plane (“has location/is located”)\n\n- \"a 4-entity model of metadata that could be applied to every library catalog entry. Work is the most abstract layer that represents the conceptual aspect of a creation. Expression is a perceptible version using some form of communication like text, sound, or a visual display. Manifestation is the realization, which can be a manufactured product in multiple copies or a single object. Item is an individual instance of the creation, often having a location in the world, including electronic locations.\"\n- includes the superclass Endeavor, which is not part of the FRBR group of entities but was added by the authors of FRBR core.\n\n## Resources\n\n- [[ar.works-expressions-manifestations-items-an-ontology]]","n":0.082}}},{"i":2560,"$":{"0":{"v":"OpenUSD","n":1},"1":{"v":"\n- url: https://openusd.org\n- repo: https://github.com/PixarAnimationStudios/OpenUSDo","n":0.447}}},{"i":2561,"$":{"0":{"v":"OpenTSDB","n":1}}},{"i":2562,"$":{"0":{"v":"OpenTelemetry","n":1},"1":{"v":"\n\n\n- resources:  \n  - https://newrelic.com/blog/best-practices/what-is-opentelemetry\n","n":0.447}}},{"i":2563,"$":{"0":{"v":"OpenSimulator","n":1},"1":{"v":"\n- [[c.software.virtual-reality]]\n- url: opensimulator.org\n- repo: https://github.com/opensim/opensim\n- written-in: c#\n- #license [[lic.bsd]]\n- [[p.supports]] [[t.cs.languages.linden]]","n":0.289}}},{"i":2564,"$":{"0":{"v":"Opensearch","n":1},"1":{"v":"\n- [[p.hasURL]] https://opensearch.org/\n\n## [[p.hadDescription]]\n\n- [[p.hasComponent]]\n  - data store and search engine (OpenSearch)\n  - visualization and user interface (OpenSearch Dashboards)\n  - plugins that enhance search, security, performance analysis, machine learning, and more","n":0.18}}},{"i":2565,"$":{"0":{"v":"OpenRPC","n":1},"1":{"v":"\n- url: https://open-rpc.org\n- repo: https://github.com/open-rpc/spec\n- [[c.software.generator]] \n  - https://gitlab.com/mburkard/openrpc-client-generator\n  - https://github.com/open-rpc/generator-client","n":0.302}}},{"i":2566,"$":{"0":{"v":"OpenNLP","n":1},"1":{"v":"\n- url: https://opennlp.apache.org/\n- ","n":0.577}}},{"i":2567,"$":{"0":{"v":"OpenMetadata","n":1},"1":{"v":"\n- [[c.software.data-discovery]]\n- url: https://open-metadata.org/\n- written_in: typescript java python\n\n## Features\n\n- developer-friendly, API-driven approach that using JSON\n\n## Issues\n\n- \"Where I could see OpenMetadata improving is moving towards developing more features aimed at data lineage. We’re seeing a lot of awesome lineage work being done by OpenLineage and DataHub.\" (as of 2021-10)\n- \"not yet as feature rich as Amundsen or DataHub, I am impressed with how OpenMetadata is taking a developer-friendly approach to the metadata store.\"\n\n## References\n\n- https://medium.com/cisco-fpie/why-openmetadata-is-taking-the-right-approach-to-metadata-cataloging-964187c331fd","n":0.115}}},{"i":2568,"$":{"0":{"v":"Openmeta","n":1},"1":{"v":"\n- https://www.openmeta.xyz/ ^12arde7m6sfn","n":0.577}}},{"i":2569,"$":{"0":{"v":"OpenLiberty","n":1},"1":{"v":"\n- https://openliberty.io/","n":0.707}}},{"i":2570,"$":{"0":{"v":"Openfire","n":1},"1":{"v":"\n- [[c.software.xmpp-server]]\n- repo:\n- written-in: java","n":0.447}}},{"i":2571,"$":{"0":{"v":"Openfaas","n":1},"1":{"v":"\nurl: https://www.openfaas.com/\n","n":0.707}}},{"i":2572,"$":{"0":{"v":"openCypher","n":1},"1":{"v":"\n- #aka Cypher\n- url: https://opencypher.org/\n- [[c.list.implementations]] https://opencypher.org/projects/","n":0.378}}},{"i":2573,"$":{"0":{"v":"Opencv","n":1},"1":{"v":"\n- url: https://opencv.org/","n":0.577}}},{"i":2574,"$":{"0":{"v":"OpenCog","n":1},"1":{"v":"\n\n- [[p.hasComponent]] [[prdct.atomspace]]\n\n## Issues\n\n- \"OpenCog's Probabilistic Logic Networks and AtomSpace sounded promising - until we investigated them. We found a lot of broken code that didn't integrate well with the world of Deep learning.\"\n  - [[ar.linkedin.semantics-mans-search-computational-meaning-joshua-reuben]]","n":0.167}}},{"i":2575,"$":{"0":{"v":"Rocca","n":1},"1":{"v":"\n- Rational OpenCog Controlled Agent, or ROCCA, is a project aiming at creating an opencog agent that acts rationally in OpenAI Gym environments (including [[prdct.minecraft]] via MineRL and Malmo).","n":0.186}}},{"i":2576,"$":{"0":{"v":"MOSES","n":1},"1":{"v":"\n\n- [[p.hadDescription]]  program evolution, based on representation-building and probabilistic modeling\n- https://wiki.opencog.org/w/Meta-Optimizing_Semantic_Evolutionary_Search\n- [[p.hasTopic]] [[t.cs.machine-learning.deme]]","n":0.277}}},{"i":2577,"$":{"0":{"v":"Link Grammar","n":0.707},"1":{"v":"\nrepo: https://github.com/opencog/link-grammar\n\n- [-] brainstorm ways LG could be used for knowledge representation\n\n## Features\n\n- As of version 5.9.0, the system include an experimental system for generating sentences. \n\ndocs: \n\n## [[c.mention]]\n\n- [[book.homotopy-type-theory]]\n\n## Resources\n\n- [[ar.an-introduction-to-the-link-grammar-parser]]\n- http://www.abisource.com/projects/link-grammar/dict/summarize-links.html\n- https://www.link.cs.cmu.edu/link/dict/introduction.html#1 ","n":0.171}}},{"i":2578,"$":{"0":{"v":"Learn","n":1},"1":{"v":"\n- a \"chair\" is both a collection of all \"facts\" one might know about chairs, as well as an English word participating in the complex grammatical network of the English language. The word \"chair\" is not so much a \"symbol\" as it is a bridge between these complex networks... the goal of this project is to not only learn what a \"chair\" is from environmental stimulous, and not only learn how to use the word \"chair\" in a grammatical sentence, but also to learn the rules of logic, and the rules of common sense reasoning, out of thing air.\n- The way in which regions of graphs look locally similar can be described by a grammar. The way they connect is a syntax.\n- If you are writing text, what you are \"actually doing\" is taking the network of interconnected facts/ideas, and serializing them into a sequence of words. A sequential, time-like order, one word after another. You serialize the graph of ideas.\n- In a text, there is both a small-scale structure, and a large scale structure. The small scale structure consists of grammatically-correct sentences written in some natural language. The large-scale structure is determined by the type of the text: is it a short story? A dissertation? An owner's manual? The large scale flows from sentence to sentence, paragraph to paragraph, as repeating ideas, characters, topics, themes reoccur throughout the text\n- all work must be done in a single, common framework, that makes it easy to collect statistical information from a large variety of sources. A place where the statistical analysis is easy. A place where inference can be automated. A place where rules can be defineed, generically, and lanuched, generically. That single location is, for me, the [[AtomSpace|prdct.atomspace]]","n":0.059}}},{"i":2579,"$":{"0":{"v":"Hyperon","n":1},"1":{"v":"\n- url: https://wiki.opencog.org/w/Hyperon\n- #related [[prdct.singularitynet]]","n":0.447}}},{"i":2580,"$":{"0":{"v":"Metta","n":1},"1":{"v":"\n- url: https://wiki.opencog.org/w/Hyperon:Atomese\n- [[p.hasSpecification]] https://wiki.opencog.org/wikihome/images/b/b7/MeTTa_Specification.pdf\n- similar-to: [[prdct.typeql]]\n\n## Features\n\n- intended both for humans to script portions of AGI cognitive processes, and for the programming activity of AGI-related learning and reasoning algorithms themselves.\n- combine elements of functional, logical and process-calculus-based programming\n- Each MeTTa program is represented as a subgraph of an Atomspace metagraph, and carries out its business centrally by querying and rewriting portions of Atomspaces.\n- handles highly abstract constructs like run-time self-modifying code simply and naturally, but is also designed for efficiency both in running its own natively implemented AGI-related algorithms, and in interfacing with external processes\n\n## Resources\n\n- https://singularitynet.zoom.us/rec/play/gFBS-rmEVTGOFH-gstIX4MLRxnRiUOlcdPtRPCmiM3lrEe4e-q0A-OpPE18z3z-dlCyhFHnXzEGbnu_o.4bOnS37_VFqGdH_s?canPlayFromShare=true&from=share_recording_detail&startTime=1650636238000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fsingularitynet.zoom.us%2Frec%2Fshare%2FVqHmU37XtbS7VnKY474tkTvvTglsgOIfsI-21MXWxVm_in7U3tGPcfjjiE0P_15R.yUwPdCzEONSUx1EL%3FstartTime%3D1650636238000\n  - ugh","n":0.1}}},{"i":2581,"$":{"0":{"v":"Generate","n":1},"1":{"v":"\n- repo: https://github.com/opencog/generate","n":0.577}}},{"i":2582,"$":{"0":{"v":"OpenCL","n":1},"1":{"v":"\n- [[p.publishedBy]] [[org.khronos-group]]","n":0.577}}},{"i":2583,"$":{"0":{"v":"openCAESAR","n":1},"1":{"v":"\n- https://www.opencaesar.io/oml-tutorials/\n- [[c.Software.Tools.Modeling]] [[c.software.semantic.ontology-editor]] [[c.methodology.ontology-engineering]]\n- related: [[prdct.ontology-modeling-language-oml]] [[prdct.oml-luxor]] [[prdct.ontology-modeling-language-oml]]\n\n![](/assets/images/2024-08-20-11-52-13.png)\n\n## Description\n\n- allows engineers to directly specify their knowledge as ontologies with precise syntax and semantics, without the usual incidental complexity found in semantic web technologies and tools [^8]\n- enabling systems engineers to consider rigor and agility across seven systems engineering architectural functions: representation, authoring, federation, configuration, integration, analysis, and reporting\n\n## Features\n\n- supports closed-world reasoning!? \n  - see [[pub.question-log.2024.08.20.opencaesar-and-closed-world#how-does-opencaesaroml-support-closed-world-reasoning]]\n\n## Concepts\n\n- Vocabulary / Vocabulary bundle equivalent to ontology\n  - but creating a vocabulary bundle \"automatically asserts that classes in the bundled vocabularies that do not have common subtypes are disjoint (have no intersection), which helps detect a wide class of errors that would otherwise not get detected due to the open-world assumption\" !?\n- Description / Description bundle equivalent to instance data\n\n## Resources\n\n- https://www.opencaesar.io/oml-tutorials/\n- [[ar.ontological-metamodeling-and-analysis-using-open-caesar]]\n- https://www.opencaesar.io/blog/2023/09/02/Two-Unsatisfiable-Metaclasses-In-SysML-v2.html\n\n\n## References\n\n- [[ar.open-caesar-balancing-agility-and-rigor-in-model-based-systems-engineering]]\n  - \"Computer Aided Engineering for Spacecraft System Architecture\"\n[^8]: [[ar.ontology-building-for-cyber-physical-systems-application-in-the-manufacturing-domain]]","n":0.084}}},{"i":2584,"$":{"0":{"v":"Openapm","n":1},"1":{"v":"\n- url: https://openapm.io/","n":0.577}}},{"i":2585,"$":{"0":{"v":"OpenAPI","n":1},"1":{"v":"\n- aka: swagger\n- ","n":0.577}}},{"i":2586,"$":{"0":{"v":"OpenAPI Workflows Specification","n":0.577},"1":{"v":"\n- repo: https://github.com/OAI/sig-workflows","n":0.577}}},{"i":2587,"$":{"0":{"v":"Openai","n":1},"1":{"v":"\n- [[p.hasSolution]]\n  - [[prdct.openai.playground]]\n\n## Comparison\n\n- https://cloud.google.com/blog/products/api-management/understanding-grpc-openapi-and-rest-and-when-to-use-them","n":0.408}}},{"i":2588,"$":{"0":{"v":"Playground","n":1},"1":{"v":"\nurl: ","n":1}}},{"i":2589,"$":{"0":{"v":"Open5e","n":1},"1":{"v":"\n- [[c.software.game-service.data]]\n- url: https://open5e.com/\n- #api https://api.open5e.com/\n- repo: https://github.com/open5e/open5e-api\n![[prdct.5e-tools#^vt5y8u6whgr9]]\n\n\n## Examples\n\n```\n    {\n        \"name\": \"Acid Arrow\",\n        \"desc\": \"A shimmering green arrow streaks toward a target within range and bursts in a spray of acid. Make a ranged spell attack against the target. On a hit, the target takes 4d4 acid damage immediately and 2d4 acid damage at the end of its next turn. On a miss, the arrow splashes the target with acid for half as much of the initial damage and no damage at the end of its next turn.\",\n        \"higher_level\": \"When you cast this spell using a spell slot of 3rd level or higher, the damage (both initial and later) increases by 1d4 for each slot level above 2nd.\",\n        \"page\": \"phb 259\",\n        \"range\": \"90 feet\",\n        \"components\": \"V, S, M\",\n        \"material\": \"Powdered rhubarb leaf and an adder's stomach.\",\n        \"ritual\": \"no\",\n        \"duration\": \"Instantaneous\",\n        \"concentration\": \"no\",\n        \"casting_time\": \"1 action\",\n        \"level\": \"2nd-level\",\n        \"level_int\": 2,\n        \"school\": \"Evocation\",\n        \"class\": \"Druid, Wizard\",\n        \"archetype\": \"Druid: Swamp\",\n        \"circles\": \"Swamp\",\n        \"rolls-attack\": true\n    },\n    ```","n":0.078}}},{"i":2590,"$":{"0":{"v":"Open Policy Agent","n":0.577},"1":{"v":"\n- [[p.hasSite]] https://www.openpolicyagent.org/\n\n## [[p.hasLearningResource]]\n\n- https://blog.openpolicyagent.org/write-policy-in-opa-enforce-policy-in-sql-d9d24db93bf4\n  - [[!|p.hasHighlight]] \"To show how you can implement a library that converts a fragment of Rego into SQL WHERE clauses, we have prepared an example that includes a library. You can find the example on GitHub in the OPA contrib repository\"\n","n":0.147}}},{"i":2591,"$":{"0":{"v":"Open Link Structured Data Editor (OSDE)","n":0.408},"1":{"v":"\n- https://osde.openlinksw.com/\n- [[c.software.semantic.authoring]] \n- repo: https://github.com/openlink/rdf-editor\n- written-in: javascript","n":0.354}}},{"i":2592,"$":{"0":{"v":"Open DIS for JavaScript","n":0.5},"1":{"v":"\n\n\n- [[p.hasRepository]] https://github.com/open-dis/open-dis-javascript\n","n":0.577}}},{"i":2593,"$":{"0":{"v":"Open Cobalt","n":0.707},"1":{"v":"\n- #dead","n":0.707}}},{"i":2594,"$":{"0":{"v":"Open Biological Ontology","n":0.577},"1":{"v":"\n- #related [[prdct.basic-formal-ontology]]\n- #publisher [[prdct.obo-foundry]]","n":0.447}}},{"i":2595,"$":{"0":{"v":"Open Biological and Biomedical Ontology Foundry","n":0.408},"1":{"v":"\n- url: http://obofoundry.org/\n  ","n":0.577}}},{"i":2596,"$":{"0":{"v":"Onyx","n":1}}},{"i":2597,"$":{"0":{"v":"Ontowiki","n":1},"1":{"v":"\n- dead\n- repo: https://github.com/AKSW/OntoWiki\n- written_in: php","n":0.408}}},{"i":2598,"$":{"0":{"v":"OntoUML","n":1},"1":{"v":"\n- related: \n  - [[prdct.ontouml-vp-plugin]] \n  - https://ontouml.org/ (dead on arrival)\n  - https://dev.ontouml.org/ \"documentation for\"\n  - [[prdct.ontouml-ufo-catalog]]\n\n## Issues\n\n- difficult to translate into OWL, given meta-modeling\n\n## Theory\n\n### Identity Principle\n\n- needs to apply to everyone, e.g. no SSN\n- \"every individual must have exactly one. So, what is the identity principle for a person? One’s fingerprint, iris pattern, DNA? Well, it is really hard to define it, even though we know it is there.\"\n- Some types have the characteristic of providing identity principles for their instances. They are stereotype as: «Kind», «Collective», «Quantity», «Relator», «Mode» and «Quantity»\n- other types don’t provide identity principle for their instances, but they all share a common one. They are stereotyped as: «Subkind», «Role» and «Phase»\n- Some other types don’t provide identity and their instances follow different identity principles. They are stereotyped as: «RoleMixin», «Mixin» and «Category». Here are some examples:\n\n\n\n## Class Stereotypes\n\n### Kind\n\n- represent rigid concepts that provide an identity principle for their instances and do not require a relational dependency\n  - When we say that a «Kind» is relationally independent, we mean that it does not necessarily require a relation to be defined, like a «Role» does\n    - e.g. from [[prdct.software-requirements-reference-ontology-srro]]\n- represent a Functional Complex, i.e., a whole that has parts contributing in different ways for its functionality\n- e.g.: human body, forest, computer, key, car, organization\n\n### Subkind\n\n\n### Phase\n\n- an anti-rigid, sortal concept that applies to an entity during a particular stage or phase of its existence\n\n### Role\n\n\n### Collective\n\n\n### Quantity\n\n\n### Relator\n\n- \"The «Relator» construct is used to represent truth-makers of material relations, i.e., the “things” that must exist in order for two or more individuals to be connected by material relations. Because of this nature, relators are always dependent on other individuals to exist.\"\n- e.g.: Marriage, Investigation, Enrollment, Employment, Subscription\n- the «Relator» meta-class is analogous to the «Kind», «Collective» and «Quantity» meta-classes, in the sense that it is rigid and provides an identity principle for its instances.\n  - The difference is that, instead of representing functional complexes, quantities or collections, a «Relator» represents the objectification of relational properties\n  - relators can also be specialised by subkinds, phases and roles, and generalised by categories and mixins\n- A «Relator» must always be connected (directly or indirectly) to at least one relation stereotyped as «Mediation»\n- \"The sum of the minimum cardinalities of the opposite ends of the mediations connected (directly or indirectly) to the «Relator» must be greater or equal to 2.\"\n  - but why?\n\n\n\n### Category\n\n- a rigid mixin that does not require a dependency to be specified\n- abstract class that generalizes across multiple kinds.\n  - \"essential characteristics that are shared by different kinds but do not directly instantiate entities.\"\n\n### PhaseMixin\n\n- equivalent of «Phase» for types that aggregate instances with different identity principles\n- A class stereotyped as «PhaseMixin» is also an anti-rigid type\n- similar semantically to «RoleMixin» with the difference in relational dependency\n\n### RoleMixin\n\n- the equivalent of «Role» for types that aggregate instances with different identity principles\n- A class stereotyped as «RoleMixin» is also an anti-rigid type whose instantiation depends on a relational property\n- e.g.,: customer, provider, purchased, resource\n- usually occur in one of the two patterns:\n  - defined by roles\n  ![](/assets/images/2024-08-28-13-28-32.png)\n  - as a role of category\n  ![](/assets/images/2024-08-28-13-29-24.png)\n  - The second pattern is a more concise form of the first. They are semantically equivalent.\n- always abstract\n  - They define characteristics that apply across multiple kinds but are not directly instantiated.\n\n### Mixin\n\n\n### Mode\n\n\n### Quality\n\n\n\n## Relationship Stereotypes\n\n### Formal\n\n- short for Domain Comparative Formal Relation\n- represents relations that can be reduced to the comparison of the quality values that characterize the related individuals\n  - like heavier-then, younger-then or cheaper-then\n  - \n\n### Material\n\n- have material structure on their own and include examples such as employments, kisses, enrollments, flight, connections and commitments\n- Material relations are derived (via «Derivation») from relators and the mediation relations that connect them to the corresponding relata\n- several «Material» relations can be derived from a single «Relator» and «Mediation» relations\n\n### Mediation\n\n- a relation of «Mediation» between a «Relator» and the entities it connects\n- a type of existential dependence relation (a form of nonfunctional inherence)\n- can be derived from the relation between the relata and the qua individiuals that compose the relator and that inhere in the relata\n- must mediate at least two distinct individuals.\n\n### Characterization\n\n- a relation between a bearer type and its feature\n- Feature is intrinsic (inherent) moment of its bearer type, and thus existentially dependent on the bearer\n- Feature may be stereotyped as «Quality» or «Mode»\n- Feature characterizes a bearer type iff every instance of bearer exemplifies the feature.\n\n### Derivation\n\n\n### Structuration\n\n\n### Part-Whole\n\n\n### ComponentOf\n\n\n### Containment\n\n\n### MemberOf\n\n\n### SubCollectionOf\n\n\n### SubQuantityOf\n\n\n\n\n## References\n\n- [^1]: https://ontouml.readthedocs.io/en/latest/classes/sortals/relator/index.html\n- [[ar.using-a-trope-based-foundational-ontology-for-bridging-different-areas-of-concern-in-ontology-driven-conceptual-modeling]]\n- https://ontouml.readthedocs.io/en/latest/theory/identity.html#identity","n":0.036}}},{"i":2599,"$":{"0":{"v":"Ontouml Visual Paradigm Plugin","n":0.5},"1":{"v":"\n- https://github.com/OntoUML/ontouml-vp-plugin\n- plugin-for: [[prdct.visual-paradigm]]","n":0.5}}},{"i":2600,"$":{"0":{"v":"OntoUML/Ufo Catalog","n":0.707},"1":{"v":"\n- creator: @claudenir-fonseca\n\n## Description\n\n- metadata about every model and every distribution materializing it","n":0.277}}},{"i":2601,"$":{"0":{"v":"Ontouml Org Ontology","n":0.577},"1":{"v":"\n- http://web.archive.org/web/20171008152055/http://www.menthor.net/o3.html\n\n\n## References\n\n- [[ar.representing-organizational-structures-in-an-enterprise-architecture-language]]","n":0.5}}},{"i":2602,"$":{"0":{"v":"Ontouml Models","n":0.707},"1":{"v":"\n- https://scs-ontouml.eemcs.utwente.nl/\n- related: [[t.cs.data.fair]]\n\n## References\n\n- [A FAIR catalog of ontology-driven conceptual models](https://www.sciencedirect.com/science/article/pii/S0169023X23000708?via%3Dihub)","n":0.289}}},{"i":2603,"$":{"0":{"v":"Ontotext Platform","n":0.707},"1":{"v":"\n\n\n- makes use of [[prdct.graphdb]] ?\n","n":0.408}}},{"i":2604,"$":{"0":{"v":"Semantic Objects","n":0.707},"1":{"v":"\n- related: [[prdct.semantic-objects-modeling-language]]\n\n## Resources\n\n- [[ar.the-rise-of-the-knowledge-graph]]\n\n## References\n\n- https://platform.ontotext.com/semantic-objects/index.html","n":0.378}}},{"i":2605,"$":{"0":{"v":"Ontospec","n":1},"1":{"v":"\n## References\n\n- [[ar.integration-of-the-dolce-top-level-ontology-into-the-onto-spec-methodology]]","n":0.577}}},{"i":2606,"$":{"0":{"v":"OntoPortal","n":1},"1":{"v":"\n- https://ontoportal.org/\n- ","n":0.707}}},{"i":2607,"$":{"0":{"v":"OntoPop","n":1},"1":{"v":"\n- backend is open-source, frontend is closed\n\n## Vision\n\nThe goal of OntoPop is to democratize ontologies by making them easier to understand and more accessible to a broader range of users beyond information and data architects. By democratizing ontologies, OntoPop enables organisations and individuals to easily visualise, explore and semantically query their knowledge assets, data and relationships. \n\n## Design Principles\n\n### Interoperability\n\nEvery OntoPop service is developed using open standards and open frameworks and, as such, is agnostic of the target deployment environment meaning that OntoPop supports deployment to on-premise, private cloud, public cloud (including Amazon Web Services, Microsoft Azure and Google Cloud Platform), multi-cloud and/or hybrid environments, and supports integration with industry-standard middleware and other open software services.\n\n### Reusability\n\nGiven that OntoPop is a collection of event-driven services, each service may be reused beyond the specific purposes of ontology visualisation, search, exploration and management. For example, the OntoPop property graph services may be reused to load, manage and query general graph databases for a wide range of alternative use cases including fraud detection, digital twins, disease modelling, behavioural analysis, recommendation systems and natural language processing.","n":0.074}}},{"i":2608,"$":{"0":{"v":"Ontoology","n":1},"1":{"v":"\n- url: https://ontoology.linkeddata.es/\n- supports: [[prdct.widoco]] \n- related: [[prdct.w3id]] \n\n## Features\n\n- ability to publish an ontology with a [[prdct.w3id]] permanent identifier.\n\n## Examples\n\nhttps://raw.githubusercontent.com/dgarijo/VideoGameOntology/","n":0.218}}},{"i":2609,"$":{"0":{"v":"Ontomedia","n":1},"1":{"v":"- url: \n  - https://r4isstatic.com/linkeddata/ontologies/ontomedia/core/expression.owl\n  - https://web.archive.org/web/20051125100843/http://ontomedia.ecs.soton.ac.uk:80/ontologies/core/media\n  - https://r4isstatic.com/linkeddata/ontologies/ontomedia/ext/common/being.owl \n  - https://r4isstatic.com/linkeddata/ontologies/ontomedia/ext/fiction/char.owl\n  - https://r4isstatic.com/linkeddata/ontologies/ontomedia/misc/date.owl\n  - https://web.archive.org/web/20160501173107/https://r4isstatic.com/linkeddata/ontologies/ontomedia/\n- dead-urls:\n  - https://purl.archive.org/domain/ontomedia\n    - but references squatted contextus.net :(\n- similar: [[prdct.abc-ontology]]\n- creator: @faith-lawrence\n\n## Motivation\n\n- The OntoMedia project began as a convergence of three interests - the creation of metadata to describe the content of online amateur fiction, the identification of events in multimedia objects to seed external applications such as sound effects or automatic music generation and, finally, as a potential way of generating narrative\n- From that beginning it has expanded to describe narrative in media\n\n\n## Description\n\n- based on an Entity/Event system\n  - provides a natural divide between spatial and temporal information\n\n## Sections\n\n- **Core** The OntoMedia Core consists of three sub-ontologies: Expression, Media, and Space. Expression describes the primary elements of OntoMedia, namely Event and Entity, as well as their subclasses. Media provides binding classes to allow links between pieces of media and their associated Expression objects. Space is an extension of the Signage Location ontology[6], and specifies classes to describe buildings, and regions of both internal and external structures.\n- **Extensions** Where Core provides only the very basic classes, Extensions provides more detailed subclasses. This includes Being, to describe people, and a set of Trait classes to define attributes of entities.\n- **Events** The Events hierarchy extends the Event class from the Core to provide specialised events. This covers Action, Gain, Loss, Travel, and also additional properties for these extra types.\n- **Fiction** In order to provide specialist classes for fiction representation, this set of classes includes Character, which builds upon Being, and other properties to denote spoiler information and accuracy.\n- **Media** The Media class in Core only defines a basic MediaItem, so it is necessary to de- fine more detailed classes to describe specific media items. This hierarchy includes audio, image, photograph, textual, and video subclasses.\n- **Miscellaneous** Finally, the Miscellaneous set provides classes which may be used by any or all of the other classes. This includes colour information, name representation, and geometry\n[[SWOOP|prdct.swoop]]\n\n## Issues\n\n- namespace URI squatted, ontologies not available!?\n  - t.2024.10.03.12 found a reference in [[ar.a-comics-ontology]]\n\n## References\n\n- [[ar.ontomedia-creating-an-ontology-for-marking-up-the-contents-of-heterogeneous-media]]\n  - has snippets\n- [[ar.assessing-the-suitability-of-existing-owl-ontologies-for-the-representation-of-narrative-structures-in-sumerian-literature]]\n- [[ar.onto-media-an-ontology-for-the-representation-of-heterogeneous-media]]\n- [[ar.onto-media-creating-an-ontology-for-marking-up-the-contents-of-fiction-and-other-media]]\n- [[ar.annotation-of-multimedia-using-onto-media]]\n- https://www.r4isstatic.com/tag/semantic-weblinked-data-roots","n":0.053}}},{"i":2610,"$":{"0":{"v":"Cor","n":1},"1":{"v":"\n```xml\n\n<?xml version=\"1.0\"?>\n<!DOCTYPE owl [\n  ...\n  \n<!ENTITY base \"http://ontomedia.ecs.soton.ac.uk/ontologies/core/expression\">\n  ...\n]>\n<rdf:RDF\n\txmlns:rdf=\"&rdf;\"\n\txmlns:dct=\"&dct;\">\n\t<owl:Ontology rdf:about=\"&base;\">\n\t\t<rdfs:label>OntoMedia Core</rdfs:label>\n\t\t<dc:title xml:lang=\"en\">OntoMedia Core</dc:title>\n\t\t<dc:description xml:lang=\"en\">OntoMedia (Ontology for Media) has been designed to describe the interactions occurring in multimedia.</dc:description>\n\t\t<dc:creator>Michael O. Jewell (mailto:moj@ecs.soton.ac.uk)</dc:creator>\n\t\t<dc:creator>K Faith Lawrence (mailto:kf03r@ecs.soton.ac.uk)</dc:creator>\n\t\t<dc:creator>Mischa M Tuffield (mailto:mmt04r@ecs.soton.ac.uk)</dc:creator>\n\t\t<dct:created>2005-05-03</dct:created>\n\t\t<owl:versionInfo>0.3</owl:versionInfo>\n\t\t<owl:imports rdf:resource=\"http://signage.ecs.soton.ac.uk/ontologies/location\" />\n\t</owl:Ontology>\n\t<!-- Core -->\n\t<owl:Class rdf:ID=\"Expression\">\n\t\t<rdfs:label>Expression</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">This class represents a piece of information conveyed through a media</rdfs:comment>\n\t</owl:Class>\n\t<owl:ObjectProperty rdf:ID=\"inspired-by\">\n\t\t<rdfs:label>inspired by</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property indicates that the\nexpression was inspired by another</rdfs:comment>\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"inspired\"/>\n\t\t</owl:inverseOf>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"has-shadow\">\n\t\t<rdfs:label>has shadow</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property indicates that the\nexpression is a variation on another, typically darker in nature</rdfs:comment>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"is-shadow_of\"/>\n\t\t</owl:inverseOf>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"has-spin-off\">\n\t\t<rdfs:label>has spin off</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property indicates that the\nexpression has developed from another</rdfs:comment>\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"is-spin-off-of\"/>\n\t\t</owl:inverseOf>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"is-potentially\">\n\t\t<rdfs:label>is potentially</rdfs:label>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property indicates that the\nexpression is potentially another. For example, it may be a possible future\nversion</rdfs:comment>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"is\">\n\t\t<rdfs:label>is</rdfs:label>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"is-not\">\n\t\t\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property indicates that\nthe expression is entirely different to another</rdfs:comment>\n\t\t\t</owl:ObjectProperty>\n\t\t</owl:inverseOf>\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property indicates that the expression is exactly the same as another</rdfs:comment>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"in-context\">\n\t\t<rdfs:label>in context</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property specifies the context in which this expression lies.</rdfs:comment>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"includes-expression\"/>\n\t\t</owl:inverseOf>\n\t\t<rdfs:range rdf:resource=\"#Context\"/>\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t</owl:ObjectProperty>\n\t<owl:Class rdf:ID=\"Entity\">\n\t\t<rdfs:label>Entity</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Expression\" />\n\t</owl:Class>\n\t<!-- Entity Subclasses -->\n\t<!-- Items -->\n\t<owl:Class rdf:ID=\"Item\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This class represents an entity which may participate in an event within the media. An Item may be abstract or physical</rdfs:comment>\n\t\t<rdfs:label>Item</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Entity\" />\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Physical-Item\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This class represents a physical entity\nwhich may participate in an event within the media</rdfs:comment>\n\t\t<rdfs:label>Physical Item</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Item\" />\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Abstract-Item\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This class represents an abstract entity\nwhich may participate in an event within the media</rdfs:comment>\n\t\t<rdfs:label>Abstract Item</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Item\" />\n\t</owl:Class>\n\t<!-- Abstract-Item Subclases -->\n\t<owl:Class rdf:ID=\"Context\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This class represents the context in\nwhich an event or entity exists</rdfs:comment>\n\t\t<rdfs:label>Context</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Abstract-Item\" />\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Collection\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This class represents a collection of\nentities</rdfs:comment>\n\t\t<rdfs:label>Collection</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Abstract-Item\" />\n\t</owl:Class>\n\t<!-- Temporal -->\n\t<owl:Class rdf:ID=\"Timeline\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This class contains a sequence of occurring\nevents</rdfs:comment>\n\t\t<rdfs:label>Timeline</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Entity\" />\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Occurrence\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This class represents a single occurrence\nof an event, placing it at a position in a timeline</rdfs:comment>\n\t\t<rdfs:label>Occurrence</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Entity\" />\n\t</owl:Class>\n\t<owl:ObjectProperty rdf:ID=\"final-event\">\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t\t<rdfs:range rdf:resource=\"http://www.w3.org/2002/07/owl#Class\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"initial-event\">\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t\t<rdfs:range rdf:resource=\"http://www.w3.org/2002/07/owl#Class\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"precedes\">\n\t\t<rdfs:label>precedes</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property defines the occurrence which\nimmediately follows this occurrence</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#Occurence\"/>\n\t\t<rdfs:domain rdf:resource=\"#Occurence\"/>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"follows\"/>\n\t\t</owl:inverseOf>\n\t</owl:ObjectProperty>\n\t<!-- Events -->\n\t<owl:Class rdf:ID=\"Event\">\n\t\t<rdfs:label>Event</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Expression\" />\n\t</owl:Class>\n\t<owl:ObjectProperty rdf:ID=\"has-subject-entity\">\n\t\t<rdfs:label>has subject entity</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">This property\nspecifies the entity which carries out the aim of the event</rdfs:comment>\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t\t<rdfs:range rdf:resource=\"#Entity\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"has-object-entity\">\n\t\t<rdfs:label>has object entity</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">This property\nspecifies the entity which is the target of the event</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#Entity\"/>\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"has-occurrence\">\n\t\t<rdfs:label>has occurrence</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property defines any occurrences\nof this event</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#Occurrence\"/>\n\t\t<rdfs:domain rdf:resource=\"#Event\" />\n\t\t<owl:inverseOf>\n\t\t\t<owl:FunctionalProperty rdf:ID=\"occurrence-of\"/>\n\t\t</owl:inverseOf>\n\t</owl:ObjectProperty>\n\t<owl:DatatypeProperty rdf:ID=\"summary\">\n\t\t<rdfs:label>summary</rdfs:label>\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t\t<rdfs:range rdf:resource=\"&xsd;string\"/>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property is a plain-text description\nof what occurs in the event</rdfs:comment>\n\t</owl:DatatypeProperty>\n\t<owl:ObjectProperty rdf:ID=\"precondition\">\n\t\t<rdfs:label>precondition</rdfs:label>\n\t\t<rdfs:range>\n\t\t\t<owl:Class>\n\t\t\t\t<owl:unionOf rdf:parseType=\"Collection\">\n\t\t\t\t\t<owl:Class rdf:about=\"#Entity\"/>\n\t\t\t\t\t<owl:Class rdf:about=\"#Event\"/>\n\t\t\t\t</owl:unionOf>\n\t\t\t</owl:Class>\n\t\t</rdfs:range>\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property is a state that must exist\nbefore the event can occur</rdfs:comment>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"postcondition\">\n\t\t<rdfs:label>postcondition</rdfs:label>\n\t\t<rdfs:range>\n\t\t\t<owl:Class>\n\t\t\t\t<owl:unionOf rdf:parseType=\"Collection\">\n\t\t\t\t\t<owl:Class rdf:about=\"#Entity\"/>\n\t\t\t\t\t<owl:Class rdf:about=\"#Event\"/>\n\t\t\t\t</owl:unionOf>\n\t\t\t</owl:Class>\n\t\t</rdfs:range>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property contains the state which\nshould occur as a consequence of this event</rdfs:comment>\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"involves\">\n\t\t<rdfs:label>involves</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property specifies the entities involved\nin this event. Note that this includes the subject and object.</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#ontomedia_Entity\"/>\n\t\t<rdfs:domain rdf:resource=\"#ontomedia_Event\"/>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"involved-in\" />\n\t\t</owl:inverseOf>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"causes\">\n\t\t<rdfs:label>causes</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property indicates the instigating\nfactor of an event, whether it be an item, event, or collection.</rdfs:comment>\n\t\t<rdfs:range>\n\t\t\t<owl:Class>\n\t\t\t\t<owl:unionOf rdf:parseType=\"Collection\">\n\t\t\t\t\t<owl:Class rdf:about=\"#Event\"/>\n\t\t\t\t\t<owl:Class rdf:about=\"#Entity\"/>\n\t\t\t\t</owl:unionOf>\n\t\t\t</owl:Class>\n\t\t</rdfs:range>\n\t\t<rdfs:domain>\n\t\t\t<owl:Class>\n\t\t\t\t<owl:unionOf rdf:parseType=\"Collection\">\n\t\t\t\t\t<owl:Class rdf:about=\"#Event\"/>\n\t\t\t\t\t<owl:Class rdf:about=\"#Entity\"/>\n\t\t\t\t</owl:unionOf>\n\t\t\t</owl:Class>\n\t\t</rdfs:domain>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"caused_by\"/>\n\t\t</owl:inverseOf>\n\t</owl:ObjectProperty>\n\t<!-- Events Subclasses -->\n\t<owl:Class rdf:ID=\"Gain\">\n\t\t<rdfs:label>Gain</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Event\" />\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This event class results in an overall\nincrease of the entities related to the primary subject or subjects of the\nevent</rdfs:comment>\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Introduction\">\n\t\t<rdfs:label>Introduction</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This event class denotes the introduction\nof an entity to the media</rdfs:comment>\n\t\t<rdfs:subClassOf rdf:resource=\"#Event\" />\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Loss\">\n\t\t<rdfs:label>Loss</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This event class results in an overall\nreduction of the entities related to the primary subject or subjects of the\nevent</rdfs:comment>\n\t\t<rdfs:subClassOf rdf:resource=\"#Event\" />\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Transformation\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This event class results in no gain or loss\nof attributes or entities, merely alteration</rdfs:comment>\n\t\t<rdfs:label>Transformation</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Event\" />\n\t</owl:Class>\n\t<owl:Class rdf:ID=\"Action\">\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This event class describes an action sequence\n(ie no plot)</rdfs:comment>\n\t\t<rdfs:label>Action</rdfs:label>\n\t\t<rdfs:subClassOf rdf:resource=\"#Event\" />\n\t</owl:Class>\n\t<owl:ObjectProperty rdf:ID=\"from\">\n\t\t<rdfs:label>from</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property specifies the entity which\nis being transformed</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#Entity\"/>\n\t\t<rdfs:domain rdf:resource=\"#Transformation\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"to\">\n\t\t<rdfs:label>to</rdfs:label>\n\t\t<rdfs:comment rdf:datatype=\"&xsd;string\">This property specifies the resultant\nentity</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#Entity\"/>\n\t\t<rdfs:domain rdf:resource=\"#Transformation\"/>\n\t</owl:ObjectProperty>\n\t<!-- Unsorted -->\n\t<owl:ObjectProperty rdf:ID=\"has_parody\">\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t\t<owl:inverseOf>\n\t\t\t<owl:ObjectProperty rdf:ID=\"is_parody_of\"/>\n\t\t</owl:inverseOf>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"occurs\">\n\t\t<rdfs:range rdf:resource=\"#locspec_Location_Specifier\"/>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/>\n\t\t<rdfs:domain rdf:resource=\"#Instant_Occurence\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:about=\"#allows_existance_of\">\n\t\t<rdfs:domain rdf:resource=\"#Context\"/>\n\t\t<owl:inverseOf rdf:resource=\"#exists_in\"/>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"start_point\">\n\t\t<rdfs:domain rdf:resource=\"#Period_Occurence\"/>\n\t\t<rdfs:range rdf:resource=\"#locspec_Location_Specifier\"/>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"duration\">\n\t\t<rdfs:domain rdf:resource=\"#Period_Occurence\"/>\n\t\t<rdfs:range>\n\t\t\t<owl:Class>\n\t\t\t\t<owl:unionOf rdf:parseType=\"Collection\">\n\t\t\t\t\t<owl:Class rdf:about=\"#locspec_Location_Specifier\"/>\n\t\t\t\t\t<owl:Class rdf:about=\"#Dimension\"/>\n\t\t\t\t</owl:unionOf>\n\t\t\t</owl:Class>\n\t\t</rdfs:range>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:about=\"#contains\">\n\t\t<owl:inverseOf rdf:resource=\"#contained_by\"/>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t\t<rdfs:domain>\n\t\t\t<owl:Class>\n\t\t\t\t<owl:unionOf rdf:parseType=\"Collection\">\n\t\t\t\t\t<owl:Class rdf:about=\"#Expression\"/>\n\t\t\t\t\t<owl:Class rdf:about=\"#Expression\"/>\n\t\t\t\t</owl:unionOf>\n\t\t\t</owl:Class>\n\t\t</rdfs:domain>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:about=\"#follows\">\n\t\t<rdfs:range rdf:resource=\"#Occurence\"/>\n\t\t<rdfs:domain rdf:resource=\"#Occurence\"/>\n\t\t<owl:inverseOf rdf:resource=\"#precedes\"/>\n\t\t<rdfs:comment rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Follows should\nspecify both timeline and event IDs where there is more than one timeline or over\ntwo events</rdfs:comment>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"timeline_ref\">\n\t\t<rdfs:range rdf:resource=\"#Timeline\"/>\n\t\t<rdfs:domain rdf:resource=\"#Occurence\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:about=\"#is_parody_of\">\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t\t<owl:inverseOf rdf:resource=\"#has_parody\"/>\n\t\t<rdfs:domain rdf:resource=\"#Expression\"/>\n\t</owl:ObjectProperty>\n\t<owl:ObjectProperty rdf:ID=\"end_point\">\n\t\t<rdfs:range rdf:resource=\"#locspec_Location_Specifier\"/>\n\t\t<rdfs:domain rdf:resource=\"#Period_Occurence\"/>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/>\n\t</owl:ObjectProperty>\n\t<owl:FunctionalProperty rdf:ID=\"TPQ\">\n\t\t<rdfs:range rdf:resource=\"#locspec_Location_Specifier\"/>\n\t\t<rdfs:comment rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Terminus Post Quem</rdfs:comment>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/>\n\t\t<rdfs:domain rdf:resource=\"#Occurence\"/>\n\t</owl:FunctionalProperty>\n\t<owl:FunctionalProperty rdf:ID=\"type\">\n\t\t<rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#string\"/>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#DatatypeProperty\"/>\n\t\t<rdfs:domain rdf:resource=\"#Item\"/>\n\t</owl:FunctionalProperty>\n\t<owl:FunctionalProperty rdf:about=\"#occurence_of\">\n\t\t<rdfs:domain rdf:resource=\"#Occurence\"/>\n\t\t<rdfs:range rdf:resource=\"#Expression\"/>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/>\n\t\t<owl:inverseOf rdf:resource=\"#has_occurence\"/>\n\t</owl:FunctionalProperty>\n\t<owl:FunctionalProperty rdf:ID=\"TAQ\">\n\t\t<rdfs:domain rdf:resource=\"#Occurence\"/>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/>\n\t\t<rdfs:comment rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Terminus Ante Quem</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#locspec_Location_Specifier\"/>\n\t</owl:FunctionalProperty>\n\t<owl:FunctionalProperty rdf:ID=\"initial_event\">\n\t\t<rdfs:comment rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">the first event which begins this sequence</rdfs:comment>\n\t\t<rdfs:range rdf:resource=\"#Event\"/>\n\t\t<rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/>\n\t\t<rdfs:domain rdf:resource=\"#Event\"/>\n\t</owl:FunctionalProperty>\n</rdf:RDF>\n```","n":0.039}}},{"i":2611,"$":{"0":{"v":"ontologydesignpatterns.org","n":1},"1":{"v":"\n- [[c.software.semantic.library]]\n- url: http://ontologydesignpatterns.org\n- repo: https://triplydb.com/odp/-/datasets\n\n## Description\n\n- portal for a catalogue of ontology design patterns. While it does not contain large domain ontologies per se, many of the ontology patterns in ODP are in fact ontologies themselves, or components that are integrated into other ontologies. For example, there are patterns for representing climactic zones or observations.\n\n## References\n\n- [[ar.where-to-publish-and-find-ontologies-a-survey-of-ontology-libraries]]","n":0.131}}},{"i":2612,"$":{"0":{"v":"Ontology4","n":1},"1":{"v":"\n- https://ontology4.us/\n\n## Interesting\n\n- In contrast to Resource_Description_Framework|RDF as standard model für data interchange on the Web, **Ontology4 uses quadrupels instead of triplets and adds the time dimension for every relation between subjects and objects.**\n- Ontology4 provides standardized notation for subjects/objects (^), relations (<>), instances (>), methods (°) and verbs/activities (~). Each of the symbols has its own graphical symbol in the semantical net graphs.\n- PQL (Predicate Query Language) translates to OQL (Ontology Query Language)\n\n### Dualism\n\n- **Class-Attribute Dualism** has two approaches\n  1. class has a property, and instances are members of class, e.g.: particularPerson is a Person, and has gender\n  2. subclasses of a class have restrictions, and instances can be members of both classes, e.g.: particularPerson is a MalePerson and FemalePerson\n- \"But only the second approach allows to model hermaphrodites by letting an instance >Instance-H1 be instance of the subclasses ^Class-F and ^Class-M at the same time. In the first approach, this can not be done, since then the attribute .Attribute-G would have to have the two values male AND female for >Instance-H1 like\"\n    - t.2024.06.06.09 but really? \n    - t.2024.07.10.08 NO! functional properties can only have one, but gender doesn't need to be a functional property\n\n### 4 dimensional representation\n\n\n    classes are represented by red ovals,\n    relations are represented by dark blue octagons and\n    activities are represented by yellow houses.\n    instances are presented by green houses.\n\n### Mereologies\n\n- model hierarchies of part-whole relations\n  - t.2024.07.10.08 but you can do that with mereological predicates in RDF\n\n### Taxoverbies\n\n- hierarchies of verbs/activities\n- They parallel taxonomies as hierarchies of classes and mereologies as hierarchies of compositions/part-wholes.\n- t.2024.07.10.08 but verbs are similar to properties, and properties can have hierarchy in RDF\n\n## References\n\n- https://ontology4.us/english/Ontologies/Upper-Ontologies/Concepts_Comparison/index.html","n":0.06}}},{"i":2613,"$":{"0":{"v":"Ontology Publisher","n":0.707},"1":{"v":"\n- https://github.com/edmcouncil/ontology-publisher\n- uses: [[prdct.rdf-toolkit]]\n- written-in: python\n\n## Examples\n\n- https://spec.edmcouncil.org/fibo/ontology/FND/AgentsAndPeople/Agents/AutomatedSystem","n":0.354}}},{"i":2614,"$":{"0":{"v":"Ontology of Plans","n":0.577},"1":{"v":"\n- http://www.ontologydesignpatterns.org/ont/dul/PlansLite.owl\n- aka: DOLCE+DnS Plan Ontology, DDPO\n\n![](/assets/images/2024-07-19-08-18-46.png)\n\n## References\n\n- [[ar.task-taxonomies-for-knowledge-content]]","n":0.333}}},{"i":2615,"$":{"0":{"v":"Ontology of Information Objects","n":0.5},"1":{"v":"\n- [[c.ontology.mid]]\n- \n- different_from: [[prdct.information-objects-ontology]]","n":0.447}}},{"i":2616,"$":{"0":{"v":"Ontology Modeling Language Oml","n":0.5},"1":{"v":"\n- http://www.opencaesar.io/oml/\n- repo: https://github.com/opencaesar/oml\n\n## Resources\n\n- https://www.opencaesar.io/oml-tutorials/\n\n## References\n\n- [[ar.ontological-metamodeling-and-analysis-using-open-caesar]]","n":0.354}}},{"i":2617,"$":{"0":{"v":"Ontology Lookup Service","n":0.577},"1":{"v":"\n- [[c.software.semantic.library]]\n- [[c.software.semantic]] [[c.software.semantic.search-engine]]\n- url: https://www.ebi.ac.uk/ols4\n- related: [[prdct.oxo]]","n":0.354}}},{"i":2618,"$":{"0":{"v":"Ontology Development Kit","n":0.577},"1":{"v":"\n- repo: https://github.com/INCATools/ontology-development-kit\n- part_of: [[prdct.ontodev-suite]]\n\n## Features\n\n- \"uses Travis CI to run workflows\nwith the ROBOT tool\"\n\n## References\n\n[[ar.the-acimov-methodology-agile-and-continuous-integration-for-modular-ontologies-and-vocabularies]]","n":0.25}}},{"i":2619,"$":{"0":{"v":"Ontolearn","n":1},"1":{"v":"\n- repo: https://github.com/dice-group/Ontolearn\n- similar: [[prdct.deeponto]]","n":0.447}}},{"i":2620,"$":{"0":{"v":"Ontohub","n":1},"1":{"v":"\n- dead\n- url: https://matpiw.github.io/OntoHub/\n- written_in: java\n\n## Features\n\nOpen - based on open source software\n\nFlexible - combine different logics in the same ontology\n\nDistributed - combine distinct ontologies into a single one\n","n":0.186}}},{"i":2621,"$":{"0":{"v":"Ontohub Org","n":0.707},"1":{"v":"\n- [[c.software.semantic.library]]\n- url: https://ontohub.org/\n- different_from: [[prdct.ontohub]]\n\n","n":0.408}}},{"i":2622,"$":{"0":{"v":"Ontographer","n":1},"1":{"v":"\n- https://ontographer.github.io/ontographer-demo/\n\n## Description\n\nOntoGrapher is one software tool among many in a toolkit known as the Assembly Line, which serves as a software suite supporting creation, management, evaluation, and publishing of vocabularies - currently for, but not theoretically limited to, those vocabularies containing terms from a legal domain. In particular, OntoGrapher has the following goals:\n\n-   offering a web-based collaborative conceptual modeling environment for domain experts,\n-   accepting SKOS terminologies on input and producing OWL ontologies on output without requiring users to understand either of these standards,\n-   tracking the source of entities, relations and attributes in conceptual models stemming from multiple vocabularies (e.g. laws).\n-   \n\n## References\n\n- https://github.com/ontographer/ontographer-demo","n":0.098}}},{"i":2623,"$":{"0":{"v":"Ontogram","n":1},"1":{"v":"\n- https://github.com/edmondchuc/ontogram\n- [[c.software.visualization.semantic]]\n- kinda dead","n":0.447}}},{"i":2624,"$":{"0":{"v":"Ontogen","n":1},"1":{"v":"\n- https://ontogen.io/\n- tested-with: [[prdct.jena.fuseki]] and [[prdct.oxigraph]]\n- related: [[prdct.rtc-ex]]\n- docs: https://ontogen.io/docs/user-guide/\n\n## Features\n\n- RDF Triple Compounds (RTC) allow named-graph-like functionality without using named graphs\n- uses [[prdct.RDF-star]] for annotations\n\n### IRI minting\n\n- \n\n### Versioning\n\n- the version-controlled data in Ontogen is kept in a triple store.\n- A SpeechAct represents a group of changes to the repository, similar to a commit in traditional VCS, but with additional metadata such as speaker, timestamp, and data source.\n- SpeechActs are prepared through the staging system and then stored as commits in the repository.\n- This staging system allows users to carefully prepare and review changes before they are committed as a SpeechAct. It provides more control and transparency in the versioning process, especially when working with complex RDF data.\n\n#### Staging file\n\n- Instead of an implicitly held staging area, there is a single staging file with which the next SpeechAct to be committed can be incrementally prepared. \n- By default, this file is called STAGE.trig and contains an RDF dataset consisting of specially named graphs for the different action types:\n  -   `og:Addition` graph with changes that should simply be added to the repository without overwriting existing statements\n  -   `og:Update` graph with changes that should overwrite existing statements with the same subject and predicate\n  -   `og:Replacement` graph with changes that should replace all existing statements with the same subject\n  -   `og:Removal` graph with statements that should be removed from the repository\n-   currently only one SpeechAct per staging file\n-   in addition to TriG, N-Quads (with file extension .nq) and JSON-LD (with file extension .jsonld) are also supported.\n\n\n## References\n\n- [[ar.ontogen.introducing-ontogen]] ","n":0.063}}},{"i":2625,"$":{"0":{"v":"OntoDev Suite","n":0.707},"1":{"v":"\n- https://ontodev.com/\n- includes: [[prdct.robot]] [[prdct.ontology-development-kit]] [[prdct.droid]]","n":0.408}}},{"i":2626,"$":{"0":{"v":"OntoClean","n":1},"1":{"v":"\n- [[c.methodology.semantic-web]] [[c.methodology.ontology-engineering]]\n- https://people.cs.uct.ac.za/~mkeet/OEbook/ontologies/ontoclean-dl.owl\n\n## Highlights\n\n- uses punning\n- \"A sortal is a class all of whose instances are identified in the same way. In information systems, these criteria are often extrinsic, like a social security number or universally unique id, which is not interesting from an ontological point of view. Identity criteria should be informative, they should help us and others understand what a class means. A triangle, for example, can be identified by the length of its three sides, or by two sides and an interior angle, etc. This says a lot about what is intended by the triangle class here, e.g. the same triangle could be in many places at the same time. Someone else may have an ontology in which the triangle class has different identity criteria, such that different drawings are always different triangles, even if they are the same size. Identity criteria (and OntoClean, for that matter) do not tell you that one of these definitions of triangle is right or wrong, just that they are different and thus that the classes are different.\" ^c4wf7a4wby5o\n\n## Resources\n\n- [[ar.onto-clean-in-owl-with-a-dl-reasoner-a-tutorial]]\n\n## References\n\n- https://en.wikipedia.org/wiki/OntoClean\n- [[ar.an-overview-of-onto-clean]]\n- https://keet.wordpress.com/tag/ontoclean/\n- [[ar.dynamic-is-a-hierarchy-generation-for-user-centric-semantic-web]]\n\n","n":0.073}}},{"i":2627,"$":{"0":{"v":"ONT-API","n":1},"1":{"v":"\n- repo: https://github.com/owlcs/ont-api\n- docs: https://github.com/owlcs/ont-api/wiki\n- related: [[prdct.jena]]\n\n## Pros\n\n- allows to use an API that meets the modern OWL specification along with other Jena-compatible products. This can be also useful to the OWL-API users, because the RDF based solution is more flexible and universal, which allows solving a number of OWL-API typical problems. \n  - Instead of mapping RDF to OWL and back that is offered by OWL-API default implementation, in ONT-API there is reading OWL from RDF and writing OWL to RDF, which, actually, is the only true-way, just because OWL is nothing but a subset of RDF. In the ONT-API reading and writing an ontology from a file or a stream happen through Jena RIOT, however, the original OWL-API mechanisms to read/write also remain working, and even are used explicitly if the data format is not supported by Jena (e.g. Functional Syntax, Manchester Syntax, OWL/RDF, etc)\n  - ONT-API supports all OWL-API features and options, but they are somewhat expanded. Instead of the original OWL-API interfaces, in ONT-API there are the overridden ones with several additional methods to access to Jena-API. ONT-API IS OWL-API, and can be used in all places where OWL-API is used. And if you don't accept this, then you're, probably, don't need ONT-API at all. It is always possible to use the original OWL-API or its parts in conjunction with ONT-API, for example, you can just copy an ontology from the ONT-API manager to the OWL-API-impl manager and vice versa.\n\n## Cons\n\nA possible downside of this approach might be different performance and memory consumption (in comparison with default OWL-API implementation), but recent research shows that such concerns may not always be justified.","n":0.06}}},{"i":2628,"$":{"0":{"v":"Onset","n":1},"1":{"v":"\n- url: http://www.meteck.org/files/onset/\n- http://www.thezfiles.co.za/ROMULUS/Onset/webonset.html #broken","n":0.447}}},{"i":2629,"$":{"0":{"v":"Onnx","n":1},"1":{"v":"\n- repo: https://github.com/onnx/onnx","n":0.577}}},{"i":2630,"$":{"0":{"v":"Online Assistant","n":0.707},"1":{"v":"\n- [[c.software.rpg.virtual-tabletop]]\n- url: https://www.aidedd.org/dnd-online/1-1\n\n## Use cases\n\n- remote live games\n- play by forum\n- around a table\n","n":0.258}}},{"i":2631,"$":{"0":{"v":"One_dnd","n":1}}},{"i":2632,"$":{"0":{"v":"One More Multiverse","n":0.577},"1":{"v":"ttrpg engine with retro 2D graphics and the promise of a marketplace\n\n- [[p.alsoKnownAs]] Multiverse\n- [[p.hasURL]] https://www.playmultiverse.com/\n- [[p.alsoKnownAs]] One More Multiverse\n\n## 2021-10-22\n\n- tried to join Wanderhome late, made my first character. Xug\n  - ![](/assets/images/2021-10-22-15-38-29.png)\n- liked the token rules:\n  - ![](/assets/images/2021-10-22-15-36-39.png)\n- #first-impression a lonely, uninteresting world \n","n":0.149}}},{"i":2633,"$":{"0":{"v":"On-To-Knowledge","n":1},"1":{"v":"\n- [[c.methodology.ontology-engineering]]\n\n\n## References\n\n- http://www.inf.ufsc.br/~fernando.gauthier/EGC6006/material/Aula%203/del18.pdf","n":0.5}}},{"i":2634,"$":{"0":{"v":"Oml Luxor","n":0.707}}},{"i":2635,"$":{"0":{"v":"Olga","n":1},"1":{"v":"\n- https://ecostruxure.github.io/OLGA/\n- built-on: [[prdct.trinity-rdf]] [[prdct.dotnetrdf]]\n\n## Examples\n\n- https://github.com/EcoStruxure/OLGA/wiki/Hello-World","n":0.378}}},{"i":2636,"$":{"0":{"v":"Oesjs","n":1},"1":{"v":"\n- https://sim4edu.com/oesjs/\n- related: https://github.com/gwagner57/oes\n\n## Resources\n\n- [[book.discrete-event-simulation-engineering]]","n":0.408}}},{"i":2637,"$":{"0":{"v":"Odd Dev","n":0.707},"1":{"v":"\n- url: https://odd.dev/\n- [[p.supports]] [[prdct.typescript]]","n":0.447}}},{"i":2638,"$":{"0":{"v":"OData","n":1},"1":{"v":"\n- url: https://www.odata.org/\n\n\n## Comparison\n\n![](/assets/images/2024-03-13-09-55-30.png)\n![](/assets/images/2024-03-13-09-56-13.png)\n\n## Resources\n\n- https://blog.bitsrc.io/choosing-between-graphql-vs-odata-api-823856bce8c2","n":0.408}}},{"i":2639,"$":{"0":{"v":"Ocxmd","n":1}}},{"i":2640,"$":{"0":{"v":"Octokit","n":1},"1":{"v":"\n\nrepo: https://github.com/octokit\n","n":0.707}}},{"i":2641,"$":{"0":{"v":"oktokit.net","n":1},"1":{"v":"\n- repo: https://github.com/octokit/octokit.net","n":0.577}}},{"i":2642,"$":{"0":{"v":"oktokit.js","n":1},"1":{"v":"\n- repo: https://github.com/octokit/octokit.js\n- ","n":0.577}}},{"i":2643,"$":{"0":{"v":"Oclif","n":1},"1":{"v":"\nrepo: https://github.com/oclif/oclif\n\njavascript-cli-framework\n\n## #features\n\n- Autocomplete, e.g.\n  - ` heroku info --app=<tab><tab> # will complete with all the Heroku apps a user has in their account`\n- Network-oriented\n  - e.g. https://github.com/heroku/cli/blob/67b9080ad0b48e654d799bced119cbab768c759a/packages/apps-v5/src/commands/apps/info.js\n\n## [[p.hasLearningResource]]\n\n- https://dev.to/raphaelmansuy/boost-your-productivity-by-creating-your-own-cli-command-with-typescript-and-oclif-part-2-1jlk\n- https://medium.com/free-code-camp/writing-a-command-line-database-client-in-10-minutes-aa608536ae4b","n":0.18}}},{"i":2644,"$":{"0":{"v":"Ochre","n":1},"1":{"v":"\n- [[c.ontology]] [[c.ontology.upper]]","n":0.577}}},{"i":2645,"$":{"0":{"v":"Obsidian","n":1},"1":{"v":"\n- https://obsidian.md/\n- [[c.software.knowledge-base]]\n- description: A markdown-based, local-first knowledge base platform, with electron applications for desktop and mobile, and Paid sync and publishing features. \n\n- [[p.hasApplication]] [[t.km]] \n- [[c.release.initial]] 2020\n\n## Pros\n\n- sweet aliasing\n- friendly yamling in default/non-source mode\n- cohabits with Dendron\n\n## Cons\n\n- frontmatter properties can't be nested\n\n## Resources\n\n- - [[ar.how-to-export-your-obsidian-vault-to-rdf]]","n":0.143}}},{"i":2646,"$":{"0":{"v":"Obsidian Portal","n":0.707},"1":{"v":"\n- url: https://www.obsidianportal.com/\n- ","n":0.577}}},{"i":2647,"$":{"0":{"v":"Obsidian Excalidraw Plugin","n":0.577}}},{"i":2648,"$":{"0":{"v":"Observable","n":1},"1":{"v":"\n- https://observablehq.com\n- [[c.software.data-framework]] [[c.Software.Computational-Notebook]]","n":0.5}}},{"i":2649,"$":{"0":{"v":"OBOlibrary","n":1},"1":{"v":"\n- similar: [[prdct.w3id]]\n  - Unlike w3id.org, we do not edit the Apache configuration files by hand.\n\n## References\n\n- https://github.com/OBOFoundry/purl.obolibrary.org/","n":0.236}}},{"i":2650,"$":{"0":{"v":"Obo Foundry","n":0.707},"1":{"v":"\n- [[c.software.semantic.library]]\n- url http://obofoundry.org/\n- ","n":0.5}}},{"i":2651,"$":{"0":{"v":"OAS","n":1}}},{"i":2652,"$":{"0":{"v":"Oakton","n":1},"1":{"v":"\n- [[c.Software.CLI-framework]]\n- url: https://jasperfx.github.io/oakton/\n\n## Description\n\n- Easily enable tools to expose multiple commands\n\n## Features\n\n- mechanism to automatically find and load Oakton commands from other assemblies through file scanning.\n- \"opts files\"\n  - inspired by Javascript tools like Mocha that use \"opts\" files to make their tools much easier to use at the command line\n\n## Use cases\n\n- Make it easy to embed and expose command help for user friendliness\n- The power of Oakton really comes into play when it's combined with applications using the HostBuilder mechanism for bootstrapping .Net applications. See Integration with IHost for more information.\n","n":0.103}}},{"i":2653,"$":{"0":{"v":"Oak","n":1}}},{"i":2654,"$":{"0":{"v":"O3DE","n":1},"1":{"v":"\n- [[p.formerlyKnownAs]] Amazon Lumberyard","n":0.5}}},{"i":2655,"$":{"0":{"v":"Nx","n":1},"1":{"v":"\nurl: https://nx.dev/\n\n## Resources\n\n- https://nx.dev/concepts/integrated-vs-package-based\n  - \"The comparison between package-based repos and integrated repos is similar to the comparison between JSDoc and TypeScript. The former is easier to adopt and provides some good benefits. The latter takes more work but provides more value, especially at a larger scale.\"\n  - ","n":0.144}}},{"i":2656,"$":{"0":{"v":"Nvm","n":1}}},{"i":2657,"$":{"0":{"v":"Nuxt","n":1},"1":{"v":"```yaml\nworks_with: \"[[prdct.deno]]\"\n```","n":0.707}}},{"i":2658,"$":{"0":{"v":"Nuxt Todos Kv","n":0.577}}},{"i":2659,"$":{"0":{"v":"Nu","n":1},"1":{"v":"\n- [[c.software.game-framework]]\n- repo: https://github.com/bryanedds/Nu\n- related: [[ar.youtube.platform-as-a-reflection-of-values]]\n\n## Features\n\n- first practical functional 2D and 3D cross-platform game engine. Built in F#, it offers a declarative MVU-based API called MMCC (Model-Message-Command-Content\n- Real-time WYSIWYG editing with hot asset and live code reloading, and the ability to undo and redo gameplay.\n- Recursive Prefab-like functionality via Entity Structure Propagation.\n\n### MVCC\n\nModel-View-Update (or MVU) is the 'killer app' of functional programming. Until MVU came along, most arguments about the benefits of functional programming resided primarily in the space of the theoretical. But when Elm introduced the world to MVU with its incredibly clean authoring form factor, the space of discussion changed forever.\n\nWith Nu's generalization of MVU via MMCC (Model-Message-Command-Content), it is the first and still only practical game engine positioned to bring the killer benefits of this declarative development form factor to game developers.\n\n### Immutability\n\n- By default in the editor, Nu is configured to run in an immutable mode. In this mode, all of the simulation backing data encapsulated behind the World API is implemented with functional data structures that can be snapshotted and restored. This snapshotting is how Nu's editor, Gaia, implements its Undo and Redo operations. However, for optimal performance, Nu is configured to use mutating data structures under the hood instead when outside of the editor. Nu can be configured to run either way in both contexts, however.\n\n## Examples\n\n- [[game.omniblade]]","n":0.067}}},{"i":2660,"$":{"0":{"v":"NSQ","n":1},"1":{"v":"\n- https://nsq.io/\n- repo: https://github.com/nsqio/nsq\n- written-in\n- supports: go javascript python\n![[prdct.nats#^69m6e1oxkdup]]\n\n\n## Features\n\n-   support distributed topologies with no SPOF\n-   horizontally scalable (no brokers, seamlessly add more nodes to the cluster)\n-   low-latency push based message delivery ([performance](https://nsq.io/overview/performance.html))\n-   combination load-balanced _and_ multicast style message routing\n-   excel at both streaming (high-throughput) and job oriented (low-throughput) workloads\n-   primarily in-memory (beyond a high-water mark messages are transparently kept on disk)\n-   runtime discovery service for consumers to find producers ([nsqlookupd](https://github.com/nsqio/nsq/tree/master/nsqlookupd/README.md))\n-   transport layer security (TLS)\n-   data format agnostic\n-   few dependencies (easy to deploy) and a sane, bounded, default configuration\n-   simple TCP protocol supporting client libraries in any language\n-   HTTP interface for stats, admin actions, and producers (_no client library needed to publish_)\n-   integrates with [statsd](https://github.com/etsy/statsd/) for realtime instrumentation\n-   robust cluster administration interface ([nsqadmin](https://github.com/nsqio/nsq/tree/master/nsqadmin/README.md))\n- durability: \"primarily an in-memory messaging platform\"\n\n## References\n\nhttps://github.com/centrifugal/centrifugo/issues/45","n":0.088}}},{"i":2661,"$":{"0":{"v":"NSpM","n":1},"1":{"v":"\n- https://aksw.org/Projects/NeuralSPARQLMachines\n- repo: https://github.com/LiberAI/NSpM","n":0.5}}},{"i":2662,"$":{"0":{"v":"Nservicebus","n":1},"1":{"v":"\n- url: https://particular.net/nservicebus","n":0.577}}},{"i":2663,"$":{"0":{"v":"Npm","n":1}}},{"i":2664,"$":{"0":{"v":"nownownow.com","n":1},"1":{"v":"\n- related: [[t.cs.web.now]]\n","n":0.577}}},{"i":2665,"$":{"0":{"v":"Notion","n":1},"1":{"v":"\na web-first knowledge base (docs, projects, and wikis) with desktop and mobile clients and a web clipper\n\n- [[c.release.initial]] 2016\n- [[p.hasApplication]] [[t.km]] [[t.tm]] \n- [[p.isRelated]] https://www.notion.so/customers\n- [[c.pricing]] https://www.notion.so/pricing\n  - free for single-user + 10 collaborators  \n## [[p.hasFeature]]\n\n- copies nicely to markdown  ^wf7vUfHYbV8u\n- supports embedded videos \n- \"progessive select-all\" takes \n- [toggles](https://www.notion.so/Toggles-c720af26b4bd4789b736c140b2dc73fe)\n \n\n## Issues\n\n- breaks the back button\n- lost the [[t.cs.ui.programming-portals]]\n  - [[p.attributedTo]] [[ar.maggieappleton.programming-portals]]\n  \n## [[p.hasExample]]\n\n- https://www.nateliason.com/brain 250 literature notes for $25\n\n## [[p.hasCriticism]]\n\n- \"Using Notion for note taking is like using a sniper to kill a mosquito.\"\n  - [[p.attributedTo]] Andrey Zagoruiko\n\n\n","n":0.106}}},{"i":2666,"$":{"0":{"v":"Notation3","n":1},"1":{"v":"\n- spec: https://w3c.github.io/N3/spec/\n- ","n":0.577}}},{"i":2667,"$":{"0":{"v":"Nostr","n":1},"1":{"v":"\n- https://nostr.com/\n- similar: [[prdct.activitypub]]","n":0.5}}},{"i":2668,"$":{"0":{"v":"Noosphere","n":1},"1":{"v":"\n- https://subconscious.network/\n- created_by: [[org.subconscious]]\n- repo: https://github.com/subconsciousnetwork/noosphere\n- related: \n  - [[prdct.decentralized-identifiers]]\n  - [[prdct.cid]]\n  - [[t.cs.distributed.hash-table]]\n- built-on: [[prdct.libp2p]]\n\n## Description\n\n### Public key infrastructure\n\nWhen Alice and Bob exchanged contact details in the story above, the exchanged data included public keys (encoded as [[DIDs|prdct.decentralized-identifiers]] that represent their respective notebooks. Bob's public key was then recorded against a pet name in Alice's notebook\n\n### Content Addressing\n\nAs Alice updated her notebook to include Bob's name, a snapshot of her entire notebook at its latest state was recorded and condensed down to a short, unique ID: a content ID, or [[prdct.cid]]. Such a snapshot and corresponding CID is recorded for every update to every user's notebook (including Bob's).\n\nSimilarly, when Bob updated their animal-notes to include a link to cat-thoughts, a new snapshot of the note was recorded and a CID was computed for it. When Alice viewed the index of links in Bob's notebook, what she actually viewed was a mapping of note slugs to their CIDs.\n\n### Immutable data\n\nNoosphere data is formatted in terms of [[prdct.ipld]] and encoded in a low-overhead binary format called DAG-CBOR. Even though a full snapshot is recorded with every revision, new storage space is only allocated for the delta between any two revisions. This strategy is similar to how Git efficiently stores the delta between any two sequential commits.\n\nA data structure that we call a Memo is used to pair open-ended header fields with a retained historical record of revisions to notebooks and their contents:\n\n### P2P routing and discovery\n\nEvery user who publishes to the network does so via a gateway server. The gateway represents the boundary edge of user sovereignty, and also gives the user a reliably available foothold in the Noosphere network. The owner of a notebook is also the owner of the gateway, and third-parties neither have or need direct access to it (even in managed hosting scenarios).\n\nThe owner of a notebook enables the gateway to publish the notebook to the network using a [[UCAN|prdct.ucan]]-based authorization scheme. UCANs establish a cryptographic chain of proof that allows anyone to verify in place that the gateway was authorized to perform actions such as signing content on the user's behalf (and without asking the user to share cryptographic keys with the gateway).\n\nWhen the user updates their notebook, they replicate the revision deltas to the gateway over HTTP (as network availability allows), and also tell the gateway which CID represents the latest version of the notebook. The revision deltas are syndicated to the public network via IPFS. Then, the gateway publishes the latest revision CID to a [[t.cs.distributed.hash-table]] (see: Noosphere Name System) mapping it to the notebook's public key and pairing it with the UCAN proof chain.\n\n## Thoughts\n\n- could use an intermediate state, like local changes to a git repo, before \"changes\" get recorded. \n\n## References\n\n- [[ar.substack.subconscious.the-minimal-definition-of-user-agency]]\n- https://github.com/subconsciousnetwork/noosphere/blob/main/design/explainer.md\n","n":0.047}}},{"i":2669,"$":{"0":{"v":"Noms","n":1}}},{"i":2670,"$":{"0":{"v":"Noise","n":1},"1":{"v":"\n\n- [[p.hasLearningResource]]\n  - [The Noise protocol framework @trevor-perrin | RWC 2018](https://www.youtube.com/watch?v=3gipxdJ22iM)\n","n":0.302}}},{"i":2671,"$":{"0":{"v":"Nodegame","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://nodegame.org/\n","n":0.577}}},{"i":2672,"$":{"0":{"v":"NodeJS","n":1},"1":{"v":"\n- [[p.correspondsTo]] [[Node.js|t.cs.runtime-environment.node-js]]\n  \n## Resources\n\n- [[ar.twilio.how-to-build-a-cli-with-node-js]] #cli\n\n## [[p.hasLearningResource]]\n\n- [[ar.medium.edge-coders.understanding-node-js-event-driven-architecture]]\n- https://github.com/samerbuna/efficient-node/blob/main/100-learning-node-runtime.adoc","n":0.316}}},{"i":2673,"$":{"0":{"v":"Node Solid Server","n":0.577},"1":{"v":"\n\n- repo: https://github.com/nodeSolidServer/node-solid-server\n- written-in: typescript\n\n\n## Similar\n\n- [[prdct.node-solid-server]] [[prdct.community-solid-server]] [[prdct.manas]]","n":0.333}}},{"i":2674,"$":{"0":{"v":"Node Postgres","n":0.707},"1":{"v":"\n#aka pg\nurl: https://node-postgres.com/\n","n":0.577}}},{"i":2675,"$":{"0":{"v":"Noda Time","n":0.707},"1":{"v":"\n- [[c.software.library.temporal]]\n- url:  https://nodatime.org\n\n## Documentation\n\n### https://nodatime.org/3.1.x/userguide/concepts\n\n- Time is measured with a granularity of nanoseconds. This is 100 times finer than the granularity used in DateTime and TimeSpan in .NET, which is the tick.\n- Instant is a good type to use for \"when something happened\" - a timestamp in a log file, for example. The instant can then be interpreted in a particular time zone and calendar system, in a way which is useful to the person looking at the log.\n## Resources\n\n- https://blog.nodatime.org/2011/08/what-wrong-with-datetime-anyway.html","n":0.11}}},{"i":2676,"$":{"0":{"v":"Noa","n":1},"1":{"v":"\n- [[c.software.game-engine]]\n- repo: https://github.com/fenomas/noa","n":0.5}}},{"i":2677,"$":{"0":{"v":"Nns","n":1},"1":{"v":"\n\n- an germinating system for decentralized naming\n- [[c.publisher]] [[org.fission]]\n\n","n":0.333}}},{"i":2678,"$":{"0":{"v":"Nlua","n":1},"1":{"v":"\n- url: http://nlua.org/","n":0.577}}},{"i":2679,"$":{"0":{"v":"Natural Language Concrete Syntax Tree format","n":0.408},"1":{"v":"\n\n- symbols can be used in words!?\n- sometimes whitespace can have content, so would maybe be a symbol\n- seems writerly... but I guess sentences or paragraphs can capture utterances","n":0.186}}},{"i":2680,"$":{"0":{"v":"Nkn","n":1},"1":{"v":"\n## Resources\n\n- https://medium.com/nknetwork/introducing-decentralized-pub-sub-based-on-nkn-1036a950360d","n":0.577}}},{"i":2681,"$":{"0":{"v":"Nima","n":1},"1":{"v":"\n```yaml\nurl: https://helidon.io/nima\n\n```","n":0.707}}},{"i":2682,"$":{"0":{"v":"Nikola","n":1},"1":{"v":"\n- https://getnikola.com/\n- [[c.software.web.ssg]]\n- written-in: python\n- similar: [[prdct.eleventy]]","n":0.378}}},{"i":2683,"$":{"0":{"v":"Apache Nifi","n":0.707},"1":{"v":"\n- https://nifi.apache.org/\n- repo: https://github.com/apache/nifi\n- written-in: java\n\n## Similar\n\n- [[prdct.Airflow]]\n\n## Comparison\n\n### Nifi vs Airflow\n\n-   **Language**: Airflow is built using Python, while NiFi is built using Java.\n-   **Workflow Definition**: Airflow uses Python scripts to define workflows as DAGs, while NiFi relies on flow-based programming with a drag-and-drop interface.\n-   **Data Processing**: Airflow focuses primarily on orchestrating data processing tasks, whereas NiFi is more focused on data movement, routing, and transformation.\n-   **Scalability**: Airflow can be scaled horizontally with distributed task execution, while NiFi can scale out using its clustering feature.\n-   **Ease of Use**: NiFi’s web-based interface is more user-friendly, especially for non-developers, compared to Airflow’s Python-based workflow definition.","n":0.099}}},{"i":2684,"$":{"0":{"v":"NIEMOpen","n":1},"1":{"v":"\n- http://niem.github.io/\n- [[c.ontology]]\n- data-catalog: https://github.com/niemopen/niem-model/blob/dev/xsd/xml-catalog.xml","n":0.447}}},{"i":2685,"$":{"0":{"v":"NGSI-LD","n":1},"1":{"v":"\n\n\n- [[p.canExportTo]] [[prdct.json-ld]] \n","n":0.5}}},{"i":2686,"$":{"0":{"v":"Ngraph","n":1}}},{"i":2687,"$":{"0":{"v":"Nginx","n":1}}},{"i":2688,"$":{"0":{"v":"NextJS","n":1}}},{"i":2689,"$":{"0":{"v":"Nextjournal","n":1},"1":{"v":"\n- [[c.software.computational-notebook]]\n- url: https://nextjournal.com/\n- [[c.pricing]] \n\n## Features\n\n-   Creating and sharing the entire file system as a docker image\n-   Docker containers that are orchestrated by separate application\n-   Facility to use multiple programming languages in a single runtime\n-   Bash environment for installations during the project\n-   GPU support with minimal necessary setup","n":0.143}}},{"i":2690,"$":{"0":{"v":"Nextcloud","n":1},"1":{"v":"\n- url: https://nextcloud.com\n- similar: [[prdct.solid]]","n":0.447}}},{"i":2691,"$":{"0":{"v":"NewId","n":1},"1":{"v":"\n- repo: https://github.com/phatboyg/NewId\n- [[c.software.tools.id-generator]]\n- written-in: c#\n\n## Similar\n\n- [[prdct.newid]]\n- [[prdct.flake]]\n- [[prdct.sonyflake]]\n- [[prdct.ulid]]\n- [[prdct.idgen]]\n- [[prdct.nanoid]]\n- [[prdct.ksuid]]\n\n## References\n\n- https://andrewlock.net/generating-sortable-guids-using-newid/","n":0.25}}},{"i":2692,"$":{"0":{"v":"New Relic","n":0.707},"1":{"v":"\n\n\n- [[p.compatibleWith]] [[prdct.opentelemetry]]\n","n":0.577}}},{"i":2693,"$":{"0":{"v":"Neverlang","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n- url: https://neverlang.di.unimi.it/\n\n\n## Features\n\n- Feature-oriented programming in the context of language development is supported by language workbenches, such as [[prdct.mps]], [[prdct.rascal]], [[prdct.racket]], Neverlang, [[prdct.melange]], and [[prdct.spoofax]]\n\n## Resources\n\n- https://cacm.acm.org/magazines/2023/11/277434-scrambled-features-for-breakfast-concepts-of-agile-language-development/fulltext","n":0.186}}},{"i":2694,"$":{"0":{"v":"Neuron","n":1},"1":{"v":"\n\n#tools-for-thought\n\nhttps://neuron.zettel.page/\n\n","n":1}}},{"i":2695,"$":{"0":{"v":"Neuro Behavior Ontology","n":0.577},"1":{"v":"\n- \n- https://bioportal.bioontology.org/ontologies/NBO\n\n## Selection\n         \n        behavioral phenotype\n             \n            cognitive behavior phenotype\n             \n            dissociative disorders\n             \n            emission behavior phenotype\n                 \n                behavioral control of excretion phenotype\n                     \n                    behavioral control of defecation phenotype\n                     \n                    behavioral control of urination phenotype\n                 \n                behavioral control of external secretion phenotype\n                     \n                    behavioral control of lacrimation phenotype\n                 \n                behavioral control of production of sound phenotype\n             \n            emotional behavior phenotype\n                 \n                apathy\n                 \n                crying behavior phenotype\n                 \n                mobbing calling phenotype\n                 \n                pathological anxiety\n             \n            feeding behavior phenotype\n             \n            kinesthetic behavior phenotype\n             \n            mood disorder\n             \n            personality disorder\n             \n            psychotic disorder\n             \n            reproductive behavior phenotype\n             \n            rhythmic behavior phenotype\n             \n            seizures/epilepsy\n             \n            social behavior phenotype\n                 \n                selective mutism\n                 \n                social withdrawal\n             \n            somatoform behavior phenotype\n                 \n                conversion disorder\n                 \n                hypochondriasis\n         \n        cellular_component","n":0.091}}},{"i":2696,"$":{"0":{"v":"Neuralkg","n":1},"1":{"v":"\n- repo: https://github.com/zjukg/NeuralKG\n- ","n":0.577}}},{"i":2697,"$":{"0":{"v":"Neural Mmo","n":0.707},"1":{"v":"\n- url: https://openai.com/research/neural-mmo\n- repo: https://github.com/NeuralMMO/environment\n- written-in: #python\n\n## Supports\n- [[prdct.pettingzoo]]\n- [[t.math.geometry.chebyshev-distance]]","n":0.316}}},{"i":2698,"$":{"0":{"v":"Networkx","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://networkx.org/\n- written-in: #python\n\n## Resources\n\n- https://medium.com/towards-nesy/pyreason-software-for-open-world-temporal-logic-d67de751830e","n":0.378}}},{"i":2699,"$":{"0":{"v":"Networked Aframe","n":0.707},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/networked-aframe/networked-aframe\n","n":0.577}}},{"i":2700,"$":{"0":{"v":"Netplayjs","n":1},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/rameshvarun/netplayjs\n","n":0.577}}},{"i":2701,"$":{"0":{"v":"Netlogo","n":1},"1":{"v":"\n- docs: https://ccl.northwestern.edu/netlogo/docs/\n\n\n## Features\n\n\n    System:\n        Free, open source\n        Cross-platform: runs on Mac, Windows, Linux, et al\n        International character set support\n    Programming:\n        Fully programmable\n        Approachable syntax\n        Language is Logo dialect extended to support agents\n        Mobile agents (turtles) move over a grid of stationary agents (patches)\n        Link agents connect turtles to make networks, graphs, and aggregates\n        Large vocabulary of built-in language primitives\n        Double precision floating point math\n        First-class function values (aka anonymous procedures, closures, lambda)\n        Runs are reproducible cross-platform\n    Environment:\n        Command center for on-the-fly interaction\n        Interface builder w/ buttons, sliders, switches, choosers, monitors, text boxes, notes, output area\n        Info tab for annotating your model with formatted text and images\n        HubNet: participatory simulations using networked devices\n        Agent monitors for inspecting and controlling agents\n        Export and import functions (export data, save and restore state of model, make a movie)\n        BehaviorSpace, an open source tool used to collect data from multiple parallel runs of a model\n        System Dynamics Modeler\n        NetLogo 3D for modeling 3D worlds\n        Headless mode allows doing batch runs from the command line\n    Display and visualization:\n        Line, bar, and scatter plots\n        Speed slider lets you fast forward your model or see it in slow motion\n        View your model in either 2D or 3D\n        Scalable and rotatable vector shapes\n        Turtle and patch labels\n    APIs:\n        controlling API allows embedding NetLogo in a script or application\n        extensions API allows adding new commands and reporters to the NetLogo language; open source example extensions are included\n","n":0.065}}},{"i":2702,"$":{"0":{"v":"NetJSON","n":1},"1":{"v":"\n- repo: https://github.com/rpgmaker/NetJSON\n- written_in: c#","n":0.447}}},{"i":2703,"$":{"0":{"v":"Netim","n":1}}},{"i":2704,"$":{"0":{"v":"NestJS","n":1},"1":{"v":"\n## [[p.supports]]\n\n- [[prdct.fastify]] or [[prdct.express]]\n- [[prdct.asyncapi]] via [[prdct.nestjs-asyncapi]]\n- [[prdct.angular]]\n\n## Use Cases\n\n- [[t.cs.programming.repl]]\n  - https://docs.nestjs.com/recipes/repl\n\n\n## [[p.hasLearningResource]]\n\n- https://javascript.plainenglish.io/a-beginners-introduction-to-kafka-with-typescript-using-nestjs-7c92fe78f638\n\n\n## Comparisons\n\n- https://innovation.alteryx.com/choosing-an-api-framework-for-your-typescript-backend/\n  - vs. [[prdct.tsoa]]\n    - \"Nest is the smarter choice for most use cases.\"","n":0.18}}},{"i":2705,"$":{"0":{"v":"nestjs-asyncapi","n":1},"1":{"v":"\nrepo: https://github.com/flamewow/nestjs-asyncapi","n":0.707}}},{"i":2706,"$":{"0":{"v":"nest-commander","n":1},"1":{"v":"\nurl: https://nest-commander.jaymcdoniel.dev/en/introduction/intro/\nrepo: https://github.com/jmcdo29/nest-commander\n\n[[p.builtOn]] [[prdct.commander]]","n":0.5}}},{"i":2707,"$":{"0":{"v":"Neptune","n":1},"1":{"v":"\n- repo: https://github.com/neptune-ai/neptune-client\n- [[p.hadDependancy]] [[prdct.neptune-ai]]","n":0.447}}},{"i":2708,"$":{"0":{"v":"Neptune Ai","n":0.707},"1":{"v":"\n- url: https://app.neptune.ai","n":0.577}}},{"i":2709,"$":{"0":{"v":"Nepomuk File Ontology (NFO)","n":0.5},"1":{"v":"\n- https://www.semanticdesktop.org/ontologies/2007/03/22/nfo/\n- related: https://www.w3.org/TR/HTTP-in-RDF/","n":0.5}}},{"i":2710,"$":{"0":{"v":"Neon","n":1},"1":{"v":"\n\n\n- resources: \n  - https://skwee357.medium.com/supercharge-your-nodejs-with-rust-f78952d2fa8\n","n":0.447}}},{"i":2711,"$":{"0":{"v":"Neo4j","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[t.cs.data.DBMS.graph]]\n","n":0.577}}},{"i":2712,"$":{"0":{"v":"Neo4j Object Graph mapper","n":0.5},"1":{"v":"\n- [[c.Software.object-graph-mapper]]\n- docs: https://neo4j.com/docs/ogm-manual\n- support: java\n- similar: [[prdct.gqlalchemy]]","n":0.354}}},{"i":2713,"$":{"0":{"v":"Neosemantics","n":1},"1":{"v":"\n\n- url https://neo4j.com/labs/neosemantics/\n- aka: n10s\n- licensing:\n  - only available for Neo4j Enterprise and not available in Aura\n\n## Features\n\n-  build integrations with RDF-generating / RDF-consuming components. \n-  validate your graph against constraints expressed in SHACL or to run basic inferencing.","n":0.16}}},{"i":2714,"$":{"0":{"v":"Nengi","n":1},"1":{"v":"\n- [[c.software.game-engine]]\n- ","n":0.707}}},{"i":2715,"$":{"0":{"v":"Neighborhoods","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://neighbourhoods.network/\n- [[p.builtOn]] [[prdct.sacred-capital.reputation-vault]]\n","n":0.447}}},{"i":2716,"$":{"0":{"v":"NegMAS","n":1},"1":{"v":"\n- url: https://pypi.org/project/negmas/\n- repo: https://github.com/yasserfarouk/negmas\n- ","n":0.447}}},{"i":2717,"$":{"0":{"v":"Nebulagraph","n":1},"1":{"v":"\n- [[c.software.database.graph.property]]\n- url: https://www.nebula-graph.io/\n- repo: https://github.com/vesoft-inc/nebula\n- written-in: #c++\n- ","n":0.354}}},{"i":2718,"$":{"0":{"v":"Nebula Jl","n":0.707},"1":{"v":"\n- repo: https://github.com/AliceRoselia/Nebula.jl\n  - [[c.mention]] [[prdct.modeling-toolkit]] [[prdct.overseer]]","n":0.378}}},{"i":2719,"$":{"0":{"v":"Near Protocol","n":0.707},"1":{"v":"\n\n\n- [[p.hasSite]] https://near.org/\n- \"NEAR runs in concert with Ethereum, Polkadot, Cosmos, and more, allowing for the free flow of assets and communication between networks for the betterment of all.\"\n","n":0.186}}},{"i":2720,"$":{"0":{"v":"Ndjson","n":1},"1":{"v":"\n- https://github.com/ontola/hextuples\n\n## Solutions\n\n- https://github.com/ontola/hextuples-parser\n- [[prdct.rdflib]]","n":0.447}}},{"i":2721,"$":{"0":{"v":"NATS","n":1},"1":{"v":"\n\n- [[c.software.messaging.bus]] \n- url: https://nats.io/\n- similar: [[prdct.nats]] [[prdct.memphis]] [[prdct.nsq]] ^69m6e1oxkdup\n- written-in: #go\n- cloud-service: https://www.synadia.com/cloud\n- related: [[prdct.walnats]] [[prdct.benthos]]\n\n## Terms\n\n- A **Leaf Node** extends an existing NATS system of any size, optionally bridging both operator and security domains.\n  - Traffic between the leaf node and the cluster assumes the restrictions of the user configuration used to create the leaf connection.\n    - Subjects that the user is allowed to publish are exported to the cluster.\n    - Subjects the user is allowed to subscribe to, are imported into the leaf node.\n  - Leaf nodes appear to the cluster as a single account connection. Leaf nodes can provide continuous NATS service for their clients, even while being temporarily disconnected from the cluster(s). You can even enable JetStream on the leaf nodes in order to create local streams that are mirrored (mirroring is store and forward and therefore can recover from connectivity outages) to global streams in the upstream cluster(s).\n\n## Hosting\n\n- Synadia cloud\n- [[prdct.fly-io]] #free-tier\n  - \"While the cluster is only accessible from inside the Fly network, you can use Fly's Wireguard support to create a VPN into your Fly organisation and private network.\"\n\n## [[p.hasFeature]]\n\n- three basic communication patterns\n  - Publish Subscribe\n  - Request/Reply (uses a special \"reply subject\")\n  - Distributed Load Balanced Queue\n- [[prdct.nats.jetstream]] for persistence\n- [[p.supports]] [[prdct.cloudevents]]\n  - https://github.com/cloudevents/spec/blob/main/cloudevents/bindings/nats-protocol-binding.md\n- Synadia cloud has an HTTP gateway\n  - leverages server-send events (SSE)\n- embeddable\n\n## Comparison\n\n### Kafka vs NATS\n\n- partitions and topics \"makes Kafka highly suited to applications where order matters; for example, state machine replication, event sourcing, log shipping, log aggregation, SEDA (staged event- driven architecture) and CEP (complex event processing).\"\n- Speaking of topics, the equivalent NATS subject is a lightweight construct that is created automatically based on demand (subscriptions) and is pruned automatically when the demand ceases. NATS subjects are cheap to create, which makes them great for hierarchically organised data, allowing for a fine-grained subscription model.\n- (Note: NATS Streaming addresses this, but as stated earlier, it is a different product in its own right.)\n- Kafka will never assign a partition to multiple consumers in the same group. So, although Kafka’s load balancing scheme is more coarse-grained than NATS’; it manages to preserve the order of records at the consumer nodes.\n- kafka is lightweight\n\n#### Dendrite use case\n\n- \"switching to JetStream was transformational. Performance is excellent overall. We make heavy use of the interest-based retention policies to ensure that work is cleaned up when it is complete. We take advantage of being able to manually acknowledge items to ensure they were processed successfully before cleaning up. We’ve been able to successfully manage pools of workers from NATS streams and considerably reduce the amount of complexity in our codebase in a number of places which no longer need their own persistent storage. We’ve even had it successfully running in application-embedded scenarios on iOS and Android as a part of our peer-to-peer demos.\"\n\n## [[p.hasLearningResource]]\n\n- https://natsbyexample.com/\n\n\n## References\n\n- https://www.quora.com/What-is-the-difference-between-Apache-Kafka-and-NATS\n- https://nats.io/blog/matrix-dendrite-kafka-to-nats/","n":0.046}}},{"i":2722,"$":{"0":{"v":"nats.ws","n":1},"1":{"v":"\n- repo: https://github.com/nats-io/nats.ws\n- [[p.builtOn]] \n\n\n## Resources\n\n- https://nats.io/blog/getting-started-nats-ws/","n":0.378}}},{"i":2723,"$":{"0":{"v":"Ngs","n":1}}},{"i":2724,"$":{"0":{"v":"Jetstream","n":1},"1":{"v":"\n- [[c.software.data-framework.streaming]]\n- url: https://docs.nats.io/nats-concepts/jetstream\n\n","n":0.5}}},{"i":2725,"$":{"0":{"v":"Narrative Ontology (NOnt)","n":0.577},"1":{"v":"\n- related: [[prdct.cidoc-crm]] [[prdct.frbr]] [[prdct.owl-time]] \n  \n## References\n\n- [[ar.representing-narratives-in-digital-libraries-the-narrative-ontology]]","n":0.333}}},{"i":2726,"$":{"0":{"v":"Nanoid","n":1},"1":{"v":"\n- [[c.software.tools.id-generator]]\n- repo: https://github.com/ai/nanoid\n\n## Features\n\n- compact\n\n## Cons\n\n- not sortable\n\n![[prdct.newid#similar]]","n":0.333}}},{"i":2727,"$":{"0":{"v":"Named Data Networking","n":0.577},"1":{"v":"\n- url: https://named-data.net/\n- ","n":0.577}}},{"i":2728,"$":{"0":{"v":"Nakama","n":1},"1":{"v":"\n- [[c.software.game-platform]] [[c.software.game-framework]]\n- repo: https://github.com/heroiclabs/nakama\n- written-in: #go\n- [[p.hasScriptingLanguage]] typescript [[prdct.lua]]\n- [[p.hasClientSupport]] [[prdct.unity]] [[prdct.unreal]] [[prdct.godot]] [[prdct.defold]] [[prdct.cocos2d]] javascript java #c #c++ [[prdct.flutter]]\n- [[p.hadPricing]] https://heroiclabs.com/pricing/\n- [[p.hadEtymology]]  In Japanese, the word nakama 仲間 means \"someone who's in the same group as you,\" or can refer to the group itself.\n- written-in: \n  - Go 86.5%\n  - Lua 5.1%\n  - TypeScript 4.4%\n- [[p.wasBuiltBy]] [[org.heroic-labs]]\n\n## Features\n-   Low-level control of real-time [routing and delivery](https://heroiclabs.com/docs/nakama/server-framework/streams/)\n-   Intercept and override functionality with [hooks](https://heroiclabs.com/docs/nakama/server-framework/introduction/#hooks)\n-   Define and call [RPC functions](https://heroiclabs.com/docs/nakama/server-framework/introduction/#rpc-functions)\n-   Run background server cron [jobs](https://heroiclabs.com/docs/nakama/guides/server-framework/background-jobs/)\n-   [Access controls](https://heroiclabs.com/docs/nakama/concepts/storage/permissions/) and [API guarding](https://heroiclabs.com/docs/nakama/guides/server-framework/guarding-apis/)\n\n## [[c.limitation]]\n\n- The JavaScript runtime code is fully sandboxed and cannot access the filesystem, input/output devices, or spawn OS threads or processes.\n\n- The JavaScript runtime is powered by the goja VM which currently supports the JavaScript ES5 spec. The JavaScript runtime has access to the standard library functions included in the ES5 spec.\n\n- There is no support for libraries that require Node, web/browser APIs, or native support (e.g. via Node).\n\n- You cannot call TypeScript functions from the Go runtime, or Go functions from the TypeScript runtime.\n\nThe JavaScript runtime code is executed in instanced contexts (VM pool). You cannot use global variables as a way to store state in memory or communicate with other JS processes or function calls.\n  \n## [[p.provokedThoughts]]\n\n- [Storage Engine] seems key-value/JSON-based (https://heroiclabs.com/docs/nakama/concepts/storage/collections/)\n\n## [[p.hasFeature]]\n\n-   **Users** - Register/login new users via social networks, email, or device ID.\n-   **Storage** - Store user records, settings, and other objects in collections.\n-   **Social** - Users can connect with friends, and join groups. Builtin social graph to see how users can be connected.\n-   **Chat** - 1-on-1, group, and global chat between users. Persist messages for chat history.\n-   **Multiplayer** - Realtime, or turn-based active and passive multiplayer.\n-   **Leaderboards** - Dynamic, seasonal, get top members, or members around a user. Have as many as you need.\n-   **Tournaments** - Invite players to compete together over prizes. Link many together to create leagues.\n-   **Parties** - Add team play to a game. Users can form a party and communicate with party members.\n-   **Runtime code** - Extend the server with custom logic written in Lua, TypeScript/JavaScript, or native Go code.\n    - [[**NOTE**|p.hadLimitation]]\n      - There is no support for libraries that require Node, web/browser APIs, or native support (e.g. via Node).\n      - The use of multi-threaded processing is not supported in the JavaScript runtime.\n-   **Matchmaker**, **dashboard**, **metrics**, and [more](https://heroiclabs.com/docs).  \n\n## [[t.cs.sd.architecture]]\n\n- https://heroiclabs.com/docs/nakama/getting-started/architecture/\n  - \"If data needs to be distributed to clients live, streams are the way it gets there. Individual player sessions join and leave streams, like subscribing and unsubscribing to a continuous flow of messages.\"\n\n- [[c.software.game-platform]] [[c.software.game-framework]]","n":0.049}}},{"i":2729,"$":{"0":{"v":"Server Framework","n":0.707},"1":{"v":"\n- [[p.supports]] [[prdct.lua]] typescript and #go\n","n":0.408}}},{"i":2730,"$":{"0":{"v":"Flutter client for Nakama","n":0.5},"1":{"v":"\n- [[p.hasLearningResource]] https://flutter-nakama.gitbook.io\n","n":0.577}}},{"i":2731,"$":{"0":{"v":"Nact","n":1},"1":{"v":"\n- url: https://nact.xyz/\n- repo: \n- [[p.supports]] [[prdct.reason-ml]]","n":0.378}}},{"i":2732,"$":{"0":{"v":"n8n","n":1},"1":{"v":"\n- repo: https://github.com/n8n-io/n8n\n- [[p.instanceOf]] [[c.software.workflow]]\n- #similar [[prdct.n8n]] [[prdct.dagster]] [[prdct.temporal]] [[prdct.prefect]] [[prdct.airflow]]  ^xnxaubd7sqiw\n- written-in: typescript\n\n## Comparison\n\n- https://jlgjosue.medium.com/alternatives-to-airflow-exist-bb2739a93b33 \n\n## #license\n\nPortions of this software are licensed as follows:\n\n-   Content of branches other than the main branch (i.e. \"master\") are not licensed.\n-   All source code files that contain \".ee.\" in their filename are licensed under the \"[[n8n Enterprise License|t.leg.licensing.n8n-enterprise-license]]\" defined in \"LICENSE\\_EE.md\".\n-   All third party components incorporated into the n8n Software are licensed under the original license provided by the owner of the applicable component.\n-   Content outside of the above mentioned files or restrictions is available under the \"[[Sustainable Use License|t.leg.licensing.sustainable-use-license]]\" as defined below.\n\n\n\n\n","n":0.1}}},{"i":2733,"$":{"0":{"v":"N3.js","n":1},"1":{"v":"\n- repo: https://github.com/rdfjs/N3.js\n- similar: [[prdct.n3-js]] [[prdct.rdflib-js]] [[prdct.rdfstore-js]] ^gxsdwqmu5a84","n":0.354}}},{"i":2734,"$":{"0":{"v":"MyTrails","n":1}}},{"i":2735,"$":{"0":{"v":"Mystic AI","n":0.707}}},{"i":2736,"$":{"0":{"v":"Myriad","n":1},"1":{"v":"\n- repo: https://github.com/MoiraeSoftware/myriad\n- keywords: [[t.cs.metaprogramming]]","n":0.447}}},{"i":2737,"$":{"0":{"v":"Mxgraph","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/jgraph/mxgraph\n- url: https://jgraph.github.io/mxgraph/\n- [[p.supports]] java [[t.cs.languages.c-sharp]] javascript","n":0.316}}},{"i":2738,"$":{"0":{"v":"Mutant Year Zero","n":0.577}}},{"i":2739,"$":{"0":{"v":"Mudlet","n":1},"1":{"v":"\n- [[c.software.game-platform.multi-user-dungeon]]\n- url: https://www.mudlet.org/\n- repo: https://github.com/Mudlet/Mudlet\n- written-in: #c++ [[prdct.lua]]","n":0.333}}},{"i":2740,"$":{"0":{"v":"Msg Fabric Core","n":0.577},"1":{"v":"\n- #dead?\n- ","n":0.707}}},{"i":2741,"$":{"0":{"v":"Mqtt","n":1},"1":{"v":"\n- [[p.supports]] [[prdct.cloudevents]]\n\n## Implementations\n\n- [[prdct.hivemq]]\n- [[prdct.aedes]]","n":0.408}}},{"i":2742,"$":{"0":{"v":"Meta Programming System","n":0.577},"1":{"v":"\n- [[c.software.language-workbench]]\n- repo: https://github.com/JetBrains/MPS\n\n\n## [[p.vs]]\n\n- [[prdct.xtext]] \n  - https://stackoverflow.com/questions/2603134/what-are-the-main-differences-between-jetbrains-mps-and-eclipse-xtext\n- ","n":0.333}}},{"i":2743,"$":{"0":{"v":"Mpi4py","n":1},"1":{"v":"\n- #docs https://mpi4py.readthedocs.io/en/stable/\n- repo: https://github.com/mpi4py/mpi4py/\n- ","n":0.447}}},{"i":2744,"$":{"0":{"v":"Movim","n":1},"1":{"v":"\n- [[c.software.xmpp-client.web]]\n- repo: https://github.com/movim/movim\n- written-in: javascript #php\n- url: https://movim.eu/","n":0.333}}},{"i":2745,"$":{"0":{"v":"Motion Canvas","n":0.707},"1":{"v":"\n- url: https://motioncanvas.io/\n- repo: https://github.com/motion-canvas/motion-canvas\n- #writtenIn typescript\n  \n## Features\n\n- signals: represents a value that can change over time, and can define dependencies between values\n\n## Resources\n\n- https://www.youtube.com/watch?v=H5GETOP7ivs","n":0.196}}},{"i":2746,"$":{"0":{"v":"Morphir","n":1},"1":{"v":"\n- url: https://morphir.finos.org/\n- repo: https://github.com/finos/morphir\n- written-in: typescript javascript\n- [[p.supports]] #elm #bosque -transpiled-> scala","n":0.277}}},{"i":2747,"$":{"0":{"v":"Morpeh","n":1},"1":{"v":"\n- repo: https://github.com/scellecs/morpeh\n- ","n":0.577}}},{"i":2748,"$":{"0":{"v":"Moose","n":1},"1":{"v":"\n- url: http://moosetechnology.org/\n- ","n":0.577}}},{"i":2749,"$":{"0":{"v":"Moonsharp","n":1},"1":{"v":"\n- #dead\n- url: https://www.moonsharp.org/\n- repo: https://github.com/moonsharp-devs/moonsharp\n- #related [[prdct.unity-lua]]","n":0.354}}},{"i":2750,"$":{"0":{"v":"Monticore","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n- url: https://monticore.github.io/monticore/\n- written-in: java\n- [[p.supports]] [[prdct.intellij]] [[prdct.eclipse]]","n":0.333}}},{"i":2751,"$":{"0":{"v":"Monoplasma","n":1},"1":{"v":"\n## Resources\n\n- https://medium.com/streamrblog/monoplasma-revenue-share-dapps-off-chain-6cb7ee8b42fa","n":0.577}}},{"i":2752,"$":{"0":{"v":"Mongooseim","n":1}}},{"i":2753,"$":{"0":{"v":"Mongodb","n":1}}},{"i":2754,"$":{"0":{"v":"Monaco Editor","n":0.707},"1":{"v":"\n- https://microsoft.github.io/monaco-editor/\n- [[c.software.web.toolkit]]\n- repo: https://github.com/microsoft/monaco-editor","n":0.447}}},{"i":2755,"$":{"0":{"v":"moment.js","n":1}}},{"i":2756,"$":{"0":{"v":"Molten Hosting","n":0.707},"1":{"v":"\n- https://moltenhosting.com/\n\n\n## FAQ\n\n### How can I let my players start my server if I’m not around?\nOn our management webpage, you can find a server startup “magic link”. You can provide this link to your players to start the server at anytime. Note: You will still need to provide your players with your Foundry administrator password if choose to set one.","n":0.129}}},{"i":2757,"$":{"0":{"v":"Molecular","n":1},"1":{"v":"\n[[c.software.microservice-frameworks]]\nwritten-in: javascript\n\nurl: https://moleculer.services/\nrepo: https://github.com/moleculerjs/moleculer\n\n## [[p.hasFeature]]\n\n-   Promise-based solution (async/await compatible)\n-   request-reply concept\n-   support event driven architecture with balancing\n-   built-in service registry & dynamic service discovery\n-   load balanced requests & events (round-robin, random, cpu-usage, latency, sharding)\n-   many fault tolerance features (Circuit Breaker, Bulkhead, Retry, Timeout, Fallback)\n-   plugin/middleware system\n-   support versioned services\n-   support [Stream](https://nodejs.org/dist/latest-v10.x/docs/api/stream.html)s\n-   service mixins\n-   built-in caching solution (Memory, MemoryLRU, Redis)\n-   pluggable loggers (Console, File, Pino, Bunyan, Winston, Debug, Datadog, Log4js)\n-   pluggable transporters (TCP, NATS, MQTT, Redis, NATS Streaming, Kafka, AMQP 0.9, AMQP 1.0)\n-   pluggable serializers (JSON, Avro, MsgPack, Protocol Buffer, Thrift)\n-   pluggable parameter validator\n-   multiple services on a node/server\n-   master-less architecture, all nodes are equal\n-   parameter validation with [fastest-validator](https://github.com/icebob/fastest-validator)\n-   built-in metrics feature with reporters (Console, CSV, Datadog, Event, Prometheus, StatsD)\n-   built-in tracing feature with exporters (Console, Datadog, Event, Jaeger, Zipkin)\n-   official [API gateway](https://github.com/moleculerjs/moleculer-web), [Database access](https://github.com/moleculerjs/moleculer-db) and many other modules…\n\n\n## Resources\n\n- https://techblog.geekyants.com/migrating-your-molecular-project-to-ts","n":0.085}}},{"i":2758,"$":{"0":{"v":"Moise","n":1},"1":{"v":"\n- https://moise-lang.github.io/\n- repo: https://github.com/moise-lang/moise\n\n\n## References\n\n- [ORA4MAS (Moise platform based on artifacts)](https://github.com/moise-lang/moise/blob/main/doc/ora4mas/readme.adoc)","n":0.302}}},{"i":2759,"$":{"0":{"v":"Modelio","n":1},"1":{"v":"\n- url: \n- #publisher [[org.modeliosoft]]","n":0.447}}},{"i":2760,"$":{"0":{"v":"Modeling Toolkit","n":0.707},"1":{"v":"\n- written-in: #julia\n- repo: https://github.com/SciML/ModelingToolkit.jl/","n":0.447}}},{"i":2761,"$":{"0":{"v":"Model","n":1},"1":{"v":"\n- url: https://github.com/goadesign/model\n- [[c.software.tools.diagramming]]","n":0.5}}},{"i":2762,"$":{"0":{"v":"MOD Ontology","n":0.707},"1":{"v":"\n- url: https://github.com/FAIR-IMPACT/MOD\n- description: Metadata for Ontology Description and Publication\n- related: [[prdct.widoco]]","n":0.289}}},{"i":2763,"$":{"0":{"v":"Mochikit","n":1},"1":{"v":"\n- [[c.software.web.toolkit]]\n![[prdct.dojo_toolkit#^tmacjwe8emtq]]","n":0.707}}},{"i":2764,"$":{"0":{"v":"Mocha","n":1},"1":{"v":"\nurl: https://mochajs.org/\nrepo: https://github.com/mochajs/mocha\n\n- [[p.comparableTo]] [[prdct.jest]] [[prdct.jasmine]] [[prdct.cypress]]\n  - [[p.hasComparison]] https://www.merixstudio.com/blog/mocha-vs-jest/\n\n| Mocha | Jest | Jasmine | Cypress |\n| --- | --- | --- | --- |\n| test runner | testing framework | testing framework | test framework |\n| requires other libraries to work | no preconfiguration required | requires a runner and assertion/mocking lib |\n| offers a huge dose of flexibility regarding test development | focused on simplicity | most flexible |\n| originally designed for Node.js | originally designed for React | popular with angular, used with node.js | web-based frontend apps\n","n":0.104}}},{"i":2765,"$":{"0":{"v":"MobX","n":1},"1":{"v":"\n- [[c.software.state-store]]\n- url: https://mobx.js.org\n\n\n## Philosophy\n\n- straightforward\n\n## Resources","n":0.378}}},{"i":2766,"$":{"0":{"v":"ML2","n":1},"1":{"v":"\n\n\n## References\n\n- [[ar.ml2-an-expressive-multi-level-conceptual-modeling-language]]","n":0.577}}},{"i":2767,"$":{"0":{"v":"Miski","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://phughesmcr.github.io/Miski/\n- [[p.hasRepository]] https://github.com/phughesmcr/Miski\n-  ","n":0.447}}},{"i":2768,"$":{"0":{"v":"Mirror","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://mirror.xyz/\n- [[p.supportedBy]] [[prdct.arweave]]\n","n":0.447}}},{"i":2769,"$":{"0":{"v":"Mira","n":1},"1":{"v":"\n## References\n\n- [[ar.mira-a-model-driven-framework-for-semantic-interfaces-for-web-applications]]\n- [[ar.adaptive-linked-data-driven-web-com-ponents-building-flexible-and-reusable-semantic-web-interfaces]]","n":0.5}}},{"i":2770,"$":{"0":{"v":"Miniplex","n":1},"1":{"v":"\n- [[c.software.entity-component-system]]\n- repo: https://github.com/hmans/miniplex\n- written-in: typescript\n- #creator [[user.hendrik-mans]]\n\n## Resources\n\n- https://douges.dev/blog/simplifying-r3f-with-ecs","n":0.316}}},{"i":2771,"$":{"0":{"v":"Minikube","n":1}}},{"i":2772,"$":{"0":{"v":"Diagrams (Mingrammer)","n":0.707},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- written-in: #python\n- repo: https://github.com/mingrammer/diagrams\n- url: https://diagrams.mingrammer.com/\n- [[p.supports]] [[t.cs.sd.c4-model]]\n\n## Resources\n\n- https://diagrams.mingrammer.com/docs/getting-started","n":0.289}}},{"i":2773,"$":{"0":{"v":"Minetest","n":1},"1":{"v":"\n- [[c.game.voxel]] [[c.game.sandbox]]\n- url: https://www.minetest.net/\n- repo: https://github.com/minetest/minetest\n- [[p.hasAPI]] [[prdct.lua]]\n- [[c.exchange]]\n- written-in: #c++","n":0.289}}},{"i":2774,"$":{"0":{"v":"Minecraft","n":1},"1":{"v":"\n- [[c.game.voxel]] [[c.game.sandbox]]\n\n\n## Related\n\n- [[game.dungeons-and-dragons]] content coming from https://everbloomgames.com/","n":0.333}}},{"i":2775,"$":{"0":{"v":"Universal Data Api","n":0.577},"1":{"v":"\n- url: https://open.mimiro.io/specifications/uda/latest.html\n- ","n":0.577}}},{"i":2776,"$":{"0":{"v":"Milo","n":1}}},{"i":2777,"$":{"0":{"v":"Milleniumdb","n":1},"1":{"v":"\n- repo: https://github.com/MillenniumDB/MillenniumDB\n- [[p.supports]] [[prdct.rdf]] OR QuadModel\n\n## References\n\n- [[ar.millennium-db-an-open-source-graph-database-system]]\n","n":0.333}}},{"i":2778,"$":{"0":{"v":"MikroORM","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://mikro-orm.io/\n- [[p.hasRepository]] \n","n":0.447}}},{"i":2779,"$":{"0":{"v":"Midway","n":1},"1":{"v":"\n- https://midwayjs.org/en/\n- written-in: typescript","n":0.5}}},{"i":2780,"$":{"0":{"v":"Midjourney","n":1}}},{"i":2781,"$":{"0":{"v":"Middleclass","n":1},"1":{"v":"\n- url: https://github.com/kikito/middleclass/\n\n## c.Feature\n\n- [\"weak\" mixins](https://github.com/kikito/middleclass/wiki/Mixins) \n  - only functions, not data?","n":0.289}}},{"i":2782,"$":{"0":{"v":"Micropsi2","n":1},"1":{"v":"\n- https://github.com/joschabach/micropsi2\n- written-in: python","n":0.5}}},{"i":2783,"$":{"0":{"v":"Micronaut","n":1},"1":{"v":"\n- [[c.software.microservice-frameworks]]\n- url: https://micronaut.io/\n- repo: https://github.com/micronaut-projects/micronaut-core\n- similar: [[prdct.quarkus]] \n\n\n## References\n\n- https://www.infoq.com/news/2023/07/micronaut-brings-virtual-thread/\n- https://www.reddit.com/r/Kotlin/comments/12p9k89/whats_the_state_of_serverside_frameworks_with/","n":0.289}}},{"i":2784,"$":{"0":{"v":"Micromark","n":1},"1":{"v":"\n- [[p.hasComparison]] https://github.com/micromark/micromark\n  - [[p.hasComparand]]","n":0.447}}},{"i":2785,"$":{"0":{"v":"Microledger","n":1}}},{"i":2786,"$":{"0":{"v":"Microcks","n":1},"1":{"v":"\n- repo: https://github.com/microcks/microcks\n- written_in: java\n- supports: [[prdct.openapi]] [[prdct.grpc]] [[prdct.graphql]] [[prdct.postman]] \n- supports: [[prdct.asyncapi]] \n  - \"AsyncAPI is an open source initiative that seeks to improve the current state of Event-Driven Architectures (EDA). Its long-term goal is to make working with EDA’s as easy as it is to work with REST APIs.\"\n  - \"Microcks supports the KAFKA, the MQTT, the WS (for WebSocket), the AMQP, the NATS, the GOOGLEPUBSUB, the SQS and the SNS bindings\"\n\n## Features\n\n- \"It deploys it’s own Kafka broker, and if you upload your AsyncAPI spec it creates Kafka topics based on the description in the spec, and starts generating and producing mock data to them on a frequency interval that you specify.\"\n\n## References\n\n- https://microcks.io/documentation/using/asyncapi/\n- https://dalelane.co.uk/blog/?p=4219","n":0.092}}},{"i":2787,"$":{"0":{"v":"Metronome","n":1},"1":{"v":"\n- [[c.software.xmpp-server]]\n- repo: https://github.com/maranda/metronome\n- written-in: [[prdct.lua]]\n- [[p.forkOf]] [[prdct.prosody]] ","n":0.354}}},{"i":2788,"$":{"0":{"v":"Methontology","n":1},"1":{"v":"\n- [[c.methodology.ontology-engineering]]","n":0.707}}},{"i":2789,"$":{"0":{"v":"Meteor","n":1},"1":{"v":"\n- [[c.software.web-framework]]\n- url: https://www.meteor.com/","n":0.5}}},{"i":2790,"$":{"0":{"v":"Meteo","n":1},"1":{"v":"\n- ","n":1}}},{"i":2791,"$":{"0":{"v":"Metaverse Markup Language","n":0.577},"1":{"v":"\n- https://mml.io/\n- written-in: typescript\n\n\n## Description\n\nThe \"MML stack\" is a combination of two main pieces usually combined together:\n\n- MML (Language) - 3D HTML elements and attributes for describing 3D objects and experiences\n- Networked DOM (Networking) - A library and network protocol for running MML/HTML documents on a server so that multiple users can interact with them in a multi-user mode.\n\nHTML and JavaScript in the form of the DOM (Document Object Model) provide an existing foundation for describing and mutating a hierarchy of elements. MML uses this foundation with new elements and attributes to allow describing 3D concepts.\n\n\n## Features\n\n- Portability: MML documents can run in any modern web browser, making them easy to share and view.\n- Composability: MML documents can be composed of multiple documents running on different servers, making it possible to create complex virtual world objects without having to provide all the compute power and technical capability on a single server.","n":0.081}}},{"i":2792,"$":{"0":{"v":"Metaplex","n":1}}},{"i":2793,"$":{"0":{"v":"Metaphactory","n":1},"1":{"v":"\n- https://metaphacts.com/product/metaphactory-overview\n- [[t.cs.sd.low-code]] [[t.cs.data.fair]]\n\n\n## Features\n\n- Knowledge Graph Management - metaphactory makes working with RDF data, SPARQL queries, and ontologies easy and straightforward: UI for data loading, ontology library, SPARQL query UI and query catalog, data quality dashboard and more.\n- Rapid Application Development - metaphactory provides Web components for search, exploration, authoring & editing, visualization and interacting with graph data; the components can be set up and combined in minutes for rapid application development.\n- End-user oriented interaction with Knowledge Graphs - metaphactory leverages the advantages of the Knowledge Graph for end users by providing intuitive interfaces for drug discovery, supply chain optimization, library management, and many more.\n\n## Pricing\n\n“starting from $13.03/hr or from $52,900.00/yr” on Amazon\n\n## References\n\n- https://aws.amazon.com/marketplace/seller-profile?id=a04eaa90-2616-469a-a304-96d35bd77641","n":0.093}}},{"i":2794,"$":{"0":{"v":"Metalsmith","n":1},"1":{"v":"\n- https://metalsmith.io/\n- [[t.cs.web.static-site-generator]]\n- related: [[prdct.metalsmith-ldschema]]\n\n\n## Features\n\n- **pluggable**: You shouldn't have to bend your project needs to a specific framework or tool. Metalsmith gives you full control of how you want to conceptualize, structure and build your project","n":0.164}}},{"i":2795,"$":{"0":{"v":"Metalsmith Ldschema","n":0.707},"1":{"v":"\n- repo: https://github.com/howarddierking/metalsmith-ldschema\n- depends_on: [[prdct.clownface]]\n## References\n\n- https://howarddierking.com/2016/12/02/generating-documentation-sites-for-linked-data-vocabularies/\n\n## Issues\n\n- only one template for each of classes, properties, index","n":0.243}}},{"i":2796,"$":{"0":{"v":"Metagraph","n":1},"1":{"v":"\n- Doesn't really support metagraphs\n- repo: https://github.com/metagraph-dev/metagraph","n":0.378}}},{"i":2797,"$":{"0":{"v":"MetaEdit+","n":1},"1":{"v":"\n- url: https://www.metacase.com/solution/","n":0.577}}},{"i":2798,"$":{"0":{"v":"Meta","n":1},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/mateodelnorte/meta\n- resources:  https://kinsta.com/blog/monorepo-vs-multi-repo/\n- [[p.solvesProblem]] [[t.cs.sd.monorepo]] [[t.cs.sd.polyrepo]]\n","n":0.354}}},{"i":2799,"$":{"0":{"v":"Messagepack","n":1},"1":{"v":"\n## Comparisons\n\n### vs [[prdct.protobuf]]\n\n- \"The Protocol Buffers format provides a significantly more compact transmission format than MessagePack because it doesn't transmit field names. However, while JSON and MessagePack aim to serialize arbitrary data structures with type tags, Protocol Buffers require a schema to define the data types.\"","n":0.146}}},{"i":2800,"$":{"0":{"v":"Meshcapade","n":1},"1":{"v":"\n- [[c.software.3d.generator]]","n":0.707}}},{"i":2801,"$":{"0":{"v":"Mermaid","n":1},"1":{"v":"\n![[prdct.structurizr#similar]]\n\n\n## Features\n\n- github can render mermaid automatically ^5hmcpg411lwy\n- \n","n":0.333}}},{"i":2802,"$":{"0":{"v":"Mercure","n":1},"1":{"v":"\n\n- https://mercure.rocks/\n- built-on: [[prdct.server-sent-events]]\n- written-in: go\n- similar: [[prdct.centrifugo]] [[prdct.mercure]] ^ahtfnaeq7g62\n\n## Comparison\n\n![[prdct.websub#websub-vs-mercure]]\n\n### Mercure vs Web Push\n\nThe [Push API](https://developer.mozilla.org/en-US/docs/Web/API/Push_API) is a simplex protocol [mainly designed](https://developers.google.com/web/fundamentals/push-notifications/) to send [notifications](https://developer.mozilla.org/en-US/docs/Web/API/Notifications_API) to devices currently not connected to the application. In most implementations, the size of the payload to dispatch is very limited, and the messages are sent through the proprietary APIs and servers of the browsers' and operating systems' vendors.\n\nOn the other hand, Mercure is a duplex protocol designed to send live updates to devices currently connected to the web or mobile app. The payload is not limited, and the message goes directly from your servers to the clients.\n\nIn summary, use the Push API to send notifications to offline users (that will be available in Chrome, Android and iOS's notification centers), and use Mercure to receive and publish live updates when the user is using the app\n\n### Mercure vs Centrifugo\n\n- [[prdct.centrifugo]] supports more complex and diverse communication protocols beyond SSE, including WebSocket, which is more suitable for environments where high throughput and lower latency are required.\n- Centrifugo offers private and public channels, presence channels, and authentication features.\n- Scalability: Centrifugo is designed to handle large numbers of concurrent clients, making it suitable for more intensive real-time applications.\n- Mercure has that built-in integration with [[prdct.api-platform]]","n":0.069}}},{"i":2803,"$":{"0":{"v":"Mental Functioning Ontology","n":0.577},"1":{"v":"\n- https://obofoundry.org/ontology/mf.html\n- repo: https://github.com/jannahastings/mental-functioning-ontology\n- related: [[prdct.basic-formal-ontology]]\n\n## Example\n\nThing\n\n    + entity\n        + occurrent\n            + process\n                + bodily process\n                    + mental process\n                        + learning\n                        - remembering\n                        + judging\n                        + cognitive process\n                        + thinking\n                        + imagination\n                        + attending\n                        + perception\n                        - planning\n                        - wanting\n                        - daydreaming\n                        - orgasm\n                        - libido\n                        - arousal","n":0.144}}},{"i":2804,"$":{"0":{"v":"Memphis","n":1},"1":{"v":"\n- [[c.software.message-bus]]\n- url: https://memphis.dev/\n- written-in: #go\n\n\n## Use Cases\n\n-   Async task management\n-   Real-time streaming pipelines\n-   Data ingestion\n-   Cloud Messaging\n    -   Services (microservices, service mesh)\n    -   Event/Data Streaming (observability, analytics, ML/AI)\n-   Queuing\n-   N:N communication patterns\n-   Ingest Grafana Loki logs at scale\n\n## Features\n\n- Stream Enrichments: serverless-type functions or complete containerized applications that aggregate several stations and streams, decorate and enrich messages from different sources, write complex functions that cannot be achieved via SQL, and manipulate the schema.\n- Memphis Functions empower developers and data engineers with the ability to seamlessly process, transform, and enrich incoming events in real-time through a serverless paradigm, all within the familiar AWS Lambda syntax, in an array of programming languages, including but not limited to Go, Python, JavaScript, .NET, Java, and SQL.\n\n### [[c.feature.possible]]\n\n- https://medium.com/memphis-dev/differences-between-nats-io-and-memphis-23ac8bd43d01\n  - \"Memphis is currently experimenting with creating that ability for consumers to be able to communicate with each other using gRPC or shared channels.\"\n- Data-Level Observability\n\n## Comparison\n\n- [[vs.nats-jetstream-vs-memphis]]\n\n### NATS API compatibility issues\n\nThe following Memphis features will not be supported when using NATS SDK:\n- Producers/Consumers' observability\n- Schemaverse\n- Dead-letter station - resend unacked messages\n\n\n## [[c.license]]\n\n- Memphis is open-sourced and operates under the \"Memphis Business Source License 1.0\" license Built out of Apache 2.0, the main difference between the licenses is: \"You may make use of the Licensed Work (i) only as part of your own product or service, provided it is not a message broker or a message queue product or service; and (ii) provided that you do not use, provide, distribute, or make available the Licensed Work as a Service. A “Service” is a commercial offering, product, hosted, or managed service, that allows third parties (other than your own employees and contractors acting on your behalf) to access and/or use the Licensed Work or a substantial set of the features or functionality of the Licensed Work to third parties as a software-as-a-service, platform-as-a-service, infrastructure-as-a-service or other similar services that compete with Licensor products or services.\" Please check out License to read the full text.","n":0.055}}},{"i":2805,"$":{"0":{"v":"Schemaverse","n":1},"1":{"v":"\n\n## Resources\n\n- https://dzone.com/articles/how-to-increase-data-quality-with-memphis-schemave","n":0.577}}},{"i":2806,"$":{"0":{"v":"Memorypack","n":1},"1":{"v":"\n- repo: https://github.com/Cysharp/MemoryPack","n":0.577}}},{"i":2807,"$":{"0":{"v":"Memo","n":1},"1":{"v":"\n\n[[p.hasRepository]] https://github.com/svsool/memo\n","n":0.707}}},{"i":2808,"$":{"0":{"v":"Memgraph","n":1},"1":{"v":"\n- [[c.software.database.graph.property]]\n- url: https://memgraph.com/\n- repo: https://github.com/memgraph/memgraph\n- [[p.compatibleWith]] [[prdct.neo4j]]\n- written-in: #c++\n- supports: [[prdct.Cypher]]\n\n## Features\n\n- in-memory storage engine, on-disk persistence/backup\n- connect to [[prdct.kafka]] [[prdct.pulsar]] [[prdct.redpanda]]\n- [[p.supports]] #python #c #rust [[prdct.node]] c# #go #haskell java javascript #php #ruby]\n- custom procedures in #python and #c / #c++\n\n## [[c.model.licensing]]\n\n- open-source community version doesn't includ access control or multi-tenant architecture\n- cloud version from as low as $20/mo for 1GB memory instance","n":0.124}}},{"i":2809,"$":{"0":{"v":"Memgator","n":1},"1":{"v":"\n- https://github.com/oduwsdl/memgator\n- [[c.software.semantic]] [[c.software.semantic.linked-data-platform]]\n- written-in: go\n- ","n":0.408}}},{"i":2810,"$":{"0":{"v":"Memex","n":1},"1":{"v":"\n- influenced the development of early hypertext systems","n":0.354}}},{"i":2811,"$":{"0":{"v":"Memento","n":1},"1":{"v":"\n- url: https://mementoweb.org/\n- related: [[prdct.ipld]]\n\n\n## Solutions\n\n- [[prdct.memgator]]\n- [[prdct.invenio]]\n\n## Use Cases\n\n- \"the Memento protocol provides a promising solution for the archiving, citation, retrieval, discovery, synchronization and sustainability challenges of data management.\"\n\n## Resources\n\n- https://github.com/machawk1/awesome-memento\n- [Resource Versioning and Memento](http://mementoweb.org/guide/howto/)\n- https://discuss.ipfs.tech/t/are-there-plans-to-cooperate-with-memento-protocol/325/5\n- ","n":0.164}}},{"i":2812,"$":{"0":{"v":"Melanie","n":1}}},{"i":2813,"$":{"0":{"v":"Melange","n":1},"1":{"v":"\n- [[c.software.language-workbench]]\n- url: http://melange.inria.fr/\n- [[p.compatibleWith]] [[prdct.sirius]]\n\n## Features\n\n- model-oriented type system","n":0.316}}},{"i":2814,"$":{"0":{"v":"Meistertask","n":1}}},{"i":2815,"$":{"0":{"v":"Medium","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[prdct.hashnode]]\n","n":0.577}}},{"i":2816,"$":{"0":{"v":"Meditate","n":1},"1":{"v":"\n- fiction GUI","n":0.577}}},{"i":2817,"$":{"0":{"v":"MediatR","n":1},"1":{"v":"\n- repo: https://github.com/jbogard/MediatR\n- written-in: [[t.cs.languages.c-sharp]]\n\n## Cons\n\n- **You want event/notification handlers to be run in independently in isolation.** This is where out-of-process messaging comes in. In this case, you might want to look at  [[prdct.nservicebus]], [Brighter](https://www.goparamore.io/), [[prdct.masstransit]], [[prdct.rebus]].\n  - https://codeopinion.com/why-use-mediatr-3-reasons-why-and-1-reason-not/","n":0.16}}},{"i":2818,"$":{"0":{"v":"Mediasoup","n":1},"1":{"v":"\n- url: https://mediasoup.org/\n- [[p.builtOn]] [[prdct.webrtc]]\n\n## description:\n\n- An SFU (Selective Forwarding Unit) receives audio and video streams from endpoints and relays them to everyone else (endpoints send one and receive many). Each receiver endpoint can select which streams and spatial/temporal layers it receives. Compared to a mixer or MCU (Multipoint Conferencing Unit) this design leads to a better performance, higher throughput and less latency. It's highly scalable and requires much less resources given that it does not transcode or mix media. Since endpoints get the other endpoints' media separately, they can have a personalized layout and choose which streams to render and how to display them.\n\n## Features\n\n- perfect choice for building multi-party video conferencing and real-time streaming apps.\n- Instead of creating yet another opinionated server, mediasoup can be used as Node.js module or Rust crate which can be integrated into a larger application.\n- comes with mediasoup-client (JavaScript library) and libmediasoupclient (C++ library) for building applications that run in any browser or device by using an unified API. Or just use well known software such as FFmpeg or GStreamer.\n\n## Thoughts\n\n- spatial and temporal layers seems to refer to the size and framerate of the provided video. ","n":0.072}}},{"i":2819,"$":{"0":{"v":"MDX","n":1},"1":{"v":"\n\n- [[p.hasBlog]] https://mdxjs.com/blog\n  - [[p.hasBlogEntry]] https://mdxjs.com/blog/v2/\n    - [[p.hasHighlight]] \"we think compiling things ahead of time and betting on hybrid models, compared to completely server-side sites or completely client-side apps, is the smart choice for us and the web’s future.\"\n    - [[p.references]] [[prdct.unified]]\n- [[c.usecase]] [[gd]]\n- supports: There are integrations for most bundlers, frameworks, and editors. Whether you build with Docusaurus, Next.js, or Vite. You prefer Rollup, esbuild, or webpack. You’re using React, Preact, or Vue. Get started »\n\n## Features\n\n- support YAML frontmatter (kinda) \n  - https://mdxjs.com/guides/frontmatter/\n- embed code blocks","n":0.107}}},{"i":2820,"$":{"0":{"v":"mdBook","n":1},"1":{"v":"\n- repo: https://github.com/rust-lang/mdBook\n- docs: https://rust-lang.github.io/mdBook/index.html\n- written-in: rust","n":0.378}}},{"i":2821,"$":{"0":{"v":"Mattermost","n":1},"1":{"v":"\n\n- [[can be extended by|p.hasExtensionMechanism]]\n  - plugin\n    - [[p.hadAtLeastOneOf]] \n      - server component \n        - runs as a server subprocess\n        - written-in: #go\n      - \"web app\" component\n        - included in page, runs alongside the Mattermost web app code\n          - desktop app is shim of web app\n        - written-in: javascript\n        - [[p.builtOn]] \n          - [[prdct.react]]\n          - [[prdct.redux-js]]\n  - app\n    - lightweight interactive \"add-ons\" \n    - in any language\n    - receive webhooks from mattermost and 3rd-parties\n    - use Mattermost REST APIs to post messages\n    - attach them selves to locations the user\n\n- Chose mysql technology for openness.\n- our web hooks and slash commands are binary level protocol compatible with Slack.\n  - [[p.hasSource]] https://go.theregister.com/feed/www.theregister.com/2022/05/26/mattermost/","n":0.095}}},{"i":2822,"$":{"0":{"v":"Matrix","n":1},"1":{"v":"\n- [[c.software.communication-server]]\n- [[c.implementation]] [[prdct.dendrite]]\n\n## Bots\n\n- \"Matrix has no distinction between user and bot accounts (nor is there any dependency between the two). Unless specifically exempted by the homeserver (not needed in most cases), bots have the same ratelimit as other users.\"\n\n## [[p.hasComparison]]\n\n- https://www.troopmessenger.com/blogs/mattermost-vs-matrix\n","n":0.152}}},{"i":2823,"$":{"0":{"v":"Hookshot","n":1}}},{"i":2824,"$":{"0":{"v":"Matrix Cloud","n":0.707}}},{"i":2825,"$":{"0":{"v":"Material Web","n":0.707},"1":{"v":"\n- url: https://m3.material.io/develop/web\n- repo: https://github.com/material-components/material-web","n":0.447}}},{"i":2826,"$":{"0":{"v":"Masterpiece Studio","n":0.707},"1":{"v":"\n- [[c.software.3d.generator]]","n":0.707}}},{"i":2827,"$":{"0":{"v":"MassTransit","n":1},"1":{"v":"\n- [[c.Software.messaging.middleware]]\n- url: https://masstransit.io/\n- [[p.supports]] [[prdct.marten]] [[prdct.rabbitimq]]\n- written-in: c#\n\n## vs\n\n### vs NATS: \n- [Nats support?](https://github.com/MassTransit/MassTransit/discussions/2548)\n\n## Features\n\n- ### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration\n\n### Message Routing\n\nType-based publish/subscribe and automatic broker topology configuration","n":0.106}}},{"i":2828,"$":{"0":{"v":"Mason Json Format","n":0.577},"1":{"v":"\n- dead\n- repo: https://github.com/JornWildt/Mason","n":0.5}}},{"i":2829,"$":{"0":{"v":"Marten","n":1},"1":{"v":"\n- url: https://martendb.io/\n- written-in: [[t.cs.languages.c-sharp]]\n\n## Resources\n\n- https://event-driven.io/pl/unique_constraint_in_marten_event_store/","n":0.378}}},{"i":2830,"$":{"0":{"v":"Marp","n":1},"1":{"v":"\n- url: https://marp.app/\n\n## [[c.limitation]]\n\n- no footnotes?\n- ","n":0.408}}},{"i":2831,"$":{"0":{"v":"Marmotta","n":1},"1":{"v":"\n- [[c.software.semantic.linked-data-platform]]\n\n\n## Features\n\n-   Read-Write Linked Data server for the Java EE stack\n-   Pluggable RDF triple stores based on [Eclipse RDF4J](https://projects.eclipse.org/projects/technology.rdf4j) (formerly Sesame):\n    -   Custom triple store ([KiWi](https://marmotta.apache.org//kiwi/)) built on top of RDBMS, with [transactions](https://marmotta.apache.org//kiwi/transactions.html), [versioning](https://marmotta.apache.org//kiwi/versioning.html) and [rule-base reasoning](https://marmotta.apache.org//kiwi/reasoner.html) support\n    -   And some [other backends](https://marmotta.apache.org//platform/backends.html)\n-   [LDP](https://marmotta.apache.org//platform/ldp-module.html), [SPARQL](https://marmotta.apache.org//platform/sparql-module.html) and [LDPath](https://marmotta.apache.org//ldpath) querying\n-   Transparent [Linked Data Caching](https://marmotta.apache.org//ldcache)\n-   Integrated basic [security](https://marmotta.apache.org//platform/security-module.html) mechanisms","n":0.132}}},{"i":2832,"$":{"0":{"v":"Marklogic Server","n":0.707},"1":{"v":"\n- https://www.progress.com/marklogic/server\n- [[c.software.database.Multi-Model]]\n- published-by: [[org.progress-software]]\n\n## Features\n\n- Document (JSON/XML), text, graph, relational, and geospatial. All your data and metadata as a single resource in a unified platform.","n":0.196}}},{"i":2833,"$":{"0":{"v":"Markdownload","n":1}}},{"i":2834,"$":{"0":{"v":"Markdown","n":1},"1":{"v":"\n- [[p.hasCreator]] [[user.john-gruber]]\n\n## [[p.hasSense]] a markup language\n\n- [[p.instanceOf]] [[t.cs.languages]] \n\n## [[p.hasSense]] the class of markup languages based on Markdown\n\n- [[p.subClassOf]] [[t.cs.languages]]\n\n## to-do\n\n- [c] summarize footnoting. using ^ seems scary give dendron references.\n\n## Resources\n\n- https://cirosantilli.com/markdown-style-guide/#top-level-header\n  - a bunch of suggested best practices\n  - first mention I've found of using horizontal rule `---` to end a header's content\n  - good examples of definition lists\n- https://stackoverflow.com/questions/4823468/comments-in-markdown\n  - no great solution for comments. \n  - tempting to just use `//` and/or `/* ... */`\n  - t.2024.01.11 according to https://www.w3schools.io/file/markdown-comments/ it should be `<!---` and `--->`\n- https://www.smashingmagazine.com/2022/02/thoughts-on-markdown/\n  - experience for editors is not ideal\n    - [[p.supportedBy]] \"Do you really want your editors to bump against merge conflicts or how to rebase branches?\"\n  - [[p.references]] [[prdct.mdx]]","n":0.091}}},{"i":2835,"$":{"0":{"v":"R Markdown","n":0.707},"1":{"v":"\n- url: https://rmarkdown.rstudio.com/\n- repo: https://github.com/rstudio/rmarkdown\n- [[p.supportedBy]]: [[prdct.rstudio]] \n  related: [[prdct.blogdown]]\n\n## Features\n\n- Use a productive notebook interface to weave together narrative text and code to produce elegantly formatted output. Use multiple languages including R, Python, and SQL.\n- \"R Markdown supports dozens of static and dynamic output formats including HTML, PDF, MS Word, Beamer, HTML5 slides, Tufte-style handouts, books, dashboards, shiny applications, scientific articles, websites, and more.\"","n":0.124}}},{"i":2836,"$":{"0":{"v":"Php Markdown Extra","n":0.577},"1":{"v":"\n\n\n- [[p.hasSpecification]] https://michelf.ca/projects/php-markdown/extra/\n- [ ] PHP Markdown Extra has ideas for [[gd]] and fixes for [[prdct.dendron]]\n\n## Special Attributes\n\nWith Markdown Extra, you can set the id and class attribute on certain elements using an attribute block. For instance, put the desired id prefixed by a hash inside curly brackets after the header at the end of the line, like this:\n\nHeader 1            {#header1}\n========\n\n## Header 2 ##      {#header2}\n\nThen you can create links to different parts of the same document like this:\n\n[Link back to header 1](#header1)\n\nTo add a class name, which can be used as a hook for a style sheet, use a dot like this:\n\n## The Site ##    {.main}\n\nYou can also add custom attributes having simple values by specifying the attribute name, followed by an equal sign, followed by the value (which cannot contain spaces at this time):\n\n## Le Site ##    {lang=fr}\n\nThe id, multiple class names, and other custom attributes can be combined by putting them all into the same special attribute block:\n\n## Le Site ##    {.main .shine #the-site lang=fr}\n\nAt this time, special attribute blocks can be used with\n\n    headers,\n    fenced code blocks,\n    links, and\n    images.\n\nFor image and links, put the special attribute block immediately after the parenthesis containing the address:\n\n[link](url){#id .class}  \n![img](url){#id .class}\n\n...\n\nYou can specify a class name that will apply to a code block. This is useful if you want to style differently code blocks depending on the language. Or you could also use it to tell a syntax highlighter what syntax to use.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .html\n<p>paragraph <b>emphasis</b>\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe class name is placed at the end of the first fence. It can be preceded by a dot, but this is not a requirement. You can also use a special attribute block:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~ {.html #example-1}\n<p>paragraph <b>emphasis</b>\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n","n":0.06}}},{"i":2837,"$":{"0":{"v":"Dragons Inn Flavored Markdown","n":0.5},"1":{"v":"\n- much saner than [[gd]]\n- [[p.hasSpecification]] https://github.com/DragonsInn/DIFM/blob/master/DIFM.GrammarSpec.js","n":0.378}}},{"i":2838,"$":{"0":{"v":"Dendron Flavored Markdown","n":0.577},"1":{"v":"\n#aka DFM","n":0.707}}},{"i":2839,"$":{"0":{"v":"Commonmark","n":1},"1":{"v":"\n\n\n- > In September 2014, Gruber objected to the usage of \"Markdown\" in the name of [the standardization] effort and it was rebranded as a new dialect named CommonMark.\n\n## Related\n\n- https://www.infoq.com/news/2014/09/markdown-commonmark/\n","n":0.18}}},{"i":2840,"$":{"0":{"v":"R Markdown","n":0.707},"1":{"v":"\n\n\n- [[p.hasSite]] https://rmarkdown.rstudio.com/\n- [[p.hasApplication]] [[t.cs.data.visualization]]\n","n":0.447}}},{"i":2841,"$":{"0":{"v":"MultiMarkdown","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://fletcherpenney.net/multimarkdown/\n- [[p.variantOf]] [[prdct.markdown]]\n- [[p.hasLearningResource]] https://github.com/fletcher/MultiMarkdown-Gallery/raw/master/What-Is-MMD/what_is_mmd.pdf\n- [ ] [[p.begsQuestion]] How is it different from other Markdowns\n","n":0.243}}},{"i":2842,"$":{"0":{"v":"GFM","n":1},"1":{"v":"\n\n\n- [[p.variantOf]] [[prdct.markdown]]\n","n":0.577}}},{"i":2843,"$":{"0":{"v":"CriticMarkup","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/CriticMarkup/CriticMarkup-toolkit\n- [[usesComputerLanguage]] #python\n\n## The Three Laws\n\n1. Critic Markup shall be human readable. A human with a simple text editor can easily read and comprehend any text containing Critic Markup.\n2. Critic Markup shall be computer readable except where it conflicts with rule 1. Markup syntax should be easily parsed with simple regular expressions to support a wide variety of implementations.\n3. Critic Markup shall be compatible with existing markup syntax for Markdown, MultiMarkdown and HTML except where it conflicts with rules one or two. Many users of plain text write in combinations of Markdown and HTML. Critic Markup should work alongside that syntax.\n","n":0.099}}},{"i":2844,"$":{"0":{"v":"Markdown to Json","n":0.577},"1":{"v":"\nurl: https://github.com/njvack/markdown-to-json\n\n- written-in: #python","n":0.5}}},{"i":2845,"$":{"0":{"v":"Markdown-LD","n":1},"1":{"v":"\n- repo: https://github.com/ozekik/markdown-ld\n- eg https://ozekik.github.io/markdown-ld/\n\n## Specification\n\nA Markdown-LD document MUST have a level-1 heading which represents the name of the graph described under the heading.\n\nLevel-1, level-2, and level-3 headings MUST be immediately followed by a line of inline code for its RDF term in Turtle syntax.\n\nA pair of a heading and a line of inline code is called _Markdown-LD heading_.\n\nA level-1 Markdown-LD heading MAY be immediately followed by a code block for `@base` and `@prefix` directives and other implicit RDF triples in Turtle syntax.\n\nUntil the next heading, Markdown texts after the code block are treated as comments.","n":0.102}}},{"i":2846,"$":{"0":{"v":"markdown-json","n":1},"1":{"v":"\nurl: https://www.npmjs.com/package/markdown-json\n","n":0.707}}},{"i":2847,"$":{"0":{"v":"markdown-it","n":1},"1":{"v":"\nrepo: https://github.com/markdown-it/markdown-it","n":0.707}}},{"i":2848,"$":{"0":{"v":"Markdown Editor","n":0.707},"1":{"v":"\n\nA bad idea, but nice GUI for tables \n\n- [[p.hasURL]] https://open-vsx.org/extension/zaaack/markdown-editor\n","n":0.302}}},{"i":2849,"$":{"0":{"v":"Markdig","n":1},"1":{"v":"\n- repo: https://github.com/xoofx/markdig\n- written-in: c#\n- [[p.usedBy]] [[prdct.literatecs]]\n\n## Related\n\n- https://github.com/Temetra/MarkdigExtensions (could be useful for Dendron SSG)","n":0.258}}},{"i":2850,"$":{"0":{"v":"Mario Project","n":0.707},"1":{"v":"\n- related: [[prdct.mario-ontology-network-mon]]\n\n\n","n":0.577}}},{"i":2851,"$":{"0":{"v":"Mario Ontology Network (MON)","n":0.5},"1":{"v":"\n- https://github.com/luigi-asprino/MON\n\n## Thoughts\n\n\n\n## Highlights\n\n### Action\n\n![](/assets/images/2024-08-23-14-20-16.png)\n\nThe MON’s Action module is meant to implement the  <a href=\"http://ontologydesignpatterns.org/wiki/Submissions:TaskExecution\">Task Execution Ontology Design Pattern</a>. \nThis module allows to keep track of the actions performed either by the robot or by its users. \nActions execute and are classified by tasks. \nThe class <tt>action:Task</tt> aims at collecting all the behaviors of the robot.\n\n<b>Example of Usage</b>\n\nWe provide an example of usage of the Action ontology for specifying the following scenario.\nX is a social robot can entertain its users by ​playing music, showing videos or telling jokes.\nOn 23 April 2015 from 3pm to 4p, X played some music for Monica.\n\n```turtle\n@prefix action: <https://w3id.org/MON/action.owl>\n@prefix time: <https://w3id.org/MON/time.owl#>\n\n:April23015Beg a time:Instant ;\n   time:inXSDDateTime \"2015-04-23T15:00:00+02:00\" .\n\n\n:April23015End a time:Instant ;\n   time:inXSDDateTime \"2015-04-23T16:00:00+02:00\" .\n\n:April23015 a time:Interval ;\n   time:hasBeginning :April23015Beg ;\n   time:hasEnd  :April23015End .\n\n:MusicBehavior a action:Behavior .\n\n:X a action:Agent .\n\n:Monica a action:Agent .\n\n:PlayMusicForMonica a action:Action ;\n  time:atTime :April23015 ;\n  action:byAgent :X ;\n  action:executesTask :MusicBehavior ;\n  action:hasParticipant :Monica .\n\n```\n\n### Time\n\n![](/assets/images/2024-08-24-08-25-27.png)\n\n- simplified version of the W3C&apos;s Time Ontology\n- TemporalEntity subClassOf DUL.owl#TimeInterval","n":0.079}}},{"i":2852,"$":{"0":{"v":"MapTool","n":1},"1":{"v":"\n[[c.software.rpg.virtual-tabletop.fat-client]]\n- https://www.rptools.net/toolbox/maptool/\n","n":0.707}}},{"i":2853,"$":{"0":{"v":"Mantis","n":1},"1":{"v":"\n- https://netflix.github.io/mantis/\n- [[c.software.data-framework.streaming]]\n- repo: https://github.com/netflix/mantis\n- written-in: java","n":0.378}}},{"i":2854,"$":{"0":{"v":"Manas","n":1},"1":{"v":"\n- repo: https://github.com/manomayam/manas\n- written-in: rust\n\n![[prdct.node-solid-server#similar]]","n":0.447}}},{"i":2855,"$":{"0":{"v":"Malli","n":1},"1":{"v":"\n- repo: https://github.com/metosin/malli","n":0.577}}},{"i":2856,"$":{"0":{"v":"Mak Rti","n":0.707},"1":{"v":"\n\n- [[p.hasURL]] https://www.mak.com/products/link/mak-rti\n- [[p.hasLicenseOption]]\n  - two-federate environments for free\n","n":0.333}}},{"i":2857,"$":{"0":{"v":"Magzter","n":1}}},{"i":2858,"$":{"0":{"v":"Magmacore","n":1},"1":{"v":"\n- https://github.com/gchq/MagmaCore\n- wiki: https://github.com/gchq/MagmaCore/wiki\n\n\n![](/assets/images/2024-07-08-14-46-29.png)\n\n## Highlights\n\n- The TLO provides the modelling framework for all the data instances that makes up the Reference Data and, as a result, the Reference Data provides the framework for all the data instances that are generated during the information system's operations. \n- Reference Data can be thought of as a library of permitted classes that define what systems are concerned with and should rarely (if ever) change once created\n  - continuous additions are allowed\n- Master Data can be considered as an important subset of IO Data that needs to be accessible to many/all participating systems","n":0.101}}},{"i":2859,"$":{"0":{"v":"Magicdraw","n":1}}},{"i":2860,"$":{"0":{"v":"MADR","n":1},"1":{"v":"\n- url: https://adr.github.io/madr/","n":0.577}}},{"i":2861,"$":{"0":{"v":"MaDKit","n":1},"1":{"v":"\n- dead since 2021\n- repo: https://github.com/fmichel/MaDKit\n\n## Features\n\n- Artificial agents creation and life cycle management\n- An organizational infrastructure for communication between agents, structuring the application\n- High heterogeneity in agent architectures: No predefined agent model\n- Multi-Agent based simulation and simulator authoring tools\n- Multi-agent based distributed application authoring facilities\n\n\n## Approach\n\nIn contrast to conventional approaches, which are mostly agent-centered, MaDKit follows an organization-centered approach (OCMAS): There is no predefnied agent model in MaDKit.\n\nEspecially, MaDKit does not enforce any consideration about the internal structure of agents, thus allowing a developer to freely implements its own agent architectures.\n\nSo, MaDKit is built upon the AGR (Agent/Group/Role) organizational model: Agents play roles in groups and thus create artificial societies.","n":0.095}}},{"i":2862,"$":{"0":{"v":"M Link","n":0.707},"1":{"v":"\n- [[c.software.xmpp-server]]\n- #closed-source","n":0.577}}},{"i":2863,"$":{"0":{"v":"m-ld","n":1},"1":{"v":"\n- https://m-ld.org/\n- [[c.software.data-framework.sharing]]\n- creator: @george-svarovsky\n- implementation:\n  - [[prdct.m-ld-js]]\n- related: [[prdct.json-rql]] [[t.cs.distributed.crdt]]\n- supports: [[prdct.ably]] [[prdct.mqtt]] [[prdct.socket-io]] \n\n## Issues\n\n- no [[prdct.JSON-LD.star]] support, but https://github.com/m-ld/m-ld-js/issues/182\n\n## Features\n\n- **live and shareable**: \n- [[prdct.shacl]] support, see https://js.m-ld.org/classes/shapeconstrained.html\n\n### Hosted persistence via the Gateway \n\n- For hosted persistence, we offer the m-ld Gateway, a server which (among other functions) operates as another participant in the domain, and thus keeps its own copy of the data, analogous to an IPFS pinning service. This Gateway service may be offered by the application developer for convenience, but it may also be operated by end user themselves if desired, preserving user control. Just as end users can bring their own pods to a Solid app, they can also bring their own Gateways to these collaborative apps.\n\n## Philosophy\n\n### web app data securely stored in reactive, replicated Linked Data sets\n\n- possible for app developers to meet today's and tomorrow's feature expectations without the high costs and limitations of today's distributed data architectures. This foundational design principle combines ideas from the semantic web (machine-readable publishable interlinked data), personal data stores (user control of user data) and local-first software (collaboration without obligatory third parties).\n\n### Coordination\n\n- There are two approaches to concurrency control that don't need a total ordering of changes. One is called Conflict-free Replicated Data Types (CRDTs), and the other Operational Transformation (OT).\n- Humans employ myriad strategies for coordination. You withhold thoughts while someone else is talking. You undo and redo thoughts against new information, both before and after expressing them. You notice conflicts that corrupt the information or render it illogical, apply obvious resolutions, and negotiate others. You actively seek consensus, or delegate decisions.\n\n### Message Delivery\n\nLocal-first web applications can still benefit from secure durable storage of data on a server. They also rely on a message delivery mechanism, which in practice must be either a deployed service (like a message broker) or a cloud service. While these are cheap to set up, they may become expensive in the long run due to operational costs, provider markup and service over-specification.\n\n\n\n\n\n## References\n\n- https://rdfjs.dev/m-ld\n- https://m-ld.org/news/#live-and-sharable\n- [Web Zero, with m-ld](https://docs.google.com/document/d/1DrMr_PI6P81w1spiUDBTkOJGz0bPS2sZIXhCz51p7CE/edit)\n- [Sustainable Web Apps, with m-ld](https://docs.google.com/document/d/17YnR6f8Xp69E09sO3BShSP5H6PXx3sDGNTVxNyvl56s/edit)","n":0.054}}},{"i":2864,"$":{"0":{"v":"m-ld Javascript Engine","n":0.577},"1":{"v":"\n- repo: https://github.com/m-ld/m-ld-js\n- docs: https://js.m-ld.org/  \n- built-on: [[prdct.json-rql]]\n- support: [[prdct.socket-io]] [[prdct.ably]] [[prdct.mqtt]]\n\n## Examples\n\n-   The [TodoMVC App](https://github.com/m-ld/m-ld-todomvc-vanillajs) shows one way to build a multi-collaborator application for browsers.\n-   The [Node.js Starter Project](https://github.com/m-ld/m-ld-nodejs-starter) uses Node processes to initialise two clones, and an MQTT broker for messaging.","n":0.152}}},{"i":2865,"$":{"0":{"v":"Lwjgl","n":1},"1":{"v":"\n- url: https://www.lwjgl.org\n- \n\n## Description\n\n- Java library that enables cross-platform access to popular native APIs useful in the development of graphics (OpenGL, Vulkan), audio (OpenAL) and parallel computing (OpenCL) applications","n":0.183}}},{"i":2866,"$":{"0":{"v":"Luxon","n":1},"1":{"v":"\nurl: https://moment.github.io/luxon/#/\nrepo: https://github.com/moment/luxon\n\n- [[p.similarTo]] [[prdct.momentjs]] [[prdct.js-joda]]\n\n## Comparison  ^z5ldk0m6zjqx\n\n- https://medium.com/swlh/best-moment-js-alternatives-5dfa6861a1eb\n- https://dev.to/gulshanaggarwal/js-date-time-libraries-you-should-use-instead-of-traditional-methods-1lc4\n\n## Features\n\n-   DateTime, Duration, and Interval types.\n-   Immutable, chainable, unambiguous API.\n-   Parsing and formatting for common and custom formats.\n-   Native time zone and Intl support (no locale or tz files).","n":0.16}}},{"i":2867,"$":{"0":{"v":"Luvit","n":1},"1":{"v":"\n- url: https://luvit.io/\n\n## Features\n\n- Luvit implements the same APIs as Node.js, but in Lua!\n- Async Choice: \"If you don’t like callbacks and event emitters, use coroutines and write blocking style code without actually blocking your event loop!\"","n":0.164}}},{"i":2868,"$":{"0":{"v":"Lusha","n":1}}},{"i":2869,"$":{"0":{"v":"Lunr","n":1},"1":{"v":"\n- https://lunrjs.com/\n- [[c.software.web.static-search]]\n\n## Features\n\n- extensible/customization","n":0.447}}},{"i":2870,"$":{"0":{"v":"Luminus","n":1},"1":{"v":"\n- url: https://luminusweb.com/","n":0.577}}},{"i":2871,"$":{"0":{"v":"Lume","n":1}}},{"i":2872,"$":{"0":{"v":"Luma","n":1},"1":{"v":"\n\n\n\nActivate Your Community; Foster meaningful relationships with events, newsletters, and community analytics\n\n- [[p.hasURL]] https://lu.ma\n\n\n- [[c.software.3d.generator]]","n":0.258}}},{"i":2873,"$":{"0":{"v":"Luma AI","n":0.707},"1":{"v":"\n- [[c.software.3d.generator]]\n\n## Features\n\n-   **Flythrough Videos**: This tool allow users to create smooth, cinematic camera movements through 3D environments or scenes. This can be particularly useful for creating previews of digital spaces (eg. real estate) or for game development.\n-   **Video to 3D**: This tool convert traditional videos into 3D models or scenes. This is especially useful in virtual reality (VR), augmented reality (AR), and for creating interactive experiences where users can navigate through the scenes.\n-   **Text to 3D (alpha)**: An alpha-stage tool that converts descriptive text into 3D models. This could be a groundbreaking tool for designers, allowing for rapid prototyping based on written descriptions.","n":0.098}}},{"i":2874,"$":{"0":{"v":"Lucidchart","n":1}}},{"i":2875,"$":{"0":{"v":"Luajit","n":1}}},{"i":2876,"$":{"0":{"v":"Lua","n":1},"1":{"v":"\n- syntax similar to Modula\n\n## c.Feature\n\n- [Metamethods](http://lua-users.org/wiki/MetamethodsTutorial)\n-  you can pass functions as arguments\n-  [[t.cs.sd.mixin]]\n\n## Pros\n\n* Fastest scripting language\n* Easiest to embed scripting language\n* Simple but expressive\n* Can be sandboxed\n\n## Resources\n\n- http://lua.space/webdev/why-we-rewrote-lua-in-js\n- [[prdct.middleclass]]\n- [[ar.unifying-component-based-gameobject-systems-and-mixin-based-inheritance]]\n\n## Implementations\n\n- [[prdct.moonsharp]] dead\n- [[prdct.nlua]] / [[prdct.keralua]]\n- \n\n## References\n\n![[Mixin|t.cs.sd.mixin#^wklu5ctv3kui]]\n- [Lua as a business logic\nlanguage in high load\napplication](https://www.lua.org/wshop14/Martynov.pdf)","n":0.143}}},{"i":2877,"$":{"0":{"v":"Lua Machine","n":0.707},"1":{"v":"\n- repo: https://github.com/rdeioris/LuaMachine\n- \"Having multiple LuaState's allows clean separation of domains: as an example you may want a state for game configuration, another one for game logic and one for the modders. More complex examples include having states dedicated to specific Actors, GameModes or Levels.\"","n":0.149}}},{"i":2878,"$":{"0":{"v":"Ltl Linear Temporal Logics","n":0.5},"1":{"v":"\n- fragment-of: [[prdct.computational-tree-logics]]","n":0.577}}},{"i":2879,"$":{"0":{"v":"Lrmoo","n":1},"1":{"v":"\n- https://cidoc-crm.org/extensions/lrmoo/owl/1.0/LRMoo_v1.0.owl\n- extends: [[prdct.cidoc-crm]]\n- related: [[t.library-science.work_expression_manifestation_item]]\n- similar: [[prdct.resource-description-and-access-rda]]\n\n## Description\n\n- LRMoo is strictly an extension of CIDOC CRM and cannot be implemented without using key classes and properties from CIDOC CRM.\n- Entities are broken into associated phenomena named “objects”, and are oriented to each other by their attributes. The various models, then, do not rely on temporality or mutually exclusive classes, but rather on associative principles of linked attributes. FRBR’s “W-E-M-I” (works-expressions-manifestations-items) entities in FRBRoo become objects that may be associated multiply according to their related attributes. In a given instantiation network derived from an ideational conception there might be many works, for each of which there might be many expressions. Not all expressions spawn manifestations, and so forth. Also a distinction is made between the intellectual work, and publication events, which might spawn manifestations.\n\n\n## Highlights\n\n- [[t.library-science.work_expression_manifestation_item]]\n- Nomen (F12) comprises associations between an instance of any class, and signs or arrangements of signs that are used to refer to and identify that instance\n  - Signs include alphanumeric characters, ideograms, notations such as chemical structure symbols, sound symbols, etc\n  - Spelling variants are regarded as different nomens, whereas the use of different fonts (visual representation variants) or different digital encodings do not change the identity\n  - An arbitrary combination of signs or symbols cannot be regarded as an appellation or designation until it is associated with something in some context. In that sense, the F12 Nomen class can be understood as the reification of a relationship between an instance of E1 CRM Entity and an instance of E41 Appellation\n  - Two instances of F12 Nomen can happen to be associated with equivalent strings and yet remain distinct, as long as they refer to distinct instances of E1 CRM Entity\n    - Furthermore, two instances of F12 Nomen referring to the same instance of E1 CRM Entity may be associated with equivalent strings, and remain distinct as long as they are associated with distinct properties of the F12 Nomen class (for example, having the same spelling in different languages, or being defined in different controlled vocabularies).\n- has_member (R10i) and E28 Conceptual Object\n  - associates an instance of F1 Work with an instance of E28 Conceptual Object that represents a generalization of the work. The property can be used to group variant, alternative or related works that are considered to share a common concept.\n  - Whereas instances of F1 Work are always realised in instances of F2 Expression, there is no particular expression that fully conveys the instance of Conceptual Object that a work may be a member of.\n  - Intended usage of the property includes what is discussed as 'superwork' in the library community. Typical examples are novels that can be grouped by fictional universes or common characters, paintings or graphical works that exist as a family of alternatives, musical compositions that are referred to as the same although they exist as particular versions that are each identified as an individual work.\n- F18_Serial_Work \n  - The retrospective reprinting of all issues of a Serial Work at once, in the form of a monograph, is regarded to be another member of the F1 Work, which contains the Serial Work and the Work realised in the monograph. This does not make the monograph part of the Serial Work.\n\n## References\n\n- https://www.cidoc-crm.org/frbroo/home-0\n- https://ontome.net/namespace/217\n- [[ar.works-expressions-manifestations-items-an-ontology]]","n":0.043}}},{"i":2880,"$":{"0":{"v":"Lotus","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://lotus.filecoin.io/\n","n":0.577}}},{"i":2881,"$":{"0":{"v":"Lottie","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n","n":0.707}}},{"i":2882,"$":{"0":{"v":"Loom","n":1},"1":{"v":"\n\n\n- [[p.hasRepository]] https://github.com/aysylu/loom\n- written-in: [[t.cs.languages.Clojure]]\n","n":0.447}}},{"i":2883,"$":{"0":{"v":"loom-actor","n":1},"1":{"v":"\n- dead since 2023-06\n- repo: https://github.com/forax/loom-actor\n\n## Features\n\n- Unlike a traditional actor system, the messages are lambdas that do a method call so the actor API is a class (or an enum, a record or even a lambda).","n":0.164}}},{"i":2884,"$":{"0":{"v":"Lokijs","n":1},"1":{"v":"\n- \n![[prdct.rxdb#^pnjx84u9yrqy]]\n\n","n":0.707}}},{"i":2885,"$":{"0":{"v":"Logz.io Open 360 Platform","n":0.5},"1":{"v":"\n- Can do distributed tracing using [[prdct.opensearch]] for $5/mo\n- [[p.alternativeTo]] \n  - [[prdct.logtail]]\n  - [[prdct.sematext]]\n","n":0.258}}},{"i":2886,"$":{"0":{"v":"Logtail","n":1},"1":{"v":"\n- [[p.basedOn]] [[prdct.clickhouse]]","n":0.577}}},{"i":2887,"$":{"0":{"v":"Logosphere","n":1},"1":{"v":"\n- [[c.software.web3]]\n- url: https://www.logosphere.io/\n- uses: [[prdct.fluree]]","n":0.408}}},{"i":2888,"$":{"0":{"v":"Lodview","n":1},"1":{"v":"\n- [[c.software.semantic.browser]]\n- repo: https://github.com/LodLive/LodView\n\n## Inspiration\n\nWe believe that the dereferencing layer has to be independent from the SPARQL endpoint implementation so during these last years we preferred using [[prdct.pubby]] to other software for publishing our data. Probably you don't know this, but you already know Pubby, it is used to publish DBpedia data and a lot of other Linked Open Data out there. Sadly, it is pretty old and its development appears to have stopped, so we created LodView taking inspiration from some of the features in it we really appreciated.","n":0.105}}},{"i":2889,"$":{"0":{"v":"LODmilla","n":1},"1":{"v":"\n- https://www.dbpedia.org/community/lodmilla/\n- [[c.software.visualization.semantic]]\n\n![](/assets/images/2024-09-23-13-51-45.png)\n\n## Features\n\n- visualizing associations in LOD graphs with special linked data functions such as\n  - searching and exploring the neighborhood of a resource node\n  - saving and sharing graph views\n  - doing minor edits on triples\n","n":0.162}}},{"i":2890,"$":{"0":{"v":"Lodlive","n":1},"1":{"v":"\n- http://en.lodlive.it\n\n![](/assets/images/2024-09-23-13-48-19.png)","n":0.707}}},{"i":2891,"$":{"0":{"v":"Lodifier","n":1},"1":{"v":"\n- https://isabelleaugenstein.github.io/papers/ESWC2012-LODifier.pdf\n- [[c.software.semantic.authoring]] [[c.software.semantic.utility]]\n\n\n## References\n\n- [[ar.lodifier-generating-linked-data-from-unstructured-text]]\n","n":0.408}}},{"i":2892,"$":{"0":{"v":"LODE","n":1},"1":{"v":"\n- similar: [[prdct.pylode]]\n- related: \n  - [[ar.w3.best-practice-recipes-for-publishing-rdf-vocabularies]]\n  - [[prdct.widoco]]\n  - ","n":0.316}}},{"i":2893,"$":{"0":{"v":"Lode Ontology","n":0.707},"1":{"v":"\n- https://linkedevents.org/ontology/\n\n![[prdct.event-ontology#related]]\n\n## Highlights\n\n- prototype \"event directory\" to locate stable URIs for events that have occurred\n  - dead: http://www.linkedevents.org","n":0.236}}},{"i":2894,"$":{"0":{"v":"Lodash","n":1}}},{"i":2895,"$":{"0":{"v":"Lod Cloud","n":0.707},"1":{"v":"\n- https://wafi.iit.cnr.it/lod/ (broken)","n":0.577}}},{"i":2896,"$":{"0":{"v":"Localforage","n":1},"1":{"v":"\n- repo: https://github.com/localForage/localForage\n- url: https://localforage.github.io/localForage/\n- ","n":0.447}}},{"i":2897,"$":{"0":{"v":"Lmdb","n":1}}},{"i":2898,"$":{"0":{"v":"Llvm","n":1}}},{"i":2899,"$":{"0":{"v":"Lively","n":1},"1":{"v":"- #dead ?\n- url: https://lively-next.org/\n- repo: https://github.com/LivelyKernel/LivelyKernel\n- written-in: javascript\n\n## Examples\n\n- https://lively-web.org/users/robertkrahn/poftp/polygons-gone-lively.html\n  - ","n":0.289}}},{"i":2900,"$":{"0":{"v":"LiterateCS","n":1},"1":{"v":"\n- repo: https://github.com/johtela/LiterateCS\n\n## Cons \n\n- doesn't support wikilinks, because [[prdct.markdig]] doesn't https://github.com/xoofx/markdig/issues/714 \n- treats XML comments as code, see https://stackoverflow.com/a/75277300/9483257\n","n":0.224}}},{"i":2901,"$":{"0":{"v":"Literary Theme Ontology","n":0.577},"1":{"v":"\n- repo: https://github.com/theme-ontology/theming\n- based-on: [[prdct.basic-formal-ontology]]\n\n\n## Content (as of 2024-08-22)\n\nliterary thematic entity\n├── the human world\n│   ├── human idea about life\n│   ├── human nature\n│   ├── personal human experience\n│   │   ├── human regular activity\n│   │   ├── humans in group\n│   │   ├── human in pairs\n│   │   ├── individual humans\n│   │   └── what life is like\n│   └── society\n│       ├── cross cultural issue\n│       ├── international issue\n│       ├── national social issue\n│       └── social ethical issue\n├── the natural world\n│   ├── folk belief\n│   ├── history\n│   ├── organized religion\n│   ├── philosophy\n│   ├── science\n│   ├── superseded scientific theory\n│   └── the art of war\n└── alternate reality\n    ├── crackpot theory\n    ├── speculative ability\n    ├── speculative being\n    ├── speculative effect\n    ├── speculative experience\n    ├── speculative natural process\n    ├── speculative place\n    ├── speculative punishment\n    ├── speculative society\n    ├── speculative technology\n    └── speculative travel","n":0.088}}},{"i":2902,"$":{"0":{"v":"Literary Character Ontology","n":0.577},"1":{"v":"\n\n\n## References\n\n- [[ar.representing-literary-characters-and-their-attributes-in-an-ontology]]","n":0.577}}},{"i":2903,"$":{"0":{"v":"Litedb","n":1},"1":{"v":"\n- url: https://www.litedb.org/","n":0.577}}},{"i":2904,"$":{"0":{"v":"Lit","n":1},"1":{"v":"\n- url: https://lit.dev/\n- ","n":0.577}}},{"i":2905,"$":{"0":{"v":"Linq","n":1},"1":{"v":"\n## Realted\n\n- [[prdct.ex-ram-gremlinq]]\n\n\n## References\n\n- https://learn.microsoft.com/en-us/dotnet/csharp/linq/","n":0.447}}},{"i":2906,"$":{"0":{"v":"LinkML","n":1},"1":{"v":"\n- url: https://linkml.io\n- repo:  https://github.com/linkml/linkml\n- written-in: #python\n- similar: [[prdct.aml]]\n- [[p.alternativeTo]] [[prdct.json-schema]]\n- [[p.supports]] \n  - [[t.cs.sd.mixin]] \n  - [[prdct.rdf]] see https://linkml.io/linkml/intro/tutorial04.html\n- [[c.feature.possible]] \n  - [[prdct.typedb]] converter\n- related: https://github.com/linkml/linkml-owl\n\n## Features\n\n- LinkML is designed to work in harmony with other frameworks, including both semantic RDF-based frameworks, as well as frameworks that are more familiar to developers such as JSON.\n\n### JSON-LD support\n\n- [[prdct.JSON-LD]] contexts and JSON-Schema provide distinct ways of describing your data, with JSON-Schema providing the structural description of how your information is organized, and contexts providing the semantics (or at least a loose semantics consisting of reuse of URIs). Despite these distinct purposes there is a lot of overlap and many organizations end up manually maintaining these and keeping them in sync.\n  - other frameworks like SHACL may be used for a frame-independent representation of the RDF.\n\n## Resources\n\n- https://www.linkedin.com/groups/14303246/\n- [LinkML: an open data modeling framework, grounded with ontologies](https://lnkd.in/gZv2TU6E)\n  - [[p.mentioned]] [[prdct.knowledge-graph-change-language]]\n- [[c.resource.learning]] \n  - https://linkml.io/linkml/intro/tutorial.html\n  - https://github.com/linkml/linkml-tutorial\n- https://github.com/w3c/wot-thing-description/blob/egekorkan-patch-3/toolchain/tool-analysis.md","n":0.08}}},{"i":2907,"$":{"0":{"v":"LinkedDataHub","n":1},"1":{"v":"\n- https://atomgraph.com/products/linkeddatahub/\n- https://atomgraph.github.io/LinkedDataHub/\n- similar: [[prdct.metaphactory]]","n":0.447}}},{"i":2908,"$":{"0":{"v":"Linked Open Vocabularies","n":0.577},"1":{"v":"\nhttps://lov.linkeddata.es/dataset/lov\n- [[c.software.semantic.search-engine]]","n":0.707}}},{"i":2909,"$":{"0":{"v":"LinkedIn","n":1}}},{"i":2910,"$":{"0":{"v":"Linked Delta","n":0.707},"1":{"v":"\n- dead\n- https://github.com/ontola/linked-delta\n- similar: [[prdct.rdf-delta]] [[prdct.json-patch]] [[prdct.json-ld-patch]] [[prdct.json-patcher]]\n\n## Description\n\n- To communicate changes to some (linked/RDF) dataset, special graph names can be used to convey the changes to that set.","n":0.186}}},{"i":2911,"$":{"0":{"v":"Linked Data Viewer","n":0.577},"1":{"v":"\n- repo: https://github.com/AKSW/Linked-Data-Viewer","n":0.577}}},{"i":2912,"$":{"0":{"v":"Linked Data Templates","n":0.577},"1":{"v":"\n- https://atomgraph.github.io/Linked-Data-Templates/\n\n## Solutions\n\n- [[prdct.atomgraph-processor]]\n\n## Comparisons\n\n### Linked Data Templates vs Linked Data Platform\n\n- Ontology as a declarative representation of the application's operations, dependency on SPARQL, formal valuation of interactions and the support for HATEOAS hypermedia are the main features that distinguish LDT from other Linked Data specifications such as Linked Data Platform [LDP]. Rather than prescribing a single interaction model as does LDP, LDT specifies ontology structure and processing rules that allow applications to define custom interaction models.\n\n### Linked Data Templates vs Hydra\n\n- Hydra Core Vocabulary is a lightweight vocabulary to create hypermedia-driven Web APIs and has similar goals to combine REST with Linked Data principles, but does not employ SPARQL and focuses on JSON-LD","n":0.094}}},{"i":2913,"$":{"0":{"v":"Linked Data Target Value Maps","n":0.447},"1":{"v":"\n- https://github.com/niklasl/ldtvm\n- related: [[prdct.trld]]\n\n## Background\n\nInferencing is often considered a foundational feature for mechanical semantic interoperability. But it is fairly unheard of outside the semantic web community. Not even in the wider circle of linked data proponents does inference feature as a part of common implementations and services.\n\nMeanwhile the web of data at large continues to grow (with REST APIs and services multiplying, with lots of invention and plenty of code being or waiting to be written for integrations of increasing complexity, with little or no reuse between them). Every need cropping up in and between our organizations which needs to be solved right now thus requires us to write up yet another integration script; batching, caching, indexing and (more or less successfully) keeping track of source updates and deletions.\n\nOn the level of terms and shapes of descriptions, metadata experts are mired in perpetuated discussion, more or less related to the crude realities of said integrations. Most crucially, these integrations seldom work for interoperability when multiple perspectives and granularities are taken into consideration. The same patterns are defined and implemented over and over again.\n\n### On OWL Reasoners\n\nThere are some things which OWL reasoners are prone to, which makes them cumbersome to integrate in \"simpler\" applications. A great amount of general intelligence for inferring facts is applied, but not so much is about selection, and handling of granularities and proportions between on the one hand events and qualifications, on the other simpler (\"dumbed-down\") \"shorthand\" properties.\n\n- Reasoners produce all inferable triples, instead of triples for a desired target vocabulary or selected combination.\n- There is no means to specify which reduction or expansion to use for a desired granularity.\n- This general inference process can be unpredictably slow.\n","n":0.059}}},{"i":2914,"$":{"0":{"v":"Linked Data Notifications","n":0.577},"1":{"v":"\n- https://www.w3.org/TR/ldn/\n\n![[prdct.websub#similar]]\n\n## Description\n\n- (LDN) supports sharing and reuse of notifications across applications, regardless of how they were generated. This allows for more modular systems, which decouple data storage from the applications which display or otherwise make use of the data. The protocol is intended to allow senders, receivers and consumers of notifications, which are independently implemented and run on different technology stacks, to seamlessly work together, contributing to decentralisation of our interactions on the Web.\n\nInstead of treating notifications as ephemeral or non-persistent entities, this specification enables the notion of a notification as an individual entity with its own URI.\n\n\n## Comparisons\n\n![[prdct.websub#websub-vs-linked-data-notification]]","n":0.1}}},{"i":2915,"$":{"0":{"v":"Linked Data Maps","n":0.577},"1":{"v":"\n- [[c.software.visualization.semantic]]\n- wa\n\n## References\n\n- https://ceur-ws.org/Vol-1472/IESD_2015_paper_2.pdf","n":0.447}}},{"i":2916,"$":{"0":{"v":"LinkedMDB Atlas","n":0.707},"1":{"v":"\n- http://wafi.iit.cnr.it/lod/linkedmdb/atlas/\n\n![](/assets/images/2024-09-23-14-00-08.png)","n":0.707}}},{"i":2917,"$":{"0":{"v":"Dbpedia Atlas","n":0.707},"1":{"v":"\n- \n- repo: https://github.com/fabiovalse/dbpedia_atlas\n\n\n![](/assets/images/2024-09-23-13-58-18.png)","n":0.5}}},{"i":2918,"$":{"0":{"v":"Linked Data Fragments","n":0.577},"1":{"v":"\n- https://linkeddatafragments.org/\n- related: [[prdct.comunica]] [[prdct.triple-data-fragments]]\n\n## Description\n\n- each **type**(?) of linked data fragment (including triple pattern fragments) is defined by\n  - data\n  - metadata\n  - controls (how to access more data)\n\n## Examples\n\n- data dumps (example): their selector is the universal selector, their metadata set includes the file size, and their control set is empty.\n\n- subject pages (example): their selector is a subject URI, their metadata set is often empty, and their control set is given by URIs that can be dereferenced.\n\n- SPARQL results (example): their selector is a CONSTRUCT query, their metadata set is empty, and their control set includes the endpoint URI, which allows to retrieve other SPARQL results.\n\n\n\n## References\n\n- https://videolectures.net/iswc2014_verborgh_querying_datasets/","n":0.095}}},{"i":2919,"$":{"0":{"v":"Triple/Quad Pattern Fragments","n":0.577},"1":{"v":"\n- spec: \n  - https://linkeddatafragments.org/specification/triple-pattern-fragments/ \n  - https://linkeddatafragments.org/specification/quad-pattern-fragments/\n\n## Description\n\n- clients execute SPARQL queries using Triple Pattern Fragments. This way, servers only need to publish Triple Pattern Fragments of a dataset, providing a scalable yet efficient way to query Linked Data.\n- A Triple Pattern Fragments server functions in front of a SPARQL endpoint or on top of other datasources.\n\n## Issues\n\n- rdf-star support?\n\n## Examples\n\n- http://data.linkeddatafragments.org/\n\n## Implementations\n\n\n### Server Implementations\n\nJavaScript\n\n[Server.js](https://github.com/LinkedDataFragments/Server.js) for Node.js\n\nPython\n\n[linked-data-fragments](https://github.com/jermnelson/linked-data-fragments/tree/development)\n\nPerl\n\n[RDF::LinkedData](https://metacpan.org/pod/RDF::LinkedData)\n\nRuby\n\n[Linked Data Fragments](https://github.com/ActiveTriples/linked-data-fragments)\n\nPHP\n\n[The DataTank](https://github.com/tdt/triples)\n\nJava\n\n[Server.java](https://github.com/LinkedDataFragments/Server.java)\n\nNetKernel\n\n[NetKernel server](https://github.com/elephantbirdconsulting/netkernel-contribution/)\n\n## References\n\n- https://linkeddatafragments.org/in-depth/","n":0.116}}},{"i":2920,"$":{"0":{"v":"Linked Data Fragments Server","n":0.5},"1":{"v":"\n- repo: https://github.com/LinkedDataFragments/Server.js\n- written_in: javascript (node)\n\n## Motivation\n\nOn today's Web, Linked Data is published in different ways, which include [data dumps](http://downloads.dbpedia.org/3.9/en/), [subject pages](http://dbpedia.org/page/Linked_data), and [results of SPARQL queries](http://dbpedia.org/sparql?default-graph-uri=http%3A%2F%2Fdbpedia.org&query=CONSTRUCT+%7B+%3Fp+a+dbpedia-owl%3AArtist+%7D%0D%0AWHERE+%7B+%3Fp+a+dbpedia-owl%3AArtist+%7D&format=text%2Fturtle). We call each such part a [**Linked Data Fragment**](http://linkeddatafragments.org/).\n\nThe issue with the current Linked Data Fragments is that they are either so powerful that their servers suffer from low availability rates ([as is the case with SPARQL](http://sw.deri.org/~aidanh/docs/epmonitorISWC.pdf)), or either don't allow efficient querying.\n\nInstead, this server offers [Quad Pattern Fragments](https://linkeddatafragments.org/specification/quad-pattern-fragments/) (a.k.a. **[Triple Pattern Fragments](https://linkeddatafragments.org/specification/triple-pattern-fragments/)**). Each Quad Pattern Fragment offers:\n\n-   **data** that corresponds to a _quad/triple pattern_ _([example](http://data.linkeddatafragments.org/dbpedia?subject=&predicate=rdf%3Atype&object=dbpedia-owl%3ARestaurant))_.\n-   **metadata** that consists of the (approximate) total triple count _([example](http://data.linkeddatafragments.org/dbpedia?subject=&predicate=rdf%3Atype&object=))_.\n-   **controls** that lead to all other fragments of the same dataset _([example](http://data.linkeddatafragments.org/dbpedia?subject=&predicate=&object=%22John%22%40en))_.\n\nAn example server is available at [data.linkeddatafragments.org](http://data.linkeddatafragments.org/).","n":0.091}}},{"i":2921,"$":{"0":{"v":"LikeC4","n":1},"1":{"v":"\n- https://likec4.dev/\n- [[c.Software.Tools.Modeling]] [[c.Software.Tools.Diagramming]]\n- repo: https://github.com/likec4/likec4\n- \n- similar: [[prdct.ilograph]]\n- related: [[prdct.C4-PlantUML]]\n\n## References\n\n- [[t.cs.sd.c4-model]]","n":0.277}}},{"i":2922,"$":{"0":{"v":"LikeC4 Vscode extension","n":0.577},"1":{"v":"\n- https://marketplace.visualstudio.com/items?itemName=likec4.likec4-vscode\n- [[c.Software.IDE.Extension.VSCode]] [[c.Software.Tools.Diagramming]]","n":0.5}}},{"i":2923,"$":{"0":{"v":"Lightstep","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[prdct.new-relic]]\n- [[p.supports]] [[t.cs.sd.observability]]\n- [[p.compatibleWith]] [[prdct.opentelemetry]]\n","n":0.378}}},{"i":2924,"$":{"0":{"v":"libp2p","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://libp2p.io\n- [[p.supports]] [[prdct.noise]]\n- [[p.hasLearningResource]] https://docs.libp2p.io/tutorials/getting-started/javascript/\n","n":0.378}}},{"i":2925,"$":{"0":{"v":"Libgdx","n":1},"1":{"v":"\n\n## Resources\n\n- https://github.com/rafaskb/awesome-libgdx#readme\n\n\n## References\n\n- ","n":0.5}}},{"i":2926,"$":{"0":{"v":"Lex","n":1},"1":{"v":"\n- https://lex.page/","n":0.707}}},{"i":2927,"$":{"0":{"v":"Levelgraph","n":1},"1":{"v":"\n\n\n- LevelGraph is a Graph Database. Unlike many other graph database, LevelGraph is built on the uber-fast key-value store [[LevelDB|prdct.leveldb]] through the powerful LevelUp library. You can use it inside your node.js application or in any IndexedDB-powered Browser.\n- ","n":0.162}}},{"i":2928,"$":{"0":{"v":"LevelDB","n":1},"1":{"v":"\n- repo: https://github.com/google/leveldb\n- written-in: #c++\n\n\n## Cons\n\n-   This is not a SQL database. It does not have a relational data model, it does not support SQL queries, and it has no support for indexes.\n-   Only a single process (possibly multi-threaded) can access a particular database at a time.\n-   There is no client-server support builtin to the library. An application that needs such support will have to wrap their own server around the library.\n\n\n\n","n":0.118}}},{"i":2929,"$":{"0":{"v":"Lets Role","n":0.707},"1":{"v":"\n- [[c.software.rpg.virtual-tabletop]]\n- https://lets-role.com/\n- partners: [[prdct.chronos-builder]]","n":0.447}}},{"i":2930,"$":{"0":{"v":"Let''s Chat","n":0.707},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] demochat\n- [[p.hasURL]] https://codefresh.io/docs/docs/learn-by-example/nodejs/lets-chat/\n- [[p.hasRepository]] https://github.com/codefreshdemo/demochat\n","n":0.378}}},{"i":2931,"$":{"0":{"v":"Lepiter","n":1},"1":{"v":"\n\n- [[p.isComponentOf]] [[prdct.glamorous-toolkit]]\n- [[p.hasApplication]] [[t.km]] \n- resources:  https://lepiter.io/feenk/introducing-lepiter--knowledge-management--e2p6apqsz5npq7m4xte0kkywn/\n- [[p.supports]] https://en.wikipedia.org/wiki/Wardley_map\n\n## Features\n\n- [[t.cs.sd.moldable-development]]","n":0.289}}},{"i":2932,"$":{"0":{"v":"Legend Keeper","n":0.707},"1":{"v":"\n- [[c.software.rpg]] [[c.software.rpg.campaign-manager]]\n- url: https://www.legendkeeper.com/\n- [[c.mention]] [[prdct.dscryb]] [[prdct.here-be-taverns]]\n- [[c.con]] JSON export is ugly and littered with html and css classnames\n\n## [[c.model.conceptual]]\n\n- elements represent \"anything\", e.g. person, place, thing, event, a piece of lore, a chapter of a book\n  - contain any number of wiki page, map, or whiteboard tabs\n\n## [[c.model.business]]\n\n- SaaS, but \"When a subscription lapses, project owners can continue to access their projects and see the contents, though they can no longer edit or create new things... Project guests can not view projects with lapsed subscriptions. Only the project creator can.\"","n":0.104}}},{"i":2933,"$":{"0":{"v":"Lean","n":1},"1":{"v":"\n- https://lean-lang.org/\n- [[c.language.programming]] [[c.software.theorem-prover]]","n":0.5}}},{"i":2934,"$":{"0":{"v":"Leaflet","n":1},"1":{"v":"\n- url: https://leafletjs.com/\n- repo: https://github.com/Leaflet/Leaflet\n\n## Resources\n\n### Learning Resource\n\n- https://github.com/renelikestacos/Web-Mapping-Leaflet-NodeJS-Tutorials #dead\n- https://fenixfox-studios.com/content/leaflet_geojson_&_topojson/ [[prdct.topojson]]","n":0.289}}},{"i":2935,"$":{"0":{"v":"Ldkit","n":1},"1":{"v":"\n- https://ldkit.io/\n- repo: https://github.com/karelklima/ldkit","n":0.5}}},{"i":2936,"$":{"0":{"v":"LDflex","n":1},"1":{"v":"\n- [[c.Software.object-graph-mapper]]\n- repo: https://github.com/LDflex/LDflex\n- used-in: [[game.solid-chess]]\n\n## References\n\n- [[ar.ldflex-a-read-write-linked-data-abstraction-for-front-end-web-developers]]","n":0.354}}},{"i":2937,"$":{"0":{"v":"LD Viewer","n":0.707},"1":{"v":"\n- [[c.software.visualization.semantic]]\n\n## References\n\n- https://jens-lehmann.org/files/2014/semantics_ld_viewer.pdf","n":0.5}}},{"i":2938,"$":{"0":{"v":"LD-R","n":1},"1":{"v":"\n- http://ld-r.org/\n- [[c.software.semantic.utility]]","n":0.577}}},{"i":2939,"$":{"0":{"v":"LD Connect","n":0.707},"1":{"v":"\n- http://ld.iospress.nl/\n- uses: [[prdct.yasgui]]","n":0.5}}},{"i":2940,"$":{"0":{"v":"Lavinhq","n":1},"1":{"v":"\n- url: https://lavinmq.com/\n- repo: https://github.com/cloudamqp/lavinmq/\n- [[p.compatibleWith]] [[prdct.amqp]]","n":0.378}}},{"i":2941,"$":{"0":{"v":"Laverna","n":1},"1":{"v":"\n- url: https://laverna.cc/\n- repo: https://github.com/Laverna/laverna\n- [[p.alternativeTo]] [[prdct.evernote]]","n":0.378}}},{"i":2942,"$":{"0":{"v":"Lava Flow","n":0.707}}},{"i":2943,"$":{"0":{"v":"Lattice Engines","n":0.707},"1":{"v":"\n\n- [[p.hasApplication]] predictive lead scoring\n","n":0.447}}},{"i":2944,"$":{"0":{"v":"Laptop Simulator","n":0.707},"1":{"v":"\n\n\n## User Stories\n\n### requires a lot of set up and is literally Roll20 with extra steps (and non-free)","n":0.236}}},{"i":2945,"$":{"0":{"v":"Landscape","n":1}}},{"i":2946,"$":{"0":{"v":"Landscape Lab","n":0.707},"1":{"v":"\n- [[c.software.virtual-reality]]\nurl: https://landscapelab.boku.ac.at/\n\n## [[c.component]]\n\n-   The geodata for the game board are pre-processed with [QGIS](https://www.qgis.org/de/site/). QGIS is also used to send the map as a video stream for the projection.\n-   The object recognition of the game tokens is realised with [OpenCV](https://opencv.org/) and Python.\n-   The 3D environment is displayed with the free game engine [Godot](https://godotengine.org/).\n-   The geo data is stored in a [PostGIS database](https://postgis.net/) or a geopackage. Single files like shapefiles or GeoTIFFs can be loaded additionally.\n-   [GDAL](https://gdal.org/) is used for data import, projections and conversions.\n-   A separate C++ plugin provides an interface between GDAL and Godot.","n":0.103}}},{"i":2947,"$":{"0":{"v":"Lancedb","n":1},"1":{"v":"\n- https://lancedb.github.io/lancedb/\n- [[c.Software.Database.Vector]]\n- written_in: python rust typescript\n- repo: https://github.com/lancedb/lancedb\n- licensing: available in two flavors: OSS and Cloud.\n- ","n":0.243}}},{"i":2948,"$":{"0":{"v":"Lance","n":1},"1":{"v":"\n- no commits since 2022\n- \"Lance is being maintained but no longer actively developed\"\n  - [[p.hasSource]] https://giters.com/lance-gg/lance/issues/141\n- \"real-time\" but can it do turn-based?\n\n## [[p.hasSource]] https://html5gamedevelopment.com/lance-real-time-multiplayer-game-server/\n\n    Optimized networking\n– TCP via websockets\n– Communication is packed and serialized into binary\n– Automatic handling of network spikes with step correction\n\n    Intelligent sync strategies for lag handling\n\n– Extrapolation (client side prediction) with step re-enactment or:\n– Interpolation for optimal object motion\n\n    Tools for debugging and tracing\n","n":0.12}}},{"i":2949,"$":{"0":{"v":"Lamina1","n":1},"1":{"v":"\n- url: https://hub.lamina1.com/\n- #docs https://docs.lamina1.com\n- [[prdct.emergence-sdk]]","n":0.408}}},{"i":2950,"$":{"0":{"v":"Lamar","n":1}}},{"i":2951,"$":{"0":{"v":"Kylin","n":1}}},{"i":2952,"$":{"0":{"v":"Kyligence Unified Semantic Layer","n":0.5},"1":{"v":"\n\n- [[p.hasURL]] https://kyligence.io/unified-semantic-layer/\n","n":0.577}}},{"i":2953,"$":{"0":{"v":"Kubernetes","n":1},"1":{"v":"\n## [[c.term]]\n\n- **Context**: group of access parameters that specify which cluster you're interacting with\n- **Pod**: Kubernetes abstraction that represents a group of one or more application containers (such as Docker), and some shared resources for those containers.\n- **Cluster**: a set of nodes\n- **Namespace**: mechanism for isolating groups of resources within a single cluster\n\n## Resources\n\n- https://earthly.dev/blog/building-k8s-tekton/\n- https://redhat-scholars.github.io/tekton-tutorial/tekton-tutorial/setup.html#tekton-prerequisites\n\n### Comparison\n\n- https://earthly.dev/blog/k8s-dev-solutions/ \n  - [[c.comparand]] \n    - [[prdct.k8s]]\n    - [[prdct.kubernetes.kubeadm]]\n    - [[prdct.kind]]\n  - [[prdct.earthly]]\n\n","n":0.12}}},{"i":2954,"$":{"0":{"v":"Kubeadm","n":1}}},{"i":2955,"$":{"0":{"v":"Gateway API","n":0.707},"1":{"v":"\nurl: https://gateway-api.sigs.k8s.io/\n","n":0.707}}},{"i":2956,"$":{"0":{"v":"Ktor","n":1},"1":{"v":"\n- url: https://ktor.io/\n- written_in: kotlin","n":0.447}}},{"i":2957,"$":{"0":{"v":"Knowledge Graph Toolkit","n":0.577},"1":{"v":"\n\n\n- [[p.hasRepository]] https://github.com/usc-isi-i2/kgtk/\n- [[p.hasCon]] \n- [[p.hasFeature]]\n  - A notable feature of KGTK is that edges are also nodes\n    - [[p.hasSource]] https://kgtk.readthedocs.io/en/latest/data_model/\n  - KGTK represents KGs using TSV files with 4 columns labeled id, node1, label and node2\n    - id column is a symbol representing an identifier of an edge\n  - Given that edges are nodes, it is possible to define edges that connect edges to other nodes, as illustrated using the blue arrows.\n- [[p.canImportFrom]]\n  - [[prdct.tsv]]\n\n- [[p.vs]] \n  - [[t.cs.graph.property-graph]]\n    - The KGTK model is a generalization of property graphs because the attribute/value pairs are also edges: the attributes are relations and the values can be arbitrary nodes.\n  - [[t.cs.graph.semantic-graph]]\n    - To represent edges about edges, RDF uses reification, typically done using rdf:Statement, where the edges are represente using three triples. The KGTK representation is simpler as it does not require the creation of extra triples to represent the edges.\n\n\n","n":0.082}}},{"i":2958,"$":{"0":{"v":"Ksuid","n":1},"1":{"v":"\n- https://github.com/segmentio/ksuid\n- written-in: go\n\n## Other Implementations\n\nf\n\n## References\n\n- https://segment.com/blog/a-brief-history-of-the-uuid/","n":0.354}}},{"i":2959,"$":{"0":{"v":"Kroki","n":1},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- url: https://kroki.io/\n- [[p.supports]] BlockDiag (BlockDiag, SeqDiag, ActDiag, NwDiag, PacketDiag, RackDiag), BPMN, Bytefield, C4 (with PlantUML), D2, DBML, Ditaa, Erd, Excalidraw, GraphViz, Mermaid, Nomnoml, Pikchr, PlantUML, Structurizr, SvgBob, TikZ, UMLet, Vega, Vega-Lite, WaveDrom, WireViz","n":0.169}}},{"i":2960,"$":{"0":{"v":"Krita","n":1}}},{"i":2961,"$":{"0":{"v":"Krew","n":1},"1":{"v":"\n- url: https://krew.sigs.k8s.io/","n":0.577}}},{"i":2962,"$":{"0":{"v":"KR Ontology","n":0.707},"1":{"v":"\n- [[c.ontology.upper]]\n- creator: @john-sowa\n\n## Top-level Categories\n\n Outer pipes Cell padding\n\n|             | Physical   | | Abstract      |\n| ----------- | ---------- | ------------- |\n|             | Continuant | Occurrent     | Continuant | Occurrent |\n| Independent | Object     | Process       | Schema | Script |\n| Relative    | Juncture   | Participation | Description | History |\n| Mediating   | Structure  | Situation     | Reason | Purpose |\n\n\n\n## References\n\n- [[book.knowledge-representation]]\n- http://www.jfsowa.com/ontology/kronto.htm\n- http://www.jfsowa.com/ontology/toplevel.htm","n":0.124}}},{"i":2963,"$":{"0":{"v":"Kotlin Simulation Library","n":0.577},"1":{"v":"\n## Resources\n\n- https://rossetti.github.io/KSLBook/overview-of-the-kotlin-simulation-library.html","n":0.577}}},{"i":2964,"$":{"0":{"v":"Korge","n":1},"1":{"v":"\n- repo: https://github.com/korlibs/korge\n- written_in: kotlin","n":0.447}}},{"i":2965,"$":{"0":{"v":"Koreografeye","n":1},"1":{"v":"\n- repo: https://github.com/eyereasoner/Koreografeye\n- written_in: typescript\n- demo: https://github.com/eyereasoner/KoreografeyeDemo\n- uses: [[prdct.fno]] [[prdct.components-js]]\n\n## Description\n\n- Koreografeye is a choreography / orchestration engine for linked data services using [[prdct.notation3]] (N3) rule engines such as [[prdct.eye]].\n\nKoreografeye was created to facilitate automated processes against Solid pods. Our main use case is monitoring the LDN Inbox of [[prdct.solid]] Pods for new notifications and running scripts when new data arrives.","n":0.128}}},{"i":2966,"$":{"0":{"v":"Kopflos","n":1},"1":{"v":"\n- \n- repo: https://github.com/zazuko/kopflos\n- based-on: [[prdct.rdf-ext]]\n\n## Description\n\n[[Hydra|prdct.hydra]] is a machine readable description for APIs. Kopflos extends the API description with links to the actual code, which provides the API. Kopflos will use such an API description to create an express middleware which provides the API and dynamically loads the required code for it.","n":0.137}}},{"i":2967,"$":{"0":{"v":"Konva.js","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n- used-in: [[prdct.lets-role]]","n":0.5}}},{"i":2968,"$":{"0":{"v":"Komma","n":1},"1":{"v":"\n- http://komma.enilink.net/\n\n## Description\n\nKOMMA simply allows to access the property by calling a method like person.getFoafName() on an object representing the person.\n\n\n## Features\n\n* Mapping of Java interfaces to RDF types\n\n* Support for multiple inheritance\n\n* Implementation of logic using behaviours and aspect-oriented programming\n\n* Caching of beans and properties\n\n* Model API for working with named graphs\n\n","n":0.137}}},{"i":2969,"$":{"0":{"v":"Kogito","n":1},"1":{"v":"\n- [[c.software.decisionengine]]\n- repo: https://github.com/kiegroup/kogito-runtimes\n- url: https://kogito.kie.org/\n- related: [[prdct.drools]]\n\n## Features\n\n- ability to use the Java-based declaration of a rule unit to automatically map it with the signature of a REST endpoint\n\n## [[c.solution.related]]\n\n- [[prdct.drools]]\n  - \"use Drools core features but bring the following improvements:\n    - Modular Rules\n      - introduces the concept of Rule unit, which is a module for rules and a unit of execution. A rule unit collects a set of rules with the declaration of the type of facts that the rules act on. A rule unit also serves as a unique namespace for each group of rules. A single rule base can contain multiple rule units.\n    - Advanced Code generation to create Endpoints from Rules","n":0.093}}},{"i":2970,"$":{"0":{"v":"Kogito Bundle","n":0.707},"1":{"v":"\n- [[c.software.ide.extension.vscode]] \n- #similar [[prdct.rulesengine.editor]]\n- [[p.supports]] [[prdct.bpmn]] [[prdct.dmn]]","n":0.354}}},{"i":2971,"$":{"0":{"v":"Koa","n":1}}},{"i":2972,"$":{"0":{"v":"Knowledge Interchange Format","n":0.577},"1":{"v":"\n- creators: @genesereth @fikes","n":0.5}}},{"i":2973,"$":{"0":{"v":"Knowledge Graph Change Language","n":0.5},"1":{"v":"\n- url: https://incatools.github.io/kgcl/\n- repo: https://github.com/INCATools/kgcl\n- related: https://github.com/linkml/linkml-transformer\n\n## Thoughts\n\n- might be an interesting reference, but aimed at property graphs","n":0.236}}},{"i":2974,"$":{"0":{"v":"Knowbe4","n":1}}},{"i":2975,"$":{"0":{"v":"Kml","n":1},"1":{"v":"\n- ","n":1}}},{"i":2976,"$":{"0":{"v":"Kit","n":1},"1":{"v":"\n- url: https://kit-clj.github.io/\n- written_in: clojure\n- successor_to: [[prdct.luminus]]","n":0.378}}},{"i":2977,"$":{"0":{"v":"Kinopio","n":1},"1":{"v":"\n- [[p.hasURL]] https://kinopio.club/\n- [[p.hasApplication]] [[t.km]] [[t.km.visualization]]\n- [[p.hasFeature]]\n  - definable connection types\n- [[p.hasCon]]\n  - tags use wikilink syntax\n  \n","n":0.236}}},{"i":2978,"$":{"0":{"v":"Kind","n":1},"1":{"v":"\n- url: https://kind.sigs.k8s.io/\n- ","n":0.577}}},{"i":2979,"$":{"0":{"v":"KIF","n":1},"1":{"v":"\n![[ar.temporal-interval-reasoning-with-clp-q#^ox70bpj41vs6]]","n":1}}},{"i":2980,"$":{"0":{"v":"KIF-Vampire","n":1},"1":{"v":"\n- related: [[prdct.sumo]] [[prdct.vampire]]\n- ","n":0.5}}},{"i":2981,"$":{"0":{"v":"Keycloak","n":1},"1":{"v":"\n- [[c.Software.Authentication]]\n- url: https://www.keycloak.org/\n- repo: https://github.com/keycloak/keycloak\n- similar:  OAuth2 Proxy, Gluu Server, WSO2 Identity Server, and Apache \n- written-in: java","n":0.229}}},{"i":2982,"$":{"0":{"v":"Kestra","n":1},"1":{"v":"\n- https://kestra.io/\n- [[c.Software.Workflow]]\n- license: \n  - [[lic.apache.2]] for open-source version\n  - enterprise edition has security, governance, and scalability\n- written-in: java\n\n![[prdct.infinitic#similar]]\n\n## Features\n\n- Write your business logic in any language. Kestra supports Java-based plugins as well as scripts written in Python, R, Julia, Ruby, Shell, Powershell and Node.js.\n- Flow execution based on event triggers including file detection, message queues, completion of certain flows, or results of a SQL query or API call.\n\n### Runners\n\n- JDBC Runner: Ideal for environments preferring traditional databases, this runner supports H2, PostgreSQL, and MySQL for both queueing and repository functions.\n- Kafka Runner: For more demanding scalability requirements, this runner employs Kafka for queue and Elasticsearch for repositary, available exclusively in the enterprise edition.\n\n### Plugins\n\n- **Git Plugin**: this plugin allows you to pull code from any Git repository at runtime, making it easier to execute custom scripts in Python, SQL, or other languages. You can set a custom branch name and configure authentication to private repositories.See the example below and [learn more about the Git plugin.](https://kestra.io/plugins/plugin-git)\n- **NATS Plugin**: this plugin allows you to trigger flows based on new messages in the [nats.io](https://nats.io/) distributed system. There’s also a task to consume or produce new messages. See the [NATS plugin documentation](https://kestra.io/plugins/plugin-nats) for more details.\n\n\n## Support\n\n### ","n":0.07}}},{"i":2983,"$":{"0":{"v":"Keralua","n":1}}},{"i":2984,"$":{"0":{"v":"Kbpedia Knowledge Ontology","n":0.577},"1":{"v":"\n- description: The upper structure of the KBpedia Knowledge Ontology (KKO) is informed by the triadic logic and universal categories of Charles Sanders Peirce. This trichotomy, also the basis for his views on semiosis (or the nature of signs), was in Peirce's view the most primitive or reduced manner by which to understand and categorize things, concepts and ideas\n\n## Resources\n\n- https://kbpedia.org/docs/kko-upper-structure/","n":0.128}}},{"i":2985,"$":{"0":{"v":"Kbox","n":1},"1":{"v":"\n- https://github.com/AKSW/KBox\n- written-in: java\n- built-on: [[prdct.jena]]\n\n## Issues\n\n- \"currently KBox does not allow you to directly publish content to make them available to other users\"\n","n":0.204}}},{"i":2986,"$":{"0":{"v":"Kare","n":1},"1":{"v":"\n- a ghost","n":0.577}}},{"i":2987,"$":{"0":{"v":"Karate","n":1},"1":{"v":"\n- [[c.software.tools.testing]] [[c.software.tools.testing.api]]\n- repo: https://github.com/karatelabs/karate\n- similar: [[prdct.cucumber]] [[prdct.gherkin]]","n":0.354}}},{"i":2988,"$":{"0":{"v":"Karaspace","n":1},"1":{"v":"\n- \"Smalltalk 3D Graphics Engine: The 3d world is programmed all in Smalltalk code. The open source three.js library is used transparently in the frontend client Smalltalk Environment. All the JavaScript libraries are available within Smalltalk because the language structure is very similar  Javascript is like the assembler of the Web.\"\n  - https://karaspace.net/smalltalk-3d-graphics/","n":0.137}}},{"i":2989,"$":{"0":{"v":"Kantola","n":1}}},{"i":2990,"$":{"0":{"v":"Kanka","n":1},"1":{"v":"\n- [[c.software.rpg.campaign-manager]]\n\n## Features\n\n- Premium campaigns can define workflows that send updates to Discord and other tools through [[t.cs.web.webhooks]] when changes to entities are made.","n":0.204}}},{"i":2991,"$":{"0":{"v":"Kanka Foundry","n":0.707},"1":{"v":"\n- repo: https://github.com/eXaminator/kanka-foundry","n":0.577}}},{"i":2992,"$":{"0":{"v":"Kairos","n":1},"1":{"v":"\n- url: https://opencollective.com/kairos-research-lab\n- repo: https://github.com/KairosResearchLab/Kairos","n":0.447}}},{"i":2993,"$":{"0":{"v":"Kafkasaur","n":1},"1":{"v":"\nurl: https://deno.land/x/kafkasaur","n":0.707}}},{"i":2994,"$":{"0":{"v":"KafkaJS","n":1},"1":{"v":"\n## Cons\n\n- doesn't support streams natively\n  - \"While certain situations require the rich state querying capabilities of the Java-based Kafka Streams, other scenarios, such as edge deployments or serverless functions, may prefer a more lightweight approach. Node.js, for example, generally offers faster startup times and a smaller footprint.\"\n  - BUT https://nodefluent.github.io/kafka-streams/\n## Resources\n\n- https://javascript.plainenglish.io/a-beginners-introduction-to-kafka-with-typescript-using-nestjs-7c92fe78f638\n- https://soshace.com/the-ultimate-introduction-to-kafka-with-javascript/","n":0.136}}},{"i":2995,"$":{"0":{"v":"Kafka","n":1},"1":{"v":"\n- [[c.software.data-framework.streaming]]\n- [[p.hostedBy]]\n  - [[prdct.upstash]] for free\n- [[p.supports]] [[prdct.cloudevents]]\n  - https://github.com/cloudevents/spec/blob/main/cloudevents/bindings/kafka-protocol-binding.md\n- related: [[prdct.samza]]\n\n![[prdct.redpanda#similar]]\n\n### Managed\n![[prdct.azure.event-hubs#^ls3s1l3vm1hl]]\n\n\n## Pros\n\n## Cons\n\n- massive\n- [[t.cs.sd.event-sourcing]] is not a top-level architecture [^1]\n\n## Features\n\n- [dynamic routing](https://www.confluent.io/blog/putting-events-in-their-place-with-dynamic-routing/)\n- **compaction** \n\n## Use Cases\n\n- \"Kafka is not an event store; rather, it is an enabler for building event stores.\"\n  - https://towardsdatascience.com/the-design-of-an-event-store-8c751c47db6f\n\n## Comparisons\n\n![[prdct.nats#kafka-vs-nats]]\n\n## Learning Resource\n\n## [[c.footnote]]\n\n[^1]: https://itnext.io/event-sourcing-why-kafka-is-not-suitable-as-an-event-store-796e5d9ab63c","n":0.137}}},{"i":2996,"$":{"0":{"v":"Sink","n":1}}},{"i":2997,"$":{"0":{"v":"Graphdb","n":1},"1":{"v":"\n- https://github.com/Ontotext-AD/kafka-sink-graphdb","n":0.707}}},{"i":2998,"$":{"0":{"v":"Kafka Streams","n":0.707},"1":{"v":"\nrepo: https://github.com/nodefluent/kafka-streams","n":0.707}}},{"i":2999,"$":{"0":{"v":"K8s","n":1}}},{"i":3000,"$":{"0":{"v":"Jupyter","n":1},"1":{"v":"\n- [[c.software.computational-notebook]]\n\n## #related\n\n- [[prdct.binder]]\n\n## Resources\n\n- https://nextjournal.com/schmudde/how-to-version-control-jupyter\n  - [[p.mentioned]] [[prdct.neptune]] [[prdct.nextjournal]]","n":0.316}}},{"i":3001,"$":{"0":{"v":"Jumpcloud","n":1}}},{"i":3002,"$":{"0":{"v":"Juliagraphs","n":1},"1":{"v":"\n- url: https://juliagraphs.org/\n- ","n":0.577}}},{"i":3003,"$":{"0":{"v":"Juggl","n":1},"1":{"v":"\n\n[[p.hasSite]] https://juggl.io/\n\n- [[p.solvesProblem]] [[t.cs.graph.visualization]]\n- [[p.hasRelatedSolution]] [[prdct.semantic-obsidian]]\n","n":0.408}}},{"i":3004,"$":{"0":{"v":"Jtp","n":1},"1":{"v":"\n- https://web.archive.org/web/20220523050219/http://www-ksl.stanford.edu/software/jtp/\n\n\n## References\n\n- Fikes, Richard, Jessica Jenkins, and Gleb Frank. 2003. JTP: A System Architecture and Component Library for Hybrid Reasoning. Proceedings of the Seventh World Multiconference on Systemics, Cybernetics, and Informatics. Orlando, Florida.\n- https://www.daml.org/2002/03/tutorial/slide106-0.html\n","n":0.169}}},{"i":3005,"$":{"0":{"v":"Jsxc","n":1},"1":{"v":"\n- [[c.software.xmpp-client.web]]\n- repo: https://github.com/jsxc/jsxc\n- written-in: typescript","n":0.408}}},{"i":3006,"$":{"0":{"v":"JSX","n":1},"1":{"v":"\n- [[p.mentionedOn]] https://mdxjs.com/docs/getting-started/#jsx","n":0.577}}},{"i":3007,"$":{"0":{"v":"Jstor","n":1}}},{"i":3008,"$":{"0":{"v":"Jsrand","n":1},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/DomenicoDeFelice/jsrand\n- [[p.hasApplication]] [[t.cs.games.deterministic-lockstep]]","n":0.447}}},{"i":3009,"$":{"0":{"v":"Jsonpatch JS","n":0.707},"1":{"v":"\n- https://jsonpatchjs.com/\n- repo: https://github.com/dharmafly/jsonpatch.js\n- implements: [[prdct.json-patch]] [[prdct.json-pointer]]","n":0.378}}},{"i":3010,"$":{"0":{"v":"jsonld-streaming-parser.js","n":1},"1":{"v":"\n\n- [[c.software.semantic.library]]\n- repo: https://github.com/rubensworks/jsonld-streaming-parser.js\n- written_in: javascript\n- author: @ruben-taelman\n","n":0.354}}},{"i":3011,"$":{"0":{"v":"Jsonld.js","n":1},"1":{"v":"\n- https://github.com/digitalbazaar/jsonld.js","n":0.707}}},{"i":3012,"$":{"0":{"v":"Jsonary","n":1},"1":{"v":"\n- dead since 2015\n- https://github.com/jsonary-js/jsonary\n- similar: \n  - [[prdct.hydra]] (for json-ld)\n  - [[prdct.siren]] JSON Hyper-Schema is far superior due to its insane flexibility, its ability to keep things DRY and support for meta schemas","n":0.171}}},{"i":3013,"$":{"0":{"v":"Json5","n":1},"1":{"v":"\n## Features\n\n### Objects\n\n-   Object keys may be an ECMAScript 5.1 _[IdentifierName](https://www.ecma-international.org/ecma-262/5.1/#sec-7.6)_.\n-   Objects may have a single trailing comma.\n\n### Arrays\n\n-   Arrays may have a single trailing comma.\n\n### Strings\n\n-   Strings may be single quoted.\n-   Strings may span multiple lines by escaping new line characters.\n-   Strings may include character escapes.\n\n### Numbers\n\n-   Numbers may be hexadecimal.\n-   Numbers may have a leading or trailing decimal point.\n-   Numbers may be [IEEE 754](http://ieeexplore.ieee.org/servlet/opac?punumber=4610933) positive infinity, negative infinity, and NaN.\n-   Numbers may begin with an explicit plus sign.\n\n### Comments\n\n-   Single and multi-line comments are allowed.\n\n### White Space\n\n-   Additional white space characters are allowed.","n":0.103}}},{"i":3014,"$":{"0":{"v":"json-to-ast","n":1},"1":{"v":"\n- repo: https://github.com/vtrushin/json-to-ast\n- url: https://astexplorer.net/\n\n## Resources\n\n- https://stackoverflow.com/questions/68647885/how-to-parse-markdown-to-json-using-remark","n":0.378}}},{"i":3015,"$":{"0":{"v":"json-schema","n":1},"1":{"v":"\nurl: https://json-schema.org\n","n":0.707}}},{"i":3016,"$":{"0":{"v":"JSON Hyper-Schema","n":0.707},"1":{"v":"\n\n## Examples\n\nHere is an example hyper-schema that adds a single link, with the IANA-registered link relation type \"self\", that is built from an instance with one known object field named \"id\":\n\n```\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"id\": {\n            \"type\": \"number\",\n            \"readOnly\": true\n        }\n    },\n    \"links\": [\n        {\n            \"rel\": \"self\",\n            \"href\": \"thing/{id}\"\n        }\n    ]\n}\n                \n```\n\nIf the instance is {\"id\": 1234}, and its base URI according to [RFC 3986 section 5.1](https://json-schema.org/draft/2019-09/json-schema-hypermedia.html#RFC3986), is \"https://example.com/api/\", then \"https://example.com/api/thing/1234\" is the resulting link's target URI.","n":0.113}}},{"i":3017,"$":{"0":{"v":"Json Rules Engine","n":0.577},"1":{"v":"\n- repo: https://github.com/CacheControl/json-rules-engine/tree/master\n- [[c.software.rules-engine]]","n":0.5}}},{"i":3018,"$":{"0":{"v":"json-rql","n":1},"1":{"v":"\n- https://json-rql.org/\n- based-on: [[prdct.json-ld]]\n- related: [[prdct.m-ld]]\n\n## Description\n\n- a convention for expressing queries against structured resources, using JSON. It helps resolve the tensions between expressibility and simplicity, and between agility and future-proofing, in API design. It is based on JSON-LD.\n- It's [[prdct.json]]: straightforward to construct in code, manipulate and serialize, and also to constrain. Use standard JSON tooling such as JSON schema to limit your API to the queries that your back-end has been designed and tested for.\n- It's [[prdct.sparql]]: in context, all queries can be translated to the W3C standard language for directed, labeled graph data. This means that your API can be extended to cover future query requirements, without breaking changes.\n\n","n":0.094}}},{"i":3019,"$":{"0":{"v":"Json Rpc","n":0.707},"1":{"v":"\n- [[p.supports]] [[prdct.deno]] via https://deno.land/x/gentleRpc@v1.1\n\n## Resources\n\n## Resource List\n\n- https://github.com/shanejonas/awesome-json-rpc  ","n":0.333}}},{"i":3020,"$":{"0":{"v":"Json Pointer","n":0.707},"1":{"v":"\n- https://datatracker.ietf.org/doc/html/rfc6901","n":0.707}}},{"i":3021,"$":{"0":{"v":"Json Patcher","n":0.707},"1":{"v":"\n- built-on: [[prdct.jsonld-js]]","n":0.577}}},{"i":3022,"$":{"0":{"v":"Json Patch","n":0.707},"1":{"v":"\n- https://jsonpatch.com/\n\n## Implementations\n\n- [[prdct.jsonpatch-js]]","n":0.5}}},{"i":3023,"$":{"0":{"v":"JSON-NLP","n":1},"1":{"v":"\n\n- [[p.hasRelatedSolution]] [[prdct.jrml]]\n\n## Resources\n\n- https://blog.semiring.com/2020/08/20/2020-08-20-JSON-NLP-2-RDF-Mapping-Language-Specification/\n","n":0.447}}},{"i":3024,"$":{"0":{"v":"JSON-LD Patch","n":0.707},"1":{"v":"\n- dead\n- https://github.com/digitalbazaar/jsonld-patch","n":0.577}}},{"i":3025,"$":{"0":{"v":"Json-FG","n":1},"1":{"v":"\n- ","n":1}}},{"i":3026,"$":{"0":{"v":"Json Decision Model","n":0.577},"1":{"v":"\n- url: https://gorules.io/docs/rules-engine/json-decision-model\n- [[p.ownedBy]]","n":0.5}}},{"i":3027,"$":{"0":{"v":"JSON-AD","n":1},"1":{"v":"\n- similar: [[prdct.hextuples]]\n- use_case: Use JSON-AD if you don't have to support existing RDF data, but do value JSON compatibility and type safety.\n- creator: @joep-meindertsma\n- complementary: [[prdct.astro]]\n\n## Description\n\n[JSON-AD](https://docs.atomicdata.dev/core/json-ad.html) (JSON Atomic Data) only supports a strict subset of RDF, so it is an odd one in this list. In other words: it cannot be used to serialize all existing RDF data. However, because it allows only a strict subset, it also has a couple of advantages over other formats:\n\n-   Very **low parsing cost / high performance**. It can be parsed as plain JSON, which means that many efficient and performant parsers are available.\n-   **Easy to understand**. Since it supports only a subset of RDF, it doesn't suffer from some of the [quirks of RDF](https://docs.atomicdata.dev/interoperability/rdf.html) such as predicate-non-uniqueness\n-   It supports **native JSON arrays** as collections, which prevents the complexities of dealing with [ordered data in RDF](https://ontola.io/blog/ordered-data-in-rdf/). \n    -   t.2024.05.27.12 but if you can't represent ordered colelctions easily in RDF, it's not a strict subset\n-   **Type safety**. Each key in a JSON-AD object should resolve to a [Property](https://atomicdata.dev/classes/Property), which describes [datatype](https://atomicdata.dev/properties/datatype) and [description](https://atomicdata.dev/properties/description).\n\nHere's the `description` Property from above, serialized as JSON-AD:\n\n![](/assets/images/2024-06-10-15-12-38.png)\n\nBecause these properties also have [`shortnames`](https://atomicdata.dev/properties/shortname), we can easily [serialize Atomic Data to plain JSON](https://docs.atomicdata.dev/interoperability/json.html), without the long URLS:\n\n![](/assets/images/2024-06-10-15-10-34.png)\n\n## Issues\n\n- something about shortnames\n- Atomic only allows those who control a resource's subject URL endpoint to edit the data. This means that you can't add triples about something that you don't control.\n\n## References\n\n- https://ontola.io/blog/rdf-serialization-formats","n":0.065}}},{"i":3028,"$":{"0":{"v":"Jsog","n":1},"1":{"v":"\n- repo: https://github.com/jsog/jsog\n\n\n## Issues\n\n- \"when it de-serializes the objects, it just leaves them as type Object, and they lose their methods.\" [1]\n  - possible solution: [[prdct.esserializer]] [[prdct.typemanager-ts]]\n\n## References\n\n- [1]: https://stackoverflow.com/questions/71004835/serializing-an-object-in-typescript-with-methods-and-a-cyclical-reference-graph","n":0.183}}},{"i":3029,"$":{"0":{"v":"Jshell","n":1}}},{"i":3030,"$":{"0":{"v":"Jsf","n":1}}},{"i":3031,"$":{"0":{"v":"Jsdoc","n":1},"1":{"v":"\n\n## References\n\n- https://levelup.gitconnected.com/is-it-not-that-typescript-is-unaffordable-but-rather-that-jsdoc-has-a-better-cost-performance-4a933bb1e076","n":0.577}}},{"i":3032,"$":{"0":{"v":"jsActor","n":1},"1":{"v":"\n- #dead or close\n- [[c.software.web-framework]]\n- url: https://js.actor/\n- #demo https://js.actor/ams/\n- repo: https://github.com/jsactor/ams\n- [[p.builtOn]] [[prdct.hapi]]\n  \n## Thoughts\n\n- Actor is a class of objects representing GUI components.\n\n## Resources\n\n- https://medium.com/@js.actor/javascript-actor-and-event-message-management-system-b773c00d49f0","n":0.196}}},{"i":3033,"$":{"0":{"v":"JS Yaml","n":0.707}}},{"i":3034,"$":{"0":{"v":"JS-son","n":1},"1":{"v":"\n\n- [[c.software.agent-framework]]\n- url: https://github.com/TimKam/JS-son\n- author: @tim-kampik\n- written-in: javascript\n- [[p.hasApplication]] web apps, [[Jupyter notebooks|prdct.jupyter]], grid worlds, and serverless (Function-as-a-Service) environments.\n- [[p.hasRoadmapFeature]] \n  - [Integration with WoT Scripting API](https://github.com/TimKam/JS-son/issues/99)\n    - [[p.hasRelatedSolution]] [[prdct.wot-scripting-api]] [[prdct.thingweb]]\n\n## [[p.hasRelatedTopic]]\n\n- [[t.cs.agents.bdi]]\n- [[t.cs.agents]]","n":0.171}}},{"i":3035,"$":{"0":{"v":"js-simulator","n":1},"1":{"v":"\n\n\n- [[p.hasRepository]] https://github.com/chen0040/js-simulator\n- [[p.hasApplication]] [[t.cs.multi-agent-system]]\n- [[p.inspiredBy]] [[prdct.mason]]\n","n":0.378}}},{"i":3036,"$":{"0":{"v":"JS Sequence Diagrams","n":0.577},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- repo: https://bramp.github.io/js-sequence-diagrams/","n":0.5}}},{"i":3037,"$":{"0":{"v":"JS Joda","n":0.707},"1":{"v":"\nrepo: https://js-joda.github.io/js-joda/\n\n## Features\n\n- LocalDate allows you to handle dates without times (like birthdays or holidays) in a clean and error-safe way, especially if these dates are persisted to an external server.\n- [[t.cs.immutability]]\n\n![[prdct.luxon#^z5ldk0m6zjqx]]","n":0.177}}},{"i":3038,"$":{"0":{"v":"JS-Interpreter","n":1},"1":{"v":"\n- docs:  https://neil.fraser.name/software/JS-Interpreter/docs.html\n- [[p.hasRepository]] https://github.com/NeilFraser/JS-Interpreter","n":0.447}}},{"i":3039,"$":{"0":{"v":"Jrml","n":1}}},{"i":3040,"$":{"0":{"v":"Jref","n":1},"1":{"v":"\n- spec: https://github.com/hyperjump-io/browser/blob/main/lib/jref/SPECIFICATION.md\n\n## References\n\n- https://github.com/hyperjump-io/browser","n":0.447}}},{"i":3041,"$":{"0":{"v":"Jotai","n":1}}},{"i":3042,"$":{"0":{"v":"Joplin","n":1},"1":{"v":"\n- url: https://joplinapp.org/\n- ","n":0.577}}},{"i":3043,"$":{"0":{"v":"JointJS","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n- #commercial but has open-source too\n- pricing: $2,990 Per developer\n- demo: https://www.jointjs.com/demos\n \n## \n\n\n## Resources\n\n- https://www.jointjs.com/blog/svg-versus-canvas","n":0.243}}},{"i":3044,"$":{"0":{"v":"Jlink","n":1}}},{"i":3045,"$":{"0":{"v":"jkabi","n":1}}},{"i":3046,"$":{"0":{"v":"Jit.io","n":1},"1":{"v":"\n- https://www.jit.io/ \n- [[c.software.security]]\n\n## Support\n\n### Languages\n\n- Java, Javascript, TypeScript, Go, Rust, Python, Scala, C#, C, C++, Ruby, PHP, Kotlin, and Swift\n\n\n### Environments\n\n- GitHub (GitLab & Azure DevOps coming soon!), AWS, GCP, Azure, Slack, VS Code, Jira, Kubernetes, and Shortcut.","n":0.16}}},{"i":3047,"$":{"0":{"v":"Jint","n":1},"1":{"v":"\n\n\n- [[p.hasRepository]] https://github.com/sebastienros/jint\n- [[c.usecase]] [[t.cs.scripting]]\n  - resources:  https://pleasenophp.github.io/posts/using-real-javascript-with-unity.html#7-save-state\n    - \"Since your gameplay logic is going to be in JavaScript, all the state, like player parameters, inventory, quest states, etc, will be contained there.\"\n\n\n\n## References\n\n- https://www.reddit.com/r/csharp/comments/whkweb/netcompatible_scripting_languages_for_users_to/\n  - mentions: [[game.screeps]]","n":0.162}}},{"i":3048,"$":{"0":{"v":"Jiber","n":1},"1":{"v":"\n- repo: https://github.com/jacob-grahn/jiber","n":0.577}}},{"i":3049,"$":{"0":{"v":"JHipster","n":1},"1":{"v":"\n- url: https://www.jhipster.tech\n- repo: \n- support: [[prdct.vscode]] [[prdct.intellij]] [[prdct.eclipse]]\n\n## Con\n\n- focused on single-page apps\n- persistence is either SQL or mongo\n- supports [[prdct.kafka]] and [[prdct.pulsar]] for [[t.cs.sd.messaging.pubsub]], but no nats or memphis","n":0.18}}},{"i":3050,"$":{"0":{"v":"Online","n":1},"1":{"v":"\n- url: https://start.jhipster.tech/","n":0.577}}},{"i":3051,"$":{"0":{"v":"JHipster Domain Language (JDL)","n":0.5}}},{"i":3052,"$":{"0":{"v":"Studio","n":1},"1":{"v":"\n- url: https://start.jhipster.tech/jdl-studio/\n- ","n":0.577}}},{"i":3053,"$":{"0":{"v":"Jgroups","n":1},"1":{"v":"\n- [[c.Software.messaging.middleware]]\n- written_in: java\n- http://www.jgroups.org/\n- repo: https://github.com/belaban/JGroups\n\n## Features\n\n- Cluster creation and deletion. Cluster nodes can be spread across LANs or WANs\n- Joining and leaving of clusters\n- Membership detection and notification about joined/left/crashed cluster nodes\n- Detection and removal of crashed nodes\n- Sending and receiving of node-to-cluster messages (point-to-multipoint)\n- Sending and receiving of node-to-node messages (point-to-point)\n- ","n":0.136}}},{"i":3054,"$":{"0":{"v":"Jfact","n":1},"1":{"v":"\n- [[c.software.reasoner.tableau]]\n- repo: https://github.com/owlcs/jfact\n- related: [[prdct.fact++]]","n":0.408}}},{"i":3055,"$":{"0":{"v":"Jexl","n":1},"1":{"v":"\n- url: https://commons.apache.org/proper/commons-jexl/","n":0.577}}},{"i":3056,"$":{"0":{"v":"Jest","n":1},"1":{"v":"\nurl: https://jestjs.io/\n\n## [[p.supports]]\n\n- [[prdct.typescript]]\n- [[prdct.node]]\n- [[prdct.react]]\n- [[prdct.babel]]\n- [[prdct.vue]]\n- [[prdct.angular]]\n\n## [[p.hasFeature]]\n\n- snapshots","n":0.302}}},{"i":3057,"$":{"0":{"v":"Jess","n":1},"1":{"v":"\n- dead since 2018\n- [[c.Software.Rules-Engine]]\n- similar: [[prdct.jess]] [[prdct.clips]] [[prdct.easy-rules]] [[prdct.rule-book]] [[prdct.drools]] [[prdct.eclipse-constraint-logic-programming]] ^cmcaoqsy0ccx\n\n## Resources\n\n- https://www.manning.com/books/jess-in-action \n- https://synotix.home.xs4all.nl/robbieng/docs/jess43doc.html\n\n## References\n\n- https://www.baeldung.com/java-rule-engines and https://www.baeldung.com/java-rule-engine-jess-jsr-94\n- [[prdct.java.jsr.94]]","n":0.213}}},{"i":3058,"$":{"0":{"v":"Jess Rules Language","n":0.577}}},{"i":3059,"$":{"0":{"v":"Jena","n":1},"1":{"v":"\n- url https://jena.apache.org\n- [[c.software.database.graph.rdf]]\n- similar-to: [[prdct.rdf4j]]\n  - \"Jena is similar to RDF4J (formerly OpenRDF Sesame); though, unlike RDF4J, Jena provides support for OWL (Web Ontology Language). \"\n- related: [[prdct.jena-geo]] \n\n## Features\n\n- [GeoSPARQL](https://jena.apache.org/documentation/geosparql/) ^lfnls4qmhyho\n\n## Issues\n\n- chatgpt.4: \"while Jena can handle multiple inheritance in the RDF/OWL sense, translating this directly into Java classes can be challenging. You might need to design your Java class model differently, potentially using interfaces, composition, or other design patterns to represent the multiple inheritance found in the ontology.\"\n- only OWL-1 support, but [[prdct.ont-api]] has OWL2\n- \"Jena is standards-conforming and can apply RDFS/OWL reasoning, but does not scale very well to larger datasets.\"\n\n## Comparison\n\n![[prdct.rdf4j#rdf4j-vs-jena]]\n- [jena rules vs shacl](https://groups.google.com/g/topbraid-users/c/gHxbWnz1yuE/m/3ETPK7J4DQAJ)\n\n## Resources\n\n- https://medium.com/duda/simplifying-your-structured-data-model-using-apache-jena-545dd93236a8\n- [[ar.owl-profiles-rule-based-reasoning-and-handling-reasoning-with-the-jena-api]]\n- https://jena.apache.org/documentation/ontology/\n\n### Learning Resources\n\n- https://jena.apache.org/getting_started/\n- [[book.design-and-implementation-of-ontologies-in-java-and-apache-jena]]\n\n## References\n\n- https://stackoverflow.com/questions/76512856/getting-all-the-owl-classes-in-an-owl-rdf-schema-using-rdf4j","n":0.091}}},{"i":3060,"$":{"0":{"v":"Ng4j","n":1},"1":{"v":"\n- http://wbsg.informatik.uni-mannheim.de/bizer/ng4j/","n":0.707}}},{"i":3061,"$":{"0":{"v":"Fuseki","n":1},"1":{"v":"\n- related: [[prdct.jena]] [[prdct.sparql]]","n":0.5}}},{"i":3062,"$":{"0":{"v":"Jena Assembler","n":0.707},"1":{"v":"\n## Resources\n\n- url: https://jena.apache.org/documentation/assembler/assembler-howto.html","n":0.5}}},{"i":3063,"$":{"0":{"v":"jena-geo","n":1},"1":{"v":"\n- repo: https://github.com/i3mainz/jena-geo\n- similar: ![[prdct.jena#^lfnls4qmhyho]]","n":0.447}}},{"i":3064,"$":{"0":{"v":"Jekyll","n":1},"1":{"v":"\n- [[t.cs.web.static-site-generator]]\n- written_in: ruby","n":0.5}}},{"i":3065,"$":{"0":{"v":"jekyll-rdf","n":1},"1":{"v":"\n- [[c.software.semantic.publishing.site-generator]]\n- http://aksw.org/Projects/JekyllRDF\n- repo: https://github.com/AKSW/jekyll-rdf\n- built_on: [[prdct.jekyll]]\n- written-in: ruby\n\n## Features\n\n- allows for custom SPARQL queries to be embedded in the site templates.\n\n## Issues\n\n- seems to only support a single source file\n\n\n## References\n\n- [[ar.jekyll-rdf-template-based-linked-data-publication-with-minimized-effort-and-maximum-scalability]]","n":0.174}}},{"i":3066,"$":{"0":{"v":"JBang","n":1},"1":{"v":"\n- url: https://www.jbang.dev/\n- ","n":0.577}}},{"i":3067,"$":{"0":{"v":"JavaScript Entity Component System","n":0.5},"1":{"v":"\n- [[c.software.entity-component-system]]\n- #dead\n- repo: https://github.com/Stuhl/javascript-entity-component-system\n- ","n":0.447}}},{"i":3068,"$":{"0":{"v":"Jason","n":1},"1":{"v":"\n- repo: https://github.com/jason-lang/jason/\n- url: https://jason-lang.github.io/\n- related: [[prdct.agentspeak]] [[prdct.jason.c4]] [[prdct.code-mas2j]]\n- written_in: java\n- works_with: \n  - [[prdct.Jade]]\n\n## features:\n\n-   strong negation, so both closed-world assumption and open-world are available;\n-   handling of plan failures;\n-   speech-act based inter-agent communication (and belief annotations on information sources);\n-   annotations in beliefs used for meta-level information and annotations in plan labels that can be used by elaborate (e.g., decision-theoretic) selection functions;\n-   meta events, declarative goal annotations, higher order variables and treating plans as terms, imperative style commands in plan bodies, and various other language extensions;\n-   support for developing Environments (which are not normally to be programmed in AgentSpeak; in this case they are programmed in Java);\n-   support for MAS organisations and agents that reason about them, using the Moise+ model, and environments using CArtAgO - see the [JaCaMo website](https://jacamo-lang.github.io) for that;\n-   the possibility to run a multi-agent system distributed over a network (using [JADE](https://jade.tilab.com)); other distribution infrastructures can be added by the user;\n-   fully customisable (in Java) selection functions, trust functions, and overall agent architecture (perception, belief-revision, inter-agent communication, and acting);\n-   a library of essential “internal actions”;\n-   straightforward extensibility by user-defined internal actions, which are programmed in Java;\n-   various ways of developing and running code include IDEs and a “mind inspector” that helps debugging.\n-   \n\n## References\n\n- [[ar.programming-jade-and-jason-agents-based-on-social-relationships-using-a-uniform-approach]]\n","n":0.069}}},{"i":3069,"$":{"0":{"v":"C4 Jason","n":0.707},"1":{"v":"\n- related: [[prdct.jason]] [[prdct.cartago]]\n- docs: \n\n## References\n\n- https://apice.unibo.it/xwiki/bin/view/CARTAGO/C4Jason","n":0.354}}},{"i":3070,"$":{"0":{"v":"Jasmine","n":1},"1":{"v":"\n- url: https://jasmine.github.io/\n- written_in: javascript\n\n## [[p.hasLearningResource]]\n\n- https://learning.oreilly.com/library/view/practical-test-automation/9781484261415/\n- ","n":0.378}}},{"i":3071,"$":{"0":{"v":"JAS-mine","n":1},"1":{"v":"\n- [[c.Software.Simulation-Framework.discrete-event]]\n- url: https://www.microsimulation.ac.uk/jas-mine/\n- ","n":0.5}}},{"i":3072,"$":{"0":{"v":"Jargon","n":1},"1":{"v":"\n- [[c.software.tools.design.api]]\n- url: https://jargon.sh/","n":0.5}}},{"i":3073,"$":{"0":{"v":"JanusXR","n":1},"1":{"v":"- url: https://janusxr.org\n- ","n":0.577}}},{"i":3074,"$":{"0":{"v":"JanusGraph","n":1},"1":{"v":"\n- [[c.Software.Database.Graph.Property]]\n- repo: https://github.com/JanusGraph/janusgraph\n- written_in: java\n- \n\n## Features\n\n- supports multi-machine cluster. \n- transactional database that can support thousands of concurrent users, complex traversals, and analytic graph queries.\n\n## Resources\n\n- https://jointhegraph.github.io/articles/hosting-multiple-graphs-on-janusgraph/","n":0.186}}},{"i":3075,"$":{"0":{"v":"Janus WebRTC","n":0.707},"1":{"v":"\n- repo: https://github.com/meetecho/janus-gateway\n- [[p.hasSite]] https://janus.conf.meetecho.com/\n- [[p.differentFrom]] `prdct.janusgraph`\n- scripting-language-support: [[prdct.lua]] [[prdct.duktape]]/javascript\n- related: \n\n## Topics\n\n## Data Channels\n\n- The TextRoom plugin, as the very original name suggests, basically implements text-based messaging over data channels. More specifically, it allows you to create and/or join multiple “chatrooms” on the same data channel, and exchange public and/or private messages with the other participants. This all happens using a custom JSON-based protocol with a defined syntax for requests, responses/errors and events. It’s important to point out that this protocol is NOT the same as Janus API: it is a protocol that only makes sense to the plugin itself.\n  - Another interesting property this plugin has is its “forward externally” functionality. Very simply, when properly configured, this plugin can make sure that any message addressed to a specific room is forwarded to an external web server via HTTP. This can be useful for different use cases: e.g., for archiving purposes, where an external component tracks all exchanged messages; or as a simple and effective way of relaying commands from a browser to a non-WebRTC component (e.g., for IoT purposes). At the time of writing, though, there’s no way to go the opposite way, that is injecting external messages into a data channel only conversation.\n\n### Temporal Layer\n\nallows a video stream to be encoded at multiple resolutions and quality levels. The \"temporal layer\" in this context specifically deals with the temporal resolution of the video stream, meaning it relates to different frame rates included within the same video stream.\n\n\n## Demos\n\n### Data Layer\n\n- [distributed remote control for a Janus-based SocialTV application](https://youtu.be/QkjIIh0cqcM?t=211); in another I used them in a custom plugin to implement a [web-based terminal shell](https://youtu.be/d0zHiLkHDyY?t=2780); in yet another I chose them as a way to [send ARI commands to Asterisk via the Lua plugin](https://youtu.be/fOUiVBaZgnQ?t=2682).","n":0.058}}},{"i":3076,"$":{"0":{"v":"Audiobridge","n":1},"1":{"v":"\n## Use Cases\n\n- The plugin supports many features that allow it to be used in many more contexts than just basic audio conferencing, though. For instance, it supports the playback of static audio streams along actual participants, and allows for plain-RTP participants to join in the conversation as well (thus not limiting it to WebRTC only attendees). Most importantly, it allows for the real-time audio mix to be sent to an external component in real-time, which allows for many additional use cases (scalable distribution, live transcriptions, audio processing, etc.).\n\n## References\n\n- https://www.meetecho.com/blog/improving-the-audiobridge-plugin/","n":0.105}}},{"i":3077,"$":{"0":{"v":"Janus Project","n":0.707},"1":{"v":"\n- [[c.software.agent-framework]]\n- url: http://www.sarl.io/runtime/janus/\n- written-in: [[prdct.sarl]]","n":0.408}}},{"i":3078,"$":{"0":{"v":"Jamf Connect","n":0.707},"1":{"v":"\n## Jamf Connect Basic\n\n- synchronizes to [[prdct.azure.active-directory]] so better user experience\n  - sign in with Microsoft, \n- can support MFA rules\n- zero-touch enrollment\n- existing users would have a conversion process; mfa becomes an option\n- MFA only on full login (not screen lock/close)\n\n## Jamf Connect ZTNA\n\n- \"zero trust\" can replace legacy VPN system with per-app private micro tunnelling\n- real-time on-device security monitor\n- cross-platform windows, android, ios\n\n![](/assets/images/2023-02-08-10-40-41.png)\n","n":0.124}}},{"i":3079,"$":{"0":{"v":"Jaeger","n":1},"1":{"v":"\n- [[p.similarTo]] [[prdct.zipkin]]\n  - https://sematext.com/blog/jaeger-vs-zipkin-opentracing-distributed-tracers/","n":0.447}}},{"i":3080,"$":{"0":{"v":"Jackson","n":1},"1":{"v":"\n## Resources\n\n- https://www.baeldung.com/jackson\n- https://www.baeldung.com/jackson-object-mapper-tutorial\n- ","n":0.5}}},{"i":3081,"$":{"0":{"v":"Jackson JS","n":0.707},"1":{"v":"\n- dead: since 2020\n- ","n":0.5}}},{"i":3082,"$":{"0":{"v":"Jackal","n":1},"1":{"v":"\n- [[c.software.xmpp-server]]\n- repo: https://github.com/ortuman/jackal\n- written-in: #go","n":0.408}}},{"i":3083,"$":{"0":{"v":"Jack","n":1},"1":{"v":"\n- url: https://aosgrp.com.au/jack/\n- written-in: java","n":0.447}}},{"i":3084,"$":{"0":{"v":"JaCaMo","n":1},"1":{"v":"\n\n- [[c.software.agent-framework]]\n- https://jacamo-lang.github.io/\n- repo: https://sourceforge.net/projects/jacamo/\n- written-in: java\n- related: [[prdct.cartago]] [[prdct.jason]] [[t.cs.agents.multi-agent-oriented-programming]] [[prdct.moise]]\n- docs: https://github.com/jacamo-lang/jacamo/tree/main/doc\n\n## Summary\n\n- agents are programmed in Jason [2] using the AgentSpeak language; organisations are specified in Moise [3] in an XML-based document; and environments are coded in Java using the CArtAgO API\n\n\n![](/assets/images/2024-04-11-08-45-50.png)\n\nWe assume that roles cannot live autonomously: they exist in the system in view of the interaction. We follow the ontological model for roles proposed in [6], and brought inside the object-oriented paradigm in [4], which is characterized by three aspects: (1) Foundation: a role must always be associated with the institution it belongs to and with its player; (2) Definitional dependence: the definition of the role must be given inside the definition of the institution it belongs to; (3) Institutional empowerment: the actions defined for the role in the definition of the institution have access to the state of the institution and of the other roles, thus, they are called powers; instead, the actions that a player must offer for playing a role are called requirements. The agents that will be the role players become able to perform protocol actions, that are powers offered by a specific role and whose execution affect the social state. On the other hand, they need to satisfy the related requirements: specifically, in order to play a role an agent needs to have the capabilities of satisfying the related commitments – capabilities which can be internal of the agent or supplied as powers as well.\n\n## Resources\n\n- [Goal-Oriented Test-Driven Development](https://github.com/jacamo-lang/jacamo/blob/master/doc/tutorials/tdd/readme.adoc)\n- [[book.multi-agent-oriented-programming]]\n- [[ar.multi-agent-oriented-programming-the-ja-ca-mo-platform]]\n\n## References\n\n- [[ar.programming-jade-and-jason-agents-based-on-social-relationships-using-a-uniform-approach]]\n- https://github.com/JaCaMo-EASSS23/slides/blob/main/environment.pdf\n- [[ar.knowledge-level-integration-for-jacamo]]","n":0.063}}},{"i":3085,"$":{"0":{"v":"iWF","n":1},"1":{"v":"\n- [[c.Software.Workflow]]\n- repo: https://github.com/indeedeng/iwf\n- sdk-support: java, go, and python\n- messaging-support: [[prdct.nats]]\n\n## Features\n\n- Workflow As Code\n\n## vs Cadence/Temporal\n\n- The biggest argument of [[prdct.cadence]]/[[prdct.temporal]] over iWF is the “normal looking” of workflow code . Cadence/Temporal let user define a workflow as a single function/method while iWF require to split into different pieces (workflow states).\n\n## Cons\n\n- no c#\n\n## Resources\n\n- https://medium.com/@qlong/iwf-vs-other-general-purposed-workflow-engines-f8f3e3d8993d\n- https://medium.com/@qlong/saga-pattern-deep-dive-with-indeed-workflow-engine-b7e82c59e51f\n- https://community.temporal.io/t/a-letter-to-cadence-temporal-community/6809\n- https://www.reddit.com/r/golang/comments/15iy0su/workflow_as_code_microservice_orchestration/\n  - \"I used to self host Cadence/Temporal but not doing it anymore. I’m using Temporal cloud behind IWF. Their cloud service is amazing and price is very good for me. I would recommend it if you want to save the headache of maintaining a Temporal or cadence cluster. If you have to host Cadence or Temporal, I would recommend using managed Cassandra from other companies like InstaClustr or DataStax. Because Cassandra is not easy to operate in my experience. If you are running for a smaller load and don’t want to use managed Cassandra , then consider using MySQL or PostgreSQL which are easier to operate\"\n\n## References\n\n- https://github.com/indeedeng/iwf-java-sdk\n","n":0.077}}},{"i":3086,"$":{"0":{"v":"Ittyon","n":1},"1":{"v":"\n- dead since 2016\n- https://github.com/weavejester/ittyon\n- written-in: clojure\n\n## Description\n\n- simple library designed to manage state in games, particularly distributed state in a client/server architecture. It supports both Clojure and ClojureScript, so is particularly suitable for web-based games.\n- Ittyon draws inspiration from the entity component model, but provides a greater separation between code and data. Its data model has a lot in common with Datomic.","n":0.126}}},{"i":3087,"$":{"0":{"v":"itch.io","n":1},"1":{"v":"\n- url: https://itch.io/","n":0.577}}},{"i":3088,"$":{"0":{"v":"iStory","n":1},"1":{"v":"\n- https://www.novelmanga.com/index","n":0.707}}},{"i":3089,"$":{"0":{"v":"Isomorphic Git","n":0.707},"1":{"v":"\n\nhttps://github.com/isomorphic-git/isomorphic-git\n\n\n","n":1}}},{"i":3090,"$":{"0":{"v":"Iso8601","n":1}}},{"i":3091,"$":{"0":{"v":"ISO 15926","n":0.707},"1":{"v":"\n- http://rds.posccaesar.org/2008/07/OWL/ISO-15926-2_2003_annotations\n\n### Description\n\n- relies on a so-called 4D top-level ontology.\n  - \" it admits the existence of events (things that necessarily exist and develop in time) but not of objects as traditionally understood.\"\n\n\n### Workaround: The OWL List ontology[](https://rds.posccaesar.org/doc/background/iso15926-2_in_OWL//#workaround-the-owl-list-ontology)\n\nThe ISO 15926-2 OWL rendering imports the _OWL List_ ontology, which is no longer available from its original location at `www.co-ode.org`, and Protégé will display the following warning. Unless you have a local copy available, select “No”. The absence of OWL lists only affects the ISO 15926-2 entity types [MultidimensionalObject](http://rds.posccaesar.org/2008/02/OWL/ISO-15926-2_2003#MultidimensionalObject) and [ClassOfMultidimensionalObject](http://rds.posccaesar.org/2008/02/OWL/ISO-15926-2_2003#ClassOfMultidimensionalObject).\n\n\nA replacement for the OWL List ontology is available at [https://w3id.org/list](https://w3id.org/list), although with a different namespace (2015).\n\n## References\n\n- https://rds.posccaesar.org/doc/background/iso15926-2_in_OWL/\n- [[ar.some-open-issues-after-twenty-years-of-formal-ontology]]","n":0.096}}},{"i":3092,"$":{"0":{"v":"Isabelle Isar","n":0.707},"1":{"v":"\n## Features\n\n- In some ways, writing a proof in Isabelle/Isar is like writing a function in an interpreted programming language.\n- the computational realization of a formal ontology in Isabelle/HOL/Isar facilitates the explicit separation of three fundamental levels of ontology development: (I) the level of axiomatization; (II) the level of model instantiation; and (III) the level of theory presentation.","n":0.131}}},{"i":3093,"$":{"0":{"v":"isSemantic","n":1}}},{"i":3094,"$":{"0":{"v":"Ipld","n":1},"1":{"v":"\n- https://ipld.io/\n- uses: [[prdct.cid]]\n\n## Use Cases\n\n\n### Bitcoin to Git\n\nReference your latest commits in a git branch to a bitcoin transaction to timestamp your work. By linking your git commit, you can view the commit from your blockchain explorer.\n\n### Ethereum to IPFS\n\nHave your next contract refer to media on IPFS, perhaps modifying it and tracking its changes on each function execution. Seamlessly jump from function to object through IPLD addressing.\n","n":0.12}}},{"i":3095,"$":{"0":{"v":"InterPlanetary File System","n":0.577},"1":{"v":"\n\n- [[p.isRelated]] [[prdct.libp2p]]\n- [[p.solvesProblem]]\n  - [[t.cs.web.transport]]\n  - [[t.cs.web.identity]]\n  - [[t.cs.security]]\n  - [[t.cs.sd.messaging.pubsub]]\n  - [[t.cs.web.content-discovery]]\n","n":0.267}}},{"i":3096,"$":{"0":{"v":"Pubsub","n":1},"1":{"v":"\n- related: [[prdct.libp2p]]\n\n## References\n\n- https://www.reddit.com/r/ipfs/comments/utv9sh/pubsub_how_usable/","n":0.447}}},{"i":3097,"$":{"0":{"v":"Iper","n":1},"1":{"v":"\n- repo: https://github.com/fibo/iper\n- #dead\n","n":0.5}}},{"i":3098,"$":{"0":{"v":"Iota","n":1},"1":{"v":"\n- url: https://www.iota.org/\n- written-in: #rust\n\n## description: \n\n- When you send an IOTA transaction you validate two other transactions.","n":0.236}}},{"i":3099,"$":{"0":{"v":"iOS Press Content Library","n":0.5},"1":{"v":"\n- https://content.iospress.com\n- published_by: [[org.iospress]]","n":0.5}}},{"i":3100,"$":{"0":{"v":"IOGrid","n":1},"1":{"v":"\n[[c.software.game-engine]]\n\nrepo: https://github.com/jondubois/iogrid\n\n## [[p.builtOn]]\n\n- [[prdct.socketcluster]]\n- [[prdct.phaser]]","n":0.447}}},{"i":3101,"$":{"0":{"v":"Inweb","n":1},"1":{"v":"\n\n- https://github.com/ganelson/inweb\n- [[p.hasRelatedTopic]] [[t.cs.sd.literate-programming]]\n- [[p.provokedThoughts]]\n  - ","n":0.408}}},{"i":3102,"$":{"0":{"v":"Invenio","n":1},"1":{"v":"\n- https://invenio-software.org/\n- [[c.software.repository]]\n- requires: [[prdct.MySQL]] or [[prdct.Postgres]]\n\n## Similar\n\n- [[prdct.synapse-repository]]","n":0.333}}},{"i":3103,"$":{"0":{"v":"Invenio Framework","n":0.707},"1":{"v":"\n- https://invenio-software.org/products/framework/\n- repo: https://github.com/inveniosoftware/invenio\n- written-in: python\n\n## Features\n\n### Flexible data model\n\nUse JSON Schema to describe your articles, books, theses, photos, videos, research data and software. Write serialisers to produce BibTeX, CSL, DataCite, Dublin Core, JSON-LD, or MARCXML.\n\n### Powerful search engine\n\nFast search times for repositories of several million records. Configurable query language and search facets. Citation networks.\n\n### Advanced file management\n\nManage millions of files attached to records. Organise files in buckets. Configure any storage system/protocol.\n\n### Preservation friendly\n\nMint persistent identifiers (DOI) for repository assets. Create links between versions. Run fixity checks. Export BagIt archival packages.\n\n### User communities\n\nOrganise your documents in community collections. Set up advanced user authentication (OAuth, SSO). Define fine-grained access rights. Collect usage statistics.\n\n### REST API\n\nUse more than one hundred independent packages collaborating via rich REST APIs. Pick the packages you want and use the full power of Python to combine and extend them.\n","n":0.084}}},{"i":3104,"$":{"0":{"v":"Internet Computer","n":0.707},"1":{"v":"\n\n\n- prosecution by the SEC ?  \n","n":0.378}}},{"i":3105,"$":{"0":{"v":"Intercooler","n":1},"1":{"v":"\n- url: https://intercoolerjs.org/","n":0.577}}},{"i":3106,"$":{"0":{"v":"Intend Do","n":0.707},"1":{"v":"\n\n- [[c.software.task-and-goal-management]]\n\n## https://intend.do/philosophy\n\n","n":0.577}}},{"i":3107,"$":{"0":{"v":"IntelliJ","n":1}}},{"i":3108,"$":{"0":{"v":"Instagram","n":1}}},{"i":3109,"$":{"0":{"v":"Insomnia","n":1},"1":{"v":"\n- [[c.software.tools.design.api]]\n- url: https://insomnia.rest/\n- repo: https://github.com/Kong/insomnia\n- supports: [[t.cs.sd.rest]]  [[t.cs.web.soap]] [[prdct.grpc]] [[prdct.graphql]] [[prdct.server-sent-events]]\n\n## Resources","n":0.277}}},{"i":3110,"$":{"0":{"v":"Insight Maker","n":0.707},"1":{"v":"\nurl: https://insightmaker.com/\n\n- [[p.supports]] \n  - [[t.cs.agents.agent-based-modeling]]\n    - [[p.hasSource]] https://insightmaker.com/agentbased","n":0.333}}},{"i":3111,"$":{"0":{"v":"Inquirer","n":1},"1":{"v":"\n[[p.hasSite]] https://www.npmjs.com/package/inquirer\n\n## #features\n\n- tab-based autosuggest with [[prdct.inquirer-prompt-suggest]]\n  - [-] but it's not dynamic\n\n## [[p.hasLearningResource]]\n\n- [ ] https://levelup.gitconnected.com/create-your-own-advanced-cli-with-typescript-5868ae3df397","n":0.243}}},{"i":3112,"$":{"0":{"v":"Inquirer Prompt Suggest","n":0.577},"1":{"v":"\nrepo: https://github.com/olistic/inquirer-prompt-suggest\n","n":0.707}}},{"i":3113,"$":{"0":{"v":"Inngest","n":1},"1":{"v":"\n- https://www.inngest.com/\n- [[c.Software.Workflow]] \n- https://github.com/inngest/inngest\n- written-in: go, typescript\n\n## Pricing\n\n- Team: $50/mo for 100k steps, 100 concurrent functions\n\n## Features\n\n- Build simple linear workflows or complex DAG-based workflows with parallelism and fan-in out of the box. Leverage our step primitives for human-in-the-loop or paused functions which automatically resume based off of conditions being met.\n\n## Description\n\n### What is Inngest?\n\nSo events are great. They let you know what's happening. They provide audit trails when things happen. But event-driven systems can be difficult to build. And they're very difficult to audit and debug. Don't get us wrong: if you want to wrangle with Terraform, maybe set up Kafka (I have a soft spot for NATS), build your publishers, subscribers, service discovery, throttling, retries, backoff, and other stuff, it can be done. But it's not exactly \"move fast\", even if it is very much \"break things\". You also don't get webhook handling, integrating with external services, change management, or non-technical insight here for free either.\n\nWell, this is where we step in. Inngest provides you with a serverless event-driven platform and DAG-based serverless functions out of the box. Send us events - any and all of them from your own systems. Connect webhooks up to external systems. And then build out serverless functions that run in real-time whenever events are received. That's the short version.","n":0.068}}},{"i":3114,"$":{"0":{"v":"Inky","n":1},"1":{"v":"\n- url: https://github.com/inkle/inky\n- repo: https://github.com/inkle/inky","n":0.447}}},{"i":3115,"$":{"0":{"v":"Inkle","n":1}}},{"i":3116,"$":{"0":{"v":"Ink","n":1},"1":{"v":"\n- repo: https://github.com/inkle/ink\n\n## Resources\n\n- https://www.inklestudios.com/ink/web-tutorial/`","n":0.447}}},{"i":3117,"$":{"0":{"v":"Ink","n":1},"1":{"v":"\n- repo: https://github.com/vadimdemedes/ink","n":0.577}}},{"i":3118,"$":{"0":{"v":"Ink Interactive Scripting Language","n":0.5},"1":{"v":"\n- url: https://www.inklestudios.com/ink/\n- repo: https://github.com/inkle/ink\n- written_in: c#\n- related: [[prdct.inky]]\n\n## Examples\n\n- [[game.the-intercept]]","n":0.302}}},{"i":3119,"$":{"0":{"v":"Information Objects Ontology","n":0.577},"1":{"v":"\n- url: https://triplydb.com/odp/iolite\n\n## Description\n\nAn ontology of information objects, encodings and realizations, as a plugin to DOLCE-Ultralite (reusing mainly the `dul:expresses` and `dul:realizes` relations from it). Several patterns are contained inside this ontology:\n\n-   encodings of information entities\n-   kinds of realizations (gestural motions, depictions, digital, multimedia, speech, etc.)\n-   combinatorial relations between information objects\n-   relations between formal expressions and generalized expressions (lexicalizations, formalizations)\n-   relations between formal expressions and their assignments in formal semantics\n-   relations between information objects and schemata (data structures, KOS, etc.)\n-   authorship\n-   kinds of linguistic objects\n-   copies, reproductions, etc.\n-   cultural combination of information objects (reuse, mixing, metaphorical blending).","n":0.102}}},{"i":3120,"$":{"0":{"v":"Information Exchange Standard Ontology","n":0.5},"1":{"v":"\n- repo: https://github.com/dstl/IES4","n":0.577}}},{"i":3121,"$":{"0":{"v":"Information Artifact Ontology","n":0.577},"1":{"v":"\n- [[c.ontology]]\n- #aka IAO\n- repo: https://github.com/information-artifact-ontology/IAO\n- ","n":0.408}}},{"i":3122,"$":{"0":{"v":"Inform7","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.software.game-framework.interactivefiction]]\n- [[p.hasSite]] https://ganelson.github.io/inform/\n  - [[p.hasHighlight]]\n    - https://ganelson.github.io/inform/structure.html\n- [[p.hasRepository]] https://github.com/ganelson/inform\n- [[p.builtOn]] [[prdct.inweb]]\n- [[p.hasFeature]]\n  - [[t.cs.game.temporality]]\n    - [[p.hasLearningResource]] https://ganelson.github.io/inform-website/book/WI_9_1.html\n      - [[p.hasHighlight]]\n        - Inform keeps track of the time of day automatically: play ordinarily begins at 9 AM and each turn takes one minute. In some works of interactive fiction, time of day is crucial: in others, it is irrelevant or even, by a sort of tacit convention, non-existent. So Inform does nothing to act upon the time, or to reveal it to the player, without instruction. Nevertheless it is there.\n\n## Pros\n\n- \"creates an illusion of letting an English major write a script for an adventure game that reads like English that someone can play in what looks like a subset of English. It does it all with a very primitive production rules engine that relies heavily on defaults. Practical logic requires attention to rules and \"schemes\" (X macros, configuration settings on the rules engine.) I wrote an adventure game with a few rooms and objects in Drools and dreamt of making something like \"Inform 7 for business rules\".\"\n  - @paul-houle\n\n## References\n\n- [[ar.hackernews.semantic-web-is-like-the-guy-that-tells-everyone-that-he-is-an-asshole]]","n":0.074}}},{"i":3123,"$":{"0":{"v":"Infintegraph","n":1}}},{"i":3124,"$":{"0":{"v":"Infinitic","n":1},"1":{"v":"\n- [[c.Software.messaging.middleware]]\n- written-in: kotlin\n- supports: java\n- requires: \n  - [[prdct.pulsar]] \n  - [[prdct.redis]] or [[prdct.MySQL]]\n\n## similar\n\n- [[prdct.infinitic]]\n- [[prdct.catalyst]]\n- [[prdct.zeebe]]\n- [[prdct.temporal]]\n- [[prdct.conductor]]\n- [[prdct.kestra]]\n- [[prdct.iwf]] \n\n## Terms\n\n- **Services** primarily defined by their interfaces and are invoked using event-based RPC\n- **Tasks** a method within a service class. It can be anything from a database operation, an API call, to any complex action specific to your domain.\n- \n\n\n## Orchestration\n\n![[t.cs.sd.architecture.orchestration#^21ydosqb6dt1]]\n\n## References\n\n- [[ar.medium.the-way-we-are-building-event-driven-applications-is-misguided]]","n":0.122}}},{"i":3125,"$":{"0":{"v":"Infinite Reality","n":0.707},"1":{"v":"\n\n## @kevin-wang\n- \"more performant and cheaper than unity\"\n- goal: (initial use case) 3D e-commerce store. \n  - tools for drag and drop\n  - eventually: generate storefront from AI\n  - ","n":0.186}}},{"i":3126,"$":{"0":{"v":"Infinite Axis Utility System","n":0.5},"1":{"v":"\n- url: https://www.gameai.com/iaus.php\n\n## Resources\n\n- https://www.gameai.com/manuals/index.php/Main_Page\n- ","n":0.447}}},{"i":3127,"$":{"0":{"v":"IndexedDB","n":1},"1":{"v":"\n- [[p.usedBy]] [[prdct.yjs]]\n\n\n","n":0.577}}},{"i":3128,"$":{"0":{"v":"Ilograph","n":1},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- url: https://www.ilograph.com/\n\n## [[p.begsQuestion]]\n\n- Any way to expose to unlimited users for free?\n  - t.2024.05.08.16 yes, with desktop, \"Export diagrams to 100% self-contained HTML files that can be hosted anywhere.\"\n\n## Concrete vs Abstract models\n\n- Concrete diagramming models are bottom-up, fact-based models that prioritize hard information over generalizations.\n- Abstract resources are intangible and purely conceptual. Their very existence has an eye-of-the-beholder quality to it. From computing, abstract resources include things like services and domains. \n  - e.g. Order Service and User Service (rendered in green) are the abstract resources. These services exist only conceptually; they are nothing more than a convenient way of grouping APIs, Lambdas and database tables. Like concrete resources in the previous section, they can be used to demonstrate higher-level relations and interactions\n\n### Concrete modeling vs C4\n\n\n\n## References\n\n- https://www.ilograph.com/blog/posts/concrete-diagramming-models/","n":0.087}}},{"i":3129,"$":{"0":{"v":"IKW Graphengine","n":0.707},"1":{"v":"\n- repo: https://github.com/InKnowWorks/IKW-GraphEngine\n- based_on: [[prdct.guan]]\n\n## Related\n\n- [[prdct.basic-formal-ontology]]\n- [[prdct.relations-ontology]]","n":0.354}}},{"i":3130,"$":{"0":{"v":"Apache Ignite","n":0.707},"1":{"v":"\n- [[c.software.database.distributed]] [[c.software.data-framework]]","n":0.577}}},{"i":3131,"$":{"0":{"v":"IFM","n":1},"1":{"v":"\n- url: https://ifm.readthedocs.io/en/latest/intro.html#","n":0.577}}},{"i":3132,"$":{"0":{"v":"Ifla Functional Requirements for Bibliographic Records","n":0.408}}},{"i":3133,"$":{"0":{"v":"IEML","n":1},"1":{"v":"\n- https://intlekt.io/ieml/\n- creator: @pierre-levy\n\n## The Problem of Coding Linguistic Meaning\n\n- \"To understand the phrase « I choose the vegetarian menu », one must of course recognize that the verb is « to choose », the subject « I » and the object « the vegetarian menu » and know moreover that « vegetarian » qualifies « menu ». But one must also know the meaning of words and know, for example, that vegetarian differs from meaty, flexitarian and vegan, which implies going beyond the sentence to situate its components in systems of taxonomy and semantic oppositions, those of language as well as those of various practical fields.\"\n- \"each sentence in IEML is located at the intersection of a syntagmatic tree and paradigmatic matrices. In addition to a regular grammar, IEML relies on a dictionary of about 3000 words – without synonyms or homonyms – organized in a little more than a hundred paradigms.\"\n\n## The complexity of semantics\n\nWhen a sentence is pronounced, it makes sense on at least three levels (grammar, dialectics and rhetoric).\n\n-   Conceptualization: the mental representation prompted by its grammatical structure and the meaning of its words (a speech evoques a network of concepts)\n-   Veridiction: the logical plane of its reference to a state of things (a speech is true or false)\n-   Interaction: the practical plane of social interaction (a speech is a move in a language game).\n\n## Pragmatic Semantics   \n\n- the enunciation of a sentence is an act.\n\n## Referential semantics, or truthfulness\n\n- for an utterance to be capable of such a pragmatic meaning, it must also be capable of describing a reality, be it exact or inexact, serious or fictitious. \n- Like states of consciousness, propositions are intentional, that is: they point to a reference.\n- Referential semantics is more a matter of the exact sciences and logic and stands out against the background of an objective reality. Here, linguistic expressions describe and index the world of interlocutors and allow logical reasoning.\n\n## Linguistic semantics, or conceptualization\n\n- Just as pragmatic semantics has referential semantics as its condition of possibility, referential semantics in turn can only manifest itself on the basis of linguistic semantics.\n- The linguistic meaning of an expression comes from the words it is composed of and the meaning assigned to them in a dictionary. \n- It also comes from the grammatical roles that these words play in the sentence. \n- In sum, linguistic meaning emerges from the inter-definitional, suitability, similarity, and difference relations between words in the dictionary and the grammatical relations between words in the sentence.\n- IEML has been designed to solve the problem of coding the linguistic or conceptual meaning\n\n\n## Saussure’s Legacy and Structuralism\n\n- the signifieds are not self-sufficient atoms of meaning but correspond to positions in systems of differences: [paradigms](https://intlekt.io/ieml-paradigms/)\n- Hjemslev renamed the opposition between signifier and signified by describing two linguistic « planes »: that of expression (the signifier) and that of content (the signified). Each of the two planes is in turn analyzed in terms of matter and form. The matter of expression is in the range of sensible phenomena, for example visual images or sounds. In contrast, the forms of expression denote the abstract units that result from the distribution of signifiers in a given language.\n\n## Tesnière’s Legacy and Cognitive Linguistics\n\n- The linguistic architecture of mental models is obviously not exclusive of sensory-motor modes of representation, especially visual ones, which can relate to fictional worlds as well as to lived reality.\n- Since one of IEML’s missions is to serve as a formal modeling tool, it must not only organize a morphism between its semantics and its syntax, but also systematize and facilitate as much as possible the representation of processes, actors, circumstances and their interactions.\n- example of the actant model : « The verbal node (…) expresses a whole little drama. Like a drama it involves (…) a process and, most often, actors and circumstances. The verb expresses the process. (…) Actors are beings or things (…) participating in the process. (…) Adjuncts express the circumstances like time, place, manner, etc. »\n- IEML integrates the main lexical functions highlighted by Melchuk, making it easy to compose new words from dictionary elements and to formally explain the semantic relationships between lexical units.\n- IEML provides its speakers with the grammatical tools needed to describe scenes and tell stories.\n  - In addition, IEML enables the modeling of a specialized knowledge domain or a particular semantic field through the free elaboration of terminologies (radical paradigms) and frame sentences (sentence paradigms).\n\n## Austin, Wittgenstein and the Pragmatic Legacy\n\n- Language is an abstract structure that combines paradigms of words (indecomposable atoms of meaning) and rules for the composition of grammatical units (recursive sentences) from words. \n- In contrast, speech – or text – is a particular sequence of morphemes that actualizes the language system in space and time.\n- IEML terminologies and framework sentences belong to an intermediate category between language and speech.\n- Without a model of the world, action is meaningless and without immersion in some practical situation, representation loses all relevance.\n- Linguistic pragmatics refers to acts performed inside the language sphere but which have extra-linguistic consequences, such as baptizing, prohibiting, condemning, etc.\n  - Since they are performed in the language, these acts demonstrate a symbolic nature. \n  - They are governed by rules and carried out by « players » who assume certain roles.\n- A multitude of « language games », to use Wittgenstein’s expression, animate the pragmatic dimension opened up by the enunciation.\n- A language can itself be likened to a system of rules or a game.\n  - if a language L is philological, it is capable of defining a multitude of restricted languages (l1, l2, l3…), rule systems or games, all of which are distinct ways of using language L in practice.\n  - Since IEML is a philological language, we will use it not only to model any semantic field, represent scenes and tell stories, but also to explain language games whose rules, roles and moves we will formalize through terminologies and sentences paradigms.\n  - When they recognize the speech acts performed by IEML speakers, algorithms will be able to automatically trigger their extra-linguistic consequences, and to compute the new states of the current « matches »\n  - four main types of speech acts that are particularly relevant for IEML: \n    - reference\n    - reasoning, \n    - social communication\n    - instructions given to machines\n- The first function of enunciation is to refer to non-linguistic objects. One of its most obvious forms is the distribution of interlocutory roles: the first, second or third person indicates who is speaking, to whom and about what.\n- a simple text does not allow us to interpret [[t.ling.deictics]] such as « I », « this » or « tomorrow ». Only the event of an utterance by someone, in a defined spatio-temporal context of interlocution, can give them content.\n- This referential function of language is particularly important for IEML, which is designed to categorize datasets and therefore to index (or label) them. Both the distribution of interlocutory roles and the categorization of data can conform to many distinct reference games.\n- the operation of reference is a speech act, this act is part of a multitude of possible games, and these games can be made explicit in IEML.\n\n## An Image of the World or an Image of Oneself?\n\n- goal: a language of clarity, as unambiguous and translatable as possible\n- As for IEML’s relationship with extralinguistic reality, it is the result of a multitude of language games that encompasses the various ways of mapping out, recognizing and referring to relevant objects according to practical contexts\n- Our metalanguage clarifies the relations between signifieds and signifiers as well as the relations between signifieds to the point of being able to automate their processing. IEML’s main contribution is therefore at the level of linguistic semantics.\n- As for reference semantics – pointing to extra-linguistic realities – it can become more precise insofar as the different reference modalities are specified in IEML\n- Finally, the illocutionary force of enunciations, i.e. the « moves » that are played in a multitude of communication games, can be recognized by algorithms and processed accordingly, provided that the games in question have been previously described in IEML.\n\n","n":0.027}}},{"i":3134,"$":{"0":{"v":"Editor","n":1},"1":{"v":"\n- https://ieml.intlekt.io","n":0.707}}},{"i":3135,"$":{"0":{"v":"IdGen","n":1},"1":{"v":"\n- repo: https://github.com/RobThree/IdGen\n\n![[prdct.newid#similar]]\n\n## Features\n\n- using the IdStructure class you can tune the structure of the created Id's to your own needs; you can use 45 bits for the timestamp, 2 bits for the generator-id and 16 bits for the sequence if you prefer. As long as all 3 parts (timestamp, generator and sequence) add up to 63 bits you're good to go!","n":0.127}}},{"i":3136,"$":{"0":{"v":"Identitas","n":1},"1":{"v":"\n## supported-by\n\n- [[prdct.protege]]\n- [[prdct.tawny-owl]]","n":0.5}}},{"i":3137,"$":{"0":{"v":"Icewind Dale: Rime of the Frostmaiden","n":0.408},"1":{"v":"\n- [[c.Work.superwork]] [[superwork]]","n":0.577}}},{"i":3138,"$":{"0":{"v":"IcePanel","n":1},"1":{"v":"\n- url: https://icepanel.io/\n- [[p.supports]] [[t.cs.sd.c4-model]]\n- [[p.similarTo]] \n- [[c.software.tools.diagramming]] [[c.software.tools.modeling]]\n\n## Features\n\n- visualize events moving through the system #cool\n- export to json","n":0.224}}},{"i":3139,"$":{"0":{"v":"Ice","n":1},"1":{"v":"\n- repo: https://github.com/zeroc-ice\n- url: https://doc.zeroc.com/ice/\n- #summary takes care of all interactions with low-level network programming interfaces. With Ice, there is no need to worry about details such as opening network connections, serializing and deserializing data for network transmission, or retrying failed connection attempts.","n":0.152}}},{"i":3140,"$":{"0":{"v":"Ice Storm","n":0.707},"1":{"v":"\n- url: ","n":0.707}}},{"i":3141,"$":{"0":{"v":"Hypothes.is","n":1},"1":{"v":"\n\n\nAnnotate the web, with anyone, anywhere.\n\n","n":0.408}}},{"i":3142,"$":{"0":{"v":"Hyperx","n":1},"1":{"v":"\n- repo: https://github.com/jinhuang/hyperx\n- ","n":0.577}}},{"i":3143,"$":{"0":{"v":"Hyperview","n":1},"1":{"v":"\n- https://hyperview.org","n":0.707}}},{"i":3144,"$":{"0":{"v":"Hypertext Application Language","n":0.577},"1":{"v":"\n- https://en.wikipedia.org/wiki/Hypertext_Application_Language\n- similar: [[prdct.hypertext-application-language]] [[prdct.json-ld-patch]] [[prdct.hydra]] [[prdct.siren]] ^iqangmreu94i\n\n","n":0.354}}},{"i":3145,"$":{"0":{"v":"Hyperquery","n":1},"1":{"v":"\n- url: https://www.hyperquery.ai\n- [[c.pricing]] free for individuals","n":0.378}}},{"i":3146,"$":{"0":{"v":"HyperNetX","n":1},"1":{"v":"\n- written-in: #python\n- [[p.supports]] hypergraph creation, hypergraph-\nconnected component computation, sub-hypergraph construction, hypergraph statistics computation (e.g., node degree distribution, edge size distribution, toplex size computation for hypergraphs), and hypergraph visualization","n":0.186}}},{"i":3147,"$":{"0":{"v":"Hypermedia Todo API","n":0.577},"1":{"v":"\n- http://json-browser.s3-website-us-west-1.amazonaws.com/?url=http%3A//hypermedia-todo.herokuapp.com/\n- repo: https://github.com/jdesrosiers/todo-api\n- uses: [[prdct.jsonary]] [[prdct.hyperjump-browser]] [[prdct.resourceful]]\n- written-in: php","n":0.316}}},{"i":3148,"$":{"0":{"v":"Hypermedia Multi Agent Systems Ontology","n":0.447},"1":{"v":"\n- https://ci.mines-stetienne.fr/hmas/core\n- repo: https://github.com/HyperAgents/hmas","n":0.5}}},{"i":3149,"$":{"0":{"v":"Hypermedia Multi-Agent Systems  Interaction Ontology","n":0.447},"1":{"v":"\n- https://ci.mines-stetienne.fr/hmas/interaction\n\n\n\n## Classes\n\n- action execution: A behavior execution that is the execution of exactly one context-free action, e.g. of a context-free HTTP request.\n- behavior execution: A course of action performed by an agent upon exploiting a behavior possibility.\n\n## Object Properties\n\n- has input: A relation between an action execution and the input that it has.\n- signifies: A relation between a signifier and the specification of a behavior execution. For instance, a SHACL shape can be used to specify an expected behavior execution.\n\n","n":0.111}}},{"i":3150,"$":{"0":{"v":"Hypermedia Multi-Agent Systems Core Ontology","n":0.447},"1":{"v":"\n- https://ci.mines-stetienne.fr/hmas/core\n- related: [[prdct.hypermedia-multi-agent-systems-ontology.interaction]]","n":0.5}}},{"i":3151,"$":{"0":{"v":"Hyperledger","n":1},"1":{"v":"\n- url: https://www.hyperledger.org/\n-","n":0.577}}},{"i":3152,"$":{"0":{"v":"Hyperjump Browser","n":0.707},"1":{"v":"\n- https://github.com/hyperjump-io/browser\n- written-in: typescript\n- uses: [[prdct.jref]]","n":0.408}}},{"i":3153,"$":{"0":{"v":"Hypergraphdb","n":1},"1":{"v":"\n- dead\n- [[p.hasAuthor]] @boris-iordanov\n- [[c.software.database.graph.hypergraph]]\n\n## Resources\n\n- https://blog.vaticle.com/meet-the-team-boris-iordanov-6a30a949cdab","n":0.378}}},{"i":3154,"$":{"0":{"v":"Hyperfiddle","n":1},"1":{"v":"\n- url: https://www.hyperfiddle.net/\n- written-in: #clojure\n- repo: https://github.com/hyperfiddle/electric","n":0.378}}},{"i":3155,"$":{"0":{"v":"Hyperagents","n":1}}},{"i":3156,"$":{"0":{"v":"Hydra","n":1},"1":{"v":"\n\n- https://www.hydra-cg.com/\n- [[c.specification.api-description]]\n\n## Similar\n\n- [[prdct.hydra]] [[prdct.HAL]] [[prdct.siren]] [[prdct.json.hyper-schema]]\n\n## Solutions\n\n- [[prdct.creta]]\n\n## Vision\n\nCurrent APIs heavily rely on out-of-band information such as human-readable documentation and API-specific SDKs. However, this only allows for very simple and brittle clients that are hardcoded against specific APIs. Hydra, in contrast, is a set of technologies that allow to design APIs in a different manner, in a way that enables smarter clients.\n\n## Details\n\n- \"Hydra consists of two key parts. There’s the all-important vocabulary mentioned above — known as the Hydra Core Vocabulary — but there’s also a format for referencing linked data (usually JSON-LD), also known as an RDF serialization format.\"\n  - \"as long as the consumer is familiar with the vocabulary being used, they can independently determine the meaning of a key-value pair without the need for external documentation.\"\n\n## The Problem\n\n\nThe meaning of json attributes in api responses, their possible values etc. is usually not obvious without referring to some information coming from outside the resource itself. That is due to the nature of json. Two solutions immediately come to mind. Both are ways of vendor-specific documentation, some are machine-readable, some aren’t.\n\nDescribe the type in some sort of json-schema, wadl, raml, swagger or similar and publish it together with the resource. People could even generate classes from this information, if they wish to. My api users coming from a wsdl background scream for something like that.\n\nOr put up documentation pages to describe your ex:doodad extension relation types and make the documentation available by dereferencing http://example.com/api/rels#doodad.\n\nBut one of the rules for a ReSTful API is:\n\n> A REST API should never have “typed” resources that are significant to the client. Specification authors may use resource types for describing server implementation behind the interface, but those types must be irrelevant and invisible to the client. The only types that are significant to a client are the current representation’s media type and standardized relation names. \\[Failure here implies that clients are assuming a resource structure due to out-of band information, such as a domain-specific standard, which is the data-oriented equivalent to RPC’s functional coupling\\].\n\n— Roy Fielding\n\nMy interpretation of this famous [rant by Roy Fielding](http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven):\n\nA publicly available media-type should give clients all necessary means to interpret a server response, and relation names for hyperlinks in the response must be recognizable based on public conventions, so that the client can act upon the responses it receives without knowing the details of a vendor-specific api.\n\nIn other words: If a client is told to make a reservation for a concert ticket, it should be able to recognize what one-fancy-api requires to achieve that without processing a vendor-specific documentation. How can we do that, purely based on a media type and relation names? Do we need hundreds of iana registered media types for all kinds of purposes?\n\n## Solution (evolving)\n\nI see [json-ld](http://www.w3.org/TR/json-ld/) (media type application/ld+json) as a possible way to solve this problem without forcing people to ask me about my vendor-specific documentation, thus decoupling the clients from my server types.\n\nClients should be able to understand a response based on widely available, standardized, public information.\n\nThe json-ld mediatype allows to bring descriptions of things in the real world from public vocabularies into your json files. With json-ld there **is** a way to say that a json response describes a [MusicEvent](http://schema.org/MusicEvent) which [offers](http://schema.org/offers) a [Ticket](http://schema.org/Ticket) without any vendor-specific documentation, and it can also link to other resources.\n\nA popular vocabulary which describes things on the internet is [http://schema.org](http://schema.org). It is used by all major search engines for search engine optimization and sufficient for basic needs. It also integrates with other vocabularies, e.g. by using [additionalType](http://schema.org/additionalType) to point to [GoodRelations](http://purl.org/goodrelations/) classes or by using external enumerated values as shown by [DeliveryMethod](http://schema.org/DeliveryMethod).\n\n(For those of you about to say that the Semantic Web never took off, please note that json-ld is [not about the Semantic Web at all](http://manu.sporny.org/2014/json-ld-origins-2/)).\n\n[Hydra](http://www.hydra-cg.com/) adds interaction to the mix. It describes exactly how to post a ticket reservation.\n\nSo I want to add json-ld information to json objects serialized from my Java beans.\n\nJava beans have no knowledge about the meaning of their bean properties and they do not know what they represent in the real world.\n\nIn the simplest possible case I want to design my json objects so that they can be understood by others based on schema.org. By simply calling my json transfer class `Person` and letting it have an attribute `name`, I want to get a publicly understandable json object\n\n## Demonstration\n\n- https://www.markus-lanthaler.com/hydra/console/?url=http://www.markus-lanthaler.com/hydra/api-demo/\n  - t.2024.04.15.16 api-demo is broken and the console always returns 403s\n\n\n## Solutions\n\n- [[prdct.hydra-java]]\n\n## Resource\n\n- [Bringing Hypermedia to the Masses](https://www.youtube.com/watch?v=F3Z6qye3LrE&feature=youtu.be)\n- https://www.w3.org/community/hydra/wiki/Restbucks_with_Hydra #cool\n\n## References\n\n- https://nordicapis.com/hydra-for-hypermedia-apis-benefits-components-and-examples/\n- https://sookocheff.com/post/api/on-choosing-a-hypermedia-format/\n- [[ar.third-generation-web-apis-bridging-the-gap-between-rest-and-linked-data]]\n- https://www.markus-lanthaler.com/hydra/\n","n":0.036}}},{"i":3157,"$":{"0":{"v":"hydra-java","n":1},"1":{"v":"\n- repo: https://github.com/dschulten/hydra-java\n\n","n":0.577}}},{"i":3158,"$":{"0":{"v":"Hugegraph","n":1},"1":{"v":"\n- url: https://hugegraph.apache.org/\n- ","n":0.577}}},{"i":3159,"$":{"0":{"v":"Hubs","n":1},"1":{"v":"\n- [[c.software.metaverse-platform]] [[c.software.virtual-reality]]\n- url:  https://hubs.mozilla.com/\n- repo: https://github.com/mozilla/hubs\n- #docs https://hubs.mozilla.com/docs/welcome.html\n- [[p.publishedBy]] [[org.mozilla]]\n- [[p.supportedBy]] [[prdct.spoke]]\n\n- written-in: javascript typescript\n- [[p.builtOn]] [[prdct.a-frame]] [[prdct.janus]] [[prdct.reticulum]]","n":0.224}}},{"i":3160,"$":{"0":{"v":"Htmx","n":1},"1":{"v":"```yaml\nurl: https://htmx.org/\nsucceeded: [[prdct.intercooler]]\nsimilar: \n  - [[prdct.hotwire]]\n```\n- repo: https://github.com/reggi/htmx-components\n\n## Pros\n\n### you could host on github pages, in a limited way:\n\nThere's nothing special about the HTTP requests that HTMX makes. So you can have it request resources hosted on GH pages, but those can't change based on previous Interactions, they are static.\n\nWhich means you could either fake a backend for demonstration purposes or you could have preplanned interactions, like in Choose Your Own Adventure books.\n\n#### get directions from a queue\n\n- choose your own adventure, but the event hub tells you where to go. new files can be uploaded for just-in-time scenario generation\n- \n\n## Cons\n\n- https://kentondejong.medium.com/sorry-im-not-diggin-htmx-cc28df862910 mentions a bunch of stuff, just being picky I think. \n\n\n\n## Resources\n\n- https://blog.yusu.ke/hono-htmx-cloudflare/\n- https://www.reddit.com/r/htmx/comments/16rp3kj/is_it_really_worth_transitioning_from_react_to/\n- https://www.kodaps.dev/en/blog/htmx-anti-javascript-framework\n- https://medium.com/@hhartleyjs/making-a-dashboard-with-htmx-go-50820d7ddedb (go)\n- https://blog.stackademic.com/my-honest-opinion-after-writing-a-small-project-using-go-templ-and-htmx-7b9acf302834\n- [baseline 11ty site that provides the flexibility for expansion, incorporating elements like HTMX for dynamic content and preparing for integrations with data visualization tools like Grafana and Dash](https://git.crazystorm.xyz/medusa/Projects/src/branch/main/11ty) with [[prdct.eleventy]]\n- [[book.hypermedia-system]]\n\n## References\n\n- https://www.reddit.com/r/htmx/comments/12rs2d0/can_someone_point_me_to_a_good_tutorial_on_htmx/ \n- https://www.reddit.com/r/htmx/comments/19c4q10/is_there_any_way_to_set_up_htmx_with_github_pages/","n":0.08}}},{"i":3161,"$":{"0":{"v":"Hqdm Framework","n":0.707},"1":{"v":"\n- related: [[prdct.magmacore]]","n":0.577}}},{"i":3162,"$":{"0":{"v":"Hozo","n":1},"1":{"v":"\n- [[c.software.semantic.ontology-editor]]\n- url: https://www.hozo.jp/\n\n## Advantages\n\n![[sh.question-log.2024.07.05#advantages-of-hozo]]\n\n## Resources\n\n- [[ar.dynamic-is-a-hierarchy-generation-for-user-centric-semantic-web]]\n","n":0.378}}},{"i":3163,"$":{"0":{"v":"Houdini","n":1},"1":{"v":"\nurl: https://www.sidefx.com/products/houdini/\n","n":0.707}}},{"i":3164,"$":{"0":{"v":"Hotwire","n":1},"1":{"v":"\n- url: https://hotwired.dev/\n- related: [[prdct.stimulus]]\n- similar: [[prdct.htmx]]\n- \n\n## Description\n\n- ' if you believe that simplicity beats the “sexy\" complexity introduced by heavy JS frameworks like React, Vue, Angular, etc; if you’re a single developer/small team wanting to productively churn out simple, easy to understand code that doesn’t require a bunch of extra build steps; if you buy into philosophies like the idea behind Tailwind CSS, Alpine.js and yes some parts of Hotwire (especially the “html over the wire” part), then I suggest you at least try out htmx before you make a decision.'\n\n## Comparisons\n\n### vs [[prdct.htmx]]\n\n- https://discuss.hotwired.dev/t/hotwire-vs-htmx-comparison/1614\n  - \n\n```yaml\nurl: \n```","n":0.1}}},{"i":3165,"$":{"0":{"v":"Hoon","n":1},"1":{"v":"\n## Resources\n\n- https://developers.urbit.org/reference/hoon/overview","n":0.577}}},{"i":3166,"$":{"0":{"v":"Hono","n":1},"1":{"v":"\n- [[c.software.web.api-framework]]\n- url: https://hono.dev/\n- repo: https://github.com/honojs\n- similar-to: [[prdct.express]] [[prdct.actionhero]]\n- supports: [[prdct.deno]]\n\n## Resources\n\n- https://blog.yusu.ke/hono-ai-ready/","n":0.277}}},{"i":3167,"$":{"0":{"v":"Holochain","n":1},"1":{"v":"\n\n\n- written-in: #rust\n- [[p.hasFeature]] end-to-end framework for peer-to-peer apps uses counter-signing and gossip for data validation and provenance in place of consensus mechanisms\n- [[p.similarTo]] [[prdct.internet-computer]]\n- [[p.hasLearningResource]] \n  - https://developer.holochain.org/\n  - https://www.youtube.com/holochain\n","n":0.18}}},{"i":3168,"$":{"0":{"v":"HOL","n":1},"1":{"v":"\n- related: [[prdct.isabelle-isar]]","n":0.577}}},{"i":3169,"$":{"0":{"v":"Hode","n":1}}},{"i":3170,"$":{"0":{"v":"Rslt","n":1}}},{"i":3171,"$":{"0":{"v":"Hmas Ontology","n":0.707},"1":{"v":"\n## References\n\n- [[ar.engineering-world-wide-multi-agent-systems-with-hypermedia]]","n":0.577}}},{"i":3172,"$":{"0":{"v":"Hjson","n":1},"1":{"v":"\n- https://github.com/hjson/hjson\n\n\n## Implementations\n\n-   Python — [hjson-py](https://github.com/hjson/hjson-py)\n-   Javascript, NodeJS & Browser — [hjson-js](https://github.com/hjson/hjson-js)\n-   C#, .NET — [hjson-cs](https://github.com/hjson/hjson-cs)\n-   C++ — [hjson-cpp](https://github.com/hjson/hjson-cpp)\n-   Java — [hjson-java](https://github.com/hjson/hjson-java)\n-   Go — [hjson-go](https://github.com/hjson/hjson-go)\n-   PHP — [hjson-php](https://github.com/hjson/hjson-php)\n-   Lua — [hjson-lua](https://github.com/hjson/hjson-lua)\n-   Rust — [hjson-rust](https://github.com/hjson/hjson-rust)\n\n## References\n\n- https://medium.datadriveninvestor.com/yes-i-found-something-better-than-json-c7190f50f4d5","n":0.167}}},{"i":3173,"$":{"0":{"v":"Hivemq","n":1},"1":{"v":"\n- url: https://www.hivemq.com\n- repo: https://github.com/hivemq/hivemq-community-edition","n":0.447}}},{"i":3174,"$":{"0":{"v":"Hidden Door","n":0.707},"1":{"v":"\n\n## Platform\n\n- Our server architecture is substantially written in Python to support our machine learning systems (e.g. spaCy, PyTorch, Hugging Face).","n":0.218}}},{"i":3175,"$":{"0":{"v":"Hiccup","n":1},"1":{"v":"\n- repo: https://github.com/weavejester/hiccup\n- description: uses vectors to represent elements, and maps to represent an element's attributes.\n- \n\n\n## References\n\n","n":0.236}}},{"i":3176,"$":{"0":{"v":"HexTuples","n":1},"1":{"v":"\n- similar: [[prdct.thrift.rdf-binary]]\n- based-on: [[prdct.ndjson]]\n\n## Description\n\nHexTuples is an NDJSON (Newline Delimited JSON) based RDF serialization format. It is designed to achieve the best possible performance in a JS context (i.e. the browser). It uses plain JSON arrays, in which the position of the items denote subject, predicate, object, datatype, lang and graph.\n\n[\"https://www.w3.org/People/Berners-Lee/\", \"http://schema.org/birthDate\", \"1955-06-08\", \"http://www.w3.org/2001/XMLSchema#date\", \"\", \"\"]\n[\"https://www.w3.org/People/Berners-Lee/\", \"http://schema.org/birthPlace\", \"http://dbpedia.org/resource/London\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#namedNode\", \"\", \"\"]\n\nHexTuples is designed by Thom van Kalkeren (a colleague of mine) because he noticed that parsing / serialization was unnecessarily costly in our stack, even when using the relatively performant n-quads format. Since HexTuples is serialized in NDJSON, it benefits from the highly optimized JSON parsers in browsers. It uses NDJSON instead of regular JSON because it makes it easier to parse concatenated responses (multiple root objects in one document). As an added plus, this enables streaming parsing as well, which gives it another performance boost. Our JS RDF libraries (link-lib, link-redux) have an internal RDF graph model which uses these arrays as well, which means that there is minimal mapping cost when parsing Hex-Tuple statements. This format is especially suitable for real front-end applications that use dynamic RDF data.\n\n## References\n\n- https://ontola.io/blog/rdf-serialization-formats","n":0.072}}},{"i":3177,"$":{"0":{"v":"Hexbin","n":1}}},{"i":3178,"$":{"0":{"v":"HETS","n":1},"1":{"v":"\n- http://hets.eu/\n\n## Resources\n\n- https://github.com/spechub/Hets/blob/master/doc/UserGuide.pdf","n":0.5}}},{"i":3179,"$":{"0":{"v":"Hermit","n":1},"1":{"v":"\n- [[c.software.reasoner]] [[c.software.reasoner.tableau]]\n- [[p.supports]] [[prdct.owl]]\n- #license [[lic.lgpl]]\n- [[p.used]] [[prdct.dk-brics-automaton]]","n":0.333}}},{"i":3180,"$":{"0":{"v":"Here Be Taverns","n":0.577},"1":{"v":"\n- [[c.software.rpg]]\n- url: https://www.herebetaverns.com\n- [[p.won]] [[t.roleplaying.award.ennie]]\n- #related [[prdct.sword-and-source]]\n\n## [[c.model.licensing]]\n\n- https://github.com/CompVis/stable-diffusion/blob/main/LICENSE","n":0.316}}},{"i":3181,"$":{"0":{"v":"Hello Worlds","n":0.707},"1":{"v":"\n- [[p.hasAuthor]] @kenny-wtf\n- [[p.hasLearningResource]] https://worlds.kenny.wtf/docs\n- [[p.isRelated]] [[Firmament|game.firmament]]","n":0.378}}},{"i":3182,"$":{"0":{"v":"Helix","n":1},"1":{"v":"\n- https://nunchi.studio/helix\n- [[c.software.framework]]\n- ","n":0.577}}},{"i":3183,"$":{"0":{"v":"Helidon","n":1},"1":{"v":"\n- [[c.software.microservice-frameworks]]\n- url: https://helidon.io/\n- repo: https://github.com/helidon-io/helidon\n- similar-to: [[prdct.micronaut]]\n\n\n## Resources\n\n- https://www.baeldung.com/microservices-oracle-helidon","n":0.316}}},{"i":3184,"$":{"0":{"v":"Hedgedoc","n":1},"1":{"v":"\n- https://hedgedoc.org/\n\n## Issues\n\n### No Git Support in HedgeDoc\n\n- \"Let's say we have a sentence \"The sky is blue\" and now, 2 people work on this document. A adds \"Today\" at the beginning, and the other adds \"like the sea\" at the end.\n\nHow are we supposed to represent this in git? Making a commit for each of them? That would result in hundreds of commits within a few minutes for 2 or 3 people working on a document, and none of them would make sense. Also what to put there as a commit message?\n\nOr should we record the changes of each user for 5 minutes and then make a commit? That doesn't work. Git would break in a merge conflict here, which is not properly resolvable. Well, might by using some force towards the final document we already recorded in CodiMD? Maybe, but I foresee a lot of trouble.\n\nSo far, I consider real-time collaboration using OT and git diffs as not workable together. Exports and imports, yes. As real backend for the document storage, no.\n\nNot to mention the problem of \"how do organize this repository-wise?\". One repository per user? One repository per document? One repository per instance? Or do we introduce collections first, which are repositories which then hold the documents? Are they read-only or do we let other people push things there? How do we merge those pushes with the real-time editing?\n\nGit is simply not made for real-time collaboration. And CodiMD is exactly that in first place: A real-time-collaboration tool for markdown.\"\n\n\n## References\n\n- https://github.com/hedgedoc/hedgedoc/issues/222\n","n":0.063}}},{"i":3185,"$":{"0":{"v":"HDT","n":1},"1":{"v":"\n- https://www.rdfhdt.org/","n":0.707}}},{"i":3186,"$":{"0":{"v":"Hazel Engine","n":0.707},"1":{"v":"\n- url: https://hazelengine.com/\n- uses: [[prdct.coral]]\n- written_in: C++\n\n## Features\n\n-   Written in C++ with support for Windows and Linux\n-   C# .NET Core for scripting (like Unity)\n-   Vulkan for rendering, with an API-agnostic renderer\n-   Multi-threaded runtime (main thread + render thread)\n-   Physically-based forward+ HDR renderer\n-   ","n":0.154}}},{"i":3187,"$":{"0":{"v":"Haxe","n":1},"1":{"v":"\n- url: https://haxe.org/\n- written-in: [[t.cs.languages.ocaml]]\n\n## Use Cases\n\n- SDK creation\n- \n\n## Features\n\n-   [Cross-platform standard library](https://haxe.org//manual/std.html)\n-   [Fast compiler / Interpreted mode](https://haxe.org//manual/introduction-hello-world.html)\n-   [Type inference](https://haxe.org//manual/type-system-type-inference.html)\n-   [Conditional Compilation](https://haxe.org//manual/lf-condition-compilation.html)\n-   [Enums / Generalized Algebraic Data Types](https://haxe.org//manual/types-enum-instance.html)\n-   [Pattern matching](https://haxe.org//manual/lf-pattern-matching.html)\n-   [Type parameters, constraints, variance](https://haxe.org//manual/type-system.html)\n-   [Classes, Interfaces, and Inheritance](https://haxe.org//manual/types-class-instance.html)\n-   [Abstract Types](https://haxe.org//manual/types-abstract.html)\n-   [Inlined Calls](https://haxe.org//manual/class-field-inline.html)\n-   [Array Comprehension](https://haxe.org//manual/lf-array-comprehension.html)\n-   [Metadata](https://haxe.org//manual/lf-metadata.html)\n-   [Static Extensions / Mixin functions](https://haxe.org//manual/lf-static-extension.html)\n    -   \"Static extensions are usually considered syntactic sugar\"\n-   [String Interpolation](https://haxe.org//manual/lf-string-interpolation.html)\n-   [Syntax-transformation / macros](https://haxe.org//manual/macro.html)\n-   [Null Safety](https://haxe.org//manual/cr-null-safety.html) (opt-in)\n\n## References\n\n- https://peterfraedrich.medium.com/haxe-the-good-the-bad-and-the-ugly-bdb6bdbdb23e","n":0.12}}},{"i":3188,"$":{"0":{"v":"Havok","n":1},"1":{"v":"\n- url: https://www.havok.com/\n- ","n":0.577}}},{"i":3189,"$":{"0":{"v":"Hashnode","n":1},"1":{"v":"\n\n## Issues\n\n- removed Sponsor support\n\n## Resources\n\n- [tag list](https://github.com/Hashnode/support/blob/main/misc/tags.json)\n\n\n## Learning Resources\n\n-  https://blog.brockherion.dev/interacting-with-hashnodes-api-with-nextjs-and-apollo-client\n\n\n","n":0.302}}},{"i":3190,"$":{"0":{"v":"HASH.ai","n":1},"1":{"v":"\n- description: end-to-end solution for quickly creating massive, rich, real-time [[t.cs.simulation]]. But also, a [[t.cs.web3]] [[t.km.knowledge-graph]] (see https://blockprotocol.org/spec/graph) \n\n- [[p.hasURL]] https://hash.ai/ \n- [[p.hasScriptingLanguage]] \n  - #python\n  - javascript\n- related: [[prdct.block-protocol]]\n\n## Features\n\n- https://hash.ai/docs/simulation/concepts/designing-for-different-timescales\n  - Expressing multiple timescales in a simulation is a difficult problem that exists across platforms and frameworks. Often you're forced to break your representation of time and just ignore the different timescales.\n    - There are a couple of different ways you can solve this problem in HASH. Common approaches are:\n      - Add discrete event features to signal when agents should pause to allow for different computation times\n      - Add delays to normalize the actions across timescales.\n\n- The hCore API provides read and write access to the code and contents of simulation projects. This access can be used, amongst other things, to change the logic of a simulation based on external changes offline or in response to user-input outside of HASH. This unlocks the creation of domain-specific and custom user interfaces for building HASH models.\n\n## Cons\n\n- ","n":0.077}}},{"i":3191,"$":{"0":{"v":"hCore","n":1},"1":{"v":"\n- url: https://hash.ai/platform/engine\n- repo: https://github.com/hashintel/hash\n\n## Related\n\n- [[prdct.wasm]] \n  - https://hash.dev/blog/wasm-ai\n\n## References\n\n- https://hash.ai/blog/self-building-database","n":0.289}}},{"i":3192,"$":{"0":{"v":"HarperDB","n":1},"1":{"v":"\n#baas\n\nurl: https://harperdb.io\n\n## [[p.hasLearningResource]]\n\n- https://dev.to/harperdb/using-socketcluster-for-distributed-computing-in-a-unique-way-1cia\n  - [[p.hasHighlight]] \n    - So we have our connection, doing full data replication between node 1 and node 2. Making sure we have deterministic data sharing - deciding what data we want to go where. This use case is common for our clients especially in an edge computing scenario: say you have devices in a manufacturing plant collecting temperature data, you really only care when that data goes out of range, so command control wants to know what device is going out of range and what it looks like - then push that data to a separate table and push up to command control - but raw data is sitting only on the edge node and is tailing with time to live - that way we only share the data that really is important to customers.\n    - ","n":0.084}}},{"i":3193,"$":{"0":{"v":"Hapi","n":1},"1":{"v":"\n- [[c.software.web-framework]]\n- [[p.builtOn]] \n  - [[prdct.node]]\n\n- [[p.hadDescription]]\n  - https://hapi.dev/\n    - #highlight\n      - \"Middleware is just another name for bad design\"\n\n\n## [[p.supports]]\n\n- [[prdct.json-rpc]] via https://www.npmjs.com/package/@konceiver/hapi-json-rpc\n\n## [[p.hasComparison]]\n\n- https://scoutapm.com/blog/express-vs-hapi\n  - [[p.hasComparand]] [[prdct.express]]\n  - #highlight\n    - One can find the manual endpoint creation aspect of Express laborious. Additionally, refactoring becomes difficult as the codebase starts to increase in size.","n":0.135}}},{"i":3194,"$":{"0":{"v":"Hanko","n":1},"1":{"v":"\n## Features\n\n- Fast integration with Hanko Elements web components (login box and user profile)\n- API-first, small footprint, cloud-native\n- Availability for self-hosting and on Hanko Cloud.\n- has-pricing:\n  - free: 10k mau, 2 projects\n  - $29/mo+$0.02/au: webhookds, admin api, \n  - startup plan: 50% discount","n":0.152}}},{"i":3195,"$":{"0":{"v":"Hangfire","n":1}}},{"i":3196,"$":{"0":{"v":"Hackernoon","n":1},"1":{"v":"\n- slightly curated is nice","n":0.447}}},{"i":3197,"$":{"0":{"v":"H3","n":1},"1":{"v":"\n- url: https://h3geo.org\n- repo: https://github.com/uber/h3\n- #docs https://h3geo.org/docs/\n\n## [[p.supports]]\n\n- javascript with [[prdct.h3.js]]\n- java with [[prdct.h3.java]]\n- [[prdct.postgres]] via [[prdct.postgres.h3-pg]]\n\n## Descriptions\n\n- Since it is not possible to tile the icosahedron with only hexagons, we chose to introduce twelve pentagons, one at each of the icosahedron vertices. These vertices were positioned using the spherical icosahedron orientation by R. Buckminster Fuller, which places all the vertices in the water. This helps avoid pentagons surfacing in our work.\n- H3 supports sixteen resolutions. Each finer resolution has cells with one seventh the area of the coarser resolution. Hexagons cannot be perfectly subdivided into seven hexagons, so the finer cells are only approximately contained within a parent cell.\n- \"Hexagons (unlike say, squares or triangles) approximate various shapes like neighborhoods and city blocks more accurately.\"[1]\n\n## Features\n\n- [flow modeling](https://h3geo.org/docs/highlights/flowmodel)\n  - H3 can create indexes that refer to the movement from one cell to a neighbor. These directed edge indexes share the advantages with their cell index counterparts, such as being 64 bit integers. The use of directed edges makes it possible to associate a weight with a movement in the grid.\n\n## #related\n\n- https://github.com/clupasq/h3-viewer\n\n## Comparison\n\n- [[prdct.s2-geometry|S2 Geometry]] test\n  - https://h3geo.org/docs/comparisons/s2\n- [[prdct.geohash]]\n  - https://h3geo.org/docs/comparisons/geohash\n- [[prdct.hexbin]]\n\n\n## Resources\n\n- https://www.uber.com/blog/h3/\n- https://betterprogramming.pub/playing-with-ubers-hexagonal-hierarchical-spatial-index-h3-ed8d5cd7739d\n- [1]: https://afi.io/blog/uber-h3-js-tutorial-how-to-draw-hexagons-on-a-map/\n  - mentions [[prdct.react-map-gl]]","n":0.071}}},{"i":3198,"$":{"0":{"v":"h3-js","n":1},"1":{"v":"\n- repo: https://github.com/uber/h3-js\n\n## Resources\n\n- https://observablehq.com/@nrabinowitz/h3-tutorial-intro-to-h3-js-v4","n":0.447}}},{"i":3199,"$":{"0":{"v":"Java","n":1},"1":{"v":"\n- repo: https://github.com/uber/h3-java","n":0.577}}},{"i":3200,"$":{"0":{"v":"GWT","n":1},"1":{"v":"![[prdct.dojo_toolkit#^tmacjwe8emtq]]\n\nDirectly integrating server-side development and client-side development, GWT takes the perspective that JavaScript is a bug to be solved and uses advanced compiler technology to allow developers to write in Java and generate dynamic, JavaScript based UIs in the Google style. The default widget set is a strict subset of those provided by Dijit, but GWT takes great pains to optimize all generated code. A growing trove of add-on libraries are available to enhance the default components. Unlike YUI and EXT, GWT is being run as a real Open Source project, allowing external committers, and doing development in the open while managing IP issues in a very sophisticated manner (CLAs, code review, etc. Much like Apache or Dojo).  GWT applications can only be written in Java and are most often deployed on Java containers. Good documentation is available and a thriving community is helpful.","n":0.083}}},{"i":3201,"$":{"0":{"v":"Gust","n":1},"1":{"v":"\n- [[c.service.startup-formation]]\n- ","n":0.707}}},{"i":3202,"$":{"0":{"v":"GunDB","n":1},"1":{"v":"\n![[prdct.rxdb#^pnjx84u9yrqy]]\n- [[p.similarTo]] \n  - [[prdct.redwood]]\n  - [[prdct.saphiredb]]\n- [[p.builtOn]] javascript\n- [[p.hasExtension]] \n  - https://github.com/brysgo/graphql-gun\n\n## [[p.hadDescription]]\n\n- While testing it was really hard to get basic things running. GUN is open source, but because of how the source code is written, it is very difficult to understand what is going wrong.\n\n## Resources\n\n  - https://medium.com/@ajmeyghani/data-modeling-with-gundb-15220cbfb8da\n    - [[Data Modeling with GunDB|ar.medium.data-modeling-with-gundb]]\n    - uses \"link nodes\" for connecting \n    - uses properties to point to book nodes\n","n":0.119}}},{"i":3203,"$":{"0":{"v":"Guncho","n":1},"1":{"v":"\n- [[p.instanceOf]] [[c.software.game-framework.interactivefiction]]\n- [[p.hasExample]] https://cp.guncho.com/EditRealm.aspx?realm=Athenian+Marketplace\n- http://wiki.guncho.com/ is broken","n":0.354}}},{"i":3204,"$":{"0":{"v":"GUM","n":1},"1":{"v":"\n- url: http://www.fb10.uni-bremen.de/anglistik/langpro/webspace/jb/gum/index.htm\n  - mentions: [[prdct.ontoclean]]\n- not automatable [^1]\n- \"realism is computationally expensive, i.e., realism increases the computational complexity of the decidability problem of any consistent theory that expresses it.\"\n\n## References\n\n- [^1]: [[ar.foundational-ontologies-meet-automatic-theorem-provers]]\n\nhttp://www.loa.istc.cnr.it/wp-content/uploads/2021/07/dolce-mace4-prover9.zip","n":0.174}}},{"i":3205,"$":{"0":{"v":"Guan","n":1},"1":{"v":"\n- repo: https://github.com/microsoft/Guan\n- written-in: c#\n- related: [[prdct.fabric-healer]]","n":0.378}}},{"i":3206,"$":{"0":{"v":"Gson","n":1},"1":{"v":"\n## References\n\n- https://dzone.com/articles/mastering-json-handling-with-gson-in-java?","n":0.577}}},{"i":3207,"$":{"0":{"v":"Gsap","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n- similar: [[prdct.anime-js]]\n- url: https://gsap.com/\n- commercial, but free scrolling, lifetime license is $1000\n- features: core, scroll, svg, ui, text","n":0.224}}},{"i":3208,"$":{"0":{"v":"Grunt.js","n":1}}},{"i":3209,"$":{"0":{"v":"Gruff","n":1},"1":{"v":"\n- https://allegrograph.com/products/gruff/\n- published_by: [[org.franz-inc]]","n":0.5}}},{"i":3210,"$":{"0":{"v":"Grpc","n":1},"1":{"v":"\n- [[c.Resource.List]] https://github.com/grpc-ecosystem/awesome-grpc\n\n## Features\n\n- [Server Reflection](https://github.com/grpc/grpc/blob/master/doc/server-reflection.md)\n\n## Implementations\n\n- https://deno.land/x/gentle_rpc\n- https://deno.land/x/deno_json_rpc\n- ","n":0.333}}},{"i":3211,"$":{"0":{"v":"gRPC-web","n":1}}},{"i":3212,"$":{"0":{"v":"gRPC Node","n":0.707},"1":{"v":"\n\n\n- [there are two ways to generate the code needed to work with protocol buffers in Node.js - one approach uses Protobuf.js to dynamically generate the code at runtime, the other uses code statically generated using the protocol buffer compiler protoc](https://grpc.io/docs/languages/node/basics/)\n","n":0.156}}},{"i":3213,"$":{"0":{"v":"Groove","n":1},"1":{"v":"\n- https://groove.cs.utwente.nl/\n- repo: https://github.com/nl-utwente-groove","n":0.5}}},{"i":3214,"$":{"0":{"v":"Gremlin","n":1},"1":{"v":"\n- [[p.supportedBy]] [[prdct.tinkerpop]]\n\n## Features\n\n- A Gremlin traversal can be written in either an imperative (procedural) manner, a declarative (descriptive) manner, or in a hybrid manner containing both imperative and declarative aspects.\n\n## Comparison\n\n- https://itnext.io/graph-query-language-comparison-gremlin-vs-cypher-vs-ngql-3680cf830f8b","n":0.174}}},{"i":3215,"$":{"0":{"v":"Greenhouse","n":1}}},{"i":3216,"$":{"0":{"v":"Great Expectations","n":0.707},"1":{"v":"\n\n- [[p.hasSite]] https://greatexpectations.io/\n- [[p.hasRepository]] https://github.com/great-expectations/great_expectations\n- [[p.hasLearningResource]]\n  - https://teamtreehouse.com/library/greater-expectations\n    - [[p.partOf]] [[course.javascript-unit-testing]]\n","n":0.302}}},{"i":3217,"$":{"0":{"v":"Grax","n":1},"1":{"v":"\n- https://rdf-elixir.dev/grax/\n- related: [[prdct.rdf-ex]]","n":0.5}}},{"i":3218,"$":{"0":{"v":"GRASS GIS","n":0.707},"1":{"v":"\n- https://grass.osgeo.org/\n- [[c.software.gis]]\n- repo: https://github.com/OSGeo/grass/\n\n## References\n\n- https://training.gismentors.eu/grass-gis-workshop-jena/units/01.html","n":0.378}}},{"i":3219,"$":{"0":{"v":"Grapoi","n":1},"1":{"v":"\n- repo: https://github.com/rdf-ext/grapoi\n- inspired-by: [[prdct.gremlin]]","n":0.447}}},{"i":3220,"$":{"0":{"v":"Graphviz","n":1},"1":{"v":"\n- url: https://graphviz.org\n- repo: https://gitlab.com/graphviz/graphviz\n- can't do hyper/metagraphs, see https://gitlab.com/graphviz/graphviz/-/issues/1911","n":0.316}}},{"i":3221,"$":{"0":{"v":"Dot Language","n":0.707},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- [[c.grammar.abstract]]\n- url: https://graphviz.org/doc/info/lang.html\n\n## Description\n\n- \"The DOT application file is noteworthy because it is structurally very similar to the RDF.\"\n\n\n## References\n\n- https://www.datasciencecentral.com/why-json-users-should-learn-turtle/","n":0.209}}},{"i":3222,"$":{"0":{"v":"GraphRAG","n":1},"1":{"v":"\n- https://microsoft.github.io/graphrag/\n- [[c.software.retrieval-augmented-generation]]\n- repo: https://github.com/microsoft/graphrag\n- related: [[t.cs.ai.retrieval-augmented-generation]]\n- published-by: [[org.microsoft]]\n","n":0.333}}},{"i":3223,"$":{"0":{"v":"GraphQL","n":1},"1":{"v":"\n## Features\n\n- self-documenting API\n- three operation types: \n  - queries\n  - mutations\n  - subscriptions\n    - use cases:\n      - Small, incremental changes to large objects.\n      - Low-latency, real-time updates.\n\n\n## Schema\n\n- \"the three most common formats for representing a GraphQL schema...\n\n1.  The GraphQL Schema Definition Language, or SDL\n2.  The GraphQL introspection query result\n3.  The GraphQL.js GraphQLSchema object\" [^1]\n\n## References\n\n- [^1]: https://www.apollographql.com/blog/backend/schema-design/three-ways-to-represent-your-graphql-schema/\n","n":0.13}}},{"i":3224,"$":{"0":{"v":"GraphQL Sse","n":0.707}}},{"i":3225,"$":{"0":{"v":"GraphQL-LD","n":1},"1":{"v":"\n- https://github.com/rubensworks/graphql-ld.js\n\n## Solutions\n\n- [[prdct.comunica]]\n\n## Issues\n\n- \"we intend to improve the way in which we determine which variables should be considered singular or plural. OWL’s InverseFunctionalProperty or JSON-LD framing are potential options that we consider for this.\"\n\n## References\n\n- https://comunica.github.io/Article-ISWC2018-Demo-GraphQlLD/\n- https://gist.github.com/rubensworks/9d6eccce996317677d71944ed1087ea6\n","n":0.16}}},{"i":3226,"$":{"0":{"v":"GraphQL Gun","n":0.707}}},{"i":3227,"$":{"0":{"v":"Graphology","n":1},"1":{"v":"\n- [[c.software.database.graph.property]]\n- [[p.isComponentOf]] [[prdct.sigma-js]]\n- resources: \n  - https://archive.fosdem.org/2017/schedule/event/graph_library_javascript/attachments/slides/1803/export/events/attachments/graph_library_javascript/slides/1803/Graphology___FOSDEM_2017.pdf\n\n\n## Examples\n\n### native filtering\n\n```\n// From a filtering function\nconst sub = subgraph(graph, function (key, attr) {\n  return key.startsWith('J') || attr.color === 'red';\n});\n```\n\n### copying to array (from @chatgpt.3.5), yuck\n\n```\nconst { Graph } = require('graphology');\n\nconst graph = new Graph();\n\ngraph.addNode('Alice', { age: 30 });\ngraph.addNode('Bob', { age: 25 });\n\nconst nodesOver25 = Array.from(graph.nodes()).filter(node => graph.getNodeAttribute(node, 'age') > 25);\n```","n":0.13}}},{"i":3228,"$":{"0":{"v":"Graphology Gremlin","n":0.707}}},{"i":3229,"$":{"0":{"v":"Graphlib","n":1}}},{"i":3230,"$":{"0":{"v":"Graphbrain","n":1},"1":{"v":"\n- url: https://graphbrain.net/\n- written-in: #python\n- #aka \"An OpenCog that works\"\n- \n\n![](/assets/images/2023-09-23-13-09-46.png)\n\n## Features\n\n- provides an actual database system that allows for persistent storage and manipulation of semantic hypergraphs.\n- \"Taxonomies can be built using type-of relations between hyperedges, with the help of the special predicate type_of/P/..\", i.e., typeof = instanceOf\n\n## Cons\n\n- single backend implementation, that is based on LevelDB (a very efficient sorted key-value store that is stored in a local directory). Hypergraphs stored in this format can only be accessed by one process/thread at a time.\n\n## Highlights\n\n- Graphbrain is built around a unifying concept: the [[Semantic Hypergraph (SH)|t.cs.graph.semantic-hypergraph]], which makes it possible to represent a natural language sentence such as “Einstein first published the theory of relativity in 1905” as an ordered, recursive hyperlink\n  - http://graphbrain.net/manual/notation.html \n\n## Resources\n\n- [[ar.linking-graph-databases-and-semantic-web-for-reasoning-in-library-domains]]","n":0.088}}},{"i":3231,"$":{"0":{"v":"Graph Explorer","n":0.707},"1":{"v":"\n- repo: https://github.com/aws/graph-explorer\n- different-from: [[prdct.zazuko-graph-explorer]]","n":0.447}}},{"i":3232,"$":{"0":{"v":"Graph Engine","n":0.707},"1":{"v":"\n- [[c.software.database.graph]] [[c.software.database.graph.property]] [[c.software.database.graph.rdf]] \n- repo: https://github.com/Microsoft/GraphEngine\n- url: https://www.graphengine.io/\n- related: [[prdct.ikw-graphengine]]\n\n## Docs\n\n- https://www.graphengine.io/docs/manual/index.html\n  - \"The most important building block provided by GE for distributed computation is declarative message passing. We can implement almost any distributed algorithm using the fine-grained event-driven message passing framework provided by GE.\"\n  - \"GE provides two methods for serving a service: REST APIs and GE protocols.\n\n  REST APIs: They are standard, cross-platform, and easy-to-use. If we specify a RESTful service protocol named MyService, GE will automatically generate a REST service endpoint: http://example.com/MyService.\n\n  GE Protocols: They are the most efficient way to call a service implemented in the computation layer.\"\n  - \"storage layer of GE is a key-value store.\"\n\n## Examples\n\n- https://www.graphengine.io/docs/manual/DemoApps/FriendsGraph.html\n\n    \n## Resources\n\n- https://github.com/microsoft/GraphEngine/issues/328\n  - https://github.com/InKnowWorks/RDF-Graph-and-HyperGraph/ ^0qxsg2noq2s8\n- [-] https://www3.nd.edu/~kogge/courses/cse60742-Fall2018/Public/StudentWork/ParadigmPaperv1/GraphEngine-Talukder.pdf\n- [-] https://github.com/InKnowWorks/RDF-Graph-and-HyperGraph\n- https://www.graphengine.io/docs/manual/TSL/tsl-basics.html","n":0.089}}},{"i":3233,"$":{"0":{"v":"Tsl","n":1},"1":{"v":"\n- [[c.language]]\n- #summary : combines the following three functionalities into one language: data modeling, message passing modeling, and data interchange format specification","n":0.213}}},{"i":3234,"$":{"0":{"v":"Likq","n":1},"1":{"v":"\n- #summary : LIKQ is a versatile graph query language built atop Graph Engine. It combines the capability of fast graph exploration with the flexibility of lambda expressions. Server-side computations can be expressed in lambda expressions, embedded in LIKQ, and executed on the Graph Engine servers during graph traversal.\n- [[p.isRelated]] ","n":0.141}}},{"i":3235,"$":{"0":{"v":"Granthika","n":1},"1":{"v":"\n- [[p.hasCapability]]\n  - [[t.roleplaying.world-building]]\n- [[p.hasFeature]] [[p.hasSource]] https://granthika.co/features\n  - [[t.roleplaying.timeline-management]]\n  - [[t.roleplaying.character-management]]\n  - [[t.roleplaying.location-management]]\n  - [[t.roleplaying.item-management]]","n":0.258}}},{"i":3236,"$":{"0":{"v":"Grammatical Framework","n":0.707},"1":{"v":"\n- url: https://www.grammaticalframework.org/\n\n## Description\n\nGF, Grammatical Framework, is a programming language for **multilingual grammar applications**. It is\n\n-   a **special-purpose language for grammars**, like [YACC](http://dinosaur.compilertools.net/yacc/), [Bison](http://www.gnu.org/software/bison/), [Happy](http://www.haskell.org/happy/), [BNFC](http://bnfc.digitalgrammars.com/), but not restricted to programming languages\n-   a **functional programming language**, like [Haskell](http://www.haskell.org/), [Lisp](http://en.wikipedia.org/wiki/Lisp_(programming_language)), [OCaml](http://ocaml.org/), [SML](http://www.smlnj.org/), [Scheme](http://schemers.org/), but specialized to grammar writing\n-   a **development platform for natural language grammars**, like [LKB](http://moin.delph-in.net/LkbTop), [XLE](http://www2.parc.com/isl/groups/nltt/xle/), [Regulus](http://www.issco.unige.ch/en/research/projects/regulus/news.shtml), but based on functional programming and type theory\n-   a **categorial grammar formalism**, like [ACG](http://www.loria.fr/equipes/calligramme/acg/), [CCG](http://openccg.sourceforge.net/), but specialized for multilingual grammars,\n-   a **logical framework**, like [Agda](http://wiki.portal.chalmers.se/agda/pmwiki.php), [Coq](http://coq.inria.fr/), [Isabelle](http://www.cl.cam.ac.uk/research/hvg/Isabelle/), but equipped with concrete syntax in addition to logic\n-   a **platform for machine translation**, like [Moses](http://www.statmt.org/moses/), [Apertium](http://www.apertium.org/), but based on deep structural analysis (and usually applied for limited fragments of language).\n\n GF has an interactive command interpreter, as well as a batch compiler. Grammars can be compiled to parser and translator code in many different formats. These components can then be embedded in applications written in other programming languages. The formats currently supported are:\n\n    Haskell\n    Java, in particular the Android platform\n    JavaScript\n    Speech recognition: HTK/ATK, Nuance, JSGF\n\n\n## Learning Resource\n\n- https://www.grammaticalframework.org/doc/tutorial/gf-tutorial.html","n":0.076}}},{"i":3237,"$":{"0":{"v":"Grafo","n":1},"1":{"v":"\n- https://gra.fo/\n- commercial\n- [[c.software.semantic.ontology-editor]] [[c.Software.Knowledge-Base]]\n\n\n## Features\n\n- import and export\n  - OWL and TTL documents. More formats coming soon.","n":0.236}}},{"i":3238,"$":{"0":{"v":"Graffoo","n":1},"1":{"v":"\n- https://essepuntato.it/graffoo/\n- related: [[prdct.spar-ontologies]]\n\n![](/assets/images/2024-10-01-12-23-14.png)","n":0.5}}},{"i":3239,"$":{"0":{"v":"GraalVM","n":1}}},{"i":3240,"$":{"0":{"v":"Gqr","n":1},"1":{"v":"\n- [[c.Software.Reasoner]]\n- url: https://www.sfbtr8.spatial-cognition.de/de/projekte/reasoning/r4-logospace/research-tools/gqr/\n\n## Features\n\n- In contrast to other qualitative reasoners, it offers reasoning services for different calculi. These services are not hard-coded into the program. \n  - Both spatial calculi, e.g., RCC-5 and RCC-8, and temporal ones, like Allen's interval algebra, are supported. \n- New logics can be added to the system using a simple text format; no programming is necessary. \n- GQR is currently one of the best reasoning systems for qualitative calculi","n":0.115}}},{"i":3241,"$":{"0":{"v":"Gqlalchemy","n":1},"1":{"v":"\n- url: https://memgraph.github.io/gqlalchemy/\n- requires: [[prdct.memgraph]]\n\n## Description\n\n- Instead of writing Cypher queries, you can write object-oriented code, which the OGM will automatically translate into Cypher queries.\n- ","n":0.2}}},{"i":3242,"$":{"0":{"v":"Gpars","n":1},"1":{"v":"\n- url: http://www.gpars.org\n- supports: [[t.cs.languages.java.virtual-threads]]\n\n## Comparison\n\n- [[c.comparand]] [[prdct.pekko]]\n  - GPars supports a mixture of styles, some offering less verbosity at the expense of capturing some errors at runtime rather than compile-time. Such code can be useful when wanting very succinct code using Groovy’s dynamic nature. When using Groovy’s static nature or Java, you might consider using select parts of the GPars API.\n\n## Resources\n\n- [We have had a quick glimpse at using virtual threads with Groovy and GPars](https://groovy.apache.org/blog/gpars-meets-virtual-threads)\n- http://www.gpars.org/webapp/guide/index.html","n":0.113}}},{"i":3243,"$":{"0":{"v":"GoRules","n":1},"1":{"v":"\n- supports: supports Rust, Python and Node.js\n\n## Comparisons\n\n- https://gorules.io/blog/gorules-vs-drools","n":0.333}}},{"i":3244,"$":{"0":{"v":"Google Voice","n":0.707},"1":{"v":"\n## Limitations\n\n- GV app is inferior to Google Messages for texting, ie. can't send video MMS; \n- maybe some MFA things don't work?\n\n\n## References\n\n- https://www.reddit.com/r/Googlevoice/comments/ueo3f0/pros_and_cons_of_using_google_voice_exclusively/","n":0.2}}},{"i":3245,"$":{"0":{"v":"Google Meet","n":0.707}}},{"i":3246,"$":{"0":{"v":"Google Analytics","n":0.707}}},{"i":3247,"$":{"0":{"v":"Google Ad Manager","n":0.577},"1":{"v":"\n- ","n":1}}},{"i":3248,"$":{"0":{"v":"GOL","n":1},"1":{"v":"\n\n## Description\n\nGeneral Ontological Language (GOL) is intended to be a formal framework for building and representing ontologies. The main purpose of GOL is to provide a library of formalized and axiomatized top-level ontologies which can be used as a framework for building more specific ontologies. The GOL-Framework consists of three components representing different levels of abstraction. Meta-GOL contains basic principles of semantic choice, a general view on categories and classes, methods of semantic transformations, and principles for meta-logical analyses. GOL- Software tools contain a number of systems which support the development, the evaluation, the mapping and the integration of ontologies, but also application software (Onco-Workstation, Onto-Builder, SOP-Creator) based on ontological principles. GOL on the object level consists of a basic logic and a representation language RGOL which is specified, in this version of the document, by a syntax whereas the semantics has not been com- pletely developed yet. RGOL has a built-in ontology which is called abstract core ontology, de- noted by ACO. ACO contains the basic entities categories, including the category of concrete entities, and classes, and as relations identity, membership and instantiation; we believe that ACO is an indispensable part of every top-level ontology. The core of GOL is intended to be a library of top-level ontologies which extend ACO. The first of these ontologies, which is called General Formal Ontology (GFO)\n\n## References\n\n- https://www.researchgate.net/publication/2498727_GOL_A_General_Ontological_Language","n":0.067}}},{"i":3249,"$":{"0":{"v":"Goja","n":1},"1":{"v":"\n- url: https://github.com/dop251/goja\n- [[p.usedBy]] [[prdct.nakama]]","n":0.447}}},{"i":3250,"$":{"0":{"v":"Godot Kotlin Jvm","n":0.577},"1":{"v":"\n- https://godot-kotl.in/\n- repo: https://github.com/utopia-rise/godot-kotlin-jvm","n":0.5}}},{"i":3251,"$":{"0":{"v":"Godex","n":1},"1":{"v":"\n- repo: https://github.com/GodotECS/godex\n- written-in: #c++","n":0.447}}},{"i":3252,"$":{"0":{"v":"Goblins","n":1},"1":{"v":"\n\nhttps://spritelyproject.org/\n\n- [[p.hadDescription]] Spritely is a project to level up the federated [[social web|t.comm.media.social]]. It builds on our experience from co-authoring [[ActivityPub|prdct.activitypub]], the largest decentralized social network on the web to date, while applying lesser known but powerful ideas from the [[object capability security community|t.cs.security.object-capability-model]].","n":0.151}}},{"i":3253,"$":{"0":{"v":"Goal","n":1},"1":{"v":"\n- [[c.software.agent-framework]]\n- not open-source?\n- #docs https://goalapl.atlassian.net/wiki/spaces/GOAL/pages/33043/Tutorials+Documentation+and+Education","n":0.408}}},{"i":3254,"$":{"0":{"v":"Gluegun","n":1},"1":{"v":"\nrepo: https://infinitered.github.io/gluegun/#/","n":0.707}}},{"i":3255,"$":{"0":{"v":"Glue Gun","n":0.707},"1":{"v":"\n- #dead but good\n- [[c.topic]] [[t.cs.ui.cli]] [[t.cs.programming.repl]]\n- [[p.instanceOf]] [[c.software.cli-framework]]\n- repo: https://github.com/infinitered/gluegun\n\n## Features\n\n🌯 _parameters_ - command-line arguments and options  \n🎛 _template_ - generating files from templates  \n🗄 _patching_ - manipulating file contents  \n💾 _filesystem_ - moving files and directories around  \n⚒ _system_ - executing other command-line scripts  \n🎅 _http_ - interacting with API servers  \n🛎 _prompt_ - auto-complete prompts  \n💃 _print_ - printing pretty colors and tables  \n👩✈️ _semver_ - working with semantic versioning  \n🎻 _strings_ - manipulating strings & template data  \n📦 _packageManager_ - installing NPM packages with Yarn or NPM","n":0.105}}},{"i":3256,"$":{"0":{"v":"glTF","n":1},"1":{"v":"\n- url: https://www.khronos.org/gltf/\n- [[c.extension]] [[prdct.ee-variant]]\n- [[c.publisher]] [[org.khronos-group]]\n- [[p.similarTo]] [[prdct.universal-scene-description]]\n\n## Implementations\n\n- [[prdct.battlemap-io]]","n":0.302}}},{"i":3257,"$":{"0":{"v":"Glitch","n":1},"1":{"v":"\n\n- [[p.supports]] [[prdct.a-frame]]\n- [[p.hasCallToAction]] The biggest players in tech are staking a claim on the metaverse, saying “it’s the next big thing.” But the metaverse is already here. It’s not the exclusive playground of big tech companies. Regular people are building the future of virtual reality right now, on the free and open web.\n\n","n":0.136}}},{"i":3258,"$":{"0":{"v":"Glenda","n":1},"1":{"v":"\n- https://relweb.cs.aau.dk/glenda/\n- repo: \n- demo: https://glenda.cs.aau.dk/ (https://github.com/dkw-aau/archiving-demo)\n- based-on: [[prdct.ostrich]]\n- published-by: [[org.qweb]]\n- related: [[prdct.piqnic]]","n":0.277}}},{"i":3259,"$":{"0":{"v":"Glassdoor","n":1}}},{"i":3260,"$":{"0":{"v":"Glamorous Toolkit","n":0.707},"1":{"v":"\n- [[c.software.computational-notebook]] [[c.software.ide]]\n- [[p.hasRepository]] https://github.com/feenkcom/gtoolkit\n- [[c.usecase]]\n  - [[t.cs.sd.specification]]\n  - [[t.cs.sd.assessment]]\n  - [[t.cs.data.visualization]]\n- written-in: [[t.cs.languages.smalltalk.pharo]]\n\n## [[p.hadDefinition]]\n\n- \"live literate programming environment\"\n  - [[p.attributedTo]] @gilad-bracha\n- \"While you write your application you're also writing the tools which make it easy to write and debug your application. In Lisp you do this through molding the language; in GToolkit you do this through molding the IDE.\"\n  - https://news.ycombinator.com/item?id=33267518\n- \"It's a suite of extensions of the Pharo Smalltalk environment that are tailored for modeling behaviour and data in multiple ways, such that you can build your own toolkit for your own problem domain.\"\n\n\n## Features\n\n- Rust enabled runtime\n  - The Glamorous Toolkit virtual machine is formed by a Rust runtime that wraps and runs the Pharo virtual machine as a library in a separate operating system thread. The runtime also comes with Rust plugins and with an infrastructure for creating Rust plugins.\n- supports [[t.cs.sd.example-driven-development]], which is like [[t.cs.sd.test-driven-development]], but supports [[t.cs.sd.live-tutorials]]\n\n## Use Cases\n\n- [[c.software.knowledge-base]] for system documentation\n- Data Explorer\n\n\n## Cons\n\n- \"To get a living system + its real time perspectives and embedded live documentation it seems you must program the system in Pharo.\" ?\n\n## Resources\n\n- https://medium.com/feenk/one-rendering-tree-918eae49bcff\n- [+] https://lepiter.io/feenk/glamorous-toolkit-and-pharo-9q25tavxwfq6z1drwvegd5u9o/","n":0.073}}},{"i":3261,"$":{"0":{"v":"Gitpitch","n":1},"1":{"v":"\n- url: https://gitpitch.github.io/gitpitch/\n- ","n":0.577}}},{"i":3262,"$":{"0":{"v":"GitLab","n":1},"1":{"v":"\n## [[p.supports]]\n\n- [[prdct.vscode]] for the IDE! Yeeahaw!","n":0.378}}},{"i":3263,"$":{"0":{"v":"GitHub","n":1},"1":{"v":"\n## #features\n\n- github supports rendering [[prdct.mermaid]], [[prdct.geojson]] and [[prdct.topojson]], and [[prdct.stl]] ^a0073drc9gy1\n\n## #resources\n\n- https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-nodejs\n\n","n":0.267}}},{"i":3264,"$":{"0":{"v":"Runners","n":1}}},{"i":3265,"$":{"0":{"v":"Self-Hosted Runners (github)","n":0.577},"1":{"v":"\n- [[p.hasLearningResource]] https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners","n":0.577}}},{"i":3266,"$":{"0":{"v":"GitHub Webhooks","n":0.707}}},{"i":3267,"$":{"0":{"v":"Github Learning Lab","n":0.577},"1":{"v":"\n\n\nan exciting approach to learning git-based technologies and workflows\n\n## Course Creation\n\n- https://lab.github.com/docs/writing-quickstart\n","n":0.289}}},{"i":3268,"$":{"0":{"v":"Copilot","n":1},"1":{"v":"\n- [[c.software.ai.development-assistant]]","n":0.707}}},{"i":3269,"$":{"0":{"v":"Copilot Workspace","n":0.707}}},{"i":3270,"$":{"0":{"v":"Blocks","n":1},"1":{"v":"\n- url: https://blocks.githubnext.com/\n\n## description:\n\n- a block is a React component; it receives a fixed set of props and returns JSX","n":0.224}}},{"i":3271,"$":{"0":{"v":"GitHub Apps","n":0.707},"1":{"v":"\n## [[p.hasLearningResource]]\n\n- https://docs.github.com/en/developers/apps/getting-started-with-apps/differences-between-github-apps-and-oauth-apps","n":0.577}}},{"i":3272,"$":{"0":{"v":"GitHub JS","n":0.707},"1":{"v":"\n#dead\nrepo: https://github.com/github-tools/github\n- [[p.similarTo]] \n","n":0.5}}},{"i":3273,"$":{"0":{"v":"github-api","n":1}}},{"i":3274,"$":{"0":{"v":"Githack","n":1},"1":{"v":"\n- https://raw.githack.com/\n- \n","n":0.577}}},{"i":3275,"$":{"0":{"v":"Gitdoc","n":1},"1":{"v":"\n\n\n## \n","n":0.707}}},{"i":3276,"$":{"0":{"v":"Git","n":1},"1":{"v":"\n## quickref\n\n-  git config --get remote.origin.url.\n-  [[wanted.lightweight-javascript-rpc-framework]]\n","n":0.378}}},{"i":3277,"$":{"0":{"v":"Submodules","n":1},"1":{"v":"\nGit submodules are a way to have another repository inside your own repository. All the benefits of code sharing, none of the fuss. Well, maybe some of the fuss. Because git’s implementation of submodules leaves something to be desired.\n\nThe first and most obvious problem with Submodules is when you pull f\n\n```\ngit config --global submodule.recurse \n```\n\nAnd second you may have to init the submodule once you clone the project onto another computer.\n\n```\ngit submodule update --init --recursive\n```\n\nAnd even after this there does not appear to be a way to keep them pointed at the `HEAD` commit which makes committing to them a bit more difficult.\n\n## References\n\n- https://medium.com/lost-but-coding/just-say-no-to-monorepos-8f288fd0eeb1","n":0.098}}},{"i":3278,"$":{"0":{"v":"Githooks","n":1},"1":{"v":"\n\n\n- resources:  https://githooks.com/\n","n":0.577}}},{"i":3279,"$":{"0":{"v":"Git Web Terminal","n":0.577},"1":{"v":"\nrepo: https://github.com/jcubic/git\n#demo https://git-terminal.js.org/\n","n":0.577}}},{"i":3280,"$":{"0":{"v":"Gist","n":1},"1":{"v":"\n- [[c.ontology.upper]]\n- url: https://www.semanticarts.com/gist/\n\n## Description\n\n- Gist concepts are not philosophical abstractions with unfamiliar terms such as endurant, perdurant, or qualia; they are everyday concepts with ordinary names such as person, organization and agreement, whose meanings are just what you would expect.\n\n## Resources\n\n### #comparison [gist Council 12-1-22 - gist/BFO comparison with Dylan Abney](https://www.youtube.com/watch?v=MV3itJhPaVo)\n\n- BFO is \n  - higher up / domain neutral\n  - FOL\n- gist is\n  -  more focused on the enterprise\n  -  OWL DL","n":0.116}}},{"i":3281,"$":{"0":{"v":"Gideros","n":1},"1":{"v":"\n- [[c.software.game-framework]]","n":0.707}}},{"i":3282,"$":{"0":{"v":"Gherkin","n":1},"1":{"v":"\n- [[c.software.tools.testing]] ","n":0.707}}},{"i":3283,"$":{"0":{"v":"GFO","n":1},"1":{"v":"\n- url: \n  - https://raw.githubusercontent.com/Onto-Med/GFO/main/gfo-basic.owl\n  - https://www.onto-med.de/sites/www.onto-med.de/files/files/uploads/Ontologies/gfo.owl\n  - https://www.onto-med.de/ontologies/gfo#impl\n- repo: \n  - https://github.com/Onto-Med/GFO\n  - https://github.com/Onto-Med/GFO-2.0 (empty)\n- related: [[prdct.gol]]\n\n![](/assets/images/2024-03-07-13-47-05.png)\n(heterarchy with multiple inheritance)\n\n## Issues\n\n- aren't \"material processes\" and \"social processes\" still processes?\n- fine line between categories and attributives\n  - \"Categories provide the basic structure of the ontology, defining what kinds of things exist, whereas attributives are used to describe specific qualities or features of these things.\"\n- \n\n## OWL\n\nThere is an OWL version of GFO, which currently comprises a stable core called gfo-basic.owl and a more extensive version called gfo.owl. The stable URLs to the current releases of these files are:\n\n    http://www.onto-med.de/ontologies/gfo-basic.owl\n\n    (version 1.0, build 13, 07.10.2008)\n    http://www.onto-med.de/ontologies/gfo.owl\n\n    (version 1.0, build 9, 28.08.2006)\n\n\n## Features\n\n-   coherent integration of objects and processes (based on a novel category of _persistants_)\n-   time and space entities as entities sui generis, and the relation of _coincidence_\n-   a category of _situoids_, comprehensible wholes of the most independent character\n-   elaborate accounts of functions and roles\n-   openness regarding philosophical positions such as realism, conceptualism, or nominalism by the provision of different kinds of categories as universals, concepts, or symbolic structures\n-   levels of reality and ontological regions\n-   three-layered meta-ontological architecture consisting of an abstract top level, an abstract core level, and a basic level.\n\n\n\n## Concepts, Symbol Structures, and Platonic and Immanent Universals\n\n- @gemini.1.5.advanced GFO accounts for different philosophical stances: It accommodates those who believe in the real existence of universals outside of minds (realism), those who view them as primarily mental (conceptualism), and those who emphasize representations (nominalism).\n\n\n\n## References\n\n- [[ar.gfo-the-general-formal-ontology]] \n- [[ar.towards-gfo-2-0-architecture-modules-and-applications]]\n- http://www.thezfiles.co.za/ROMULUS/ontologicalCommitments.html\n- [[ar.towards-ontological-foundations-for-conceptual-modeling-the-unified-foundational-ontology-ufo-story]]\n- [[ar.towards-a-new-foundational-ontology-of-properties-attributives-and-data]]\n- [[ar.developing-gfo-2-0-further-initiating-the-modules-of-space-and-material-objects]]\n- [[email.gfo-users-gfo-presential-persistent-perpetuant]]\n- [[ar.general-formal-ontology-gfo-a-foundational-ontology-integrating-objects-and-processes]]","n":0.063}}},{"i":3284,"$":{"0":{"v":"Light","n":1},"1":{"v":"\n- https://raw.githubusercontent.com/Onto-Med/GFO/e3289274b0f0e02e6d316fd4b2b13d1b4fe00f42/gfo-light.ttl\n\n![](/assets/images/2024-09-05-10-44-38.png)","n":0.707}}},{"i":3285,"$":{"0":{"v":"Bio","n":1},"1":{"v":"\n- https://www.onto-med.de/ontologies/gfo-bio","n":0.707}}},{"i":3286,"$":{"0":{"v":"Geotic","n":1},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/ddmills/geotic\n- [[p.solvesProblem]] [[t.cs.entity-component-system]]\n","n":0.447}}},{"i":3287,"$":{"0":{"v":"Geospatial Creator","n":0.707},"1":{"v":"- #related [[prdct.arcore]]","n":0.577}}},{"i":3288,"$":{"0":{"v":"Geoserver","n":1},"1":{"v":"\n- [[c.software.gis]]\n- url: https://geoserver.org/\n- repo: https://github.com/geoserver/geoserver\n- written-in: java\n\n## Issues\n\n- no [[t.geo.ecef]] or 3d support?\n  - https://gis.stackexchange.com/questions/244737/how-can-i-project-earth-centered-cartesian-coordinates-epsg4978-to-lat-lon-wi\n  - \"because JTS Topology Suite, which is an important component of GeoServer, does not support 3D spatial operations, it also does not support solid geometries.\" [1]\n    - \n\n## Resources\n\n- [1]: [[ar.development-of-an-extension-of-geo-server-for-handling-3-d-spatial-data]]","n":0.146}}},{"i":3289,"$":{"0":{"v":"Geopose","n":1},"1":{"v":"\n- url: https://www.ogc.org/standard/geopose/\n\n## Implementations\n\n- [[prdct.ethar-geopose]]\n- [[prdct.cesium.cesiumjs]]\n\n## Resources\n\n- https://htmlpreview.github.io/?https://github.com/opengeospatial/GeoPoseGuides/blob/working-draft/GeoPose-Reviewers-Guide.html#_what_is_geopose\n- https://en.wikipedia.org/wiki/Six_degrees_of_freedom","n":0.333}}},{"i":3290,"$":{"0":{"v":"Geometry2rdf","n":1},"1":{"v":"\n- https://oeg.fi.upm.es/index.php/en/technologies/151-geometry2rdf/index.html","n":0.707}}},{"i":3291,"$":{"0":{"v":"Geojson","n":1},"1":{"v":"\n- url: https://geojson.org/\n\n\n## Resources\n\n- [[prdct.geojson-io]]","n":0.447}}},{"i":3292,"$":{"0":{"v":"Geohash","n":1},"1":{"v":"\n- ","n":1}}},{"i":3293,"$":{"0":{"v":"Geography Markup Language","n":0.577},"1":{"v":"\n- url: https://www.ogc.org/standard/gml/\n- similar-to: [[prdct.geojson]]\n- published-by: [[org.open-geospatial-consortium]]","n":0.378}}},{"i":3294,"$":{"0":{"v":"Geodot Plugin","n":0.707},"1":{"v":"\n- [[p.builtOn]] [[prdct.godot]]","n":0.577}}},{"i":3295,"$":{"0":{"v":"Gendocu","n":1},"1":{"v":"\n- docs:  https://doc.gendocu.com/gendocu/api/GendocuPublicApis?utm_source=mainpage&utm_medium=mainpage&utm_campaign=mainpage\n- [[p.supports]] [[prdct.grpc]]","n":0.447}}},{"i":3296,"$":{"0":{"v":"Gemini","n":1}}},{"i":3297,"$":{"0":{"v":"GDK","n":1},"1":{"v":"\n## Resources\n\n- https://learn.microsoft.com/en-us/gaming/gdk/_content/gc/get-started-with-pc-dev/get-started-with-custom-engine/gc-get-started-with-custom-engine-pc-csharp","n":0.577}}},{"i":3298,"$":{"0":{"v":"GDAL","n":1},"1":{"v":"\n- url: https://gdal.org/\n- repo: https://github.com/OSGeo/gdal/\n- written-in: #c++ #python #c","n":0.333}}},{"i":3299,"$":{"0":{"v":"Gatsby Digital Garden","n":0.577},"1":{"v":"\n- [[p.hasRepository]] https://github.com/mathieudutour/gatsby-digital-garden#readme\n- ","n":0.577}}},{"i":3300,"$":{"0":{"v":"GamingAPI","n":1},"1":{"v":"\n- #broken\n- repo: https://gamingapi.org/\n- supports: [[game.rust]]\n- description: Rust game server plugin that collected in-game events, such as when a player farms resources, kills another player, loots a container, etc, and send them to a backend. Later these could be extracted by an API to display the player's progression and detailed account of what the player did on the game server.\n\n## References\n\n- ","n":0.128}}},{"i":3301,"$":{"0":{"v":"GameShift","n":1},"1":{"v":"\n- [[c.software.game-framework]] [[c.Software.Web3]]\n- url https://gameshift.solanalabs.com/\n- [[p.announcedOn]] 2023.07.19\n\n## Features\n\n- provide non-custodial wallets\n- interactions are all in fiat currencies from minting to marketplace\n- branded marketplace (coming soon)\n- minting game assets\n- \"data indexing\" \n\n## Pricing\n\n- first 100 MAU free\n- first 500 NFT free\n- purchase: 5% + $0.35\n\n","n":0.151}}},{"i":3302,"$":{"0":{"v":"Gamelift","n":1},"1":{"v":"\n[[c.software.game-engine]]\nurl: https://aws.amazon.com/gamelift/\n\n- [[p.similarTo]] [[prdct.playfab]] [[prdct.nakama]]\n","n":0.447}}},{"i":3303,"$":{"0":{"v":"GameDemo","n":1},"1":{"v":"\n- repo: https://github.com/chickensoft-games/GameDemo\n- written_in: c#\n- built_on: [[prdct.godot]]\n\n## Features\n\n-  Node mixins using SuperNodes: we can add additional code to node scripts at build time using C# source generation, which makes up for the lack of mixin support in C#.\n-  \n\n## Resources\n\n- https://chickensoft.games/blog/game-architecture/","n":0.156}}},{"i":3304,"$":{"0":{"v":"gamecontroller.js","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/alvaromontoro/gamecontroller.js/\n","n":0.577}}},{"i":3305,"$":{"0":{"v":"GameAnalytics","n":1},"1":{"v":"\n- supports: \n  - [javascript](https://docs.gameanalytics.com/integrations/sdk/javascript/)","n":0.447}}},{"i":3306,"$":{"0":{"v":"Game2text","n":1},"1":{"v":"\n- https://game2text.com/\n\n## Description\n\n- If you are already playing [[t.cs.game.rpg.jrpg]], visual novels, or basically anything in Japanese, you can turn your gaming session into opporunities to learn Japanese through the power of immersive learning.\n\n## Features\n\n- **Visual Novel Hooker:** Extract text from visual novels with text hooks\n- **Script Matcher:** Use OCR to assist extracting dialog from game scripts","n":0.134}}},{"i":3307,"$":{"0":{"v":"Game Oriented Assembly Lisp","n":0.5},"1":{"v":"\n## References\n\n- https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp","n":0.577}}},{"i":3308,"$":{"0":{"v":"Game Makers Toolkit","n":0.577},"1":{"v":"\n- url: https://gmtk.itch.io/\n\n\n## Highlights\n\n- [Platformer Toolkit](https://gmtk.itch.io/platformer-toolkit) an \"interactive essay\" [[c.text.essay.interactive]]\n","n":0.316}}},{"i":3309,"$":{"0":{"v":"Game Description Language","n":0.577},"1":{"v":"\n- related: [[t.cs.game.general-game-playing]]\n\n## References\n\n- http://ggp.stanford.edu/\n- https://en.wikipedia.org/wiki/Game_Description_Language","n":0.408}}},{"i":3310,"$":{"0":{"v":"Game Box","n":0.707}}},{"i":3311,"$":{"0":{"v":"Gama","n":1},"1":{"v":"\n\n- [[c.software.agent-framework]] [[c.software.cognitive-architecture]]\n- url: https://gama-platform.org/\n- repo: https://github.com/gama-platform/gama\n- written-in: java\n- [[p.implements]] [[prdct.fipa.acl]]\n  - https://gama-platform.org/wiki/UsingFIPAACL\n\n## #features\n\n- [[prdct.fipa]], see https://gama-platform.org/wiki/1.8.1/UsingFIPAACL\n- supports [[t.cs.agents.bdi]] via [[prdct.gama.ben]]\n- [[prdct.jstor]]\n\n\n## Thoughts\n\n- seems overly-attached to the UI; \n  - [headless mode](https://gama-platform.org/wiki/Headless-mode-for-dummies) is experiment-oriented, not interactive\n    - [[p.hadLimitation]]\n      - close the socket on client-side) gama-server will destroy all running simulations of that client, so you have to keep your client alive.\n      - communicates via websocket only? i.e., no http/s or grpc\n## Examples\n\n- [Kiss Nightclub simulation](https://www.comses.net/codebases/7ca5fbb1-9e3a-4ea1-a63f-87d2ba9f39d6/releases/1.1.0/)\n- [LittoSIM-GEN: a serious game of flooding risk management](https://hal.science/hal-03519918/)\n- [Sprite](https://sites.google.com/site/caroleadamphd/development/sprite)\n  - https://drive.google.com/file/d/12J6Wyr1DBqvRXfH5xWQNWRNpNiWhIyHt/view\n\n## Resources\n\n### Learning Resource\n\n- https://unigis-salzburg.github.io/Opt_Spatial-Simulation/\n\n\n### Comparison\n\n- [[An Initial Comparison of Selected Agent Based Simulation Tools in the Context of Industrial Health and Safety Management|ar.acm.an-initial-comparison-of-selected-agent-based-simulation-tools-in-the-context-of-industrial-health-and-safety-management]]\n","n":0.096}}},{"i":3312,"$":{"0":{"v":"Gaml","n":1},"1":{"v":"\n- url: https://gama-platform.org/wiki/GamlLanguage\n\n## #features\n\n- species can be constructed in a compositional way with the notion of skills, bundles of attributes and actions that can be shared between different species and inherited by their children. ^8jzl8r4hwjj2\n\n\n## [[c.model.conceptual]]\n  \n- defining a model in GAML amounts to defining a model species, which later allows to instantiate a model agent (aka a simulation), which may or may not contain micro-species, and which can be flanked by experiment plans in order to be simulated.\n\nThis conceptual structure is respected in the definition of model files, which follows a similar pattern:\n\n    Definition of the global species, preceded by a header, in order to represent the model species\n    Definition of the different micro-species (either nested inside the global species or at the same level)\n    Definition of the different experiment plans that target this model\n\n-    Since simulations, or experiments, are represented by agents, GAMA is bound to support high-level model compositionality, i.e. the definition of models that can use other models as inner agents, leveraging multi-modeling or multi-paradigm modeling as particular cases of composition.\n    The visualization of models can be expressed by models of visualization, composed of agents entirely dedicated to visually represent other agents, allowing for a clear separation of concerns between a simulation and its representation and, hence, the possibility to play with multiple representations of the same model at once.\n\n- The agent-oriented modeling paradigm means that everything \"active\" (entities of a model, systems, processes, activities, like simulations and experiments) can be represented in GAML as an agent (which can be thought of as a computational component owning its own data and executing its own behavior, alone or in interaction with other agents).\n- Any species can be nested in another species (called its macro-species), in which case the populations of its instances will imperatively be hosted by an instance of this macro-species. A species can also inherit its properties from another species (called its parent species), creating a relationship similar to specialization in object-oriented design. In addition to this, species can be constructed in a compositional way with the notion of skills, bundles of attributes and actions that can be shared between different species and inherited by their children.","n":0.053}}},{"i":3313,"$":{"0":{"v":"Gama2","n":1},"1":{"v":"\n- repo: https://github.com/gama-platform/gama2\n- ","n":0.577}}},{"i":3314,"$":{"0":{"v":"Ben","n":1},"1":{"v":"\n- url: https://gama-platform.org/wiki/next/Using-BEN-simple-bdi\n- [[p.builtOn]] ","n":0.5}}},{"i":3315,"$":{"0":{"v":"Fuse.js","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://fusejs.io/\n- [[c.usecase]]\n  - When you want client-side fuzzy searching of small to moderately large data sets.\n  - When you can't justify setting up a dedicated backend simply to handle search. [[prdct.elasticsearch]] or [[prdct.algolia]], although both great services, may be overkill for your particular use cases\n","n":0.146}}},{"i":3316,"$":{"0":{"v":"Functional Requirements for Information Resources (FRIR)","n":0.408},"1":{"v":"\n## Description\n\n- Members of the Open Government Data community have proposed a FRBR-based data model called FRIR (for Functional Requirements for Information Resources) for datasets\n- the use of abstraction, expressed information, and physical sources is needed to allow members of the community to combine data from different sources and to determine at what level the sources represent the same information\n- exact copies of files (the same bitstream) considered items of the same manifestation\n\n## References\n\n- [[ar.works-expressions-manifestations-items-an-ontology]]\n- https://dspace.rpi.edu/items/03e7773b-953d-476d-b3f7-19f44ec6085b\n- [[ar.functional-requirements-for-information-resource-provenance-on-the-web]] ^f7kehn8hc41j","n":0.113}}},{"i":3317,"$":{"0":{"v":"Fulcro","n":1},"1":{"v":"\n- related: [[prdct.clara]]\n- demo: https://github.com/fulcrologic/fulcro-rad-demo\n- written-in: clojure\n- related: [[prdct.clara]]\n\n## Resources\n\n- https://book.fulcrologic.com/\n\n## References\n\n- https://www.reddit.com/r/Clojure/comments/wmi258/anyone_having_success_in_production_with_fulcro/\n- https://www.reddit.com/r/fulcro/comments/f3gjvu/fulcro_rad_clara_rules/","n":0.267}}},{"i":3318,"$":{"0":{"v":"Friend of a Friend Ontology (FOAF)","n":0.408},"1":{"v":"\n\n## Issues\n\n- As foaf:homepage is an Inverse Functional Property ([OWL], Section 6.1), different descriptions of a dataset provided in different places on the Web can be automatically connected or “smushed” if they use the same homepage URI. To avoid inappropriate “smushing”, one should not use related pages that are not specifically about the dataset, such as the funding project's homepage or publishing organisation's homepage, as the value of foaf:homepage.","n":0.12}}},{"i":3319,"$":{"0":{"v":"Freeroam","n":1},"1":{"v":"\n- url: https://freeroam.app/\n- #rv","n":0.5}}},{"i":3320,"$":{"0":{"v":"Freepik","n":1},"1":{"v":"\n## [[p.hadLicense]]\n\nOur license allows you to use the content\n\n-   For commercial and **personal projects**\n-   On digital or **printed media**\n-   For an **unlimited number of times** and without any time limits\n-   From **anywhere in the world**\n-   To make **modifications** and create derivative works\n\nBUT \n\nIf you are a Free user, you must always include the attribution line “Designed by Freepik” on the final products or designs you use our resources for, whether these are physical or digital products.\n\n## [[p.hasExample]]\n\n### Medieval Icon Pack\n\nurl: https://www.freepik.com/premium-icon/medieval_26045530.htm#query=battle&position=5&from_view=search&track=sph\n\n![](/assets/images/2023-01-07-04-51-04.png)","n":0.111}}},{"i":3321,"$":{"0":{"v":"Frbroo","n":1},"1":{"v":"\n- related: [[prdct.frbr]]","n":0.577}}},{"i":3322,"$":{"0":{"v":"Frbr","n":1},"1":{"v":"\n- succeeded-by: [[prdct.lrmoo]]\n\n## Description\n\n- FRBR can describe how different copies of the same book, or differ- ent editions of the book, relate to each other. The most concrete aspect is the Item – the physical book that exists in the world. Items are singular entities; making a copy of an Item results in a new Item. Items are exemplars of Manifes- tations, which represent similar physical structure. For instance, an exact copy of an Item preserves the original Manifestation. If the copy is inexact, or if the book is turned into an audio book, then the Manifestation changes. However, the Expression of the paperback and audio book remains the same, because the Expression reflects particular content regardless of physical configuration. An Expression in turn realizes a Work, which is “a distinct intellectual or artistic creation.” [7] A Work remains the same through different realized Expressions that result from translation, revision, or any other change. ^kph9708t2eod\n\n## References\n\n- [[ar.functional-requirements-for-information-resource-provenance-on-the-web]]\n- http://www.sparontologies.net/examples#frbr_1","n":0.08}}},{"i":3323,"$":{"0":{"v":"Frbr Core","n":0.707},"1":{"v":" \n- https://vocab.org/frbr/core\n\n\n## References\n\n- [[ar.works-expressions-manifestations-items-an-ontology]]","n":0.5}}},{"i":3324,"$":{"0":{"v":"Framer Motion","n":0.707},"1":{"v":"\n- url: https://www.framer.com/motion/\n- ","n":0.577}}},{"i":3325,"$":{"0":{"v":"Framenet","n":1},"1":{"v":"\n- #dead ?\n- url: ?\n\n## Cons\n\n- not reference-aware (like [[prdct.amr]])","n":0.316}}},{"i":3326,"$":{"0":{"v":"Foundry Server","n":0.707},"1":{"v":"\n- https://foundryserver.com/","n":0.707}}},{"i":3327,"$":{"0":{"v":"FoundationDB","n":1}}},{"i":3328,"$":{"0":{"v":"Foundational Foundational Ontology","n":0.577},"1":{"v":"\n- related: [[prdct.romulus]]\n- url: http://www.thezfiles.co.za/ROMULUS/ontologies/FFO.owl\n\n\n## Classes\n\n- Material-object\n- Property\n- Spatial-region\n- 3D (endurant)\n- 4D (perdurant/occurent)\n- Process","n":0.267}}},{"i":3329,"$":{"0":{"v":"Forem","n":1},"1":{"v":"\n- url: https://forem.dev/\n- repo:  https://github.com/forem/forem\n- #writtenIn #ruby","n":0.378}}},{"i":3330,"$":{"0":{"v":"Forbidden Lands","n":0.707}}},{"i":3331,"$":{"0":{"v":"Footprints","n":1}}},{"i":3332,"$":{"0":{"v":"Fody","n":1},"1":{"v":"\n- [[c.software.library]]\n- repo: https://github.com/Fody/Fody\n- description: An extensible tool for weaving .net assemblies. It enables the manipulation of the IL of an assembly as part of a build, which requires a significant amount of plumbing code. This plumbing code involves knowledge of both the MSBuild and Visual Studio APIs. Fody attempts to eliminate that plumbing code through an extensible add-in model. This technique is very powerful, for example you can turn simple properties into full INotifyPropertyChanged implementations, add checks for null arguments, add Method Timings, even make all your string comparisons case insensitive.\n- #writtenIn c#","n":0.103}}},{"i":3333,"$":{"0":{"v":"Foam","n":1},"1":{"v":"\n\n\na vscode-based km system\n\n- [[p.hasURL]] https://foambubble.github.io/foam/\n- [[p.hasApplication]] [[t.km.pkm]]\n\n## features\n\n- > supports creating relationships between thoughts and information to help you think better.\n\n## [[p.vs]] [[prdct.dendron]]\n\n- it's alive!","n":0.196}}},{"i":3334,"$":{"0":{"v":"FNO","n":1},"1":{"v":"\n- https://fno.io/\n- spec: https://fno.io/spec/\n- related: [[prdct.prov-o]]\n\n## References\n\n- https://2016.eswc-conferences.org/sites/default/files/papers/Accepted%20Posters%20and%20Demos/ESWC2016_POSTER_An_Ontology_to_Semantically_Declare_Describe_Functions.pdf\n  - \"we present a data model, specification, and ontology to semantically declare and describe functions independently of the used technology. This way, we can declare and use actionable events in semantic applications, without restricting ourselves to programming language-dependent implementations. \"\n- There exist many specifications handling Web services, both non-semantically (e.g., WSDL and WADL) and semantically (e.g., [[prdct.owl-s]] and [[prdct.hydra]]) 1. These specifications target different facets (e.g., HTTP-based vs SOAP-based access, defining RESTful APIs, etc.), but have in common that they define Web ser- vices.","n":0.104}}},{"i":3335,"$":{"0":{"v":"FNA","n":1},"1":{"v":"\n- repo: https://github.com/FNA-XNA/FNA\n\n## Cons\n\n- no android support","n":0.378}}},{"i":3336,"$":{"0":{"v":"Flyte","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://flyte.org\n- [[p.vs]] \n  - [[prdct.airflow]] \n    - The biggest difference between Airflow and Flyte is from an idea point of view, Flyte is completely data-aware. It means it understands what’s the data that’s flowing through the system, while Airflow is a pure task dependency system. \n- ","n":0.144}}},{"i":3337,"$":{"0":{"v":"Fly.io","n":1}}},{"i":3338,"$":{"0":{"v":"Fluxus","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/zzkt/fluxus\n- [[p.extends]] [[prdct.racket]]\n- [[p.mentionedOn]] [[org.toplap]]","n":0.354}}},{"i":3339,"$":{"0":{"v":"Flutter","n":1},"1":{"v":"\n- [[p.hasSite]] https://flutter.dev/\n- [[p.builtWith]] [[t.cs.languages.Dart]]\n- [\"Flutter is basically just a 2D game engine\"](https://medium.com/codex/stop-trying-to-make-flutter-web-happen-its-not-going-to-happen-a29f805df504)\n","n":0.277}}},{"i":3340,"$":{"0":{"v":"FlutterFlow","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://flutterflow.io/\n","n":0.577}}},{"i":3341,"$":{"0":{"v":"Fluree","n":1},"1":{"v":"\nsupports: \n  - type: storage\n    products: [\"[[prdct.ipfs]]\", \"[[prdct.aws.s3]]\"]\n  - type: data_format\n    products: prdct.json-ld\n\n- [[c.software.database.graph]] [[c.software.database.graph.rdf]]\n- written-in: #clojure JVM!\n- [[p.hasApplication]] [[t.km]]\n- [[p.hasBlog]] https://flur.ee/blog/\n- [[p.hasFeature]] \n  - [[t.cs.data.time-travel]]\n    - resources:  https://flur.ee/2019/02/21/time-travel-with-fluree/ x\n  - \" optionally decentralized (e.g. using StorJ via Tardigrade)\"\n    - [[p.hasSource]] https://github.com/athensresearch/athens/issues/9#issuecomment-786844129\n  - [[prdct.json-ld]] support\n\n## Features\n\n- FlureeQL is similar to SPARQL, \n  - results from queries can be exported as JSON-LD\n- a query peer \"runs as an in-memory database peer to the ledger it's subscribed to. But like you mention, it doesn't only need (or need at all) to do so because it's intended to answer Fluree queries from other clients. It could very usefully just subscribe to a ledger in order to monitor data events like newly committed blocks and then to evaluate if that data meets a certain criteria, and--if so--to then trigger some downstream function or additional side effect... the NodeJS peer subscribes to the ledger as a particular cryptographic identity, which means that the listener itself will only be privy to data updates that that identity SHOULD be able to access.\"\n- \"can be embedded inside of your applications (Clojure, NodeJS for now)\"\n- [Time and Immutability in Data Systems](https://www.youtube.com/watch?v=CLZm3ZjvQqM&t=1972s)... probably only for clock-time, natively.  \n- inferencing (e.g., equivalent properties, but that's only useful if you're using data from different ontologies; okay, it's just useful, period) and \n  - Aliasing makes it possible to not only find equivalent data, but return it in the terms that are useful to us.\n- Objects: you can further describe the subgraph you want to build by including nested objects. Our dataset doesn't actually include any data with multiple layers of connections\n- History Queries: also powered by immutability, but are preformed differently than time-travel queries. While time-travel allows users to view the ledger from different points in history, history queries capture each of the data state changes that effected a given entity up until the present moment.\n\n## Use Cases\n\n- A particular use case around user-specific ledgers, where each user has their own ledger, would demonstrate this perfectly. Given the ability to run database/query peers directly off of an individual ledger, this would also allow ledger-specific users to efficiently build their own applications off their own database peers without any of the security complexities of establishing a downstream peer to a multi-tenant ledger\n\n## Learning Resources\n\n- [ ] [Building a Front-End App on Fluree.](https://www.youtube.com/watch?v=USh0-b-f5fo)\n- [[ar.fluree.working-with-graph-data]]\n\n## References\n\n- https://next.developers.flur.ee/docs/learn/guides/working-with-ontologies/\n- https://www.reddit.com/r/Clojure/comments/187qsck/fluree_a_datomiclike_database_that_embraces_the/","n":0.05}}},{"i":3342,"$":{"0":{"v":"Nexus","n":1},"1":{"v":"\n- https://data.flur.ee\n\n\n## References\n\n- https://next.developers.flur.ee/docs/nexus/datasets/overview/","n":0.5}}},{"i":3343,"$":{"0":{"v":"Flureeql","n":1}}},{"i":3344,"$":{"0":{"v":"Flume","n":1},"1":{"v":"\n- [[p.hasSite]] https://flumewater.com/\n- ","n":0.577}}},{"i":3345,"$":{"0":{"v":"Fluf World","n":0.707},"1":{"v":"\n- https://www.fluf.world/\n- ","n":0.707}}},{"i":3346,"$":{"0":{"v":"Fluentd","n":1},"1":{"v":"\n\n\n- written-in: [[t.cs.languages.Ruby]]\n- [[p.hasIssue]] https://kthunk.atlassian.net/browse/OPS-2\n- ","n":0.447}}},{"i":3347,"$":{"0":{"v":"Fluent Editor","n":0.707},"1":{"v":"\n- https://www.cognitum.eu/semantics/fluenteditor/\n- works-with: [[prdct.protege]]\n- last-update: 2015\n\n\n![](/assets/images/2024-10-18-12-56-20.png)\n\n## Features\n\n-  uses Controlled English as a knowledge modeling language\n-  \n\n\n## Issues\n\n- no source editing\n- assumes that IRI has form: namespace#identifier e.g. IRI: ‘http://sample.org/ontologies/human.owl#woman’\n-  doesn't support .ttl file extension\n-\n\n","n":0.171}}},{"i":3348,"$":{"0":{"v":"Flowchart JS","n":0.707},"1":{"v":"\n- #ul https://github.com/adrai/flowchart.js\n  - [[c.mention]] [[prdct.mingrammer-diagrams]]\n\n## Features\n\n- Nodes and connections are defined separately so that nodes can be reused and connections can be quickly changed. \n- Fine grain changes to node and connection style can also be made right in the DSL.\n- ","n":0.154}}},{"i":3349,"$":{"0":{"v":"Flowable","n":1},"1":{"v":"\n- repo: https://github.com/flowable/flowable-engine\n- written_in: java\n\n## Features\n\n- fully supports the [[prdct.bpmn]], [[prdct.cmmn-case-management-model-and-notation]], and [[prdct.dmn]] open standards.\n- data dictionary for type definitions, see https://www.flowable.com/blog/engineering/data-structure-with-data-dictionary\n- default tenant backstops regular tenants\n\n## Interesting\n\n- There is no simple way in Flowable to list tasks that have not occurred yet. Tasks are not created until execution gets to them and the engine makes no assumption about what tasks are upcoming or even what the next task is until the last task is complete. Due things to gateways, conditional sequence flows, multi-instance tasks, and workflows that iterate multiple times by looping back on themselves, knowing what tasks are coming up is very difficult, if not impossible without limiting processes or making assumptions... For you, your best alternative is to retrieve and parse the model, find the currently active task and follow the sequence flows out of it.","n":0.085}}},{"i":3350,"$":{"0":{"v":"Flow","n":1},"1":{"v":"\nurl: https://www.estuary.dev/product/\nrepo: https://www.estuary.dev/product/\n\n- [[p.hadLicense]] https://github.com/estuary/flow/blob/master/LICENSE-BSL\n  - [[p.hasHighlight]] You may make use of the Licensed Work, provided that you may not use the Licensed Work for a Data Processing Service.\n\n[[p.wasBuiltBy]] [[org.estuary]]","n":0.183}}},{"i":3351,"$":{"0":{"v":"Flogo","n":1},"1":{"v":"\n\n- https://www.flogo.io/\n- [[c.Software.Workflow]]\n- repo: https://github.com/tibcosoftware/flogo\n\n## Support\n\n- [[prdct.kafka]] \n- [[prdct.pulsar]]","n":0.333}}},{"i":3352,"$":{"0":{"v":"Flip","n":1},"1":{"v":"\n- dead\n- url: https://irisate.com/flip-overview/\n- repo: https://github.com/ohmtech/flip-public\n\n## Features\n\n- supports a text-editable back-end writing format as well as a binary one. This has many advantages, including:\n  - Parsing the binary format is fast and portable\n  - the ability to use a text editor in debug mode, which offers outstanding readability with the text-editable back-end\n\n\n## Resources\n\n- https://irisate.com/collaborative-editing-solutions-round-up/","n":0.136}}},{"i":3353,"$":{"0":{"v":"Flink","n":1},"1":{"v":"\n\n- [[c.software.data-framework]] [[c.software.data-framework]]\n\n## Features\n\n- known for its powerful stream processing capabilities and exactly-once semantics, making it well-suited for real-time data processing.\n- \"RisingWave and Flink are prominent examples of streaming-first platforms that excel at processing real-time, continuously updated data. [[prdct.risingwave]] is particularly well-suited for running SQL queries on event streams, making it easier for users to gain insights in real-time without dealing with the complexity of traditional stream processing. Similarly, Flink’s distributed stream processing capabilities make it a powerful tool for low-latency, high-throughput applications.\"\n\n## References\n\n- https://medium.com/@yingjunwu/kafka-has-reached-a-turning-point-649bd18b967f","n":0.108}}},{"i":3354,"$":{"0":{"v":"Flexidate","n":1},"1":{"v":"\n- repo: https://github.com/datopian/flexidate\n\n## Features\n\n1.  Cast dates according to the [Anno Domini](https://en.wikipedia.org/wiki/Anno_Domini) notation system (e.g., 399 BC, AD 417) as well as the [Common Era](https://en.wikipedia.org/wiki/Common_Era) notation system (e.g., 399 B.C.E, 417 CE)\n2.  Handle dates before AD 1 or 1 CE\n3.  Cast imprecise dates (c.1860, 18??, fl. 1534, etc)\n4.  Normalize dates to machine-readable data types\n5.  Create sortable date objects\n\nFlexidate builds on the excellent [dateutil](https://dateutil.readthedocs.org/en/latest/).","n":0.127}}},{"i":3355,"$":{"0":{"v":"Flecs","n":1},"1":{"v":"\n\n- [[c.software.entity-component-system]]\n- repo: https://github.com/SanderMertens/flecs\n- written-in: #c #c++ \n- author: @sander-mertens\n- supports: c# via [[prdct.flecs.flecs-cs]]\n- inspiration: prolog\n\n## FAQ\n\n- Can I use Flecs without using systems?\n  - You can! Systems are an optional addon that can be disabled. You can build applications that just use Flecs queries.\n\n## Features\n\n- World cell partitioning\n- \"Flecs introduced an extremely powerful innovation to ECS - the concept of an entity relationship. You can relate one entity to another via a relationship containing metadata. For example, a player entity can be related to a character entity via a Controls relationship. One entity could follow another entity via a Follow relationship. This allows you to conveniently express patterns that would not be possible only via components. When I read about this idea I immediately borrowed it for my own ECS library and it was like a missing link that let me get rid of all kinds of awkwardly structured patterns that I had used before.\n\nBeyond that, the main innovation of Flecs is that it’s structured like a database, to allow you to perform complex data queries on the structure of the world. It has all kinds of neat design tricks, like the fact that every component type is actually also an entity itself. This stuff is like catnip for a certain type of programmer. Leibniz himself would weep at its purity.\"\n  - https://moonside.games/posts/archetypal-ecs-considered-harmful/\n\n## Learning Resource\n\n- ![FLECS overview](https://github.com/SanderMertens/flecs/raw/master/docs/img/flecs-quickstart-overview.png)\n\n","n":0.066}}},{"i":3356,"$":{"0":{"v":"Flecs Script","n":0.707},"1":{"v":"\n## Use cases\n\n- building scenes \n- assets\n- language for configuration files.","n":0.302}}},{"i":3357,"$":{"0":{"v":"flecs-cs","n":1},"1":{"v":"\n- repo: https://github.com/flecs-hub/flecs-cs\n- related: [[prdct.flecs-net]]","n":0.447}}},{"i":3358,"$":{"0":{"v":"Explore","n":1},"1":{"v":"\n- repo: https://github.com/flecs-hub/explorer\n- demo: https://www.flecs.dev/explorer/?wasm=https://www.flecs.dev/explorer/playground.js","n":0.447}}},{"i":3359,"$":{"0":{"v":"Flecs Net","n":0.707},"1":{"v":"\n- repo: https://github.com/BeanCheeseBurrito/Flecs.NET\n- related: [[prdct.zig]]\n\n## Examples\n\n- https://github.com/BeanCheeseBurrito/Flecs.NET.GodotExample","n":0.378}}},{"i":3360,"$":{"0":{"v":"Flask","n":1},"1":{"v":"\n- [[c.software.web-framework]]\n- written-in: #python","n":0.5}}},{"i":3361,"$":{"0":{"v":"Flake","n":1},"1":{"v":"\n- \"best considered deprecated\"\n- repo: https://github.com/boundary/flake\n- [[c.software.tools.id-generator]]\n- written-in: erlang\n\n![[prdct.newid#similar]]\n\n## References\n\n- https://brandur.org/fragments/k-sorted-ids","n":0.302}}},{"i":3362,"$":{"0":{"v":"Fission","n":1},"1":{"v":"\n- url: https://fission.codes/\n- [[p.supports]] [[prdct.ucan]]\n- [[p.ownedBy]] [[org.fission]]","n":0.378}}},{"i":3363,"$":{"0":{"v":"Financial Industry Business Ontology Fibo","n":0.447},"1":{"v":"\n\n## References\n\n- [[ar.an-infrastructure-for-collaborative-ontology-development]]","n":0.577}}},{"i":3364,"$":{"0":{"v":"Filecoin","n":1},"1":{"v":"\n\n- resources:  https://docs.filecoin.io/build/\n\n-   [Use Glif nodes](https://lotus.filecoin.io/docs/developers/hosted-lotus/)\n- Build with [[Lotus|prdct.lotus]] for users looking to interact with their own, local Lotus nodes.\n- Build with [[Powergate|prdct.powergate]], for users wanting to combine IPFS (fast retrieval) and Filecoin (backup) with full control of both.\n- Build with [[Textile|prdct.textile]] buckets, for users looking for simple IPFS storage with Filecoin-based archival, with encryption and shared buckets support","n":0.13}}},{"i":3365,"$":{"0":{"v":"Fiction Finder","n":0.707},"1":{"v":"\n- dead\n- https://www.oclc.org/research/areas/data-science/fictionfinder.html\n\n\n## Features\n\n- search and browse by genres, characters (real & fictional), settings (real & imaginary) and literary awards.","n":0.224}}},{"i":3366,"$":{"0":{"v":"Fibry","n":1},"1":{"v":"\n- [[c.software.actor-framework]]\n- repo: https://github.com/lucav76/Fibry\n- supports: [[t.cs.languages.java.virtual-threads]]\n","n":0.408}}},{"i":3367,"$":{"0":{"v":"Fermat","n":1},"1":{"v":"\n\n- resources:  [[ar.maggieappleton.programming-portals]]","n":0.577}}},{"i":3368,"$":{"0":{"v":"Fedora","n":1},"1":{"v":"\n- supported_by: [[org.lyrasis]]","n":0.577}}},{"i":3369,"$":{"0":{"v":"Federated Core","n":0.707},"1":{"v":"\n- url: https://www.federated.computer/core/\n\n$59.99\n/ month\n\n    Email\n\n    Nextcloud\n\n    Vaultwarden\n\n    Element and Matrix\n\n    Wordpress\n\n    EspoCRM\n\n    Freescout\n\n    Jitsi\n\n    Listmonk\n\n    Baserow\n\n    Bookstack\n\n    Gitea\n\n    Castopod\n\n    VPN\n\n    Human Support\n\n    Unlimited Users\n\n    Custom Domain\n\n    100% Data Sovereignty\n\n    160 GB Storage ","n":0.177}}},{"i":3370,"$":{"0":{"v":"Feathers","n":1},"1":{"v":"\n- [[c.Software.real_time_framework]]\n- url: https://feathersjs.com/","n":0.5}}},{"i":3371,"$":{"0":{"v":"Faststream","n":1},"1":{"v":"\n- https://faststream.airt.ai/\n- [[c.software.data-framework.streaming]]\n- repo: https://github.com/airtai/faststream\n- written-in: python\n- supports: [[prdct.nats]] [[prdct.kafka]] [[prdct.rabbitimq]]\n- similar: [[prdct.mantis]]\n\n## References\n\n- https://nats.io/blog/nats-supported-by-faststream/","n":0.258}}},{"i":3372,"$":{"0":{"v":"Fastify","n":1},"1":{"v":"\nrepo: https://github.com/fastify/fastify\n\n- [[p.supportedBy]] [[prdct.nestjs]]\n\n## [[p.hasFeature]]\n\n-   **Highly performant:** as far as we know, Fastify is one of the fastest web frameworks in town, depending on the code complexity we can serve up to 76+ thousand requests per second.\n-   **Extendible:** Fastify is fully extensible via its hooks, plugins and decorators.\n-   **Schema based:** even if it is not mandatory we recommend to use [JSON Schema](https://json-schema.org/) to validate your routes and serialize your outputs, internally Fastify compiles the schema in a highly performant function.\n-   **Logging:** logs are extremely important but are costly; we chose the best logger to almost remove this cost, [Pino](https://github.com/pinojs/pino)!\n-   **Developer friendly:** the framework is built to be very expressive and help the developer in their daily use, without sacrificing performance and security.","n":0.091}}},{"i":3373,"$":{"0":{"v":"FastEndpoints","n":1},"1":{"v":"\n- url: https://fast-endpoints.com/\n- ","n":0.577}}},{"i":3374,"$":{"0":{"v":"Fastapi","n":1},"1":{"v":"\n- url: https://fastapi.tiangolo.com/\n- ","n":0.577}}},{"i":3375,"$":{"0":{"v":"Fantasy Name Generator","n":0.577},"1":{"v":"\n- url: https://www.d20srd.org/fantasy/name","n":0.577}}},{"i":3376,"$":{"0":{"v":"Fantasy Grounds","n":0.707},"1":{"v":"\n\n- https://www.fantasygrounds.com\n- [[c.software.rpg.virtual-tabletop]] [[c.software.rpg.virtual-tabletop.fat-client]] \n\n## Features\n\nmeasuring distance is a single right click and pick a pointer(line, square, circle) you wish to measure with. Or you can just target the creature you wish to attack and it will give you distance. Advantage, disadvantage, cover, etc, etc. Are automatic if the DM knows how to apply statuses, that's a click and drag onto the token btw. There is a grid and it's very easy to set. Literally a click and drag to size lol. Loading the active map is as easy as double clicking on the token on your character sheet. Should I go on? \n\n\n## User Stories\n\n### Foundry is unmatched in its user interface. FG is unmatched in its automation. \n\n### better DM prep time \n\n Fantasy Grounds is still much easier on the DM for prep time. With one of the published adventures I can literally run a game with zero preparation beforehand. I wouldn't say it's a great idea, but it can be done. That isn't possible in Foundry. Imported adventures (see below) in Foundry are a long way from the plug-and-play Fantasy Grounds set up.\n\nThe automation in Foundry is actually very limited without community-built-modules. And those modules can be a pain-in-the-butt to get set up and play nice. Fantasy Grounds has the automation built in and doesn't require maintaining a dozen, or more, modules to keep that working. \n\n###  chatbox is just cluttered. \n\nThe format of text and everything it likes to throw in there forces me to sit here and squint every time something happens to figure out the actual result. \n\n### data is mine\n\n- \"Knowing that all my stuff will be mine as long as I want it even if Smiteworks goes bankrupt, and that WotC doesn't have the legal right to revoke my access was huge. Roll20 can cancel your account and you lose all your content. FG is immune to that thanks to the contract language they have. \"\n\n\n## Resources\n\n- https://www.fantasygroundsacademy.com/\n\n## References\n\n- https://www.reddit.com/r/FantasyGrounds/comments/x3s4f4/why_is_fantasy_grounds_so_popular/","n":0.055}}},{"i":3377,"$":{"0":{"v":"Fanfic Ontology","n":0.707}}},{"i":3378,"$":{"0":{"v":"Fan Online Persona Fop","n":0.5},"1":{"v":"\n## References\n\n- [[ar.bringing-communities-to-the-semantic-web-and-the-semantic-web-to-communities]]","n":0.577}}},{"i":3379,"$":{"0":{"v":"FactEngine","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://factengine.ai/\n- [[p.implements]] [[t.cs.data.object-role-modeling]]\n  - \"Use [Object-Role Modeling](https://factengine.ai/index.php/articles/object-role-modeling) to verbalise your enterprise model.\"\n- [[p.builtOn]] [[prdct.typedb]]\n- [[p.hasCreator]] @victor-morgante\n","n":0.236}}},{"i":3380,"$":{"0":{"v":"Fact++","n":1},"1":{"v":"\n- [[c.software.reasoner.tableau]]","n":0.707}}},{"i":3381,"$":{"0":{"v":"Fabric Healer","n":0.707},"1":{"v":"\n- repo: https://github.com/microsoft/service-fabric-healer","n":0.577}}},{"i":3382,"$":{"0":{"v":"FaBiO","n":1},"1":{"v":"\n- https://sparontologies.github.io/fabio/current/fabio.html\n- [[c.ontology.creative-work]]\n- related: [[t.library-science.work_expression_manifestation_item]]\n\n![](/assets/images/2024-08-21-12-23-06.png)\n\n## Highlights\n\n- Fabio:work – A subclass of FRBR work, restricted to works that are published or potentially publishable, and that contain or are referred to by bibliographic references, or entities used to define bibliographic references. FaBiO works, and their expressions and manifestations, are primarily textual publications such as books, magazines, newspapers and journals, and items of their content. However, they also include datasets, computer algorithms, experimental protocols, formal specifications and vocabularies, legal records, governmental papers, technical and commercial reports and similar publications, and also bibliographies, reference lists, library catalogues and similar collections. For this reason, fabio:Work is not an equivalent class to frbr:ScholarlyWork. An example of a fabio:Work is your latest research paper.\n\n## References\n\n- [[ar.works-expressions-manifestations-items-an-ontology]]","n":0.092}}},{"i":3383,"$":{"0":{"v":"EzyFox","n":1},"1":{"v":"\n- repo: https://github.com/youngmonkeys/ezyfox-server\n- related: [[prdct.game-box]]","n":0.447}}},{"i":3384,"$":{"0":{"v":"Eye","n":1},"1":{"v":"\n- [[c.Software.Reasoner]]\n- repo: https://github.com/eyereasoner/eye\n- written_in: prolog\n- supports: [[prdct.notation3]]\n- related: [[prdct.koreografeye]]","n":0.316}}},{"i":3385,"$":{"0":{"v":"Extmodal","n":1},"1":{"v":"\n## References\n\n- https://www.informatik.uni-bremen.de/agbkb/forschung/formal_methods/CoFI/hets/src-distribution/versions/Hets/docs/ExtModal-Logic_ExtModal.html","n":0.577}}},{"i":3386,"$":{"0":{"v":"Extensible Coordination Tools","n":0.577},"1":{"v":"\n- dead\n- https://github.com/behnaaz/extensible-coordination-tools/\n- ","n":0.577}}},{"i":3387,"$":{"0":{"v":"Extended Date Time Format","n":0.5},"1":{"v":"\n## Implementations\n\n- [[prdct.rdf-edtf]]\n- https://www.mediawiki.org/wiki/Extension:Wikibase_EDTF\n\n## References\n\n- https://www.loc.gov/standards/datetime/","n":0.408}}},{"i":3388,"$":{"0":{"v":"Express","n":1}}},{"i":3389,"$":{"0":{"v":"Express Modelling Language","n":0.577},"1":{"v":"\n- https://en.wikipedia.org/wiki/EXPRESS_(data_modeling_language)#EXPRESS-G\n- ","n":0.707}}},{"i":3390,"$":{"0":{"v":"Express Gateway","n":0.707},"1":{"v":"\n- [[p.hasSite]] https://www.express-gateway.io/\n- [[p.builtOn]] [[prdct.express]]","n":0.447}}},{"i":3391,"$":{"0":{"v":"Excaliber","n":1},"1":{"v":"\n[[c.software.game-platform]] \n\n## [[p.supports]]\n\n- [[t.cs.actors]]\n- [[t.cs.entity-component-system]]\n\nurl: https://excaliburjs.com/\n\n- I like the docs! https://excaliburjs.com/docs/api/edge/modules/Events.html \n\n## [[t.pdm.design]]\n\n### Main Loop\n\n![](/assets/images/2023-01-15-19-40-27.png)\n\n### Actor Lifecycle\n\n- ![](/assets/images/2023-01-15-19-39-31.png)\n\n### [[t.cs.entity-component-system]]\n\n#### Built-in Systems\n\n\n\n## [[p.hasDemonstration]]\n\n- https://excaliburjs.com/examples\n  - [[p.builtOn]] [[prdct.storybook]]","n":0.196}}},{"i":3392,"$":{"0":{"v":"Gremlinq","n":1},"1":{"v":"\n- [[c.Software.object-graph-mapper]]\n- url: \"A .NET object-graph-mapper for Apache TinkerPop™ Gremlin enabled databases. \"\n- repo: https://github.com/ExRam/ExRam.Gremlinq\n- supports: [[prdct.gremlin]], [[prdct.neptune]], [[prdct.azure.cosmos-db]] and [[prdct.janusgraph]].\n- similar: [[prdct.ex-ram-gremlinq]] [[prdct.neo4j.ogm]] [[prdct.gqlalchemy]]\n- written_in: c#\n\n## Features\n\n- supports inheritance\n\n\n## Issues\n\n- no transactions on [[prdct.azure.cosmos-db]]","n":0.169}}},{"i":3393,"$":{"0":{"v":"EveXL","n":1},"1":{"v":"\n- https://www.metaphorofitself.net/evexl-introduction","n":0.707}}},{"i":3394,"$":{"0":{"v":"Evernote","n":1}}},{"i":3395,"$":{"0":{"v":"EventStoreDB","n":1},"1":{"v":"\n- url: https://www.eventstore.com/\n- repo: https://github.com/EventStore/EventStore\n- written-in: [[t.cs.languages.c-sharp]]\n\n\n## Resources\n\n- https://www.eventstore.com/blog/keep-your-streams-short-temporal-modelling-for-fast-reads-and-optimal-data-retention","n":0.333}}},{"i":3396,"$":{"0":{"v":"Eventide","n":1}}},{"i":3397,"$":{"0":{"v":"Event Ontology","n":0.707},"1":{"v":"\n- dead\n- https://motools.sourceforge.net/event/event.html\n- [[c.ontology.events]]\n\n## Issues\n\n- doesn't distinguish among fundamental types of events\n\n## Related\n\n-  [[prdct.simple-event-model-ontology]] [[prdct.event-ontology]] [[prdct.lode-ontology]]\n\n## References\n\n- https://www.techscience.com/iasc/v29n2/42943/html\n- [[ar.lode-linking-open-descriptions-of-events]]","n":0.229}}},{"i":3398,"$":{"0":{"v":"Event Model F","n":0.577},"1":{"v":"\n- http://ontologydesignpatterns.org/wiki/Ontology:Event_Model_F\n- RDF:  https://web.archive.org/web/20150919143318if_/http://events.semantic-multimedia.org/ontology/2008/12/15/model.owl\n- built-on: [[prdct.dolce.dns-ultralite]]\n\n![](/assets/images/2024-07-02-12-35-06.png)\n\n\n## Features\n\n- compared to [[prdct.dolce.dns-ultralite]], provides\n  - additional properties and classes for modeling participation in events\n  - parthood relations, causal relations, and correlations between\nevents\n  -  ability to assert that multiple models represent views\nupon or interpretations of the same event\n- causal relationships between events and interpretations of the same event by different humans\n- \"By introducing certain types of events and situations, events can be composed to form more complex situations, such as mereological composi- tions of events or causality relations among events.\" ^uh1jn8phbw3o\n\n\n## Issues\n\n- imports from swiped-domain http://www.loa-cnr.it/ontologies/DUL.owl\n- why are EventType and EventRole equivalent\n- \"the F-Event model does not suggest how to distinguish among different kinds of participants in an event.\" ^le51vrhfwetp\n\n\n## References \n\n- [[ar.f-a-model-of-events-based-on-the-foundational-ontology-dolce-dn-s-ultralite]]\n- [[prdct.descriptions-and-situations-ontology]]\n- [[ar.lode-linking-open-descriptions-of-events]]\n- [[ar.linked-data-and-time-modeling-researcher-life-lines-by-events#^uh1jn8phbw3o]]","n":0.091}}},{"i":3399,"$":{"0":{"v":"Event Model F Prime","n":0.5},"1":{"v":"\n## log\n\n### t.2024.07.02.15\n\n- converted loa-cnr references to ontologydesignpatterns","n":0.354}}},{"i":3400,"$":{"0":{"v":"EventCatalog","n":1},"1":{"v":"\n- [[Diagramming|c.Software.Tools.Diagramming]]\n- url: https://www.eventcatalog.dev/\n- [[p.integratesWith]] [[prdct.asyncapi]]\n- [[p.supports]] \n  - [[prdct.react-flow]] \n  - [[prdct.asyncapi]] https://www.eventcatalog.dev/blog/2022/01/19/releasing-asyncapi-plugin","n":0.267}}},{"i":3401,"$":{"0":{"v":"Eve","n":1},"1":{"v":"\n- #dead since 2019\n- url: https://witheve.com/\n- [[t.cs.sd.literate-programming]]\n- ","n":0.378}}},{"i":3402,"$":{"0":{"v":"Eureca","n":1},"1":{"v":"\n\n- written-in: javascript\n- ","n":0.577}}},{"i":3403,"$":{"0":{"v":"Etke","n":1},"1":{"v":"\n```yaml\nurl: https://etke.cc/\nprovides_hosting: [[prdct.matrix]]\n```\n\nsimilar_to: [[prdct.federated-core]]","n":0.5}}},{"i":3404,"$":{"0":{"v":"Ethereum Virtual Machine","n":0.577}}},{"i":3405,"$":{"0":{"v":"Ethereal Engine","n":0.707},"1":{"v":"\n- [[c.software.metaverse-platform]]\n- url: https://www.etherealengine.org/\n- repo: https://github.com/XRFoundation/XREngine-Control-Center#readme\n- #license [[lic.cpal]] - source modifications must be published, attribution must be prominent\n- written-in: typescript \n- [[p.hadDependancy]] [[prdct.mediasoup]]\n- [[p.basedOn]] [[prdct.bitecs]]\n  \n## Features\n\n- [metaverse control plane](https://www.etherealengine.com/post/ee-release-1)\n- state management uses [hookstate](https://hookstate.js.org/) and [react](https://react.dev/). Together, these tools give reactive, declarative, and controlled state management across any scope.\n- #ecs \n\n## Resources\n\n- https://www.etherealengine.com/blog\n\n","n":0.137}}},{"i":3406,"$":{"0":{"v":"ee-maps","n":1},"1":{"v":"\n- repo: \n- [[p.supports]] [[prdct.geopose]] [[prdct.opencv]]","n":0.408}}},{"i":3407,"$":{"0":{"v":"Digital Beings","n":0.707},"1":{"v":"\n- repo: https://github.com/etherealengine/Digital-Beings\n- written-in: typescript #python\n- [[p.supports]] [[prdct.discord]] [[prdct.twitter]] [[prdct.instagram]] [[prdct.facebook.messenger]] [[prdct.reddit]] [[prdct.telegram]] [[prdct.twilio]] [[prdct.ethereal-engine]] [[prdct.zoom]]","n":0.25}}},{"i":3408,"$":{"0":{"v":"Behave Graph","n":0.707},"1":{"v":"\n- repo: https://github.com/bhouston/behave-graph\n- ","n":0.577}}},{"i":3409,"$":{"0":{"v":"Ethar Geopose","n":0.707},"1":{"v":"\n- url: https://geopose.ethar.com/\n- repo: https://github.com/EtharInc/Ethar.GeoPose\n- [[p.supports]] [[prdct.unity]] c#\n- #related [[prdct.geospatial-creator]] [[prdct.geopose]]","n":0.302}}},{"i":3410,"$":{"0":{"v":"Etebase","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://www.etebase.com/\n","n":0.577}}},{"i":3411,"$":{"0":{"v":"ESSerializer","n":1},"1":{"v":"\n- [[c.software.serializer]]\n- repo: https://github.com/shaochuancs/esserializer\n\n## Issues\n\n- Pro version required for [[t.cs.languages.javascript.symbol]]","n":0.316}}},{"i":3412,"$":{"0":{"v":"ErgoAI","n":1},"1":{"v":"\n- repo: https://github.com/ErgoAI/ErgoEngine\n- written-in: [[t.cs.languages.abl]]","n":0.447}}},{"i":3413,"$":{"0":{"v":"Studio","n":1}}},{"i":3414,"$":{"0":{"v":"Ergoengine","n":1}}},{"i":3415,"$":{"0":{"v":"Equilibrium Engine","n":0.707},"1":{"v":"\n- seems dead\n- [[c.software.game-engine]]\n- repo: https://github.com/clibequilibrium/EquilibriumEngine-CSharp\n- written-in: c#\n- uses: [[prdct.arch]]","n":0.316}}},{"i":3416,"$":{"0":{"v":"Epilog","n":1},"1":{"v":"\n- http://logic.stanford.edu/epilog/homepage/index.php\n- similar: [[t.cs.languages.prolog]] [[prdct.datalog]] [[prdct.game-description-language]]\n\n## Description\n\n- \"Epilog is similar to other logic programming languages, such as Datalog and Prolog, but there are some differences. Like Datalog, Epilog separates data and rules. Like Prolog, Epilog supports data and rules with functional terms. Like both of these languages, Epilog provides the ability to define views of data. However, Epilog also provides a way to express database dynamics. Whereas Prolog treats side effects implicitly using assert and retract as subgoals in view definitions, Epilog enables users to express side effects in the form of operations defined as database transformation\"\n\n## Benefits\n\n### Programming Ease\n\n- Easier to create and modify than traditional programs\n  - Programmers can get by with little or no knowledge of the\n  capabilities of systems executing those programs.\n  - Less work. The specification is the program; no need to\n  make choices about data structures and algorithms.\n  - Easier to learn logic programming than traditional\nprogramming. Think spreadsheets.\n\n\n## References\n\n- http://logicprogramming.stanford.edu/lectures/slides_01.pdf","n":0.08}}},{"i":3417,"$":{"0":{"v":"Env0","n":1},"1":{"v":"\n- [[p.supports]]\n  - [[prdct.terraform]]\n  - [[prdct.terragrunt]]\n  - \"custom flows\"\n  - [[prdct.open-policy-agent]]","n":0.302}}},{"i":3418,"$":{"0":{"v":"Entity Store","n":0.707}}},{"i":3419,"$":{"0":{"v":"Entitas","n":1},"1":{"v":"\n- [[c.software.entity-component-system]]\n- repo: https://github.com/sschmid/Entitas\n- written-in: c#\n\n## Features\n\n- https://github.com/sschmid/Entitas/wiki/Code-Generator\n\n### Language availability\n\n\n    C#\n    C++\n    Clojure !\n    Crystal\n    Erlang\n    F#\n    Go\n    Haskell\n    Java\n    Kotlin\n    Objective-C\n    Python\n    Scala\n    Swift\n    TypeScript\n\n\n## Resources\n\n- https://mzaks.medium.com/let-s-talk-about-relationships-in-entitas-csharp-2aee8efda8b6 deals with how to cleanup entities\n- https://github.com/sschmid/Entitas/wiki/How-I-build-games-with-Entitas-%28FNGGames%29","n":0.169}}},{"i":3420,"$":{"0":{"v":"Enterprise Simulation Platform","n":0.577}}},{"i":3421,"$":{"0":{"v":"Enterprise Architect","n":0.707}}},{"i":3422,"$":{"0":{"v":"Ent Comp","n":0.707},"1":{"v":"\n- dead: since 2022\n- repo: https://github.com/fenomas/ent-comp\n- ","n":0.408}}},{"i":3423,"$":{"0":{"v":"Emscripten","n":1}}},{"i":3424,"$":{"0":{"v":"Emotion Ontology","n":0.707},"1":{"v":"\n- repo: https://github.com/jannahastings/emotion-ontology/\n  - sumo version: http://sigmakee.cvs.sourceforge.net/viewvc/sigmakee/KBs/emotion.kif\n- foundry: [[prdct.obo-foundry]]\n\n## Selection\n\n![](/assets/images/2024-05-31-14-18-06.png)\n","n":0.316}}},{"i":3425,"$":{"0":{"v":"Emotion Frame Ontology","n":0.577},"1":{"v":"\n- The OWL version of DOLCE\n([[prdct.dolce.d0]]) is used because it fits the cognitive aspects considered in this work, and includes the Description&Situation [24] ODP, which enables a rei-\nfied relational modelling of an emotion as both a :ConceptualFrame, and its occurrences as emotion situations (as an :EmotionSituation)\n\n## References\n\n- [[ar.arxiv.the-emotion-frame-ontology]]","n":0.144}}},{"i":3426,"$":{"0":{"v":"EmoKG","n":1},"1":{"v":"\n- url: \n  - http://ontologydesignpatterns.org/wiki/Ontology:Emotional_Knowledge_Graph_%28EmoKG%29","n":0.447}}},{"i":3427,"$":{"0":{"v":"Emf","n":1},"1":{"v":"\n- url: https://projects.eclipse.org/projects/modeling.emf.emf\n- ","n":0.577}}},{"i":3428,"$":{"0":{"v":"Emergence Sdk","n":0.707},"1":{"v":"\n- [[c.Software.Web3]]\n- url: https://www.emergence.site/\n\n## Components\n\n- [[prdct.emergence-sdk.emergence-avatar-service]]\n- [[prdct.emergence-sdk.inventory-service]]\n## Use Cases\n\n- game collectibles that are interoperable across experiences\n- crafting with NFT ingredients that outputs an NFT\n- avatars\n- on-chain game logic (Lamina1) - gassless [[prdct.ethereum-virtual-machine]]\n  - if there's no gas cost, how you prevent spamming/DOS\n\n## Features\n\n- dynamic metadata\n\n\n## Resources\n\n- https://docs.emergence.site/introduction/readme\n- https://docs.emergence.site/game-engines/unity/sample-code/how-to-use-emergence-with-lamina-1 \n- https://docs.emergence.site/game-engines/unreal/sample-code/lamina1-integration \n","n":0.14}}},{"i":3429,"$":{"0":{"v":"Inventory Service","n":0.707}}},{"i":3430,"$":{"0":{"v":"Emergence Avatar Service","n":0.577}}},{"i":3431,"$":{"0":{"v":"Ember.js","n":1}}},{"i":3432,"$":{"0":{"v":"Elsa","n":1},"1":{"v":"\n- [[c.software.workflow]] [[c.software.business-process-management]]\n- repo: https://github.com/elsa-workflows/elsa-core\n- different_from: [[prdct.elsa-speak]]\n- similar: [[prdct.copper]]\n\n## Features\n\n- multi-tenancy coming in 3.1?\n-   Support for both short-running and long-running workflows.\n-   A web-based drag & drop designer with support for custom activities.\n-   Native support for activity composition, including activities like `Sequence`, `Flowchart`, and `ForEach`.\n-   Parallel execution of activities.\n-   Built-in activities for common scenarios, such as sending emails, making HTTP calls, scheduling tasks, sending and receiving messages, and more.\n-   Workflow versioning and migration via API.\n-   Easy integration with external applications via HTTP, message queues, and more.\n-   Actor model for increased workflow throughput. (used [[Proto.Actor|prdct.proto-actor]])\n-   Dynamic expressions with support for C#, JavaScript, Python, and Liquid.\n-   Alterations API: Modify existing workflow instances at runtime.\n-   activities can schedule other activities\n-   Service Bus Broker: [[prdct.rebus]] for sending messages via service bus brokers. Out of the box, it uses a memory provider.\n-   Distributed Lock Provider: filesystem, [[prdct.redis]], [[prdct.sql-server]], Azure\n-   Distributed Temporal Services: A temporal service provides functionality to schedule a workflow to execute at a specific time and/or on a recurring interval. Elsa uses these services to implement the Timer, Cron and StartAt activities; supports [[prdct.quartz-net]] and [[prdct.hangfire]]\n\n## Cons\n\n- The designer is not yet fully embeddable in other applications; this feature is planned for a future release.\n- The designer currently only supports Flowchart activities. Support for Sequence and StateMachine activities is planned for a future release.\n- UI input validation is not yet implemented.\n\n## Tips\n\n-  you might be able to achieve [per-user execute permission] by setting up a Policy from Program.cs that has a set of Requirements that the inbound principal needs to meet. From the HTTP endpoint activity, you then tock the \"Authorize\" checkboz and then provide the name of the Policy to evaluate.\n-  Short-running Workflows can be useful to implement a business rules engine, while long-running workflows greatly simplify the implementation of complex processes that involve coordinating between multiple agents (users & machines).\n-  [How to Dynamically Create Workflows in Elsa Using C#? · elsa-workflows/elsa-core · Discussion #4425 · GitHub](https://github.com/elsa-workflows/elsa-core/discussions/4425) suggests checking out BlobStorageWorkflowProvider and ClrWorkflowProvider\n\n## Resources\n\n- https://sipkeschoorstra.medium.com/part-7-of-building-workflow-driven-net-applications-with-elsa-2-e369e7784555\n- https://sipkeschoorstra.medium.com/elsa-3-0-2b341e7cbfa7\n- https://medium.com/codenx/elsa-workflow-engine-in-net-core-applications-812b745b7385\n- https://sipkeschoorstra.medium.com/orchestrating-intelligent-agents-with-elsa-workflows-f3346b91dc17","n":0.055}}},{"i":3433,"$":{"0":{"v":"Elsa Speak","n":0.707},"1":{"v":"\n- [[c.software.ai.speech-coach]] [[c.software.ai.speech-recognition]]","n":0.577}}},{"i":3434,"$":{"0":{"v":"Elixir","n":1},"1":{"v":"\n- [[c.programminglanguage]]\n- related: [[t.cs.languages.erlang]], [[prdct.phoenix]]\n\n## Strenghts\n\nElixir is a functional, concurrent programming language designed for building scalable and maintainable applications. Its key strengths include:\n\n1. **Concurrency**: Built on the Erlang VM (BEAM), Elixir excels at handling many concurrent processes, making it ideal for distributed systems.\n2. **Fault Tolerance**: It supports robust error handling, allowing systems to recover from failures gracefully.\n3. **Scalability**: Elixir can efficiently manage thousands of simultaneous connections.\n4. **Performance**: Its lightweight processes lead to high performance in real-time applications.\n5. **Ecosystem**: The Phoenix framework, part of the Elixir ecosystem, is particularly powerful for web development.\n\n## References\n\n- @chatgpt.4o","n":0.103}}},{"i":3435,"$":{"0":{"v":"Eleventy","n":1},"1":{"v":"\n- https://www.11ty.dev/\n- [[c.software.web.ssg]]\n- repo: https://github.com/11ty/eleventy\n- written-in: javascript\n\n## Features\n\n- by default, Eleventy can load data from JSON files, and the fields from those files can then be used in templates. However, support for other formats can also be added, by passing in a function that takes the input file and outputs a JavaScript object\n\n## Resources\n\n- https://11ty.rocks/posts/going-beyond-static-with-eleventy/","n":0.135}}},{"i":3436,"$":{"0":{"v":"Element","n":1},"1":{"v":"\nurl: https://matrix.org/docs/projects/client/element\nrepo: https://github.com/vector-im/element-web/\n\n- written-in: typescript","n":0.447}}},{"i":3437,"$":{"0":{"v":"Elasticsearch","n":1}}},{"i":3438,"$":{"0":{"v":"Ejabberd","n":1}}},{"i":3439,"$":{"0":{"v":"Ego","n":1},"1":{"v":"\n## References\n\n- https://www.ycombinator.com/launches/KeD-ego-an-ai-native-3d-simulation-engine-getting-us-closer-to-the-matrix-one-pixel-at-a-time\n  - highlight: \"In the age of Gen AI, it is finally possible to build a game engine that is also a game.\"","n":0.2}}},{"i":3440,"$":{"0":{"v":"Egeria","n":1},"1":{"v":"\n- [[c.software.data-discovery]]\n- url: https://egeria-project.org/\n- built_on: [[prdct.xtdb.v1]]\n\n- \"Egeria supports an integration of different catalogs through a metadata event bus, but it doesn’t seem to be feature complete yet as of this writing. \" t.2020.12.07\n\n## Topics\n\n### Roles vs Personas\n\n- https://egeria-project.org/practices/coco-pharmaceuticals/roles-vs-personas/overview/ \n- ![](/assets/images/2024-03-02-23-34-16.png)\n- roles have a context. \n  - For example, Tessa is a manager, but not for everyone in Coco Pharmaceuticals. She is a manager of a specific team. Similarly, she may be a system owner, but not of all systems.\n- roles have a scope \"and as we design the Egeria software, we need to be sure that this code is included with the definition of the role. We also need to ensure roles can be combined together to form the complete \"job\" that an individual performs.\"\n\n### Schema\n\n- \"A schema describes the structure of the data associated with an Asset. The technology that supports the asset often limits the structural choices for data. For example:\n\n    A relational database organizes data into collections of tables and columns.\n    Technologies such as JSON or XML, organizes data into nested structures.\n    Graph databases organizes data in nodes and relationships.\n\nThese differences need to be represented in the Open Metadata Types. However, at the same time, data governance is concerned with the accuracy and appropriate use of individual data values. This is very expensive if each data item was governed individually so the data governance practices aim to group like data together, so they can be governed in a consistent way. As such, the open metadata types provide a root set of types that all the specific schema structures inherit from.\"\n- https://egeria-project.org/concepts/schema/\n\n\n## Examples\n\n- The Egeria community uses the Coco Pharmaceuticals personas to test that there is easy movement from role to role.\n\nThis is implemented as follows:\n\n  - Each person has a personal profile (stored as Person entity) that describes the individual (persona).\n  - The Egeria community uses the Coco Pharmaceuticals [personas](https://egeria-project.org/practices/personas/overview) to test that there is easy movement from role to role.\n\nThis is implemented as follows:\n\n-   Each person has a personal profile [(stored as Person entity)](https://egeria-project.org/types/1/0112-People) that describes the individual (persona).\n-   Linked off of the personal profile are person roles [(stored as PersonRole entity](https://egeria-project.org/types/1/0112-Peoplel) that define each role (and their associated scope) that the person performs.\n\nThe profile and role are managed primarily by the [Community Profile OMAS](https://egeria-project.org/services/omas/community-profile/overview) and this drives the display on Egeria's user interfaces as well as some aspects of security.\n","n":0.05}}},{"i":3441,"$":{"0":{"v":"EE_variant","n":1},"1":{"v":"\n- [[p.isRelated]] [[prdct.gltf]]","n":0.577}}},{"i":3442,"$":{"0":{"v":"Edtf Ontology","n":0.707},"1":{"v":"\n- https://periodo.github.io/edtf-ontology/\n- repo: https://github.com/periodo/edtf-ontology\n- authors: @ryan-shaw\n\n- related: [[prdct.extended-date-time-format]]\n  \n## Discussion\n\n### Goal of this repository\n\n- from https://github.com/periodo/edtf-ontology/discussions/3\n\n- @ryan-shaw: \"In PeriodO and in most of the placename gazetteer projects, people seem to be doing fine with some variation of earliest-start / latest-start / earliest-end / latest-end (with only the first of these required).\"\n- mentions: [[prdct.edtf-humanize]] \n\n\n## References\n\n- https://lists.w3.org/Archives/Public/semantic-web/2020Jul/0200.html","n":0.134}}},{"i":3443,"$":{"0":{"v":"Edtf Humanize","n":0.707},"1":{"v":"\n- repo: https://github.com/corylown/edtf-humanize\n- written-in: ruby\n- related: [[prdct.extended-date-time-format]]","n":0.378}}},{"i":3444,"$":{"0":{"v":"Ecsy","n":1},"1":{"v":"\n- dead: since 2022\n- [[c.software.entity-component-system]]\n- repo: https://github.com/ecsyjs/ecsy\n- written-in: javascript\n","n":0.333}}},{"i":3445,"$":{"0":{"v":"Ecscala","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/atedeg/ecscala","n":0.5}}},{"i":3446,"$":{"0":{"v":"EclipseStore / MicroStream","n":0.577},"1":{"v":" \n- url: https://microstream.one/\n- repo: https://github.com/microstream-one/microstream\n- aka: MicroStream\n- [[p.usedBy]] [[prdct.helidon]] [[prdct.micronaut]] [[prdct.rapidclipse]]\n- supports: java kotlin scala groovy clojure android [[prdct.graalvm]]\n\n## Features\n\n- There is no need to use special query languages like SQL. All operations can be done with plain Java... One possibility may be Streams if you use the standard Java collections.\n  - \"Of course you must care about [lazy loading](https://docs.microstream.one/manual/storage/queries.htmlloading-data/lazy-loading/index.html) if you use that feature.\"\n\n\n## References\n\n- https://medium.com/@zakgof/microstream-performance-large-collection-search-3be4fbd48b92","n":0.122}}},{"i":3447,"$":{"0":{"v":"Eclipse","n":1}}},{"i":3448,"$":{"0":{"v":"Eclipse Lyo","n":0.707},"1":{"v":"\n- related: [[prdct.oslc]] ","n":0.577}}},{"i":3449,"$":{"0":{"v":"Lyo Designer","n":0.707},"1":{"v":"\n## Features\n\nLyo Designer includes a integrated code generator that synthesizes the model into almost-complete Lyo-compliant running implementation. The resulting code includes:\n\n    Java classes with appropriate Lyo annotations to reflect the modelled RDF resource shapes\n        This automates the marshaling/unmarshaling of Java instances as Linked Data RDF resources.\n    JAX-RS Service operations for accessing, updating, creating and deleting RDF resources.\n        These operations handle any of the supported formats (turtle, RDF/XML, Json, etc.)\n        For debugging purposes, JSP pages are also produced to deliver HTML representations of all RDF resources.\n    JAX-RS Service operations to completely handle Delegated UI for both creation and selection dialogs.\n        Including the initial generation of basic JSP pages for the html-representation of the dialogs.\n    JAX-RS Service operations to handle Resource Preview\n        Including the initial generation of basic JSP pages for the html-representation of the resource previews.\n\nLyo Designer supports incremental development, where manual changes to the generated code are preserved upon changes to the model, and subsequent code regeneration.","n":0.08}}},{"i":3450,"$":{"0":{"v":"Eclipse Constraint Logic Programming","n":0.5},"1":{"v":"\n- dead-ish\n- repo: https://sourceforge.net/projects/eclipse-clp/files/\n- url: https://eclipseclp.org","n":0.408}}},{"i":3451,"$":{"0":{"v":"ECJ","n":1},"1":{"v":"\n- [[c.Software.Simulation-Framework]] \n- https://cs.gmu.edu/~eclab/projects/ecj/\n- repo: https://github.com/GMUEClab/ecj\n- ","n":0.408}}},{"i":3452,"$":{"0":{"v":"Ebucore","n":1},"1":{"v":"\n- repo: https://github.com/ebu/ebucore\n- docs: https://tech.ebu.ch/docs/tech/tech3293.pdf\n\n## Features\n\n-  'props', 'costumes', 'timed text, ''actions and ''emotions' (among others) can be associated to scenes and persons or character","n":0.204}}},{"i":3453,"$":{"0":{"v":"Easy Rules","n":0.707},"1":{"v":"\n- dead since 2021\n- [[c.Software.Rules-Engine]]\n- repo: https://github.com/j-easy/easy-rules\n![[prdct.jess.rules-language#^cmcaoqsy0ccx]]\n- supports: [[prdct.jexl]]\n\n## Description\n\n- Easy Rules is a simple Java rules engine providing a lightweight and POJO based framework to define business. It can create complex rules from primitive ones by using the composite pattern.\n\n- This framework, in contrast to the most traditional rules engines, doesn’t make use of XML files or any Domain Specific Language files to segregate rules from the application. It uses annotation-based classes and methods for injecting business logic into the application.\n- Easy Rules can be handy for developers to create and maintain applications with business logic that’s entirely separated from the application itself. On the other hand, as this framework doesn’t implement the JSR94 standard and the business logic has to be coded straight to Java code.\n\n\n## References\n\nhttps://www.baeldung.com/java-rule-engines","n":0.088}}},{"i":3454,"$":{"0":{"v":"Earthly","n":1},"1":{"v":"\n- url: https://earthly.dev/","n":0.577}}},{"i":3455,"$":{"0":{"v":"Earth System Modeling Framework","n":0.5},"1":{"v":"\n- #aka ESMF\n- url: https://earthsystemmodeling.org/","n":0.447}}},{"i":3456,"$":{"0":{"v":"Eagle","n":1},"1":{"v":"\n## Features\n\n- backed by distributed database management systems, i.e., [[prdct.opentsdb]] for temporal data and [[prdct.elasticsearch]] for spatial data\n\n## Related Solutions\n\n- [[prdct.jena]] [[prdct.elasticsearch]] [[prdct.opentsdb]]\n\n## References\n\n- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6832792/","n":0.2}}},{"i":3457,"$":{"0":{"v":"E2core","n":1},"1":{"v":"\n- dead? acquired by f5?\n- repo: https://github.com/suborbital/e2core\n- written-in: #go\n- [[p.builtOn]] [[prdct.wasm]]","n":0.302}}},{"i":3458,"$":{"0":{"v":"E","n":1},"1":{"v":"\n- http://erights.org/\n- ","n":0.707}}},{"i":3459,"$":{"0":{"v":"Dynamic Language Runtime","n":0.577},"1":{"v":"\n## Resources\n\n- https://learn.microsoft.com/en-us/dotnet/framework/reflection-and-codedom/dynamic-language-runtime-overview\n- ","n":0.577}}},{"i":3460,"$":{"0":{"v":"Dynamic Expresso","n":0.707},"1":{"v":"\n- c#\n- repo: https://github.com/dynamicexpresso/DynamicExpresso","n":0.5}}},{"i":3461,"$":{"0":{"v":"Dungeon Fog","n":0.707},"1":{"v":"\n- [[c.software.rpg]]\n- [[p.hasURL]] https://www.dungeonfog.com/\n- [[p.hasApplication]] [[t.cs.game.rpg]] \n","n":0.378}}},{"i":3462,"$":{"0":{"v":"Dungeon Alchemist","n":0.707},"1":{"v":"\n- https://www.dungeonalchemist.com/\n- wiki: https://dungeonalchemist.fandom.com/wiki/DungeonAlchemist","n":0.5}}},{"i":3463,"$":{"0":{"v":"Duktape","n":1},"1":{"v":"\n- [[c.software.script-engine]]\n- https://duktape.org/\n\n## References\n\n- https://janus.conf.meetecho.com/docs/duktape.html","n":0.447}}},{"i":3464,"$":{"0":{"v":"Dublin Core","n":0.707}}},{"i":3465,"$":{"0":{"v":"Type Vocabulary DCMITYPE","n":0.577},"1":{"v":"\n- https://www.dublincore.org/specifications/dublin-core/dcmi-terms/#section-7","n":0.707}}},{"i":3466,"$":{"0":{"v":"Dublin Core Metadata Element Set (DCMES)","n":0.408},"1":{"v":"\n- https://www.dublincore.org/specifications/dublin-core/dces/\n- related: [[prdct.dublin-core.metadata-element-set-dces]]\n\n## 15 core elements\n\n- contributor\n- coverage (spatial, temporal, jurisdicational)\n- creator\n- date\n- description\n- format\n- identifier\n- language\n- publisher\n- relation (\"a related resource\")\n- rights\n- source\n- subject (keywords, key phrases, classification codes, or other controlled vocab)\n- type (recommend [[prdct.dublin-core.type-vocabulary-dcmitype]])","n":0.162}}},{"i":3467,"$":{"0":{"v":"dScryb","n":1},"1":{"v":"\n- [[c.software.rpg]]\n- url: https://dscryb.com\n\n## [[c.model.business]]\n\n- tiered subscription\n![](/assets/images/2023-10-10-16-03-56.png)\n- commissioned character illustrations\n\n## [[c.model.licensing]]\n\n- Send us an email and there is an extremely good chance that we’ll grant you permission to reproduce or narrate a scene or scenes, for free, in your publication or broadcast. Same goes with playing Michael Ghelfi Studios & dScryb's original music, ambiences, and sound effects from the Sonic Library. Typically, all we ask is that you provide your audience with attribution of the content to dScryb, including our URL.\n\n## Resources\n\n- [ ] [How To Write Boxed Text for Your Favorite RPG](https://dscryb.com/thinking-inside-the-box/)","n":0.104}}},{"i":3468,"$":{"0":{"v":"Dropwizard","n":1},"1":{"v":"\n- [[c.software.web.rest-framework]]\n- url: https://www.dropwizard.io\n- ","n":0.5}}},{"i":3469,"$":{"0":{"v":"Drools","n":1},"1":{"v":"\n- [[c.software.rules-engine]]\n\n## Features\n\n### Complex Event Processing (CEP)\n\n- https://docs.jboss.org/drools/release/8.44.0.Final/drools-docs/drools/rule-engine/index.html#cep-con_rule-engine\n  - \n\n## Cons\n\n- \"lacks of a complex execution model: there is no proper notion of a module hence you cannot perfectly isolate one rule from another, or to properly partition the working memory. As the rule base increases in complexity, it will become harder and harder to understand which rules trigger and why.\"\n\n## References\n\n- https://developer.jboss.org/servlet/JiveServlet/download/14964-126-12133/SottaraD-ontorules.pdf","n":0.126}}},{"i":3470,"$":{"0":{"v":"Swrlapi","n":1},"1":{"v":"\n- repo: https://github.com/protegeproject/swrlapi-drools-engine\n\n## Issues\n\n- [[prdct.owl.rl]]","n":0.447}}},{"i":3471,"$":{"0":{"v":"Drools Semantic Module","n":0.577},"1":{"v":"\n- dead since 2011\n- https://github.com/salaboy/drools-semantics\n\n## References\n\n- https://blog.kie.org/2007/12/drools-extensible-process-definition-language-epdl-and-the-semantic-module-framework-smf.html","n":0.378}}},{"i":3472,"$":{"0":{"v":"Droid","n":1},"1":{"v":"\n- repo: https://github.com/ontodev/droid\n- written_in: clojure","n":0.447}}},{"i":3473,"$":{"0":{"v":"Drizzle","n":1},"1":{"v":"\n- [[c.software.game-platform]]\n- written-in: typescript\n\n## Resources\n\n- https://medium.com/@aleksandrblokh/weve-built-typescript-orm-for-821-days-then-this-happened-71282a8b0206","n":0.408}}},{"i":3474,"$":{"0":{"v":"DriftDB","n":1},"1":{"v":"\n- [[c.Software.real_time_framework]]\n- no commits since Aug. '23\n- url: https://driftdb.com/\n- written_in: rust\n- repo:  https://github.com/drifting-in-space/driftdb\n\n## Description\n\nClients connect to it directly over a WebSocket. It supports a number of messaging primitives, including:\n\n-   Publisher / subscriber channels (PubSub)\n-   Key/value storage with subscriptions\n-   Ordered streams\n\n## Use cases\n\nAs a general rule, DriftDB is useful any time you wish you could connect directly from one browser to another, or from a non-web-connected backend (e.g. background task) to a browser. Examples include:\n\n- Backend for state synchronization in real-time collaborative apps (e.g. a whiteboard or casual multiplayer game)\n- Streaming build logs in real time in a CI/CD system\n- WebRTC signaling\n\n## Demos\n\n- [Voxel Editor](https://demos.driftdb.com/voxel?_driftdb_room=NsCCT2QyUhIRAL6w9yeTDeae) #cool\n\n## References\n\n- https://news.ycombinator.com/item?id=34639728","n":0.097}}},{"i":3475,"$":{"0":{"v":"Dpmn Discrete Event Process Modeling Notation","n":0.408},"1":{"v":"\n- https://dpmn.info/\n- related: [[prdct.sigma-event-graph-simulation-modeling]]\n- creator: @gerd-wagner\n- related: [[prdct.oesjs]]\n\n## Features\n\n\n    It has an ontological/conceptual foundation based on objects, events and causal regularities in the form of event rules\n    It has a formal semantics based on the semantics of Event Graphs of (Wagner 2017)\n    It integrates the objects that participate in events and activities\n    It allows general forms of declarative resource modeling with resource roles, resource pools and constraints\n    It allows modeling both Activity Networks and Processing Networks\n\n## Examples\n\n- https://sim4edu.com/oesjs/core2/load-haul-dump-1/ [[prdct.sim4edu]]\n- https://sim4edu.com/oesjs/core4/signaling-game-1/","n":0.112}}},{"i":3476,"$":{"0":{"v":"dotNetRDF","n":1},"1":{"v":"\n- supports: [[prdct.RDF-star]] [[prdct.sparql.star]]\n- supports: [[prdct.allegrograph]] [[prdct.virtuoso]] [[prdct.jena]] [[prdct.stardog]]\n- author: @ruben-taelman\n\n## Description\n\n- A complete library for parsing, managing, querying and writing RDF.\n- A common .NET API for working with RDF triple stores such as AllegroGraph, Jena, Stardog and Virtuoso.\n- A suite of command-line and GUI tools for working with RDF under Windows\n\n## Questions\n\n- any advantage to one backend over the other?\n  - https://github.com/dotnetrdf/dotnetrdf/discussions/491 makes it sound like native virtuoso is out, but no big loss\n  - probably best to use the sparql interface anyhow unless you have a reason not to. ","n":0.105}}},{"i":3477,"$":{"0":{"v":"Dominion Ecs Java","n":0.577},"1":{"v":"\n- [[c.Software.Entity-Component-System]]\n- repo: https://github.com/dominion-dev/dominion-ecs-java\n\n## Pros\n\n- component types can be both classes and records\n\n## Cons\n\n- archetype-based\n- maybe not the best dx\n- new\n- dying?","n":0.213}}},{"i":3478,"$":{"0":{"v":"DOLCE","n":1},"1":{"v":"\n- http://www.loa.istc.cnr.it/index.php/dolce/\n- [[c.ontology]] [[c.ontology.upper]]\n- repo: https://github.com/appliedontolab/DOLCE\n- similar: [[prdct.dolce.lite]] [[prdct.dolce.dns-ultralite]]  [[prdct.dolce.d0]]\n- related: [[prdct.colore]]\n- terms: https://github.com/gruninger/colore/blob/master/ontologies/dolce/DOLCE-Terms.docx\n\n![](/assets/images/2024-07-05-21-58-59.png)\n\n## Thoughts\n\n- where's the universals?\n\n## Elements\n\n### Stative\n\n#### State\n\nWithin stative occurrences, we distinguish between  states and processes according to homeomericity: sitting is classified as a state  but running is classified as a process, since there are (very short) temporal parts  of a running that are not themselves runnings.In general, states differ from situations because they are not assumed to have a description from which they depend. They can be sequenced by some course, but they do not require a description as a unifying criterion.On the other hand, at any time, one can conceive a description that asserts the constraints by which a state of a certian type is such, and in this case, it becomes a situation.Since the decision of designing an explicit description that unifies a perdurant depends on context, task, interest, application, etc., when aligning an ontology do DLP, there can be indecision on where to align a state-oriented class. For example, in the WordNet alignment, we have decided to put only some physical states under 'state', e.g. 'turgor', in order to stress the social orientedness of DLP. But whereas we need to talk explicitly of the criteria by which we conceive turgor states, these will be put under 'situation'.Similar considerations are made for the other types of perdurants in DOLCE.A different notion of event (dealing with change) is currently investigated for further developments: being 'achievement', 'accomplishment', 'state', 'event', etc. can be also considered 'aspects' of processes or of parts of them. For example, the same process 'rock erosion in the Sinni valley' can be conceptualized as an accomplishment (what has brought the current state that e.g. we are trying to explain), as an achievement (the erosion process as the result of a previous accomplishment), as a state (if we collapse the time interval of the erosion into a time point), or as an event (what has changed our focus from a state to another).In the erosion case, we could have good motivations to shift from one aspect to another: a) causation focus, b) effectual focus, c) condensation d) transition (causality).If we want to consider all the aspects of a process together, we need to postulate a unifying descriptive set of criteria (i.e. a 'description'), according to which that process is circumstantiated in a 'situation'. The different aspects will arise as a parts of a same situation.\n\n### Spaces and Places in DOLCE\n\n    Space:\n        In DOLCE, a Space (or Space Region) is an abstract, often continuous entity that provides a context for locating other entities. It is more about the conceptual or physical extent without specific delineations or functional attributes.\n        Spatial Region (dolce\n        ): An abstract region of space where objects and places can be located.\n\n    Place:\n        A Place in DOLCE is typically a spatial region with some sort of defined boundary or significance. It is often associated with a particular function, meaning, or context.\n        Physical Place (dolce\n        ): A location that is often defined by physical boundaries or significant contextual features. It can be a part of a space but is distinguished by its specific role or context.\n\n## References\n\n- [[ar.ontology-infrastructure-for-the-semantic-web]]\n- http://www.loa.istc.cnr.it/dolce/overview.html\n    - mentions [[prdct.unified-foundational-ontology]]\n- http://www.thezfiles.co.za/ROMULUS/ontologies/DOLCE-No-Quality-Qualia.owl\n- [old site](http://www.loa.istc.cnr.it/old/Files/dolce.html)\n- [[ar.dolce-a-descriptive-ontology-for-linguistic-and-cognitive-engineering]]","n":0.043}}},{"i":3479,"$":{"0":{"v":"Systems Lite","n":0.707},"1":{"v":"\n- http://www.ontologydesignpatterns.org/ont/dul/SystemsLite.owl\n- [[c.ontology.extension]]\n- ","n":0.577}}},{"i":3480,"$":{"0":{"v":"DOLCE Plans Lite","n":0.577},"1":{"v":"\n- http://www.ontologydesignpatterns.org/ont/dul/PlansLite.owl\n- [[c.ontology.extension]]\n- ","n":0.577}}},{"i":3481,"$":{"0":{"v":"Lite","n":1},"1":{"v":"\n- vapor? [[prdct.dolce.lite-plus]]\n\n## References\n\n- http://www.loa.istc.cnr.it/index.php/dolce/","n":0.447}}},{"i":3482,"$":{"0":{"v":"DOLCE Lite-Plus","n":0.707},"1":{"v":"\n- url: http://www.loa.istc.cnr.it/old/ontologies/DLP3971.zip\n\n![](/assets/images/2024-06-05-23-48-20.png)\n\n## Expressivity\n\nthe current state (for 397) of the DLP library is:\n`DL` Expressivity (for the complete library): SHION(D) [within OWL-DL]\n`S` == ALCR+\n`AL` - Attribute Logic: Conjunction, Universal Value Restriction, Limited Existential Quantification\n`C` - Complement (together with AL allows Disjunction, Full Existential Quantification)\n`R+` - Role Transitivity\n`H` - Role Hierarchy\n`I` - Role Inverse\n`O` - Nominal\n`N` - Unqualified Number Restrictions\n`(D)` - Datatypes\n\n\n\n## Description\n\nThe lite versions of DOLCE are simplified translations of DOLCE into various logical languages. They are maintained for several reasons: 1. allowing the implementation of DOLCE-based ontologies in languages that are less expressive than FOL. In particular, DOLCE-Lite does not make use of S5 modalities and of some temporally-indexed relations. Modal operators are not heavily exploited in DOLCE, then the consequences are not very harmful for most uses. Temporal indexing is partly supported by composing originally indexed relations with temporal location relations. Even this support is not provided for description logic versions of DOLCE-Lite like DAML+OIL, OWL-DL, etc. 2. allowing a description-logic-like naming policy for DOLCE signature. In many cases, different names are adopted for relations that have the same name but different arities in the FOL version, or for relations that have polymorphic domains 3. allowing extensions of DOLCE that do not have a detailed axiomatization yet, and modularizing them (placeholders) 4. taking benefit of the services of certain implemented languages -specially the classification services provided by description logics- in order to support domain applications The DLP ontology library is currently maintained in two languages: a dialect of KIF3.0 (PL), and DAML+OIL. The first one contains a complete code for the library, including theWordNet alignment modules. The second one contains the library (according to available costructs of DAML+OIL) without the WordNet code, since it is very simple and takes much space. DLP+KIF is currently used in some applications that need deep inferences, which can only be provided by expressive, logic-programming-enabled languages. DLP+DAML is currently used in Semantic Web applications, for example in the Core Ontology for Services (COS). The extensions to DOLCE presented in the library are work in progress, and although some of them have been tested in realistic applications, they should be taken cautiously from the viewpoint of rigorous formal ontology.\n\n### Comment from OWL file\n\nThe version 3.9 of DOLCE-Lite (updated to D18 of            DOLCE-Full) with  some basic extensions, called            DOLCE-Lite-Plus, or DLP.  The ontology graph in this version            is the following:            ------Backbone:            http://www.loa-cnr.it/ontologies/DOLCE-Lite#            http://www.loa-cnr.it/ontologies/TemporalRelations#            http://www.loa-cnr.it/ontologies/SpatialRelations#            http://www.loa-cnr.it/ontologies/ExtendedDnS# [includes a minimal            action and process theory]            ------Basic            extensions:            http://www.loa-cnr.it/ontologies/FunctionalParticipation#            http://www.loa-cnr.it/ontologies/Plans#            http://www.loa-cnr.it/ontologies/InformationObjects#            http://www.loa-cnr.it/ontologies/SocialUnits#            http://www.loa-cnr.it/ontologies/Collections#            http://www.loa-cnr.it/ontologies/Collectives#            http://www.loa-cnr.it/ontologies/CommonSenseMapping#            -----Experimental extensions:            http://www.loa-cnr.it/ontologies/MentalObjects# [just a placeholder]            http://www.loa-cnr.it/ontologies/Systems#            http://www.loa-cnr.it/ontologies/SemioticCommunicationTheory#            http://www.loa-cnr.it/ontologies/Causality#            http://www.loa-cnr.it/ontologies/ModalDescriptions#            The backbone of the library is constituted by:           (1)            DOLCE-Lite,             which is an encoding of most            predicates formalized in DOLCE-Full             (S5 and KIF            versions), as presented in the Deliverable D18            of the WonderWeb EU Project            (http://wonderweb-semanticweb.org).           (2) two sets            of temporal relations defined over perdurants            which are adapted from Allen's temporal calculus, and            of spatial relations that simplify the expression of places            and locations from particulars to regions, and           (3) the DnS            (Descriptions and Situations) ontology, which provides a            vocabulary to talk of reified (social) entities such as            relations,             roles, contexts,  situations,            parameters, etc. Appropriate             relations link DnS            reifications to DOLCE-Lite non-reified             entities.            The reification ontology of DnS includes a minimal            vocabulary for action and process theory, following the main            assumptions in situation and action theories, like Situation            and Attitudes, BDI, etc.            The backbone has a stratification, so that TemporalRelations, SpatialRelations, and Extended DnS all inherit the DOLCE-Lite ontology.                 Based on that            backbone, other wide-scoping             ontologies are            provided: (4) ontology of information             objects,            based on semiotics, which provides a vocabulary to            talk of languages, expressions vs. meaning, logical vs.            physical documents, reference, etc. (5) a well-developed ontology of            plans and tasks, containing also a set of individual tasks            that provide grounded primitives to specify process types:            this is             the OWL port of a FOL version as            presented in the Deliverable             D07 of the Metokis            EU Project: http://metokis.salzburgresearch.at;            (6) a preliminary ontology of functional participation            relations, which provide a vocabulary for event-oriented            relations encoded by linguistic verbs (in Western            languages), like  'performs' or 'makes';            (7) an ontology for collections and collectives; (8) a set of            common sense mappings, introduced to support a mapping to            WordNet  (contained in another file).  Besides these basic            extensions, which are currently exploited in several            application  domains, and are actively under development,            there are also some less developed ontologies, all bases on            the backbone, but still at a preliminary and debatable            stage. They are included here as placeholders, and are used            by some applications, but they are not yet stable.            *******Scope of DOLCE-Lite-Plus*******  The lite            versions of DOLCE are simplified translations of DOLCE            into various logical languages. They are maintained for            several reasons:    1. allowing the implementation of            DOLCE-based ontologies in languages that are less expressive            than FOL. In particular, DOLCE-Lite does not make use of S5            modalities and of some temporally-indexed relations.   Modal            operators are not heavily exploited in DOLCE, then the            consequences are not very harmful for most uses.   Temporal            indexing is partly supported by composing            originally indexed relations with temporal location            relations. Even this support is not provided for description            logic versions of DOLCE-Lite like DAML+OIL, OWL-DL, etc.            2. allowing a description-logic-like naming policy for DOLCE            signature. In many cases, different names are adopted for            relations that have the same name but different arities in            the FOL version, or for relations that have polymorphic            domains  3. allowing extensions of DOLCE that do not have a            detailed axiomatization yet, and modularizing them            (placeholders) 4. taking benefit of the services of certain            implemented languages -specially the            classification services provided by  description            logics- in order to support domain applications.            The DLP ontology library is currently maintained in two            languages: a dialect of KIF3.0 (PL), and DAML+OIL (and now            OWL-DL).            The first one contains a complete code            for the library,             including theWordNet alignment            modules. The second one             contains the library            (according to available costructs of             DAML+OIL)            without the WordNet code, since it is very simple            and takes much space.  DLP+KIF is currently used in            some applications that need deep inferences, which can only            be provided by expressive, logic-programming-enabled            languages. DLP+DAML is currently used in Semantic Web            applications, for example in the Core Ontology for Services            (COS).  The extensions to DOLCE presented in the library are            work in progress, and although some of them have been tested            in realistic applications, they should be taken cautiously            from the viewpoint of rigorous formal ontology.            The axioms for constraining the semantics of relations in DLP, which exist in the KIF or FOL versions, are not included into this OWL version, because a workaround is needed for representing relation axioms in OWL-DL, which increases beyond acceptability the time employed by a reasoner to check the ontologies.            *********Updates can be downloaded from: http://dolce.semanticweb.org*********\n\n\n## References\n\n- https://www.w3.org/2001/sw/BestPractices/WNET/DLP3941_daml.html\n- http://www.ontologydesignpatterns.org/ont/dlp/\n- http://www.loa.istc.cnr.it/old/Files/DLPOnts/\n","n":0.03}}},{"i":3483,"$":{"0":{"v":"Lexical MetaModel Level 1","n":0.5},"1":{"v":"\n- http://www.ontologydesignpatterns.org/ont/lmm/LMM_L1.owl\n\n## Description\n\nThis ontology is a composition of some content design patterns for the semiotic triangle. Its structure is extracted from DOLCE-Ultralite (DOLCE+c.DnS), but it uses a different terminology, and explicitly defines the semiotic function: Expression is the semiotic term for dul:InformationObject, when they actually express or denote something; Meaning is the semiotic term for dul:SocialObject, when they are actually expressed by something, or are interpretation of something; Reference is the semiotic term for dul:Entity, when they are interpreted or denoted by something. The denotes relation is equivalent to dul:isAbout, the expresses relation is imported from DOLCE Ultralite, and the hasInterpretation relation generalizes over: dul:isClassifiedBy, dul:isCoveredBy, dul:isDescribedBy, dul:isUnifiedBy, and dul:satisfies Extensions to the triangle: A typical extension of the semiotic triangle concerns the participation of agents: this is introduced by using the dul:conceptualizes relation, holding between a dul:Agent and a dul:SocialObject (the Meaning). An additional extension concerns semiotic context: this is provided by including four notions of 'Context': 'Paradigm' (the context of the conceptualized meaning), 'KnowledgeCollective' (the context of agents that conceptualize the paradigm), 'Cotext' (the context of expressions), and dul:Situation (the context of denoted entities). A final extension links semiotics to formal semantics: this is provided by reusing dul:FormalEntity, iol:isGroundingFor, iol:FormalExpression, iol:isAssignedTo, iol:FormalLanguage, etc. The complete pattern allows to declare relations between Expression(s) and their Reference(s) (denotes), between Expression(s) and their Meaning (dul:expresses), between Meaning(s) and Reference(s) (isInterpretationOf), between Reference(s) and dul:FormalEntity(ies) (iol:isGroundingFor), between dul:FormalEntity(ies) and iol:FormalExpression(s) (iol:isAssignedTo). This 'formalization pathway' moves from Expression(s) to iol:FormalExpression(s) by taking into account both Meaning(s) and Referent(s). The informal denotation of Expression(s) is moved to a formal denotation (iol:isAssignedTo) of iol:FormalExpression(s). For example: the Expression 'Mariachi' dul:expresses the dul:Concept (Meaning) 'MexicanStreetSinger' that isInterpretationOf the dul:Collection (Reference) 'TheStreetSingersFromMexico'. 'TheStreetSingersFromMexico' then iol:isGroundingFor e.g. the dul:Set (dul:FormalEntity) that includes all Mexican street singers, which iol:isAssignedTo e.g. the iol:FormalExpression 'owl:Class#Mariachi'. The formalization pathway enables a technique to move from/to socio-cognitive and formal semantics through denotation, in the Tarskian sense. As a matter of fact, translating directly a Meaning into a FormalEntity (or viceversa) is not always clearly implementable, while passing through an extensional grounding is easier and more accessible to intuition. Among possible uses, information extraction, ontology learning, KOS reengineering, lexical semantics, etc. For example, statistical learning of instances for a dul:Concept would be modelled as the building of a dul:Collection that isInterpretationOf the dul:Concept, but also dul:isGroundingFor a dul:Set that iol:isAssignedTo e.g. an owl:Class. An additional semiotic pattern is based on the hasInterpretant relation, which allows to link two Expression(s) (or dul:InformationRealization(s)), when the second one counts as a Meaning (or a relatedMeaning) of the first. In practice, this is implemented by allowing a relation between an Expression (or its realization), and whatever Meaning (or another dul:InformationRealization). Technically speaking, the correct path would be passing through another Expression used to express a Meaning for the first one: (Exp1 hasInterpretant some (Exp2 and expresses some (Meaning and isExpressedBy some Exp1))) or even: (Exp1 hasInterpretant some (Exp2 and expresses some (Meaning and relatedMeaning some (Meaning and isExpressedBy some Exp1)))) but given the expressive power of OWL, which lacks co-reference, this is the best sub-optimal solution.","n":0.044}}},{"i":3484,"$":{"0":{"v":"DOLCE Information Objects","n":0.577},"1":{"v":"\n- http://www.ontologydesignpatterns.org/ont/dul/IOLite.owl\n- ","n":0.707}}},{"i":3485,"$":{"0":{"v":"DNS Ultralite","n":0.707},"1":{"v":"\n- [[c.ontology.upper]]\n- simplification_of: [[prdct.dolce.lite-plus]]\n- related: [[prdct.dolce.d0]] [[prdct.dolce.plans-lite]] [[prdct.dolce.information-objects]] [[prdct.dolce.systems-lite]] [[prdct.dolce.core-legal]] [[prdct.dolce.lexical]]\n- url: \n  - http://ontologydesignpatterns.org/wiki/Ontology:DOLCE+DnS_Ultralite\n  - http://www.ontologydesignpatterns.org/ont/dul/DUL.owl (v4.1)\n  - http://www.ontologydesignpatterns.org/ont/dul/DUL_v40.owl\n- authors: [[user.aldo-gangemi]]\n\n## Features\n\n- DUL provides a good combination of flexibility and expressiveness and makes at least the basic distinctions explicit, such as that between events, physical objects and social construction ^y3piqf56xjis\n- In DUL the DOLCE distinction be- tween endurants and perdurants is simplified to a distinction between objects and events, which suffices for most situations and avoids the heavy terminology\n- \n\n\n## Issues\n\n- properties are all SubProperty of associatedWith\n\n## Description\n\nthe DOLCE+D&S Ultralite15 (DUL) OWL ontology was intended to popularize DOLCE to the Semantic Web community. DUL uses DOLCE, D&S, and a few more ontology design patterns (Plan16, Information Object17, and Collection, that extend DOLCE. See [29] for an account of DUL as an architec- ture of ontology design patterns inspired by those integrated theories, and [12] for an integrated axiom- atization of plans, information objects and collections in D&S. DUL is the result of various refinements and integrations of the OWL versions of those theories. The main motivations why DUL was conceived include: (i) intuitive terminology (e.g. substituting Endurant and Perdurant with Object and Event), (ii) lighter axiomatization (e.g. giving up some predicate indexing), (iii) integration of other theories, (iv) semantic-web-oriented OWL2 modeling styles. [^1]\n\nMain aspects in which DOLCE+DnS Ultralite departs from DOLCE Lite-Plus are the following:\n\n- The names of classes and relations have been made more intuitive\n- The DnS-related part is closer to the newer 'constructive DnS' ontology (http://www.ontologydesignpatterns.org/ont/cdns/cDnS.owl). \n- Temporal and spatial relations are simplified - Axiomatization makes use of simpler constructs than DOLCE Lite-Plus \n- The architecture of the ontology is pattern-based, which means that DOLCE+DnS Ultralite is also available in modules, called 'content ontology design patterns', which can be applied independently in the design of domain ontologies (cf. http://www.ontologydesignpatterns.org). If many modules are needes in a same ontology project, is anyway useful to use this integrated version. \n\n### Events\n\nrdfs:comment \"Any physical, social, or mental process, event, or state.\n\nMore theoretically, events can be classified in different ways, possibly based on 'aspect' (e.g. stative, continuous, accomplishement, achievement, etc.), on 'agentivity' (e.g. intentional, natural, etc.), or on 'typical participants' (e.g. human, physical, abstract, food, etc.).\nHere no special direction is taken, and the following explains why: events are related to observable situations, and they can have different views at a same time.\nIf a position has to be suggested here anyway, the participant-based classification of events seems the most stable and appropriate for many modelling problems.\n\n(1) Alternative aspectual views\n\nConsider a same event 'rock erosion in the Sinni valley': it can be conceptualized as an accomplishment (what has brought a certain state to occur), as an achievement (the state resulting from a previous accomplishment), as a punctual event (if we collapse the time interval of the erosion into a time point), or as a transition (something that has changed from a state to a different one). \nIn the erosion case, we could therefore have good motivations to shift from one aspect to another: a) causation focus, b) effectual focus, c) historical condensation, d) transition (causality).\n\nThe different views refer to the same event, but are still different: how to live with this seeming paradox? \nA typical solution e.g. in linguistics (cf. Levin's aspectual classes) and in DOLCE Full (cf. WonderWeb D18 axiomatization) is to classify events based on aspectual differences. But this solution would create different identities for a same event, where the difference is only based on the modeller's attitude.\nAn alternative solution is suggested here, and exploits the notion of (observable) Situation; a Situation is a view, consistent with a Description, which can be observed of a set of entities. It can also be seen as a 'relational context' created by an observer on the basis of a 'frame'. Therefore, a Situation allows to create a context where each particular view can have a proper identity, while the Event preserves its own identity. \nFor example, ErosionAsAccomplishment is a Situation where rock erosion is observed as a process leading to a certain achievement: the conditions (roles, parameters) that suggest such view are stated in a Description, which acts as a 'theory of accomplishments'. Similarly, ErosionAsTransition is a Situation where rock erosion is observed as an event that has changed a state to another: the conditions for such interpretation are stated in a different Description, which acts as a 'theory of state transitions'.\nConsider that in no case the actual event is changed or enriched in parts by the aspectual view.\n\n(2) Alternative intentionality views\n\nSimilarly to aspectual views, several intentionality views can be provided for a same Event. For example, one can investigate if an avalanche has been caused by immediate natural forces, or if there is any hint of an intentional effort to activate those natural forces.\nAlso in this case, the Event as such has not different identities, while the causal analysis generates situations with different identities, according to what Description is taken for interpreting the Event. \nOn the other hand, if the possible actions of an Agent causing the starting of an avalanche are taken as parts of the Event, then this makes its identity change, because we are adding a part to it. \nTherefore, if intentionality is a criterion to classify events or not, this depends on if an ontology designer wants to consider causality as a relevant dimension for events' identity.\n\n(3) Alternative participant views\n\nA slightly different case is when we consider the basic participants to an Event. In this case, the identity of the Event is affected by the participating objects, because it depends on them. \nFor example, if snow, mountain slopes, wind, waves, etc. are considered as an avalanche basic participants, or if we also want to add water, human agents, etc., that makes the identity of an avalanche change.\nAnyway, this approach to event classification is based on the designer's choices, and more accurately mirrors lexical or commonsense classifications (see. e.g. WordNet 'supersenses' for verb synsets).\n\nUltimately, this discussion has no end, because realists will keep defending the idea that events in reality are not changed by the way we describe them, while constructivists will keep defending the idea that, whatever 'true reality' is about, it can't be modelled without the theoretical burden of how we observe and describe it. \nBoth positions are in principle valid, but, if taken too radically, they focus on issues that are only partly relevant to the aim of computational ontologies, which assist domain experts in representing a certain portion of reality according to their own assumptions and requirements. \n\nFor this reason, in this ontology version of DOLCE, both events and situations are allowed, together with descriptions (the reason for the inclusion of the D&S framewrok in DOLCE), in order to encode the modelling needs, independently from the position (if any) chosen by the model designer.\"\n\n\n## References\n\n- [^1]: [[ar.dolce-a-descriptive-ontology-for-linguistic-and-cognitive-engineering]]\n- [[ar.understanding-the-semantic-web-through-descriptions-and-situations]]","n":0.03}}},{"i":3486,"$":{"0":{"v":"D0","n":1},"1":{"v":"\n- http://www.ontologydesignpatterns.org/ont/dul/d0.owl\n- https://triplydb.com/odp/d0/\n- similar: [[prdct.dolce.dns-ultralite]]\n\n## Description\n\n- A supplementary ontology used as a generalization of DOLCE+DnS Ultralite (DUL), in order to deal with the systematic polysemy of many lexical items, whose senses create problems when used as OWL classes. For example, it's customary to find lexical items that carry both a sense of physical or abstract location, of event or event type, etc. [^2]\n\n### vs DOLCE Lite-Plus\n\n\n\n## References\n\n[^1]: \n[^2]: https://triplydb.com/odp/d0/","n":0.12}}},{"i":3487,"$":{"0":{"v":"Core Legal","n":0.707},"1":{"v":"\n- http://www.ontologydesignpatterns.org/ont/dul/CoreLegal.owl","n":0.707}}},{"i":3488,"$":{"0":{"v":"Basic","n":1},"1":{"v":"- repo: https://appliedontolab.github.io/DOLCE/OWL/DOLCEbasic.owl\n- related: [[prdct.ace.parsing-engine]]\n\n![](/assets/images/2024-06-06-09-09-38.png)","n":0.447}}},{"i":3489,"$":{"0":{"v":"Dol Distributed Ontology Model and Specification Language","n":0.378},"1":{"v":"\n- https://www.omg.org/spec/DOL/1.0/About-DOL","n":0.707}}},{"i":3490,"$":{"0":{"v":"Dokieli","n":1},"1":{"v":"\n- repo: https://github.com/linkeddata/dokieli\n- [[c.software.semantic.authoring]] [[c.software.semantic.activity-pub]]\n- url: https://dokie.li\n- built_on: [[prdct.solid]] [[prdct.activitypub]]\n- written_in: javascript (client-side)\n- supports: [[prdct.activitypub]] [[prdct.web-annotations]]\n\n## Features\n\n- A dokieli article is simply an HTML document, so anything you can include in an HTML page you can include in your article. We’re adding new features to the UI to help with this all the time. You can directly embed raw data; in Turtle, [[prdct.JSON-LD]], or TriG (used in Nanopublications).\n- \n- Unique identifiers (URIs) are automatically generated for every section of your article to make it easy for others to link and refer to them. You can add identifiers to any concepts you think are important at any level of granularity. Additionally, you can add descriptive markup to any concept or snippet of prose which has an identifier; dokieli generates RDFa markup under the hood so your ideas are exposed as Linked Data for others to query, reuse and visualise.","n":0.082}}},{"i":3491,"$":{"0":{"v":"Dojo Toolkit","n":0.707},"1":{"v":"\n- [[c.software.web.toolkit]]\n- supports: [[prdct.rdf]] but: seems dated/discontinued\n- similar: [[prdct.mochikit]] [[prdct.prototype]] + [[prdct.scriptaculous]] [[prdct.yui]] [[prdct.gwt]] ^tmacjwe8emtq\n\n\n## Why Choose Dojo? [^1]\n\n## References\n\n- [^1]: https://dojotoolkit.org/reference-guide/1.7/quickstart/introduction/whydojo.html\n\n","n":0.213}}},{"i":3492,"$":{"0":{"v":"Doi","n":1},"1":{"v":"\n- https://www.doi.org/the-identifier/what-is-a-doi/\n- similar: [[prdct.purl]]\n  - see https://www.doi.org/the-identifier/resources/factsheets/doi-system-and-persistent-urls\n- managed-by: [[org.doi-foundation]]\n\n## Issues\n\n- registration agencies charge money\n  - e.g. https://www.crossref.org/fees/\n\n## References\n\n- https://www.doi.org/the-identifier/what-is-a-doi/","n":0.229}}},{"i":3493,"$":{"0":{"v":"Dogg3rz","n":1},"1":{"v":"\n- mentions: [[ar.martinfowler.data-mesh-principles]]\n\n## Approach\n\nDogg3rz leverages a combination of W3C standards and common cloud native services in conjunction with emergent Web 3 Technologies. The JSON-LD document is used as a representational data model for linked data; whereas [[prdct.decentralized-identifiers]] (DIDs) serve as self-sovereign, globally unique, and verifiable identifiers for the data products and those who use them. Dogg3rz uses container and Serverless technologies to apply reactive behavior to your data . The final packaging, delivery, and streaming update notifications of your linked data product are performed by the Interplanetary File System (IPFS). IPFS encapsulates and persists your linked data product components through an immutable snapshot that can be referenced and used anywhere through its verifiable content identifiers (CIDs).","n":0.093}}},{"i":3494,"$":{"0":{"v":"Docfx","n":1},"1":{"v":"\n- repo: https://dotnet.github.io/docfx/","n":0.577}}},{"i":3495,"$":{"0":{"v":"Dndbeyond","n":1},"1":{"v":"\n- related: [[prdct.abovevtt]]\n\n## User Stories\n\n### DnDBeyond works with Owlbear\n\n- We use DnDBeyond for character sheets, and I find that pairs perfectly with the functionality provided by owlbear.rodeo.","n":0.192}}},{"i":3496,"$":{"0":{"v":"Dnd5eapi","n":1},"1":{"v":"\n- https://www.dnd5eapi.co/\n- https://github.com/5e-bits/5e-database\n\n\n\n## Resources\n\n### Learning Resources\n\nAdvanced tutorials are designed to help you build more complex applications with the API. They are intended for developers who are comfortable with programming and want to build more advanced applications.\n\n-   [Interactive Monster Search with JavaScript](https://5e-bits.github.io/docs/tutorials/advanced/monster-search-with-javascript)\n-   [Creating a Spell Card Library with React](https://5e-bits.github.io/docs/tutorials/advanced/react-spell-cards)\n-   [Command Line Spellbook with Python](https://5e-bits.github.io/docs/tutorials/advanced/terminal-spellbook-with-python)","n":0.137}}},{"i":3497,"$":{"0":{"v":"Dnd Beyond","n":0.707},"1":{"v":"\n- url: https://www.dndbeyond.com\n- ","n":0.577}}},{"i":3498,"$":{"0":{"v":"Dnd 5e Srd","n":0.577},"1":{"v":"\n- [[c.software.game-service.data]]\n- repo: https://github.com/BTMorton/dnd-5e-srd/\n![[prdct.5e-tools#^vt5y8u6whgr9]]\n\n## Examples\n\n            \"Acid Arrow\": {\n                \"content\": [\n                    \"*2nd-level evocation*\",\n                    \"**Casting Time:** 1 action\",\n                    \"**Range:** 90 feet\",\n                    \"**Components:** V, S, M (powdered rhubarb leaf and an adder’s stomach)\",\n                    \"**Duration:** Instantaneous\",\n                    \"A shimmering green arrow streaks toward a target within range and bursts in a spray of acid. Make a ranged spell attack against the target. On a hit, the target takes 4d4 acid damage immediately and 2d4 acid damage at the end of its next turn. On a miss, the arrow splashes the target with acid for half as much of the initial damage and no damage at the end of its next turn.\",\n                    \"***At Higher Levels.*** When you cast this spell using a spell slot of 3rd level or higher, the damage (both initial and later) increases by 1d4 for each slot level above 2nd.\"\n                ]\n            },","n":0.085}}},{"i":3499,"$":{"0":{"v":"Decision Model and Notation","n":0.5},"1":{"v":"\n## Comparisons\n\n## vs [[prdct.bpmn]]\n\n- \n\n## Resources\n\n- https://methodandstyle.com/dmn-decision-modeling-language/\n\n## References\n\n- https://stackoverflow.com/questions/71241905/business-rules-in-dmn-or-database-table","n":0.333}}},{"i":3500,"$":{"0":{"v":"Dmn Engine","n":0.707},"1":{"v":"\n- repo: https://github.com/adamecr/Common.DMN.Engine\n- [[p.used]] [[prdct.dynamic-expresso]]","n":0.447}}},{"i":3501,"$":{"0":{"v":"DLRUS","n":1},"1":{"v":"\n- [[c.description-logic]]\n\n## Features\n\n- uses linear time and mostly qualitative temporal constraints.","n":0.302}}},{"i":3502,"$":{"0":{"v":"Dk Brics Automaton","n":0.577}}},{"i":3503,"$":{"0":{"v":"djradon.github.io","n":1},"1":{"v":"\n- https://djradon.github.io/\n- description: resurrected from daverichardson.com after a 10 year hiatus, I hope it's a harbinger web content to come.","n":0.224}}},{"i":3504,"$":{"0":{"v":"Log","n":1},"1":{"v":"\n## t.2024.07.22.12\n\n- after 10 years, the scroller still works, but looks like only in quirks mode.\n- added GA tag\n- was tempting to feel bad about the sloppiness... but hand-written HTML is human, and so has a beauty.\n\n","n":0.164}}},{"i":3505,"$":{"0":{"v":"Djot","n":1},"1":{"v":"\n- url: https://djot.net/\n\n## References\n\n- https://johnmacfarlane.net/beyond-markdown.html","n":0.447}}},{"i":3506,"$":{"0":{"v":"djot-js","n":1},"1":{"v":"\n- repo: https://github.com/jgm/djot.js\n\n","n":0.577}}},{"i":3507,"$":{"0":{"v":"Distributed Ontology Modeling and Specification Language (DOL)","n":0.378},"1":{"v":"\n- https://www.omg.org/spec/DOL/1.0\n- publication-date:2018-03\n- spec: https://www.omg.org/spec/DOL/1.0/PDF\n- owl2:  \tptc/17-11-11.rdf (paywalled)\n\n","n":0.354}}},{"i":3508,"$":{"0":{"v":"Discord","n":1},"1":{"v":"\n\n\n## Index\n- [[Discord Activities|prdct.discord.activities]] \n\n## Resources\n\n- https://discord.com/developers/docs/tutorials/developing-a-user-installable-app","n":0.378}}},{"i":3509,"$":{"0":{"v":"Discord Activities","n":0.707}}},{"i":3510,"$":{"0":{"v":"Discord Webgame Toolkit","n":0.577},"1":{"v":"\nrepo: https://github.com/gamestdio/discord-webgame-toolkit\n#contributors @endel-dreyer\n","n":0.577}}},{"i":3511,"$":{"0":{"v":"Digitalbuildings","n":1},"1":{"v":"\n- repo: https://github.com/google/digitalbuildings\n- written-in: python","n":0.447}}},{"i":3512,"$":{"0":{"v":"Rdf Generator","n":0.707},"1":{"v":"\n- https://google.github.io/digitalbuildings/tools/rdf_generator/\n- [[c.software.semantic.publishing.site-generator]]","n":0.577}}},{"i":3513,"$":{"0":{"v":"Diffgram","n":1},"1":{"v":"\n- url: https://www.diffgram.com/\n- repo: https://github.com/diffgram/diffgram \n- [[c.review]] https://humansintheloop.medium.com/tools-we-love-vol-7-diffgram-3ed3d08f767d","n":0.354}}},{"i":3514,"$":{"0":{"v":"Dialog","n":1},"1":{"v":"\n- [[p.instanceOf]] [[c.software.game-framework.interactivefiction]]\n","n":0.577}}},{"i":3515,"$":{"0":{"v":"Diagrams Net","n":0.707}}},{"i":3516,"$":{"0":{"v":"Dgraph","n":1},"1":{"v":"\n- url: \n\n## Features\n- Facets: Supports facets corresponding to rdf-star expressions for annotations and version management.\n  - \"key value pairs on edges — as an extension to RDF triples.\"\n  - can also be used as weights for edges.\n  - \"Facets are however not first class citizen in Dgraph like predicates.\"\n- \"combines RDF and labeled property graphs, making it ideal for AI-aware large language model editors and data analytics.\"\n- Not a triple store, but uses RDF \"for convention\"\n\nfaq:\n  - q: Does Dgraph support GraphQL?\n  - a: Dgraph started with the aim to fully support GraphQL. However, as our experience with the language grew, we started hitting the seams. It couldn’t support many of the features required from a language meant to interact with Graph data, and we felt some of the features were unnecessary and complicated. So, we’ve created a simplified and feature rich version of GraphQL. For lack of better name, we’re calling DQL. You can read more about it here.\n  - q: When is Dgraph going to support Gremlin?\n    a: Dgraph will aim to support Gremlin after v1.0. However, this is not set in stone. If our community wants Gremlin support to interact with other frameworks, like Tinkerpop, we can look into supporting it earlier.\n\n\n\n## References\n\n- https://www.bloorresearch.com/technology/graph-databases/\n- https://dgraph.io/docs/dql/dql-syntax/dql-rdf/\n- https://www.linkedin.com/pulse/dgraph-exploring-json-graph-database-kurt-cagle/","n":0.069}}},{"i":3517,"$":{"0":{"v":"Dfrnt","n":1},"1":{"v":"\n- url: https://dfrnt.com\n- built-on: [[prdct.TerminusDB]]","n":0.447}}},{"i":3518,"$":{"0":{"v":"Dexie.js","n":1},"1":{"v":"\n![[prdct.rxdb#^pnjx84u9yrqy]]\n","n":1}}},{"i":3519,"$":{"0":{"v":"Devs","n":1}}},{"i":3520,"$":{"0":{"v":"DevIns","n":1},"1":{"v":"\n- [[c.language]]\n- url: https://ide.unitmesh.cc/devins","n":0.5}}},{"i":3521,"$":{"0":{"v":"Devin","n":1},"1":{"v":"\n- https://www.cognition.ai/blog/introducing-devin\n- [[c.software.ai.development-assistant]]","n":0.577}}},{"i":3522,"$":{"0":{"v":"Development Containers","n":0.707},"1":{"v":"\n- url: https://containers.dev\n- ","n":0.577}}},{"i":3523,"$":{"0":{"v":"Dev To","n":0.707},"1":{"v":"\n- ","n":1}}},{"i":3524,"$":{"0":{"v":"DESO","n":1},"1":{"v":"\n- related: [[prdct.unified-foundational-ontology]]\n- purpose: provide a basis for evaluating discrete event simulation languages\n\n## Ontologies\n\n- see [[sh.question-log.2024.04.17#why-does-the-deso-discrete-event-simulation-ontology-separate-run-time-from-design-time-ontologies]]\n\n### Runtime Ontology (DESO-I)\n\n![](/assets/images/2024-04-17-12-07-42.png)\n\n- (physical) objects\n- situations and object snapshots\n- In DESO-I, for simplicity, we assume that there are only binary material relationships, which are represented by references specifying a value for a reference property. (boo!)\n- A slot is either a reference or an attribution (an attribute-value pair).\n\n### Design-Time Ontology (DESO-U)\n![](/assets/images/2024-04-17-12-12-35.png)\n\n- entity types\n\n\n## Evaluating DES Languages\n\nThere are four properties of a simulation language to be checked in its evaluation:\n1. Soundness: L is sound w.r.t. DESO iff every element of L has an interpretation in terms of a do- main concept from DESO. The degree of soundness can be measured relatively as the number of L elements that have a DESO interpretation divided by the total number of L elements.\n2. Completeness: L is complete w.r.t. DESO iff every DESO concept is represented by a modeling primitive of L. The degree of completeness can be measured relatively as the number of DESO concepts that are represented by an element of L divided by the total number of DESO concepts.\n3. Lucidity: L is lucid w.r.t. DESO iff every element of L has at most one interpretation in DESO. The degree of lucidity can be measured relatively as the number of L elements that have at most one interpretation in DESO divided by the total number of L elements.\n4. Laconicity: L is laconic w.r.t. DESO iff every domain concept from DESO is represented by at most one element of L. The degree of laconicity can be measured relatively as the number of DESO concepts that are represented by at most one element of L.\n\n\n\n## References\n\n- [[ar.towards-an-ontological-foundation-of-discrete-event-simulation]]\n\nDESO, a foundational ontology","n":0.06}}},{"i":3525,"$":{"0":{"v":"Descriptions and Situations Ontology","n":0.5},"1":{"v":"\nThe Descriptions and Situations (D&S) ontology pattern is a conceptual framework used in the Semantic Web for modeling and representing context and situational information. This ontology pattern enables the formalization of how descriptions (conceptualizations of situations) relate to the actual situations they describe. The D&S pattern is essential for applications that need to handle contextual information and varying interpretations of data. Here is an overview of the key components and concepts of the D&S ontology:\n\n![](/assets/images/2024-06-04-10-12-29.png)\n\n## Features\n\n- provides a formalization of frame semantics, generalizing over Fillmore’s [Fillmore and others, 2006] and Minsky’s [Minsky, 1974] proposals\n- defines a general vocabulary for n-ary relations, introducing the concepts of description and situation\n  - A situation is a set of facts, as it is described by an observer, involving a set of entities.\n  - A  description is a perspective (a theory, a schema) defining concepts that can classify, hence interpret, the entities observed in a situation\n- both descriptions and situations are formalized as first-order entities in an ontology, therefore potentially enabling reasoning over them both at the intensional (description) and extensional (situation) level, in the same domain of discourse\n\n\n### Key Components of D&S Ontology\n\n1. **Description**\n   - aka conceptualization, representation, schema, or\nfunction\n   - **Definition**: A conceptualization that defines a situation. It includes concepts, roles, and relationships that are expected in a situation.\n   - **Example**: A description of a \"Meeting\" might include roles like \"Participant\" and \"Location\" and relationships like \"attends\" and \"held in\".\n\n2. **Situation**\n   - **Definition**: An actual instance or occurrence in the real world that satisfies a description. A situation is bound by the entities and relationships defined in the description.\n   - **Example**: An actual meeting where Alice and Bob participate in Room 101.\n\n3. **Entity**\n   - **Definition**: Any object or individual that plays a role in a situation.\n   - **Example**: Alice, Bob, and Room 101 are entities in the situation.\n\n4. **Concept**\n   - **Definition**: The abstract idea or category that entities belong to within a description.\n   - **Example**: The concept of a \"Participant\" in a meeting.\n\n5. **Role**\n   - **Definition**: The function or part played by an entity in a situation, as defined by the description.\n   - **Example**: Alice and Bob playing the role of \"Participants\".\n\n6. **Relationship**\n   - **Definition**: The connections or associations between entities in a situation, as specified in the description.\n   - **Example**: The \"attends\" relationship between \"Participants\" and the \"Meeting\".\n\n7. **Constraint**\n   - **Definition**: Conditions or rules that must be met for a situation to satisfy a description.\n   - **Example**: A constraint that a meeting must have at least two participants.\n\n### Core Concepts and Axioms\n\n1. **Satisfies**\n   - **Definition**: A situation satisfies a description if all the roles, entities, relationships, and constraints specified in the description are present and met in the situation.\n   - **Example**: The situation where Alice and Bob are in Room 101 satisfies the description of a \"Meeting\".\n\n2. **Classification**\n   - **Definition**: Entities in a situation are classified according to the concepts defined in the description.\n   - **Example**: Alice and Bob are classified as \"Participants\".\n\n3. **Role Assignment**\n   - **Definition**: Entities in a situation play specific roles as defined by the description.\n   - **Example**: Alice and Bob are assigned the role of \"Participants\" in the meeting.\n\n4. **Relationship Representation**\n   - **Definition**: The relationships among entities in a situation correspond to the relationships defined in the description.\n   - **Example**: The \"attends\" relationship between Alice, Bob, and the meeting.\n\n5. **Constraint Satisfaction**\n   - **Definition**: All constraints specified in the description must hold true in the situation.\n   - **Example**: The constraint of having at least two participants in the meeting is satisfied.\n\n6. **Temporal and Spatial Context**\n   - **Definition**: Situations are bounded by the temporal and spatial contexts as described.\n   - **Example**: The meeting takes place at a specific time and location.\n\n### Use Cases\n\n1. **Event Modeling**: Representing events like meetings, conferences, or workshops where specific roles, entities, and relationships need to be defined and verified.\n2. **Contextual Information**: Capturing the context in which data was generated or used, which is crucial for accurate interpretation and decision-making.\n3. **Complex Systems**: Modeling complex systems where different components interact in various roles and relationships.\n\nBy using the D&S ontology pattern, one can create a robust framework for representing and reasoning about the contexts and situations in which data and entities are involved, enhancing the Semantic Web's capability to handle complex and contextual information.\n\n\n## References\n\n- \n- [[ar.arxiv.sandra-a-neuro-symbolic-reasoner-based-on-descriptions-and-situations]]","n":0.038}}},{"i":3526,"$":{"0":{"v":"Denon","n":1},"1":{"v":"\n- repo: https://github.com/denosaurs/denon\n\n## Resources\n\n- [[Help] How to properly configure Denon with VS Code](https://github.com/denosaurs/denon/issues/116)","n":0.277}}},{"i":3527,"$":{"0":{"v":"Denomander","n":1},"1":{"v":"\nrepo: https://github.com/siokas/denomander\n","n":0.707}}},{"i":3528,"$":{"0":{"v":"Denoflare","n":1},"1":{"v":"\n## Resources\n\n- https://blog.logrocket.com/develop-test-deploy-cloudflare-workers-denoflare/\n- ","n":0.577}}},{"i":3529,"$":{"0":{"v":"Deno","n":1},"1":{"v":"\n\n## Features\n\n- [[prdct.websocket]] support, but\n  - \"Note: We are aware that this API can be challenging to use, and are planning to switch to WebSocketStream once it is stabilized and ready for use.\"\n- native typescript support\n\n## References\n\n- https://www.imaginarycloud.com/blog/deno-vs-node/\n- https://medium.com/deno-the-complete-reference/denos-past-present-and-future-40e4d5683ce5 [[p.mentioned]] [[prdct.deno.deploy]]\n\n## Resources\n\n- https://docs.deno.com/runtime/manual/references/vscode_deno#using-the-debugger\n- https://medium.com/deno-the-complete-reference/learn-deno-by-example-part-1-introduction-to-content-server-e3c77bbf9c2d\n- https://blog.logrocket.com/deno-alternatives-to-popular-node-projects/","n":0.149}}},{"i":3530,"$":{"0":{"v":"Queues","n":1},"1":{"v":"\n## Resources\n\n- https://deno.com/blog/queues","n":0.577}}},{"i":3531,"$":{"0":{"v":"Deno KV","n":0.707},"1":{"v":"\n## Features\n\n- Deno KV is built for JavaScript and TypeScript. Store any JavaScript value, from strings to objects, without having to worry about \n\n\n\n- \" As a main data store, it doesn't feel powerful enough and I think there's a lot to consider in terms of data layout. For caching, I rather use Redis (or some flavor of Redis) - I find myself using sorted sets a lot so it's maybe out of commodity.\"\n  - https://github.com/denoland/deno/discussions/19460","n":0.115}}},{"i":3532,"$":{"0":{"v":"Deno Deploy","n":0.707},"1":{"v":"\n- [[p.supports]] [[prdct.supabase]]\n\n## Resources\n\n- https://deno.com/blog/queues","n":0.447}}},{"i":3533,"$":{"0":{"v":"Subhosting","n":1},"1":{"v":"\n- t.2023.12.09: according to https://www.youtube.com/watch?v=wCCTPpf6lbQ,  working on layers and embeddable code editor\n","n":0.289}}},{"i":3534,"$":{"0":{"v":"Deno Fresh","n":0.707},"1":{"v":"\n## Comparison\n\n### vs [[prdct.oak]]\n\n- ","n":0.5}}},{"i":3535,"$":{"0":{"v":"Deno Embedder","n":0.707},"1":{"v":"\n- repo: https://github.com/nfnitloop/deno-embedder\n- ","n":0.577}}},{"i":3536,"$":{"0":{"v":"Dendron","n":1},"1":{"v":"\n- creator: @kevin-lin\n- [[c.software.Knowledge-Base]] \n\n## Tips\n\n- don't end your dendron top-level domain with the same letter. i.e., `prdct.`, `t.` - it hampers search autocomplete ^ln5q1ooyf17z\n\n## Publishing\n\n- `rm -rf .next && rm -rf docs`\n- `dendron publish export --target github --yes`\n- to customize the next.js template... use \"--dest       override where nextjs-template is located\"\n  - https://docs.dendron.so/notes/PgwAXFfotfgpFVqHQRlBl/\n- customizing the header is also apparently an option\n- for \"files to include\", vaults have to be specified as, e.g. ./public-notes\n  \n\n## Resources\n\n- [Deploy to Github Pages using Actions with both Private and Public Vaults](https://wiki.dendron.so/notes/N2XTqKPFEkKCFJ6kRnzl0/) mostly worked, but couldn't get permissions to commit","n":0.103}}},{"i":3537,"$":{"0":{"v":"Traits","n":1},"1":{"v":"\n- [[p.hasLearningResource]]\n  - https://wiki.dendron.so/notes/bdZhT3nF8Yz3WDzKp7hqh/","n":0.5}}},{"i":3538,"$":{"0":{"v":"Proxy Notes","n":0.707}}},{"i":3539,"$":{"0":{"v":"Dendrite","n":1},"1":{"v":"\nrepo: https://github.com/matrix-org/dendrite\n\n## [[p.hadDependancy]]\n\n- [[prdct.postgres]] or [[prdct.cockroachdb]]\n  - https://github.com/matrix-org/dendrite/discussions/1996","n":0.354}}},{"i":3540,"$":{"0":{"v":"DeMO Project","n":0.707},"1":{"v":"\n- http://cobweb.cs.uga.edu/~jam/jsim/DeMO/\n- rdf: http://cobweb.cs.uga.edu/~jam/jsim/DeMO/DeMO.owl\n  - ugly!\n\n## Features\n\n- the DeMO ontology constitutes a high-level simulation language supporting the paradigms of ‘state-oriented’, ‘event-oriented’, ‘activity-oriented’ and ‘process-oriented’ simulation\n- We start by placing two equivalent (in modeling power) formalisms on the top � Generalized Stochastic Petri Nets and Generalized Semi-Markov Process models\n- There are three main components of the formalisms in consideration:\n  1. Underlying graphical representation;\n\n  2. Probabilistic transitions; (these may be also considered as a part of 1)\n\n  3. [[t.cs.simulation.time.stochastic-clock-structure]] that introduces time in the model and is used as an input\n\n","n":0.106}}},{"i":3541,"$":{"0":{"v":"Delaunator","n":1},"1":{"v":"\nrepo: https://github.com/mapbox/delaunator\n#demo https://mapbox.github.io/delaunator/demo.html\n  - amazing, #cool, you can add points interactively\n\n## [[p.hasLearningResource]]\n\n- https://mapbox.github.io/delaunator/\n  - #highlight \"A triangle edge may be shared with another triangle. Instead of thinking about each edge A↔︎B, we will use two [[half-edges|t.cs.graph.half-edge]] A→B and B→A.\"\n\n## [[p.hasRelatedTopic]]\n\n- [[t.math.geometry.delaunay-triangulation]]\n\n## [[p.supports]]\n\n- [[prdct.d3-geo-voronoi]]\n- [[prdct.d3-delaunay]]","n":0.151}}},{"i":3542,"$":{"0":{"v":"Delaford","n":1},"1":{"v":"\n- [[c.software.game-platform]]\n- repo: https://github.com/delaford/game\n- url: https://beta.delaford.com/\n\n","n":0.408}}},{"i":3543,"$":{"0":{"v":"Defold","n":1},"1":{"v":"\n[[c.software.game-engine]]\n- url: https://defold.com/\n- repo: https://github.com/defold/defold\n- [[p.supports]] [[prdct.lua]]\n- written-in: #c++ #c #clojure java\n\n## Features\n\n- create and modify 3D geometry at runtime ^camw7v2l0zve\n- Engine supports reactive-style Lua scripting for low overhead and great performance\n- allows you to write extensions to the engine in C, C++, ObjectiveC, Java and JavaScript.\n- Integrated with tools such as Atom, VS Code, Spine and Tiled.\n- publish to web\n  - [[c.issue]]\n    - no hot reload\n\n\n## c.Resource\n\n- [Building a Multiplayer Server](https://forum.defold.com/t/building-a-multiplayer-server/69010)\n  - mentioned [[prdct.luvit]]\n- https://defold.com/2020/05/31/The-Defold-engine-code-style/\n- https://forum.defold.com/t/building-a-multiplayer-server/69010\n- https://forum.defold.com/t/implementing-in-game-lua-scripting/68311","n":0.113}}},{"i":3544,"$":{"0":{"v":"Definitelytyped","n":1},"1":{"v":"\n- repo: https://github.com/DefinitelyTyped/DefinitelyTyped/","n":0.577}}},{"i":3545,"$":{"0":{"v":"DefaultECS","n":1},"1":{"v":"\n- dead\n- author: @doraku\n\nWhy did I think it was updated recently? maybe a fork?","n":0.267}}},{"i":3546,"$":{"0":{"v":"Deeptelos","n":1}}},{"i":3547,"$":{"0":{"v":"Deepstream","n":1},"1":{"v":"\n- url: https://deepstream.io/\n- written_in: typescript\n- support: \n  - clients: javascript java [[prdct.nats]]\n  - storage: [[prdct.rethinkdb]]\n- similar: [[prdct.colyseus]]","n":0.243}}},{"i":3548,"$":{"0":{"v":"Deeponto","n":1},"1":{"v":"\n- repo: https://github.com/KRR-Oxford/DeepOnto\n\n## Background\n\n- relies on [[prdct.owlapi]] version 4.5.22 (written in Java) for ontologies.\n\nWe follow what has been implemented in mOWL that uses JPype to bridge Python and Java Virtual Machine (JVM). Please check JPype's installation page for successful JVM initialisation.\nPytorch\n\nrelies on Pytorch for deep learning framework.\n\n## Features\n\nOntology Reasoning ([OntologyReasoner][deeponto.onto.OntologyReasoner]): Each instance of DeepOnto has a reasoner as its attribute. It is used for conducting reasoning activities, such as obtaining inferred subsumers and subsumees, as well as checking entailment and consistency.\n\nOntology Pruning ([OntologyPruner][deeponto.onto.OntologyPruner]): This sub-module aims to incorporate pruning algorithms for extracting a sub-ontology from an input ontology. We currently implement the one proposed in [2], which introduces subsumption axioms between the asserted (atomic or complex) parents and children of the class targeted for removal.\n\nOntology Verbalisation ([OntologyVerbaliser][deeponto.onto.OntologyVerbaliser]): The recursive concept verbaliser proposed in [4] is implemented here, which can automatically transform a complex logical expression into a textual sentence based on entity names or labels available in the ontology. See verbalising ontology concepts.\n\nOntology Projection ([OntologyProjector][deeponto.onto.OntologyProjector]): The projection algorithm adopted in the OWL2Vec* ontology embeddings is implemented here, which is to transform an ontology's TBox into a set of RDF triples. The relevant code is modified from the mOWL library.\n\nOntology Normalisation ([OntologyNormaliser][deeponto.onto.OntologyNormaliser]): The implemented\n\nnormalisation is also modified from the mOWL library, which is used to transform TBox axioms into normalised forms to support, e.g., geometric ontology embeddings.\n\nOntology Taxonomy ([OntologyTaxonomy][deeponto.onto.OntologyTaxonomy]): The taxonomy extracted from an ontology is a directed acyclic graph for the subsumption hierarchy, which is often used to support graph-based deep learning applications.\n","n":0.063}}},{"i":3549,"$":{"0":{"v":"Deco CX","n":0.707},"1":{"v":"\n- https://deco.cx/\n- commercial","n":0.577}}},{"i":3550,"$":{"0":{"v":"Declare","n":1},"1":{"v":"\n- dead\n- https://www.win.tue.nl/declare/\n- \n## References\n\n- https://www.win.tue.nl/declare/wp-content/uploads/2011/01/manual.pdf","n":0.408}}},{"i":3551,"$":{"0":{"v":"Decentralized Identifiers","n":0.707},"1":{"v":"\n- spec: https://www.w3.org/TR/did-core/\n\n\n## References\n\n- https://www.dock.io/post/decentralized-identifiers","n":0.447}}},{"i":3552,"$":{"0":{"v":"Decentraland","n":1},"1":{"v":"\n\n\n- [[p.vs]] [[prdct.sandbox]]\n- [[p.hasApplication]] [[t.cs.metaverse]]\n- resources: \n  - https://github.com/decentraland-scenes/Colyseus-Tutorial \n","n":0.316}}},{"i":3553,"$":{"0":{"v":"DCAT Data Catalog","n":0.577},"1":{"v":"\n- https://www.w3.org/TR/vocab-dcat/\n\n## Features\n\n- DCAT does not make any assumptions about [the various] serialization formats of the datasets but it does distinguish between the abstract dataset and its different manifestations or distributions\n- defines a relatively comprehensive set of reusable terms from established vocabularies (Dublin Core, SKOS, FOAF, PROV) and extends these with some integrating classes and missing properties.\n\n## Issues\n\n### Dataset Ordering (claude)\n\nDCAT itself doesn't have a direct property for specifying the order of datasets within a catalog. This comes up when you want to present datasets in a specific sequence in a user interface or documentation, but there isn't a standard DCAT property for it.\nSome possible workarounds people use:\n\n- Use Dublin Core's terms:sequence\n- Create a custom property for ordering\n- Use RDF List structures (though this is more complex)\n\n\n\n## Terms\n\n- **dcat:Catalog**: a dataset in which each individual item is a metadata record describing datasets and data services\n- **dcat:Resource**: not intended to be used directly, but is the parent class of dcat:Dataset, dcat:DataService and dcat:Catalog\n- **dcat:DatasetSeries**: \n\n\n### Spatiotemporal terms\n\ndistribution\nfrequency\nspatial/geographic coverage\nspatial resolution\n\n#### dct:temporal (temporal coverage)\n\n#### \tdcat:temporalResolution\n\nintended to provide a summary indication of the temporal resolution of the data distribution as a single value. More complex descriptions of various aspects of temporal precision, accuracy, resolution and other statistics can be provided using the Data Quality Vocabulary [VOCAB-DQV](https://www.w3.org/TR/vocab-dcat/#Property:dataset_distribution#bib-vocab-dqv) \"Data on the Web Best Practices: Data Quality Vocabulary\".\n\n#### prov:wasGeneratedBy\n\n\n\n## References\n\n- [[prdct.dcat-data-catalog.v2]]\n- [[prdct.dcat-data-catalog.v3]]\n- [[community.github.semiceu.dcat-ap.issues.296-clarification-on-dataset-series-as-an-ordered-or-unordered-collection]]","n":0.067}}},{"i":3554,"$":{"0":{"v":"DCATv3","n":1},"1":{"v":"\n## Features\n\n### Versioning\n\n- In DCAT 3 (Data Catalog Vocabulary version 3), versioning is managed using properties that allow you to describe different versions of datasets, distributions, and other cataloged resources. Specifically, DCAT 3 introduces the `dcterms:hasVersion`, `dcterms:isVersionOf`, and `adms:versionNotes` properties to indicate relationships between versions, and to describe changes across versions.\n- This enables users to track the evolution of datasets and maintain a clear history of modifications, ensuring that consumers of the data are aware of its version history and any updates that have occurred.\n\n### Dataset Series\n\n- DCAT makes dataset series first class citizens of data catalogs by minting a new class dcat:DatasetSeries, defined as a subclass of dcat:Dataset. The datasets are linked to the dataset series by using the property dcat:inSeries. Note that a dataset series can also be hierarchical, and a dataset series can be a member of another dataset series.\n- see [[community.github.w3c.dxwg.issues.868]] and [[community.github.w3c.dxwg.issues.1409-using-dcat-next-and-dcat-version-in-dataseries]]\n\n#### \n\n## Example\n\n```turtle\nex:catalog\n  a dcat:Catalog ;\n  dcterms:title \"Imaginary Catalog\"@en ;\n  dcterms:title \"Catálogo imaginario\"@es ;\n  rdfs:label \"Imaginary Catalog\"@en ;\n  rdfs:label \"Catálogo imaginario\"@es ;\n  foaf:homepage <http://dcat.example.org/catalog> ;\n  dcterms:publisher ex:transparency-office ;\n  dcterms:language <http://id.loc.gov/vocabulary/iso639-1/en>  ;\n  dcat:dataset ex:dataset-001 , ex:dataset-002 , ex:dataset-003 ;\n  .\n\nex:dataset-001\n  a dcat:Dataset ;\n  dcterms:title \"Imaginary dataset\"@en ;\n  dcterms:title \"Conjunto de datos imaginario\"@es ;\n  dcat:keyword \"accountability\"@en, \"transparency\"@en, \"payments\"@en ;\n  dcat:keyword \"responsabilidad\"@es, \"transparencia\"@es, \"pagos\"@es ;\n  dcterms:creator ex:finance-employee-001 ;\n  dcterms:issued \"2011-12-05\"^^xsd:date ;\n  dcterms:modified \"2011-12-15\"^^xsd:date ;\n  dcat:contactPoint <http://dcat.example.org/transparency-office/contact> ;\n  dcterms:temporal [ a dcterms:PeriodOfTime ;\n    dcat:startDate \"2011-07-01\"^^xsd:date ; \n    dcat:endDate   \"2011-09-30\"^^xsd:date ;\n  ];\n  dcat:temporalResolution \"P1D\"^^xsd:duration ;\n  dcterms:spatial <http://sws.geonames.org/6695072/> ;\n  dcat:spatialResolutionInMeters \"30.0\"^^xsd:decimal ;\n  dcterms:publisher ex:finance-ministry ;\n  dcterms:language <http://id.loc.gov/vocabulary/iso639-1/en> ;\n  dcterms:accrualPeriodicity <http://purl.org/linked-data/sdmx/2009/code#freq-W>  ;\n  dcat:distribution ex:dataset-001-csv ;\n  .\n\nex:dataset-001-csv\n  a dcat:Distribution ;\n  dcat:downloadURL <http://dcat.example.org/files/001.csv> ;\n  dcterms:title \"CSV distribution of imaginary dataset 001\"@en ;\n  dcterms:title \"distribución en CSV del conjunto de datos imaginario 001\"@es ;\n  dcat:mediaType <http://www.iana.org/assignments/media-types/text/csv> ;\n  dcat:byteSize \"5120\"^^xsd:nonNegativeInteger ;\n  .\n```\n","n":0.059}}},{"i":3555,"$":{"0":{"v":"DCATv2","n":1},"1":{"v":"\n\n- has-implementation: \n  - [[prdct.dcat-data-catalog.v3]]\n- [[p.hasSpecification]] https://www.w3.org/TR/vocab-dcat/\n- [[p.instanceOf]] [[t.cs.web.w3c.rdf.vocabulary]]\n- topic: [[prdct.dcat-data-catalog]]\n\n## [[p.hasSummaryPoints]]\n\n- DCATv1 \"made an important distinction between a dataset as an abstract idea and a distribution as a manifestation of the dataset\"\n- addition of ways to represent loosely structured catalogs, where there is no distinction between a dataset and its distributions\n  - t.2023.12.01.09 sounds like a [[t.library-science.work_expression_manifestation_item]] issue\n- [aligned with schema.org vocabulary](https://www.w3.org/TR/vocab-dcat/#dcat-sdo)\n- [[p.addressed]]\n\n\n## References\n\n- https://medium.com/@stephanef/unraveling-the-dcat-standard-and-the-benefits-of-a-dcat-us-profile-c2c5b6cfbd44","n":0.123}}},{"i":3556,"$":{"0":{"v":"Application Profile","n":0.707},"1":{"v":"\n\n## References\n\n- [[ar.semiceu.dcat-ap-3-0]]\n- [Application Profiles \nWhat are they and how to model and reuse them properly? \nA look through the DCAT-AP example](https://docs.google.com/document/d/1JWMfdgkqacDvgnnUXL7a_UtFWiWGmA7YzOr-dA14yEs/edit)","n":0.213}}},{"i":3557,"$":{"0":{"v":"dbt","n":1},"1":{"v":"\n![[prdct.n8n#^xnxaubd7sqiw]]\n- [[p.vs]] [[prdct.airflow]] [[prdct.great_expectations]][[prdct.flyway]]\n- resources:  https://aptitive.com/blog/what-is-dbt/\n","n":0.408}}},{"i":3558,"$":{"0":{"v":"Dbpedia","n":1},"1":{"v":"\n- uses [[prdct.databus]]\n\n\n\n\n","n":0.577}}},{"i":3559,"$":{"0":{"v":"Ontology","n":1},"1":{"v":"\n- \"Since the DBpedia 3.7 release, the ontology is a directed-acyclic graph, not a tree. Classes may have multiple superclasses, which was important for the mappings to schema.org. A taxonomy can still be constructed by ignoring all superclasses except the one that is specified first in the list and is considered the most important.\"\n\n## References\n\n- https://www.dbpedia.org/resources/ontology/","n":0.134}}},{"i":3560,"$":{"0":{"v":"DBeaver","n":1},"1":{"v":"\n- url: https://dbeaver.io/\n\n## Comparison\n\n- https://medium.com/bright-days/choose-right-query-tool-dbeaver-vs-datagrip-1ca123926344","n":0.447}}},{"i":3561,"$":{"0":{"v":"Datomic","n":1},"1":{"v":"\n- \n- url: https://www.datomic.com/\n- repo: ???\n- written-in: #clojure\n\n## Features\n\n- persistent data structure\n  - valid times, you have to roll your own\n\n## Resources\n\n- https://blog.podsnap.com/bitemp.html","n":0.209}}},{"i":3562,"$":{"0":{"v":"Dataspects","n":1},"1":{"v":"\n- creator: @lex-sulzer","n":0.577}}},{"i":3563,"$":{"0":{"v":"Datascript","n":1},"1":{"v":"\n- [[c.software.database.graph]]\n- [[p.hasRepository]] https://github.com/tonsky/DataScript\n- [[p.hostedOn]] [[t.cs.web.browser]]\n- [[p.hasApplication]] \n  - storage for client-side applications that need to track a lot of state during their lifetime\n","n":0.204}}},{"i":3564,"$":{"0":{"v":"Datalog","n":1},"1":{"v":"\n\n## Resources\n\n- https://blogit.michelin.io/an-introduction-to-datalog/","n":0.577}}},{"i":3565,"$":{"0":{"v":"Datahub","n":1},"1":{"v":"\n- [[c.software.data-discovery]]\n- repo: https://github.com/datahub-project/datahub\n\n## Features\n\n- You may be familiar with this [popular blog post](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying) on why logs should be at the heart of your data ecosystem. Turns out, the same is actually true about metadata as well. A modern data catalog  should enable real-time subscription to changes in the metadata as a first-class offering. \n- graph!\n\n## References\n\n- https://www.linkedin.com/blog/engineering/data-management/datahub-popular-metadata-architectures-explained\n  - \"Out of all the systems out there that we’ve surveyed, the only ones that have a third-generation metadata architecture are [[prdct.atlas]], [[prdct.egeria]], [[prdct.databook]], and [[prdct.datahub]]. Among these, Apache Atlas is tightly coupled with the Hadoop ecosystem. Some companies are experimenting with attaching Amundsen on top of Atlas to try to get the best of both worlds, but it seems like there are several challenges with this integration. For example, you must ingest your metadata and store it in Atlas’s graph and search index, bypassing Amundsen’s data ingestion, storage, and indexing modules completely. This means any new concepts you want to model need to be introduced as Atlas concepts, and then bridged with Amundsen’s UI, leading to quite a bit of complexity. Egeria supports an integration of different catalogs through a metadata event bus, but it doesn’t seem to be feature complete yet as of this writing. Uber Databook seems to be based on very similar design principles as DataHub, but is not available as open source. Of course, we are biased due to our personal experience with DataHub, but the open-sourced DataHub offers all the benefits of a third-generation metadata system with the ability to support multiple types of entities and relationships and a stream-first architecture.\"","n":0.061}}},{"i":3566,"$":{"0":{"v":"DataHike","n":1},"1":{"v":"\n\n- [[c.software.database.graph]]\n- [[p.hasRepository]] https://github.com/replikativ/datahike\n- [[p.isPortOf]] [[prdct.datascript]]\n","n":0.408}}},{"i":3567,"$":{"0":{"v":"Datagrip","n":1},"1":{"v":"\n- https://www.jetbrains.com/datagrip/\n- published-by: [[org.jetbrains]]","n":0.5}}},{"i":3568,"$":{"0":{"v":"Datagraft","n":1},"1":{"v":"\n- https://datagraft.net/ (dead)\n- repo: https://github.com/datagraft/datagraft-platform\n\n## References\n\n- https://www.sintef.no/en/publications/publication/1452414/","n":0.378}}},{"i":3569,"$":{"0":{"v":"Datadog","n":1}}},{"i":3570,"$":{"0":{"v":"Real User Monitoring","n":0.577},"1":{"v":"\n#aka RUM","n":0.707}}},{"i":3571,"$":{"0":{"v":"Databus","n":1},"1":{"v":"\n- [[c.software.data-management-platform]]\n- docs: https://dbpedia.gitbook.io/databus\n\n## Description\n\n- The Databus implements well-known concepts from Software Engineering such as agile rapid prototyping, build automation, test-driven development for Data Engineering and connects data via a loosely-coupled bus system and a common, but extensible metadata format through state-of-the-art semantic technologies such as ontologies, SPARQL, SHACL and Linked Data.\n\n## Features\n\n- Semantic Layer On-Top: Databus is a proud member of the Open Energy Family and deployed as an additional semantic layer over the various existing databases to extend the underlying rigid metadata schemas and enable search, persistent IDs and provenance tracking of scientific results.\n\n## Use cases\n\n## data version control\n\n- Databus uses the Apache Maven concept hierarchy (group, artifact, version) and ports it to a Linked Data based platform, in order to manage data pipelines and enable automated publishing and consumption of data.\n  - we define **compiling of data** as the process that converts, transforms or translates data geared to the needs of a specific target application\n\n## Automated deployment\n\n- Dataset Publication: microservice's configuration and data can be published as individual or combined datasets on the DBpedia Databus. For example, all the configurations can be published as a single dataset where different content variants serve for searching the right configuration. Datasets can be versioned, allowing for easy rollbacks and traceability.\n- Semantic Queries: DBpedia Databus supports semantic querying, allowing microservices or deployment engine to query for specific data subsets or retrieve relevant configurations based on their requirements.\n\n## Concepts\n\n- Collection: a labelled SPARQL query that is retrievable via URI\n\n\n## References\n\n- https://dbpedia.gitbook.io/databus\n- https://dbpedia.gitbook.io/databus/v/download-client","n":0.063}}},{"i":3572,"$":{"0":{"v":"Databook","n":1},"1":{"v":"\n- [[c.software.data-discovery]]","n":0.707}}},{"i":3573,"$":{"0":{"v":"data.world","n":1},"1":{"v":"\n- [[c.software.semantic.browser]]\n\n## Thoughts\n\n- used [[t.cs.web.w3c.rdf.named-graphs]]","n":0.447}}},{"i":3574,"$":{"0":{"v":"Data Oriented Pyglet","n":0.577},"1":{"v":"\n- #dead\n- [[t.cs.entity-component-system]]\n- repo: https://github.com/Permafacture/data-oriented-pyglet\n- ","n":0.447}}},{"i":3575,"$":{"0":{"v":"Darktrace Respond","n":0.707},"1":{"v":"\n- AI makes micro-decisions\n- proportionate and targeted actions\n- reacts faster than human teams, \"10 seconds\"\n- enforces normal business operations","n":0.229}}},{"i":3576,"$":{"0":{"v":"Darktrace Prevent","n":0.707},"1":{"v":"\n- feeds back critical information to the Continuous AI Loop\n- learns normal \"patterns of life\" \"on the job\" across all environments\n- \"zero-scope\": no IP ranges or technical input needed\n- hardens denfenses by feeding into   [[prdct.darktrace-detect]] and [[prdct.darktrace-respond]]\n- helps [[t.cs.security.risk-management.prioritization]]\n- tailored [[t.cs.security.security-awareness-training]] for high-risk individuals ","n":0.151}}},{"i":3577,"$":{"0":{"v":"Darktrace Heal","n":0.707},"1":{"v":"\n- provides healing\n- restores assets to their condition before an attack\n- empowers informed human decisions","n":0.258}}},{"i":3578,"$":{"0":{"v":"Darktrace Detect","n":0.707},"1":{"v":"\n- [[p.hasURL]] https://darktrace.com/products/detect","n":0.577}}},{"i":3579,"$":{"0":{"v":"Dapr","n":1},"1":{"v":"\n- [[c.software.distributed-systems-runtime]] [[c.software.actor-framework]]\n- url: https://dapr.io\n- repo: https://github.com/dapr\n- [[c.documentation]] https://docs.dapr.io\n- alternatives: \n\n## [[p.supports]]\n\n- c# #python javascript java #go #php #c++ #rust (see https://docs.dapr.io/developing-applications/sdks/)\n- [[prdct.nats.jetstream]] (alpha for state)\n- [[prdct.postgres]]\n- #python: [[prdct.grpc]] [[prdct.fastapi]] [[prdct.flask]]\n- [[prdct.mqtt]]\n\n## [[p.hasNoSupportFor]]\n\n- [[t.cs.languages.f-sharp]] or any functional language\n\n## Features\n\n-   **Client**: The Dapr client allows you to invoke Dapr building block APIs and perform each building block’s actions\n-   **Server extensions**: The Dapr service extensions allow you to create services that can be invoked by other services and subscribe to topics\n-   **Actor**: The Dapr Actor SDK allows you to build virtual actors with methods, state, timers, and persistent reminders\n-   **Workflow**: Dapr Workflow makes it easy for you to write long running business logic and integrations in a reliable way\n\n### State Store (Hot Data)\n\n- key-value only? can work with relational dbs, but not designed for all yer customer data (https://youtu.be/0y7ne6teHT4)\n  - [share state across applications](https://docs.dapr.io/developing-applications/building-blocks/state-management/howto-share-state/)\n\n### Bindings\n\n- input bindings trigger endpoint methods\n- dapr executes operations on external systems via output bindings\n\n## Use Cases\n\n- \"You want to work with single-threaded objects that do not require significant interaction from external components, including querying state across a set of actors.\"\n\n## [[c.faq]]\n\n- \"What is the relationship between Dapr, Orleans and Service Fabric Reliable Actors?\"\n  - Dapr's actor framework is  similar to Orleans\n- \"Differences between Dapr and an actor framework\"\n  - \"actors can be called from any language. This allows actors written in one language to invoke actors written in a different language... Currently .NET, Java, Go and Python SDK have actor frameworks.\"\n  -  Dapr is a comprehensive microservice sidecar that does lots of different things.\n    - https://www.reddit.com/r/dotnet/comments/13t3tsf/is_dapr_actually_used_by_anyone/ \n      - \"if you have a product that aspires to be vendor agnostic, it might help\"\n\n## Issues\n\n-\"You cannot dynamically add new programmatic subscriptions, only add new ones at compile time\"\n  - https://docs.dapr.io/developing-applications/building-blocks/pubsub/subscription-methods/\n  - and presumably the declarative subscriptions too\n\n## [[c.notes]]\n\n- \"Redis does not support transaction rollbacks and should not be used in production as an actor state store.\"\n- the Dapr SDK for Java builds upon Project Reactor, all methods are asynchronous. This means they return a Mono<T> or a Flux<T>, respectively a single item or a stream of items somewhere in the future. Since both a Mono<T> and a Flux<T> are “cold”, you have to “subscribe” on them. By subscribing, you tell the code that will produce the items that you are ready to process the items that they will produce. One of the ways to do this is by invoking .block() on the Mono<T> or Flux<T>.\n  - https://maarten.mulders.it/2022/01/the-dapr-sdk-for-java-pubsub-distributed-tracing/\n\n\n## Examples\n\n- https://github.com/dotnet-architecture/eShopOnDapr #showcase\n- [[prdct.dapr-traffic-control]]\n- https://github.com/kimcuhoang/dapr-tye-simple-microservices\n- https://github.com/thangchung/practical-dapr #dead\n- https://github.com/vietnam-devs/coolstore-microservices \"Minimal Clean Architecture with DDD-lite, CQRS-lite, and just enough Cloud-native patterns apply on the simple eCommerce\"\n- https://github.com/benc-uk/dapr-store #go\n- https://github.com/sjefvanleeuwen/showcase\n  - [[p.builtOn]] [[prdct.zeebe]] [[prdct.camunda.modeler]]\n- https://github.com/thangchung/coffeeshop-on-dapr\n- https://github.com/thangchung/clean-architecture-dotnet\n\n## Resources\n\n- https://www.reddit.com/r/dotnet/comments/13t3tsf/is_dapr_actually_used_by_anyone/\n  - \"just a set of APIs hosted in the sidecar that you can opt-in to calling if you want some particular feature such as using Pubsub or acquiring a distributed lock. It does not enforce any particular way for you to structure your application code\"\n- https://raw.githubusercontent.com/dotnet-architecture/eBooks/main/current/dapr-for-net-developers/Dapr-for-NET-Developers.pdf\n- https://learning.oreilly.com/library/view/practical-microservices-with/9781803248127/B18620_01.xhtml#_idParaDest-31\n- https://blog.dapr.io/posts/2021/01/26/observing-dapr-applications-with-new-relic-one/\n- https://dev.to/aaronblondeau/virtual-actors-dapr-vs-orleans-30f0\n - https://medium.com/event-driven-utopia/5-reasons-why-you-should-use-microsoft-dapr-to-build-event-driven-microservices-cb2202c579a0\n- https://itnext.io/dapr-vs-envoy-when-to-use-what-6c2ac3caaed2\n- https://www.daveabrock.com/2021/04/29/meet-dapr/\n- [-  ] https://medium.com/codex/event-driven-programming-with-dapr-db96ac855a2d\n\n### Learning Resources\n\n- https://learn.microsoft.com/en-us/dotnet/architecture/dapr-for-net-developers/\n- [[book.practical-microservices-with-dapr-and-dotnet]]                            - https://www.freshbrewed.science/dapr-getting-started/index.html\n  - has a node service and python client\n\n## References\n\n- [[event.2024.03.07.dapr-actors]]","n":0.044}}},{"i":3580,"$":{"0":{"v":"Workflow","n":1},"1":{"v":"\nThe durable, resilient Dapr Workflow capability:\n\n-   Offers a built-in workflow runtime for driving Dapr Workflow execution.\n-   Provides SDKs for authoring workflows in code, using any language.\n-   Provides HTTP and gRPC APIs for managing workflows (start, query, pause/resume, raise event, terminate, purge).\n-   Integrates with any other workflow runtime via workflow components. (!)\n\n## Details\n\n- Because the workflow engine will replay the workflow several times, the workflow code must be deterministic. This means that each time the workflow replays, the code must behave in the same way as the initial execution, and any arguments used as activity inputs should stay the same.\n- Any non-deterministic code should go into activities. This includes, calling other (Dapr) services, state stores, pub/sub systems, and external endpoints. The workflow should only be responsible for the business logic that defines the sequence of the activities.\n\n\n## Resources\n\n- https://www.diagrid.io/blog/authoring-dapr-workflows-in-dotnet","n":0.085}}},{"i":3581,"$":{"0":{"v":"Dapr Traffic Control","n":0.577},"1":{"v":"\n- repo: https://github.com/EdwinVW/dapr-traffic-control\n- written-in: c# javascript\n- [[p.builtOn]] [[prdct.phaser]] [[prdct.dapr]]\n\n## Visual Simulation\n\n- `d` for debug\n- ","n":0.267}}},{"i":3582,"$":{"0":{"v":"Dapr Actor Demos","n":0.577},"1":{"v":"\n- repo: https://github.com/diagrid-labs/dapr-actor-demos\n- uses: [[prdct.CodeTour]] [[prdct.rest-client]] [[prdct.ably]]","n":0.378}}},{"i":3583,"$":{"0":{"v":"Daily.Dev","n":1}}},{"i":3584,"$":{"0":{"v":"Dagster","n":1},"1":{"v":"\n![[prdct.n8n#^xnxaubd7sqiw]]\n","n":1}}},{"i":3585,"$":{"0":{"v":"D3","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n\n## Resources\n\n- https://vsantos.info/animate-svg-with-d3/\n  - \"I have tried different frameworks to animate like [[prdct.joint-js]], [[prdct.pixi-js]], [[prdct.three-js]], [[prdct.popmotion]], [[prdct.react-spring]], [[prdct.animate-css]], [[prdct.animator-js]], and [[prdct.d3-js]].\"","n":0.213}}},{"i":3586,"$":{"0":{"v":"D3 Graphviz","n":0.707},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- repo: https://github.com/magjac/d3-graphviz","n":0.5}}},{"i":3587,"$":{"0":{"v":"D3 Geo Voronoi","n":0.577},"1":{"v":"\nrepo: https://github.com/Fil/d3-geo-voronoi\n\n## [[p.hasAPI]]\n\n- GeoJSON API\n- geoDelaunay","n":0.408}}},{"i":3588,"$":{"0":{"v":"D3 Delaunay","n":0.707}}},{"i":3589,"$":{"0":{"v":"D20srd","n":1},"1":{"v":"\n- https://www.d20srd.org/","n":0.707}}},{"i":3590,"$":{"0":{"v":"d20","n":1}}},{"i":3591,"$":{"0":{"v":"D20 Pro","n":0.707},"1":{"v":"\n- [[c.software.rpg.virtual-tabletop.fat-client]] [[c.software.rpg.virtual-tabletop]]\n- https://d20pro.com/\n\n## References\n\n- https://www.reddit.com/r/rpg/wiki/con/\n- https://en.wikipedia.org/wiki/GameTable_Online","n":0.378}}},{"i":3592,"$":{"0":{"v":"D2","n":1},"1":{"v":"\n- url: https://d2lang.com/\n- [[c.software.tools.diagramming]]\n  \n## [[p.supportedBy]]\n\n- [[prdct.structurizr]]\n\n## Resources\n\n- https://terrastruct-site-assets.s3.us-west-1.amazonaws.com/documents/d2_cheat_sheet.pdf","n":0.333}}},{"i":3593,"$":{"0":{"v":"Studio","n":1}}},{"i":3594,"$":{"0":{"v":"CZML","n":1},"1":{"v":"\n- related: [[prdct.czml-writer]]\n\n## Description\n\n- \"A [CZML document](https://github.com/AnalyticalGraphicsInc/czml-writer/wiki/CZML-Structure) is an array of ‘[packet](https://github.com/AnalyticalGraphicsInc/czml-writer/wiki/Packet)’ elements, each of which represents one object in the Cesium visualization scene (e.g., a cylinder in our case), and its associated properties (e.g., color, position, availability). It is worth mentioning that the [Cesium Sandcastle site](https://sandcastle.cesium.com/) provides a fair number of live examples that can be used to learn CZML.\"\n\n## Features\n\n- \"describe properties that change value over time. For example, a line can be red for one interval of time and blue for another. Clients are also expected to be able to interpolate over time-tagged samples. If the position of a vehicle is specified at two times, the client can accurately display the location of the vehicle in between those two times by using a CZML-specified interpolation algorithm. Every property is time-dynamic.\"\n- \n\n## Comparison\n\n## vs [[prdct.kml]]\n\n## Resources\n\n- https://cesium.com/blog/2018/03/21/czml-time-animation/","n":0.086}}},{"i":3595,"$":{"0":{"v":"czml-writer","n":1},"1":{"v":"\n- repo: https://github.com/AnalyticalGraphicsInc/czml-writer","n":0.577}}},{"i":3596,"$":{"0":{"v":"Cytoscape","n":1},"1":{"v":"\n\n\nurl: https://js.cytoscape.org/\n- [[p.supports]] directed graphs, undirected graphs, mixed graphs, loops, multigraphs, compound graphs (a type of hypergraph), and so on\n\n","n":0.224}}},{"i":3597,"$":{"0":{"v":"Cypress","n":1},"1":{"v":"\n## [[p.hasReview]]\n\n- https://engineering.udacity.com/cypress-is-superior-to-react-testing-library-heres-why-3fac0675910","n":0.577}}},{"i":3598,"$":{"0":{"v":"Cypher Query","n":0.707}}},{"i":3599,"$":{"0":{"v":"Cyc","n":1},"1":{"v":"\n- url: https://cyc.com/\n\n## Issues\n\n- also described as a huge ontology, but axioms are not consistent\n  - @barry-smith\n- proprietart","n":0.236}}},{"i":3600,"$":{"0":{"v":"Cupboard","n":1},"1":{"v":"\n## References\n\n- https://link.springer.com/chapter/10.1007/978-3-642-02121-3_81\n- https://www.aifb.kit.edu/web/Inproceedings1957","n":0.5}}},{"i":3601,"$":{"0":{"v":"Cuis","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.smalltalk.cuis]]","n":0.577}}},{"i":3602,"$":{"0":{"v":"Cucumber","n":1},"1":{"v":"\n- [[c.software.tools.testing]] ","n":0.707}}},{"i":3603,"$":{"0":{"v":"ct.js","n":1},"1":{"v":"\n- [[p.basedOn]] [[prdct.pixi-js]]\n- [[p.hasLearningResource]] https://docs.ctjs.rocks/","n":0.447}}},{"i":3604,"$":{"0":{"v":"CSS","n":1},"1":{"v":"\n## Resources\n\n### Resources Lists\n\n- https://dev.to/lissy93/super-useful-css-resources-1ba3","n":0.447}}},{"i":3605,"$":{"0":{"v":"Crux Geo","n":0.707},"1":{"v":"\n- repo: https://github.com/teknql/crux-geo\n- related: [[prdct.xtdb.v1]] \n- built_on: [[prdct.sqlite.spatialite]]","n":0.354}}},{"i":3606,"$":{"0":{"v":"Crossplane","n":1},"1":{"v":"\n## Cons\n\n- \"crossplane has an incredibly steep learning curve, even when you have several years of sysadmin/devops/IaC/K8S experience. And it is very hard to debug.\" [^1]\n\n\n## References\n\n- [^1]: https://www.reddit.com/r/devops/comments/10iix3j/whats_your_thoughts_on_crossplane/\n\n```yaml\nurl: https://www.crossplane.io/\n\n```","n":0.183}}},{"i":3607,"$":{"0":{"v":"Croquet","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://croquet.io https://npm.io/package/@croquet/croquet\n- [[p.supports]] [[prdct.unity]] [[t.cs.web]]\n","n":0.378}}},{"i":3608,"$":{"0":{"v":"CroquetOS","n":1},"1":{"v":"\n- [[c.software.virtual-reality]]\n- url: https://croquet.io/croquet-os/\n- supports: [[prdct.wordpress]]\n- related: [[prdct.croquet.microverse-builder]]\n\n## Features\n\n- multi-user [[c.software.live-programming]]\n- \"time-based OS\": A shared simulation requires not just that external events are propagated between the instances of the shared VM, but these events have an associated time stamp provided by the Croquet Reflector. This ensures that events occur and are processed at the same virtual time for all participants in a session. Secure event/message distribution \n- Applications are structured into a shared and a local part, but both parts are executed locally and developed using only client-side tools.\n\n## Thoughts\n\n- perfectly synced worlds doesn't seem optimal, since users don't all need the whole thing\n\n\n## Architecture\n\n- reflector runs somewhere on the internet\n- kernel is replicated virtual machine that runs bit-identical on all client systems\n- locally-rendered view\n- events/messages are sent to reflector, sends to kernels\n- ","n":0.087}}},{"i":3609,"$":{"0":{"v":"Microverse Builder","n":0.707},"1":{"v":"\n- https://croquet.io/microverse-builder/\n\n## Features\n\n- multi-user [[c.software.live-programming]]\n\n\n### Connectors\n\nEnable cards to access external data streams that can then be displayed in all participating systems in a session.\n","n":0.204}}},{"i":3610,"$":{"0":{"v":"Creta","n":1},"1":{"v":"\n- dead since 2023\n- https://creta.hypermedia.app/\n- repo: https://github.com/hypermedia-app/creta","n":0.378}}},{"i":3611,"$":{"0":{"v":"CouchDB","n":1},"1":{"v":"\n- different_from: [[prdct.couchbase]]\n- ","n":0.577}}},{"i":3612,"$":{"0":{"v":"Couchbase","n":1}}},{"i":3613,"$":{"0":{"v":"Couchbase Lite","n":0.707}}},{"i":3614,"$":{"0":{"v":"Coswot Ontology","n":0.707}}},{"i":3615,"$":{"0":{"v":"Cosplayengine","n":1},"1":{"v":"\n- url: https://cosplayengine.com/\n- repo: https://github.com/nivanov/cosplay\n- written-in: scala","n":0.378}}},{"i":3616,"$":{"0":{"v":"COSMO","n":1},"1":{"v":"\n- [[c.ontology.upper]]\n\n## Cons\n\n- \"7339 types (OWL classes), 808 relations, and 2039 restrictions\"\n\n## References\n\n- https://bartoc.org/en/node/657#about","n":0.267}}},{"i":3617,"$":{"0":{"v":"Corporate Memory Enterprise Knowledge Graph Platform","n":0.408},"1":{"v":"\n- published-by: [[org.eccenca]]","n":0.577}}},{"i":3618,"$":{"0":{"v":"Cormas","n":1},"1":{"v":"\n- url: http://cormas.cirad.fr/indexeng.htm\n- repo: https://github.com/cormas/cormas (new version, based on [[prdct.pharo]])","n":0.316}}},{"i":3619,"$":{"0":{"v":"Corese","n":1},"1":{"v":"\n- https://github.com/Wimmics/corese\n\n## Features\n\n- allows to create, manipulate, parse, serialize, query, reason and validate RDF data.","n":0.258}}},{"i":3620,"$":{"0":{"v":"CoreNLP","n":1},"1":{"v":"\n- url: https://stanfordnlp.github.io/CoreNLP/\n- repo: https://github.com/stanfordnlp/CoreNLP\n- written-in: java\n- description: provide the foundational building blocks for higher-level and domain-specific text understanding applications\n- [[p.usedBy]] https://nlp4j.org/ \n  - [[c.reference]] https://groovy.apache.org/blog/natural-language-processing-with-groovy","n":0.196}}},{"i":3621,"$":{"0":{"v":"Core Platform","n":0.707},"1":{"v":"\n- commercial\n- https://telicent.io/the-core-platform/","n":0.577}}},{"i":3622,"$":{"0":{"v":"Core Ontology for Biology and Biomedicine","n":0.408},"1":{"v":"\n- #aka COB\n- url: https://ontobee.org/ontology/COB\n- [[p.isRelated]] [[prdct.open-biological-and-biomedical-ontology-foundry]]","n":0.378}}},{"i":3623,"$":{"0":{"v":"Core Games","n":0.707},"1":{"v":"\n- url: https://coregames.com\n- #publisher [[org.manticore-games]]\n- [[p.builtOn]] [[prdct.unreal]] [[prdct.lua]]\n\n\n## Resources\n\n- https://forums.coregames.com/t/advanced-code-architecture-for-core-part-2-entity-component-system/3194/1 and https://forums.coregames.com/t/advanced-code-architecture-for-core-part-1-model-view-controller/3188\n  - [[p.mentioned]] [[t.cs.sd.architecture.mvc]]\n  - but there doesn't seem to be much references to a Descendent's architecture","n":0.189}}},{"i":3624,"$":{"0":{"v":"Corda","n":1}}},{"i":3625,"$":{"0":{"v":"Coral","n":1},"1":{"v":"\n- repo: https://github.com/StudioCherno/Coral","n":0.577}}},{"i":3626,"$":{"0":{"v":"Copper","n":1},"1":{"v":"\n- [[c.Software.Workflow]]\n- example: https://github.com/copper-engine/copper-starter\n\n## Features\n\n- You can dynamically modify workflows at runtime! As soon as you save the changed code, COPPER compiles it automatically and loads it.\n- You can implement both real-time tasks as well as persistent long-running tasks.\n- One of its key features is the asynchronous workflow processing that supports the processing of a large number of workflow threads in parallel without facing operating system thread count limitations.\n- With COPPER, you can easily implement high-performance transaction systems.\n- ","n":0.113}}},{"i":3627,"$":{"0":{"v":"Converse JS","n":0.707},"1":{"v":"\n- [[c.software.xmpp-client.web]]\n- repo: ","n":0.577}}},{"i":3628,"$":{"0":{"v":"Convergence","n":1},"1":{"v":"\n- dead-ish\n- written_in: scala\n- url: https://convergence.io/","n":0.408}}},{"i":3629,"$":{"0":{"v":"Conventional Commits","n":0.707},"1":{"v":"\n## #summary\n\n- Commits MUST be prefixed with a type, which consists of a noun\n  - e.g feat:, fix:, build:, chore:, ci:, docs:, style:, refactor:, perf:, test:\n- scope after type is optional\n- ! for breaking change\n\n- [[p.hasURL]] https://www.conventionalcommits.org \n- [[p.isRelated]] https://gist.github.com/joshbuchea/6f47e86d2510bce28f8e7f42ae84c716\n- [[p.hasSpecification]] https://www.conventionalcommits.org/en/v1.0.0/\n\n## Thoughts\n\n- `!` used for BREAKING CHANGE\n  - `!` could be used in [[gd]] for emphasizing tags, predicates, or objects  ^cN92w9TjfnXM\n    - hard to imagine the need to emphasize an subject but I suppose \n      - (since subjects are ultimately equivalent to objects related with an inverse predicate)\n    - emphasis could denote \"default\" or preferred properties\n- always at the start, understandably... \n  - but\n    - if you treated them as tags, you could include them at the end, or anywhere internal\n","n":0.091}}},{"i":3630,"$":{"0":{"v":"Construct 3","n":0.707},"1":{"v":"\n- [[p.supports]] javascript\n- [[p.instanceOf]] [[c.software.game-platform]]\n- \"runs right inside your browser\"\n\n## Features\n\n- Game Changing Visual Scripting, \"coding optional\"","n":0.243}}},{"i":3631,"$":{"0":{"v":"Connext","n":1}}},{"i":3632,"$":{"0":{"v":"Connect","n":1},"1":{"v":"\n\n- [[p.builtOn]] [[prdct.node]]\n- ","n":0.577}}},{"i":3633,"$":{"0":{"v":"Confluence","n":1}}},{"i":3634,"$":{"0":{"v":"Conductor","n":1},"1":{"v":"\n- dead\n- repo: https://github.com/danielgerlag/conductor\n- built_on: [[prdct.workflow-core]]\n- written_in: c#\n\n![[prdct.infinitic#similar]]\n\n## Description\n\nConductor is a workflow server built upon Workflow Core that enables you to coordinate multiple services and scripts into workflows so that you can rapidly create complex workflow applications. Workflows are composed of a series of steps, with an internal data object shared between them to pass information around. Conductor automatically runs and tracks each step, and retries when there are errors.\n\nWorkflows are written in either JSON or YAML and then added to Conductor's internal registry via the definition API. Then you use the workflow API to invoke them with or without custom data.\n\n## Issues\n\n- Conductor uses a JSON-based DSL for workflow definitions ^jf9f3krl2u71","n":0.094}}},{"i":3635,"$":{"0":{"v":"Concurrentsim Jl","n":0.707},"1":{"v":"\n- [[c.software.simulation-framework]]\n- repo: https://github.com/JuliaDynamics/ConcurrentSim.jl\n- written-in: #julia\n\n## Features\n\n-  uses coroutines to make arbitrary jumps in time\n","n":0.258}}},{"i":3636,"$":{"0":{"v":"Conceptnet","n":1},"1":{"v":"\n- url: https://conceptnet.io/\n- repo: https://github.com/commonsense/conceptnet5","n":0.447}}},{"i":3637,"$":{"0":{"v":"Comunica","n":1},"1":{"v":"\n- \n- written_in: typescript\n- supports: [[prdct.solid]] [[prdct.linked-data-fragments]]\n- used-in: [[prdct.ldflex]] [[prdct.graphql-ld]] [[prdct.quadstore]]","n":0.302}}},{"i":3638,"$":{"0":{"v":"Computational Tree Logics","n":0.577},"1":{"v":"\n- related: [[prdct.reo]]","n":0.577}}},{"i":3639,"$":{"0":{"v":"Composio","n":1},"1":{"v":"\n- supports: python and typescript","n":0.447}}},{"i":3640,"$":{"0":{"v":"Swekit","n":1},"1":{"v":"\n- https://github.com/ComposioHQ/composio/tree/master/python/swe\n\n## Features\n\n-   **Customizable**: It is simple and highly customizable. You can use the LLM providers of your choice and change the prompts to suit your requirements.\n-   **Framework Agnostic**: It works with all the popular agentic frameworks, such as LangChain and LlamaIndex.\n-   **Extensible**: Adding more tools, such as browsing and scrapping, can easily extend the agent's capability. You can add tools from the Composio ecosystem.\n-   **Open-source**: Needless to say, the code is open-source, so you can fork and add custom changes.\n-   **Multiple Language Support**: SweKit has native support for Python and Typescript. You can go with the language of your choice.\n\n## References\n\n- https://dev.to/github20k/i-10xd-my-coding-productivity-using-this-ai-tool-i-wish-i-had-known-it-earlier-2eoo?context=digest","n":0.099}}},{"i":3641,"$":{"0":{"v":"Components.js","n":1},"1":{"v":"\n- docs: https://componentsjs.readthedocs.io/en/latest/\n- repo: https://github.com/LinkedSoftwareDependencies/Components.js/\n- written_in: typescript\n\n","n":0.378}}},{"i":3642,"$":{"0":{"v":"Component Story Format","n":0.577},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/ComponentDriven/csf\n","n":0.577}}},{"i":3643,"$":{"0":{"v":"CoModIDE","n":1},"1":{"v":"\n- https://comodide.com/\n- [[c.software.plugin.protege]]\n- ","n":0.577}}},{"i":3644,"$":{"0":{"v":"Community Solid Server","n":0.577},"1":{"v":"\n- [[c.software.semantic.solid-server]]\n- https://communitysolidserver.github.io/CommunitySolidServer/latest/\n- repo: https://github.com/CommunitySolidServer/CommunitySolidServer/\n- written-in: typescript\n\n![[prdct.node-solid-server#similar]]","n":0.378}}},{"i":3645,"$":{"0":{"v":"Commonplace","n":1},"1":{"v":"\n- [[p.hasSite]] https://www.commonplace.one/\n- [[p.supports]] [[prdct.markdown]]","n":0.447}}},{"i":3646,"$":{"0":{"v":"Common Logic","n":0.707},"1":{"v":"\n![](/assets/images/2024-03-05-15-29-59.png)\n\n## Solutions\n\n[[prdct.hets]]\n\n## Resources\n\n- https://www.w3.org/2004/12/rules-ws/slides/pathayes.pdf","n":0.5}}},{"i":3647,"$":{"0":{"v":"Common Core Ontologies","n":0.577},"1":{"v":"\n- [[c.ontology.upper]]\n- repo: https://github.com/CommonCoreOntology/CommonCoreOntologies\n- [[p.used]] [[prdct.owlapi]]\n- extends: [[prdct.basic-formal-ontology]]\n\n\n## Features\n\n- familial relations\n- communications acts\n\n## Sample of Extension\n- Aircraft Ontology\n- Airforce Aircraft Maintenance Ontology\n- Army Universal Task List Ontology\n- Atmospheric Feature Ontology\n- Cyber Ontology\n- Hydrographic Feature Ontology\n- Legal and Criminal Act Ontology\n- Marine Corps Task List Ontology\n- Military Operations Ontology\n- Mission Planning Ontology\n- Occupation Ontology\n- Outerspace Ontology\n- Physiographic Feature Ontology\n- Sensor Ontology\n- Spacecraft Mission Ontology\n- Spacecraft Ontology\n- Space Event Ontology\n- Space Object Ontology\n- Transportation Infrastructure Ontology\n- Undersea Warfare Ontology\n- Watercraft Ontology\n\n## References\n\n- https://www.nist.gov/system/files/documents/2021/10/14/nist-ai-rfi-cubrc_inc_004.pdf\n- ","n":0.111}}},{"i":3648,"$":{"0":{"v":"Commander","n":1},"1":{"v":"\nrepo: https://github.com/tj/commander.js\n","n":0.707}}},{"i":3649,"$":{"0":{"v":"Comedy","n":1},"1":{"v":"\n- repo: https://github.com/untu/comedy\n- ","n":0.577}}},{"i":3650,"$":{"0":{"v":"Comake","n":1},"1":{"v":"\n\nbrowser extension-based bookmark manager posing as a KnowledgeOS\n\n- [[p.hasURL]] https://www.comake.io/\n- [[p.hasApplication]] [[t.km]] \n","n":0.277}}},{"i":3651,"$":{"0":{"v":"Colyseus","n":1},"1":{"v":"\n- [[c.Software.Game-Framework]] [[c.Software.real_time_framework]]\n\n- repo: https://github.com/colyseus/colyseus\n- creator: @endel-dreyer\n\n- [[p.ownedBy]] [[org.lucid-sight]]\n- [[p.hasRelatedSolution]] https://github.com/endel/ecs #ecs\n- [[p.hasClientSupport]]\n   - [[prdct.unity]]\n   - [[prdct.defold]]\n     - https://docs.colyseus.io/getting-started/defold-client/\n   - [[prdct.babylon-js]]\n     - https://doc.babylonjs.com/guidedLearning/networking/Colyseus\n   - [[prdct.playcanvas]]\n     - https://developer.playcanvas.com/en/tutorials/real-time-multiplayer-colyseus/\n   - [[prdct.phaser]]\n     - https://github.com/colyseus/tutorial-phaser/tree/master\n     - https://learn.colyseus.io/phaser\n   - [[prdct.construct]]\n   - [[prdct.haxe]]\n- [[p.hasExample]]\n  - [[Tosios|game.tosios]]\n  - https://forum.babylonjs.com/t/open-source-multiplayer-3d-rpg-using-colyseus/35733\n    - [[p.mentioned]] [[prdct.yuka-ai]]\n\n## Issues\n\n- [Ability to serialize/deserialize Schema on the server side](https://github.com/colyseus/schema/issues/115)\n  - \"So I guess the option at this point would be to serialize the state to the database continually, but only as a backup. If the server crashes it can reread the state and would send the full update to the clients to ensure they are back in sync. Which is probably what you want anyway.\"\n\n### Best Practices Limitations\n\n-   Keep your room classes as small as possible, delegating game-specific functionality to other composable structures.\n-   Keep your synchronizeable data structures as small as possible\n    -   Ideally, each class extending `Schema` should only have field definitions.\n    -   Do not implement _heavy_ game logic inside `Schema` structures. _Some_ logic is fine, specially if they're self-contained within the scope of the structure itself, mutating only its own properties.\n-   Rooms should have as little code as possible, and forward actions to other structures\n-   Your game logic should be handled by other structures, such as:\n    -   Custom external functions\n    -   The [Command Pattern](https://docs.colyseus.io/best-practices//#the-command-pattern).\n    -   An [Entity-Component System](https://docs.colyseus.io/best-practices//#entity-component-system-ecs).\n\n\n## Resources\n\n### Learning Resources\n- https://drive.google.com/file/d/19EyfO5xQUNx4ejxFTz1KYDjzfGo7UPHA/view\n  - [full doc available for $10](https://endel.gumroad.com/l/mazmorra)\n  - [[p.hasAuthor]] @endel-dreyer\n- [Making Online Multiplayer Game Experiences](https://docs.google.com/presentation/d/e/2PACX-1vSjJtmU-SIkng_bFQ5z1000M6nPSoAoQL54j0Y_Cbg7R5tRe9FXLKaBmcKbY_iyEpnMqQGDjx_335QJ/embed?start=false&loop=false&delayms=3000#slide=id.g6de835f45d_0_170)\n- [Tetrolyseus](https://blog.s1h.org/colyseus-multiplayer-game/)\n- [[Real Time Multiplayer Colyseus Tutorial|ar.real-time-multiplayer-colyseus]]\n- https://blog.logrocket.com/building-a-multiplayer-game-with-colyseus-io/\n- https://www.smashingmagazine.com/2021/10/real-time-multi-user-game/\n\n## Implementations\n\n- [[game.tosios]]\n- [[prdct.t5c]]\n\n## [[prdct.windows.wsl]]\n\n- netsh interface portproxy add not necessary\n","n":0.063}}},{"i":3652,"$":{"0":{"v":"Colore","n":1},"1":{"v":"\n- repo: https://github.com/gruninger/colore/\n- related: [[prdct.common-logic]]\n\n## Objective\n\n","n":0.408}}},{"i":3653,"$":{"0":{"v":"Cola JS","n":0.707},"1":{"v":"\n- url: https://ialab.it.monash.edu/webcola/\n- #aka WebCola\n- repo: https://github.com/tgdwyer/WebCola","n":0.378}}},{"i":3654,"$":{"0":{"v":"CoJACK","n":1},"1":{"v":"\n- url: https://aosgrp.com.au/cojack/\n- related: [[prdct.jack]] [[prdct.c-bdi]]\n\n## References\n\n- [[ar.co-jack-a-high-level-cognitive-architecture-with-demonstrations-of-moderators-variability-and-implications-for-situation-awareness]]","n":0.354}}},{"i":3655,"$":{"0":{"v":"Coherence.io","n":1},"1":{"v":"\n- url: https://coherence.io/features\n\n## Features\n\n- High-fidelity interpolation with historical states.\n- Build extremely large worlds with 64-bit world origin shifting.\n- two types of replicated environments - Rooms and Worlds. Rooms are best for session-based multiplayer gameplay that takes place in a short-lived environment. Think of a tennis match, a first-person shooter map, or a race track session. The players go in, play until the end, the results get recorded and the Room is closed. Worlds on the other hand are long-lived and permanent\n- use the Steam Datagram Relay to run your game with zero server costs.","n":0.103}}},{"i":3656,"$":{"0":{"v":"Cogpo","n":1},"1":{"v":"\n- http://www.cogpo.org/\n\n\n## Paradigm Classes\n\nCurrently, CogPO has defined 84 classes of paradigms:\n\n    Action Observation Paradigm\n    Acupuncture Paradigm\n    Anti-Saccades Paradigm\n    Braille Reading Paradigm\n    Breath-Holding Paradigm\n    Chewing or Swallowing Paradigm\n    Classical Conditioning Paradigm\n    Counting or Calculation Paradigm\n    Cued Explicit Recognition Paradigm\n    Deception Task Paradigm\n    Deductive Reasoning Paradigm\n    Delay Discounting Task Paradigm\n    Delayed Match To Sample Paradigm\n    Delayed Non Match To Sample Paradigm\n    Divided Auditory Attention Paradigm\n    Drawing Paradigm\n    Eating or Drinking Paradigm\n    Encoding Paradigm\n    Episodic Recall Paradigm\n    Face Monitor or Discrimination Paradigm\n    Film Viewing Paradigm\n    Finger Tapping Paradigm\n    Fixation Paradigm\n    Flanker Task Paradigm\n    Flashing Checkerboard Paradigm\n    Flexion or Extension Paradigm\n    Free Word List Recall Paradigm\n    Go/No-Go Paradigm\n    Grasping Paradigm\n    Imagined Movement Paradigm\n    Imagined Objects or Scenes Paradigm\n    Isometric Force Paradigm\n    Mental Rotation Paradigm\n    Micturition Task Paradigm\n    Music Comprehension or Production Paradigm\n    n-back Paradigm\n    Naming (Covert) Paradigm\n    Naming (Overt) Paradigm\n    Non-Painful Electrical Stimulation Paradigm\n    Non-Painful Thermal Stimulation Paradigm\n    Oddball Discrimination Paradigm\n    Olfactory Monitor or Discrimination Paradigm\n    Orthographic Discrimination Paradigm\n    Pain Monitor or Discrimination Paradigm\n    Paired Associate Recall Paradigm\n    Passive Listening Paradigm\n    Passive Viewing Paradigm\n    Phonological Discrimination Paradigm\n    Pitch Monitor or Discrimination Paradigm\n    Pointing Paradigm\n    Posner Task Paradigm\n    Reading (Covert) Paradigm\n    Reading (Overt) Paradigm\n    Recitation or Repetition (Covert) Paradigm\n    Recitation or Repetition (Overt) Paradigm\n    Rest Paradigm\n    Reward Task Paradigm\n    Saccades Paradigm\n    Semantic Monitor or Discrimination Paradigm\n    Sequence Recall or Learning Paradigm\n    Simon Task Paradigm\n    Sleep Paradigm\n    Spatial or Location Discrimination Paradigm\n    Sternberg Task Paradigm\n    Stroop Task Paradigm\n    Subjective Emotional Picture Discrimination Paradigm\n    Syntactic Discrimination Paradigm\n    Tactile Monitor or Discrimination Paradigm\n    Task Switching Paradigm\n    Theory of Mind Task Paradigm\n    Tone Monitor or Discrimination Paradigm\n    Tower of London Paradigm\n    Transcranial Magnetic Stimulation Paradigm\n    Vibrotactile Monitor or Discrimination Paradigm\n    Video Games Paradigm\n    Visual Distractor or Visual Attention Paradigm\n    Visual Pursuit or Tracking Paradigm\n    Whistling Paradigm\n    Wisconsin Card Sorting Test Paradigm\n    Word Generation (Covert) Paradigm\n    Word Generation (Overt) Paradigm\n    Word Stem Completion (Covert) Paradigm\n    Word Stem Completion (Overt) Paradigm\n    Writing Paradigm","n":0.057}}},{"i":3657,"$":{"0":{"v":"Cognitive Characteristics Ontology","n":0.577},"1":{"v":"\n- https://smiy.sourceforge.net/cco/spec/cognitivecharacteristics.html\n- [[c.ontology.mid]]\n\n## References\n\n- http://ontologydesignpatterns.org/wiki/Ontology:Cognitive_Characteristics_Ontology","n":0.447}}},{"i":3658,"$":{"0":{"v":"Cognitive Atlas","n":0.707},"1":{"v":"\n- https://www.cognitiveatlas.org/","n":0.707}}},{"i":3659,"$":{"0":{"v":"Cognism","n":1}}},{"i":3660,"$":{"0":{"v":"Cogniam","n":1},"1":{"v":"\n- related: [[prdct.bpmn]] [[prdct.dmn]] [[prdct.sbvr]]\n\n## References\n\n- https://en.wikipedia.org/wiki/Cognition_enhanced_Natural_language_Information_Analysis_Method","n":0.378}}},{"i":3661,"$":{"0":{"v":"Cody","n":1},"1":{"v":"\n- https://sourcegraph.com/cody\n- [[c.software.ai.development-assistant]]","n":0.577}}},{"i":3662,"$":{"0":{"v":"CodiMD","n":1},"1":{"v":"\n- https://codimd.web.cern.ch/\n- superseded-by: [[prdct.hedgedoc]]\n\n## References\n\n- https://volodymyrpavlyshyn.medium.com/codimd-the-collaborative-markdown-editor-for-open-communities-273c839d0cb5","n":0.408}}},{"i":3663,"$":{"0":{"v":"Codewars","n":1},"1":{"v":"\n- url: https://www.codewars.com\n- description: developer training platform and community","n":0.333}}},{"i":3664,"$":{"0":{"v":"Codespells","n":1},"1":{"v":"\n- https://codespells.org/\n- blog: https://codespells.org/#/blog\n- written_in: \n- uses: [[prdct.racket]] [[prdct.unreal]]\n\n## References\n\n- https://store.steampowered.com/app/324190/CodeSpells/","n":0.302}}},{"i":3665,"$":{"0":{"v":"Codeq","n":1},"1":{"v":"\n- repo:\n\n\n## Resources\n\n-  https://blog.datomic.com/2012/10/codeq.html","n":0.5}}},{"i":3666,"$":{"0":{"v":"Codeium","n":1}}},{"i":3667,"$":{"0":{"v":"Code Mas2j","n":0.707},"1":{"v":"\n- [[c.Software.IDE.Extension.VSCode]]\n- repo: https://github.com/TimKam/code-mas2j","n":0.5}}},{"i":3668,"$":{"0":{"v":"Code Chisel 3d","n":0.577},"1":{"v":"\n- #dead\n- url: https://robert.kra.hn/past-projects/live-programming-with-three-and-webvr.html\n- repo:  https://github.com/cdglabs/CodeChisel3D\n- [[p.similarTo]] [[prdct.apparatus]]\n\n\n## Features\n\n- Code that is evaluated in CodeChisel3D uses the [lively.vm module](https://github.com/LivelyKernel/lively.vm) of the [Lively Web construction kit](https://lively-next.org). It enables to control the execution of JavaScript code much more than a simple eval usage. Code can be instrumented, and state injected and extracted.","n":0.141}}},{"i":3669,"$":{"0":{"v":"Cocos2d","n":1},"1":{"v":"\n[[c.software.game-engine]]","n":1}}},{"i":3670,"$":{"0":{"v":"CockroachDB","n":1},"1":{"v":"\nurl: https://www.cockroachlabs.com/\n\n## Features\n\n- [geometry and geography support](https://www.cockroachlabs.com/docs/v22.1/spatial-data)\n\n\n## Resources\n\n- https://www.cockroachlabs.com/blog/living-without-atomic-clocks/\n- https://shijuvar.medium.com/building-microservices-with-event-sourcing-cqrs-in-go-using-grpc-nats-streaming-and-cockroachdb-983f650452aa","n":0.316}}},{"i":3671,"$":{"0":{"v":"Cocalc","n":1},"1":{"v":"\n- url: https://cocalc.com\n- [[c.pricing]] $5.43/mo for hobbyists","n":0.378}}},{"i":3672,"$":{"0":{"v":"Cmmn Case Management Model and Notation","n":0.408},"1":{"v":"\n## Concepts\n\n- The complete behavior model of a Case is captured in a case Plan Model. \n  - For a particular Case model, a case Plan model comprises of all elements that represent the initial plan of the case, and all elements that support the further evolution of the plan through run-time planning by case workers. \n  - There are four types of Plan Items:\n\n## Description\n\n- There is no model of sequence flow in CMMN. Execution of a task depends on events and conditions called sentries.\n  -  A sentry captures the occurrence of a certain event occurring or a condition being fulfilled within a case. \n  -  Sentries are used as entry and exit criteria. Note that the black and white diamonds represent the criteria.\n\n## Issues\n\n- poor adoption\n- [[prdct.bpmn]] overlap \n\n## Comparison\n\n### vs [[prdct.bpmn]]\n\n![](/assets/images/2023-11-28-10-39-20.png)\n\n\n| Most of BPMN Notations | CMMN Notation |\n| --- | --- |\n| Imperative | Declarative |\n| Process centric | Data centric |\n| Arcs describe the sequence | No predefined sequence |\n| Guided work (head down workers) | Enables workers (knowledge workers) |\n| Everything is modeled | Not everything is modeled |\n\n\n\n## Resources\n\n- https://www.processmaker.com/blog/intro-to-case-management-model-and-notation-cmmn/\n  - \"Business Process Model and Notation (BPMN), Case Management Model and Notation (CMMN), and Decision Model and Notation (DMN) form what is often called the “triple crown” of business modeling notations.\"\n\n\n## References\n\n- https://camunda.com/blog/2020/08/how-cmmn-never-lived-up-to-its-potential/\n- https://www.flowable.com/blog/business/introducing-the-case-management-model-and-notation-standard-cmmn\n- https://www.visual-paradigm.com/guide/cmmn/what-is-cmmn/","n":0.067}}},{"i":3673,"$":{"0":{"v":"CLP(Q)","n":1}}},{"i":3674,"$":{"0":{"v":"Clownface","n":1},"1":{"v":"\n- https://zazuko.github.io/clownface/#/\n- ","n":0.707}}},{"i":3675,"$":{"0":{"v":"Cloudstrike","n":1}}},{"i":3676,"$":{"0":{"v":"Cloudron","n":1},"1":{"v":"\n- url: https://www.cloudron.io/\n  - ","n":0.5}}},{"i":3677,"$":{"0":{"v":"Cloudflare_workers","n":1},"1":{"v":"\n```yaml\nsupports:\n  - [[prdct.denoflare]]\n```","n":0.577}}},{"i":3678,"$":{"0":{"v":"Cloudevents","n":1},"1":{"v":"\nurl: https://cloudevents.io/\n\n- [[p.supportedBy]] [[prdct.openfaas]] [[prdct.triggermesh]] [[prdct.kafka]] [[prdct.quarkus]]\n- [[p.supports]] \n  - [XML](https://github.com/cloudevents/spec/blob/main/cloudevents/working-drafts/xml-format.md)\n  - [JSON](https://github.com/cloudevents/spec/blob/main/cloudevents/formats/json-format.md)\n\n## [[p.hadDefinition]]\n\n\n## Specifications\n\n- https://github.com/cloudevents/spec/blob/main/cloudevents/formats/json-format.md\n- https://github.com/cloudevents/spec/blob/main/cloudevents/working-drafts/xml-format.md\n\n### https://quarkus.io/blog/kafka-cloud-events/\n\n- Events can be used to implement event sourcing, communicate facts, trigger out-of-band processing, or send notifications. Events become an essential piece of any system.\n\n\n## Resources\n\n- https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents\n  - \"Currently, there are two event formats: Binary, which is the preferred format, and structured. Binary is recommended because it is additive. That is, the binary format only adds some headers to the HTTP request. If there is a middleware that doesn’t understand CloudEvents, it won’t break anything, but if that system is updated to support CloudEvents, it starts working.\"  ","n":0.098}}},{"i":3679,"$":{"0":{"v":"Clooney","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/GoogleChromeLabs/clooney\n- ","n":0.5}}},{"i":3680,"$":{"0":{"v":"ClojureScript","n":1},"1":{"v":"\n## Features\n\n- support interactive programming, see https://www.youtube.com/watch?v=KZjFVdU8VLI\n\n### Learning Resources\n\n- https://blog.logrocket.com/getting-started-clojurescript-javascript-developers/","n":0.316}}},{"i":3681,"$":{"0":{"v":"Clips","n":1},"1":{"v":"- [[c.Software.Rules-Engine]]\n![[prdct.jess.rules-language#^cmcaoqsy0ccx]]\n- written_in: c","n":0.5}}},{"i":3682,"$":{"0":{"v":"Cliffy","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/c4spar/deno-cliffy\n- [[p.builtOn]] [[prdct.deno]]\n- [[p.differentFrom]] https://github.com/drew-y/cliffy \n- not [[p.builtOn]] [[prdct.vorpal]]\n\n## #features\n\n  - [[t.cs.ui.cli.dynamic-prompts]]","n":0.267}}},{"i":3683,"$":{"0":{"v":"CLIF","n":1},"1":{"v":"\n- related: [[prdct.common-logic]]","n":0.577}}},{"i":3684,"$":{"0":{"v":"Clickhouse","n":1},"1":{"v":"\n- [[p.hasURL]] https://clickhouse.com/","n":0.577}}},{"i":3685,"$":{"0":{"v":"Clevercloud","n":1}}},{"i":3686,"$":{"0":{"v":"Clerky","n":1},"1":{"v":"\n- [[c.service.startup-formation]]\n- url: https://www.clerky.com/\n- ","n":0.5}}},{"i":3687,"$":{"0":{"v":"Clerk","n":1},"1":{"v":"\n\n- [[t.cs.sd.moldable-development]]\n- url: https://clerk.vision/\n- written in: clojure\n\n## Semantic Queries\n\n- \"Clerk can be very helpful when exploring any kind of data, including the sorts of things for which we might turn to the Semantic Web.\"\n\n## Resources\n- https://docs.xtdb.com/static/learn-xtql-today-with-clojure.html\n- https://github.clerk.garden/nextjournal/clerk-demo/commit/ff0b806e7da3e42865803bc3ceeb26444e136a51/notebooks/semantic/","n":0.164}}},{"i":3688,"$":{"0":{"v":"Clearscript","n":1},"1":{"v":"\n- url: https://microsoft.github.io/ClearScript/\n- repo: https://github.com/microsoft/ClearScript\n\n## Issues\n\n- Windows-only, see https://github.com/microsoft/ClearScript/issues/9\n\n## Resources\n\n- https://medium.com/@manjulcr7/running-javascript-in-c-combining-two-powerful-languages-6c6d0a3672ab","n":0.302}}},{"i":3689,"$":{"0":{"v":"Class Transformer","n":0.707},"1":{"v":"\n\n## Features\n\n- In case the nested object can be of different types, you can provide an additional options object, that specifies a discriminator. The discriminator option must define a property that holds the subtype name for the object and the possible subTypes that the nested object can converted to. A sub type has a value, that holds the constructor of the Type and the name, that can match with the property of the discriminator.","n":0.116}}},{"i":3690,"$":{"0":{"v":"Clarion","n":1},"1":{"v":"\n- #closed-source\n- url: https://sites.google.com/site/clarioncognitivearchitecture\n- ","n":0.5}}},{"i":3691,"$":{"0":{"v":"Clara Rules","n":0.707},"1":{"v":"\n- http://www.clara-rules.org/\n- [[c.software.rules-engine]]\n- written_in: clojure\n- related: [[prdct.pathom]]\n\n## Features\n\n- Easily used from Java\n  - \"In Java, our facts would typically be JavaBeans.\"\n- Simple but expressive\n- combine the best ideas from expert systems, functional programming, and the best known develpment practices.\n\n## Approach\n\n- http://www.clara-rules.org/docs/approach/\n  - expressiveness: We didn’t want to fall into the trap of most rule engines, which used a limited host language that blocked easy expression or invocation of rich logic. Limited languages are great for limited problems, but they can become an obstacle as problems evolve.\n  - Lisp-style macros are what makes Clara possible. At its core, Clara is a collection of macros that takes a set of independent rules, identifies and merges commonality, and compiles those rules into an efficient executable structure.\n\n## Clojure for games\n\n- \"There are also experiments with trying to make rule systems like Clara fast enough to use in games.\"\n- \"Alex Kehayias gave a talk about designing a functional game engine in ClojureScript, using components, here: https://www.youtube.com/watch?v=TW1ie0pIO_E I thought it was a superb talk. \"\n- [[prdct.ittyon]]\n\n## References\n\n- [Entity–component–system and Clojure](https://groups.google.com/g/clojure/c/2eBO5ABe7z4?pli=1)","n":0.076}}},{"i":3692,"$":{"0":{"v":"Cl Fast Ecs","n":0.577},"1":{"v":"\n- [[c.Software.Entity-Component-System]]\n- https://awkravchuk.itch.io/cl-fast-ecs\n- written-in: lisp","n":0.447}}},{"i":3693,"$":{"0":{"v":"CIDOC-CRM","n":1},"1":{"v":"\n\n- url:\n  - https://www.cidoc-crm.org/sites/default/files/cidoc_crm_version_7.1.3.pdf\n  - \n\n## Highlights\n\n- identifiers! letter+integer for classes and properties\n-  In order to understand the function of a formal ontology of this kind, one needs to make the following distinctions:\n  - The material reality\n  - The units of description or particulars, i.e. the things and relations which we refer to in order to distinguish parts of reality... What goes on in our minds or is produced by our minds is also regarded as part of the material reality, as it becomes materially evident to other people at least by our utterances, behaviour and products.\n- A formal ontology, such as the CIDOC CRM, constitutes a controlled language for talking about particulars. I.e., it provides classes and properties for categorizing particulars as so-called “instances” in a way that their individuation, unity and relevant properties are as unambiguous as possible.\n- A KB does not represent a slice of reality, but the justified beliefs of its maintainers about that reality. For simplicity, we speak about a KB as representing some reality\n  - t.2024.03.20.20:  everything should have attribution?\n  - is it just as simple as \"haha, in my use case, the knowledge base is the reality.\"?\n    - t.2024.08.21.11 more likely, the reality is abstracted as works, and the knowledge base is the expression? \n\n\nCIDOC’s P14.1 `in the role of`","n":0.068}}},{"i":3694,"$":{"0":{"v":"Cid","n":1},"1":{"v":"\n- repo: https://github.com/multiformats/cid\n\n## Examples\n\n### example CID\nzb2rhe5P4gXftAwvA4eXQ5HJwsER2owDyS9sKaQRRVQPn93bA\n\n### corresponding human readable CID\nbase58btc - cidv1 - raw - sha2-256-256-6e6ff7950a36187a801613426e858dce686cd7d7e3c0fc42ee0330072d245c95","n":0.25}}},{"i":3695,"$":{"0":{"v":"Chronos Rti","n":0.707}}},{"i":3696,"$":{"0":{"v":"Chronos Builder","n":0.707},"1":{"v":"\n- [[c.software.rpg.map-maker]]\n- https://chronosbuilder.com/\n- keywords: [[t.roleplaying.map-making]]\n- export-formats: [[prdct.Foundry-VTT]] [[prdct.universal-vtt]]","n":0.354}}},{"i":3697,"$":{"0":{"v":"chromeOS-flex","n":1}}},{"i":3698,"$":{"0":{"v":"Chrome","n":1}}},{"i":3699,"$":{"0":{"v":"Capabilities","n":1}}},{"i":3700,"$":{"0":{"v":"Choicescript","n":1},"1":{"v":"\n- https://www.choiceofgames.com/make-your-own-games/choicescript-intro/","n":0.707}}},{"i":3701,"$":{"0":{"v":"Chatgpt","n":1},"1":{"v":"\n- [[c.software.ai.assistant]]","n":0.707}}},{"i":3702,"$":{"0":{"v":"CharacterStudio","n":1},"1":{"v":"\n- repo: https://github.com/m3-org/CharacterStudio\n- related: [[t.cs.virtual-reality]]\n- written-in: javascript\n\n## Features\n\n- drag-n-drop user-created content","n":0.302}}},{"i":3703,"$":{"0":{"v":"Change_case_vscode","n":1},"1":{"v":"\n## Cons\n\n- changes camelCase instances to spaced\n\n","n":0.378}}},{"i":3704,"$":{"0":{"v":"Chalk","n":1},"1":{"v":"\nrepo: https://github.com/chalk/chalk","n":0.707}}},{"i":3705,"$":{"0":{"v":"Chalk Pipe","n":0.707},"1":{"v":"\nrepo: https://github.com/LitoMore/chalk-pipe","n":0.707}}},{"i":3706,"$":{"0":{"v":"Chalk Animation","n":0.707},"1":{"v":"\nrepo: https://github.com/bokub/chalk-animation","n":0.707}}},{"i":3707,"$":{"0":{"v":"Chainvayler","n":1},"1":{"v":"\n- repo: https://github.com/raftAtGit/Chainvayler\n- based-on: [[prdct.prevayler]]\n\n## Cons\n\n- requires running the Chainvayler compiler after running javac","n":0.267}}},{"i":3708,"$":{"0":{"v":"Cettia","n":1},"1":{"v":"\n- dead\n- similar_to: [[prdct.colyseus]]\n- supports: [[prdct.vertx]] Java EE, Spring WebFlux, Spring Web MVC, Play Framework,  Grizzly, Netty, [[prdct.atmosphere]],\n- repo: https://github.com/cettia/cettia-java-server\n","n":0.224}}},{"i":3709,"$":{"0":{"v":"Cesium","n":1},"1":{"v":"\n- url: https://cesium.com","n":0.577}}},{"i":3710,"$":{"0":{"v":"CesiumJS","n":1},"1":{"v":"\n## Features\n\n- Time-dynamic visualization\n- 3D tiles and models\n- vectors and geometry\n- supports: [[prdct.czml]]\n\n### Co-ordinates\n\n- Coordinates in CesiumJS are expressed in [ECEF](https://en.wikipedia.org/wiki/ECEF) using the [Cartesian3](https://cesium.com/learn/cesiumjs/ref-doc/Cartesian3.html) class. In this system, the origin (0, 0, 0) is the center of Earth.\n\nThis is why we use `Cartesian3.fromDegrees` to convert from longitude, latitude, and height to X, Y, and Z in ECEF.\n\nThe height in CesiumJS is in meters relative to the WGS84 ellipsoid. We’ve preprocessed the radar data to convert the heights from feet relative to mean sea level to meters relative to the ellipsoid.\n\n## Learning Resource\n\n- https://cesium.com/learn/cesiumjs-learn/\n- https://cesium.com/learn/cesiumjs-learn/cesiumjs-flight-tracker/\n  - \"you can later extend this code to parse the original data or even visualize live air traffic as samples are passed to your app from a server\"\n\n## References\n\n- https://community.cesium.com/t/vector-data-from-database-postgis/889\n  - Q: \"I try to pull my vector data(points and lines) from my PostGIS database and render it on the top of base map. Any API to connect the database and render new features on the top of map?\"\n    - A: \"use GeoServer and display the data in Cesium using a WMS layer\"\n- https://community.cesium.com/t/polygon-with-height-data-to-3d/4406\n  - \"Cesium has support for geojson directly, so depending on the complexity, you may be able to simply load in the generated geojson file. Here is an example for how to add it to Cesium: http://cesiumjs.org/Cesium/Apps/Sandcastle/index.html?src=GeoJSON%20and%20TopoJSON.html&label=DataSources \"","n":0.069}}},{"i":3711,"$":{"0":{"v":"Cerbos","n":1},"1":{"v":"\n## Features\n\n- Implement context-aware role definitions and attribute-based access control for adaptable, granular security policies.","n":0.258}}},{"i":3712,"$":{"0":{"v":"Policy Decision Point","n":0.577},"1":{"v":"\n- [[c.software.authorization]]\n- https://www.cerbos.dev/product-cerbos-pdp\n\n![](/assets/images/2024-04-14-16-50-12.png)","n":0.577}}},{"i":3713,"$":{"0":{"v":"Centrifugo","n":1},"1":{"v":"\n- repo: https://github.com/centrifugal/centrifugo\n- written-in: go\n- commercial-version: [[prdct.centrifugo.pro]]\n- based-on: [[prdct.redis]]\n![[prdct.mercure#^ahtfnaeq7g62]]\n\n## Description\n\n- Centrifugo can instantly deliver messages to application online users connected over supported transports (WebSocket, HTTP-streaming, SSE/EventSource, GRPC, SockJS, WebTransport). Centrifugo has the concept of channel subscriptions – so it's a user-facing PUB/SUB server.\n\n## Use Cases\n\n- Chats apps, live comments, multiplayer games, real-time data visualizations, collaborative tools, etc. can all be built on top of a real-time messaging system.\n\n## Features\n\n- Built-in Redis, KeyDB, Tarantool engines, or [[prdct.nats]] broker make it possible to scale connections across different Centrifugo nodes\n- while Centrifugo can still transfer JSON data over the wire it now also supports binary Websocket connections with Protobuf message format.\n- On backend side Centrifugo provides HTTP and GRPC API to publish data into channels.\n- several kinds of channels with different security levels and some options that can be defined in configuration. For example so called private channels where every subscription attempt must be additionally signed.\n  - Within channel developer has some useful features like history cache, presence information (information about active channel subscribers), also join and leave notifications when client subscribes on channel (or unsubscribes from it). This is very important to have to build game lobby for example.\n- recovery feature: Every channel can optionally keep a stream of Publications and client can recover missed messages upon reconnect providing the sequence number of last seen Publication in channel.\n- while Centrifugo server is mostly designed to stream messages in one direction — from server to client — library allows to exchange messages in fully bidirectional way with full control over each client connection.\n- supports durability with redis backend\n\n## Comparison\n\n### Centrifugo vs PubNub\n\n- Pubnub's channel groups allow you to group multiple channels under a single identifier. This grouping mechanism enables a client to subscribe to multiple channels via a single group name rather than subscribing to each channel individually. It simplifies client-side logic, especially when the exact channels a client needs to listen to can change dynamically.\n\n\n![[prdct.mercure#mercure-vs-centrifugo]]\n\n\n## References\n\n- https://medium.com/@fzambia/how-centrifugo-solves-real-problems-of-real-time-messaging-applications-a15d6b8fc8ac\n- https://centrifugal.dev/docs/getting-started/comparisons\n\nCentrifugo\n\n: go","n":0.055}}},{"i":3714,"$":{"0":{"v":"Centrifugo Pro","n":0.707},"1":{"v":"\n- https://centrifugal.dev/docs/pro/overview","n":0.707}}},{"i":3715,"$":{"0":{"v":"Catlab Jl","n":0.707},"1":{"v":"\n- [[p.supports]] [[prdct.graphviz]]","n":0.577}}},{"i":3716,"$":{"0":{"v":"Catalyst","n":1},"1":{"v":"\n![[prdct.infinitic#similar]]\n- published-by: [[org.diagrid]]\n\n![[prdct.infinitic#similar]]\n\n## Issues\n\n- programmatic subscription support via the SDKs is not supported when using the Catalyst Pub/Sub API.\n- 2024.05: only .NET support for [[prdct.dapr]] workflow APIs\n\n## Support\n\n### Pub/Sub\n\n    AWS SNS/SQS: aws.snssqs\n\n    Azure Event Hubs: azure.eventhubs\n\n    Azure Service Bus Topics: azure.servicebus.topics\n\n    GCP Pub/Sub: gcp.pubsub\n\n    Apache Kafka: kafka\n\n    MQTT3: mqtt3\n\n    Apache Pulsar: pulsar\n\n    RabbitMQ: rabbitmq\n\n    Redis: redis","n":0.134}}},{"i":3717,"$":{"0":{"v":"CasualOS","n":1},"1":{"v":"\nurl: https://casualos.com/\nrepo: https://github.com/casual-simulation/casualos\n\n- docs:  https://docs.casualos.com\n\n## [[p.hasFeature]]\n\n- [[t.cs.scripting]] ","n":0.378}}},{"i":3718,"$":{"0":{"v":"Castore","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/theodo/castore\n- ","n":0.577}}},{"i":3719,"$":{"0":{"v":"CASL","n":1},"1":{"v":"\n- related: [[prdct.hets]]","n":0.577}}},{"i":3720,"$":{"0":{"v":"ModalCASL","n":1},"1":{"v":"\n- a [[c.logic.extension]] for [[prdct.casl]]\n- similar: [[prdct.extmodal]]","n":0.378}}},{"i":3721,"$":{"0":{"v":"Case Ontology","n":0.707},"1":{"v":"\n- description: Cyber-investigation Analysis Standard Expression (CASE) is a community-developed evolving standard that provides a structured (ontology-based) specification for representing information commonly analyzed and exchanged by people and systems during investigations involving digital evidence.","n":0.171}}},{"i":3722,"$":{"0":{"v":"Casbin","n":1},"1":{"v":"\n- [[c.software.authorization]]\n- url: https://casbin.org/\n- similar-to\n\n## Features\n\n- cross-platform\n- flexible policy storage\n- role manager is used to manage the RBAC role hierarchy (user-role mapping)","n":0.213}}},{"i":3723,"$":{"0":{"v":"CArtAgO","n":1},"1":{"v":"\n- dead since 2022\n- url: https://sourceforge.net/projects/cartago/\n- repo: https://github.com/CArtAgO-lang/cartago\n- docs: https://github.com/CArtAgO-lang/cartago/blob/master/docs/cartago_by_examples/cartago_by_examples.pdf\n\n## Resources\n\n- [Interoperability among Jason, Cartago, and C4Jason](https://github.com/jacamo-lang/jacamo/issues/38)\n\n## References\n\n","n":0.236}}},{"i":3724,"$":{"0":{"v":"Carta","n":1},"1":{"v":"\n- [[c.list.features]] https://carta.com/plans/pricing-for-companies/","n":0.577}}},{"i":3725,"$":{"0":{"v":"Cardinal","n":1},"1":{"v":"\n- url: https://world.dev/cardinal/introduction\n- written_in: go\n\n## Features\n\n-   **High-performance** - Cardinal is how a blockchain would be constructed if it was designed for games. It can handle thousands of game moves per second in real-time.\n-   **Highly customizable** - Developers can write Cardinal plugins to introduce new features such as your own user scripting language, zero-knowledge proof systems, and more.\n-   **Tick-driven runtime** - Cardinal utilizes the concept of ticks, commonly used in game server architecture, to allow developers to implement complex real-time game logic such as game physics, combat systems, and many more that are difficult to implement in an event-driven runtime of a typical blockchain.\n-   **Easy integration with game engines** - Cardinal provides a simple, easy-to-use API and client libraries for game developers to integrate their game with popular game engines such as Unity and Unreal Engine.\n-   **Entity Component System** - Cardinal comes with native ECS architecture that allows game developers to easily manage and extend their game state and logic.","n":0.079}}},{"i":3726,"$":{"0":{"v":"Carbon LDP (dead)","n":0.577},"1":{"v":"\n- dead\n- [[t.cs.semantic-web.linked-data-platform]]\n- commercial, \n- https://carbonldp.com/\n- [[c.software.semantic.linked-data-platform]]\n","n":0.378}}},{"i":3727,"$":{"0":{"v":"Carbide","n":1},"1":{"v":"\n- url: https://carbide.dev/\n- [[c.con]] no data export","n":0.378}}},{"i":3728,"$":{"0":{"v":"Capbase","n":1},"1":{"v":"\n- [[c.service.startup-formation]]\n- url: https://capbase.com\n- [[p.hadPricing]] $999/year\n- [[p.similarTo]] [[prdct.gust]]","n":0.354}}},{"i":3729,"$":{"0":{"v":"Camunda","n":1}}},{"i":3730,"$":{"0":{"v":"Operate","n":1},"1":{"v":"\n- repo: https://docs.camunda.io/docs/components/operate/operate-introduction/","n":0.577}}},{"i":3731,"$":{"0":{"v":"Modeler","n":1},"1":{"v":"\n- repo: https://github.com/camunda/camunda-modeler","n":0.577}}},{"i":3732,"$":{"0":{"v":"Calva","n":1}}},{"i":3733,"$":{"0":{"v":"Callimachus","n":1},"1":{"v":"\n- dead since 2016\n- [[c.software.semantic.linked-data-platform]]\n- repo: https://github.com/3-Round-Stones/callimachus\n\n## References\n\n- https://learning.oreilly.com/library/view/linked-data/9781617290398/OEBPS/Text/kindle_split_021.html","n":0.333}}},{"i":3734,"$":{"0":{"v":"Cadence","n":1},"1":{"v":"\n- url: https://cadenceworkflow.io/\n- forked-by: [[prdct.temporal]]\n- related: [[prdct.iwf]]\n\n## References\n\n- https://community.temporal.io/t/a-letter-to-cadence-temporal-community/6809","n":0.333}}},{"i":3735,"$":{"0":{"v":"C Owl","n":0.707},"1":{"v":"\n## References\n\n- [[ar.c-owl-contextualizing-ontologies]]","n":0.577}}},{"i":3736,"$":{"0":{"v":"C-BDI","n":1},"1":{"v":"\n## Features\n\n### Open Agent Protocol\n\nC-BDI’s SDK provides programmable hooks, which enable explainable AI to be distributed, without compromise, across any network configuration such as DDS, WebSockets, IPC or your own routing layer.\n\n### Open Agent Protocol\n\nC-BDI’s SDK provides programmable hooks, which enable explainable AI to be distributed, without compromise, across any network configuration such as DDS, WebSockets, IPC or your own routing layer.\n\n### Open Agent Protocol\n\nC-BDI’s SDK provides programmable hooks, which enable explainable AI to be distributed, without compromise, across any network configuration such as DDS, WebSockets, IPC or your own routing layer.\n\n### Open Agent Protocol\n\nC-BDI’s SDK provides programmable hooks, which enable explainable AI to be distributed, without compromise, across any network configuration such as DDS, WebSockets, IPC or your own routing layer.\n\n### Open Agent Protocol\n\nC-BDI’s SDK provides programmable hooks, which enable explainable AI to be distributed, without compromise, across any network configuration such as DDS, WebSockets, IPC or your own routing layer.","n":0.081}}},{"i":3737,"$":{"0":{"v":"Business Objects Reference Ontology","n":0.5},"1":{"v":"\n- http://www.borosolutions.net/boro-foundation-enterprise-ontology\n- related: @chris-partridge\n\n## Features\n\n- BORO's foundational ontology is grounded in philosophy and its metaontological choices (including perdurantism, extensionalism, and possible worlds) follow well-established theories.\n\n## References\n\n- [[ar.boro-as-a-foundation-to-enterprise-ontology]]","n":0.192}}},{"i":3738,"$":{"0":{"v":"Bun","n":1},"1":{"v":"\n- [[p.hasComparison]] \n  - https://www.codemotion.com/magazine/backend/languages/will-bun-replace-deno-as-node-js-killer/\n  - https://twitter.com/slicknet/status/1562916330113605633\n    - [[p.hasHighlight]]\n      - \"Deno started out with two high-level goals: to be more secure than Node.js and to have an API that was compatible with web browsers so the same JavaScript code could be run both on Deno and in the browser. It has succeeded in both of these goals.\"","n":0.132}}},{"i":3739,"$":{"0":{"v":"Bump Sh","n":0.707},"1":{"v":"\n- [[c.software.tools.design.api]]\n- url: https://bump.sh\n\n\n## Pricing\n\n- free (public only)\n- $149/mo for up to 10 private APIs\n\n## Comparisons\n\n- https://bump.sh/compare/stoplight","n":0.243}}},{"i":3740,"$":{"0":{"v":"Bullet Journaling","n":0.707},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.km]] \n- [[p.isRelated]] https://www.goodhousekeeping.com/life/a25940356/what-is-a-bullet-journal/\n","n":0.408}}},{"i":3741,"$":{"0":{"v":"Bulla Network","n":0.707},"1":{"v":"\n## Features\n\n- mints NFTs to represent invoices and scheduled payments","n":0.316}}},{"i":3742,"$":{"0":{"v":"Bruno","n":1},"1":{"v":"\n- [[c.software.tools.testing]]\n- url: https://www.usebruno.com/","n":0.5}}},{"i":3743,"$":{"0":{"v":"Broadcast Channel API","n":0.577},"1":{"v":"\nurl: https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API\n","n":0.707}}},{"i":3744,"$":{"0":{"v":"Brimm","n":1},"1":{"v":"\n- [[c.software.knowledge-base]]\n- repo: https://github.com/zeitstein/brimm\n- written_in: clojure","n":0.408}}},{"i":3745,"$":{"0":{"v":"Brighter","n":1},"1":{"v":"\n- https://www.goparamore.io/\n- [[c.software.framework]]\n- repo: https://github.com/BrighterCommand/Brighter\n- written-in: C#","n":0.378}}},{"i":3746,"$":{"0":{"v":"Brein Time Utilities","n":0.577},"1":{"v":"\n- https://github.com/Breinify/brein-time-utilities\n- keywords: [[t.cs.time.interval-tree]]","n":0.5}}},{"i":3747,"$":{"0":{"v":"Brackit","n":1},"1":{"v":"\n- repo: https://github.com/sirixdb/brackit\n\n## Mission\n\nOur work is guided by the following basic questions:\n\n-   What is an appropriate level of abstraction for accessing and (de-)composing semi-structured data? How should we represent semi-structured data with deep nestings and varying sizes at runtime? How can we support native operations and alternative access methods, i.e., indexes etc.?\n-   How should we represent queries, whole scripts, and user-defined functions to leverage proven optimization techniques from both query languages (e.g., predicate-pushdown, join ordering, optimized aggregation) and programming languages (e.g., tail recursion)?\n-   How can we support different evaluation philosophies (pull-based, push-based, mixed push/pull) and proven query algorithms?. How can we (automatically) exploit partitioned data, parallel hardware and query-inherent parallelism?\n-   How can we incorporate physical and system-specific properties (e.g., memory locality) in the compilation and evaluation process?\n\n## References\n\n- https://github.com/sirixdb/brackit/blob/master/mission.md","n":0.088}}},{"i":3748,"$":{"0":{"v":"BPMNator","n":1},"1":{"v":"\n## Features\n\n- programmatic or command line","n":0.408}}},{"i":3749,"$":{"0":{"v":"Bpmn","n":1},"1":{"v":"\n## Related\n\n- [[prdct.bpel]]\n- [[prdct.bpmnator]]\n\n\n\n## Issues\n\n- spec is > 500 pages\n- from https://dpmn.info/presentations/2023-SW/#/7 :\n    Overloading/ambiguity of sequence flow arrows\n    Insufficient integration of the objects that participate in a process\n    Insufficient resource modeling\n    No support of processing activities\n    No convincing formal/operational semantics\n\n\n## Types of Elements\n\n- flow objects\n  - ![](/assets/images/2023-11-28-09-22-37.png)\n  - events are not specifically technical... just what has happened in the problem domain\n  - sub process is a collection of flow objects\n  - gateways are commonly about branching, e.g. \n    - exclusive (or) \n    - parallel\n- connecting objects\n  - ![](/assets/images/2023-11-28-09-25-11.png)\n  - sequence\n  - message\n- pools and swimlanes\n  - ![](/assets/images/2023-11-28-09-25-50.png)\n  - maybe a pool for each participant/company, and each department is a lane\n  - or pool is a domain, lane is a subdomain\n  - i.e., establishing responsibilities\n    - arrow crossing a lane or a pool, that's a dependency\n- artifacts\n  - ![](/assets/images/2023-11-28-09-27-54.png)\n  - not events, tasks, decision points\n  - some kind of persistence\n\n## Example\n\n- \n\n## References\n\n[[event.2023.bpmn_for_profit_and_fun]]","n":0.081}}},{"i":3750,"$":{"0":{"v":"Bpel","n":1}}},{"i":3751,"$":{"0":{"v":"Bot Framework Sdk","n":0.577},"1":{"v":"\n- [[c.software.ai.bot-framework]]","n":0.707}}},{"i":3752,"$":{"0":{"v":"Boston","n":1},"1":{"v":"\n\n- [[p.hasComparison]] https://www.viev.com/index.php/products-menu/boston-versions-price-comparison\n","n":0.577}}},{"i":3753,"$":{"0":{"v":"Bog","n":1},"1":{"v":"\n- related: [[prdct.ontogen]]\n\n## Features\n\n- addresses some of the fundamental challenges in configuring RDF-based systems and offers innovative solutions for resource naming and identification\n  - aims to automate the problem of resource naming (aka URI minting) for a specific class of resources, initially and specifically for the resources of an Ontogen service that need to be minted as part of the configuration.\n  - With `bog:ref`, a resource initially identified by a blank node can be given a locally valid name.\n\n## Planned Features\n\n![[ar.ontogen.introducing-ontogen#^ezq1fl2ro8qr]]\n\n## References\n\n- https://ontogen.io/introduction/part-4","n":0.11}}},{"i":3754,"$":{"0":{"v":"Blogdown","n":1},"1":{"v":"\n## Resources\n\n- https://bookdown.org/yihui/blogdown/","n":0.577}}},{"i":3755,"$":{"0":{"v":"Blockchain in a Box","n":0.5},"1":{"v":"\nrepo: https://github.com/XRFoundation/Blockchain-in-a-Box","n":0.707}}},{"i":3756,"$":{"0":{"v":"Block Protocol","n":0.707},"1":{"v":"\n- url: https://blockprotocol.org/\n\n## Resources\n\n- [[ar.maggieappleton.block-data]]","n":0.447}}},{"i":3757,"$":{"0":{"v":"Blitz","n":1},"1":{"v":"\n- built_on: [[prdct.nextjs]]\n- ","n":0.577}}},{"i":3758,"$":{"0":{"v":"Blitz Orm","n":0.707},"1":{"v":"\n- [[c.Software.object-graph-mapper]]\n- repo: https://github.com/Blitzapps/blitz-orm/\n- written_in: typescript\n- supports: \n  - [[prdct.typedb]]\n  - [[prdct.surrealdb]] (soon, see https://github.com/Blitzapps/blitz-orm/pull/50)\n\n## References\n\n- https://lveillard.notion.site/BlitzORM-RFC-8b11f519fc464f86804259259c72bb19","n":0.243}}},{"i":3759,"$":{"0":{"v":"Blender","n":1}}},{"i":3760,"$":{"0":{"v":"Blazor","n":1},"1":{"v":"\n```yaml\nurl: https://dotnet.microsoft.com/en-us/apps/aspnet/web-apps/blazor\nalternatives: \n  - [[prdct.React]]\n  - [[prdct.vaadin]]\n  - [[prdct.flutter]]\nrelated:\n  - \n```\n\n## Pros\n\n- wide range of polished component libraries, many of which are free even for commercial use. Consider the offerings from [MudBlazor](https://mudblazor.com/), [MatBlazor](https://www.matblazor.com/), [Radzen](https://razor.radzen.com/), [Ant Design](https://antblazor.com/en-US/components/overview), [Telerik](https://www.telerik.com/blazor-ui), and the [Blazored](https://github.com/Blazored) collectionpho\n\n## Cons\n\n- slow startup: \"download an embedded version of the .NET runtime (compiled to WebAssembly), along with DLLs for your application and the .NET class libraries it uses (compiled to Microsoft’s [Common Intermediate Language](https://en.wikipedia.org/wiki/Common_Intermediate_Language), just like every version of .NET since 2000). The download size is a non-negotiable 2 or 3 MB. The startup delay ranges from fractions of a second to several seconds or — occasionally — [even more](https://twitter.com/firstdrafthell/status/1422154020546879490).\"\n  - caveat: \"It Blazor could open the door wider to optimized browser applications, it’s startup lag might not matter so much.\"\n- ","n":0.087}}},{"i":3761,"$":{"0":{"v":"Bitsy","n":1},"1":{"v":"\n- [[c.software.database.graph.property]] [[c.software.database.embedded]]\n- repo: https://github.com/lambdazen/bitsy\n- #docs https://github.com/lambdazen/bitsy/wiki\n- written-in: java","n":0.333}}},{"i":3762,"$":{"0":{"v":"BiTRDF","n":1},"1":{"v":"\n## Implementation\n\n- uses [[prdct.Postgres]], keeps triples in one big table.\n\nComplex Data Type \nPostgreSQL provides a list of primitive data types, such as numeric, monetary, character, binary, date and time, boolean, etc. PostgreSQL also provides a way to define new data types by the CREATE TYPE statement. To implement BiTRDF, we first create a complex data type, named BiTemporalResource. The statement [115] for creating BiTemporalResource is as follows: \n\nCREATE TYPE BiTemporalResource AS (\n  Name VARCHAR ,\n  VtBegin TIMESTAMP WITH TIME ZONE ,\n  VtEnd TIMESTAMP WITH TIME ZONE ,\n  TtBegin TIMESTAMP WITH TIME ZONE ,\n  TtEnd TIMESTAMP WITH TIME ZONE ,\n);\n\n## References\n\n-  [BiTRDF: Extending RDF for BiTemporal Data](https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=6041&context=gc_etds)","n":0.097}}},{"i":3763,"$":{"0":{"v":"BitECS","n":1},"1":{"v":"\n- [[c.software.entity-component-system]] [[t.cs.entity-component-system]]\n- repo: https://github.com/NateTheGreatt/bitECS\n- written-in: javascript\n- [[p.usedBy]] [[prdct.ethereal-engine]] [[prdct.hubs]] [[prdct.matrix]] [[prdct.third-room]]\n- [[p.hasClientSupport]]\n  - [[prdct.element]] [[prdct.babylon-js]]\n  - [[prdct.phaser]]\n\n## [[p.hasFeature]]\n\n🔮 Simple, declarative API \t\n🔥 Blazing fast iteration\n🔍 Powerful & performant queries \n💾 Serialization included\n🍃 Zero dependencies \t\n🌐 Node or browser\n🤏 ~5kb minzipped \t\n🏷 TypeScript support\n❤ Made with love \t\n🔺 glMatrix support\n\n## Interesting\n\n- \"bitECS has no built-in concept of systems. We frequently refer the functions invoked during the game loop as “systems”, but there is no formal construct.\"\n\n## [[c.faq]]\n\n- Is there a string type for components?\n  - Strings are expensive and usually unnecessary to have the ECS handle. Instead, create a mapping of integers to strings, and store the integers in the component data as a reference to a string. This makes string serialization minimal and  \n\n## Resources\n\n### Learning Resource\n\n- https://github.com/ourcade/phaser3-bitecs-getting-started\n- https://www.youtube.com/playlist?list=PLNwtXgWIx3rhz72-UxKLdCDdqFsnwNc_u\n\n","n":0.088}}},{"i":3764,"$":{"0":{"v":"Birt","n":1},"1":{"v":"\n- url: https://download.eclipse.org/birt/updates/release/latest/\n- ","n":0.577}}},{"i":3765,"$":{"0":{"v":"Binder","n":1},"1":{"v":"\n- url: https://mybinder.org/","n":0.577}}},{"i":3766,"$":{"0":{"v":"Biff","n":1},"1":{"v":"\n- repo: \n- url: https://biffweb.com/\n- built_on: [[prdct.htmx]] [[prdct.xtdb.v1]]\n\n## Features\n\n- curates libraries and tools from across the ecosystem and composes them into one polished whole.\n- Strong defaults, weakly held. Biff is designed to be taken apart and modified, so it doesn't get in the way as your needs evolve.\n- REPL made easy: Changes are evaluated whenever you save a file. Connect to a production REPL and develop your whole app on the fly.","n":0.118}}},{"i":3767,"$":{"0":{"v":"Bibframe","n":1}}},{"i":3768,"$":{"0":{"v":"Bfo Classifier","n":0.707},"1":{"v":"\n- https://bfo-classifier.github.io/\n- repo: https://github.com/SteveWang7596/BFO_2_0_DecisionDiagram\n- ","n":0.5}}},{"i":3769,"$":{"0":{"v":"Bfg Repo Cleaner","n":0.577},"1":{"v":"\n- url: https://rtyley.github.io/bfg-repo-cleaner/\n- written-in: java","n":0.447}}},{"i":3770,"$":{"0":{"v":"Beyond20","n":1},"1":{"v":"\n- [[c.software.rpg.virtual-tabletop.utilities]]","n":0.707}}},{"i":3771,"$":{"0":{"v":"Bevy","n":1},"1":{"v":"\n- [[c.software.game-engine]]\n- url: https://bevyengine.org/\n\n## Features\n\n- Hot Reloading: Changes to scene files are automatically applied to running apps","n":0.243}}},{"i":3772,"$":{"0":{"v":"Benthos","n":1},"1":{"v":"\n- https://www.benthos.dev/\n- [[c.software.data-framework.streaming]] \n- repo: https://github.com/benthosdev/benthos\n- written-in: go\n- similar: [[prdct.midway]] [[prdct.brighter]]\n\n## Description\n\n- Benthos solves common data engineering tasks such as transformations, integrations, and multiplexing with declarative and unit testable configuration. This allows you to easily and incrementally adapt your data pipelines as requirements change, letting you focus on the more exciting stuff.","n":0.139}}},{"i":3773,"$":{"0":{"v":"Beliefdb","n":1},"1":{"v":"\n- url: https://db.cs.washington.edu/projects/beliefdb/\n\n## Summary\n\n- [we need] an annotation semantics that helps collaborating database users engage in a structured discussion on both content and each other's annotations. This creates several challenges for a DB that supports such annotations: (1) it needs to allow for conflicting beliefs: users should be able to use annotations to indicate conflicts between what they believe and what others believe. The DB should allow and expose those conflicts; (2) it must also support higher-order annotations: users should be able to not only annotate content but also other users' annotations","n":0.104}}},{"i":3774,"$":{"0":{"v":"Behavior3JS","n":1},"1":{"v":"\n- [[c.software.game-framework.behavior-trees]]\n- repo: https://github.com/behavior3/behavior3js\n\n## [](https://github.com/behavior3/behavior3js#main-features)Main features\n\n-   Based on the work of [(Marzinotto et al., 2014)](http://www.csc.kth.se/~miccol/Michele_Colledanchise/Publications_files/2013_ICRA_mcko.pdf), in which they propose a **formal**, **consistent** and **general** definition of Behavior Trees;\n    \n-   **Optimized to control multiple agents**: you can use a single behavior tree instance to handle hundreds of agents;\n    \n-   It was **designed to load and save trees in a JSON format**, in order to use, edit and test it in multiple environments, tools and languages;\n    \n-   A **cool visual editor** which you can access online;\n    \n-   Several **composite, decorator and action nodes** available within the library. You still can define your own nodes, including composites and decorators;\n    \n-   **Completely free**, the core module and the visual editor are all published under the MIT License, which means that you can use them for your open source and commercial projects;\n    \n-   **Lightweight**!\n-   \n\n## References\n\n- https://www.reddit.com/r/gamedev/comments/2ki2uv/just_released_my_library_for_behavior_trees_in/ (also has some tips)","n":0.083}}},{"i":3775,"$":{"0":{"v":"Beeminder","n":1},"1":{"v":"\n- https://www.beeminder.com/\n- [[c.software.task-and-goal-management]]\n- complements: [[prdct.intend-do]]\n\n## Integrations\n\n\nBeeminder\nFitbit\nDuolingo\nHabitica\nToggl\nGmail\nRescueTime\nTodoist\nTrello\nGitminder\nPocket\nStrava\nGarmin\nWithings\nApple Health\nRunkeeper\nSleep as Android\nFocusmate\nCodeCombat\nTry Deep Work\nClozemaster\nLichess\nProject Euler\nIntend\nSlack\nZapier\nIFTTT\nMake\nTwitter\nTaskRatchet\nBeeminder as a Service\nfreeCodeCamp\nStorygraph\nReadwise Reader\nRSSminder\nURLminder\nSkritter\nManifold\nWakaTime\nYNAB\n","n":0.25}}},{"i":3776,"$":{"0":{"v":"Becsy","n":1},"1":{"v":"\n- [[c.software.entity-component-system]]\n- [[p.hasRoadmapFeature]] [[t.cs.multithreading]]","n":0.5}}},{"i":3777,"$":{"0":{"v":"Beanshell","n":1},"1":{"v":"\n- [[c.software.script-engine]]\n- repo: https://github.com/beanshell/beanshell\n\n## Use Cases\n\n### Interactive Scripting\n\nYou can use BeanShell interactively for Java experimentation and debugging as well as to extend your applications in new ways. Scripting Java lends itself to a wide variety of applications including rapid prototyping, user scripting extension, rules engines, configuration, testing, dynamic deployment, embedded systems, and even Java education.\n\n### Embedded Script Engine\n\nBeanShell is small and embeddable, so you can call BeanShell from your Java applications to execute Java code dynamically at run-time or to provide extensibility in your applications. Alternatively, you can use standalone BeanShell scripts to manipulate Java applications; working with Java objects and APIs dynamically. Since BeanShell is written in Java and runs in the same VM as your application, you can freely pass references to \"live\" objects into scripts and return them as results.","n":0.087}}},{"i":3778,"$":{"0":{"v":"Bdi4jade","n":1},"1":{"v":"\n- repo: https://github.com/ingridnunes/bdi4jade\n\n## Features\n\n- BDI abstractions \n- reasoning cycle\n-   **Use of Capabilities** – agents aggregate a set of capabilities, which are a collection of beliefs and plans, and allow modularisation of particular agent functionality.\n-   **Plan Body is an Extension of JADE Behaviour** – in order to better exploit JADE features, plan bodies are subclasses of JADE behaviours.\n-   **Java Annotations** – annotations are provided to allow easier configuration of agent components, without compromising its flexibility.\n-   **Extension Points** – strategies can be easily implemented to extend parts of the reasoning cycle, such as belief revision and plan selection.\n-   **Listeners and Events** – different events (such as events related to goals and beliefs) can be observed in the platform, allowing listeners to react according to events that occurred.\n-   **Java Generics for Beliefs** – beliefs can store any kind of information and are associated with a name, and if the value of a belief is retrieved, it must be cast to its specific type, so the use of Java generics allows us to capture incorrect castings at compile time.","n":0.076}}},{"i":3779,"$":{"0":{"v":"Battlemap Io","n":0.707},"1":{"v":"\n- [[c.software.rpg]]\n- url: https://battlemapp.io/\n- #related [[prdct.questforge]]","n":0.408}}},{"i":3780,"$":{"0":{"v":"Battlecode","n":1},"1":{"v":"\n- url: https://battlecode.org/\n![[game.screeps#^zwsvp7ab3c0e]]\n\n## References\n\n- https://www.youtube.com/watch?v=x3a5dXaj-XA","n":0.447}}},{"i":3781,"$":{"0":{"v":"Batch Rename","n":0.707},"1":{"v":"\n- url: https://marketplace.visualstudio.com/items?itemName=JannisX11.batch-rename-extension\n  - Dendron refactor doesn't work across vaults anyhow","n":0.302}}},{"i":3782,"$":{"0":{"v":"Basic Formal Ontology","n":0.577},"1":{"v":"\n- [[c.ontology.upper]]\n- url: https://basic-formal-ontology.org/ https://raw.githubusercontent.com/BFO-ontology/BFO/master/bfo.owl\n- repo: https://github.com/bfo-ontology/BFO/\n- #docs https://github.com/bfo-ontology/BFO/wiki\n- #similar [[prdct.gist]]\n- related: [[prdct.common-core-ontologies]]\n\n![](/assets/images/2023-10-10-11-37-53.png)\n\n## Description\n\n- \"The Basic Formal Ontology (BFO)6 sees Ontology as reality representation. It aims at reconciling the 3-dimensionalist and 4-dimensionalist views with a ‘Snap’ ontology of endurants, which is reproduced at each moment of time and is used to characterize static views of the world, and a ‘Span’ ontology of happenings and occurrents and, more generally, of entities which persist in time by perduring. It has a limited granularity and is heavily influenced by parthood relations, boundaries, dependence.\"\n- \"BFO grows out of a philosophical orientation which overlaps with that of DOLCE and SUMO. Unlike these, however, it is narrowly focused on the task of providing a genuine upper ontology which can be used in support of domain ontologies developed for scientific research, as for example in biomedicine within the framework of the OBO Foundry. Thus BFO does not contain physical, chemical, biological or other terms which would properly fall within the special sciences domains. BFO is the upper level ontology upon which OBO Foundry ontologies are built.\n\n## Issues\n\n- monohierarchy\n- IRIs aren't human-readable, e.g. http://purl.obolibrary.org/obo/BFO_0000015\n- \"only continuants – and hence not occurrents – are allowed to have qualities.\"\n\n- entity\n  - continuant: exists through time, i.e. \"three-dimensionalist\"\n    - independent continuant: doesn't require a bearer, e.g. \n      - material entity\n        - object\n        - fiat object part: arm (it's not an object b/c it reflects decision)\n        - object aggregate\n      - immaterial entity\n        - site (e.g. holes)\n        - continuant fiat boundary\n          - fiat point (zero-d)\n          - fiat line (1d)\n          - fiat surface (2d)\n        - spatial region\n          - 0d, 1d, 2d, and 3d\n    - generically dependent continuant\n    - specifically dependent continuant\n      - qualities: not realizable (like redness)\n      - realizable entity: a potential, or function, like the ability of a phone to make phone calls\n        - role\n        - disposition\n          - function\n  - occurrent\n    - process\n    - process boundary\n    - temporal regional\n    - spatiotemporal region\n\n## Attributes\n\n- **realist**: all classes have (or had) instances in space and time\n  - fictional world ontologies are built by mimicking existing BFO-conformant ontologies\"\n- **backbone taxonomy + lateral relations** : \n\n## [BFO2 Reference](https://raw.githubusercontent.com/BFO-ontology/BFO/master/docs/bfo2-reference/BFO2-Reference.pdf) \n\n- We use ‘category’ to refer to those universals at the most general and domain-neutral level. BFO treats only of categories in this sense. A category is a formal (= domain-neutral) universal, as contrasted with the material (domain-specific) universals represented in one or other domain ontology. BFO:fiat object part is a category in this sense; not however organism or weapon, or mortgage contract. Spatial, temporal and spatiotemporal region terms are counted as representing formal universals in this sense, since they apply in all domains.\n- is_a hierarchy\n- specifically dependent continuants are subject to the axiom of non-migration – they cannot migrate from one bearer to another. Generically dependent continuants, in contrast, can in a sense migrate, namely through a process of exact copying which allows, for example, the very same information artifact to be saved to multiple storage devices.\n![[#comparison gist Council 12-1-22 - gist/BFO comparison with Dylan Abney|prdct.gist#comparison-gist-council-12-1-22---gistbfo-comparison-with-dylan-abney]]\n\n## Resources\n\n- [[ar.bfo-2-0-specification-and-users-guide]]\n- https://therecouldbebadgers.wordpress.com/2018/06/27/endurants-perdurants-continuants-occurrents/\n- [[ar.basic-formal-ontology-july-2023]]\n- [[prdct.bfo-classifier]]\n- [[book.building-ontologies-with-basic-formal-ontology]]\n\n## References\n\n- https://www.youtube.com/watch?v=uflMfvI-ZxI\n- [[ar.foundational-ontologies-in-action]]\n- https://eng.libretexts.org/Bookshelves/Computer_Science/Programming_and_Computation_Fundamentals/An_Introduction_to_Ontology_Engineering_(Keet)/07%3A_Top-Down_Ontology_Development/7.02%3A_Foundational_Ontologies\n- https://raw.githubusercontent.com/BFO-ontology/BFO/master/docs/bfo2-reference/BFO2-Reference.pdf","n":0.044}}},{"i":3783,"$":{"0":{"v":"BFO 2020","n":0.707},"1":{"v":"\n- https://github.com/BFO-ontology/BFO-2020/\n\n## Features\n\n### Temporal \n\n- [temporal extensions](https://github.com/BFO-ontology/BFO-2020/blob/master/src/owl/profiles/temporal%20extensions/README.md)\n  - To satisfy needs of the community then, the BFO development team encourages a strategy of developing and deploying Temporal Extensions which will provide users options for representing time in their domains.\n  - Given the need to represent time and change in many domains and the wide use of OWL in ontology circles, proposals have been offered by users of BFO for representing such phenomena within the binary constraints of OWL. Examples include:\n\n    -   [Temporalized Relations](https://github.com/BFO-ontology/BFO-2020/blob/master/src/owl/profiles/temporal%20extensions/temporalized%20relations/owl/README.md)  \n        -   https://github.com/BFO-ontology/BFO-2020/blob/master/src/owl/profiles/temporal%20extensions/temporalized%20relations/owl/bfo-temporalized-relations.ttl\n    -   [Temporal Interpretation Annotation](https://oborel.github.io/obo-relations/temporal-semantics/)\n\n#### Competency Questions for temporal representation\n\n- https://github.com/CommonCoreOntology/CommonCoreOntologies/issues/118\n\n##### How to turn dates into into temporal information\n\n- https://github.com/CommonCoreOntology/CommonCoreOntologies/issues/118#issuecomment-810285200\n- Purposes:\n  - reasoning and inferencing; when rules can't be express in (OWL?) DL, use [[prdct.spin]]\n  - sparql queries for now or historical\n  - recording provenance. \"text in a document that denotes a day, month, or year is typically as close as I can get to knowing the temporal region during which a process occurs.\"\n  - assumption: \"The temporal region does not explicitly state the starting and ending moments, but these values can be calculated.\"\n  - I assert the process to be the subject of an [[t.km.ontology.information-content-entity]], which in turn generically depends on an [[t.km.ontology.information-bearing-entity]]. The Information Bearing Entity is the subject of a triple in the above form, where the predicate is cco:has_date_value and the object is a literal, either with a language tag or of type xsd:string.\n  - I create a temporal interval based on the text literal. I associate the temporal interval with the process and the Information Content Entity.\n```\n:process occupies-temporal-region :tr .\n:tr designated-by :ice .\n:ice generically-depends-on-at-all-times :ibe .\n:ibe has-date-value \"March 31\"@en .\n```\nThis establishes provenance. Next I create temporal instants representing the first and last instants of March 31:\n```\n:instant-01 a cco:TemporalInstant .\n:instant-02 a cco:TemporalInstant .\n:tr has-first-instant :instant-01 .\n:tr has-last-instant :instant-02 .\n```","n":0.058}}},{"i":3784,"$":{"0":{"v":"Basic Fantasy","n":0.707},"1":{"v":"\n- [[p.hasURL]] https://www.basicfantasy.org/\n- ","n":0.577}}},{"i":3785,"$":{"0":{"v":"Basalt Engine","n":0.707},"1":{"v":"\n- repo: https://github.com/axyiee/basalt-engine\n\ndevelopment is slow/stopped","n":0.447}}},{"i":3786,"$":{"0":{"v":"Barista","n":1},"1":{"v":"\n## Resources\n\n- https://javascript.plainenglish.io/meet-barista-client-side-codebase-as-a-graph-9479c99aa3a9","n":0.577}}},{"i":3787,"$":{"0":{"v":"Bandersnatch","n":1},"1":{"v":"\n- [[c.topic]] [[t.cs.ui.cli]] [[t.cs.programming.repl]]\n- [[p.instanceOf]] [[c.software.cli-framework]]\n- repo: https://github.com/hongaar/bandersnatch\n\n## Features\n\n-   🌊 [Fluid](https://www.martinfowler.com/bliki/FluentInterface.html) syntax, intuitive to use\n-   🔜 Autocompletion of commands, arguments, options and choices\n-   ➰ Built-in [REPL](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop) for interactive programs with 🔙 Command history\n-   💬 Can prompt for missing arguments\n-   🤯 Built for TypeScript, command arguments are fully typed\n-   🪆 Supports singular (e.g. `foo`) and nested commands (e.g. `foo bar`)\n-   🏃 Argument types are guaranteed at runtime (coming soon)\n-   ","n":0.121}}},{"i":3788,"$":{"0":{"v":"Babylon.js","n":1},"1":{"v":"\n- repo: https://github.com/BabylonJS\n- written-in: typescript\n\n## Features\n\n- [[prdct.havok]] for physics\n- headless with [NullEngine](https://doc.babylonjs.com/setup/support/serverSide)\n- GUI with Babylon.js GUI library\n\n### ECS\n\n- https://forum.babylonjs.com/t/babylon-meets-ecs/38716/3 [[p.mentioned]]\n  - [[prdct.miniplex]]\n\n## Resources\n\n- [[book.going-the-distance-with-babylonjs]]\n- https://forum.babylonjs.com/t/babylon-js-project-start-organization/23856/36 (useless)\n- https://babylonjs.medium.com/creating-thousands-of-animated-entities-in-babylon-js-ce3c439bdacf\n","n":0.192}}},{"i":3789,"$":{"0":{"v":"Null Engine","n":0.707}}},{"i":3790,"$":{"0":{"v":"BabyAGI","n":1},"1":{"v":"\n- repo: https://github.com/yoheinakajima/babyagi\n- ","n":0.577}}},{"i":3791,"$":{"0":{"v":"Babel","n":1},"1":{"v":"\nurl: https://babeljs.io/\n\n","n":0.707}}},{"i":3792,"$":{"0":{"v":"Babashka","n":1},"1":{"v":"\n- repo: https://github.com/babashka/babashka","n":0.577}}},{"i":3793,"$":{"0":{"v":"Azure","n":1},"1":{"v":"\n## Management\n\n![](/assets/images/2023-01-27-02-46-42.png)","n":0.707}}},{"i":3794,"$":{"0":{"v":"Service Bus","n":0.707},"1":{"v":"\n## Comparison \n\n![[prdct.azure.event-grid#^tlbdk95pkgk8:#^e48anqzd79vy]]\n","n":0.577}}},{"i":3795,"$":{"0":{"v":"Pub Sub","n":0.707}}},{"i":3796,"$":{"0":{"v":"Functions","n":1}}},{"i":3797,"$":{"0":{"v":"Azure Event Hubs","n":0.577},"1":{"v":"\n#similar [[prdct.azure.event-hubs]] [[prdct.kafka]] [[prdct.aws.msk]]   ^ls3s1l3vm1hl\n\n\n## \n\n## Comparison\n- https://drive.google.com/open?id=1-M5ljqu4hi5t6bdeskRKL8TenWFYbBpy&authuser=dave%40towerofscience.com&usp=drive_fs\n  - \"Serverless cannot work with non-Java clients at all\"\n\n![[prdct.azure.event-grid#^tlbdk95pkgk8:#^e48anqzd79vy]]\n\n\n## Learning Resource\n\n- https://learn.microsoft.com/en-us/azure/event-hubs/apache-kafka-frequently-asked-questions","n":0.224}}},{"i":3798,"$":{"0":{"v":"Event Grid","n":0.707},"1":{"v":"\n[[p.instanceOf]] [[t.cs.sd.architecture.event-driven.event-broker]]\n\n- [[p.similarTo]] [[prdct.google-cloud.eventarc]] [[prdct.aws.event-bridge]]\n- [[p.supports]] [[prdct.cloudevents]]\n\nurl: https://azure.microsoft.com/en-us/products/event-grid/\n\n- [[p.hasLearningResource]] https://learn.microsoft.com/en-us/azure/event-grid/overview\n- [[p.supports]] on-prem deployment via https://learn.microsoft.com/en-us/azure/event-grid/kubernetes/overview\n\n## Comparison \n\n### [[prdct.azure.event-grid]] vs. [[prdct.azure.event-hubs]] vs. [[prdct.azure.service-bus]]  ^tlbdk95pkgk8\n\nhttps://learn.microsoft.com/en-us/azure/event-grid/compare-messaging-services\n\n| Service | Purpose | Type | When to use |\n| --- | --- | --- | --- |\n| Event Grid | Reactive programming | Event distribution (discrete) | React to status changes |\n| Event Hubs | Big data pipeline | Event streaming (series) | Telemetry and distributed data streaming |\n| Service Bus | High-value enterprise messaging | Message | Order processing and financial transactions |  ^e48anqzd79vy","n":0.106}}},{"i":3799,"$":{"0":{"v":"Databricks","n":1}}},{"i":3800,"$":{"0":{"v":"Cosmos Db","n":0.707},"1":{"v":"\n- [[p.supports]] [[prdct.tinkerpop]]\n  - https://learn.microsoft.com/en-us/azure/cosmos-db/gremlin/introduction\n  - https://learn.microsoft.com/en-us/azure/cosmos-db/gremlin/support\n- ","n":0.378}}},{"i":3801,"$":{"0":{"v":"Active Directory","n":0.707},"1":{"v":"\n- ","n":1}}},{"i":3802,"$":{"0":{"v":"Azure Cognitive Services","n":0.577},"1":{"v":"\n\n\nAzure Cognitive Services\n","n":0.577}}},{"i":3803,"$":{"0":{"v":"Axios","n":1},"1":{"v":"\nrepo: https://github.com/axios/axios\n\n## Use Case\n\n- retrieving (text) content from [[prdct.github]]\n  - ![[Log|sh.log#^dvfb327f379i]]","n":0.302}}},{"i":3804,"$":{"0":{"v":"Axie Infinity","n":0.707},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.cs.metaverse]]\n- Lunacia SDK to be release 2022-12\n","n":0.333}}},{"i":3805,"$":{"0":{"v":"Avalonia","n":1},"1":{"v":"\n- url: https://avaloniaui.net/\n\n## Features\n\n- usage of a [[sh.archt.svg]] rendering engine, which allows apps to seem pixel-perfect on any platform or screen size.\n\n## References\n\n- https://tomaszs2.medium.com/10-c-apps-you-should-know-eb2beb9292e3\n  - mentions [[prdct.memorypack]]","n":0.192}}},{"i":3806,"$":{"0":{"v":"Automerge","n":1}}},{"i":3807,"$":{"0":{"v":"Autogen","n":1}}},{"i":3808,"$":{"0":{"v":"Autodev","n":1},"1":{"v":"\n- [[c.software.ai.development-assistant]]\n- repo: https://github.com/unit-mesh/auto-dev\n- written_in: kotlin\n- depends_on: [[prdct.devins]]","n":0.354}}},{"i":3809,"$":{"0":{"v":"Auth.js","n":1},"1":{"v":"\n- supports: [[prdct.typedb]] kinda, see https://github.com/Blitzapps/next-auth","n":0.408}}},{"i":3810,"$":{"0":{"v":"Atomspace","n":1},"1":{"v":"\n- repo: https://github.com/opencog/atomspace\n- written-in: #c++\n- [[p.builtOn]] [[prdct.postgres]]\n- [[p.hasRelatedTopic]] [[t.km.kr]] \n- \"AtomSpace is a platform for building Artificial General Intelligence (AGI) systems. It provides the central knowledge representation component for OpenCog. As such, it is a fairly mature component, on which a lot of other systems are built, and which depend on it for stable, correct operation in a day-to-day production environment.\"\n\n## [[p.hasFeature]]\n\n-   **Search queries are graphs.** (The API to the [pattern engine](https://wiki.opencog.org/w/Pattern_engine) is a graph.) That is, every query, every search is also a graph. That means one can store a collection of searches in the database, and access them later. This allows a graph rule engine to be built up.\n-   **Inverted searches.** ([DualLink](https://wiki.opencog.org/w/DualLink).) Normally, a search is like \"asking a question\" and \"getting an answer\". For the inverted search, one \"has an answer\" and is looking for all \"questions\" for which its a solution. This is pattern recognition, as opposed to pattern search. All chatbots do this as a matter of course, to handle chat dialog. No chatbot can host arbitrary graph data, or search it. The AtomSpace can. This is because queries are also graphs, and not just data.\n-   Both [**\"meet\" and \"join\"**](https://en.wikipedia.org/wiki/Join_and_meet) searches are possible: One can perform a \"fill in the blanks\" search (a meet, with [MeetLink](https://wiki.opencog.org/w/MeetLink)) and one can perform a \"what contains this?\" search (a join, with [JoinLink](https://wiki.opencog.org/w/JoinLink).)\n-   **Graphs are executable.** Graph vertex types include \"plus\", \"times\", \"greater than\" and many other programming constructs. The resulting graphs encode [\"abstract syntax trees\"](https://en.wikipedia.org/wiki/Abstract_syntax_tree) and the resulting language is called [Atomese](https://wiki.opencog.org/w/Atomese). It resembles the [intermediate representation](https://en.wikipedia.org/wiki/Intermediate_representation) commonly found in compilers, except that, here, its explicitly exposed to the user as a storable, queriable, manipulable, executable graph.\n-   **Graphs are typed** ([TypeNode](https://wiki.opencog.org/w/TypeNode) and [type constructors](https://wiki.opencog.org/w/Type_constructor).) Graph elements have types, and there are half a dozen type constructors, including types for graphs that are functions. This resembles programming systems that have type constructors, such as CaML or Haskell.\n-   **Graphs specify flows** ([Values](https://wiki.opencog.org/w/Value) and [DynamicFormulaLink](https://wiki.opencog.org/w/DynamicFormulaLink).) Graph elements host dynamic, mutable key-value databases. That is, every graph element has an associated key-value database. Think of the graph is \"pipes\" or \"plumbing\"; the key-value data is the mutable, dynamically changing \"water\" that flows through those pipes.\n-   **Unordered sets** ([UnorderedLink](https://wiki.opencog.org/w/UnorderedLink).) A graph vertex can be an unordered set (Think of a list of edges, but they are not in any fixed order.) When searching for a matching pattern, one must consider **all** permutations of the set. This is easy, if the search has only one unordered set. This is hard, if they are nested and inter-linked: it becomes a constraint-satisfaction problem. The AtomSpace pattern engine handles all of these cases correctly.\n-   **Alternative sub-patterns** ([ChoiceLink](https://wiki.opencog.org/w/ChoiceLink).) A search query can include a menu of sub-patterns to be matched. Such sets of alternatives can be nested and composed arbitrarily. (*i.e.* they can contain variables, *etc.*)\n-   **Globby matching** ([GlobNode](https://wiki.opencog.org/w/GlobNode).) One can match zero, one or more subgraphs with globs This is similar to the idea of globbing in a regex. Thus, a variable need not be grounded by only one subgraph: a variable can be grounded by an indeterminate range of subgraphs.\n-   **Quotations** ([QuoteLink](https://wiki.opencog.org/w/QuoteLink).) Executable graphs can be quoted. This is similar to quotations in functional programming languages. In this case, it allows queries to search for other queries, without triggering the query that was searched for. Handy for rule-engines that use rules to find other rules.\n-   **Negation as failure** ([AbsentLink](https://wiki.opencog.org/w/AbsentLink).) Reject matches to subgraphs having particular sub-patterns in them. That is, find all graphs of some shape, except those having these other sub-shapes.\n-   **For-all predicate** ([AlwaysLink](https://wiki.opencog.org/w/AlwaysLink).) Require that all matches contain a particular subgraph or satisfy a particular predicate. For example: find all baskets that have only red balls in them. This requires not only finding the baskets, making sure they have balls in them, but also testing each and every ball in a basket to make sure they are **all** of the same color. ","n":0.039}}},{"i":3811,"$":{"0":{"v":"Atomicserver","n":1},"1":{"v":"\n- https://atomicserver.eu/\n- repo: https://github.com/atomicdata-dev/atomic-server\n- written-in: rust typescript\n- demo: https://atomicdata.dev\n- based-on: [[prdct.atomic-data]]","n":0.302}}},{"i":3812,"$":{"0":{"v":"ATOMIC","n":1},"1":{"v":"\n- url: https://allenai.org/data/atomic\n\n## Example\n\n- \"if X pays Y a compliment, then Y will likely return the compliment\"\n\n## Resources\n\n- https://www.semanticscholar.org/paper/ATOMIC%3A-An-Atlas-of-Machine-Commonsense-for-If-Then-Sap-Bras/8209a8703d8c48aaca1523cfa307dd1c069e58f3","n":0.229}}},{"i":3813,"$":{"0":{"v":"Atomic Data","n":0.707},"1":{"v":"\n- published-by: [[org.ontola]]\n- related: [[prdct.json-ad]]\n- creators: @joep-meindertsma\n\n![](/assets/images/2024-10-16-12-12-59.png)\n\n## Thoughts\n\n- like [[prdct.solid]], requies the use of a personal server, aka [[t.cs.data.personal-online-datastore]].\n- requiring resolvable properties and emphasizing resolvable URLs seems limiting.\n- not being able to use common namespace:terms is kinda sad. you could adopt a no-modification- (or -restriction?-) -of-existing classes and properties\n- giving up \"anyone can say anything about anyone\" is too much. \n  - i.e., \"Atomic only allows those who control a resource's subject URL endpoint to edit the data. This means that you can't add triples about something that you don't control.\"\n- requiring online-ness and lookups for parsing is too troubling.\n- it is true that minting IRIs is troublesome.\n\n## Comparisons\n\n\n## vs [[prdct.rdf]] \n\n(from https://docs.atomicdata.dev/interoperability/rdf)\n\n-   Atomic calls the three parts of a Triple `subject`, `property` and `value`, instead of `subject`, `predicate`, `object`.\n-   Atomic does not support having multiple statements with the same `<subject> <predicate>`, every combination must be unique.\n-   Atomic does not have `literals`, `named nodes` and `blank nodes` - these are all `values`, but with different datatypes.\n-   Atomic uses `nested Resources` and `paths` instead of `blank nodes`\n-   Atomic requires URL (not URI) values in its `subjects` and `properties` (predicates), which means that they should be resolvable. Properties must resolve to an `Atomic Property`, which describes its datatype.\n-   Atomic only allows those who control a resource's `subject` URL endpoint to edit the data. This means that you can't add triples about something that you don't control.\n-   Atomic has no separate `datatype` field, but it requires that `Properties` (the resources that are shown when you follow a `predicate` value) specify a datatype. However, it is allowed to serialize the datatype explicitly, of course.\n-   Atomic has no separate `language` field.\n-   Atomic has a native Event (state changes) model ([Atomic Commits](https://docs.atomicdata.dev/commits/intro)), which enables communication of state changes\n-   Atomic has a native Schema model ([Atomic Schema](https://docs.atomicdata.dev/schema/intro)), which helps developers to know what data types they can expect (string, integer, link, array)\n-   Atomic does not support Named Graphs. These should not be needed, because all statements should be retrievable by fetching the Subject of a resource. However, it _is_ allowed to include other resources in a response.\n\n## vs [[prdct.solid]]\n\n**similar goals** to Atomic Data:\n\n-   Decentralize the web\n-   Make things more interoperable\n-   Give people more control over their data\n\nTechnically, both are also similar:\n\n-   Usage of **personal servers**, or PODs (Personal Online Datastores). Both Atomic Data and Solid aim to provide users with a highly personal server where all sorts of data can be stored.\n-   Usage of **linked data**. All Atomic Data is valid RDF, which means that **all Atomic Data is compatible with Solid**. However, the other way around is more difficult. In other words, if you choose to use Atomic Data, you can always put it in your Solid Pod.\n\nBut there are some important **differences**, too, which will be explained in more detail below.\n\n-   Atomic Data uses a strict built-in schema to ensure type safety\n-   Atomic Data standardizes state changes (which also provides version control / history, audit trails)\n-   Atomic Data is more easily serializable to other formats (like JSON)\n-   Atomic Data has different models for authentication, authorization and hierarchies\n-   Atomic Data does not depend on existing semantic web specifications\n-   Atomic Data is a smaller and younger project, and as of now a one-man show\n   \n### [Atomic Data is more easily serializable to other formats (like JSON)](https://docs.atomicdata.dev/interoperability/solid#atomic-data-is-more-easily-serializable-to-other-formats-like-json)\n\nAtomic Data is designed with the modern (web)developer in mind. One of the things that developers expect, is to be able to traverse (JSON) objects easily. Doing this with RDF is not easily possible, because doing this requires _subject-predicate uniqueness_. Atomic Data does not have this problem (properties _must_ be unique), which means that traversing objects becomes easy.\n\nAnother problem that Atomic Data solves, is dealing with long URLs as property keys. Atomic Data uses `shortnames` to map properties to short, human-readable strings.\n\nFor more information about these differences, see the previous [RDF chapter](https://docs.atomicdata.dev/interoperability/rdf).\n\n### [Authentication](https://docs.atomicdata.dev/interoperability/solid#authentication)\n\nBoth Solid an Atomic Data use URLs to refer to individuals / users / Agents.\n\nSolid's identity system is called WebID. There are multiple supported authentication protocols, the most common being [WebID-OIDC](https://github.com/solid/webid-oidc-spec).\n\nAtomic Data's [authentication model](https://docs.atomicdata.dev/authentication) is more similar to how SSH works. Atomic Data identities (Agents) are a combination of HTTP based, and cryptography (public / private key) based. In Atomic, all actions (from GET requests to Commits) are signed using the private key of the Agent. This makes Atomic Data a bit more unconventional, but also makes its auth mechanism very decentralized and lightweight.\n\n### Solid advantages\n\n-   No inbox or [notifications](https://www.w3.org/TR/ldn/) yet ([issue](https://github.com/ontola/atomic-data/issues/28)) ([[prdct.linked-data-notifications]])\n-   No OIDC support yet. ([issue](https://github.com/atomicdata-dev/atomic-server/issues/277))\n-   No support from a big community, a well-funded business or the inventor of the world wide web.\n\n## Shortnames\n\n- Requiring Properties to resolve is part of what enables the type system of Atomic Schema - they provide the shortname and datatype.\n\n### Advantages of Shortnames\n\nReadability: Shortnames can make your transactions and queries more concise and easier to understand, especially when dealing with complex Property names.\nBrevity: They reduce data size in transaction payloads.\nPotential Namespace Management: Shortnames can play a role in how you manage namespaces within your data model.\n\n### Important Considerations\n\n- Name Collisions: Atomic Data guarantees uniqueness of the Subject-Property combination, mitigating shortname collisions within the context of an entity. However, if resources from multiple Classes with the same shortname are mixed, clients need a strategy to resolve potential clashes (see the Atomic Data FAQ you linked earlier).\n- Not a Replacement for Full URIs: Shortnames are a convenience mechanism. Internally, Atomic Data still relies on full Property URIs.\n- each Property URL must resolve to an online Atomic Data Property.\n\n\n## References\n\n- https://docs.atomicdata.dev/interoperability/solid","n":0.033}}},{"i":3814,"$":{"0":{"v":"Atomgraph Processor","n":0.707},"1":{"v":"\n- https://github.com/AtomGraph/Processor\n- published-by: [[org.atomgraph]]\n- related: [[prdct.linkeddatahub]]\n\n## Description\n\n- \"abstract application logic away from source code and capture it in a machine-processable representation that enables reuse, composition, and reasoning. Our goal is to permit software to operate on itself through metaprogramming to generate higher-level applications — a feature not available in imperative languages\"\n\n\n## Resources\n\n- https://github.com/AtomGraph/Processor/wiki/Articles-and-presentations","n":0.137}}},{"i":3815,"$":{"0":{"v":"Atmosphere","n":1},"1":{"v":"\n- [[c.Software.real_time_framework]]\n- repo: https://github.com/Atmosphere/atmosphere\n- supports: [[prdct.vertx]]","n":0.408}}},{"i":3816,"$":{"0":{"v":"Atlas","n":1},"1":{"v":"\n- [[c.software.data-discovery]]\n- url: https://atlas.apache.org/#/\n- repo: https://github.com/apache/atlas\n- written_in: java\n- uses: [[prdct.janusgraph]]","n":0.316}}},{"i":3817,"$":{"0":{"v":"Athens Research","n":0.707},"1":{"v":"\n#dead\n\n\n- [[p.hasRepository]] https://github.com/athensresearch/athens\n- [[p.hasDemonstration]] https://athensresearch.github.io/athens/#/\n- [[p.hasBlog]] https://athensresearch.ghost.io/\n- [[p.hasApplication]] [[t.km.pkm]] [[t.km.ckm]]\n- [[p.similarTo]] [[prdct.notion]]\n\n- [[p.hasConcept]]\n  - `[[type]]` is the most global level attribute. It applies to both knowledge pages (e.g. notes, writings, and documentation) as well as action pages (e.g. objectives, projects)\n\n## [[p.hasRoadmapItems]]\n\n- comments and suggestions like in Google Docs, but addressable and referenceable\n- forking, branching, and merging\n- cross-graph references \n  - [[p.begsQuestion]] \"[Should cross-graph references update in real-time or require confirmation? History, identity, and permissioning are fundamental challenges when it comes to building shared graphs.](https://athensresearch.ghost.io/season-2/)\" \n\n## [[p.hasFeature]]\n  - If you mention two pages in tandem, either in the same bullet or sub-bullet (just as I did above), Athens will automatically link the pages. So, using the example I created, if you clicked on the restaurant [[Muzita Abyssinian Bistro]], not only can you type new content on that page, but you can immediately see it’s linked to “March 26, 2021,” “Kaito,” “San Diego,” and “Siga Kilwa.” Athens generated those associations that you determined were important.\n    - [How I became more productive during the pandemic](https://blakestephenanderson.medium.com/how-i-became-more-productive-during-the-pandemic-ab5cb68c0d9f)\n\n\n## [[p.hasCon]]\n- standalone app-ish (but )\n- storage isn't git-enabled or plaintext?\n","n":0.074}}},{"i":3818,"$":{"0":{"v":"AsyncAPI","n":1},"1":{"v":"\n\n- related: [[prdct.asyncapi.modelina]]\n\n## Terms\n\n- **gateway**: intercepts all incoming messages and routes them through the middleware and handler pipelines.\n\n## Highlights\n\n- \"Like with OpenAPI, an AsyncAPI documents an application from the client perspective.\"\n- \"there is no client/server paradigm... AsyncAPI approaches this by describing an application as having two potential roles:\n  - If it sends messages to a channel, it's a “Publisher\".\n  - If it is interested in receiving messages from a channel, it is a “Subscriber\"...\n  - The exception to the rule is websockets - there is a client/server paradigm rather than a messaging infrastructure - so other applications will connect directly to the server.\"\n\n## Comparison\n\n## [[c.comparand]] [[prdct.openapi]] \n\n- https://www.asyncapi.com/blog/openapi-vs-asyncapi-burning-questions\n  - ![](/assets/images/2023-09-29-11-33-20.png)\n- https://stackoverflow.com/questions/67055564/how-to-document-a-mixture-of-synchronous-and-asynchronous-apis-do-we-use-asynca\n- https://bump.sh/blog/asyncapi-vs-openapi\n- https://www.asyncapi.com/docs/tutorials/getting-started/coming-from-openapi\n  - \n\n## [[c.comparand]] [[prdct.cloudevents]]\n\n- https://www.asyncapi.com/blog/asyncapi-cloud-events\n  - \"Unlike CloudEvents —who focuses on the message— AsyncAPI does not impose how your event must look like but, instead, allows you to strictly define its shape.\"\n  - \"We can define the event payload but its structure is totally free and user-defined. And that's what makes AsyncAPI so powerful! Since our event payload can be anything, it can also be a CloudEvents event.\"\n- https://atamel.dev/posts/2023/05-23_asyncapi_cloudevents/\n  - CloudEvents help to define the format of the events and AsyncAPI helps to define the event-driven APIs.\n\n## Solutions\n\n- [[prdct.zenwave]] java-based toolkit for Domain Driven Design (DDD) and API-First\n\n## Resources\n\n- https://nordicapis.com/6-asyncapi-validation-tools/\n- https://www.asyncapi.com/blog/websocket-part1\n- https://nordicapis.com/7-protocols-good-for-documenting-with-asyncapi/\n  - includes [[prdct.nats]]\n- https://blog.postman.com/asyncapi-joins-forces-with-postman-future-of-apis/\n- https://www.asyncapi.com/b\n- [ ] [asyncapi-miniseries](https://github.com/jonaslagoni/asyncapi-miniseries/blob/master/docs/Part%201%20-%20Designing%20the%20API's.md)\n  - \"I always start with the basics and define all the different channels for which the game server should produce events over.\"\n  - mentions: Nic Townsend's post about [Demystifying the Semantics of Publish and Subscribe](https://www.asyncapi.com/blog/publish-subscribe-semantics).\n- https://icepanel.medium.com/asyncapi-for-event-driven-architectures-b08d6ee952fc\n- https://www.asyncapi.com/blog/publish-subscribe-semantics\n  - \"When reading an AsyncAPI document:\n\n    publish means publish an event to the channel and this application will receive it\n    subscribe means subscribe to this channel to receive events published by this application\"\n- https://www.asyncapi.com/blog/understanding-asyncapis\n- \n\n### c#\n\n- [[prdct.asyncapi.template.c-sharp]]","n":0.058}}},{"i":3819,"$":{"0":{"v":"Template","n":1}}},{"i":3820,"$":{"0":{"v":"C Sharp","n":0.707},"1":{"v":"\n- repo: https://github.com/asyncapi/dotnet-nats-template","n":0.577}}},{"i":3821,"$":{"0":{"v":"Studio","n":1},"1":{"v":"\n- url: https://studio.asyncapi.com/\n- ","n":0.577}}},{"i":3822,"$":{"0":{"v":"AsyncAPI.Net","n":1},"1":{"v":"\n- repo: https://github.com/LEGO/asyncapi.net\n- ","n":0.577}}},{"i":3823,"$":{"0":{"v":"Modelina","n":1},"1":{"v":"\n- contributor: @jonas-lagoni\n- repo: https://github.com/asyncapi/modelina","n":0.447}}},{"i":3824,"$":{"0":{"v":"Astro","n":1},"1":{"v":"\n- url: https://astro.build/\n\n## @chatgpt.3.5\n\n-   Astro is a static site generator and framework for building fast and efficient websites. It focuses on creating static sites that can be optimized for performance by pre-rendering pages and loading only the necessary JavaScript when needed.\n-   Astro uses a component-based architecture and supports various front-end frameworks, such as React, Svelte, and Vue.\n-   It aims to reduce the amount of JavaScript needed to deliver a web page, resulting in faster page loads and improved SEO.\n\n","n":0.113}}},{"i":3825,"$":{"0":{"v":"Astral Tabletop","n":0.707},"1":{"v":"\n- dead","n":0.707}}},{"i":3826,"$":{"0":{"v":"Astradb","n":1}}},{"i":3827,"$":{"0":{"v":"Astra","n":1},"1":{"v":"\n- url: https://guide.astralanguage.com/en/latest/\n- repo: https://gitlab.com/astra-language/astra-core\n\n## \n","n":0.408}}},{"i":3828,"$":{"0":{"v":"Assettiger","n":1},"1":{"v":"\n\n- no client?\n","n":0.577}}},{"i":3829,"$":{"0":{"v":"Asp Net","n":0.707}}},{"i":3830,"$":{"0":{"v":"Ashley","n":1},"1":{"v":"\n- [[c.Software.Entity-Component-System]]\n- repo: https://github.com/libgdx/ashley\n- written_in: java\n- ","n":0.408}}},{"i":3831,"$":{"0":{"v":"Asciiflo","n":1}}},{"i":3832,"$":{"0":{"v":"Arweave","n":1},"1":{"v":"\n- [[p.supports]] [[prdct.mirror]]\n- [ ] get a wallet at https://faucet.arweave.net/\n","n":0.316}}},{"i":3833,"$":{"0":{"v":"Artemis Odb","n":0.707},"1":{"v":"\n- dead since t.2021.07\n- url: https://github.com/junkdog/artemis-odb\n- supports: [[prdct.gwt]]\n\n## Highlights\n\n* Full Android, HTML5, iOS support.\n* High performance, GC-friendly, less boilerplate!\n* Optionally auto-pooled components and hotspot optimization via compile-time bytecode instrumentation.\n* Serialize to either json or binary.\n* Automatic tracking, and maintenance of entity relationships.\n* Fast prototyping with fluid interfaces (optional).\n* Easy migration from Artemis clones.\n","n":0.137}}},{"i":3834,"$":{"0":{"v":"Arrow","n":1},"1":{"v":"\n- url: https://arrow-kt.io\n- \n\n## @chatgpt.3.5\n\n- Arrow is a web framework for building web applications in the Kotlin programming language. It's designed for server-side development and can be used to create RESTful APIs, web applications, and more.\n- Arrow provides abstractions and tools for building type-safe and functional applications. It promotes functional programming practices and is inspired by the Arrow library for Kotlin.\n- It is not a front-end library like Astro or htmx but focuses on the back-end and server-side development.","n":0.113}}},{"i":3835,"$":{"0":{"v":"Arrow JS","n":0.707},"1":{"v":"\n- url: https://www.arrow-js.com/\n\n\n## Features\n\n- Observable data.\n- Declarative/Reactive DOM rendering.\n\n## Philosophy\n\n- simple\n- modern\n  - \"Arrow relies heavily on modern features of JavaScript such as [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals), [modules](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules) (think `import` and `export`), and [Proxies](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy).\"\n- performant","n":0.174}}},{"i":3836,"$":{"0":{"v":"ARKnowD","n":1},"1":{"v":"\n\n![](/assets/images/2024-07-14-07-38-24.png)\n\n![](/assets/images/2024-07-14-07-39-16.png)\n\n![](/assets/images/2024-07-14-07-39-36.png)\n\n![](/assets/images/2024-07-14-07-39-57.png)","n":1}}},{"i":3837,"$":{"0":{"v":"Arkenforge","n":1},"1":{"v":"\n- https://arkenforge.com/\n- [[c.software.rpg.virtual-tabletop]]\n\n## Features\n\n### Play in Person with Fog of War\n\n- [[sh.use-case.play-in-person]]","n":0.289}}},{"i":3838,"$":{"0":{"v":"Aristotle","n":1},"1":{"v":"\n- repo: https://github.com/arachne-framework/aristotle","n":0.577}}},{"i":3839,"$":{"0":{"v":"ARIA","n":1},"1":{"v":"\n\n\n[[p.hasLearningResource]]\n  - https://docs.microsoft.com/en-us/learn/modules/web-development-101-accessibility/4-links-images\n","n":0.577}}},{"i":3840,"$":{"0":{"v":"ArgoUML","n":1},"1":{"v":"- [[c.software.tools.modeling]] \n- [[c.con]] no undo?\n ","n":0.408}}},{"i":3841,"$":{"0":{"v":"Argo","n":1},"1":{"v":"\n- created-by: [[org.intuit]]","n":0.577}}},{"i":3842,"$":{"0":{"v":"Workflows","n":1}}},{"i":3843,"$":{"0":{"v":"Rollouts","n":1}}},{"i":3844,"$":{"0":{"v":"Argo Events","n":0.707},"1":{"v":"\n- https://argoproj.github.io/argo-events/\n- ","n":0.707}}},{"i":3845,"$":{"0":{"v":"Argo CD","n":0.707}}},{"i":3846,"$":{"0":{"v":"Argdown","n":1},"1":{"v":"\nurl: https://argdown.org/\nrepo: \n\n- uses `->` for references\n- overloads `-` for \"con\"\n\n\n","n":0.302}}},{"i":3847,"$":{"0":{"v":"ARCore","n":1},"1":{"v":"\n- url: https://developers.google.com/ar","n":0.577}}},{"i":3848,"$":{"0":{"v":"Archi","n":1},"1":{"v":"\n- url: https://www.archimatetool.com/\n- [[p.similarTo]] [[prdct.argouml]]","n":0.447}}},{"i":3849,"$":{"0":{"v":"Arche","n":1},"1":{"v":"\n- repo: https://github.com/mlange-42/arche\n- uses: [[prdct.pixel]]\n- written_in: go\n\n## Features\n\n-   Simple [core API](https://pkg.go.dev/github.com/mlange-42/arche/ecs). See the [API docs](https://pkg.go.dev/github.com/mlange-42/arche).\n-   Optional logic [filter](https://pkg.go.dev/github.com/mlange-42/arche/filter) and type-safe [generic](https://pkg.go.dev/github.com/mlange-42/arche/generic) API.\n-   Entity relations as first-class feature. See [Architecture](https://github.com/mlange-42/arche/blob/main/ARCHITECTURE.md#entity-relations).\n-   World serialization and deserialization with [arche-serde](https://github.com/mlange-42/arche-serde).\n-   No systems. Just queries. Use your own structure (or the [Tools](https://github.com/mlange-42/arche?tab=readme-ov-file#tools)).\n    -   similar to [[prdct.bitecs]]?\n-   No dependencies. Except for unit tests ([100% coverage](https://coveralls.io/github/mlange-42/arche)).\n-   Probably the fastest Go ECS out there. See the [Benchmarks](https://github.com/mlange-42/arche?tab=readme-ov-file#benchmarks).\n-   \n\n## Interesting\n\n- Arche is designed for the development of scientific, individual-based models rather than for game development. This motivates some design decisions, with an emphasis on simplicity, safety and performance. Nevertheless, Arche can also be used for game development.\n\n## Cons\n\n- The number of component types per World is limited to 256. This is mainly a performance decision.","n":0.089}}},{"i":3850,"$":{"0":{"v":"Arch","n":1},"1":{"v":"\n- url: https://github.com/genaray/Arch\n- [[p.instanceOf]] [[t.cs.entity-component-system]]\n- written-in: c#\n\n## Features\n\n- supports persistence (to json and binary) and relationships\n\n## Comparison\n\n- \"Svelto and Entitas are great, no question... but they are also damn complex, need even more boilerplate code and use sparsesets instead of archetypes\"\n\n## Demos\n\n- https://github.com/genaray/Arch/wiki/Projects-using-Arch\n- https://github.com/Doprez/stride-arch-ecs\n\n### [](https://github.com/genaray/Arch#space-station-14)[Space Station 14](https://spacestation14.io/)\n\nSpace Station 14 is inspired by the cult classic Space Station 13 and tells the extraordinary story of everything that can go wrong on a shift at a space station. You take on a role and complete your tasks so that the space station doesn't go to the dogs... or do the exact opposite. Prepare yourself for chaos and the finest roleplay. Best of all, SS14 is open-source and anyone can play!\n\n## [Roguelite-Survivor](https://github.com/genaray/Arch#roguelite-survivor)\n\n- must've been deleted\n\n## [[prdct.equilibrium-engine]]\n\n","n":0.09}}},{"i":3851,"$":{"0":{"v":"Arcadia","n":1},"1":{"v":"\n- dead\n- repo: https://github.com/arcadia-unity/Arcadia","n":0.5}}},{"i":3852,"$":{"0":{"v":"ArcadeDB","n":1},"1":{"v":"\n- [[c.software.database.multi-model]]  [[c.software.database.graph.property]] [[c.software.database.embedded]] [[c.software.database.vector]]\n- repo: https://github.com/ArcadeData/arcadedb\n- [[p.forkOf]] [[prdct.orientdb]]\n- written-in: java \n- [[p.compatibleWith]] [[prdct.cypher]] [[prdct.tinkerpop]]/[[prdct.gremlin]] [[prdct.redis]] [[prdct.postgres]]\n- [[p.supports]] [[t.cs.gis.geospatial-querying]] [[t.cs.data.vector-embedding]]\n- related: [[prdct.arcade-time-graph]]\n\n## Pro\n\n- embed in JVM, so [[p.compatibleWith]] scala #groovy #kotlin #clojure\n- ArcadeDB’s document model also adds the concept of a \"Relationship\" between documents. With ArcadeDB, you can decide whether to embed documents or link to them directly. When you fetch a document, all the links are automatically resolved by ArcadeDB. This is a major difference to other document databases, like MongoDB or CouchDB, where the developer must handle any and all relationships between the documents herself.\n- in the key-value store, it supports documents and graph elements as values\n\n## Con\n\n- One edge can only connect two vertices. (no hypergraph/metagraphs)\n\n## Questions\n\n- are the different modes using completely separate data?\n  - t.2024.01.26: yes, documents, edges and vertices are different types of records\n- presumably properties can't refer to vertexes\n  - t.2024.01.26: maybe not in a direct way, but you could use text\n\n## Comparison\n\n### vs [[prdct.neo4j]]\n\n- \"Neo4j supports multiple labels per node, while in ArcadeDB a node (vertex) must have only one type. The Neo4j importer will simulate multiple labels by creating new types with the following name: <label1>[_<labelN>]*.\"\n\n## References\n\n- [TinkerPop Wide: ArcadeDB - a Multi-Model Database with Gremlin](https://www.youtube.com/watch?v=X6qC-P-pkgs)\n- https://www.linkedin.com/pulse/experience-using-arcadedb-modelling-tool-vineeth-joseph/\n  - mentioned issues:\n    - no versioning\n    - no constraints over edge types\n    - no renaming properties","n":0.067}}},{"i":3853,"$":{"0":{"v":"Arcade","n":1},"1":{"v":"\n- url: https://api.arcade.academy\n- repo: https://github.com/pythonarcade/arcade\n\n\n## Comparison \n\n- https://api.arcade.academy/en/latest/pygame_comparison.html\n","n":0.354}}},{"i":3854,"$":{"0":{"v":"Arcade Time Graph","n":0.577},"1":{"v":"\n- repo: https://github.com/topofocus/arcade-time-graph\n- ","n":0.577}}},{"i":3855,"$":{"0":{"v":"Arbital","n":1},"1":{"v":"\nurl: https://arbital.com/\n\n","n":0.707}}},{"i":3856,"$":{"0":{"v":"Arangodb","n":1},"1":{"v":"\n- [[c.software.database.multi-model]]\n- written-in: #c++ javascript\n\n\n## Resources\n\n- https://arangodb.com/learn/graphs/time-traveling-graph-databases/\n  - \"each vertex in our application is joined by a single edge to an in-proxy vertex and to an out-proxy vertex. Then, each edge in our application connects the out-proxy of its source vertex to the in-proxy of its target vertex. In this way, when we modify a vertex, we need only copy it, and it’s proxy edges. The proxy vertices remain stable with respect to application edges.\" ^70wne4dgjwqz\n- https://arangodb.com/2024/02/reintroducing-the-arangodb-rdf-adapter/","n":0.114}}},{"i":3857,"$":{"0":{"v":"ArangeDB Query Language","n":0.577}}},{"i":3858,"$":{"0":{"v":"Apple Business Essentials","n":0.577}}},{"i":3859,"$":{"0":{"v":"Apparatus","n":1},"1":{"v":"\n- url: http://aprt.us/\n- repo: https://github.com/cdglabs/apparatus\n- [[p.similarTo]] [[prdct.scratch]]","n":0.378}}},{"i":3860,"$":{"0":{"v":"Apollo","n":1}}},{"i":3861,"$":{"0":{"v":"Tooling","n":1},"1":{"v":"\n## Features\n\n-     Download any GraphQL schema using a GraphQL endpoint, and then generate TypeScript types for queries written in an Apollo Client project (given a valid GraphQL schema)","n":0.189}}},{"i":3862,"$":{"0":{"v":"Apisix","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/apache/apisix\n- resources:  https://apisix.apache.org/blog/2022/09/23/build-event-driven-api/\n- [[p.supports]]\n  - [[prdct.grpc.web]] via [grpc-web plugin](https://apisix.apache.org/docs/apisix/plugins/grpc-web/)","n":0.302}}},{"i":3863,"$":{"0":{"v":"Apibldr","n":1},"1":{"v":"\n- [[c.software.tools.design.api]]\n- url: https://www.apibldr.com/","n":0.5}}},{"i":3864,"$":{"0":{"v":"API Platform","n":0.707},"1":{"v":"\n- https://api-platform.com/\n- supports: [[prdct.rdf]] [[prdct.JSON]] [[prdct.mercure]] [[t.cs.web.hateoas]] [[prdct.hydra]]\n- similar: [[prdct.api-platform]] [[prdct.creta]]\n\n## Features\n\n- Design your own data model as plain old PHP classes or import an existing ontology.\n- Expose in minutes a hypermedia REST or a GraphQL API with pagination, data validation, access control, relation embedding, filters, and error handling...\n- Benefit from Content Negotiation: GraphQL, JSON-LD, Hydra, HAL, JSON:API, YAML, JSON, XML and CSV are supported out of the box.\n- ","n":0.12}}},{"i":3865,"$":{"0":{"v":"Apex Utility Ai","n":0.577},"1":{"v":"\n- url: https://assetstore.unity.com/packages/tools/visual-scripting/apex-utility-ai-personal-edition-56306","n":0.577}}},{"i":3866,"$":{"0":{"v":"Apache Age","n":0.707},"1":{"v":"\n- url: https://age.apache.org/\n- fork_of: [[prdct.agensgraph]]\n\n## Goal\n\n- create single storage that can handle both relational and graph model data so that users can use standard ANSI SQL along with openCypher, the Graph query language.","n":0.174}}},{"i":3867,"$":{"0":{"v":"Anzograph DB","n":0.707},"1":{"v":"\n- url: https://cambridgesemantics.com/anzograph/\n- has free commercial version\n- supports: [[prdct.RDF-star]] [[prdct.sparql]] [[prdct.odata]]","n":0.302}}},{"i":3868,"$":{"0":{"v":"Mulesoft Anypoint","n":0.707},"1":{"v":"\n## Issues\n\n- [[prdct.anypoint.api-designer]] and Flow Designer do not support AsyncAPI. If you open an AsyncAPI specification or asset in one of these tools, an error message is displayed.\n\n## Referencs\n\n- https://docs.mulesoft.com/release-notes/platform/event-driven-api","n":0.183}}},{"i":3869,"$":{"0":{"v":"Exchange","n":1}}},{"i":3870,"$":{"0":{"v":"API Designer","n":0.707},"1":{"v":"\n- url: https://www.mulesoft.com/platform/api/anypoint-designer","n":0.577}}},{"i":3871,"$":{"0":{"v":"Any23","n":1},"1":{"v":"\n- retired\n- https://any23.apache.org/","n":0.577}}},{"i":3872,"$":{"0":{"v":"Any Json","n":0.707}}},{"i":3873,"$":{"0":{"v":"Annyang","n":1},"1":{"v":"\n[[t.cs.speech-recognition]]\n\n- url: https://github.com/TalAter/annyang\n","n":0.577}}},{"i":3874,"$":{"0":{"v":"Anime.js","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n- url: https://animejs.com/\n- ","n":0.5}}},{"i":3875,"$":{"0":{"v":"Animator.js","n":1},"1":{"v":"\n- [[c.software.web.animation-library]]\n- url: https://gao-sun.github.io/animatorjs/","n":0.5}}},{"i":3876,"$":{"0":{"v":"Animate.css","n":1},"1":{"v":"\n- url: https://animate.style/","n":0.577}}},{"i":3877,"$":{"0":{"v":"Angular","n":1},"1":{"v":"\nurl: https://angular.io/\n- [[p.builtOn]] [[prdct.reactivex]]","n":0.5}}},{"i":3878,"$":{"0":{"v":"Anglo American Cataloguing Rules (AACR2)","n":0.447}}},{"i":3879,"$":{"0":{"v":"Angel List Stack","n":0.577},"1":{"v":"\n- [[c.service.startup-formation]]\n- url: https://www.angellist.com/startups\n- [[c.list.features]] https://www.angellist.com/startups/pricing#pricing-plans\n  - [[c.mention]] [[prdct.carta]]","n":0.333}}},{"i":3880,"$":{"0":{"v":"Abstract Meaning Representation","n":0.577},"1":{"v":"\n- url: https://amr.isi.edu https://catalog.ldc.upenn.edu/LDC2020T02\n- [[p.hasSpecification]] https://github.com/amrisi/amr-guidelines/blob/master/amr.md\n\n\n## Cons\n\n* It does not represent quantifier scope, or even universal quantification at all.\n* It does not represent co-references that cross sentence boundaries.\n* It drops grammatical number, tense, aspect, quotation marks, etc.\n* It does not deeply capture many noun-noun or noun-adjective relations.\n* It does not include deep frames such as Earthquake (with roles for magnitude, epicenter, casualties, etc) or Pregnancy (with roles for mother, father, baby gender, time since inception, etc). AMR 1.2 looks forward to AMR 2.0!\n\n## Examples\n\n- \"About 14,000 people fled their homes at the weekend after a local tsunami warning was issued, the UN said on its Web site\"\n```\n(s / say-01\n  :ARG0 (g / organization\n          :name (n / name\n                  :op1 \"UN\"))\n  :ARG1 (f / flee-01\n          :ARG0 (p / person\n                  :quant (a / about\n                           :op1 14000))\n          :ARG1 (h / home\n                  :poss p)\n          :time (w / weekend)\n          :time (a2 / after\n                  :op1 (w2 / warn-01\n                         :ARG1 (t / tsunami)\n                         :location (l / local))))\n  :medium (s2 / site\n            :poss g\n            :mod (w3 / web)))\n```","n":0.077}}},{"i":3881,"$":{"0":{"v":"AML","n":1},"1":{"v":"\n## Features\n\n- \"AML enables you to formally describe different kinds of models, whether syntactic models—specific to languages or specifications-or semantic models specific to industries and domains.\"\n- \"a.ml: Anything Modeling Language... which targets mapping of YAML schemas to ontologies and SHACL shapes, and YAML documents to RDF graphs.\" \n  - https://platform.ontotext.com/3.4/soml/intro.html\n\n## Terms\n\nDialect\n: defines a set of constraints over a RDF data-model composed by a graph of nodes connected by properties. All node types and properties have associated terms that must have been defined in a AML Vocabulary. Additionally, the AML Dialect also defines a mapping of this nodes over a set of modular documents (including partial definitions encoded in fragments and libraries of reusable components), that encode a mapping function capable of transforming document instances of the dialect encoded in YAML or JSON documents into RDF graphs encoded in JSON-LD documents.\n\nVocabulary\n: a mechanism to describe any domain of discourse using familiar YAML syntax and modular documents.\n\n## Resources\n\n- https://github.com/aml-org/als/blob/develop/readme.md \n  - \"You can adapt the Microsoft VSCode LSP example by following these instructions, which guides you to successfully run an ALS client in VSCode.\"","n":0.074}}},{"i":3882,"$":{"0":{"v":"Amine","n":1},"1":{"v":"\n![](/assets/images/2024-01-31-11-35-52.png)","n":1}}},{"i":3883,"$":{"0":{"v":"AMF","n":1},"1":{"v":"\n## Features\n\nAMF natively supports the following formats:\n\n-   YAML\n-   JSON\n\nthe following semantic models:\n\n-   WebApi (or \"Web APIs\" as in \"APIs accessible over the network\")\n-   AsyncApi\n\nand the following syntactic models:\n\n-   JSON-LD \"AMF model\"\n-   RAML 0.8 / 1.0 (mapped to \"WebApi\")\n-   OpenAPI (OAS) 2.0 / 3.0 (mapped to \"WebApi\")\n-   AsyncAPI 2.0 (mapped to \"AsyncApi\")\n\nCode samples are in scala, java, and typescript   \n\n\n## Description\n\n### nordic apis\n\nThe AML Modeling Framework (AMF) is an open-source library that serves as a powerful tool for working with AsyncAPI and other API specifications. AMF is capable of parsing, transforming, validating, and rendering arbitrary models, making it an invaluable asset for developers working with AsyncAPI.\n\nOne of the key components of AMF is the API Contract Model, which contains all the information expressed in the source API document. This model can be used for validations, transformations, and conversions, making it highly versatile and adaptable to different use cases.\nWhat sets AMF apart is its support for custom models and parsers, which can be defined using the AML (API Modeling Language) language. This allows developers to create their own models and parsers tailored to their specific needs and requirements.\n\nTo illustrate the power of AMF, let’s consider an example where an OpenAPI Specification (OAS) 3.0 API document needs to be parsed, validated, transformed, and rendered in RAML 1.0. With AMF, this can be achieved seamlessly, simplifying the process and saving valuable development time.\n\nIf you want to learn more about the AML Modeling Framework and its capabilities, various resources are available, including the official documentation, tutorials, and code examples. These resources can provide a deeper understanding of AMF and help you unlock its full potential for working with AsyncAPI and other API specifications.\n\n## References\n\n- https://nordicapis.com/6-asyncapi-validation-tools/","n":0.06}}},{"i":3884,"$":{"0":{"v":"Amethyst","n":1},"1":{"v":"\n- #dead see https://amethyst.rs/posts/amethyst--starting-fresh\n- [[c.software.game-engine]]\n- url: https://amethyst.rs/\n- repo: \n- [[p.builtOn]] [[prdct.specs]]\n\n\n## [[p.vs]]\n\n- https://www.reddit.com/r/rust/comments/k8kv3z/amethyst_or_bevy/","n":0.277}}},{"i":3885,"$":{"0":{"v":"Ambient","n":1},"1":{"v":"\n\n- [[c.software.game-engine]] [[c.software.entity-component-system]]\n- repo: https://github.com/AmbientRun/Ambient\n- written-in: #rust\n\n## Features\n\n- **Ambient Proxy**: An important part of building multiplayer projects is being able to share them with other people. Traditionally, this involves port forwarding, NAT punchthrough, running a dedicated server, and other complicated networking trickery. Ambient provides a solution to this problem: the Ambient Proxy.\n- Entities contain components, which are typed pieces of data, and these are acted upon with systems ^1nl6ma5m12zt\n\n\n## Cons\n\n- Networked components are automatically synchronized to all clients, ensuring a consistent experience across all players; instead of grappling with complex networking intricacies, developers can focus on building their server and client-side logic. ^zumxj8d7vwkb\n\n![[ECS|t.cs.entity-component-system#^h56imtf2ip3n]]","n":0.099}}},{"i":3886,"$":{"0":{"v":"Amber","n":1},"1":{"v":"\n- [[p.coreferences]] [[t.cs.languages.smalltalk.amber]]","n":0.577}}},{"i":3887,"$":{"0":{"v":"Ambassador Telepresence","n":0.707},"1":{"v":"\n- url: https://www.getambassador.io/products/telepresence","n":0.577}}},{"i":3888,"$":{"0":{"v":"Alteryx","n":1}}},{"i":3889,"$":{"0":{"v":"Alpine_js","n":1},"1":{"v":"\n## References\n\n- https://news.ycombinator.com/item?id=29319298","n":0.577}}},{"i":3890,"$":{"0":{"v":"Alpine AJAX","n":0.707}}},{"i":3891,"$":{"0":{"v":"Alloydb","n":1}}},{"i":3892,"$":{"0":{"v":"Alloy Specification Language","n":0.577},"1":{"v":"\n- https://alloytools.org/\n- [[c.Software.Tools.Modeling]]\n- repo: https://github.com/AlloyTools/org.alloytools.alloy\n\n## Resources\n\n- https://haslab.github.io/formal-software-design/\n\n## References\n\n- [[ar.the-temporal-logic-of-actions]]","n":0.333}}},{"i":3893,"$":{"0":{"v":"Allegrograph","n":1},"1":{"v":"\n- published_by: [[org.franz-inc]]\n- [[c.software.database.graph.rdf]] [[c.software.database.Multi-Model]] [[c.software.database.Vector]]\n- \n## References\n\n- https://franz.com/agraph/support/documentation/current/temporal-tutorial.html#Temporal-Queries\n- https://franz.com/agraph/support/documentation/current/magic-properties.html#sparql-magic-temporal\n","n":0.316}}},{"i":3894,"$":{"0":{"v":"Rdfs++","n":1},"1":{"v":"\n- https://franz.com/agraph/allegrograph/dynamic-materialization.lhtml\n- https://franz.com/agraph/support/learning/Overview-of-RDFS++.lhtml","n":0.577}}},{"i":3895,"$":{"0":{"v":"Alien RPG","n":0.707},"1":{"v":"\n## Game System\n\n[[game-system.year-zero-engine-yze]] has been customized to reflect the themes of the Alien universe, focusing on survival horror, stress mechanics, and cinematic play. Players roll pools of dice based on character attributes and skills, with successes determined by rolling sixes. The stress mechanic adds a unique twist, as accumulating stress gives you more dice to roll but also increases the chance of panic during high-pressure situations. This combination of mechanics helps recreate the tense atmosphere of the Alien franchise. (chatgpt)\n","n":0.112}}},{"i":3896,"$":{"0":{"v":"Alchemy Rpg","n":0.707},"1":{"v":"\n- https://alchemyrpg.com/\n- [[c.software.rpg.virtual-tabletop]]\n\n## Focus\n\n- Whereas most others provide a map and grid as your starting point, we focus on cinematic elements, like music and environmental backgrounds, motion overlays, and more. We still have the map and grid, but we don’t think that’s the only thing players want to look at for hours during a session.","n":0.135}}},{"i":3897,"$":{"0":{"v":"Alcaeus","n":1},"1":{"v":"\n- https://github.com/hypermedia-app/Alcaeus\n- prononciation: AL-SEE-UHS\n\n## Features\n\n- configured using an RDF/JS Environment factory. This decouples the library from any specific RDF/JS implementation. It is recommended to use the implementation provided by @zazuko/env which allows to easily reuse extend existing environments.","n":0.162}}},{"i":3898,"$":{"0":{"v":"Akka","n":1},"1":{"v":"\n- url: https://akka.io/\n- [[p.supports]] \n  - java scala directly\n- #related [[prdct.pekko]]\n\n## Features\n\n- Akka Persistence is based upon event-sourcing, which means that the PersistentActor emits events that represent state changes to be applied. Snapshots may be used as an optimization to shorten recovery time.\n  - https://github.com/akka/akka-meta/blob/master/ComparisonWithOrleans.md\n  \n## Comparison\n\n- https://github.com/akka/akka-meta/blob/master/ComparisonWithOrleans.md\n","n":0.144}}},{"i":3899,"$":{"0":{"v":"JS","n":1},"1":{"v":"\n- #dead\n- repo: https://github.com/akka-js/akka.js","n":0.5}}},{"i":3900,"$":{"0":{"v":"Akka Net","n":0.707},"1":{"v":"\n- url: https://getakka.net/","n":0.577}}},{"i":3901,"$":{"0":{"v":"Airwatch","n":1},"1":{"v":"\n\n\n- [[p.renamedTo]] [[prdct.workspaceone]]\n","n":0.577}}},{"i":3902,"$":{"0":{"v":"Aiml","n":1}}},{"i":3903,"$":{"0":{"v":"Ai Comic Maker","n":0.577},"1":{"v":"\n- https://app.aiprm.com/gpts/g-1LM0T9LSW/ai-comic-maker\n\n## Issues\n\n- probably just chatgpt issues, but unsatisfying images and characters look different between frames.","n":0.25}}},{"i":3904,"$":{"0":{"v":"Agora Server","n":0.707},"1":{"v":"\n\n\n- [[supportsFormats]] [[prdct.unrival-protocol]], [[prdct.foam]]\n\n","n":0.5}}},{"i":3905,"$":{"0":{"v":"Agora Bridge","n":0.707},"1":{"v":"\n- related: [[prdct.Agora]]\n\n- [[p.hasRepository]] https://github.com/flancian/agora-bridge\n","n":0.447}}},{"i":3906,"$":{"0":{"v":"Agones","n":1},"1":{"v":"\n- url: https://agones.dev/site/\n- repo:\n- description: Agones replaces bespoke or proprietary cluster management and game server scaling solutions with an open source solution that can be utilised and communally developed - so that you can focus on the important aspects of building a multiplayer game, rather than developing the infrastructure to support it.\n- [[p.supports]] [[prdct.unreal]] [[prdct.unity]] #c++ c# [[prdct.node]]  #go #rust [[t.cs.sd.rest]]","n":0.128}}},{"i":3907,"$":{"0":{"v":"Agentspeak","n":1},"1":{"v":"\n## References\n\n- [AgentSpeak(L): BDI agents speak out in a logical computable language](http://goanna.cs.rmit.edu.au/~ssardina/courses/Roma07PhDcourse/lect07/rao96agentspeakl.pdf))","n":0.289}}},{"i":3908,"$":{"0":{"v":"Agentscript","n":1},"1":{"v":"\n- [[p.inspiredBy]] [[prdct.netlogo]]\n- [[p.hasRelatedTopic]] [[t.cs.actors]]","n":0.447}}},{"i":3909,"$":{"0":{"v":"Agentscope","n":1},"1":{"v":"\n- repo: https://github.com/modelscope/agentscope\n- docs: https://modelscope.github.io/agentscope/en/index.html\n- written_in: python\n\n## Examples\n\n- https://github.com/modelscope/agentscope/tree/main/examples/conversation_with_mentions","n":0.333}}},{"i":3910,"$":{"0":{"v":"Agents","n":1},"1":{"v":"\n- repo: https://github.com/aiwaves-cn/agents\n- written_in: python\n\n## Resources\n\n- ","n":0.408}}},{"i":3911,"$":{"0":{"v":"Agents and Artifacts Metamodel","n":0.5},"1":{"v":"\n## References\n\n- [[ar.agents-and-artifacts-a-meta-model-for-agent-oriented-computing]] ","n":0.577}}},{"i":3912,"$":{"0":{"v":"Agent Protocol","n":0.707},"1":{"v":"\n- spec: https://github.com/AI-Engineer-Foundation/agent-protocol/blob/main/schemas/openapi.yml","n":0.577}}},{"i":3913,"$":{"0":{"v":"Agentkit","n":1},"1":{"v":"\n- repo: https://github.com/holmeswww/agentkit\n- written_in: python\n\n## References\n\n- https://www.marktechpost.com/2024/04/19/this-ai-paper-from-cmu-introduces-agentkit-a-machine-learning-framework-for-building-ai-agents-using-natural-language/","n":0.378}}},{"i":3914,"$":{"0":{"v":"Agent","n":1},"1":{"v":"\n- url: https://www.tshu.io/AGENT//\n\n\n## Abstract\n\nFor machine agents to successfully interact with humans in real-world settings, they will need to develop an understanding of human mental life. Intuitive psychology, the ability to reason about hidden mental variables that drive observable actions, comes naturally to people: even pre-verbal infants can tell agents from objects, expecting agents to act efficiently to achieve goals given constraints. Despite recent interest in machine agents that reason about other agents, it is not clear if such agents learn or hold the core psychology principles that drive human reasoning. Inspired by cognitive development studies on intuitive psychology, we present a benchmark consisting of a large dataset of procedurally generated 3D animations, AGENT (Action, Goal, Efficiency, coNstraint, uTility), structured around four scenarios (goal preferences, action efficiency, unobserved constraints, and cost-reward trade-offs) that probe key concepts of core intuitive psychology. We validate AGENT with human-ratings, propose an evaluation protocol emphasizing generalization, and compare two strong baselines built on Bayesian inverse planning and a Theory of Mind neural network. Our results suggest that to pass the designed tests of core intuitive psychology at human levels, a model must acquire or have built-in representations of how agents plan, combining utility computations and core knowledge of objects and physics.","n":0.07}}},{"i":3915,"$":{"0":{"v":"AgensGraph","n":1}}},{"i":3916,"$":{"0":{"v":"Age","n":1},"1":{"v":"\n- repo: https://github.com/apache/age\n- supports: [[prdct.opencypher]]","n":0.447}}},{"i":3917,"$":{"0":{"v":"Afsim","n":1},"1":{"v":"\n- url: https://www.infoscitex.com/afsim/\n- supposedly open-source","n":0.447}}},{"i":3918,"$":{"0":{"v":"Aedes","n":1},"1":{"v":"\n- https://github.com/moscajs/aedes","n":0.707}}},{"i":3919,"$":{"0":{"v":"Adventuron","n":1},"1":{"v":"\n- [[p.instanceOf]] [[c.software.game-framework.interactivefiction]]\n- [[p.hasURL]] https://adventuron.io/\n- ","n":0.447}}},{"i":3920,"$":{"0":{"v":"Adventure Forge","n":0.707},"1":{"v":"\n## Philosophy\n\n- Adventure Forge opens up game development to everyone, regardless of their technical expertise, with only imagination required, empowering a new generation of “Gamesmiths” thanks to its powerful and accessible tools. \n\n## Cons\n\n- Single player","n":0.167}}},{"i":3921,"$":{"0":{"v":"Adobe Sensei","n":0.707}}},{"i":3922,"$":{"0":{"v":"Adobe Audience Manager","n":0.577},"1":{"v":"\n\n- [[p.succeededBy]] [[prdct.adobe-sensei]]\n\n\n","n":0.577}}},{"i":3923,"$":{"0":{"v":"ActressMas","n":1},"1":{"v":"\n- dead since 2022\n- [[c.software.agent-framework]] #dead\n- repo: https://github.com/florinleon/ActressMas\n- written-in: [[t.cs.languages.c-sharp]]","n":0.316}}},{"i":3924,"$":{"0":{"v":"Actr","n":1},"1":{"v":"\n- [[c.software.actor-framework]]\n- repo: https://github.com/zakgof/actr\n- creator: @alexander-zakusylo\n- written-in: java\n- supports: [[t.cs.languages.java.virtual-threads]]\n\n## Features\n\n- Virtual Threads are supported\n\n## References\n\n- https://medium.com/@zakgof/a-simple-benchmark-for-jdk-project-looms-virtual-threads-4f43ef8aeb1\n- https://medium.com/@zakgof/type-safe-actor-model-for-java-7133857a9f72","n":0.236}}},{"i":3925,"$":{"0":{"v":"Activitystreams","n":1},"1":{"v":"\n- https://www.w3.org/TR/activitystreams-core/\n\n## References\n\n- https://github.com/w3c/activitystreams/blob/main/vocabulary/activitystreams2.owl","n":0.5}}},{"i":3926,"$":{"0":{"v":"Activitypub","n":1}}},{"i":3927,"$":{"0":{"v":"Activiti","n":1},"1":{"v":"\n- https://www.activiti.org/\n- repo: https://github.com/Activiti/Activiti\n- written-in: java\n- [[c.Software.Workflow]] [[c.software.business-process-management]]","n":0.354}}},{"i":3928,"$":{"0":{"v":"Actionhero","n":1},"1":{"v":"\n- [[c.software.web.api-framework]]\n- [[p.hasSite]] https://www.actionherojs.com\n- [[p.hasPro]]\n  - \"Actionhero includes a robust testing framework that works with Jest for testing JS and TS projects. \"\n  - allows you to build or add many types of servers into one application. Not only can you support HTTP and Web Socket, but you can add custom protocols like Quick and Protobuf to your application and easily reuse your Actions!\n  - includes a REPL \n  - \"not inherently 'RESTful' (which is meaningless for persistent socket connections) but can be extended to be so if you wish.\"\n- resources: \n  - [Why Typescript?](https://www.actionherojs.com/tutorials/typescript)\n  - [Key Concepts](https://www.actionherojs.com/key-concepts)\n\n","n":0.101}}},{"i":3929,"$":{"0":{"v":"Ace","n":1},"1":{"v":"\n- http://attempto.ifi.uzh.ch/site/\n- [[c.grammar.controlled]]\n- ","n":0.577}}},{"i":3930,"$":{"0":{"v":"ACE Parsing Engine","n":0.577},"1":{"v":"\n- http://attempto.ifi.uzh.ch/site/","n":0.707}}},{"i":3931,"$":{"0":{"v":"Acceleo","n":1}}},{"i":3932,"$":{"0":{"v":"Abovevtt","n":1},"1":{"v":"\n- ","n":1}}},{"i":3933,"$":{"0":{"v":"Ably","n":1},"1":{"v":"\n- [[c.Software.real_time_framework]]\n- url: https://ably.com\n![[prdct.pubnub#^mbnq0t6yrz45]]\n\n## Comparison\n\n### vs Stream\n\n## Resources\n\n- https://ably.com/blog/ably-aws-web-components\n- https://quest.ably.dev/\n\n## References\n\n[^1]: https://ably.com/compare/getstream-vs-ably","n":0.289}}},{"i":3934,"$":{"0":{"v":"Spaces","n":1},"1":{"v":"\n## Features\n\n- avatar stack\n- live cursors\n- member location (UI component) \"which page, cell, slide or block they're viewing.\"\n- component locking","n":0.224}}},{"i":3935,"$":{"0":{"v":"Live Sync","n":0.707}}},{"i":3936,"$":{"0":{"v":"Abce","n":1},"1":{"v":"\n\n- #dead\n- repo: https://github.com/AB-CE/abce\n- ","n":0.5}}},{"i":3937,"$":{"0":{"v":"Abc Ontology","n":0.707},"1":{"v":"\n- https://dcpapers.dublincore.org/article/952106556\n  - https://dcpapers.dublincore.org/files/articles/952106556/dcmi-952106556.pdf has an appendix with the ontology represented in RDF\n\n![](/assets/images/2024-08-19-11-30-47.png)\n\n## Issues\n\n- tries to describe everything using the same basic structures and had its roots in factual events outside the document. [^1]\n\n## Model\n\n- entity\n  - temporality\n  - actuality\n  - abstraction\n\n### Temporality\n\n- the ABC model makes it possible to unambiguously express states in which object properties exist, the transitions that demark those states, and the actions and agency that participate in those transitions.\n- A state provides the context for framing time- dependent properties of entities. Every ABC description has an implicit global context and can have additional states that are local contexts. Effectively, entities and their property sets that are not associated with a state (through an instate property) exist across time in the world view of the description.\n- An event marks a transition from one state to another. Events always have time properties. The effect is that a state implicitly has time duration as defined by its bounding events\n  - e.g.: the model could express the loan of the Mona Lisa to the Metropolitan Museum as follows: a instance of the Mona Lisa with a property “located at the Metropolitan” could be associated with a state that is that associated via hasInput and hasOut properties with two events, one of which gives the time of the loan, the other the time of the return\n- An action denotes a verb in the context of event– the hasAction property connects an action to an event. Actions provide the locus for Agents and express the responsibility of a person or organization in some act.\n\n### Actuality\n\n- encompasses entities that are sensible – they can be heard, seen, smelled, or touched. \n- entities that are Actualities, can have a time-independent facet and many time-dependent facets. ABC expresses this notion through the inState and hasInstance properties.\n  - e.g.: Bill Clinton might have one entity (resource) with the property “born in Arkansas” that is related via the hasInstance property to an entity (resource) with property “President of the United States”\n    - The latter would be related via the inState property to a State that resulted from an Event representing Clinton’s election in 1992.\n    - The result is a statement that expresses the “sameness” of the two entities (they are both “Bill Clinton”), but the fact that one is an occurrent facet and one is a continuant facet.\n- ABC model also incorporates intellectual creation semantics influenced by the [[prdct.ifla-functional-requirements-for-bibliographic-records]]\n  - subcategory of actuality is Artifact, expresses sensible entities that are tangible realizations of preconceived concepts, and that can be manifested in multiple ways; e.g., as Manifestations and Items ([[t.library-science.work_expression_manifestation_item]])\n\n### Abstraction\n\n- concepts or ideas\n  - never stateful\n  - While it can be argued that an idea is “born” at some time, ABC treats the “birth of an idea” when it is manifested in some sensible way; e.g., when it is told, demonstrated, or shown in some manner.\n  - ideas cannot exist in isolation in the model. They must be bound to some Actuality through the hasRealization property.\n    - t.2024.05.31.10 since psychological modeling is important for [[sh.compnts.cognitive-engine]]\n\n## Foundations\n\n- [[t.phil.time.situational-calculus]]\n\n## References\n\n[^1]: [[ar.onto-media-creating-an-ontology-for-marking-up-the-contents-of-fiction-and-other-media]]","n":0.044}}},{"i":3938,"$":{"0":{"v":"A-Frame","n":1},"1":{"v":"\n\n- [[p.builtOn]] [[prdct.three-js]]\n- [[p.hasExample]] \n  - https://aframe.io/showcase/","n":0.378}}},{"i":3939,"$":{"0":{"v":"XMPP","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://xmpp.org/\n\n## Features\n\n- a node is a particular \"channel\" or \"feed\" hosted at a publish-subscribe service, where the nature of the channel or feed is defined in part by the characteristic payload published at the node (e.g., Atom notifications) and in part by the focus or topic of such payloads\n\n\n## Comparable\n\n### Comparison\n\n- https://www.rst.software/blog/xmpp-vs-matrix-vs-mqtt-which-instant-messaging-protocol-is-best-for-your-chat-application\n\n### [[prdct.matrix]]\n\n- What is the difference between Matrix and XMPP?\n\nWe think of Matrix and XMPP as being quite different; at its core Matrix can be thought of as an eventually consistent global JSON database with an HTTP API and pubsub semantics - whilst XMPP can be thought of as a message passing protocol. You can use them both to build chat systems; you can use them both to build pubsub systems; each comes with different tradeoffs. Matrix has a deliberately extensive 'kitchen sink' baseline of functionality; XMPP has a deliberately minimal baseline set of functionality. If XMPP does what you need it to do, then we're genuinely happy for you! Meanwhile, rather than competing, an XMPP Bridge like Skaverat's xmpptrix beta or jfred's matrix-xmpp-bridge or Matrix.org's own purple-matrix has potential to let both environments coexist and make the most of each other's benefits.\n\nThe whole area of XMPP vs Matrix is quite subjective. Rather than fighting over which open interoperable communication standard works the best, we should just collaborate and bridge everything together. The more federation and interoperability the better.\n  - https://matrix.org/faq/\n  \n### [[prdct.websocket]]\n\n- https://www.wallarm.com/what/xmpp-vs-websocket-which-to-use-for-applications\n  - ","n":0.065}}},{"i":3940,"$":{"0":{"v":"XML","n":1}}},{"i":3941,"$":{"0":{"v":"X3D","n":1},"1":{"v":"\n\n\n- [[p.hasSolution]] [[prdct.x3d-Edit]]\n","n":0.577}}},{"i":3942,"$":{"0":{"v":"X3D-Edit","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.web3d.org/x3d/content/README.X3D-Edit.html\n- [[p.compatibleWith]] [[prdct.x3d]]\n","n":0.447}}},{"i":3943,"$":{"0":{"v":"WorldAnvil","n":1},"1":{"v":"\n- [[c.software.rpg]] [[c.software.rpg.campaign-manager]] [[c.software.rpg.map-maker]] \n- [[p.hasURL]] https://www.worldanvil.com/\n- [[p.hasApplication]] [[t.roleplaying.world-building]]\n- [[p.hasCapability]] world-item management\n  - Buildings\n  - Characters\n  - Conditions\n  - Wars & Conflicts\n  - Countries\n  - Important Documents\n  - Ethnicities\n  - Geographic Locations\n  - Items\n  - Languages\n  - Materials\n  - Myths & Legends\n  - Natural & Supernatural Laws\n  - Religions\n  - Timelines (https://www.worldanvil.com/features/timelines)\n  - Towns & Cities\n  - Spells\n  - Science & Technology\n  - Vehicles\n  \n\n## Issues\n\n- integration with [[prdct.Foundry-VTT]] is simple import. \n\n## Resources\n\n- https://www.worldanvil.com/learn/workflows/gm-workflow\n\n## References\n\n- https://www.reddit.com/r/FoundryVTT/comments/p391jj/how_useful_is_world_anvil_with_foundry/\n","n":0.114}}},{"i":3944,"$":{"0":{"v":"api","n":1}}},{"i":3945,"$":{"0":{"v":"Boromir API","n":0.707},"1":{"v":"\n- https://www.worldanvil.com/api/external/boromir/swagger-documentation\n\n","n":0.707}}},{"i":3946,"$":{"0":{"v":"welcome-email","n":1},"1":{"v":"\n\nHey djradon!\n\nHow’s your world coming along?\n\nNow you’re set up with the basics, take your next steps in world creation.\n\nLuckily, we’ve prepared a toolkit with everything you need to create, share and monetize rich, immersive worlds for gaming or fiction, in one secure place.\n\n(You might want to save this email, in case you need to come back to it later.)\nCreate an immersive, interactive world.\n\n📃 [Articles](https://www.youtube.com/watch?v=dKEXqz5kd1A&list=PLmurZz9emqGn53_DnqfI6GQrmfl-6LT0u&index=3) in World Anvil are the building blocks of your world. Start with one of 25+ templates designed to inspire you with prompts that give depth to your lore. They make writing articles for important people, places, and things in your world easy!\n\n➡️ Pro tip: Start with elements from your [Worldbuilding Meta](https://blog.worldanvil.com/worldanvil/tutorials/how-to-start-worldbuilding-with-the-worldbuilding-meta/) - especially the Scene, People, and Drama sections!\n\n🗺️ [Maps](https://blog.worldanvil.com/worldanvil/tutorials/how-to-create-your-world-by-setting-up-your-map/) in World Anvil can be linked to worldbuilding Articles, or other Maps. You can drill down from your world map all the way to the dungeon your party is crawling. Your players or readers can explore your world like never before!\n\n➡️ Pro tip: Did you know you can create your own custom markers on maps?\n\n⏳ [Timelines](https://blog.worldanvil.com/worldanvil/tutorials/how-to-start-worldbuilding-history-with-timelines/) help you keep your story straight (or circular, if your players or characters create a time loop paradox…) Track party or character history separately from the larger world and display your lore chronologically.\n\n➡️ Pro tip: Timelines are great to start, but Chronicles are what you need to make the biggest impact to your players and readers!\nKeeps you organized, motivated, and inspired.\n\n🗂️ [Categories](https://blog.worldanvil.com/worldanvil/tutorials/how-to-organize-worldbuilding-with-categories-getting-started-with-world-anvil/) form your world’s table of contents, and organize your world! Think of them like folders that sort and store your Articles.\n\n➡️ Pro tip: Keep each category under 20 articles. It will make finding what you need much faster and will allow you to quickly order everything inside them\n\nWith friendly monthly Challenges, weekly Streams featuring expert advice, and hundreds of worldbuilding Prompts, you’ll never run out of ideas again.\nShare it with others, but keep your secrets safe.\n\n🕮 Manuscripts, 👨‍💻 Subscribers and 🤫 Secrets are tools for pro novelists and GMs. They allow you to share work with your readers or players - but ONLY the parts you want them to see, and WHEN you want them to see.\n\n➡️ Pro tip: Guild member tools like these are available when you’re ready to take your world to the next level.\n🤯 Overwhelmed? We’ve got you.\n\nWorld Anvil is BIG… because World Anvil is a complete toolkit! But you don’t have to use every tool. Start with only what you need.\n\nGo to Features to enable (or disable) tools.\n\nReady to get organized? Grab your hammer, and go worldbuild!\n\n    Janet and the World Anvil Community Team ♥🌍\n\nP.S. Need help? Reply to this email with your questions!\n\nThese onboarding emails are here to help you get to know World Anvil and make sure you learn all the important tips and tricks that will make your life and projects easier and better. We will only be sending you five of them and no more. If you still want to stop receiving these emails click here.\n\nIf you'd like to unsubscribe and stop receiving these emails click here .\n","n":0.044}}},{"i":3947,"$":{"0":{"v":"WikiLens","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://marketplace.visualstudio.com/items?itemName=lostintangent.wikilens\n","n":0.577}}},{"i":3948,"$":{"0":{"v":"Webroot","n":1},"1":{"v":"\nmore than just antivirus\n","n":0.5}}},{"i":3949,"$":{"0":{"v":"Visual OMT","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://pitchtechnologies.com/visual-omt/\n","n":0.577}}},{"i":3950,"$":{"0":{"v":"VideOWL Ontology","n":0.707},"1":{"v":"\n- [[c.ontology.fictional]]\n- repo: https://github.com/Stefano-Angelo-Rizzo/VideOWL\n\n## Thoughts\n\n- computer agents aren't fictional, but I'm starting to think that fictional characters aren't fictional.\n\n## References \n\n- https://ceur-ws.org/Vol-3579/paper15.pdf","n":0.213}}},{"i":3951,"$":{"0":{"v":"Vercel","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[prdct.netlify]]\n- ![[prdct.netlify#^uUZD1OtrpGRW]]\n- free hobby plan\n- [[p.hasFeature]] \n  - [[t.cs.serverless]]\n    - [[p.hasClientSupport]] javascript #go #python [[t.cs.languages.Ruby]]\n  - [[t.cs.web.ssr]]\n  - Fetch API\n    - SWR (stale-while-revalidate)\n      - resources:  https://javascript.plainenglish.io/stop-using-fetch-api-directly-swr-is-way-better-588976ef6782\n","n":0.189}}},{"i":3952,"$":{"0":{"v":"Unity","n":1},"1":{"v":"\n\n[[c.software.game-engine]]\n\n- [[p.hasScriptingLanguage]] javascript\n  - [ ] [[prdct.jint]] https://pleasenophp.github.io/posts/using-real-javascript-with-unity.html\n\n\n## Features\n\n- [script composition](https://gamedevbeginner.com/how-to-use-script-composition-in-unity/) ^2tiad033817r\n\n## Resources\n\n- https://gamedevbeginner.com/how-to-spawn-an-object-in-unity-using-instantiate/#instantiate_empty_object\n- https://medium.com/@RunningMattress/10-things-my-10-years-of-using-unity-have-taught-me-about-structuring-a-new-project-b45481b900fd\n- https://www.sebaslab.com/ioc-container-unity-part-1/\n- https://forum.unity.com/threads/does-unity-support-code-only-context-from-net-no-editor-involvement.1228872/","n":0.243}}},{"i":3953,"$":{"0":{"v":"Umod","n":1},"1":{"v":"\n- url: https://assetstore.unity.com/packages/tools/integration/umod-2-0-58293\n- #decription use the intuitive user interface of the Unity Editor to create their content and then export to mod format in a single click.\n","n":0.192}}},{"i":3954,"$":{"0":{"v":"uLua","n":1},"1":{"v":"\n- [[c.software.game-framework]]\n- repo: https://github.com/antUnity/uLua-docs","n":0.5}}},{"i":3955,"$":{"0":{"v":"Quantum Console","n":0.707},"1":{"v":"\n- url: https://assetstore.unity.com/packages/tools/utilities/quantum-console-211046\n- ","n":0.577}}},{"i":3956,"$":{"0":{"v":"Ml Agent","n":0.707},"1":{"v":"\n- repo: https://github.com/Unity-Technologies/ml-agents\n- url: https://unity.com/products/machine-learning-agents","n":0.447}}},{"i":3957,"$":{"0":{"v":"Lua Modding Framework","n":0.577},"1":{"v":"\n- url: https://assetstore.unity.com/packages/tools/utilities/lua-modding-framework-226043\n- \"wraps around [[prdct.moonsharp]]\"","n":0.408}}},{"i":3958,"$":{"0":{"v":"Dots","n":1},"1":{"v":"\n- url: https://unity.com/dots\n\n\n## Learning Resource\n\n- https://dots-tutorial.moetsi.com/dots-netcode/intro-to-dots-netcode","n":0.408}}},{"i":3959,"$":{"0":{"v":"Barracuda","n":1},"1":{"v":"\n## Use Cases\n\n- [[prdct.unity.ml-agent]]\n-   [MobileNet v1/v2](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md) image classifiers\n-   [Tiny YOLO v2](https://pjreddie.com/darknet/yolov2/) object detector\n-   U-Net models\n-   Fully convolutional models\n-   Fully dense models\n-   [Spade](https://nvlabs.github.io/SPADE/) architecture (https://nvlabs.github.io/SPADE/)","n":0.204}}},{"i":3960,"$":{"0":{"v":"Twisted","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://twistedmatrix.com/trac/\n","n":0.577}}},{"i":3961,"$":{"0":{"v":"TerminusDB","n":1},"1":{"v":"\n- repo: https://github.com/terminusdb/terminusdb\n- written_in: prolog\n- [[p.builtWith]] [[prdct.rdf]] but evolved into a document graph db\n- [[p.similarTo]]\n  - [[prdct.typedb]] but more triple/semantic-webby\n  - [[prdct.fluree]] \n- related: [[prdct.dfrnt]]\n- supports: [[prdct.graphql]] [[prdct.woql]]\n- client_support: \n  - javascript: TerminusDB JavaScript client library can be used either as a Node.js package or as a script that runs in the browser.\n  - python\n\n## Features\n\n-   The [db schema](https://terminusdb.com/docs/schema) is defined in [[prdct.owl]]\n-   Most operation occurs in-memory, but is persisted in a forward-only log (similar to git)\n-   This “git-for-data” approach allows branch, merge, squash, rollback, diff, blame, and time-travel, etc.\n-   [[prdct.json-ld]] is interchange format, suitable for web, but editing in turtle is possible\n-   You can query any part of a graph and retrieve as a JSON-LD document (serialized to the depth you want)\n-   Query format is also JSON-LD, making queries composable and you can store/query queries like normal data\n-   Client-side the queries are created using fluent JS (for web devs) and/or Ruby (for data scientists)\n-   Provides transaction processing and updates using immutable database data structures\n-   Through this immutability the db regains full ACID support\n-   \"TerminusDB can read RDF files with little difficulty. However, to get the value of TerminusDB you really need a schema. So first stop is really trying to figure out what we might need to massage about the RDF to get it into an easily schemable form.\"\n\n## Issues\n\n- maybe doesn't export JSON-LD but https://github.com/dfrnt-com/tuscli might work\n- WOQL need rework\n  - temporal not fully supported in query\n    - \"TerminusDB has valid time as data in the database, and system or transaction time as a data in a commit graph.\nThe commit graph keeps track of the time at which facts are known, creates a structure called a \"commit\" and connects it to the parent commit.\nThis allows us to do things like present object change histories which are based on the transaction/system time of a change.\nOur query language works on the commit graph (both WOQL and GraphQL) and the database itself so its possible to look at these two time dimensions independently.\nWe also have APIs to expose object history etc. and we hope to include these in our query language so that you can easily ask temporal questions. At the minute the temporal questions usually are somewhat simple that we are able to ask (when did this object change, what was its change history) etc. rather than the complete bitemporal query which is theoretically possible.\"\n\n## Resources\n\n- https://medium.com/terminusdb/6-reasons-why-terminusdb-is-the-right-toolkit-to-build-collaborative-apps-6fb9ae96ff4\n- https://terminusdb.com/blog/loading-data-in-turtle-rdf-format-to-terminusdb/\n- https://forum.solidproject.org/t/terminusdb-a-delightful-database-for-linked-data/3140\n  - mentioned: https://news.ycombinator.com/item?id=22867767\n- https://terminusdb.com/blog/graphql-query/\n- [[ar.terminusdb.the-semantic-web-is-dead]]","n":0.05}}},{"i":3962,"$":{"0":{"v":"TOML","n":1},"1":{"v":"\n\n\n- [[p.hasFeature]]\n  - allows comments\n  - [[p.hasSource]] https://blog.heroku.com/why-buildpacks-use-toml ^fYNGmXNfdcJj\n    - \"designed to be human readable, which is why it favors simple structures.\"\n      - doesn’t rely on significant whitespace with difficult to read indentation\n    - \"easy for machines to read and write\"\n      - can append to a TOML file without reading it first, which makes it a great data interchange format\n\n## Resources \n\n- https://stackoverflow.com/questions/65283208/toml-vs-yaml-vs-strictyaml\n- https://tomaszs2.medium.com/2023-may-be-a-year-of-toml-b3c5f0e37efc","n":0.125}}},{"i":3963,"$":{"0":{"v":"TAGML","n":1},"1":{"v":"\n- [[gd]] isn't a markup language for text, it's a markup language for semantics/meaning\n\n## Highlights\n\n- A well-known example of discontinuity is the tagging of citations or quotes in a text, e.g. `[q>and what is the use of a book,<-q] thought Alice[+q>without pictures or conversation?<q]`","n":0.151}}},{"i":3964,"$":{"0":{"v":"Supabase","n":1},"1":{"v":"\n![[prdct.rxdb#^pnjx84u9yrqy]]\n- description: Supabase labels itself as \"an open source Firebase alternative\". It is a collection of open source tools that together mimic many Firebase features, most of them by providing a wrapper around a PostgreSQL database. While it has realtime queries that run over the wire, like with RethinkDB, Supabase has no client-side storage or replication feature and therefore is not offline first.\n\n- [[p.instanceOf]] [[t.cs.data.DBaaS]]\n- [[p.builtOn]] [[prdct.postgres]]\n- [[p.alternativeTo]] [[prdct.firebase]] \n- [[p.hasSite]] https://supabase.io/\n","n":0.118}}},{"i":3965,"$":{"0":{"v":"Staticman","n":1},"1":{"v":"\n\n\n## [[p.hasLearningResource]]\n  - https://travisdowns.github.io/blog/2020/02/05/now-with-comments.html\n","n":0.5}}},{"i":3966,"$":{"0":{"v":"Slack","n":1}}},{"i":3967,"$":{"0":{"v":"Simulation Core","n":0.707},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] SimCore\n- [[p.hasRepository]] https://github.com/delta3d/SimulationCore\n- [[p.isRelated]] [[prdct.delta3d]]\n","n":0.378}}},{"i":3968,"$":{"0":{"v":"SimPy","n":1},"1":{"v":"\n- [[c.software.simulation-framework.discrete-event]]\n- repo: https://gitlab.com/team-simpy/simpy/\n- written-in: #python\n- [[p.similarTo]] [[prdct.concurrentsim-jl]] \n\n\n## Resources\n\n- https://realpython.com/simpy-simulating-with-python/#when-to-change-things-up","n":0.302}}},{"i":3969,"$":{"0":{"v":"SiebogJS","n":1},"1":{"v":"\n\n\n- [[p.hasRepository]] https://github.com/orgs/SiebogJS\n- [[p.hasApplication]] [[t.cs.multi-agent-system]]\n","n":0.447}}},{"i":3970,"$":{"0":{"v":"Google Sheets","n":0.707}}},{"i":3971,"$":{"0":{"v":"Sentry","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://sentry.io/\n- [[p.hasApplication]] [[t.cs.tracing]]\n","n":0.447}}},{"i":3972,"$":{"0":{"v":"Scribe","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://scribehow.com\n","n":0.577}}},{"i":3973,"$":{"0":{"v":"Sandbox","n":1},"1":{"v":"\n\n\n- [[p.vs]] [[prdct.decentraland]] \n  - resources:  https://medium.datadriveninvestor.com/the-sandbox-vs-decentraland-where-should-you-set-your-bets-3b80785b985b\n\n","n":0.378}}},{"i":3974,"$":{"0":{"v":"Sales Assembly","n":0.707}}},{"i":3975,"$":{"0":{"v":"SPADE","n":1},"1":{"v":"\n- [[c.software.agent-framework]] but \"platform-less\"\n- [[p.hasRepository]] https://github.com/javipalanca/spade\n- [[p.hasSite]] https://spade-mas.readthedocs.io\n- written-in: #python\n- created-by: [[user.javipalanca]]\n- [[p.builtOn]] [[prdct.xmpp]]\n  - there's a matrix-xmpp bridge, and even more abandoned https://matrix.org/docs/projects/bridge/matrix-appservice-prosody\n  - [[prdct.cloudevents]] has an XML spec: https://github.com/cloudevents/spec/blob/main/cloudevents/working-drafts/xml-format.md\n- [[p.isRelated]] [[prdct.spade.pubsub]] [[prdct.spade.bdi]] [[prdct.spade.artifact]]\n\n## Features\n\n- \"you can develop your own agents in the programming language of your choice and use them with SPADE. The only requirement those agents must fulfill is to be able to communicate through the XMPP protocol.\"\n- \"SPADE 3 is not planned to be FIPA compatible\" but \"Supports FIPA metadata using XMPP Data Forms \"\n- \"Currently there is no AMS or DF in SPADE, which are the agents that allow to search for other agents or services in JADE (FIPA, really). This is due to SPADE's platform-less approach, which tries to have a very small and fast core. However, the possibility of creating plugins for SPADE is explained in the documentation, so, if you think this is an interesting feature: just write a plugin! :)\"\n## Comparison\n\n[[vs.spade-vs-pade]]\n\n## Resources\n\n- https://github.com/javipalanca/spade/issues/54#issuecomment-475730896\n  - ","n":0.078}}},{"i":3976,"$":{"0":{"v":"Pubsub","n":1},"1":{"v":"\n- ","n":1}}},{"i":3977,"$":{"0":{"v":"Bdi","n":1}}},{"i":3978,"$":{"0":{"v":"Artifact","n":1},"1":{"v":"\n- #docs https://spade-artifact.readthedocs.io/en/latest/\n","n":0.577}}},{"i":3979,"$":{"0":{"v":"SAM","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://mbakeranalecta.github.io/sam\n- [[p.wasInspirationFor]] [[gd]]\n\n\n## [[p.hasFeature]]\n\n- phrases\n  -  a piece of text within a paragraph that you want to apply metadata to. A phrase is marked up with curly braces. In the recipe example, the words \"Cobb Salad\" are marked up as a phrase: {Cobb Salad}. We mark up phrases so that we can add metadata to them with annotations and citations.\n- fields\n  - a label and a value, e.g. \"sugar: 6g\"\n- annotations\n  - links are a type of annotation\n  - seems to support \"link types\"\n  - a way of adding descriptive labels or metadata to individual phrases within a text. \n    - metadata types\n      - formatting\n      - linking\n      - semantic \n  - consists of type attribute and optional \"specifically\" and \"namespace\" attributes\n    - e.g. `{The Duke}(actor \"John Wayne\" (SAG)) plays an ex-Union Colonel out for revenge.`  \n  - can be chained\n- citations\n  - two forms:\n    - internal names/ids\n    - citations of external resources\n  - for referring to other resources\n  - the treatment of the citation is based on the type of object that the citation references, not the type of the citation \n- record sets \n\n## [[p.hasCon]]\n\n- not designed to be directly human-readable\n","n":0.072}}},{"i":3980,"$":{"0":{"v":"Roam","n":1},"1":{"v":"\n\n- #publisher [[org.roam-research]]\n- [[p.hasURL]] https://roamresearch.com/\n  - \"As easy to use as a document. As powerful as a graph database.\"\n- [[p.hasApplication]] [[t.km.note-taking]] [[t.tm]]\n- [[p.hasClientSupport]] [[t.cs.web.browser]] [[t.cs.os.windows]] [[t.cs.os.mac]] [[t.cs.os.linux]]\n- resources:  [[ar.every.the-fall-of-roam]]\n  - [[p.hasHighlight]] \n    - At least for me—and most of the people I know—we got a garbage dump full of crufty links and pieces of text we hardly ever revisit. And we feel guilty and sad about it.\n    - ","n":0.121}}},{"i":3981,"$":{"0":{"v":"Rhombus Systems","n":0.707},"1":{"v":"\n- [[p.instanceOf]] [[c.company]]\n","n":0.577}}},{"i":3982,"$":{"0":{"v":"RemNote","n":1},"1":{"v":"\n\n#tools-for-thought\n\na note-taking tool that helps your organize and remember what you learn\n\n- [[p.hasApplication]] [[t.km]] \n\n\n## features\n\n- [[prdct.bullet-journaling]]  \n- create flashcards and take notes at the same time.\n\n## concepts\n\n### rem\n- [[p.hadDefinition]] a unit of knowledge in remnote, stated with a bullet point\n- [[p.hasSubClass]] Concept :: A Rem that represents a concept or something in the real world\n- [[p.hasSubClass]] Descriptor :: a piece of information that describes a concept\n- [[p.hasSubClass]] Question :: \n\n\n### [portal](https://www.remnote.com/p/help/document/rML9ANQyE7DW3XqPn)\n\n- [[p.hadDefinition]] view a rem in multiple context\n- [[p.vs]] [[prdct.dendron#references]]\n  - portal is a weird name\n## Issues\n\n- selecting text is hard/impossible\n- copying text leaves out the links (concepts)\n- navigation seems broken\n- browser shortcut alt+d captured\n\n\n","n":0.097}}},{"i":3983,"$":{"0":{"v":"RedwoodJS","n":1},"1":{"v":"\n- [[c.software.application-framework]]\n- [[p.hasSite]] https://redwoodjs.com/\n- [[p.hasLearningResource]] https://learn.redwoodjs.com/docs/tutorial/welcome-to-redwood/ ^wgjmziky7OX7\n- [[p.startedBy]] @tom-preston-werner\n- [[p.differentFrom]] [[prdct.redwood]]","n":0.302}}},{"i":3984,"$":{"0":{"v":"React","n":1}}},{"i":3985,"$":{"0":{"v":"React Native","n":0.707},"1":{"v":"\n- url: https://reactnative.dev/\n- [[p.hadHistory]]\n  - \"Facebook released React Native in 2015 and has been maintaining it ever since.\"\n  - ","n":0.229}}},{"i":3986,"$":{"0":{"v":"RTI","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.middleware]]\n- [[c.Resource.List]] https://en.wikipedia.org/wiki/Run-time_infrastructure_(simulation)\n\n## Resources\n\n- [Comparison of High Level Architecture\nRun-Time Infrastructure Wire Protocols\nPart Two](https://www.sisostds.org/DesktopModules/Bring2mind/DMX/API/Entries/Download?Command=Core_Download&EntryId=42344&PortalId=0&TabId=105)","n":0.258}}},{"i":3987,"$":{"0":{"v":"RML","n":1},"1":{"v":"\n\n\n- [[p.hasSpecification]] https://rml.io/specs/rml/\n- [[p.vs]] [[prdct.r2rml]]\n  - resources:  https://rml.io/docs/rml/rmlvsr2rml/\n\n## References\n\nhttps://ruben.verborgh.org/publications/dimou_ldow_2014/","n":0.333}}},{"i":3988,"$":{"0":{"v":"RDFReactor","n":1},"1":{"v":"\n- dead\n- https://openhub.net/p/rdfreactor\n- published-by: [[org.synopsys]]\n- repo: https://github.com/semweb4j/semweb4j","n":0.378}}},{"i":3989,"$":{"0":{"v":"RDF-star","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://w3c.github.io/rdf-star/\n- [[p.hasRepository]] https://github.com/w3c/rdf-star/\n- [[p.alsoKnownAs]] RDF-*\n- [[c.usecase]] https://w3c.github.io/rdf-star/UCR/rdf-star-ucr.html#submitted-use-cases\n\n## Features\n\n- makes use of the \"many-to-many\" nature of reifiers, where multiple triples can be reified at once, and several reifiers can be related to the same triple\n- \n\n## To Do\n\n- [ ] [[p.summarized]] rdf-star use cases \n  - https://gist.github.com/niklasl/f4a5dee1b991ff5a19a33360c6fd3078\n\n## Implementations\n\n- [[prdct.ontotext-platform]]\n\n## Issues\n\n- https://w3c.github.io/rdf-star/cg-spec/editors_draft.html#sa-mode-and-pg-mode\n  - are quoted triples asserted?\n    - t.2023.12.01 depends on the implementation!?\n      - [[prdct.JSON-LD.star]] has embedded nodes for non-assertion, annotation objects for assertion\n- https://w3c.github.io/rdf-star/cg-spec/editors_draft.html#the-seminal-example\n  - can you have multiple identical triples?\n    - nope! have to use standard reification, new relationship concept\n      - but don't need them anyhow if you're not asserting the triples (ie., Separate Assertion / SA) or if the thing asserted is quoted and assigned a temporal / instance info\n    - [[t.phil.type-token-distinction]]\n      - https://www.w3.org/2021/12/rdf-star.html#occurrences\n- Referential Opacity\n  - https://www.w3.org/2021/12/rdf-star.html#ref-opacity\n  - https://github.com/w3c/rdf-star/issues/22\n  - t.2024.06.07.10 things should be opaque most of the time, since it's important for beliefs and provenance, and since you can get transparency from opacity\n    - but see https://github.com/w3c/rdf-star-wg/wiki/RDF%E2%80%90star-examples-of-profiles#9-why-opaque-triples-do-not-work-for-data-integration-p-a-champin for an argument that opaque isn't sufficient, but it's possible that Charlie's sameAs is incorrect \n  - [[email.public-rdf-star.some-notes-on-the-rdf-star-examples-of-profiles]]\n\n\n## Possible Features\n\n- https://lists.w3.org/Archives/Public/semantic-web/2009Nov/0040.html\n\n\n## Resources\n\n- https://www.ontotext.com/knowledgehub/fundamentals/what-is-rdf-star/\n\n## References\n\n- [[ar.medium.dallemang.why-im-not-excited-about-rdf-star]]\n- https://www.youtube.com/watch?v=gTMvHJdMnzI","n":0.073}}},{"i":3990,"$":{"0":{"v":"R2RML","n":1},"1":{"v":"\n\n\n- resources:  https://rml.io/docs/rml/rmlvsr2rml/\n- [[p.hasSpecification]] https://www.w3.org/TR/r2rml/\n- [[p.isRelated]] [[prdct.rml]]\n","n":0.378}}},{"i":3991,"$":{"0":{"v":"Postgres","n":1},"1":{"v":"\n\n\nrelational database par excellence\n\n## [[c.solution.related]]\n\n- [[prdct.protoculture]]\n- [[prdct.pg-bitemporal]]\n\n## Resources\n\n- [Bitemporal Data Model: Making it happened in Postgres](https://www.youtube.com/watch?v=MGSdq6EYaKk)\n  - \"assertive time\" and \"effective time\"","n":0.213}}},{"i":3992,"$":{"0":{"v":"h3-pg","n":1},"1":{"v":"\n- url: https://github.com/zachasme/h3-pg  ","n":0.577}}},{"i":3993,"$":{"0":{"v":"Portico","n":1},"1":{"v":"\n\n\nprobably the best option for open source HLA\n\n- [[p.hasRepository]] https://github.com/openlvc/portico\n- [[p.implements]] [[prdct.hla]]\n","n":0.289}}},{"i":3994,"$":{"0":{"v":"PlantUML","n":1},"1":{"v":"\n- [[c.software.tools.diagramming]]\n- supports: \n  - [[prdct.svg]] (see https://plantuml.com/svg)\n\n![[prdct.structurizr#similar]]\n\n## Features\n\n- plantuml embeds the source code in SVGs\n\n### 📈 Supported Non-UML Diagrams\n\nCreate well-structured UML diagrams including but not limited to:\n\n-   [Sequence diagram](https://plantuml.com//sequence-diagram)\n-   [Usecase diagram](https://plantuml.com//use-case-diagram)\n-   [Class diagram](https://plantuml.com//class-diagram)\n-   [Object diagram](https://plantuml.com//object-diagram)\n-   [Activity diagram (Beta)](https://plantuml.com//activity-diagram-beta) (Find the [legacy syntax here](https://plantuml.com//activity-diagram-legacy))\n-   [Component diagram](https://plantuml.com//component-diagram)\n-   [Deployment diagram](https://plantuml.com//deployment-diagram)\n-   [State diagram](https://plantuml.com//state-diagram)\n-   [Timing diagram](https://plantuml.com//timing-diagram)\n\n### 📈 Supported Non-UML Diagrams\n\nBeyond UML, PlantUML supports a range of other diagrams such as:\n\n-   [JSON data](https://plantuml.com//json)\n-   [YAML data](https://plantuml.com//yaml)\n-   [EBNF diagram](https://plantuml.com//ebnf)\n-   [Regex diagram](https://plantuml.com//regex)\n-   [Network diagram (nwdiag)](https://plantuml.com//nwdiag)\n-   [UI mockups (salt)](https://plantuml.com//salt)\n-   [Archimate diagram](https://plantuml.com//archimate-diagram)\n-   [Specification and Description Language (SDL)](https://plantuml.com//activity-diagram-beta#sdl)\n-   [Ditaa diagram](https://plantuml.com//ditaa)\n-   [Gantt diagram](https://plantuml.com//gantt-diagram)\n-   [Chronology diagram](https://plantuml.com//chronology-diagram)\n-   [MindMap diagram](https://plantuml.com//mindmap-diagram)\n-   [WBS diagram](https://plantuml.com//wbs-diagram)\n-   [Mathematics with AsciiMath or JLaTeXMath notation](https://plantuml.com//ascii-math)\n-   [Information Engineering diagram](https://plantuml.com//ie-diagram)\n-   [Entity Relationship diagram](https://plantuml.com//er-diagram)\n\n## Learning Resource\n\n- https://crashedmind.github.io/PlantUMLHitchhikersGuide/\n- https://blog.dornea.nu/2023/07/30/documentation-as-code-for-cloud-plantuml/\n- https://crashedmind.github.io/PlantUMLHitchhikersGuide/\n- http://real-world-plantuml.com/","n":0.093}}},{"i":3995,"$":{"0":{"v":"Pendo.io","n":1},"1":{"v":"\n\n## Events\n\n- you click on something and engage with it\n","n":0.316}}},{"i":3996,"$":{"0":{"v":"PagerDuty","n":1}}},{"i":3997,"$":{"0":{"v":"PADE","n":1},"1":{"v":"\n- [[c.software.agent-framework]]\n- repo: https://github.com/grei-ufc/pade\n- #similar [[prdct.spade]]\n\n- [[p.hasSite]] https://pade.readthedocs.io/en/latest/\n- written-in: #python\n- [[p.builtOn]] [[prdct.twisted]]\n- [[p.isRelated]] [[vs.spade-vs-pade]]","n":0.267}}},{"i":3998,"$":{"0":{"v":"Opensense","n":1}}},{"i":3999,"$":{"0":{"v":"OpenFL","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://www.openfl.org/\n","n":0.577}}},{"i":4000,"$":{"0":{"v":"Open Graph Protocol","n":0.577},"1":{"v":"\n\n\n- [[p.hasSite]] https://ogp.me/\n- resources: \n  - https://jessie.codes/article/seo-blog-ogp-jsonld/\n    - [[p.isRelated]] [[prdct.json-ld]]\n","n":0.316}}},{"i":4001,"$":{"0":{"v":"Open-DIS","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] http://open-dis.org/ https://github.com/open-dis\n","n":0.5}}},{"i":4002,"$":{"0":{"v":"OneNote","n":1},"1":{"v":"\n\n- [[p.hasApplication]] [[t.km.note-taking]] \n","n":0.5}}},{"i":4003,"$":{"0":{"v":"ORA4MAS","n":1},"1":{"v":"\n- https://www.emse.fr/~boissier/enseignement/maop14/DOC/moise/ora4mas/ora4mas-basic.html\n\n\n## References\n\n- [[ar.instrumenting-multi-agent-organisations-with-organisational-artifacts-and-agents]]","n":0.5}}},{"i":4004,"$":{"0":{"v":"OGL-SRD5","n":1},"1":{"v":"\n- [[c.publication.rules.srd]]\n- repo: https://github.com/ucffool/OGL-SRD5/\n- fork of [[prdct.DND-SRD-Wiki]]","n":0.378}}},{"i":4005,"$":{"0":{"v":"Netlify","n":1},"1":{"v":"\n\n\n- [[p.vs]] [[prdct.vercel]]  ^uUZD1OtrpGRW\n  - resources:  https://dev.to/maxniederman/netlify-vs-vercel-a-comparison-5643\n    - Netlify bills based on the number of invocations, whereas Vercel bills based on GB-hours since you can customize your serveless function instances. \n- [[p.hasFeature]] \n  - [[t.cs.serverless]]\n    - [[p.hasClientSupport]] javascript #go\n  - [[t.cs.authentication]] via built-in authentication platform based on the [[GoTrue|prdct.GoTrue]] API \n  - Netlify Forms\n  - Netlify Analytics (Paid)\n  - Split Testing\n  - Allows commercial use\n","n":0.124}}},{"i":4006,"$":{"0":{"v":"MySQL","n":1},"1":{"v":"\n\n\n- [[p.hasSense]] \n  - the original free database\n  - a set of variants that are more-or-less compatible\n    - [[prdct.dolt]]\n    - [[prdct.mariadb]]\n","n":0.218}}},{"i":4007,"$":{"0":{"v":"Monogame","n":1}}},{"i":4008,"$":{"0":{"v":"Milkdown","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://milkdown.dev\n- [[p.hasApplication]] [[prdct.markdown]]\n","n":0.447}}},{"i":4009,"$":{"0":{"v":"Microsoft365","n":1},"1":{"v":"\n\n- [[p.alsoKnownAs]] Office365\n","n":0.577}}},{"i":4010,"$":{"0":{"v":"Mesa","n":1},"1":{"v":"\n\n- [[c.software.agent-framework]]\n- [[p.hasRepository]] https://github.com/projectmesa/mesa\n- written-in: #python\n\n## Cons\n\n- no communication, so netlogo-like\n  - https://stackoverflow.com/questions/60126207/mas-platform-written-in-python\n    - [[p.mentioned]] [[prdct.osbrain]]\n\n\n## Resources\n\n### Learning Resource\n\n- https://towardsdatascience.com/intro-to-agent-based-modeling-3eea6a070b72","n":0.224}}},{"i":4011,"$":{"0":{"v":"Mastodon","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://mastodon.social\n- implements: [[prdct.activitypub]]\n- similar: [[prdct.nostr]]","n":0.378}}},{"i":4012,"$":{"0":{"v":"MariaDB","n":1},"1":{"v":"\n\n\n- [[p.hasFeature]] temporal database tables\n","n":0.447}}},{"i":4013,"$":{"0":{"v":"Magic","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://magic.link/\n- written-in: javascript\n- [[p.hasApplication]] [[t.cs.authentication]]\n  - [[p.hasLearningResource]] \n    - [How to Implement Auth in Next.js with Magic](https://magic.link/posts/magic-link-nextjs)\n    - https://github.com/vercel/next.js/tree/canary/examples/with-magic [[prdct.vercel]]\n","n":0.213}}},{"i":4014,"$":{"0":{"v":"Lumos","n":1},"1":{"v":"\n- [[p.hasURL]] https://lumosidentity.com/\n","n":0.577}}},{"i":4015,"$":{"0":{"v":"Logseq","n":1},"1":{"v":"\n\n\na joyful, open-source outliner that works on top of local or git-homed plain-text Markdown and Org-mode files\n\n- [[p.hasSite]] https://logseq.com/\n- [[p.hasApplication]] [[t.km]] [[t.km.digital-gardening]] [[t.tm]] [[prdct.bullet-journaling]]\n  \n- [[p.hasIssue]]\n  - [Desktop version doesn't work with github yet](https://www.reddit.com/r/logseq/comments/og3tkf/github_repository_for_desktop_app/)\n","n":0.171}}},{"i":4016,"$":{"0":{"v":"Libby","n":1}}},{"i":4017,"$":{"0":{"v":"LeapFrog-LeapReader","n":1},"1":{"v":"\n\n\ndiscontinued? \"smart-pen\"\n","n":0.707}}},{"i":4018,"$":{"0":{"v":"Lattice","n":1},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.org-theory.performance-management]] [[t.planning.goal-management]] [[t.org-theory.workforce-analytics]] [[t.management.employee-engagement]] [[t.planning.career-development-planning]]\n","n":0.378}}},{"i":4019,"$":{"0":{"v":"Lacework","n":1},"1":{"v":"\n![](/assets/images/2023-07-06-10-56-19.png)\n\n\n\n","n":1}}},{"i":4020,"$":{"0":{"v":"LVC Game","n":0.707},"1":{"v":"\n- [[t.cs.simulation.live-virtual-constructive]]\n- [[p.ownedBy]] [[org.Calytrix]]\n- [[p.hasURL]] https://www.calytrix.com/products/lvcgame/\n- [[p.hasApplication]] [[t.cs.game.serious-games]]\n- [[p.supports]] [[prdct.unity]]\n  - [[p.hasComponent]] Calytrix LVC Game for Unity SDK\n","n":0.236}}},{"i":4021,"$":{"0":{"v":"Kandji","n":1}}},{"i":4022,"$":{"0":{"v":"KQML","n":1},"1":{"v":"\n\n\n= [[p.supersededBy]] [[prdct.fipa.acl]]\n","n":0.577}}},{"i":4023,"$":{"0":{"v":"Jekyll-Bonsai","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://manunamz.github.io/jekyll-bonsai/\n  - [[p.instanceOf]] [[c.digitalgarden]]\n","n":0.408}}},{"i":4024,"$":{"0":{"v":"Javelin","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[t.cs.entity-component-system]]\n- [[p.hasRepository]] https://github.com/3mcd/javelin\n- [[p.hasSite]] https://javelin.games\n  - [[p.references]] https://godotengine.org/article/why-isnt-godot-ecs-based-game-engine\n    - \"[[Godot|prdct.godot]] does composition at a higher level than in a traditional ECS.\"\n","n":0.209}}},{"i":4025,"$":{"0":{"v":"Jamf-Pro","n":1}}},{"i":4026,"$":{"0":{"v":"Jade","n":1},"1":{"v":"\n- [[c.software.agent-framework]]\n- [[p.hasApplication]] [[t.cs.multi-agent-system]]\n- written-in: java\n- [[p.implements]] [[prdct.fipa]]\n- license [[lic.lgpl]]\n\n## [[p.hasExample]]\n\n- https://github.com/motapinto/multi-agent-system-conquest \n  - uses Jade and its capabilities to develop a multi-agent system using FIPA Communication Protocols and ACL messages.\n\n## Comparison\n\n- [[ar.exposing-agents-as-web-services-a-case-study-using-jade-and-spade]] ","n":0.174}}},{"i":4027,"$":{"0":{"v":"Leap","n":1},"1":{"v":"\n## Description\n\n- they compile Jade 2.5+LEAP 2.1 with Microsoft Visual J#.NET. This results in a .NET DLL file that can be used from any .NET language (e.g. C#, VB.NET, ...) which means, it is possible to write a Jade/LEAP agent in these languages. For a LEAP.NET agent platform/container it is also possible to communicate with a LEAP agent running in a different platform/container beeing executed in Java. Hence, LEAP is becoming a way to interoperate between Java and .NET.","n":0.113}}},{"i":4028,"$":{"0":{"v":"JSON","n":1},"1":{"v":"\n- [[p.instanceOf]] [[c.fileformat]] [[c.dataformat]]\n- similar: [[prdct.hjson]]\n\n## Cons\n\n- \"there is no good answer.\" for multiline splitting, unlike [[prdct.yaml]]\n\n[[p.hasCriticism]] https://www.lucidchart.com/techblog/2018/07/16/why-json-isnt-a-good-configuration-language/\n","n":0.236}}},{"i":4029,"$":{"0":{"v":"Modern JSON","n":0.707},"1":{"v":"\n[[p.hasLearningResource]]\n- https://modern-json-schema.com/what-is-modern-json-schema?source=personalized-newsletter&source-id=2022-11-17\n\n","n":0.707}}},{"i":4030,"$":{"0":{"v":"Hyper Schema","n":0.707},"1":{"v":"\n- related: [[prdct.jsonary]]\n\n![[prdct.hydra#similar]]\n\n## Examples\n\n- [[prdct.hypermedia-todo-api]] \n\n## References\n\n- https://github.com/json-schema-org/json-schema-spec/issues/48","n":0.354}}},{"i":4031,"$":{"0":{"v":"JSON-LD","n":1},"1":{"v":"\n\n\n- [[p.isComparandOf]] https://sookocheff.com/post/api/on-choosing-a-hypermedia-format/\n\n## Features\n\n```json\n\"@context\": {\n  \"\": \"http://example.com/default/\",\n}\n```\n\nis the same as, I think:\n\n\"@context\": \"http://example.com/default/\"\n\n### attach a contextual document in the response\n\n- \"Provide a context in an HTTP Link header\n\nA method for attaching a JSON context to a plain JSON object via an HTTP Link header is described by the JSON-LD specification, section 4.9, Interpreting JSON as JSON-LD. In short, a plain JSON file that is passed via HTTP can be accompanied by a separate JSON-LD context document. The URI of the JSON-LD context document is passed via an HTTP Link header, using the link relation http://www.w3.org/ns/json-ld#context.\"\n\n### Keywords\n\n- @id keyword allows you to give a node a URI\n- @context lets you define vocabulary references\n  - this is more versatile than turtle and other RDF formats, because have more granularity and can \"define terms\", so no prefixing is required\n- @import \"Context files are imported/re-used by creating the context as an array where the first value(s) is the path(s) to the imported context, followed by an object\" (https://www.w3.org/TR/json-ld-syntax/#the-context).\n  - https://www.w3.org/TR/json-ld/#imported-contexts\n- Each of the JSON-LD keywords, except for @context, may be aliased to application-specific keywords.\n- @type specifies the subject's class\n  - objects can have multiple types, e.g. `\"@type\": [\"Person\", \"Author\"]`\n- @graph allows multiple subjects in one document\n- @included \n\n## Best Practices\n\n- https://stackoverflow.com/questions/42398060/json-ld-to-normal-json\n- http://niem.github.io/json/reference/json-ld/context/ discuss context, expansions, and contractions\n\n## vs RDF\n\n- In JSON-LD properties can be IRIs or blank nodes whereas in RDF properties (predicates) have to be IRIs. This means that JSON-LD serializes generalized RDF Datasets.\n- In JSON-LD lists are part of the data model whereas in RDF they are part of a vocabulary, namely [RDF11-SCHEMA].\n- RDF values are either typed literals (typed values) or language-tagged strings whereas JSON-LD also supports JSON's native data types, i.e., number, strings, and the boolean values true and false. The JSON-LD Processing Algorithms and API specification [JSON-LD-API] defines the conversion rules between JSON's native data types and RDF's counterparts to allow round-tripping.\n\n### Streaming\n\n- https://www.w3.org/TR/json-ld11-streaming/\n\n### @chatgpt.4\n\nwhat's the best practices for referencing other entities/objects in json-ld\nChatGPT\n\nIn JSON-LD, best practices for referencing other entities or objects include:\n\n    Use of @id and @type Properties: Assign a unique identifier (@id) to each entity and specify its type (@type). This helps in clearly distinguishing and referencing different entities.\n\n    Consistent and Descriptive Identifiers: Ensure identifiers are consistent and descriptive across your JSON-LD data. This aids in readability and maintainability.\n\n    Utilizing Well-Known Contexts: Reference standard vocabularies or contexts (like schema.org) for common types and properties. This enhances compatibility and interoperability with other systems.\n\n    Embedding vs. Linking: Decide whether to embed other objects directly or just link to them using their @id. Embedding can make the data self-contained, while linking keeps the JSON-LD document concise.\n\n    Handling Multiple References: When referencing multiple entities, use an array of objects or identifiers. This keeps the structure organized and easy to parse.\n\n    Contextualizing Relationships: Use descriptive property names that accurately represent the relationship between entities. This adds semantic clarity to your data.\n\n    Maintaining JSON-LD Best Practices: Apart from referencing, follow general JSON-LD best practices like using a compact and readable format, validating your JSON-LD, and ensuring it aligns with the intended semantic meaning.\n\n    Documentation: Document how references and entities are structured and related in your JSON-LD. This is crucial for others who will use or extend your data.\n\nThese practices help in creating a well-structured, understandable, and semantically rich JSON-LD document, facilitating better data integration and usage.\n\n\n\n## Resources\n\n- https://github.com/fairsharing/jsonldschema\n- https://www.baeldung.com/json-linked-data\n  - mentions: [[prdct.hydra]]\nhttps://developer.chrome.com/blog/creating-semantic-sites-with-web-components-and-jsonld/\n\n## References:\n- https://www.w3.org/TR/json-ld\n- https://json-ld.org/contexts/dollar-convenience.jsonld\n- https://www.w3.org/2013/dwbp/wiki/RDF_AND_JSON-LD_UseCases\n- https://news.ycombinator.com/item?id=31890041\n","n":0.042}}},{"i":4032,"$":{"0":{"v":"JSON-LD-star","n":1},"1":{"v":"\n- specification: https://json-ld.github.io/json-ld-star/\n\n## Concepts\n\nEmbedded Node\n: supports the ability to make one or more statements about a triple, represented by an embedded node, without that triple being necessarily considered to be part of the Linked Data Graph.\n\nAnnotation Object\n: supports the ability to make one or more statements (annotations) about a triple, where the triple is considered to be part of the Linked Data Graph.","n":0.126}}},{"i":4033,"$":{"0":{"v":"JIAC","n":1},"1":{"v":"\n- #dead\n- [[c.software.agent-framework]]\n- written-in: java\n","n":0.447}}},{"i":4034,"$":{"0":{"v":"JADEX","n":1},"1":{"v":"\n- [[c.software.agent-framework]]\n- written-in: java\n- repo: https://github.com/actoron/jadex","n":0.408}}},{"i":4035,"$":{"0":{"v":"Insycle","n":1},"1":{"v":"\n\n\norganize, cleanse, and update customer data – all in one place\n\n- [[p.extends]] [[prdct.hubspot]]\n","n":0.277}}},{"i":4036,"$":{"0":{"v":"Instapaper","n":1}}},{"i":4037,"$":{"0":{"v":"IdRamp","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://idramp.com/\n- [[p.hasApplication]] [[t.cs.authentication]]\n","n":0.447}}},{"i":4038,"$":{"0":{"v":"HyperGraphQL","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://www.hypergraphql.org\n","n":0.577}}},{"i":4039,"$":{"0":{"v":"Hubspot","n":1}}},{"i":4040,"$":{"0":{"v":"Heartex","n":1}}},{"i":4041,"$":{"0":{"v":"HLA","n":1},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.cs.simulation]] [[Distributed Interactive Simulation|t.cs.simulation.distributed-interactive-simulation]]\n- [[c.implementation]]\n  - [[prdct.mak-rti]]\n  - [[prdct.certi]]\n  - [[prdct.prepar3d]]\n- [[p.hasComponent]] [[prdct.rti]]\n- [[p.hasTraining]] https://pitchtechnologies.com/hla-hands-on-training/\n  - [[p.hasAuthor]] [[org.Pitch-Technologies]]\n\n## [[c.Resource.List]]\n\n- [HLA Run Time Infrastructure: A Comparative Study](https://oaji.net/articles/2019/2712-1573379026.pdf)\n- https://www.informs-sim.org/wsc97papers/0373.PDF\n\n","n":0.186}}},{"i":4042,"$":{"0":{"v":"HLA Time Management Services","n":0.5},"1":{"v":"\n## [[p.referredFrom]] https://en.wikipedia.org/wiki/High_Level_Architecture#Time_Management_Services\n\nSome important concepts in HLA Time Management are:\n\n**Logical time**: A time axis in HLA, starting at zero. Logical time is used for Time Management timestamps and operations. The logical time axis can be mapped to the scenario time of the federation. An example of such a mapping is to let zero represent the scenario time 8:00 of the 1-Jan-[1066](https://en.wikipedia.org/wiki/1066) and let an increment by one represent one second of the scenario.\n\n**Lookahead**: A time interval specifying the lowest time in the future for which a federate will produce messages. For a federate with a fixed time step, this is usually the length of the time step.\n\n**Granted**: A federate is granted (allowed to advance) to a particular logical time by the RTI, when all time-stamped messages up to that time have been delivered. The federate can then safely start calculating messages with a timestamp in the future. This timestamp may not be earlier than the granted time plus the federates lookahead.\n\n**Advancing**: When a federate has finished producing data for the granted time plus the lookahead, it may request to be advanced to a later time, which also means that it promises not to produce any more messages with a time stamp less than the requested time plus the lookahead. The federate is now in the advancing state.\n\n**Time Regulating**: A federate that sends time stamped events is considered Time Regulating since the time advance by other federates may be regulated by this.\n\n**Time Constrained**: A federate that receives time managed events is considered Time Constrained since the reception of time stamped messages, constrains its time advance.\n\nThe main principles of HLA Time Management are that:\n\n-   Each time-regulating federate assigns a time stamp to messages (updates and interactions) when they are sent, indicating the scenario time at which the message is valid.\n-   The RTI manages delivery of messages to time-constrained federates, with messages from time-regulating federates delivered at the appropriate time using a Time Stamp Order queue.\n-   Time-constrained federates request permission from the RTI to advance their time.\n-   The RTI grants a time advance to a time-constrained federates when it is sure that the federate cannot receive a message with a time stamp in its past.\n\nExample of Lookahead, granted and advancing:\n\n1.  A federate uses a fixed time step of 10 and has a Lookahead of 10.\n2.  The federate is granted to logical time 50 by the RTI. The RTI thus guarantees that all messages with time step less or equal to 50 have been delivered to the federate.\n3.  The federate now has all the necessary data to correctly calculate and send messages for the granted time plus Lookahead, i.e. 60.\n4.  When the federate has sent all messages with timestamp 60, it requests to be advanced to time 60. It thereby promises not to send any messages with a timestamp less than 70.\n5.  The RTI delivers all messages with timestamp less or equal to 60 to the federate. It then grants the federate to time 60.\n6.  Etc.\n\nIf at least one federate in the federation performs pacing, i.e. correlates their time advance requests with a real time clock, the federation may run in real time or scaled real time. Without pacing, the federation will run as fast as possible (e.g., federations that do not require human interaction at runtime nor interfaces with systems that depend upon a real-time clock can run as fast as computing resources will allow).\n\nKey services include:\n\n-   EnableTimeConstrained and EnableTimeRegulating that enables theses modes for a federate\n-   TimeAdvanceRequest whereby a federate requests to be advanced to a specified logical time\n-   TimeAdvancedGrant whereby the RTI informs a federate that it is granted to a specified logical time.\n-   EnableAsynchronousDelivery that enables delivery of Receive Order messages both when a federate is in the granted and advancing state.\n\nFor event driven simulation it is also possible for a federate to request to be advanced to the next event using the following service:\n\n-   NextMessageRequest whereby a federate requests to be advanced to the timestamp of the next message due for delivery to the federate, or a specified logical time, whichever has a lower timestamp.\n\nAnother important concept is **Greatest Available Logical Time** (GALT). The greatest time that each federate can be granted to, depends on the time that other federates have been granted to as well as their lookahead. The GALT for a federate specifies how far a federate can be granted, without having to wait for other federates to be granted. This is particularly interesting for a federate that joins late into a time managed federation.\n\nKey services for GALT are:\n\n-   QueryGALT that returns the GALT for the calling federate.\n\nMore advanced services include:\n\n-   FlushQueueRequest whereby a federate can request delivery of all queued, timestamped messages, no matter how far in the future their timestamp is.\n-   Retract whereby a federate can request that an already sent message is retracted. This is useful in optimistic simulation.","n":0.035}}},{"i":4043,"$":{"0":{"v":"JSON-HAL","n":1},"1":{"v":"\n\n\n- [[p.correspondsTo]] [[JSON-HAL|t.cs.web.ietf.draft-kelly-json-hal]]\n- [[p.hasSpecification]] https://datatracker.ietf.org/doc/html/draft-kelly-json-hal-08\n- [[p.similarTo]] [[prdct.json-ld]]\n- [[p.isComparandOf]] https://sookocheff.com/post/api/on-choosing-a-hypermedia-format/\n\n## Comparisons\n\n### HAL vs JSON-LD\n\n- both support curries\n- json-ld has the semantic-webby context/ontology linkage\n\n## Resources\n\n- https://stateless.group/hal_specification.html\n\n## References\n\n- https://www.reddit.com/r/javascript/comments/1j08ov/hal_vs_jsonld/\n- https://sookocheff.com/post/api/on-choosing-a-hypermedia-format/\n","n":0.192}}},{"i":4044,"$":{"0":{"v":"GraphML","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] http://graphml.graphdrawing.org/\n- [[p.instanceOf]] [[c.fileformat]]\n- [[p.builtOn]] [[prdct.xml]]\n- [[p.supports]] [[t.cs.graph.hypergraph]]","n":0.333}}},{"i":4045,"$":{"0":{"v":"GraphDB","n":1},"1":{"v":"\n- [[c.software.database.graph]]\n- [[p.instanceOf]] [[t.cs.data.dbms.graph]]\n- written-in: java\n- [[p.supports]] [[prdct.rdf-star]] [[prdct.kafka]]\n- produced_by: [[org.ontotext]]\n- based_on: [[prdct.rdf4j]]\n- related: [[prdct.ontotext-platform]]\n\n\n## Features\n\n- [embeddable](https://graphdb.ontotext.com/documentation/9.8/free/devhub/embeddedgraphdb.html)\n- Synchronize data to downstream systems with the Kafka connector.\n- can be used with [[prdct.jena]], see https://graphdb.ontotext.com/documentation/9.1/free/using-graphdb-with-jena.html\n- [[prdct.sparql.mm]] supports \"system time\" queries\n  - \"Note that querying the history log may be slow for big history logs. This is why we recommend using filters to reduce the number of history entries if you have a big repository.\"\n- [[prdct.sparql.geosparql]]\n- javascript support allows custom functions\n  - could be useful in context of auto-versioning [[ar.star-vers-versioning-and-timestamping-rdf-data-by-means-of-rdf-star-an-approach-based-on-annotated-triples]]\n- [spatial extensions](https://graphdb.ontotext.com/documentation/10.6/geo-spatial-extensions.html?highlight=spatial)\n\n\n## References\n\n- https://www.ontotext.com/knowledgehub/fundamentals/semantic-repository/\n- https://ontotext.medium.com/ingesting-data-in-graphdb-using-the-kafka-sink-connector-53036f2e1680","n":0.104}}},{"i":4046,"$":{"0":{"v":"Graph Commons","n":0.707},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.km]]\n- [[p.hasSite]] https://graphcommons.com\n- [-]  [[p.summarized]] Graph Commons    \n- [[p.hasFeature]]\n  - [[p.canImportFrom]]\n    - [[prdct.csv]]\n    - [[prdct.sheets]]\n  - [[p.canExportTo]]\n    - [[prdct.csv]]\n    - [[prdct.sheets]]\n    - [[prdct.json]]\n    - [[prdct.cypher]]\n    - [[prdct.graphml]]\n  - [[p.hasAPI]] https://graphcommons.github.io/api-v1/\n    - \"Develop graph-driven smart applications\"\n\n\n","n":0.164}}},{"i":4047,"$":{"0":{"v":"Google-Workspace","n":1},"1":{"v":"\n\n- [[p.alsoKnownAs]] GSuite\n","n":0.577}}},{"i":4048,"$":{"0":{"v":"Godot","n":1},"1":{"v":"\n[[c.software.game-engine]]\n\n- [[p.hasRepository]] https://github.com/godotengine/godot\n- [[p.hasSite]] https://godotengine.org/\n- [[p.builtWith]] #c++\n- [[p.hasScriptingLanguage]] \n  - [[t.cs.languages.gdscript]] \n  - [[t.cs.languages.C-sharp]]\n  - #c++\n  - typescript via https://github.com/GodotExplorer/ECMAScript and [[prdct.quickjs]]\n  - #rust\n  - #python via [PythonScript](https://godotengine.org/asset-library/asset/179)\n\n\n## Features\n\n- publish to web\n  - [[c.issue]]  ^x343t4fze5lf\n    - t.2023.10.09 Projects written in C# using Godot 4 currently cannot be exported to the web. To use C# on web platforms, use Godot 3 instead.\n    - Godot 4's HTML5 exports currently cannot run on macOS and iOS due to upstream bugs with SharedArrayBuffer and WebGL 2.0.\n- dynamic execution\n  - @tool makes scripts execute in the editor  https://docs.godotengine.org/en/stable/tutorials/plugins/running_code_in_the_editor.html ^lk1riz8a7a5e\n    - e.g. If your player doesn't use a sprite, but draws itself using code, you can make that drawing code execute in the editor to see your player.\n  - https://ask.godotengine.org/34626/dynamic-code\n- [[prdct.wasm]] [support](https://docs.godotengine.org/en/acctable/contributing/development/compiling/compiling_for_web.html) via [[prdct.emscripten]]\n  - Using Go for WebAssembly offers several advantages. First, Go provides a familiar and straightforward programming environment for web developers, making it easy to transition from traditional Go development to web development.\n  - Secondly, Go’s performance and concurrency features are well-suited for building efficient web applications that can handle heavy workloads.\n  - Finally, the combination of Go and WebAssembly allows for cross-platform compatibility, enabling the deployment of applications on various browsers without the need for plugins or additional dependencies.\n- [[c.software.entity-component-system]] \n\n## Cons\n\n- as of early 2024, no c# support for web platform\n- does not support exception handling https://heroiclabs.com/docs/nakama/client-libraries/godot/ \n- @hendrik-mans: \"I love that Godot exists, but I hate it so much\nIt is what it is, and if you take it as just that, it's alright, but as soon as you look at the terrible source code or otherwise interact with the project or the people in it, it gets so painful.\nMy favorite Godot experience is how, after reporting something that's obviously broken, or opening a proposal for a new feature/change that I think might be useful because I use them in other engines, someone from the core team will always end up telling me how the bug/broken behavior might, in fact, be good, or how the thing that literally every other engine does is in fact bad\nHow about a mute button that will disable sound when running the game/a scene? No, the user can just drop down their PC's volume for that!\nHow about an icosphere geometry generator? lol what's an icosphere, that kinda looks funny, juse use a normal sphere!\nShader code can't shadow global names in local variable names! Oh yeah we don't know if that is on purpose but it feels like if they can do that, it might confuse people\nBut your language claims to be GLSL compatible, and in GLSL you can shadow global names! Oh yeah well it's still confusing\nHow about being able to scale rigidbodies? THAT'S IMPOSSIBLE!!!!!\nNo, it's not, literally every engine supports it (by internally scaling colliders)! oh yeah? well, that's kinda confusing. All rigidbodies should be the same size! If you need an object in several different sizes, just make copies of the scene and adjust the colliders manually!\netc. etc. etc.\nIt really is a terrible terrible terrible piece of software and the only chance one has at maybe enjoying it is to just think of fluffy little kittens every time you encounter something that's broken or bad. But do not, I repeat, do NOT engage with the project.\"\n  - https://discord.com/channels/844566064281026600/850335072242237470/1175129150068109367\n\n## Resources\n\n- https://github.com/abmarnie/godot-architecture-organization-advice\n- https://chickensoft.games/blog/godot-csharp-2024/\n\n## References\n\n- https://godotengine.org/article/whats-new-in-csharp-for-godot-4-0/\n- https://godotengine.org/article/why-isnt-godot-ecs-based-game-engine/\n- https://programminghaven.home.blog/2020/01/30/designing-a-loosely-coupled-gdscript/","n":0.043}}},{"i":4049,"$":{"0":{"v":"GoTrue","n":1},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.cs.authentication]]\n","n":0.577}}},{"i":4050,"$":{"0":{"v":"Gatsby","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] gatsbyjs\n- [[p.hasSite]] https://www.gatsbyjs.com/\n","n":0.447}}},{"i":4051,"$":{"0":{"v":"FrameworkJS","n":1},"1":{"v":"\n\n\n- [[p.hasRepository]] https://bitbucket.org/teamframeworkjs/frameworkjsnode\n- [[p.hasApplication]] [[t.cs.multi-agent-system]]\n- docs:  https://iconline.ipleiria.pt/bitstream/10400.8/3482/1/Vers%C3%A3o%20corrigida%20-%20Carlos_Silva_Villafuerte.pdf\n","n":0.378}}},{"i":4052,"$":{"0":{"v":"Foundry-VTT","n":1},"1":{"v":"\n- [[c.software.rpg.virtual-tabletop]]\n\n## Integrations\n\n- map-imports: [[prdct.Dungeon-Draft]] [[prdct.dungeon-alchemist]]\n- content-integrations: [[prdct.WorldAnvil]] [[prdct.dscryb]] [[prdct.syrinscape]] [[prdct.plutonium]]\n- others: [[prdct.kanka]] (via [[prdct.kanka-foundry]]) [[prdct.the-only-sheet]] [[prdct.lava-flow]]\n- built-on: [[prdct.pixi-js]]\n\n## Solutions\n\n### Cloud Hosting\n\n- [[prdct.the-forge]]\n- [[prdct.foundry-server]]\n- [[prdct.molten-hosting]]\n\n## User Stories\n\n### modding\n\n- \"easily it can be modded which puts it's automation above that of what I've witnessed in any other VTT. \"\n- \" there is a thing about platforms where the one that is pretty popular and moddable attracts the best modders, which means it becomes much better and attracts more great modders and users.. Foundry has snowballed to a point where a DM who is a bit technical and wants to add mods has an amazing variety of options. \"\n\n### planning\n\n- \"I've been enjoying writing my new campaign in Obsidian. Wiki style links and an add on allows for pinnable maps. There are a number of other plug ins specifically for D&D or similar. \"\n- \"I've since moved to running sessions directly off of journal entries. There's nothing better than being able to control the game world with in-line links and scripts\"\n- \"While I love Foundry, I always found a little janky to use it to worldbuild and to take notes. I love using Obsidian and I currently use it to plan my sessions and worldbuild. However, I would very much like to use a single app to all my TTRPG needs.\"\n\n### GM Website\n\n- \"Honestly, I just found the friction of trying to world-build within Foundry too high, even with mods.\n\nSo, I have elected to move everything \"not nailed down in Foundry\" to a website I control (built using Hugo) -- though I strongly considered using [[prdct.legend-keeper]] for a hot-second (but I wanted my files local). So, I just fired up a webserver on the same machine as the foundry server and deployed from a Hugo site I build in VSCode.\n\nThen, in Foundry, I'll have journal entries that are just HTML iframes to particular sites. I mean, hell, my players are already using the browser in Foundry. They might as well be able to leverage the power of browsing while we play, too. The Arc browser makes this a breeze, too, with it's good tab, spaces, and window controls. Edge can do similar.\n\nNow, the only stuff in Foundry really are just the mechanical fiddly bits needed to run the game. Everything else is sitting in the website. And then my private notes/wiki in Obsidian (yes, I tinkered with using Obsidian to manage the website, but I did't like 1. paying the extra fee for Obsidian Publish when I already had a perfectly fine host and 2. I really wanted a lot of control over the player-facing site. Love Obsidian as my GM wiki, though.\"\n\n## Development\n\n### Module Development\n\nModules extend and modify the behavior of Foundry Virtual Tabletop and its game systems. At a conceptual level, think of each Module as a \"plug-in\" or \"add-on\" which changes the software behavior in small (or large) ways. Modules can alter the behavior of the core software in several different ways:\n\nContent\n    Modules which add data in the form of compendium packs of Adventures, Actors, Items, Scenes, Journal Entries, Roll Tables, or Playlists.\nInterface\n    Modules which change the way the UI looks or behaves, changing the aesthetics and user experience of the software.\nFunctionality\n    Modules which add entirely new functionalities or features which do not exist in the base software, or modules which change the behavior of core features so they behave differently.\nTranslation\n    Modules which add support for translation of text displayed in Foundry VTT into other languages. \n\n### System Development\n\n\n\n\n## Resources\n\n- https://www.reddit.com/r/FoundryVTT/comments/10gt7jt/what_options_are_there_for_organizing_world/\n- https://www.reddit.com/r/FoundryVTT/comments/1asnse4/there_are_modules_to_use_foundry_to_worldbuild/\n\n### Learning Resources\n\n- https://foundryvtt.com/article/module-development/\n- https://forge-vtt.com/game/demo\n\n\n## References\n\n- https://www.reddit.com/r/FoundryVTT/comments/10mmkj0/where_do_i_start_creating_a_game_system/","n":0.041}}},{"i":4053,"$":{"0":{"v":"Foundry Client-side API","n":0.577},"1":{"v":"\n- https://foundryvtt.com/api/\n\n\n## Topics\n\n### Public API\n\nmethods and properties that we officially support and recommend Package developers to use in their integrations.\n\n","n":0.224}}},{"i":4054,"$":{"0":{"v":"Flyway","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[prdct.dbt]] [[prdct.airflow]] [[prdct.great_expectations]]\n","n":0.447}}},{"i":4055,"$":{"0":{"v":"Firebase","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[t.cs.data.DBaaS]]\n","n":0.577}}},{"i":4056,"$":{"0":{"v":"Fetch-AI","n":1},"1":{"v":"\n- [[c.Software.Web3]] [[c.software.agent-framework]]\n- [[p.hasSite]] https://fetch.ai/\n- [[p.hasComponent]] [[prdct.fetch-ai.aea]] [[prdct.fetch-ai.agentverse]]\n- ![](/assets/images/2021-11-25-19-52-26.png)\n\n## Description\n\n- Agent registration in the Almanac contract is a key feature which enables discoverability of agents as well enabled remote agent communication. In order to register agents must pay a small fee therefore, your agents need to have funds available in their Fetch address.\n\n## Features\n\n- define your own protocols, with [[prdct.protobuf]] support for:\n  -   go: `go` #go\n  -   c++: `cpp` #c++\n  -   java: `java` java\n  -   c#: `csharp` c#\n  -   ruby: `ruby` #ruby\n  -   objective-c: `objc` \n  -   javascript: `js` javascript\n\n\n## References\n\n- https://docs.fetch.ai/aea-framework-documentation/protocol/","n":0.104}}},{"i":4057,"$":{"0":{"v":"agentverse","n":1},"1":{"v":"\n- url: https://agentverse.ai/\n\n## Pricing\n\n### Free Tier\n\n- for developers\n- Mailbox\n  Data transfer out\n  200.00 MBremaining\n  Messages\n  10,000remaining\n  Storage Size\n  50.00 MBremaining\n  Mailboxes\n  4remaining\n- Hosting\n  Computation Time\n  62,000 secsremaining\n  Processed Messages\n  620,000remaining\n  Processed Messages\n  1.27 GBremaining\n  Agents\n  8remaining\n","n":0.167}}},{"i":4058,"$":{"0":{"v":"aea","n":1},"1":{"v":"\n## Terms\n\n### Skills\n\n- self-contained capabilities that implement business logic to deliver economic value for the AEA\n- A skill encapsulates implementations of the three abstract base classes `Handler`, `Behaviour`, `Model`, and is closely related with the abstract base class `Task`:\n  -   [`Handler`](https://docs.fetch.ai/aea-framework-documentation/protocol-generator/#how-to-run../api/skills/base#handler-objects): each skill has zero, one or more `Handler` objects, each responsible for the registered messaging protocol. Handlers implement AEAs' **reactive** behaviour. If the AEA understands the protocol referenced in a received `Envelope`, the `Handler` reacts appropriately to the corresponding message. Each `Handler` is responsible for only one protocol. A `Handler` is also capable of dealing with internal messages (see next section).\n  -   [`Behaviour`](https://docs.fetch.ai/aea-framework-documentation/protocol-generator/#how-to-run../api/skills/base#behaviour-objects): zero, one or more `Behaviours` encapsulate actions which further the AEAs goal and are initiated by internals of the AEA, rather than external events. Behaviours implement AEAs' **pro-activeness**. The framework provides a number of [abstract base classes](https://docs.fetch.ai/aea-framework-documentation/protocol-generator/#how-to-run../api/skills/behaviours) implementing different types of behaviours (e.g. cyclic/one-shot/finite-state-machine/etc.).\n  -   [`Model`](https://docs.fetch.ai/aea-framework-documentation/protocol-generator/#how-to-run../api/skills/base#model-objects): zero, one or more `Models` that inherit from the `Model` class. `Models` encapsulate custom objects which are made accessible to any part of a skill via the `SkillContext`.\n  -   [`Task`](https://docs.fetch.ai/aea-framework-documentation/protocol-generator/#how-to-run../api/skills/tasks#task-objects): zero, one or more `Tasks` encapsulate background work internal to the AEA. `Task` differs from the other three in that it is not a part of skills, but `Task`s are declared in or from skills if a packaging approach for AEA creation is used.\n\n- [[p.hasRepository]] https://github.com/fetchai/agents-aea\n","n":0.067}}},{"i":4059,"$":{"0":{"v":"Fauna","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://fauna.com/\n\n\n## Features\n\n- supports native joins, which is the number one missing feature in document databases","n":0.243}}},{"i":4060,"$":{"0":{"v":"FIPA","n":1},"1":{"v":"\n\n- written-in: java\n\n## Implementations\n\n- [[prdct.fetch-ai]]\n- [[prdct.jade]]\n- [[prdct.jadex]]\n- [[prdct.jiac]]\n- [[prdct.spade]](Python)\n- [[prdct.jack]] Intelligent Agents (Java)\n- [[prdct.gama]]\n\n## Resources\n\n- [[ar.fipa_rdf_content_language_specification]]\n- [[ar.a-fipa-compliant-agent-framework-integrating-protege-2000]]","n":0.243}}},{"i":4061,"$":{"0":{"v":"FIPA-ACL","n":1},"1":{"v":"\n\n## Cons\n\n- doesn't seem to cover deception\n\n## Resources\n\n- [FIPA ACL Message Structure Specification](http://www.fipa.org/specs/fipa00061/SC00061G.html)\n- [FIPA Communicative Act Library Specification](http://www.fipa.org/specs/fipa00037/SC00037J.html)\n- https://jmvidal.cse.sc.edu/talks/agentcommunication/performatives.html\n\n","n":0.229}}},{"i":4062,"$":{"0":{"v":"Microsoft Excel","n":0.707}}},{"i":4063,"$":{"0":{"v":"Dungeon-Draft","n":1},"1":{"v":"\n- [[c.software.rpg]]\n- [[p.hasURL]] https://dungeondraft.net/\n- [[p.hasApplication]] [[t.roleplaying.map-making]]\n","n":0.408}}},{"i":4064,"$":{"0":{"v":"Dolt","n":1},"1":{"v":"\n- [[p.instanceOf]] [[t.cs.data.DBMS]]\n- [[p.compatibleWith]] [[prdct.mysql]]\n- [[p.hasFeature]] [[t.cs.version-control]] [[t.cs.data.time-travel]] [[t.cs.collaboration]]\n- [[p.hasRepository]] https://github.com/dolthub/dolt\n\n## Cons\n\n- \"Dolt is technically uni-temporal as it implements a built in log via the Git-style commit system. Dolt does not implement time period functionality but if it did it could be made bi-temporal or tri-temporal. If you want time period support, file an issue.\" \n\n## [[p.hasSource]]\n\n- https://www.dolthub.com/\n","n":0.131}}},{"i":4065,"$":{"0":{"v":"DoltHub","n":1},"1":{"v":"\n\n- [[p.instanceOf]] [[t.cs.data.DBaaS]]\n- [[p.hasSite]] https://www.dolthub.com/\n- [[p.builtOn]] [[prdct.dolt]]\n","n":0.378}}},{"i":4066,"$":{"0":{"v":"DnD5eCharacter","n":1},"1":{"v":"\n- [[c.ontology]] [[c.ontology.domain]] [[c.ontology.domain.rpg.dnd]]\n- https://github.com/rwambacq/DnD5eCharacter/blob/master/DnD5eCharacter.ttl\n\n## Thoughts\n\n- [[prdct.owl.full]], e.g.\n  - class CureWounds DnD5eCharacter:inMagicSchool DnD5eCharacter:Evocation ;\n\n## Issues\n\n- \"armor\" \n  - seems to represent types of armor\n  - isn't a subclass of anyting, including [[prdct.ttrpg]]'s ItemType.Armor\n- Monster is a CharacterType, along with AbilityScore and Skill\n- Character seems redundant with ttrpg:Character, doesn't have any superclass or details\n- creates a custom \"version\" property to keep track of ontology version","n":0.125}}},{"i":4067,"$":{"0":{"v":"Delta3D","n":1},"1":{"v":"\n\n- [[p.hasApplication]] [[t.cs.simulation]] [[t.roleplaying.mmorpg]]\n- [[p.hasRepository]] https://github.com/delta3d/delta3d\n- [[p.isRelated]] [[prdct.simulation-core]]\n","n":0.354}}},{"i":4068,"$":{"0":{"v":"DSEEP","n":1},"1":{"v":"\n\n\n1. Define Simulation Environment Objectives\n2. Perform Conceptual Analysis\n3. Design Simulation Environment\n4. Develop Simulation Environment\n5. Integrate and Test Simulation Environment\n6. Execute Simulation\n7. Analyse Data and Evaluate Results\n\n","n":0.196}}},{"i":4069,"$":{"0":{"v":"DND-SRD-Wiki","n":1},"1":{"v":"\n- [[c.publication.rules.srd]]\n- https://github.com/OldManUmby/DND.SRD.Wiki","n":0.577}}},{"i":4070,"$":{"0":{"v":"DIS","n":1},"1":{"v":"\n\n\n- [[c.implementation]] [[prdct.open-dis-javascript]]\n\n- PDU: Protocol Data Units\n\n## PDU types\n\n- Entity information/interaction family - Entity State, Collision, Collision-Elastic, Entity State Update, Attribute\n- Warfare family - Fire, Detonation, Directed Energy Fire, Entity Damage Status\n- Logistics family - Service Request, Resupply Offer, Resupply Received, Resupply Cancel, Repair Complete, Repair Response\n- Simulation management family - Start/Resume, Stop/Freeze, Acknowledge\n- Distributed emission regeneration family - Designator, Electromagnetic Emission, IFF/ATC/NAVAIDS, Underwater Acoustic, Supplemental Emission/Entity State (SEES)\n- Radio communications family - Transmitter, Signal, Receiver, Intercom Signal, Intercom Control\n- Entity management family\n- Minefield family\n- Synthetic environment family\n- Simulation management with reliability family\n- Live entity family\n- Non-real time family\n- Information Operations family - Information Operations Action, Information Operations Report\n","n":0.096}}},{"i":4071,"$":{"0":{"v":"DESim4JS","n":1},"1":{"v":"\n- [[c.software.simulation-framework.discrete-event]]\n- [[p.hasRepository]] https://github.com/uia4w/uia-simjs\n- written-in: javascript\n- [[p.isRelated]] [[prdct.simpy]] [[prdct.sim-js]]\n\n","n":0.333}}},{"i":4072,"$":{"0":{"v":"Cypher","n":1},"1":{"v":"\n## Resources\n\n- http://fooo.fr/~vjeux/github/github-recommandation/db/doc/manual/html/cypher-cookbook-hyperedges.html\n\n\n","n":0.577}}},{"i":4073,"$":{"0":{"v":"CodeTour","n":1},"1":{"v":"\n- [[p.hasURL]] https://marketplace.visualstudio.com/items?itemName=vsls-contrib.codetour\n- [[p.instanceOf]] [[c.software.ide.extension.vscode]]\n","n":0.447}}},{"i":4074,"$":{"0":{"v":"CSV (file format)","n":0.577}}},{"i":4075,"$":{"0":{"v":"CERTI","n":1},"1":{"v":"\n\n\n- [[p.hasRepository]] https://github.com/etopzone/CERTI\n- [[p.supports]] HLA 1.3 specifications (C++ and Java) and partial IEEE 1516-v2000 and IEEE 1516-v2010 (C++)\n","n":0.236}}},{"i":4076,"$":{"0":{"v":"C4-PlantUML","n":1},"1":{"v":"\n- related: [[prdct.plantuml]] [[t.cs.sd.c4-model]]\n\n- [[p.hasRepository]] https://github.com/plantuml-stdlib/C4-PlantUML\n","n":0.408}}},{"i":4077,"$":{"0":{"v":"BitSight","n":1}}},{"i":4078,"$":{"0":{"v":"BibSonomy","n":1},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.cs.web.social.bookmarking]] [[t.km.reference-management]]\n","n":0.5}}},{"i":4079,"$":{"0":{"v":"Automox","n":1}}},{"i":4080,"$":{"0":{"v":"Asana","n":1},"1":{"v":"\nHome of the \"pyramid of transparency\"\n\n- [[hasCapability]]\n\n![](/assets/images/2021-10-28-12-00-01.png)\n\n","n":0.378}}},{"i":4081,"$":{"0":{"v":"Asami","n":1},"1":{"v":"\n- dead\n- similar: [[prdct.datomic]]\n- [[p.hasRepository]] https://github.com/threatgrid/asami\n- [[p.hasComponent]] [[prdct.loom]]\n- [[p.instanceOf]] [[t.cs.data.DBMS.graph]]\n- written-in: [[t.cs.languages.Clojure]]\n- [[p.hasFeature]]\n  - Clojure and ClojureScript: Asami runs identically in both systems.\n  - Schema-less: Asami does not require a schema to insert data.\n  - Query planner: Queries are analyzed to find an efficient execution plan. This can be turned off.\n  - Analytics: Supports fast graph traversal operations, such as transitive closures, and can identify subgraphs.\n  - Integrated with Loom: Asami graphs are valid Loom graphs, via Asami-Loom.\n  - [[Open World Assumption|t.cs.web.w3c.rdf.open-world-assumption]]: Related to being schema-less, Asami borrows semantics from RDF to lean towards an open world model.\n  - Pluggable Storage: Like Datomic, storage in Asami can be implemented in multiple ways. There are currently 2 in-memory graph systems, and durable storage available on the JVM\n\n## References\n\n- https://www.linkedin.com/pulse/how-i-query-rdf-clojure-using-asami-adrian-medina/","n":0.088}}},{"i":4082,"$":{"0":{"v":"Algolia","n":1}}},{"i":4083,"$":{"0":{"v":"algolia-search","n":1}}},{"i":4084,"$":{"0":{"v":"algolia-recommend","n":1}}},{"i":4085,"$":{"0":{"v":"Algolia-Search","n":1},"1":{"v":"\n\n\n- [[p.integratesWith]] [[prdct.react]] #static-site-revolution\n- [[p.hasApplication]] [[t.cs.web.site.search]]\n","n":0.408}}},{"i":4086,"$":{"0":{"v":"Airflow","n":1},"1":{"v":"\n![[prdct.n8n#^xnxaubd7sqiw]]\n- [[p.instanceOf]] [[c.software.workflow]]\n\n## Comparisons\n\n![[prdct.nifi#nifi-vs-airflow]]","n":0.5}}},{"i":4087,"$":{"0":{"v":"Agora","n":1},"1":{"v":"\n\n\n- [[p.hasApplication]] [[t.km]] \n\nAn Agora is a collection of digital gardens and other information sources that are assembled into a distributed knowledge graph.\n\n- [[p.hasComponent]]\n  - agora root repository\n    - [list of gardens](https://github.com/flancian/agora/blob/master/gardens.yaml)\n    - [community contract](https://github.com/flancian/agora/blob/master/CONTRACT.md)\n  - [[prdct.agora-server]]\n  - [[prdct.agora-bridge]]\n\n- [[p.hasURL]] https://anagora.org/agora\n- [[hasIntroduction]] https://docs.google.com/presentation/d/10OWEuLriQpZzSJGq6vCSozZN4M34CNmEC1IrJxqk8xE/edit#slide=id.p\n- [[p.isRelated]] [[ar.anagora]], [[prdct.agora-server]]\n\n## Features\n\n- >\"lightweight conventions for sense making\"\n- >\"Edges are `wikilinks` referring to other nodes as found in volunteered subnodes. They are labeled by context, e.g. by adjacency or proximity to other links. This gives the graph hypergraph-like qualities, which will be expounded on later.\n\n- [[p.vs]] [[gd]]\n  -  push! \n     -  [[p.hasURL]] https://anagora.org/push\n## Activity\n\n- [ ] #read [agora presentation](https://docs.google.com/presentation/d/10OWEuLriQpZzSJGq6vCSozZN4M34CNmEC1IrJxqk8xE/edit#slide=id.gb6e3bafbdf_19_31)\n\n- [[p.hasLearningResource]]\n  - https://docs.google.com/presentation/d/10OWEuLriQpZzSJGq6vCSozZN4M34CNmEC1IrJxqk8xE/edit#slide=id.gced2630138_0_32\n","n":0.097}}},{"i":4088,"$":{"0":{"v":"AgentMaps","n":1},"1":{"v":"\n- #dead\n- [[p.hasRepository]] https://github.com/noncomputable/AgentMaps\n- [[p.hasApplication]] [[t.cs.multi-agent-system]]\n- written-in: javascript\n- [ ] [[p.reviewed]] AgentMaps\n\n## Summary\n\n- functions as an extension of [[prdct.leaflet]]","n":0.229}}},{"i":4089,"$":{"0":{"v":"AgentFramework","n":1},"1":{"v":"\n- [[p.hasRepository]] https://github.com/agentframework/agentframework\n- written-in: typescript\n- [[p.hasApplication]] [[t.cs.metaprogramming]] [[t.cs.simulation]]\n\n### Concepts\n\n| HUMAN | AGENT FRAMEWORK | DESCRIPTION |\n| --- | --- | --- |\n| People | Agent | A class decorate with @agent attribute |\n| Action | Behavior | Class method decorate with @action, @method or @behavior attribute |\n| Belief | Memory | Private class field decorated with @state, @remember, @memory attribute |\n| Environment | Domain | A container for agents, entities, services or artifacts |\n| Autonomy | Activation | Timer, scheduler which based on environment conditions |\n| Sociality | Message | Agent can communicate with other agent |\n| Mobility | Mobile Agent | An agent can move from domain to domain with their belief unchanged |\n\n### [](https://github.com/agentframework/agentframework#when-use-agent-framework)\n\n### Concepts\n\n| HUMAN | AGENT FRAMEWORK | DESCRIPTION |\n| --- | --- | --- |\n| People | Agent | A class decorate with @agent attribute |\n| Action | Behavior | Class method decorate with @action, @method or @behavior attribute |\n| Belief | Memory | Private class field decorated with @state, @remember, @memory attribute |\n| Environment | Domain | A container for agents, entities, services or artifacts |\n| Autonomy | Activation | Timer, scheduler which based on environment conditions |\n| Sociality | Message | Agent can communicate with other agent |\n| Mobility | Mobile Agent | An agent can move from domain to domain with their belief unchanged |\n\n### [](https://github.com/agentframework/agentframework#when-use-agent-framework)","n":0.067}}},{"i":4090,"$":{"0":{"v":"ACT-R","n":1},"1":{"v":"\n- [[c.software.cognitive-architecture]]\n- written-in:   [[t.cs.languages.lisp]]\n- [[p.hasSite]] http://act-r.psy.cmu.edu/\n- [[p.hasSense]]\n  - [[p.instanceOf]] [[Cognitive Architecture|t.cs.ai.cognitive-architecture]]\n  - a theory for simulating and understanding human cognition\n\n## Features\n\nACT-R’s main components are:\n\n    modules,\n    buffers,\n    pattern matcher.\n\nModules\n\nThere are two types of modules:\n\n    perceptual-motor modules, which take care of the interface with the real world (i.e., with a simulation of the real world), The most well-developed perceptual-motor modules in ACT-R are the visual and the manual modules.\n    memory modules.\n\nThere are two kinds of memory modules in ACT-R:\n\n    declarative memory , consisting of facts such as Washington, D.C. is the capital of United States, France is a country in Europe, or 2+3=5, and\n    procedural memory, made of productions. Productions represent knowledge about how we do things: for instance, knowledge about how to type the letter “Q” on a keyboard, about how to drive, or about how to perform addition.\n\nBuffers\n\nACT-R accesses its modules (except for the procedural-memory module) through buffers. For each module, a dedicated buffer serves as the interface with that module. The contents of the buffers at a given moment in time represents the state of ACT-R at that moment.\nPattern Matcher\n\nThe pattern matcher searches for a production that matches the current state of the buffers. Only one such production can be executed at a given moment. That production, when executed, can modify the buffers and thus change the state of the system. Thus, in ACT-R cognition unfolds as a succession of production firings.\n\nACT-R Structure\n\nACT-R is a hybrid cognitive architecture. Its symbolic structure is a production system; the subsymbolic structure is represented by a set of massively parallel processes that can be summarized by a number of mathematical equations. The subsymbolic equations control many of the symbolic processes. For instance, if several productions match the state of the buffers, a subsymbolic utility equation estimates the relative cost and benefit associated with each production and decides to select for execution the production with the highest utility. Similarly, whether (or how fast) a fact can be retrieved from declarative memory depends on subsymbolic retrieval equations, which take into account the context and the history of usage of that fact. Subsymbolic mechanisms are also responsible for most learning processes in ACT-R.","n":0.053}}},{"i":4091,"$":{"0":{"v":"5e Tools","n":0.707},"1":{"v":"\n- [[c.software.game-service.data]]\n- url: https://5e.tools\n- repo: https://github.com/5etools-mirror-1/5etools-mirror-1.github.io\n- #docs https://wiki.tercept.net/en/home\n- [[p.builtOn]] [[prdct.node]]\n- written-in: javascript\n- similar: [[prdct.5e-tools]] [[prdct.open5e]] [[prdct.dnd-5e-srd]] [[prdct.foundry.dnd5e]] [[prdct.5e-schema]] [[prdct.dnd5eapi]] ^vt5y8u6whgr9\n\n## Examples\n\nsource: https://github.com/5etools-mirror-2/5etools-mirror-2.github.io/blob/d16f8386835509b6cd3ff9dda9e07f4379e837c6/data/spells/foundry.json#L715\n\n```\n\t\t{\n\t\t\t\"name\": \"Melf's Acid Arrow\",\n\t\t\t\"source\": \"PHB\",\n\t\t\t\"system\": {\n\t\t\t\t\"damage.parts\": [\n\t\t\t\t\t[\n\t\t\t\t\t\t\"4d4[immediate]\",\n\t\t\t\t\t\t\"acid\"\n\t\t\t\t\t],\n\t\t\t\t\t[\n\t\t\t\t\t\t\"(@item.level)d4[end of turn]\",\n\t\t\t\t\t\t\"acid\"\n\t\t\t\t\t]\n\t\t\t\t],\n\t\t\t\t\"scaling.mode\": \"none\",\n\t\t\t\t\"scaling.formula\": \"\"\n\t\t\t}\n\t\t}\n```\n","n":0.177}}},{"i":4092,"$":{"0":{"v":"5e Schema","n":0.707},"1":{"v":"\n- dead since 2020\n- https://github.com/Swimminschrage/5e-schema\n![[prdct.5e-tools#^vt5y8u6whgr9]]","n":0.447}}},{"i":4093,"$":{"0":{"v":"3d Tiles","n":0.707},"1":{"v":"\n## Implementations\n\n## Resources\n\n### [[c.resource.list]]\n\n- https://github.com/pka/awesome-3d-tiles\n\n### Learning Resource\n\n- https://cesium.com/blog/2015/08/10/introducing-3d-tiles/","n":0.354}}},{"i":4094,"$":{"0":{"v":"Podcasts","n":1}}},{"i":4095,"$":{"0":{"v":"gtd podcast","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://soundcloud.com/user-697578497\n","n":0.577}}},{"i":4096,"$":{"0":{"v":"Gamecraft","n":1}}},{"i":4097,"$":{"0":{"v":"Predicates","n":1}}},{"i":4098,"$":{"0":{"v":"Slipped","n":1}}},{"i":4099,"$":{"0":{"v":"Away","n":1}}},{"i":4100,"$":{"0":{"v":"yelled","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n\n\n","n":0.577}}},{"i":4101,"$":{"0":{"v":"wrote","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4102,"$":{"0":{"v":"writtenIn","n":1},"1":{"v":"\n\n\n- [[p.hasRange]] [[c.language]]\n","n":0.577}}},{"i":4103,"$":{"0":{"v":"Wounded","n":1}}},{"i":4104,"$":{"0":{"v":"workedWith","n":1}}},{"i":4105,"$":{"0":{"v":"workedOn","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[p.did]]\n  - but excludes \n    - play\n    - passive activity\n","n":0.289}}},{"i":4106,"$":{"0":{"v":"workedFor","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] employed by\n- [[p.hasRange]] [[c.agent]]\n- [[p.hasDomain]] [[c.agent]]\n- [[p.equivalentPredicate]] [schema:worksFor](http://schema.org/worksFor)\n\n## [[hasComment]]\n\n- unlike `schema:worksFor`, this predicate captures, e.g.\n  - a bot working for a person\n  - #marginal organizations working for an animal\n  - #excludes being dedicated to an abstract cause \n","n":0.158}}},{"i":4107,"$":{"0":{"v":"Wore","n":1}}},{"i":4108,"$":{"0":{"v":"wondered","n":1},"1":{"v":"\n\nreal beat\n","n":0.707}}},{"i":4109,"$":{"0":{"v":"won","n":1}}},{"i":4110,"$":{"0":{"v":"Woke","n":1}}},{"i":4111,"$":{"0":{"v":"Wireframed","n":1}}},{"i":4112,"$":{"0":{"v":"whispered","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4113,"$":{"0":{"v":"wentTo","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4114,"$":{"0":{"v":"went","n":1}}},{"i":4115,"$":{"0":{"v":"welcomed","n":1},"1":{"v":"\n\n\n- vampires can't enter your home unless you welcome them in.\n","n":0.302}}},{"i":4116,"$":{"0":{"v":"watched","n":1}}},{"i":4117,"$":{"0":{"v":"wasTricked","n":1}}},{"i":4118,"$":{"0":{"v":"wasReminded","n":1}}},{"i":4119,"$":{"0":{"v":"wasNamespaceFor","n":1},"1":{"v":"\n#ontology #gd\n","n":0.707}}},{"i":4120,"$":{"0":{"v":"wasInspirationFor","n":1}}},{"i":4121,"$":{"0":{"v":"wasBuiltBy","n":1}}},{"i":4122,"$":{"0":{"v":"was","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4123,"$":{"0":{"v":"Wanted","n":1}}},{"i":4124,"$":{"0":{"v":"walked","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity \n","n":0.5}}},{"i":4125,"$":{"0":{"v":"vs","n":1}}},{"i":4126,"$":{"0":{"v":"visited","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4127,"$":{"0":{"v":"visitWith","n":1}}},{"i":4128,"$":{"0":{"v":"variantOf","n":1},"1":{"v":"\n\n- perhaps all the variants of a thing are members of a class, but\n- [[p.similarTo]] [[dendron://predicates/p.forkOf]]\n","n":0.25}}},{"i":4129,"$":{"0":{"v":"usedBy","n":1}}},{"i":4130,"$":{"0":{"v":"used","n":1}}},{"i":4131,"$":{"0":{"v":"upgraded","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4132,"$":{"0":{"v":"untied","n":1}}},{"i":4133,"$":{"0":{"v":"unsubscribedFrom","n":1}}},{"i":4134,"$":{"0":{"v":"unlocked","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4135,"$":{"0":{"v":"turned","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4136,"$":{"0":{"v":"triggered","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4137,"$":{"0":{"v":"tried","n":1}}},{"i":4138,"$":{"0":{"v":"triaged","n":1},"1":{"v":"\n\n\nassign degrees of urgency; \n\nalso has the alternate/mistaken sense of \"taking care of an urgent problem\n","n":0.25}}},{"i":4139,"$":{"0":{"v":"travelled","n":1}}},{"i":4140,"$":{"0":{"v":"transformedInto","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4141,"$":{"0":{"v":"Transferred","n":1}}},{"i":4142,"$":{"0":{"v":"tracked","n":1}}},{"i":4143,"$":{"0":{"v":"tore","n":1}}},{"i":4144,"$":{"0":{"v":"toppled","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4145,"$":{"0":{"v":"tookALongRest","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4146,"$":{"0":{"v":"took","n":1}}},{"i":4147,"$":{"0":{"v":"toldTheStoryOf","n":1}}},{"i":4148,"$":{"0":{"v":"told","n":1},"1":{"v":"\n- [[c.sphere]] #communication #epistemology\n","n":0.5}}},{"i":4149,"$":{"0":{"v":"tied","n":1}}},{"i":4150,"$":{"0":{"v":"threw","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4151,"$":{"0":{"v":"thought","n":1},"1":{"v":"\n- [[c.sphere]] #activity #epistemology\n","n":0.5}}},{"i":4152,"$":{"0":{"v":"tested","n":1},"1":{"v":"\n\n\n- [[c.usecase]]\n  - testing a door to see if it is locked\n","n":0.289}}},{"i":4153,"$":{"0":{"v":"teleported","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4154,"$":{"0":{"v":"telepathed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4155,"$":{"0":{"v":"Tasted","n":1},"1":{"v":"\n## Senses\n\n### Linking Verb\n\n### Activity","n":0.447}}},{"i":4156,"$":{"0":{"v":"talkedTo","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n- [[p.similarTo]] [[dendron://predicates/p.metWith]]\n  - to meet with someone implies\n    - pre-arrangement\n","n":0.277}}},{"i":4157,"$":{"0":{"v":"Talked","n":1}}},{"i":4158,"$":{"0":{"v":"takeCareOf","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4159,"$":{"0":{"v":"Tag For","n":0.707}}},{"i":4160,"$":{"0":{"v":"supports","n":1}}},{"i":4161,"$":{"0":{"v":"supportedBy","n":1}}},{"i":4162,"$":{"0":{"v":"supersededBy","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4163,"$":{"0":{"v":"summarized","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4164,"$":{"0":{"v":"suggested","n":1}}},{"i":4165,"$":{"0":{"v":"succeededBy","n":1}}},{"i":4166,"$":{"0":{"v":"subscribedTo","n":1},"1":{"v":"\n\n\nvoluntarily receiving something, usually on-the-regular, sometimes in exchange for money\n\n- [[p.subPredicateOf]] [[p.signedUpFor]]\n- [[c.sphere]] #activity\n","n":0.267}}},{"i":4167,"$":{"0":{"v":"subPredicateOf","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.pred]]\n- [[p.equivalentPredicate]] [rdfs:subPropertyOf](http://www.w3.org/2000/01/rdf-schema#subPropertyOf)\n","n":0.447}}},{"i":4168,"$":{"0":{"v":"subClassOf","n":1},"1":{"v":"\nThe subject is a subclass of the object. Often confused with `type`.\n\n- [[p.equivalentPredicate]] [rdfs:subClassOf](http://www.w3.org/2000/01/rdf-schema#subClassOf)\n- [[p.hasDomain]] [[c.class]]\n- [[p.hasRange]] [[c.class]]\n- [[c.sphere]] #ontological","n":0.224}}},{"i":4169,"$":{"0":{"v":"stumbled","n":1}}},{"i":4170,"$":{"0":{"v":"studied","n":1}}},{"i":4171,"$":{"0":{"v":"strode","n":1}}},{"i":4172,"$":{"0":{"v":"stood","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4173,"$":{"0":{"v":"stifled","n":1}}},{"i":4174,"$":{"0":{"v":"steppedOn","n":1}}},{"i":4175,"$":{"0":{"v":"stepped","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4176,"$":{"0":{"v":"startedToward","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4177,"$":{"0":{"v":"startedBy","n":1},"1":{"v":"\n\n\n- [[p.hasRange]] [[c.agent]]\n","n":0.577}}},{"i":4178,"$":{"0":{"v":"started","n":1},"1":{"v":"\n\n\n- [[p.inverseOf]] [[p.startedBy]]\n- [[c.sphere]] #activity\n","n":0.447}}},{"i":4179,"$":{"0":{"v":"staked","n":1}}},{"i":4180,"$":{"0":{"v":"squinted","n":1}}},{"i":4181,"$":{"0":{"v":"squeezed","n":1}}},{"i":4182,"$":{"0":{"v":"spun","n":1},"1":{"v":"- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4183,"$":{"0":{"v":"spokeWith","n":1}}},{"i":4184,"$":{"0":{"v":"spilled","n":1}}},{"i":4185,"$":{"0":{"v":"spikedInto","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] spike into\n- [[c.sphere]] #activity\n- [[p.hasSource]] https://www.visual-paradigm.com/scrum/what-is-scrum-spike/\n","n":0.354}}},{"i":4186,"$":{"0":{"v":"sounded","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4187,"$":{"0":{"v":"solvesProblem","n":1},"1":{"v":"\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4188,"$":{"0":{"v":"snuffled","n":1}}},{"i":4189,"$":{"0":{"v":"snuckUp","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4190,"$":{"0":{"v":"snuckBy","n":1}}},{"i":4191,"$":{"0":{"v":"Smelled","n":1},"1":{"v":"\n## Senses\n\n### Linking Verb\n\n### Activity","n":0.447}}},{"i":4192,"$":{"0":{"v":"slid","n":1}}},{"i":4193,"$":{"0":{"v":"slept","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity #shapow\n","n":0.5}}},{"i":4194,"$":{"0":{"v":"slapped","n":1}}},{"i":4195,"$":{"0":{"v":"skimmed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity #discursive\n","n":0.5}}},{"i":4196,"$":{"0":{"v":"sisterOf","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4197,"$":{"0":{"v":"similarTo","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] is similar to, is like\n- [[p.instanceOf]] [[c.pred]]\n- [[p.equivalentPredicate]] [[schema:isSimilarTo|http://schema.org/isSimilarTo]] [[dbo:similar|http://dbpedia.org/ontology/similar]]\n- [[p.subPredicateOf]] [[p.vs]]\n","n":0.267}}},{"i":4198,"$":{"0":{"v":"similarReferentTo","n":1}}},{"i":4199,"$":{"0":{"v":"signedUpFor","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] created account for, volunteered for\n- [[c.sphere]] #activity\n","n":0.333}}},{"i":4200,"$":{"0":{"v":"shuttered","n":1}}},{"i":4201,"$":{"0":{"v":"shrieked","n":1}}},{"i":4202,"$":{"0":{"v":"showed","n":1}}},{"i":4203,"$":{"0":{"v":"shot","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4204,"$":{"0":{"v":"shadow-stepped","n":1}}},{"i":4205,"$":{"0":{"v":"sewed","n":1}}},{"i":4206,"$":{"0":{"v":"setUp","n":1},"1":{"v":"\n\n\n\n- do an initial configuration of something\n- [[p.vs]] [[dendron://predicates/p.preparedFor]]\n  - object of preparedFor is an event\n","n":0.25}}},{"i":4207,"$":{"0":{"v":"sent","n":1}}},{"i":4208,"$":{"0":{"v":"sensed","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4209,"$":{"0":{"v":"searched","n":1},"1":{"v":"\n\n- can take as objects\n  - optional: something, e.g. the cupboard\n    - optional: \"near\", \"on\", \n  - optional: \"for\" something, e.g. an envelope\n  - optional: \"with\" something, e.g. a magnifying glass\n  - ","n":0.177}}},{"i":4210,"$":{"0":{"v":"screamed","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4211,"$":{"0":{"v":"sawUnplannedActivity","n":1},"1":{"v":"\n\n\ncoupled with [[p.sawPlannedActivity]], can help replace \"sawActivity\" if everything is either planned or unplanned\n","n":0.267}}},{"i":4212,"$":{"0":{"v":"sawPlannedActivity","n":1}}},{"i":4213,"$":{"0":{"v":"sawLeaning","n":1}}},{"i":4214,"$":{"0":{"v":"sawEvent","n":1}}},{"i":4215,"$":{"0":{"v":"sawActivity","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.timeperiod]]\n\n- a time-period can be said to have seen happenings\n  - [[p.hasSource]]\n    - [personification of a time period](https://www.reddit.com/r/grammar/comments/g69d1t/is_the_use_of_the_word_saw_to_describe_casualties/)\n- [c] maybe delete, had is adequate\n  - t.2023.04.08 Yep, had is actually excessive, just use `c.Activity`","n":0.167}}},{"i":4216,"$":{"0":{"v":"saw","n":1}}},{"i":4217,"$":{"0":{"v":"saved","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4218,"$":{"0":{"v":"sat","n":1}}},{"i":4219,"$":{"0":{"v":"said","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity #communication\n","n":0.5}}},{"i":4220,"$":{"0":{"v":"rose","n":1}}},{"i":4221,"$":{"0":{"v":"rode","n":1}}},{"i":4222,"$":{"0":{"v":"rise","n":1}}},{"i":4223,"$":{"0":{"v":"ripped","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4224,"$":{"0":{"v":"revoked","n":1},"1":{"v":"\n\n\n\nfor permissions\n","n":0.707}}},{"i":4225,"$":{"0":{"v":"revisited","n":1}}},{"i":4226,"$":{"0":{"v":"revised","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4227,"$":{"0":{"v":"reviewed","n":1}}},{"i":4228,"$":{"0":{"v":"reunited","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4229,"$":{"0":{"v":"returned","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n- [-] add sequence diagram with conditions, ie. #temporal-logic\n \n","n":0.289}}},{"i":4230,"$":{"0":{"v":"retrieved","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4231,"$":{"0":{"v":"retreated","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4232,"$":{"0":{"v":"restrained","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4233,"$":{"0":{"v":"researched","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[p.spikedInto]]\n","n":0.577}}},{"i":4234,"$":{"0":{"v":"requested","n":1}}},{"i":4235,"$":{"0":{"v":"represented","n":1}}},{"i":4236,"$":{"0":{"v":"reported","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4237,"$":{"0":{"v":"renewed","n":1}}},{"i":4238,"$":{"0":{"v":"rended","n":1}}},{"i":4239,"$":{"0":{"v":"renamedTo","n":1}}},{"i":4240,"$":{"0":{"v":"removed","n":1},"1":{"v":"\n- - [[c.sphere]] #shapow","n":0.5}}},{"i":4241,"$":{"0":{"v":"remembered","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4242,"$":{"0":{"v":"refutes","n":1},"1":{"v":"\n\n\n[[c.sphere]] #activity #discursive\n","n":0.577}}},{"i":4243,"$":{"0":{"v":"reflects","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #discursive #metaphoric\n- [[p.hasSense]]\n  - shows the truth in something related\n","n":0.289}}},{"i":4244,"$":{"0":{"v":"referredFrom","n":1}}},{"i":4245,"$":{"0":{"v":"references","n":1},"1":{"v":"\n\nThe object resource is referenced, cited, or otherwise pointed to by the described resource.\n\n- [[p.equivalentPredicate]] [dcterms:references](http://purl.org/dc/terms/references)\n","n":0.25}}},{"i":4246,"$":{"0":{"v":"refactored","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4247,"$":{"0":{"v":"rediscovered","n":1}}},{"i":4248,"$":{"0":{"v":"reconfigured","n":1},"1":{"v":"\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4249,"$":{"0":{"v":"recommendedBy","n":1}}},{"i":4250,"$":{"0":{"v":"recommended","n":1}}},{"i":4251,"$":{"0":{"v":"recognized","n":1}}},{"i":4252,"$":{"0":{"v":"recharged","n":1},"1":{"v":"\n\n\n- [[p.hasSense]]\n  - add potential energy to a battery-powered device\n  - animal revitalization via rest, sleep, vacation\n","n":0.243}}},{"i":4253,"$":{"0":{"v":"realized","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #mental\n","n":0.577}}},{"i":4254,"$":{"0":{"v":"read","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n- [[p.hasRange]] [[c.creativework]]\n","n":0.447}}},{"i":4255,"$":{"0":{"v":"reactivated","n":1}}},{"i":4256,"$":{"0":{"v":"reached","n":1}}},{"i":4257,"$":{"0":{"v":"ran","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4258,"$":{"0":{"v":"raised","n":1}}},{"i":4259,"$":{"0":{"v":"raged","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4260,"$":{"0":{"v":"put","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4261,"$":{"0":{"v":"pushed","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4262,"$":{"0":{"v":"purchasedOn","n":1}}},{"i":4263,"$":{"0":{"v":"punched","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4264,"$":{"0":{"v":"pulsed","n":1}}},{"i":4265,"$":{"0":{"v":"pulled","n":1}}},{"i":4266,"$":{"0":{"v":"publishedBy","n":1}}},{"i":4267,"$":{"0":{"v":"published","n":1}}},{"i":4268,"$":{"0":{"v":"provokedThoughts","n":1},"1":{"v":"\n\n\n\nIf it's not thought-provoking, what's the use?\n","n":0.378}}},{"i":4269,"$":{"0":{"v":"providesCapability","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[p.hasFeature]]\n\n## Thoughts\n\n- original problem: how to categorize a solution as \"addressing\" the problem/opportunity of authentication? \n  - [nist glossary](https://csrc.nist.gov/glossary?keywords-lg=capability&sortBy-lg=relevance&ipp-lg=100) lists a bunch of great types of (ISCM) capabilities\n","n":0.183}}},{"i":4270,"$":{"0":{"v":"providedBy","n":1}}},{"i":4271,"$":{"0":{"v":"provided","n":1},"1":{"v":"\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4272,"$":{"0":{"v":"proposedSolution","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4273,"$":{"0":{"v":"produced","n":1},"1":{"v":"\n[[p.hadDefinition]]\n- bring forth an item\n- facilitate an event or a work","n":0.302}}},{"i":4274,"$":{"0":{"v":"proceeded","n":1}}},{"i":4275,"$":{"0":{"v":"probed","n":1}}},{"i":4276,"$":{"0":{"v":"presented","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity #product-management\n","n":0.5}}},{"i":4277,"$":{"0":{"v":"preparedFor","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n- [[p.hasRange]] [[c.event]]\n","n":0.447}}},{"i":4278,"$":{"0":{"v":"pleased","n":1},"1":{"v":"\n\n\n[[p.alsoKnownAs]] contented\n","n":0.707}}},{"i":4279,"$":{"0":{"v":"played","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n- [[p.hasRange]] [[c.game]] [[c.computergame]]\n\n","n":0.408}}},{"i":4280,"$":{"0":{"v":"planned","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4281,"$":{"0":{"v":"pickedUp","n":1}}},{"i":4282,"$":{"0":{"v":"perceived","n":1}}},{"i":4283,"$":{"0":{"v":"peeked","n":1}}},{"i":4284,"$":{"0":{"v":"paused","n":1}}},{"i":4285,"$":{"0":{"v":"patched","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n- [[p.vs]] \n  -  `updated` \n     -  might be more general, but that's overloaded in [[prdct.yaml.frontmatter]]\n  -  [[p.upgraded]]\n     -  patch is more transparent (i.e., fixing a bug, closing a security hole)\n  \n\n","n":0.171}}},{"i":4286,"$":{"0":{"v":"partOf","n":1}}},{"i":4287,"$":{"0":{"v":"panicked","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4288,"$":{"0":{"v":"paid","n":1},"1":{"v":"\n\n\n\nmoney give money money money\n","n":0.447}}},{"i":4289,"$":{"0":{"v":"ownedBy","n":1},"1":{"v":"\n\n\n- [[p.hasSense]] property rights\n- [[p.hasSense]] responsibility for\n","n":0.378}}},{"i":4290,"$":{"0":{"v":"overlapsWith","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #conceptual\n","n":0.577}}},{"i":4291,"$":{"0":{"v":"organizedBy","n":1}}},{"i":4292,"$":{"0":{"v":"ordered","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n- [[p.hasSense]]\n  - direct somebody (to do something)\n  - purchase something (for later delivery)\n","n":0.25}}},{"i":4293,"$":{"0":{"v":"openedIssue","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4294,"$":{"0":{"v":"opened","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow #activity\n\n","n":0.5}}},{"i":4295,"$":{"0":{"v":"onboarded","n":1}}},{"i":4296,"$":{"0":{"v":"offboarded","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4297,"$":{"0":{"v":"noticed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow \n","n":0.5}}},{"i":4298,"$":{"0":{"v":"needsApprisalOf","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[Agents]]\n- maybe replace with `mightBenefitFromKnowing` \n","n":0.354}}},{"i":4299,"$":{"0":{"v":"muttered","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4300,"$":{"0":{"v":"moved towards","n":0.707}}},{"i":4301,"$":{"0":{"v":"movedTo","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4302,"$":{"0":{"v":"moved","n":1},"1":{"v":"\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4303,"$":{"0":{"v":"mounted","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4304,"$":{"0":{"v":"motioned","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4305,"$":{"0":{"v":"mitigatedBy","n":1}}},{"i":4306,"$":{"0":{"v":"migrated","n":1}}},{"i":4307,"$":{"0":{"v":"metWith","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n- [[p.hasRange]] [[c.agent]]\n","n":0.447}}},{"i":4308,"$":{"0":{"v":"messedUp","n":1}}},{"i":4309,"$":{"0":{"v":"mentionedOn","n":1}}},{"i":4310,"$":{"0":{"v":"mentioned","n":1}}},{"i":4311,"$":{"0":{"v":"memberOf","n":1},"1":{"v":"- [[c.sphere]] #shapow\n- part of a group","n":0.378}}},{"i":4312,"$":{"0":{"v":"meditated","n":1}}},{"i":4313,"$":{"0":{"v":"managedDomainNames","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4314,"$":{"0":{"v":"managed","n":1}}},{"i":4315,"$":{"0":{"v":"makesDebatableClaim","n":1},"1":{"v":"\n\n\nmore important than highlights: point of contention\n","n":0.378}}},{"i":4316,"$":{"0":{"v":"madeProgress","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4317,"$":{"0":{"v":"madeOffer","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #negotiation\n\n","n":0.577}}},{"i":4318,"$":{"0":{"v":"madeComment","n":1},"1":{"v":"\n\n\n\n- [[p.hasDomain]] [[c.agent]]\n","n":0.577}}},{"i":4319,"$":{"0":{"v":"made","n":1},"1":{"v":"\n\n- [[p.hasPresentTenseForm]] make","n":0.577}}},{"i":4320,"$":{"0":{"v":"lostConsciousness","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4321,"$":{"0":{"v":"looked out of","n":0.577},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4322,"$":{"0":{"v":"lookedFor","n":1}}},{"i":4323,"$":{"0":{"v":"looked at","n":0.707}}},{"i":4324,"$":{"0":{"v":"looked","n":1}}},{"i":4325,"$":{"0":{"v":"locked","n":1}}},{"i":4326,"$":{"0":{"v":"listened","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n- [[p.hasRange]] [[c.creativework]] [[c.agent]]\n","n":0.408}}},{"i":4327,"$":{"0":{"v":"linkedTo","n":1}}},{"i":4328,"$":{"0":{"v":"left","n":1}}},{"i":4329,"$":{"0":{"v":"led","n":1}}},{"i":4330,"$":{"0":{"v":"learned","n":1}}},{"i":4331,"$":{"0":{"v":"landed","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4332,"$":{"0":{"v":"knocked","n":1}}},{"i":4333,"$":{"0":{"v":"killed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4334,"$":{"0":{"v":"kicked","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4335,"$":{"0":{"v":"jumped","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4336,"$":{"0":{"v":"jumped over","n":0.707}}},{"i":4337,"$":{"0":{"v":"joinedWaitlist","n":1}}},{"i":4338,"$":{"0":{"v":"joinedCommunity","n":1},"1":{"v":"\n\n- [[c.sphere]] #community\n- [[p.hasObject]] [[c.community]]\n- [[p.hasSubject]] [[c.agent]]\n","n":0.378}}},{"i":4339,"$":{"0":{"v":"joined","n":1},"1":{"v":"- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4340,"$":{"0":{"v":"jammed","n":1}}},{"i":4341,"$":{"0":{"v":"isTopicOfDiscussion","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #discursive\n","n":0.577}}},{"i":4342,"$":{"0":{"v":"isThemeOf","n":1},"1":{"v":"\n\n\n- inverseOf [[p.hasTheme]]\n","n":0.577}}},{"i":4343,"$":{"0":{"v":"isRelated","n":1},"1":{"v":"\n\n\n- #conceptual\n\n- isn't every predicate?\n  - should have something for unrelated ! ;)\n  - although unrelated is a self-negating relationship\n\n[[p.equivalentPredicate]] schema:isRelatedTo, dbo:related \n","n":0.209}}},{"i":4344,"$":{"0":{"v":"isPortOf","n":1},"1":{"v":"\n\n\n- [[p.hasRange]]\n  - [[c.solution]]\n  - [[c.solution]] to [[c.software.platform]]  ^EMM3VT4uZhW2\n","n":0.333}}},{"i":4345,"$":{"0":{"v":"isHighlightOf","n":1},"1":{"v":"\n\n\n- [[p.inverseOf]] [[p.hasHighlight]]\n","n":0.577}}},{"i":4346,"$":{"0":{"v":"isCounterIndicatedFor","n":1},"1":{"v":"\n \n\n- maybe better is anti-recommend\n","n":0.408}}},{"i":4347,"$":{"0":{"v":"isComponentOf","n":1},"1":{"v":"\n- [[c.sphere]] #product-management\n- [[p.inverseOf]] [[p.hasComponent]]\n","n":0.447}}},{"i":4348,"$":{"0":{"v":"isComparandOf","n":1},"1":{"v":"\n\n\n\n- [[p.hasRange]] [[c.comparison]] \n","n":0.5}}},{"i":4349,"$":{"0":{"v":"invoked","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4350,"$":{"0":{"v":"investigated","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4351,"$":{"0":{"v":"inverseOf","n":1},"1":{"v":"\n\n\n- [[p.equivalentPredicate]] [owl:inverseOf](http://www.w3.org/2002/07/owl#inverseOf) ?\n","n":0.5}}},{"i":4352,"$":{"0":{"v":"invented","n":1}}},{"i":4353,"$":{"0":{"v":"interviewed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4354,"$":{"0":{"v":"interestedIn","n":1}}},{"i":4355,"$":{"0":{"v":"intendedToHave","n":1}}},{"i":4356,"$":{"0":{"v":"intendedTo","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #mental\n- [[p.hasDomain]] [[c.agent]]\n- [[p.hasRange]] [[c.predicates]] \n- [[p.vs]] [[p.planned]]\n  - sure, you can plan your day but\n    - I also want to be able to say when I'm doing actual planning, i.e., creating a plan to do a specific task\n    - planning can involve more than intention; it can involve actual preparation (making reservations), sequencing, delegation\n    - ultimately, plan your day is colloquial\n","n":0.125}}},{"i":4357,"$":{"0":{"v":"intendTo","n":1}}},{"i":4358,"$":{"0":{"v":"integratesWith","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] works with;\n- [[p.hasDomain]] [[c.solution]]\n- [[p.hasRange]] [[c.solution]]\n- [[p.instanceOf]] [[c.pred]] \n","n":0.302}}},{"i":4359,"$":{"0":{"v":"instanceOf","n":1},"1":{"v":"\n#ontology\n\n- [[p.alsoKnownAs]] isA, is a, is an instance of the class\n- [[p.hasDomain]] resources: \n- [[p.hasRange]] [[c.class]]\n- [[p.equivalentPredicate]] [rdf:type](http://www.w3.org/1999/02/22-rdf-syntax-ns#type)\n- [[p.inverseOf]] ???\n  - [-] important thing to have a name for, maybe \"hasInstance\"  or classOf\n    - maybe not so important, when do classes need to refer to their instances? backlinks provides inventory \n  - sometimes things (topics primarily/only) can be classes, without being Classes.\n  \n  \n## instanceOf Discussion\n\n- changed because \n  - \"instanceOf\" underscores that the subject is not a Class\n    - t.2024.03.18.16 unless it's an instanceOf a class\n  - it feels like, colloquially, \"type\" is ambiguous between hasType and isTypeOf; the latter can mean  something more like subClassOf\n- isA is nice and compact, but maybe feels ambiguous for classes, e.g. \"[a] digital garden is a website\" \n- https://stackoverflow.com/questions/25737584/subclassof-and-instance-of-rdf-rdfsclass\n\n## log\n\n- [x] #gd replace all in-Class occurences of instanceOf that have Class subjects with subClassOf\n  t.2022.12.12 there was only one... [[c.dsl]]","n":0.082}}},{"i":4360,"$":{"0":{"v":"installed","n":1}}},{"i":4361,"$":{"0":{"v":"inspiredBy","n":1},"1":{"v":"\n\n\n- subjective to state what inspires others, maybe \"seemsInspiredBy\" is better\n","n":0.302}}},{"i":4362,"$":{"0":{"v":"informed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4363,"$":{"0":{"v":"included","n":1}}},{"i":4364,"$":{"0":{"v":"improved","n":1},"1":{"v":"\n\n\n\nleave it better than you found it\n\n- [[c.sphere]] #activity\n","n":0.333}}},{"i":4365,"$":{"0":{"v":"implements","n":1},"1":{"v":"\n\n\n- [[p.inverseOf]] [[p.implements]]\n- [[c.sphere]] #product-management\n- [[p.decided]] to use \"instanceOf\" for ACT-R's relationship to `t.cs.ai.cognitive-architecture` \n","n":0.258}}},{"i":4366,"$":{"0":{"v":"illustrated","n":1}}},{"i":4367,"$":{"0":{"v":"hunkeredDown","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4368,"$":{"0":{"v":"hugged","n":1}}},{"i":4369,"$":{"0":{"v":"hostedOn","n":1}}},{"i":4370,"$":{"0":{"v":"hostedBy","n":1}}},{"i":4371,"$":{"0":{"v":"hitBy","n":1}}},{"i":4372,"$":{"0":{"v":"hit","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4373,"$":{"0":{"v":"heard","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4374,"$":{"0":{"v":"headed","n":1}}},{"i":4375,"$":{"0":{"v":"hasWishList","n":1}}},{"i":4376,"$":{"0":{"v":"hasVision","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management #conceptual\n","n":0.5}}},{"i":4377,"$":{"0":{"v":"hasVariant","n":1}}},{"i":4378,"$":{"0":{"v":"hasValidityStart","n":1},"1":{"v":"\n\n\n- [[c.usecase]] you think there's a \"first\" `hasValidityPoint`\n","n":0.354}}},{"i":4379,"$":{"0":{"v":"hasValidityPoint","n":1},"1":{"v":"\n\n\n\n- [[p.isRelated]] [[dendron://predicates/p.hasValidityStart]]; [[dendron://predicates/p.hasValidityPeriod]]\n","n":0.5}}},{"i":4380,"$":{"0":{"v":"hasValidityPeriod","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.statement]]\n- [[p.hasRange]] [[c.timeperiod]]\n\n## Notes\n\n- until there's a standard for expressing \"infinite interval boundaries\", I'm just going to follow @Meno-Hochschild and [use a \"double dot\" on either side of the solidus](https://stackoverflow.com/questions/48696238/is-it-possible-to-represent-and-open-ended-time-interval-with-iso-8601)\n- of course, if there's only a single date-fragment, you can assume that's the start time, and end time is either open or unknown\n- it we be nice to be able to express \"validity until at least\" and \"validity since at least\", maybe can be captured nicely with \"hasValidityPoint\"\n- kinda need \"hasInvalidityPeriod\" and \"hasInvalidityPoint\" too\n","n":0.108}}},{"i":4381,"$":{"0":{"v":"hasUseCase","n":1},"1":{"v":"\n\n\n- [[p.hasRange]] [[c.usecase]]\n- [[p.subPredicateOf]] [[p.hasApplication]]\n","n":0.447}}},{"i":4382,"$":{"0":{"v":"hasURL","n":1},"1":{"v":"\n- [[p.alsoKnownAs]] is associated with URL; webpage; URL;\n- [[p.equivalentPredicate]] [vcard:hasURL](http://www.w3.org/2006/vcard/ns#hasURL)\n\n## use of \"URL\"\n\n### [[p.vs]] URI\n\n- [What's the Difference Between a URI and a URL?](https://danielmiessler.com/study/difference-between-uri-url/) :\n  - \"If the protocol (https, ftp, etc.) is either present or implied for a domain, you should call it a URL—even though it’s also a URI.\"\n\n- the terms URI and IRI might represent more general and accessible concepts, but\n\n### [[p.vs]] site\n\n- [c] better to use [[p.hasSite]] when appropriate? \n  - t.2023.04.08 Why? You can probably tell from the URL whether there's a site to back things up. keep it simple\n\n## possible alternatives\n\n## [[p.vs]] [[vcard:url]]\n\n- url is shorter than hasUrl\n- hasUrl probably reads better\n\n## [[p.vs]] `foaf.homepage` \n\n\"Has URL\" is like `foaf.homepage`, but homepage (in the sense of a personal web site) feels almost antiquated. \n\n### \"homepage\" [[p.hasSense]] \n\n- the \"first page you go to on a site\",\n  - i.e. the high-effort page nobody sees any more\n- the browser home page\n\n##  [[p.vs]] identifier\n\n- [Data Model - schema.org](https://schema.org/docs/datamodel.html#identifierBg)\n  - \"in most cases there is a conventional short name for most identifier schemes\"\n  - unrelated: \"we do not treat isicV4 as a subproperty of identifier since it serves to identify a category not an individual Thing\" -- categories need identifiers too!\n    - [2021-10-20] I think what I meant here was \"categories are things too\"\n\n\n\n\n\n","n":0.068}}},{"i":4383,"$":{"0":{"v":"hasTraining","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.solution]]\n- [[c.sphere]] #product-management\n- [[p.similarTo]] [[p.hasLearningResource]]\n","n":0.378}}},{"i":4384,"$":{"0":{"v":"hasTopic","n":1},"1":{"v":"\n\n\nA subject you write or speak about.\n\n## Thoughts\n\n- \"subject\" is already overloaded in the RDF world\n  - of course \"object\" is overloaded too, with the sense of an objective is a goal\n\n## Quotes\n\n- > [A topic defines a particular aspect that will be covered in conversation or in any written form, whereas subject is used in context to a wider aspect of knowledge. A subject cannot be a part of a topic whereas a subject may have many topics covered in it. However, topic and subject may be used interchangeably if they are used to denote the important aspect of a document, lecture, discussion, presentation or a conversation.][1] \n  - this sort of captures a hierarchical relationship that feels substantial, but due to overloading and wikipedia's preference for \"topic\" even for very general categories, probably will \"smooth over\" the substance\n\n## Resources\n- [[vs.topic-vs-subject]]\n- https://en.wikipedia.org/wiki/Wikipedia:Version_1.0_Editorial_Team/Core_topics\n- https://en.wikipedia.org/wiki/Wikipedia:Core_topics,_inner_levels\n\n## References\n\n- [1]: http://www.speakupcroatia.com/topic-vs-subject-vs-theme/ \"“Topic” VS “subject” VS “theme”\"\n","n":0.081}}},{"i":4385,"$":{"0":{"v":"hasTheme","n":1},"1":{"v":"\n\n\nA general topic of the resource.\n","n":0.408}}},{"i":4386,"$":{"0":{"v":"hasSummaryPoints","n":1}}},{"i":4387,"$":{"0":{"v":"hasSubject","n":1},"1":{"v":"\n\n\nI've avoided this because of the supposed ambiguity between \"main topic\" and the thing you're making a statement about, but maybe they're close enough to being the same thing \n","n":0.183}}},{"i":4388,"$":{"0":{"v":"hasSubClass","n":1},"1":{"v":"\n\nset up your Class hierarchy\n\n- [[p.inverseOf]] [[p.subClassOf]]\n- [[p.vs]] ebucore:hasType\n  - `hasType` is more concise but [[vs.class-vs-type-vs-category]]\n## Examples\n\n- dog isSubClass animal\n  - same as dog hasSuperClass animal\n","n":0.196}}},{"i":4389,"$":{"0":{"v":"hasSpouse","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #familial\n","n":0.577}}},{"i":4390,"$":{"0":{"v":"hasSpecification","n":1},"1":{"v":"\n\n\n- [[p.hasRange]] [[c.specification]]\n","n":0.577}}},{"i":4391,"$":{"0":{"v":"hasSource","n":1},"1":{"v":"\n\n\n- [[p.equivalentPredicate]] http://www.w3.org/ns/oa#hasSource\n- [[p.similarTo]] [[p.hasCitation]]\n","n":0.447}}},{"i":4392,"$":{"0":{"v":"hasSon","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #familial\n","n":0.577}}},{"i":4393,"$":{"0":{"v":"hasSolution","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4394,"$":{"0":{"v":"hasSite","n":1},"1":{"v":"\n\n\n- [[p.hasRange]] [[c.website]]\n- the subject [[c.agent]] or [[c.topic]] has a set of web pages:\n  - about itself and/or\n  - [[p.ownedBy]] or [[p.controlledBy]] by itself\n","n":0.204}}},{"i":4395,"$":{"0":{"v":"hasSisterPublication","n":1},"1":{"v":"\n\n\n- more prevalent than \"sibling publication\"\n","n":0.408}}},{"i":4396,"$":{"0":{"v":"hasSense","n":1},"1":{"v":"\n\n\nused for disambiguation\n\n## Resources\n\n- https://en.wikipedia.org/wiki/Sense_and_reference\n","n":0.447}}},{"i":4397,"$":{"0":{"v":"hasScriptingLanguage","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4398,"$":{"0":{"v":"hasScreenShot","n":1}}},{"i":4399,"$":{"0":{"v":"hasSample","n":1},"1":{"v":"\n\n\n\na multi-use predicate... could refer to a randomized sampling of a dataset or satistical distribution, or a \"free chapter\" from a book\n","n":0.213}}},{"i":4400,"$":{"0":{"v":"hasSameReferantAs","n":1},"1":{"v":"\n\n\n- for notes that refer to things, this predicate references other notes or resources with at least nearly-identical referents.\n- [[p.vs]] [[p.similarReferentTo]] \n","n":0.213}}},{"i":4401,"$":{"0":{"v":"hasRoadmapFeature","n":1},"1":{"v":"\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4402,"$":{"0":{"v":"hasReview","n":1}}},{"i":4403,"$":{"0":{"v":"hasRepository","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.solution]] [[prdct]] [[c.organization]] [[c.community]]\n\nstorage for code and other data that uses a version control protocol like Git or SVN\n","n":0.218}}},{"i":4404,"$":{"0":{"v":"hasRelatedTopic","n":1},"1":{"v":"\n\n- only stories/articles/etc have topics, but things like solutions or organizations can be related to topics\n  - could use `isRelated` but some specificity is nice","n":0.2}}},{"i":4405,"$":{"0":{"v":"hasRelatedSolution","n":1}}},{"i":4406,"$":{"0":{"v":"hasRecurrence","n":1},"1":{"v":"\n- [[c.sphere]] #temporal\n   \n","n":0.5}}},{"i":4407,"$":{"0":{"v":"hasRecording","n":1}}},{"i":4408,"$":{"0":{"v":"hasRecipe","n":1},"1":{"v":"\n\n\n\nnot just for food/drinks or chef. A recipe is kinda like a [[c.usecase]]\n","n":0.277}}},{"i":4409,"$":{"0":{"v":"hasRange","n":1},"1":{"v":"\n\n\nThe Range is the set of Classes that can be the objects of a statement\n\n- [[p.equivalentPredicate]] [rdfs:range](http://www.w3.org/2000/01/rdf-schema#range)\n- [[p.hasDomain]] [[c.predicates]]\n","n":0.229}}},{"i":4410,"$":{"0":{"v":"hasPro","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] has pros, has advanatages, has benefits\n- [[p.similarReferentTo]] [[p.hasFeature]]\n- [[p.hasContext]]  \n","n":0.289}}},{"i":4411,"$":{"0":{"v":"hasPrinciple","n":1}}},{"i":4412,"$":{"0":{"v":"hasPresentTenseForm","n":1}}},{"i":4413,"$":{"0":{"v":"hasPart","n":1},"1":{"v":"\n\n\ncould have inverse of `partOf`\n","n":0.447}}},{"i":4414,"$":{"0":{"v":"hasParaphrase","n":1}}},{"i":4415,"$":{"0":{"v":"hasOptions","n":1}}},{"i":4416,"$":{"0":{"v":"hasObject","n":1},"1":{"v":"\n\n- [[c.sphere]] #discursive\n","n":0.577}}},{"i":4417,"$":{"0":{"v":"hasNoSupportFor","n":1}}},{"i":4418,"$":{"0":{"v":"hasModelNumber","n":1}}},{"i":4419,"$":{"0":{"v":"hasMetaphor","n":1}}},{"i":4420,"$":{"0":{"v":"hasMemorableUtterance","n":1}}},{"i":4421,"$":{"0":{"v":"hasLog","n":1}}},{"i":4422,"$":{"0":{"v":"hasLearningResource","n":1},"1":{"v":"\n\n\ncoursework, examples, articles\n\n- [[p.vs]] [[dendron://predicates/p.hasTraining]]\n  - training implies more structure, guidance, exercises, test\n","n":0.277}}},{"i":4423,"$":{"0":{"v":"hasLayers","n":1}}},{"i":4424,"$":{"0":{"v":"hasJustification","n":1},"1":{"v":"\n#product-management\n\n[[t.pdm.design]] choices should be justified","n":0.447}}},{"i":4425,"$":{"0":{"v":"hasIssue","n":1},"1":{"v":"\n\n\nIf you care about the solution, unreported issues get reported.\n\n- [[p.alsoKnownAs]] has issues, problems, challenges. \n- [[c.sphere]] #product-management\n  \n","n":0.229}}},{"i":4426,"$":{"0":{"v":"hasInventoryURL","n":1}}},{"i":4427,"$":{"0":{"v":"hasInstance","n":1}}},{"i":4428,"$":{"0":{"v":"hasInitiative","n":1},"1":{"v":"\n\n\n\ntheme > initiative > epic > story\n","n":0.378}}},{"i":4429,"$":{"0":{"v":"hasImplementation","n":1},"1":{"v":"\n\n\n- [[p.inverseOf]] [[p.implements]]\n- [[c.sphere]] #product-management\n","n":0.447}}},{"i":4430,"$":{"0":{"v":"hasIdentifier","n":1},"1":{"v":"\n\n\n- [[p.equivalentPredicate]] dcterms.identifier\n","n":0.577}}},{"i":4431,"$":{"0":{"v":"hasHighlightCollection","n":1}}},{"i":4432,"$":{"0":{"v":"hasHighlight","n":1},"1":{"v":"\n\npicking out the best parts is subjective\n","n":0.378}}},{"i":4433,"$":{"0":{"v":"hasGenre","n":1}}},{"i":4434,"$":{"0":{"v":"hasFormat","n":1},"1":{"v":"\n\n\n- [[p.hasRange]] [[c.application]]\n","n":0.577}}},{"i":4435,"$":{"0":{"v":"hasFeature","n":1},"1":{"v":"\n- [[p.hasDomain]] [[c.capability]] [[c.solution]]\n- [[p.hasRange]] [[c.feature]]\n\nRelates a product, capability, or solution with a property or piece of functionality, usually that provides a benefit.\n\n","n":0.209}}},{"i":4436,"$":{"0":{"v":"hasExtensionMechanism","n":1},"1":{"v":"\n\n- [[c.sphere]] #product-management\n\n","n":0.577}}},{"i":4437,"$":{"0":{"v":"hasExtension","n":1},"1":{"v":"\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4438,"$":{"0":{"v":"hasExpertise","n":1}}},{"i":4439,"$":{"0":{"v":"hasExceptions","n":1}}},{"i":4440,"$":{"0":{"v":"hasExampleList","n":1},"1":{"v":"\n## [[p.hasExample]]\n\n- https://forum.effectivealtruism.org/posts/bbtvDJtb6YwwWtJm7/epistemic-status-an-explainer-and-some-thoughts","n":0.577}}},{"i":4441,"$":{"0":{"v":"examples","n":1},"1":{"v":"\n\n\n- [[p.equivalentPredicate]] skos.example\n\n\n","n":0.577}}},{"i":4442,"$":{"0":{"v":"hasEmailAddress","n":1}}},{"i":4443,"$":{"0":{"v":"hasEditor","n":1}}},{"i":4444,"$":{"0":{"v":"hasDomain","n":1},"1":{"v":"\n\n\n- [[p.equivalentPredicate]] [rdfs:domain](http://www.w3.org/2000/01/rdf-schema#domain)\n\n","n":0.577}}},{"i":4445,"$":{"0":{"v":"hasDocumentation","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] resources: \n","n":0.5}}},{"i":4446,"$":{"0":{"v":"hasDimensions","n":1}}},{"i":4447,"$":{"0":{"v":"hasDiameter","n":1}}},{"i":4448,"$":{"0":{"v":"hasDemonstration","n":1},"1":{"v":"\n\n\nnothing inspires like an impressive demo\n","n":0.408}}},{"i":4449,"$":{"0":{"v":"hasCriticism","n":1},"1":{"v":"\n\n\n\nI'm on a role tonight!\n","n":0.447}}},{"i":4450,"$":{"0":{"v":"hasCreator","n":1}}},{"i":4451,"$":{"0":{"v":"hasContext","n":1},"1":{"v":"\n\n\n## [[p.vs]] as:context\n\n- at least very similar in meaning\n- probably can say equivalent\n- \"context\" as a term is too much a property, we're shooting for predicates and readability here\n\n### as:content\n\n","n":0.183}}},{"i":4452,"$":{"0":{"v":"hasConferenceSeries","n":1},"1":{"v":"\n #academic #business\n\n- [[p.hasDomain]] [[c.organization]] [[c.community]] [[c.topic]]\n","n":0.378}}},{"i":4453,"$":{"0":{"v":"hasConferenceInstance","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[p.hasConferenceSeries]]\n- [[c.sphere]] #academic\n","n":0.447}}},{"i":4454,"$":{"0":{"v":"hasConcept","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #conceptual\n","n":0.577}}},{"i":4455,"$":{"0":{"v":"hasCon","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] has cons, has disadvanatages, has drawbacks\n- [[p.similarReferentTo]] [[p.hasIssue]]\n\n","n":0.316}}},{"i":4456,"$":{"0":{"v":"hasComponent","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n- [[p.inverseOf]] [[p.isComponentOf]]","n":0.447}}},{"i":4457,"$":{"0":{"v":"hasComparison","n":1},"1":{"v":"\n- [x] do I mean wasComparableTo\n  - t.2022.12.26 fixed\n\n- [[p.hasRange]]\n  - [[c.work]]\n  - [[c.addressableresource]]\n","n":0.267}}},{"i":4458,"$":{"0":{"v":"hasComparand","n":1}}},{"i":4459,"$":{"0":{"v":"hasCommunity","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.topic]] [[c.solution]] \n","n":0.447}}},{"i":4460,"$":{"0":{"v":"hasComment","n":1},"1":{"v":"\n\n\n\n- [[p.hasDomain]] [[c.creativework]] \n- [[p.differentFrom]] [[p.madeComment]]\n","n":0.408}}},{"i":4461,"$":{"0":{"v":"hasClientSupport","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.solution]] \n- [[p.hasRange]] [[t.cs.os]] [[c.platform]] \n","n":0.354}}},{"i":4462,"$":{"0":{"v":"hasCitation","n":1},"1":{"v":"\n\n\n- [[p.equivalentPredicate]] [schema:citation](http://schema.org/citation)\n","n":0.577}}},{"i":4463,"$":{"0":{"v":"hasCapability","n":1},"1":{"v":"\n- marker: capabilities\n- [[p.hasDomain]] [[c.solution]] [[prdct]] [[c.agent]]\n- [[p.hasRange]] [[c.activity]] [[c.benefit]]\n- [[p.alsoKnownAs]] is capable of; \n- [[p.similarTo]] [[p.hasFeature]]\n- [[p.vs]] [[p.hasFeature]]\n![[p.hasApplication#^t0eYw34Px2ZU]]\n","n":0.229}}},{"i":4464,"$":{"0":{"v":"hasCallToAction","n":1},"1":{"v":"\n\n- [[c.sphere]] #communication #community\n","n":0.5}}},{"i":4465,"$":{"0":{"v":"hasBlogEntry","n":1}}},{"i":4466,"$":{"0":{"v":"hasBlog","n":1}}},{"i":4467,"$":{"0":{"v":"hasAuthor","n":1},"1":{"v":"\n\nwrittenBy is nicer, but authorship isn't always written.\n\nauthorship is literary creatorship\n\n- [[p.subPredicateOf]] [[p.hasCreator]]\n- [[p.equivalentPredicate]] [pred.writtenBy](https://predicate.info)\n","n":0.258}}},{"i":4468,"$":{"0":{"v":"hasAudience","n":1}}},{"i":4469,"$":{"0":{"v":"hasAssesment","n":1}}},{"i":4470,"$":{"0":{"v":"hasArchitecture","n":1}}},{"i":4471,"$":{"0":{"v":"hasApplication","n":1},"1":{"v":"\n\n\nsolutions or product ideas can be applied to problems, user stories, other solutions, or topics in general\n\n- [[p.vs]] ([[p.hasCapability]] or [[p.hasFeature]])  ^t0eYw34Px2ZU\n  - the object of `hasApplication` is the problem or topic to which the functionality can be applied\n  - the object of `hasCapability` or `hasFeature` is the functionality which can be applied to a topic\n\n## #log\n\n- t.2022.12.22 fix domain/range confusion","n":0.128}}},{"i":4472,"$":{"0":{"v":"hasAnswers","n":1},"1":{"v":"\n\n\na beautiful \n","n":0.577}}},{"i":4473,"$":{"0":{"v":"hasAPI","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n- [[p.correspondsTo]] [[t.cs.api]]\n","n":0.447}}},{"i":4474,"$":{"0":{"v":"hailsFrom","n":1}}},{"i":4475,"$":{"0":{"v":"hailed","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4476,"$":{"0":{"v":"hadVision","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4477,"$":{"0":{"v":"hadVersion","n":1},"1":{"v":"\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4478,"$":{"0":{"v":"hadTouch","n":1},"1":{"v":"\n- for timestamping returns to notes\n  - you never look at the commit history","n":0.267}}},{"i":4479,"$":{"0":{"v":"hadSummary","n":1},"1":{"v":"\n#conceptual\n\n- [[p.vs]] [[p.hasSummaryPoints]]\n  - whole-part relationship\n","n":0.408}}},{"i":4480,"$":{"0":{"v":"hadSerialNumber","n":1}}},{"i":4481,"$":{"0":{"v":"hadSense","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4482,"$":{"0":{"v":"hadRole","n":1}}},{"i":4483,"$":{"0":{"v":"hadResponse","n":1}}},{"i":4484,"$":{"0":{"v":"hadRejectedOptions","n":1}}},{"i":4485,"$":{"0":{"v":"hadPriorities","n":1}}},{"i":4486,"$":{"0":{"v":"hadPricing","n":1}}},{"i":4487,"$":{"0":{"v":"hadPresenter","n":1}}},{"i":4488,"$":{"0":{"v":"hadPresentation","n":1}}},{"i":4489,"$":{"0":{"v":"hadPossibleSolution","n":1},"1":{"v":"\n\n\n- inverse of [[p.hasCapability]] and/or [[p.hasApplication]] ?\n  - really, kinda inverse of any predicate with a product or solution as a subject\n","n":0.213}}},{"i":4490,"$":{"0":{"v":"hadPanelist","n":1},"1":{"v":"\n\n\n\nprobably could be more general, but hadParticpant captures the audience\n","n":0.316}}},{"i":4491,"$":{"0":{"v":"had offer accepted by","n":0.5},"1":{"v":"\n- [[c.sphere]] #negotiation\n- [[p.inverseOf]] [[p.hadOfferAcceptedBy]]","n":0.447}}},{"i":4492,"$":{"0":{"v":"hadMission","n":1}}},{"i":4493,"$":{"0":{"v":"hadMember","n":1}}},{"i":4494,"$":{"0":{"v":"hadMeetingNotes","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.pred]]\n- [[p.hasDomain]] [[c.meeting]]\n","n":0.447}}},{"i":4495,"$":{"0":{"v":"hadLocation","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #geoSpatial\n","n":0.577}}},{"i":4496,"$":{"0":{"v":"hadLimitation","n":1}}},{"i":4497,"$":{"0":{"v":"hadLicense","n":1}}},{"i":4498,"$":{"0":{"v":"hadInsight","n":1}}},{"i":4499,"$":{"0":{"v":"hadHost","n":1},"1":{"v":"\n\n\n\n- [[p.isRelated]] [[dendron://predicates/p.hadPanelist]]\n","n":0.577}}},{"i":4500,"$":{"0":{"v":"hadHistory","n":1}}},{"i":4501,"$":{"0":{"v":"hadGoal","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.agent]] [[c.project]] \n- [[p.hasOptionalProperty]] \n  - [[p.hadStartDate]] \n  - [[p.hadDueDate]] [[c.timeperiod]]\n  - [[p.hadFinishDate]] [[c.timeperiod]]\n\n## thoughts\n\n- if listed on a daily or weekly journal/planning note, the implication is \"I have (or my superordinate agents have) an intended [[Completion Time|t.cs.data.temporality#completion-time]]\"\n","n":0.158}}},{"i":4502,"$":{"0":{"v":"description","n":1},"1":{"v":"\n- [[p.hadDescription]] \"can be described as\"\n- [[p.equivalentPredicate]] dcterms:description; \n","n":0.333}}},{"i":4503,"$":{"0":{"v":"hadDependancy","n":1}}},{"i":4504,"$":{"0":{"v":"hadDefinition","n":1},"1":{"v":"\n#linguistics #ontology \n\n- [[p.equivalentPredicate]] skos.defintion\n- [[p.alsoKnownAs]] `::`\n  - from [[prdct.remnote]]\n  - but `::` doesn't work in filenames, and Dendron doesn't have the kind of aliases I would like it to have\n\n\n","n":0.18}}},{"i":4505,"$":{"0":{"v":"hadCost","n":1}}},{"i":4506,"$":{"0":{"v":"hadContent","n":1}}},{"i":4507,"$":{"0":{"v":"hadCallToAction","n":1}}},{"i":4508,"$":{"0":{"v":"hadBenefit","n":1},"1":{"v":"\n(been meaning to do this for a while... hasPro is anti-literary, and benefit is a decent refinement)","n":0.243}}},{"i":4509,"$":{"0":{"v":"hadAttendee","n":1}}},{"i":4510,"$":{"0":{"v":"hadAnnouncement","n":1},"1":{"v":"\n\n\n- [[p.hasRange]] [[c.announcement]]\n","n":0.577}}},{"i":4511,"$":{"0":{"v":"had","n":1}}},{"i":4512,"$":{"0":{"v":"growled","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4513,"$":{"0":{"v":"groomed","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4514,"$":{"0":{"v":"grewUpIn","n":1}}},{"i":4515,"$":{"0":{"v":"gratefulFor","n":1}}},{"i":4516,"$":{"0":{"v":"grappled","n":1}}},{"i":4517,"$":{"0":{"v":"granted","n":1},"1":{"v":"\n\n\n\nfor permissions\n\n- [[p.inverseOf]] [[p.revoked]]\n","n":0.5}}},{"i":4518,"$":{"0":{"v":"grabbed","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4519,"$":{"0":{"v":"gotHit","n":1}}},{"i":4520,"$":{"0":{"v":"got","n":1}}},{"i":4521,"$":{"0":{"v":"generated","n":1}}},{"i":4522,"$":{"0":{"v":"gave","n":1}}},{"i":4523,"$":{"0":{"v":"gasped","n":1}}},{"i":4524,"$":{"0":{"v":"gagged","n":1}}},{"i":4525,"$":{"0":{"v":"froze","n":1}}},{"i":4526,"$":{"0":{"v":"freed","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4527,"$":{"0":{"v":"found","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4528,"$":{"0":{"v":"fought","n":1},"1":{"v":"\n\n\nverbal or physical conflict\n","n":0.5}}},{"i":4529,"$":{"0":{"v":"formerlyKnownAs","n":1}}},{"i":4530,"$":{"0":{"v":"forkedInto","n":1}}},{"i":4531,"$":{"0":{"v":"forkOf","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #lineage\n","n":0.577}}},{"i":4532,"$":{"0":{"v":"forgot","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4533,"$":{"0":{"v":"flung","n":1}}},{"i":4534,"$":{"0":{"v":"flipped","n":1}}},{"i":4535,"$":{"0":{"v":"flew","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4536,"$":{"0":{"v":"flailed","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4537,"$":{"0":{"v":"fixed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4538,"$":{"0":{"v":"finished","n":1}}},{"i":4539,"$":{"0":{"v":"filled","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4540,"$":{"0":{"v":"figuredOut","n":1}}},{"i":4541,"$":{"0":{"v":"felt","n":1},"1":{"v":"\n## Senses\n\n### Linking Verb\n\n- \n\n### Activity\n\n- perceived","n":0.378}}},{"i":4542,"$":{"0":{"v":"fellBehind","n":1}}},{"i":4543,"$":{"0":{"v":"fell","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4544,"$":{"0":{"v":"featherFell","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4545,"$":{"0":{"v":"failed","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4546,"$":{"0":{"v":"extends","n":1}}},{"i":4547,"$":{"0":{"v":"explored","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4548,"$":{"0":{"v":"exploded","n":1},"1":{"v":"- [[c.sphere]] #shapow\n\n","n":0.577}}},{"i":4549,"$":{"0":{"v":"explained","n":1}}},{"i":4550,"$":{"0":{"v":"exercised","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4551,"$":{"0":{"v":"exemplified","n":1}}},{"i":4552,"$":{"0":{"v":"excluded","n":1}}},{"i":4553,"$":{"0":{"v":"exclaimed","n":1}}},{"i":4554,"$":{"0":{"v":"excerptedFrom","n":1}}},{"i":4555,"$":{"0":{"v":"examined","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4556,"$":{"0":{"v":"evaluated","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] assessed\n- [[c.sphere]] #activity\n","n":0.447}}},{"i":4557,"$":{"0":{"v":"escaped","n":1},"1":{"v":"- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4558,"$":{"0":{"v":"escape","n":1}}},{"i":4559,"$":{"0":{"v":"equivalentTopic","n":1},"1":{"v":"\n#important\n\n- [[p.analogousTo]]\n  - [[p.equivalentTopic]]\n  - [[p.equivalentClass]]","n":0.408}}},{"i":4560,"$":{"0":{"v":"equivalentPredicate","n":1}}},{"i":4561,"$":{"0":{"v":"equivalentClass","n":1}}},{"i":4562,"$":{"0":{"v":"entered","n":1}}},{"i":4563,"$":{"0":{"v":"engage","n":1}}},{"i":4564,"$":{"0":{"v":"encountered","n":1},"1":{"v":"\n\n\n- [[p.hasSense]] crossing of paths, usually unanticipated \n","n":0.354}}},{"i":4565,"$":{"0":{"v":"emerged","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4566,"$":{"0":{"v":"emailed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4567,"$":{"0":{"v":"dumped","n":1}}},{"i":4568,"$":{"0":{"v":"drove","n":1}}},{"i":4569,"$":{"0":{"v":"droppedDown","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4570,"$":{"0":{"v":"dreamt","n":1}}},{"i":4571,"$":{"0":{"v":"drank","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow #activity\n","n":0.5}}},{"i":4572,"$":{"0":{"v":"dive","n":1}}},{"i":4573,"$":{"0":{"v":"dissipated","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4574,"$":{"0":{"v":"discussed","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4575,"$":{"0":{"v":"discovered","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4576,"$":{"0":{"v":"disappeared","n":1},"1":{"v":"- [[c.sphere]] #shapow\n\n","n":0.577}}},{"i":4577,"$":{"0":{"v":"directed","n":1},"1":{"v":"- [[c.sphere]] #shapow\n- ","n":0.577}}},{"i":4578,"$":{"0":{"v":"differentFrom","n":1},"1":{"v":"\n\n\n\nDon't underestimate the importance of difference! Have I really not captured this somewhere?\n","n":0.277}}},{"i":4579,"$":{"0":{"v":"died","n":1}}},{"i":4580,"$":{"0":{"v":"did","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n- [[p.similarTo]] [[p.workedOn]]\n- [[p.hasIssue]]\n  - was the activity finished?\n  - extremely non-specific\n","n":0.267}}},{"i":4581,"$":{"0":{"v":"detected","n":1}}},{"i":4582,"$":{"0":{"v":"demonstrated","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4583,"$":{"0":{"v":"defeated","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4584,"$":{"0":{"v":"decided","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n## [[hasComment]]\n\n- Why not make it more active? Well, if the decision-maker is implied from the context, and the context is already a question with a list of points, counter-points, and examples that's run for days it's nice to finish things off with a `2021-10-21` `sawDecision` `give up the whole affair`\n","n":0.137}}},{"i":4585,"$":{"0":{"v":"decapitated","n":1}}},{"i":4586,"$":{"0":{"v":"dashed","n":1}}},{"i":4587,"$":{"0":{"v":"danced","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4588,"$":{"0":{"v":"croaks","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4589,"$":{"0":{"v":"crept","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4590,"$":{"0":{"v":"creditedWith","n":1},"1":{"v":"\n\nlike creator or originator, but with built-in [[t.km.uncertainty]]\n","n":0.354}}},{"i":4591,"$":{"0":{"v":"creditedTo","n":1}}},{"i":4592,"$":{"0":{"v":"createdOn","n":1},"1":{"v":"\n#aka \"came up with on\", \"invented on\", \"was started on\"\n\n## [[p.provokedThoughts]]\n\nusing the #created tag works around some thorny complexities\n  - for \"creation times\" (to the minute) in English you would say \"created at {time} on {date}\" \n  - for \"creation hour\", you would say \"created around {time, to the nearest hour} on {date}\"\n  - for \"creation month\", you would say \"created in {month} of {year}\"\n  - for \"creation year\", you would say \"created in {year}\"","n":0.115}}},{"i":4593,"$":{"0":{"v":"created","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n- [[p.equivalentPredicate]] [dbo:created](http://dbpedia.org/ontology/created)\n- [[p.hasRange]] [[c.creativework]]\n","n":0.378}}},{"i":4594,"$":{"0":{"v":"crawled","n":1}}},{"i":4595,"$":{"0":{"v":"couldDiscuss","n":1}}},{"i":4596,"$":{"0":{"v":"couldBeConfusedWith","n":1},"1":{"v":"\n- [[p.similarTo]] [[p.hasRelatedTopic]]","n":0.577}}},{"i":4597,"$":{"0":{"v":"correspondsTo","n":1},"1":{"v":"\n\n\n## Thoughts\n\n- evolved from relatesToSolution\n- can be used for aliasing in general...\n","n":0.289}}},{"i":4598,"$":{"0":{"v":"coreferences","n":1},"1":{"v":"\n- the object/[[t.ling.grammar.subject.complement]] refers to the same thing as the subjec","n":0.302}}},{"i":4599,"$":{"0":{"v":"is the main coreference","n":0.5},"1":{"v":"\n- the object/[[t.ling.grammar.subject.complement]] is the preferred way to refer to the concept","n":0.289}}},{"i":4600,"$":{"0":{"v":"cooked","n":1}}},{"i":4601,"$":{"0":{"v":"conveyed","n":1},"1":{"v":"\n\n\n\na service-oriented beaut\n\n- [[c.sphere]] #activity\n","n":0.447}}},{"i":4602,"$":{"0":{"v":"controlledBy","n":1},"1":{"v":"\n\n\n- [[p.vs]] [[p.ownedBy]]\n  - eg the air force is arguably owned by tax-payers but controlled by the president and the chief of staff\n","n":0.209}}},{"i":4603,"$":{"0":{"v":"contributedTo","n":1},"1":{"v":"\n\n\n\n- [[p.hasDomain]] [[c.agent]]\n- [[c.sphere]] #activity\n- [[p.equivalentPredicate]] dcterms:contributor\n- [[p.similarTo]] schema:contributor\n","n":0.333}}},{"i":4604,"$":{"0":{"v":"continued","n":1}}},{"i":4605,"$":{"0":{"v":"consultedOn","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4606,"$":{"0":{"v":"considered","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n## thoughts\n\n- consideration begs summarization\n","n":0.378}}},{"i":4607,"$":{"0":{"v":"connected","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4608,"$":{"0":{"v":"conductedPoll","n":1},"1":{"v":"\n\n\n- [[p.hasDomain]] [[c.agent]]\n","n":0.577}}},{"i":4609,"$":{"0":{"v":"completed","n":1},"1":{"v":"\n\n\n\nalmost as generic as \"did\", but with more sense of accomplishment\n\n- [[c.sphere]] #activity\n","n":0.277}}},{"i":4610,"$":{"0":{"v":"compatibleWith","n":1}}},{"i":4611,"$":{"0":{"v":"compared","n":1}}},{"i":4612,"$":{"0":{"v":"comparableTo","n":1},"1":{"v":"\n- [[p.similarTo]] [[p.similarTo]]\n- I think that usually, similarTo is better","n":0.316}}},{"i":4613,"$":{"0":{"v":"cofounded","n":1}}},{"i":4614,"$":{"0":{"v":"closed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity #shapow\n","n":0.5}}},{"i":4615,"$":{"0":{"v":"closed the distance","n":0.577}}},{"i":4616,"$":{"0":{"v":"climbed","n":1}}},{"i":4617,"$":{"0":{"v":"cleaned","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4618,"$":{"0":{"v":"clawed","n":1}}},{"i":4619,"$":{"0":{"v":"classified","n":1},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.activitypredicate]]\n","n":0.577}}},{"i":4620,"$":{"0":{"v":"claimedBy","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #discursive\n","n":0.577}}},{"i":4621,"$":{"0":{"v":"checked","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4622,"$":{"0":{"v":"charged","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n\n","n":0.577}}},{"i":4623,"$":{"0":{"v":"chanted","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4624,"$":{"0":{"v":"celebrated","n":1}}},{"i":4625,"$":{"0":{"v":"caused","n":1}}},{"i":4626,"$":{"0":{"v":"catchGlimpse","n":1}}},{"i":4627,"$":{"0":{"v":"cast","n":1}}},{"i":4628,"$":{"0":{"v":"Eldritch Blast","n":0.707}}},{"i":4629,"$":{"0":{"v":"cancelled","n":1}}},{"i":4630,"$":{"0":{"v":"canImportFrom","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n","n":0.577}}},{"i":4631,"$":{"0":{"v":"canExportTo","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n\n","n":0.577}}},{"i":4632,"$":{"0":{"v":"canBePluralizedAs","n":1},"1":{"v":"\n\n\n- dubious utility, for humans anyhow\n","n":0.408}}},{"i":4633,"$":{"0":{"v":"came","n":1}}},{"i":4634,"$":{"0":{"v":"called out","n":0.707}}},{"i":4635,"$":{"0":{"v":"called","n":1}}},{"i":4636,"$":{"0":{"v":"builtWith","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #product-management\n- [[p.vs]] [[dendron://predicates/p.builtOn]]\n  - builtOn is for foundational components, platforms, operating systems, or hardware\n  - builtWith is for components\n","n":0.218}}},{"i":4637,"$":{"0":{"v":"builtOn","n":1},"1":{"v":"\n- [[c.sphere]] #product-management\n- [[p.similarTo]] [[dendron://predicates/p.extends]] \n- [[p.vs]] [[p.builtWith]]\n- [[p.inverseOf]] [[p.supports]]\n","n":0.316}}},{"i":4638,"$":{"0":{"v":"built","n":1},"1":{"v":"\n- [[p.inverseOf]] [[p.wasBuiltBy]]\n- [[p.similarTo]] [[p.created]], but implies \"(probably) created and then continued to improve\"","n":0.267}}},{"i":4639,"$":{"0":{"v":"bucked","n":1}}},{"i":4640,"$":{"0":{"v":"broke","n":1},"1":{"v":"\n\n\n\nI'm my own chaos monkey.\n","n":0.447}}},{"i":4641,"$":{"0":{"v":"breathed","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4642,"$":{"0":{"v":"brandished","n":1}}},{"i":4643,"$":{"0":{"v":"bought","n":1},"1":{"v":"\n## [[c.verbforms]]\n\n### #en\n\n- [[c.verbforms.root]] buy\n- [[c.verbforms.thirdpersonsingular]] buys\n- [[c.verbforms.pasttense]] bought\n- [[c.verbforms.pastparticiple]] bought\n- [[c.verbforms.presentparticiple]] buying\n\n## [[c.predicateforms]]\n\n### \n\n## [[c.prepositionalforms]]\n","n":0.25}}},{"i":4644,"$":{"0":{"v":"blasted","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4645,"$":{"0":{"v":"beheaded","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4646,"$":{"0":{"v":"begsQuestion","n":1}}},{"i":4647,"$":{"0":{"v":"becomesPersuaded","n":1},"1":{"v":"\n\n- convinced of something or to do something\n","n":0.354}}},{"i":4648,"$":{"0":{"v":"becameInterestedIn","n":1}}},{"i":4649,"$":{"0":{"v":"becameFrightened","n":1}}},{"i":4650,"$":{"0":{"v":"becameEnraged","n":1}}},{"i":4651,"$":{"0":{"v":"becameAwareOf","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4652,"$":{"0":{"v":"bashed open","n":0.707},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4653,"$":{"0":{"v":"bashed","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4654,"$":{"0":{"v":"basedOn","n":1},"1":{"v":"\n- [[p.similarTo]] [[p.builtOn]]\n\n","n":0.577}}},{"i":4655,"$":{"0":{"v":"banged","n":1},"1":{"v":"\n- [[c.sphere]] #shapow","n":0.577}}},{"i":4656,"$":{"0":{"v":"backtracked","n":1}}},{"i":4657,"$":{"0":{"v":"augured","n":1}}},{"i":4658,"$":{"0":{"v":"audited","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4659,"$":{"0":{"v":"attributedTo","n":1},"1":{"v":"\n\n\na way to cite the agent responsible for a statement, quote, idea, or belief\n\n- [[p.equivalentPredicate]] as:attributedTo prov:wasAttributedTo\n- [[c.sphere]] #discursive #communication\n","n":0.224}}},{"i":4660,"$":{"0":{"v":"attributedBy","n":1},"1":{"v":"\n\n\n\n- [[p.isRelated]] [[dendron://predicates/p.attributedTo]]\n","n":0.577}}},{"i":4661,"$":{"0":{"v":"attended","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4662,"$":{"0":{"v":"attemptedStealth","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4663,"$":{"0":{"v":"attempted","n":1}}},{"i":4664,"$":{"0":{"v":"attacked","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4665,"$":{"0":{"v":"ateAt","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity\n\n","n":0.577}}},{"i":4666,"$":{"0":{"v":"ate","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #shapow #activity\n- mostly for animals and food or meals\n","n":0.302}}},{"i":4667,"$":{"0":{"v":"associatedWith","n":1}}},{"i":4668,"$":{"0":{"v":"assistedWith","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] helpedWith\n- [[c.sphere]] #activity\n\n","n":0.447}}},{"i":4669,"$":{"0":{"v":"asked","n":1}}},{"i":4670,"$":{"0":{"v":"arrivedAt","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4671,"$":{"0":{"v":"arrived","n":1},"1":{"v":"\n\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4672,"$":{"0":{"v":"argues","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #discursive\n","n":0.577}}},{"i":4673,"$":{"0":{"v":"approached","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n","n":0.577}}},{"i":4674,"$":{"0":{"v":"appliedTo","n":1}}},{"i":4675,"$":{"0":{"v":"appearedIn","n":1},"1":{"v":"\n\n\nnot sure if this qualified as an ActivityPredicate or not\n","n":0.316}}},{"i":4676,"$":{"0":{"v":"appeared","n":1}}},{"i":4677,"$":{"0":{"v":"answered","n":1}}},{"i":4678,"$":{"0":{"v":"annoyedBy","n":1}}},{"i":4679,"$":{"0":{"v":"announcedOn","n":1}}},{"i":4680,"$":{"0":{"v":"announced","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4681,"$":{"0":{"v":"analyzed","n":1},"1":{"v":"\n\n\n\n- [[c.sphere]] #activity\n","n":0.577}}},{"i":4682,"$":{"0":{"v":"analogousTo","n":1}}},{"i":4683,"$":{"0":{"v":"alternativeTo","n":1},"1":{"v":"\n\n\ndon't say competitors, it's not always a competition\n","n":0.354}}},{"i":4684,"$":{"0":{"v":"alsoKnownAs","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] alias, altLabel, also known as \n- [[p.instanceOf]] [[c.pred]] \n- [[p.equivalentPredicate]] http://www.w3.org/2004/02/skos/core#altLabel \n- [[p.isRelated]]\n  - https://www.goedel.io/p/the-importance-of-aliases","n":0.243}}},{"i":4685,"$":{"0":{"v":"alerted","n":1},"1":{"v":"\n- [[c.sphere]] #shapow\n  ","n":0.577}}},{"i":4686,"$":{"0":{"v":"administrated","n":1},"1":{"v":"\n\n\n\n- [[p.alsoKnownAs]] administered\n- [[c.sphere]] #activity\n\n","n":0.447}}},{"i":4687,"$":{"0":{"v":"adjusted","n":1},"1":{"v":"\n\n\n\nwhat's life without lots of fine tuning?\n\n- [[p.alsoKnownAs]] re-configured\n- [[c.sphere]] #activity\n","n":0.302}}},{"i":4688,"$":{"0":{"v":"addressed","n":1},"1":{"v":"\n\n\n- [[c.sphere]] #activity #product-management\n- [[p.similarTo]] [[dendron://predicates/p.hasApplication]]\n","n":0.408}}},{"i":4689,"$":{"0":{"v":"acquired","n":1}}},{"i":4690,"$":{"0":{"v":"acceptedOfferFrom","n":1},"1":{"v":"\n- [[c.sphere]] #negotiation\n- [[p.inverseOf]] [[p.hadOfferAcceptedBy]]","n":0.447}}},{"i":4691,"$":{"0":{"v":"Organizations","n":1}}},{"i":4692,"$":{"0":{"v":"Zoominfo","n":1}}},{"i":4693,"$":{"0":{"v":"Zazuko","n":1}}},{"i":4694,"$":{"0":{"v":"Xr Association","n":0.707},"1":{"v":"\nurl: https://xra.org","n":0.707}}},{"i":4695,"$":{"0":{"v":"Wso2","n":1}}},{"i":4696,"$":{"0":{"v":"Wafi","n":1},"1":{"v":"\n- published: [[prdct.lod-cloud]] [[prdct.space-time]] [[prdct.meteo]]\n- ","n":0.447}}},{"i":4697,"$":{"0":{"v":"W3c","n":1}}},{"i":4698,"$":{"0":{"v":"Semantic Web Best Practices Working Group Swbp","n":0.378},"1":{"v":"\n## Resources\n\n- https://github.com/w3c/html/blob/master/.spec-data/biblio/biblio-sw.data","n":0.577}}},{"i":4699,"$":{"0":{"v":"Virtasant","n":1},"1":{"v":"\n- url: https://www.virtasant.com/\n- trusted advisor leaves a lot to be desired\n- they add recommendation to jira, then help engineers execute\n- charge 25% of savings annualized\n- can pull from cloud APIs, datadog\n- process:\n  - engineer accepts as \"net new\" reduction\n  - month later, bill has to have been reduced\n- can do an audit of cloud efficiency (a measure of $ spent for actual workload)\n  - can give you ammunition for negotiations\n  - available in looker via cross-account access\n- trains engineers to think differently\n- builds efficiencies into terraform \n- PROBABLY, we can re-negotiate our Google commit\n- ","n":0.103}}},{"i":4700,"$":{"0":{"v":"Vinci","n":1},"1":{"v":"\n```yaml\nurl: https://www.vinci.com\n```","n":0.707}}},{"i":4701,"$":{"0":{"v":"Viev","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://www.viev.com\n- [[p.provided]] [[prdct.boston]]\n- [[p.isRelated]] [[prdct.factengine]]\n- [[p.associatedWith]] @victor-morgante\n","n":0.333}}},{"i":4702,"$":{"0":{"v":"Vaticle","n":1},"1":{"v":"\n\n- [[p.alsoKnownAs]] Grakn Labs\n","n":0.5}}},{"i":4703,"$":{"0":{"v":"Universitaet Leipzig","n":0.707}}},{"i":4704,"$":{"0":{"v":"Unity Technologies","n":0.707}}},{"i":4705,"$":{"0":{"v":"Udemy","n":1}}},{"i":4706,"$":{"0":{"v":"United Auto Workers","n":0.577}}},{"i":4707,"$":{"0":{"v":"Triply","n":1},"1":{"v":"\n- url: https://triply.cc/\n- published: [[prdct.triplydb]] [[prdct.triplydb.js]]","n":0.408}}},{"i":4708,"$":{"0":{"v":"TopQuadrant","n":1},"1":{"v":"\n- published: [[prdct.topbraid-composer]]","n":0.577}}},{"i":4709,"$":{"0":{"v":"Toplap","n":1},"1":{"v":"\n- url: https://toplap.org","n":0.577}}},{"i":4710,"$":{"0":{"v":"Tlon","n":1}}},{"i":4711,"$":{"0":{"v":"Tiktok","n":1},"1":{"v":"\n- [[p.published]] [[prdct.tiktok]]","n":0.577}}},{"i":4712,"$":{"0":{"v":"Thousand Trails","n":0.707}}},{"i":4713,"$":{"0":{"v":"Thirdweb","n":1}}},{"i":4714,"$":{"0":{"v":"The Trade Desk","n":0.577},"1":{"v":"\n\n- 2022-03-15 Moving to % Of Media model\n","n":0.354}}},{"i":4715,"$":{"0":{"v":"Terminusdb","n":1}}},{"i":4716,"$":{"0":{"v":"Telicent","n":1},"1":{"v":"\n- published: [[prdct.core-platform]]","n":0.577}}},{"i":4717,"$":{"0":{"v":"Synopsys","n":1},"1":{"v":"\n- https://www.synopsys.com/","n":0.707}}},{"i":4718,"$":{"0":{"v":"Suborbital","n":1},"1":{"v":"\n- url: https://suborbital.dev\n- [[p.published]] [[prdct.e2core]]","n":0.447}}},{"i":4719,"$":{"0":{"v":"Subconscious","n":1},"1":{"v":"\n- winding down as of 2024-05\n- https://subconscious.network/\n\n## References \n\n- https://newsletter.squishy.computer/p/subconscious-is-winding-down","n":0.316}}},{"i":4720,"$":{"0":{"v":"Stanford","n":1}}},{"i":4721,"$":{"0":{"v":"Ksl","n":1},"1":{"v":"\n- https://tw.rpi.edu/knowledge-systems-lab-ksl-stanford-archive","n":0.707}}},{"i":4722,"$":{"0":{"v":"Stagecraft","n":1}}},{"i":4723,"$":{"0":{"v":"Stackadapt","n":1}}},{"i":4724,"$":{"0":{"v":"Springer","n":1}}},{"i":4725,"$":{"0":{"v":"spin.ai","n":1}}},{"i":4726,"$":{"0":{"v":"Spectrum","n":1},"1":{"v":"\n- url: (https://www.spectrumlabsai.com/)\n\n","n":0.577}}},{"i":4727,"$":{"0":{"v":"Smashing Magazine","n":0.707},"1":{"v":"\n\n- [[p.published]] [[TypeScript in 50 Lessons|book.typescript-in-50-lessons]]  ","n":0.408}}},{"i":4728,"$":{"0":{"v":"Siemens","n":1},"1":{"v":"\n- [[p.signedUpFor]] [[t.cs.security.charter-of-trust]]","n":0.577}}},{"i":4729,"$":{"0":{"v":"Sharedvocabs","n":1}}},{"i":4730,"$":{"0":{"v":"Sequoia","n":1}}},{"i":4731,"$":{"0":{"v":"Seeek","n":1},"1":{"v":"\n- https://seeek.co/\n- founder: connor","n":0.5}}},{"i":4732,"$":{"0":{"v":"Sap","n":1}}},{"i":4733,"$":{"0":{"v":"Salesforce","n":1}}},{"i":4734,"$":{"0":{"v":"Real-Time Innovations","n":0.707},"1":{"v":"\n\n- [[p.provided]] [[prdct.connext]]\n","n":0.577}}},{"i":4735,"$":{"0":{"v":"Roleplay Tools","n":0.707}}},{"i":4736,"$":{"0":{"v":"Roam Research","n":0.707},"1":{"v":"\n- url: https://roamresearch.com","n":0.577}}},{"i":4737,"$":{"0":{"v":"Richardson_bros","n":1}}},{"i":4738,"$":{"0":{"v":"Reutlingen University","n":0.707}}},{"i":4739,"$":{"0":{"v":"Responsibile Metaverse Alliance","n":0.577},"1":{"v":"\nurl: https://responsiblemetaverse.org","n":0.707}}},{"i":4740,"$":{"0":{"v":"Relyance Ai","n":0.707},"1":{"v":"\n- url: https://www.relyance.ai/\n\n![](/assets/images/2023-07-05-11-53-17.png)\n![](/assets/images/2023-07-05-11-56-53.png)\n- contracts & policies gives a checklist of requirements\n- source code integration is basically static code analysis; \n- can help identify shadow it\n- optional to connect directly to databases; ML models?\n","n":0.174}}},{"i":4741,"$":{"0":{"v":"Reely","n":1},"1":{"v":"\n- url: https://www.reely.ai/\n- now part of [[org.magnifi]]","n":0.378}}},{"i":4742,"$":{"0":{"v":"Redhat","n":1}}},{"i":4743,"$":{"0":{"v":"Red Blob Games","n":0.577},"1":{"v":"\nurl: https://www.redblobgames.com/\n","n":0.707}}},{"i":4744,"$":{"0":{"v":"Rapid7","n":1}}},{"i":4745,"$":{"0":{"v":"Qweb","n":1}}},{"i":4746,"$":{"0":{"v":"Progress Software","n":0.707}}},{"i":4747,"$":{"0":{"v":"Processing","n":1},"1":{"v":"\n- url: https://processingfoundation.org/","n":0.577}}},{"i":4748,"$":{"0":{"v":"Posit","n":1}}},{"i":4749,"$":{"0":{"v":"PivotPoint","n":1}}},{"i":4750,"$":{"0":{"v":"Pinnacle","n":1}}},{"i":4751,"$":{"0":{"v":"Patron","n":1},"1":{"v":"\n- url: https://patron.xyz/\n- patron looking for core player community with a wedge.","n":0.289}}},{"i":4752,"$":{"0":{"v":"Park Avenue Capital","n":0.577}}},{"i":4753,"$":{"0":{"v":"Pali Hiking Club","n":0.577}}},{"i":4754,"$":{"0":{"v":"Outpost Capital","n":0.707}}},{"i":4755,"$":{"0":{"v":"Open Wallet Foundation","n":0.577},"1":{"v":"\n- url: https://openwallet.foundation/","n":0.577}}},{"i":4756,"$":{"0":{"v":"Open Metaverse Foundation","n":0.577},"1":{"v":"\n- url: https://www.openmv.org/","n":0.577}}},{"i":4757,"$":{"0":{"v":"Open Geospatial Consortium","n":0.577},"1":{"v":"\n- url: https://www.ogc.org/","n":0.577}}},{"i":4758,"$":{"0":{"v":"Ontotext","n":1},"1":{"v":"\n- url: https://www.ontotext.com/","n":0.577}}},{"i":4759,"$":{"0":{"v":"Ontola","n":1},"1":{"v":"\n- https://ontola.io/about/\n- Never manage a namespace object map again, scrap typo's for well-known ontologies. Like DefinitelyTyped, but for ontologies. \n\n## Solutions\n\n- https://github.com/ontola/ontologies (dead)\nRDF tools that we've built\n\n- link-lib JS lib for managing an RDF store, registering views and handling actions\n- link-redux JS lib for React components, works with link-lib\n- linked-rails Ruby gem that does a whole lot of linked data goodness\n- rdf-serializers Ruby gem that for serializing RDF\n- linked-delta for communicating state changes (between server / client, or persisting as event log)\n- @ontologies - make it easier to use ontologies (schema, owl, dcterms..) in JS projects\n- js.rdf.dev A whole lot of RDF tools for JS!\n- Check out the rest at Github.\n- If you need any help, get in touch!\n\n## References\n\n- [[ar.ontola.full-stack-linked-data]]","n":0.091}}},{"i":4760,"$":{"0":{"v":"Okta","n":1}}},{"i":4761,"$":{"0":{"v":"Nvidia","n":1}}},{"i":4762,"$":{"0":{"v":"Niantic","n":1}}},{"i":4763,"$":{"0":{"v":"Mozilla","n":1}}},{"i":4764,"$":{"0":{"v":"Modeliosoft","n":1},"1":{"v":"\n- url: https://www.modeliosoft.com","n":0.577}}},{"i":4765,"$":{"0":{"v":"Microsoft","n":1}}},{"i":4766,"$":{"0":{"v":"Methodist","n":1}}},{"i":4767,"$":{"0":{"v":"Methodist Preschool","n":0.707}}},{"i":4768,"$":{"0":{"v":"Metaverse Standards Forum","n":0.577},"1":{"v":"\n- 2500 members t.2023.05.23","n":0.5}}},{"i":4769,"$":{"0":{"v":"Merrill Lynch","n":0.707}}},{"i":4770,"$":{"0":{"v":"Mass Mutual","n":0.707}}},{"i":4771,"$":{"0":{"v":"Marcaria","n":1},"1":{"v":"\n\n- [[p.hasURL]] https://www.marcaria.com\n","n":0.577}}},{"i":4772,"$":{"0":{"v":"Manticore Games","n":0.707}}},{"i":4773,"$":{"0":{"v":"MamaP","n":1},"1":{"v":"\n\n- [[p.hasSite]] https://mamap.life","n":0.577}}},{"i":4774,"$":{"0":{"v":"Malwarebytes","n":1}}},{"i":4775,"$":{"0":{"v":"Magnetargames","n":1},"1":{"v":"\n\n- [[p.hasSolution]] \n  - [[prdct.chronos-rti]]\n  - [[prdct.voyager]]\n","n":0.378}}},{"i":4776,"$":{"0":{"v":"Lyrasis","n":1},"1":{"v":"\n- https://www.lyrasis.org","n":0.707}}},{"i":4777,"$":{"0":{"v":"Lumu.io","n":1}}},{"i":4778,"$":{"0":{"v":"Lucid","n":1},"1":{"v":"\n\n\n- [[p.provided]] [[prdct.lucidchart]]\n","n":0.577}}},{"i":4779,"$":{"0":{"v":"Lucid Sight","n":0.707}}},{"i":4780,"$":{"0":{"v":"Lockheed Martin","n":0.707}}},{"i":4781,"$":{"0":{"v":"Liveramp","n":1}}},{"i":4782,"$":{"0":{"v":"Latitude","n":1},"1":{"v":"\n\n\n- [[c.ceo]]\n","n":0.707}}},{"i":4783,"$":{"0":{"v":"Lamina1","n":1},"1":{"v":"\n- [[p.published]] [[prdct.lamina1]]\n\n## Contacts\n\n- ecosystem@lamina1.com \n  - \"Interested in launching a project on LAMINA1 with the Emergence toolkit?\"\n  - \"[Apply for funding](https://www.lamina1.com/ecosystem). The LAMINA1 Ecosystem Fund is dedicated to funding projects in the open metaverse that will directly leverage the LAMINA1 blockchain. It is open to anyone building infrastructure, protocols, metaverse applications and experiences, and beyond.\"\n\n## References\n\n- https://venturebeat.com/metaverse/get-ready-for-neal-stephensons-open-metaverse-as-lamina1-unveils-avalanche-web3-plans/","n":0.131}}},{"i":4784,"$":{"0":{"v":"Lamas Finance","n":0.707},"1":{"v":"\n- url https://www.lamas.co/","n":0.577}}},{"i":4785,"$":{"0":{"v":"Ladwp","n":1}}},{"i":4786,"$":{"0":{"v":"Khronos Group","n":0.707},"1":{"v":"\n- url: https://www.khronos.org/\n\n## Products\n\n- [[prdct.openxr]]","n":0.447}}},{"i":4787,"$":{"0":{"v":"Kaseya","n":1}}},{"i":4788,"$":{"0":{"v":"Juxt","n":1}}},{"i":4789,"$":{"0":{"v":"Jetbrains","n":1}}},{"i":4790,"$":{"0":{"v":"Jamf","n":1}}},{"i":4791,"$":{"0":{"v":"Iospress","n":1},"1":{"v":"\n- http://iospress.nl/\n- producst: [[prdct.ld-connect]]","n":0.5}}},{"i":4792,"$":{"0":{"v":"Inworld","n":1}}},{"i":4793,"$":{"0":{"v":"Intuit","n":1}}},{"i":4794,"$":{"0":{"v":"International Association for Ontology and Its Applications","n":0.378},"1":{"v":"\n- url: https://iaoa.org/","n":0.577}}},{"i":4795,"$":{"0":{"v":"Improbable","n":1},"1":{"v":"\n- https://www.improbable.io/\n\n\n## Solutions\n\n- [[prdct.spatialos]]\n- [[prdct.metaverse-markup-language]]\n- [[prdct.thanos]]","n":0.408}}},{"i":4796,"$":{"0":{"v":"Ilm","n":1}}},{"i":4797,"$":{"0":{"v":"Ibm","n":1}}},{"i":4798,"$":{"0":{"v":"Human Interactive","n":0.707},"1":{"v":"\n- url: https://www.human-interactive.org/","n":0.577}}},{"i":4799,"$":{"0":{"v":"Hidden Door","n":0.707},"1":{"v":"\n- url: https://www.hiddendoor.co/\n- related: [[prdct.hidden-door]]\n\n## Employees\n\n- CEO: @hillary-mason","n":0.354}}},{"i":4800,"$":{"0":{"v":"Heroic Labs","n":0.707},"1":{"v":"\n[[p.hasSite]] https://heroiclabs.com/\n","n":0.707}}},{"i":4801,"$":{"0":{"v":"Hashnode","n":1}}},{"i":4802,"$":{"0":{"v":"Hasbro","n":1}}},{"i":4803,"$":{"0":{"v":"Gray Area","n":0.707}}},{"i":4804,"$":{"0":{"v":"Granthika","n":1},"1":{"v":"\n\n- [[p.provided]] [[prdct.granthika]]\n","n":0.577}}},{"i":4805,"$":{"0":{"v":"Granite Media","n":0.707},"1":{"v":"\ncontent-optimization for publishers","n":0.577}}},{"i":4806,"$":{"0":{"v":"Grafana","n":1},"1":{"v":"\n- https://grafana.com/","n":0.707}}},{"i":4807,"$":{"0":{"v":"Futureverse","n":1},"1":{"v":"\n\n## References\n\n- [[ar.futureverse-whitepaper]]","n":0.577}}},{"i":4808,"$":{"0":{"v":"Frontier Communications","n":0.707}}},{"i":4809,"$":{"0":{"v":"Free League Publishing","n":0.577}}},{"i":4810,"$":{"0":{"v":"Franz Inc","n":0.707}}},{"i":4811,"$":{"0":{"v":"Founders Inc","n":0.707},"1":{"v":"\n- incubator\n- building","n":0.577}}},{"i":4812,"$":{"0":{"v":"Fission","n":1},"1":{"v":"\n- winding down as of 2024-05\n\n## Products\n\n- [[Odd Dev|prdct.odd-dev]]\n- [[prdct.rhizomedb]]\n\n## [[c.vision]]\n\nFission sees a world where:\n👤  People control their digital lives.\n🖥  Edge computing is part of critical infrastructure.\n🎉  Open source is celebrated and well-funded.\n🛠  Protocols replace platforms as the foundation of software development.\n🏠  [[Local-first|t.cs.sd.local-first]] software is the norm.\n🔁  Exit from one application to another is seamless.","n":0.135}}},{"i":4813,"$":{"0":{"v":"First Spark Ventures","n":0.577}}},{"i":4814,"$":{"0":{"v":"Fable","n":1},"1":{"v":"\n- produced: [[game.wolves-in-the-walls]]","n":0.577}}},{"i":4815,"$":{"0":{"v":"Exabeam","n":1}}},{"i":4816,"$":{"0":{"v":"Every Media Inc","n":0.577}}},{"i":4817,"$":{"0":{"v":"Estuary","n":1}}},{"i":4818,"$":{"0":{"v":"Endless Adventures","n":0.707},"1":{"v":"\n\n## Resources\n\n- https://venturebeat.com/games/endless-adventures-will-enable-gamers-to-create-narrative-games-with-no-code-tools-and-ai/","n":0.577}}},{"i":4819,"$":{"0":{"v":"Eighth Generation","n":0.707}}},{"i":4820,"$":{"0":{"v":"Ego","n":1},"1":{"v":"\n- url: https://www.ego.live/\n- product: [[prdct.ego]]","n":0.447}}},{"i":4821,"$":{"0":{"v":"Eccenca","n":1}}},{"i":4822,"$":{"0":{"v":"Doi Foundation","n":0.707},"1":{"v":"\n- https://www.doi.org/","n":0.707}}},{"i":4823,"$":{"0":{"v":"DocuSign","n":1}}},{"i":4824,"$":{"0":{"v":"Diagrid","n":1},"1":{"v":"\n- url: https://www.diagrid.io","n":0.577}}},{"i":4825,"$":{"0":{"v":"Dendron Inc","n":0.707},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.company]] \n- [[p.hasURL]] https://www.dendron.so/about https://wiki.dendron.so/notes/8d6bb6c6-f2b5-4fb4-a7f0-1930b528051f/\n\n","n":0.378}}},{"i":4826,"$":{"0":{"v":"Datadog","n":1}}},{"i":4827,"$":{"0":{"v":"Darktrace","n":1}}},{"i":4828,"$":{"0":{"v":"Cohn Reznick","n":0.707}}},{"i":4829,"$":{"0":{"v":"Cisco","n":1}}},{"i":4830,"$":{"0":{"v":"CDW","n":1}}},{"i":4831,"$":{"0":{"v":"Capitalize Analytics","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.linkedin.com/company/capitalize-analytics/\n","n":0.577}}},{"i":4832,"$":{"0":{"v":"Box","n":1}}},{"i":4833,"$":{"0":{"v":"Blackberry","n":1}}},{"i":4834,"$":{"0":{"v":"Bitsight","n":1}}},{"i":4835,"$":{"0":{"v":"Bhphotovideo","n":1}}},{"i":4836,"$":{"0":{"v":"Bell South","n":0.707}}},{"i":4837,"$":{"0":{"v":"Beatshapers","n":1},"1":{"v":"\n- url: http://www.beatshapers.com/\n- \"easy to hop-in gameplay, with fast sessions and addicting compulsion cycles\"\n- \"co-located multiplayer is a natural way to play\" / \"LAN Parties will be back\"\n- ","n":0.189}}},{"i":4838,"$":{"0":{"v":"Banyan Security","n":0.707}}},{"i":4839,"$":{"0":{"v":"Azra Games","n":0.707}}},{"i":4840,"$":{"0":{"v":"Auxbrain","n":1},"1":{"v":"\n## References\n\n- https://egg-inc.fandom.com/wiki/Auxbrain,_Inc.","n":0.577}}},{"i":4841,"$":{"0":{"v":"Atomgraph","n":1}}},{"i":4842,"$":{"0":{"v":"Atlassian","n":1}}},{"i":4843,"$":{"0":{"v":"Artificial Intelligence Research (ART) at Tor Vergata","n":0.378}}},{"i":4844,"$":{"0":{"v":"Angellist","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.angellist.com/\n","n":0.577}}},{"i":4845,"$":{"0":{"v":"Andreessen Horowitz","n":0.707}}},{"i":4846,"$":{"0":{"v":"Altera","n":1}}},{"i":4847,"$":{"0":{"v":"Aeon Media","n":0.707}}},{"i":4848,"$":{"0":{"v":"Adobe","n":1}}},{"i":4849,"$":{"0":{"v":"Accenture","n":1}}},{"i":4850,"$":{"0":{"v":"6sense","n":1}}},{"i":4851,"$":{"0":{"v":"djradon’s Now","n":0.707},"1":{"v":"\n![[ko.now]]\n![[sflow.now]]\n![[pub.now]]\n","n":1}}},{"i":4852,"$":{"0":{"v":"Namespaces","n":1},"1":{"v":"\n- ar: addressable resources\n  - desc: you go to the URL, and get \"the thing\" back\n  - thought: should've called it \"locatable resource\"\n  - features: hierarchically consistent\n- book: since ARs can be books, this probably needs reworking. Also, since some ARs are subclassed by website, website/author, \n- community: not exactly an organization; could be used for factions, alliances, etc; differs from group in that a community is a social unit with some common values; a group is just an enumeration with common characteristics\n  - hierarchically consistent\n- course: educational unit of teaching\n- email: \n- event: \n","n":0.103}}},{"i":4853,"$":{"0":{"v":"Music","n":1}}},{"i":4854,"$":{"0":{"v":"The Magic Store","n":0.577},"1":{"v":"\n- created: 1979?\n- composed-for: [[video.the-muppet-movie]]\n- composed-by: @paul-williams\n\n\n## Lyrics\n  \n[Part 1: The Magic Store]  \n  \n[Verse 1: Kermit]  \nIt starts when we're kids  \nA show-off in school  \nMakin' faces at friends  \nYou're a clown and a fool  \nDoin' prat-falls and bird-calls  \nAnd bad imitations  \nIgnoring your homework  \nIs that dedication?  \nYou work through the mirror  \nYou're getting standing ovations  \n  \n[Verse 2: Fozzie, Miss Piggy, and various Muppets]  \nYou're burning with hope  \nYou're building up steam  \nWhat was once juvenilish is grown-up and stylish  \nYou're close to your dream  \nThen somebody out there loves you  \nStands up and hollers for more (More!)  \nYou found a home at the Magic Store  \n  \n[Instrumental Bridge]  \n  \n[Part 2: Rainbow Connection (Reprise)]  \n  \n[Verse 3: Kermit, Fozzie, Gonzo, Miss Piggy, and various Muppets]  \nWhy are there so many songs about rainbows  \nThat's part of what rainbows do  \nRainbows are memories, sweet dream reminders  \nWhat is it you'd like to do  \nAll of us watching and wishing we find it  \nI noticed you're watching, too  \nSomeday you'll find it, the Rainbow Connection  \nThe lovers, the dreamers and...  \n  \n[Instrumental Bridge]  \n  \n[Outro: Kermit and various Muppets]  \nLife's like a movie  \nWrite your own ending  \nKeep believing  \nKeep pretending  \nWe've done just what we've set out to do  \nThanks to the lovers, the dreamers, and you  \n  \n## Notes\n\n- \"At the beginning of the movie, Bernie the Agent describes Hollywood as \"the Dream Factory, the Magic Store\". So this song is a callback to that line.\"\n\n## References\n\n- https://genius.com/The-muppets-finale-the-magic-store-lyrics\n- https://forums.delphiforums.com/toughpigs/messages?msg=17392.972&gid=2121252205","n":0.063}}},{"i":4855,"$":{"0":{"v":"Hallelujah I Love Her So","n":0.447},"1":{"v":"\n## References\n\n- https://en.wikipedia.org/wiki/Hallelujah_I_Love_Her_So","n":0.577}}},{"i":4856,"$":{"0":{"v":"Champagne Problems","n":0.707}}},{"i":4857,"$":{"0":{"v":"Beethovens 9th","n":0.707}}},{"i":4858,"$":{"0":{"v":"Locations","n":1}}},{"i":4859,"$":{"0":{"v":"Utah","n":1}}},{"i":4860,"$":{"0":{"v":"Salt Lake City","n":0.577}}},{"i":4861,"$":{"0":{"v":"Xcaret Park","n":0.707},"1":{"v":"\n- cave swimming, kids snorkeling, and more","n":0.378}}},{"i":4862,"$":{"0":{"v":"Will Rogers State Historic Park","n":0.447}}},{"i":4863,"$":{"0":{"v":"Wheeler Gorge Campground","n":0.577}}},{"i":4864,"$":{"0":{"v":"The Venice Whaler","n":0.577}}},{"i":4865,"$":{"0":{"v":"The Ranch House","n":0.577},"1":{"v":"\n\n\n- bluesy standards by virtuoso pianist on wide-open dance-floor\n- tables scattered through bamboo glades\n- arch bridge across coi pond\n- prix fixe\n- everything delicious\n","n":0.209}}},{"i":4866,"$":{"0":{"v":"The Getty","n":0.707}}},{"i":4867,"$":{"0":{"v":"Temescal Gateway Park","n":0.577}}},{"i":4868,"$":{"0":{"v":"Stokes Tire Service","n":0.577}}},{"i":4869,"$":{"0":{"v":"Stanford","n":1}}},{"i":4870,"$":{"0":{"v":"Roseroom","n":1}}},{"i":4871,"$":{"0":{"v":"Pali Elementary","n":0.707}}},{"i":4872,"$":{"0":{"v":"Olds Elementary School","n":0.577}}},{"i":4873,"$":{"0":{"v":"Noahs Bagels","n":0.707}}},{"i":4874,"$":{"0":{"v":"New York Bagel Deli","n":0.5}}},{"i":4875,"$":{"0":{"v":"Meditation Mount","n":0.707},"1":{"v":"\n\n\n- lotsa benches tucked away\n- paths\n- spiritual words embossed on rocks\n- lillpad pond\n","n":0.277}}},{"i":4876,"$":{"0":{"v":"Los Angeles","n":0.707}}},{"i":4877,"$":{"0":{"v":"Lake Pleasant, WA","n":0.577}}},{"i":4878,"$":{"0":{"v":"Indian Wells","n":0.707}}},{"i":4879,"$":{"0":{"v":"Hollywood Bowl","n":0.707}}},{"i":4880,"$":{"0":{"v":"Farmers Market","n":0.707}}},{"i":4881,"$":{"0":{"v":"Fairmont Grand Del Mar","n":0.5}}},{"i":4882,"$":{"0":{"v":"Espresso Cielo","n":0.707}}},{"i":4883,"$":{"0":{"v":"Cvs","n":1}}},{"i":4884,"$":{"0":{"v":"Caffe Luxxe","n":0.707}}},{"i":4885,"$":{"0":{"v":"Bonnie Lu's (Restaurant)","n":0.577},"1":{"v":"\n\n\n- breakfast all day\n- diner feel\n","n":0.408}}},{"i":4886,"$":{"0":{"v":"Bainbridge Island","n":0.707}}},{"i":4887,"$":{"0":{"v":"Azacualpa, El Salvador","n":0.577}}},{"i":4888,"$":{"0":{"v":"Anawalt","n":1}}},{"i":4889,"$":{"0":{"v":"Licenses","n":1}}},{"i":4890,"$":{"0":{"v":"Creative Commons","n":0.707}}},{"i":4891,"$":{"0":{"v":"Cc by 4","n":0.577}}},{"i":4892,"$":{"0":{"v":"CC-BY-4.0","n":1},"1":{"v":"\n- [[p.coreferences]] #CC-BY-4.0","n":0.577}}},{"i":4893,"$":{"0":{"v":"Ogl","n":1}}},{"i":4894,"$":{"0":{"v":"OGL 1.2","n":0.707},"1":{"v":"\n- \n- has [[t.roleplaying.virtual-tabletop]] addendum, \n- ","n":0.408}}},{"i":4895,"$":{"0":{"v":"Apache","n":1}}},{"i":4896,"$":{"0":{"v":"Apache 2 license","n":0.577}}},{"i":4897,"$":{"0":{"v":"LGPL","n":1}}},{"i":4898,"$":{"0":{"v":"Cpal","n":1},"1":{"v":"\n- resources:  https://en.wikipedia.org/wiki/Common_Public_Attribution_License","n":0.577}}},{"i":4899,"$":{"0":{"v":"BY","n":1}}},{"i":4900,"$":{"0":{"v":"Bsd","n":1}}},{"i":4901,"$":{"0":{"v":"Kosmion","n":1},"1":{"v":"\n## Description\n\nThe Kosmion ontology is designed with a human-first orientation and a domain-first approach that allows data modelers to define their own top-level constructs and hierarchies rather than fitting them into a predefined universal structure. \n\nBut if you're already using an upper ontology, it can work with that too.\n      \nKosmion is intended to be a utilitarian foundational ontology, advocating for “relator instances” as a reification-like alternative to traditional properties/relations. This approach allows:\n\n- relevant facets instead of instantiating traditional classes.\n- n-ary relations, including unary relations\n- system-time (with kosm:relator-genesis, kosm:relator-tombstone, and kosm:relator-successor)\n- immutability and attribution for lineage, auditing, and time-travel purposes\n- “statements about relators”, and since any traditional RDF statement can be expressed with a relator (I think), it could be considered an alternative to RDF-star, which aims to support “statements about statements”\n- contexts for specifying alternate realities and other less-truthy perspectives\n- **Multi-perspective Modeling**: By using relators for every connection, it becomes possible to represent different perspectives or interpretations of the same entities, allowing richer semantic descriptions and supporting use cases like storytelling, versioning, or conflicting viewpoints.\n- maybe: relations that may involve either a datatype property or an object property as their object, or both \n\nKosmion is intend to use “OWL2 Full” (i.e., the RDF-based semantics), which supposedly might mean it's undecideable and unreasonable. It's also unorthodox, so probably breaks a lot of tooling. Tough luck computers.\n\nArguably, relators are also less readable and more complicated than classic RDF triples. Sorry about that, humans. At least the expressiveness is decent.\n","n":0.064}}},{"i":4902,"$":{"0":{"v":"Review","n":1}}},{"i":4903,"$":{"0":{"v":"Ontoge","n":1},"1":{"v":"\n## t.2024.08.16.10\n\n- [x] regarding [[prdct.ontogen]], is it at odds with keeping history (of events, relator validity) in the dataset? i.e., RDF immutability or event-driven/relator-based RDF \n  - see [[pub.question-log.2024.08.16.ontogen-vs-relator-based-rdf]]\n  - graph-based versioning might be orthogonal to an immutable-ish data store (in text files, in git)\n  - t.2024.08.16.15: ultimately, no... ontogen seems mostly concerned with commit history, not validity or application time. its speech acts are the acts of data stewards more than application users","n":0.116}}},{"i":4904,"$":{"0":{"v":"False Starts","n":0.707}}},{"i":4905,"$":{"0":{"v":"2024 10 11","n":0.577},"1":{"v":"\n```turtle\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n@prefix kosm: <https://kosmion.github.io/ont/v0/> .\n@prefix owl: <http://www.w3.org/2002/07/owl#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix sh: <http://www.w3.org/ns/shacl#> .\n@prefix gufo: <http://purl.org/nemo/gufo#> .\n\n# Ontology metadata\n<https://kosmion.github.io/ont/v0/kosmion-v0.ttl> a owl:Ontology ;\n    rdfs:label \"Kosmion ontology\" ;\n    rdfs:comment \"A foundational ontology for modeling relators, relationships, and temporal aspects.\" ;\n    owl:versionInfo \"v0.1\" ;\n    owl:versionIRI <https://kosmion.github.io/ont/v0/kosmion-v0.0.1.ttl> ;\n    owl:imports <http://www.w3.org/2002/07/owl#> .\n\n# Define the relator class\nkosm:relator a owl:Class ;\n    rdfs:label \"relator\" ;\n    rdfs:comment \"A class representing relators, which describe relationships (including unary relationships) among entities.\" .\n\n# Define the context class\nkosm:context a owl:Class ;\n    rdfs:label \"context\" ;\n    rdfs:comment \"A class representing the applicable reality for the relationship represented by a relator.\" .\n\n# Define the type class, same as gUFO Type\nkosm:type a owl:Class ;\n    owl:equivalentClass gufo:Type ;\n    rdfs:label \"type\" ;\n    rdfs:comment \"A class representing types, equivalent to gUFO Type.\" .\n\n# Define relationship-type class as a subclass of type\nkosm:relationship-type a owl:Class ;\n    rdfs:subClassOf kosm:type ;\n    rdfs:label \"relationship type\" ;\n    rdfs:comment \"A class representing types of relationships.\" .\n\n# Define comparative-relationship-type as a subclass of relationship-type\nkosm:comparative-relationship-type a owl:Class ;\n    rdfs:subClassOf kosm:relationship-type ;\n    rdfs:label \"comparative relationship type\" ;\n    rdfs:comment \"A class representing types of comparative relationships.\" .\n\n# Define material-relationship-type as a subclass of relationship-type\nkosm:material-relationship-type a owl:Class ;\n    rdfs:subClassOf kosm:relationship-type ;\n    rdfs:label \"material relationship type\" ;\n    rdfs:comment \"A class representing types of material relationships.\" .\n\n# Define datatype-relation property\nkosm:datatype-relation a owl:DatatypeProperty ;\n    rdfs:domain kosm:relator ;\n    rdfs:label \"datatype relation\" ;\n    rdfs:comment \"A super-property for capturing datatype relations described by a relator.\" ;\n\n# Define object-relation property as a super-property for relationships described by a relator\nkosm:object-relation a owl:ObjectProperty ;\n    rdfs:domain kosm:relator ;\n    rdfs:label \"object relation\" ;\n    rdfs:comment \"A super-property for capturing object relations involved in relationships described by a relator.\" .\n\n# Define relator-genesis property\nkosm:relator-genesis a owl:DatatypeProperty ;\n    rdfs:domain kosm:relator ;\n    rdfs:range xsd:dateTimeStamp ;\n    rdfs:label \"relator genesis\" ;\n    rdfs:comment \"The timestamp when the relator was created.\" .\n\n# Define relator-tombstone property\nkosm:relator-tombstone a owl:DatatypeProperty ;\n    rdfs:domain kosm:relator ;\n    rdfs:range xsd:dateTimeStamp ;\n    rdfs:label \"relator tombstone\" ;\n    rdfs:comment \"The timestamp when the relator became invalid or ended.\" .\n\n# Define SHACL constraints\nkosm:relator-shape a sh:NodeShape ;\n    sh:targetClass kosm:relator ;\n    sh:property [\n        sh:path kosm:relator-genesis ;\n        sh:minCount 1 ;\n        sh:maxCount 1 ;\n        sh:datatype xsd:dateTimeStamp\n    ] ;\n    sh:property [\n        sh:path kosm:relator-tombstone ;\n        sh:maxCount 1 ;\n        sh:datatype xsd:dateTimeStamp\n    ] ;\n    sh:property [\n        sh:path kosm:object-relation ;\n        sh:minCount 1\n    ] .\n\n\n```","n":0.052}}},{"i":4906,"$":{"0":{"v":"Concepts","n":1}}},{"i":4907,"$":{"0":{"v":"Unique Identifiers","n":0.707},"1":{"v":"\n## Thoughts\n\n- IRIs are identifiers, \n- [with k-sortable IDs,] You may be allowing your storage needs to escape abstraction layers. \n- \"If you ever make these values end-user visible, you are leaking info that you might not realize... why should Alice be allowed to know, to within a second, when Bob created their account? This could be misused, or dangerous, in some applications. \"\n\n## Possible Solutions\n\n[[prdct.ulid]]: 128-bit UUID compatible, with 48 bits timestamp, 80 bits random.\n\n[[prdct.snowflake]]: 64-bit, with 41 bits timestamp, 10 bits machine ID, 12 bits per-machine sequence. This may be the oldest, but one of the most relevant as it was invented by Twitter, and both Discord and Instagram are using variations of it.\n\n[[prdct.uuid.v6]]: 128-bit UUID, with 64 bits timestamp (minus 4 bits UUID version embedded in it), 2 bits UUID variant, 14 bits “clock sequence”, and 48 bits random. Has a non-expired IETF draft.\n\n[[prdct.ksuid]] (K-Sortable Unique IDentifier): 160-bit, with 32 bits timestamp and 128 bits random. Created by Segment and probably mostly in use internally to them as well.\n\nStripe IDs: Like ch_1Iyqf42eZvKYlo2C4MIyA80e, are a combination of timestamp and random bits and base62 (-ish) encoded, although I don’t remember the proportions and didn’t spend the time reverse engineering them.\n\nFlake: 128-bit, with 64 bits timestamp, 48 bits machine ID, and 16 bits sequence. Created by Boundary (which is under new management) in Erlang, and best considered deprecated.\n\n[[prdct.nanoid]]  A ~~tiny~~ (124 bytes), secure, URL-friendly, unique string ID generator for JavaScript \n\n\n## References\n\n- https://brandur.org/fragments/k-sorted-ids\n- https://www.reddit.com/r/golang/comments/10bg0rn/which_uuid_package_do_you_use_and_why/\n- https://deepam-kapur.medium.com/ulid-and-snowflake-id-the-cool-coders-alternative-to-boring-uuids-1e772064f275","n":0.064}}},{"i":4908,"$":{"0":{"v":"Temporality","n":1},"1":{"v":"\n## Thoughts\n\n- maybe the triple format is not naturally up to the task of meta-modelled time\n- \n\n### temporal-context\n\n- calendar system\n- time-slice granularity\n- fluency approach?\n\n\n### genesis-timestamp\n  - has an associated store\n  - naturally precise, but could be fuzzed \n  - universal (even if not recorded)\n    - e.g. every keystroke has one, with a text editor (in-memory store)\n  - context is real-world, digital, \n  - can be preserved or not across different stores\n    - could be used for lineage\n      - e.g. on every copy, the data adds a tx-ts+store-identifier\n  - in RDF, a triple isn't enough (and using the graph in a quad wasteful) for expressing a transaction timestamp\n    - so need to add a transaction-timestamp statement\n    - but then you might go down an infinitely recursive rabbit hole of tx-timestamping the tx-timestamp statement \n      - maybe tx-ts triples are special, having a tx-ts equal to the tx-ts they encode\n    - if you use [[ko.concepts.relator]] exclusively, you are golden\n  - should be automated\n\n### tombstone-timestamp \n\n- formery \"invalidation-timestamp\", but needed a new name, because it treads on valid-time\n\n#### issues\n\n- should be stored outside the relator/data because who's to say when a piece of data is dead?\n\n#### uses\n\n- for immutable contexts, expresses \"not current\"\n  - can be complementary or an alternative to \"[[ko.concepts.successor]]\"?\n  - corrections, like data-entry errors or buggy pipeline\n- \n\n\n\n#### validity\n\n- validity-start, valid-at, invalidity-start, invalid-at\n  - only apply to relations\n- abstractions shouldn't lose validity\n\n- different kinds of validity\n  - \"in-world\"/\"in-application\"\n  - real-time\n  - decision-time/assertion-time replaces transaction time because, for the most part, who cares when it was recorded in a store. \n    - mostly, assertion-time would be equal to transaction time, at least in a \"live\" system\n\n#### immutability\n\n- might be helpful to differentiate between corrections and updates, but that line is very thin and unstable, \n  - e.g. in a role-playing experience platform where in-world facts get bent/corrected and truth is more of a \"what we decided worked best in the narrative\"\n  - i wanted to say abstractions are always true, but what about the case of corrections\n\n\n## Prior Art\n\n### \n\n![[ar.valid-time-rdf#instantiating-identifying-conceptrelationship-iir]]","n":0.054}}},{"i":4909,"$":{"0":{"v":"Temporality Log","n":0.707},"1":{"v":"\n## Thoughts\n\n- or maybe you just need an explicit external data store for every graph\n- maybe transaction time just isn't important... \n","n":0.213}}},{"i":4910,"$":{"0":{"v":"Successor","n":1},"1":{"v":"\n- when you keep track of history, and especially in immutable stores, it can be helpful to know when your data has been superceded\n- [[prdct.rdf.containers-vs-collections]] could apply, but better to use [[prdct.dcat-data-catalog.v3#dataset-series]]\n\n## References\n\n- [[ar.ontola.ordered-data-in-rdf]]","n":0.171}}},{"i":4911,"$":{"0":{"v":"Speech Act","n":0.707},"1":{"v":"\n- agency/speaker\n- everything that exists has some physical aspect, but some physical systems have sub-systems that support \"a-physical things\", and it can be useful to speak of those as universes of their own and abstract away the \"physical-prime\" context (that is kinda boring because it subsumes everything else). Call them sub-universes or subcontexts, eg., brains, computers, networked games.","n":0.131}}},{"i":4912,"$":{"0":{"v":"Relator","n":1},"1":{"v":"\n- aka: [[Relationship to Entity Conversion (REC)|ar.valid-time-rdf#relationship-to-entity-conversion-rec]]\n- facets provide a mixin-style impressionistic\n- the RDFS-style class is replaced by [[type facets|ko.concepts.facet]]\n  - rdfs:Class is still used in meta ways, e.g., classifying relators\n  \n## Benefits\n\n- relations can be temporalized and contextualized\n- supports unary and n-ary relations\n- multiple subjects can participate in relations\n- \n\n## What would it look like to have a \"domain-classes-as-individuals\" data model where relationships are primarily expressed by relators?\n\ninstead of \n\n```turtle\n:mattGroening :hasName \"Matt\" .\n:mattGroening :gaveName :bart .\n:bart :hasName \"Bart\" .\n:bart a :FictionalCharacter .\n:bart a :Person .\n:bart a :SimpsonFamily\n```\n\nwe would have\n\n```turtle\n:matt-groening-hasName-Matt a :NamingRelator ;\n  :named-thing :matt-groening ;\n  :name  \"Matt\" .\n\n:matt-groening-named-Bart a :NamingRelator ;\n  :name-giver  :matt-groening ;\n  :named-thing :bart ;\n  :name \"Bart\" .\n\n:bart-isa-Simpson a :MembershipRelator ;\n  :context :simpsons-world\n  :member :bart ;\n  :group :simpsons-family \n  .\n\n\n:bart-isa-character-in-reality a :KindRelator ;\n  :context :reality ;\n  :individual :bart ;\n  :kind :fictional-character # punning or OWL-Full\n  .\n\n:bart-isa-person-in-simpsons-world a :KindRelator ;\n  :context :simpsons-world\n  :individual :bart\n  :kind :Person # punning or OWL-Full\n  .\n\n```\n\nand then you can go to town with relator enhancement (temporality, attribution) etc.:\n\n```turtle\n:matt-groening-hasName-Matt a :NamingRelator ;\n  :named-thing :matt-groening ;\n  :name  \"Matt\" ;\n  :name-giver :margaret-groening ;\n  :name-giver :homer-groening ;\n  :when \"1954-01-10\"^approxInstant ;\n  :hadAssertionTimestamp \"2024-07-24T15:25:00Z\" .\n```\n\n\n## Thoughts\n\n- is that just making relations into \"assertions? Which are kinda events?\n- sure, a profusion of predicates, but it's still legible. As long as we have tools for creation, a profusion of predicates is okay\n\n## Benefits\n\n- can clarify the type/is-a relationships between individuals and classes\n  - i.e.,\n    - membership?\n    - kind?\n    - role?\n\n## Issues\n\n### Relator Naming\n\n- you could rename the relators without change the underlying \"data\"... e.g., if Sam Palmisano was CEO of IBM again, you could rename the original :Sam-Palmisano-CEO-of-IBM to :Sam-Palmisano-CEO-of-IBM-1 or :Sam-Palmisano-CEO-of-IBM-2002\n  - if you're going for immutability, do you need a new relator IRI as soon as the data changes? I guess so, but even if you're just adding predicate-object pairs to the same relator? \n    - gets into aliasing? \n    - gets into transactions... want to add all the roles and metadata at once.\n    - a \"record\" isn't really immutable if you add invalidation and successor metadata\n    - relevant to [[prdct.RDF-star]]: you should be able to annotate a set up triples. or treat a set of triples as a unit. maybe named-graph per relator?\n  - being \n\n### Inversion\n\n![[ar.a-reusable-ontology-for-fluelnts-in-owl#^zqsq4cdml6ud]]\n- I thought I saw somewhere that there would just be a profusions of inverse properties, but maybe it's actually impossible.\n- it seems like inversion might not be appliable to relator-based RDF. and that's probably okay. Who cares about ceoOf vs hasCEO when you have a ceo role and a company role on the same footing\n  - t.2024.10.07.09 for meaning, it obviates the need to distinguish between active and passive voices, although you might want to preserve that distinction for reasons of accuracy. I guess there might be small variations in meaning\n    - t.2024.10.25.02 you could have an additional property like \":subject\" (which I'd been, perhaps foolishly, using generically )\n\n## so the question becomes, generality\n\n```turtle\n:Sam-Palmisano-CEO-of-IBM a OrganizationalRoleRelator;\n  :role :CEO\n  :role-holder :Sam-Palmisano\n  :organization :IBM\n```\n ","n":0.045}}},{"i":4913,"$":{"0":{"v":"Relator Log","n":0.707},"1":{"v":"\n## t.2024.10.25.02\n\n### Removed\n\n- t.2024.08.09.20 what? more like traditional \"relationship directly expressed with predicate\" gets replaced by \"RelationshipClass has shapes, pieced together impressionistic style from meta-predicates\"\n-   :groupClass :SimpsonsFamily, foaf:Person. //kinda redundant, but that's OK","n":0.174}}},{"i":4914,"$":{"0":{"v":"Reification","n":1},"1":{"v":"\n## Truthmaking and Reification Patterns\n\n- [[ar.reification-and-truthmaking-patterns]] illustrates some options with [[prdct.ontouml]], but the most expressive involves reifing both qualities and quality occurences, and addresses the intrinsic/extrinsic and descriptive/non-descriptive axes\n\n## Singleton Properties\n\n","n":0.18}}},{"i":4915,"$":{"0":{"v":"Namespace","n":1}}},{"i":4916,"$":{"0":{"v":"Micro Graphs","n":0.707}}},{"i":4917,"$":{"0":{"v":"Meta Lattice","n":0.707},"1":{"v":"\n- maps relators to validity\n  - i.e., collects micro-graphs into a \"valid macro-graph\" that's associated with \"now\"\n\n## Thoughts\n\n- maybe a use case for @thomas-lorsch's \"states\" -- when no longer valid, change \"states\" to \"reifies\"? \n\n\n## Examples\n\n","n":0.167}}},{"i":4918,"$":{"0":{"v":"Immutability","n":1}}},{"i":4919,"$":{"0":{"v":"Graph","n":1}}},{"i":4920,"$":{"0":{"v":"Facet","n":1},"1":{"v":"\n- facets can be declared explicitly\n- hopefully they can be inferred implicitly based on the relator-atom profile, aka [[ko.concepts.aspect]]\n\n## Kinds of Facets\n","n":0.213}}},{"i":4921,"$":{"0":{"v":"Everything Perdurant","n":0.707},"1":{"v":"\n\n- Endurants have at least one temporal part. Or maybe at least two. But give people flexibility, they can always add restrictions\n![[t.phil.perdurantism#features]]\n\n## References\n\n- [[ar.a-reusable-ontology-for-fluents-in-owl]] old\n- [[ar.representing-temporal-information-in-lexical-linked-data]]\n- ","n":0.196}}},{"i":4922,"$":{"0":{"v":"Events","n":1},"1":{"v":"\n## Thoughts\n\n- Events are holonic, organic (changing through time) and often unstable. Ultimately, do events exist independently of observers/documentors/mentalists? Probably not. You could argue the big bang was an event. At least in the abstract, it has a pretty weighty footprint\n\n## Issues\n\n\n## References\n\n- [[ar.reification-and-truthmaking-patterns]]\n- [[ar.towards-ontological-foundations-for-the-conceptual-modeling-of-events]] \n- [ ] [[ar.towards-an-ontological-foundation-of-agent-based-simulation]]","n":0.143}}},{"i":4923,"$":{"0":{"v":"Dataset","n":1}}},{"i":4924,"$":{"0":{"v":"Dataset Series","n":0.707}}},{"i":4925,"$":{"0":{"v":"Context","n":1},"1":{"v":"\n\n- optional metadata\n- used to express things like:\n  - authorship\n  - data-entryship\n  - creatorship\n  - realityness\n  - abstraction in the sense of [[prdct.openwemi]]\n  - data paradigm\n  - theoretical paradigm\n  - meta-ness\n  - temporal universe\n  - lineage\n  - mutability\n  - data-sanitization, governance policy\n  - license\n- kinda like a named graph, except every triple/quad/graph/dataset can have multiple contexts\n\n## Uses\n\n- not repeating yourself\n- ","n":0.129}}},{"i":4926,"$":{"0":{"v":"Catalog","n":1}}},{"i":4927,"$":{"0":{"v":"Aspect","n":1},"1":{"v":"\n- a named combination (shape) of properties of things \n- maybe can be mapped to facets for implicit typing\n\n","n":0.229}}},{"i":4928,"$":{"0":{"v":"Agency","n":1},"1":{"v":"\n## References\n\n- [[book.agent-oriented-constructivist-knowledge-management]] has a chance of being helpful","n":0.333}}},{"i":4929,"$":{"0":{"v":"Requirements","n":1},"1":{"v":"\n- enables domain ontologies to capture the distinctions, overlap, and temporality of their physical, social, mental/conceptual, and representational/digital modalities without encumbering them with restrictions or too much complexity\n- supports class-like entities (types) as individuals... \"instances\" meaning classes as semantically rich components, mixins, traits, relator-types, \n  - interface with traditional RDFS/OWL Classes\n    - [ ] as subClasses\n    - [ ] as instances properties/relations\n- rich [[ko.concepts.events]] support\n\n### Intensional vs Extensional\n\n\n### Immutability \n\n- aka append-only\n- xtdb records are immutable, except for the end transaction time.\n  - see https://docs.xtdb.com/tutorials/immutability-walkthrough/part-4.html\n- corrections vs changes\n  - corrections ","n":0.105}}},{"i":4930,"$":{"0":{"v":"Relation Types","n":0.707}}},{"i":4931,"$":{"0":{"v":"LocatableContent","n":1},"1":{"v":"\n## ","n":1}}},{"i":4932,"$":{"0":{"v":"Now (Kosmion)","n":0.707},"1":{"v":"\n## *[Kosmion](https://djradon.github.io/wiki/notes/c5qcd8cate4ic318mkmmkn0)* Foundational Ontology\n\n* datasets, catalogs, named graphs, distributions\n* how to do multi-level\n* can facets/aspects replace classes\n\n","n":0.243}}},{"i":4933,"$":{"0":{"v":"Kosmion Log","n":0.707},"1":{"v":"\n## t.2024.08.08.13\n\n- \"micro-graph\" approach, where each relator is its own named graph, might have some benefits\n  - maybe you could preserve (some of) the classic S-P-O approach, layering on @christopher-welty's Ontology for Fluents\n\n\n- [x] regarding [[prdct.ontogen]], is it at odds with keeping history (of events, relator validity) in the dataset? i.e., RDF immutability or event-driven/relator-based RDF \n  - see [[pub.question-log.2024.08.16.ontogen-vs-relator-based-rdf]]\n  - graph-based versioning might be orthogonal to an immutable-ish data store (in text files, in git)\n\n# t.2024.08.17.12\n\n- everything that exists has some physical aspect, but some physical systems have sub-systems that support \"aphysical (supra-physical) things\", and it can be useful to speak of those as universes of their own and abstract away the \"physical-prime\" context (that is kinda boring because it subsumes everything else). Call them supra-universes or subcontexts, eg., a functioning brain, an operating computer, a networked game.\n- versioning everywhere... major signals breaking change, so there's value in using the major version with no minor specific as an alias to \"latest minor\"\n- there's value in aliasing your ontology to other used ontologies... avoids a profusion of namespacing. Maybe you don't like that other guy's uptime or prefix choices\n- how much of starting with a conventional ontology leak into [[ko.concepts.relator]]-based predication. \n- as long as the reference is unique, you can do nice aliasing that cuts through \n  - [ ] could do aliasing in RDF... maybe just an import statement pointing to current version.\n\n## t.2024.08.17.13\n\n- holonic RDF, where each level of aggregation gets its own versioning\n  - used-version\n  - WHAT WAS that [[ar.w3.cool-uris]] tech for appending stuff\n\n## t.2024.10.11.12\n\n- using [[prdct.unified-foundational-ontology.gUFO]] as a guide, my head is starting to swim.  \n\n## t.2024.10.13.07\n\n- [[prdct.prov-o]] has `qualifiedInfluence` and its subproperties:\n  - prov:qualifiedAssociation\n  - prov:qualifiedRevision\n  - prov:qualifiedInvalidation\n  - prov:qualifiedPrimarySource\n  - prov:qualifiedDerivation\n  - prov:qualifiedGeneration\n  - prov:qualifiedUsage\n  - prov:qualifiedQuotation\n  - prov:qualifiedStart\n  - prov:qualifiedAttribution\n  - prov:qualifiedEnd\n  - prov:qualifiedCommunication\n  - prov:qualifiedDelegation\n\n\n## t.2024.10.15.11\n\n- RelatorCatalog per entity collects all the RelatorSets, which are datasets where the default graph (mutable) points to the immutable named graphs. \n  - pointer isn't strictly necessary, but might speed querying, aid distribution-packing, or be used for consistency checking\n- damn, brain not working, why did we need a catalog of relatorsets?\n  - well, all the info about an entity might be split across different datasets. \n  - the fact that there's not an inverse property for dcat:dataset might be a hint, but it seems like data should be allowed to join itself? \n- Another reason for separating names from downloadURLs, you might want to shadow-recreate something on your own (or with local files)\n\n## t.2024.10.15.12\n\n- using IRI refs instead of anyURI helps clear the clutter, but maybe there'd be cases where you want to preserve a sourceURL and change the prefix\n- things aren't literally immutable in github, but quasi-immutability (aka stable) is better... allows you to preserve history but take out PI, typos, and embarassments.\n- for concision, maybe the \"current relator\" gets duplicated into the placeholder/primary entity?\n- it makes sense to be able to come at things from both ways, with atoms making claims on collectives/entities. named graphs as atoms probably makes the most sense.\n- atomicity is a facit.\n  - datatype-property-carrying\n- conventional RDF, esp. class hierarchy, only for interfacing with RDF and owl: only for owl.\n- ethos is: it's just guidelines. so lots of things should be in the \n\n## t.2024.10.15.16\n\n- http://www.w3.org/ns/prov#Agent should be a sublass of Entity? Or mayb eit doesn't matter. \n- probably I just just go for it, make kosm: the one stop shop for fixing everyone else's issues and integrating it. A ruthless and misleading-ish approach would be to steal the most popular terms.\n  - review 'em for\n    - domain and range are reasonable\n    - document is literal, sense is IRI.\n      - could use a new datatype for IRI that includes folder hierarchy pattern matching, I guess I can leave that to the computers to develop. we're just at v0 buddy.\n- is the time to modularize: right from the start?\n- full, core, facet-stereotypes, borrowed terms/mnemonic forks.\n- can you make a property's subproperty require different things\n  - e.g downloadURL, homepageURL, et al subproperty downloadIRI. ie.., a superproperty for objectprop/dataprop\n- it's going to be so great, you'll want to use quasi-immutable, facet-oriented RDF for your ontologies too.\n- make two versions avail, one with owl:includes, or rather kosm:includes means the same thing \n- everything is a data catalog, or rather, every decent (kosmethodology-compliant entity) is\n\n\n## t.2024.10.24.06\n\n- maybe a \"semantic repo\" is the top-level concept, with:\n  - ns/entity\n  - ns/graph\n  - ns/dataset\n  - ns/catalog\n\n## t.2024.10.24.11\n\n- maybe a dataset defines a graph of exportable data... stuff that's not about the dataset (i.e., no metadata). This is the \"metadata lives in the default graph\" pattern\n- maybe differentiate between EssentialsCatalog and RelevantCatalog, or just have the catalogs specify \n\n## t.2024.10.24.14\n\n- maybe need a ReverseList, \n  - would it work with last and rest?\n\n## t.2024.10.25.13\n\n- a rdf triple (or relator-atom) is not necessarily an assertion, it is just a configuration of content units or at best a statement. ","n":0.035}}},{"i":4934,"$":{"0":{"v":"Inspiration","n":1},"1":{"v":"\n## flexibility\n\n- give people flexibility (i.e., metaphysical neutrality), they can always add restrictions\n\n## Messiness\n\n- beware class-based conceptualizations\n  - \"A character in D&D might have traits that are completely uncommon for their class.\"\n  - types might be better\n\n\n## References\n\n- [[ar.hackernews.semantic-web-is-like-the-guy-that-tells-everyone-that-he-is-an-asshole#real-world-knowledge-is-quite-messy]]","n":0.16}}},{"i":4935,"$":{"0":{"v":"Design","n":1},"1":{"v":"\n- contextualized, immutable, bitemporal, multi-level things\n\n\n\n\n## from UFO/gUFO\n\n## gufo differentiates between comparative and material relationships. what is the benefit?\n\n- see \n\n### Types\n\n![[ar.incorporating-types-of-types-in-ontology-driven-conceptual-modeling#^18mad1ssk2w1]]","n":0.213}}},{"i":4936,"$":{"0":{"v":"Kosmion-related Conversations","n":0.707}}},{"i":4937,"$":{"0":{"v":"2024","n":1}}},{"i":4938,"$":{"0":{"v":"07","n":1}}},{"i":4939,"$":{"0":{"v":"23","n":1}}},{"i":4940,"$":{"1":{"v":"\n## Kosmion Charter\n\n### dave\n\nOK, Kosmion is going to be a foundational ontology that enables domain ontologies to capture the distinctions, overlap, and temporality of the physical, social, mental/conceptual, and representational/digital modalities without encumbering them with restrictions or too much complexity. Can I clarify any of that for you?\n\n### chatgpt\n\nGot it. Kosmion will be a versatile and foundational ontology that bridges various modalities. Here are a few points we might want to clarify or expand on to ensure a comprehensive understanding:\n\n1. **Core Concepts and Classes**: What are the primary classes and properties in Kosmion? How do they represent the different modalities (physical, social, mental/conceptual, representational/digital)?\n\n2. **Temporal Modeling**: How will temporality be represented in Kosmion? Are you looking to model events, states, or both? Will you use time intervals, points in time, or both?\n\n3. **Inter-Modality Relationships**: How do you plan to handle the relationships and interactions between the different modalities? Are there specific properties or classes that facilitate this?\n\n4. **Extensibility and Customization**: Since Kosmion is foundational, how easy will it be for domain-specific ontologies to extend or customize it? Are there guidelines or mechanisms to ensure consistency and interoperability?\n\n5. **Examples and Use Cases**: Can you provide some examples or scenarios where Kosmion would be used? This would help illustrate its application and versatility.\n\n6. **Complexity Management**: How do you plan to keep Kosmion from becoming overly complex? Are there design principles or strategies in place to maintain simplicity and avoid unnecessary restrictions?\n\nAny details or clarifications on these points will help in understanding and potentially refining Kosmion.\n\n### claude\n\nTo ensure a comprehensive understanding of Kosmion, we might want to clarify or expand on the following points:\n\n1. Foundational ontology: How does Kosmion define itself as a foundational ontology? What are its core principles or structures?\n\n2. Domain ontologies: How does Kosmion specifically enable or support the creation of domain ontologies?\n\n3. Modalities: Could you provide more detail on how Kosmion conceptualizes and distinguishes between the physical, social, mental/conceptual, and representational/digital modalities?\n\n4. Temporality: How does Kosmion handle or represent the temporal aspects of these modalities?\n\n5. Overlap: What mechanisms or concepts does Kosmion use to capture the overlap between different modalities?\n\n6. Complexity management: How does Kosmion balance the need for expressiveness with the goal of not encumbering domain ontologies with too much complexity?\n\n7. Practical application: Are there any specific use cases or domains where Kosmion has been or is intended to be applied?\n\n8. Relation to existing ontologies: How does Kosmion compare to or interact with other foundational ontologies?\n\nWould you like to elaborate on any of these points, or are there other aspects of Kosmion you'd like to discuss?\n","n":0.048}}},{"i":4941,"$":{"0":{"v":"10","n":1}}},{"i":4942,"$":{"0":{"v":"21","n":1}}},{"i":4943,"$":{"0":{"v":"Kosmion Dev","n":0.707},"1":{"v":"\n- interlocutor: chatgpt\n\n## kosmion dev 10/12\n\nIt looks like you're requesting a summary or update of the development related to Kosmion as of October 12th. Based on the most recent updates and your relator-based approach, here are some key details from the development of Kosmion up to this point:\n\n1. **Relator-Based Approach**: You’ve settled on using a relator-based structure, where predicates become classes, and specific predicate instances become expressions of those classes. This allows for greater flexibility in modeling relationships, and you’re considering avoiding OWL Full for now while continuing to refine the approach.\n   \n2. **Immutability & Bitemporality**: You’ve moved towards making Kosmion immutable with bitemporality using both 'system-time' (aka 'transaction-time') and 'valid-time' for temporal modeling. You're exploring the idea of system-time as external metadata that governs immutability, while valid-time is treated as internal data.\n\n3. **Naming and Metadata**: You've been working on a naming convention, leaning towards terms like 'genesis' and 'tombstone' (or 'relator-genesis' and 'relator-tombstone') to represent the birth and death of statements, and preferring 'relator-' as a prefix for metadata. \n\n4. **Slash-Based IRIs**: You're using slash-based IRIs for the Kosmion ontology, establishing a namespace (`https://kosmion.github.io/ont/v0/`) to structure the ontology.\n\n5. **Metadata vs. Data**: You clarified that metadata will not use relators. For example, class membership like `:Person1 a :Person` would be treated as metadata and not included in the relator framework.\n\n6. **Facets and Aspects**: There’s a developing idea where facets (singular properties) might contribute to aspects (emergent properties), but this is still in the exploratory phase for future discussion.\n\n7. **Versioning Strategy**: You are working on a versioning strategy for handling changes to the ontology, where typo corrections or mistakes would be classified as PATCH changes, adding new data would be MINOR, and changing existing data would be considered a MAJOR update.\n\n8. **Redundant Data**: You are considering duplicating relators from relator datasets into the corresponding entity datasets, favoring redundancy to enable consistency checks and smoother attribute management.\n\nIf you're looking for more specific details about progress from that date or an update on particular parts of development, let me know!\n\n\n## regarding #5, I'm thinking to supplant class membership with facets and/or aspects. The kosmion ontology itself might use class hierarchies, but I'd like it to use relators too if that ends up making sense.\n\n\nGot it! Replacing class membership with facets and/or aspects could give more flexibility, especially if emergent properties can dynamically represent membership or classification based on context. Using relators for class hierarchies within Kosmion also sounds interesting—it could open up new ways of expressing relationships between classes. If you find that relators streamline this kind of hierarchy without losing semantic clarity, it could unify the modeling approach.\n\nLet me know if you want to dive deeper into any aspect of this transition or explore how relators might fit into class hierarchies.\n\n## How does dolce use relators, aka reified relations.\n\nIn DOLCE (Descriptive Ontology for Linguistic and Cognitive Engineering), relators (also known as reified relations) are a key concept used to model complex relationships between entities. Here's how DOLCE approaches relators and reified relations:\n\n### Relators in DOLCE:\nA **relator** in DOLCE is an entity that mediates or relates two or more other entities (called \"relata\"). Instead of using a simple direct relation between two entities (like a binary predicate), DOLCE uses relators to represent more complex situations where additional contextual information or properties about the relationship itself are needed. This is often referred to as **reified relations** because the relationship is treated as a first-class entity (a relator) in the ontology.\n\n### Structure of Relators:\nIn DOLCE, a relator relates multiple entities by connecting them through **roles**. Each entity involved in the relation plays a specific role. The roles themselves are also explicitly modeled as individuals in the ontology.\n\n- **Relator**: An abstract object that represents the relationship as a first-class entity.\n- **Roles**: Define the part that each related entity plays in the relationship. Each role is connected to the relator.\n- **Mediated entities (relata)**: The entities that the relator connects through their respective roles.\n\n### Example:\nLet’s say we have a **marriage** relationship between two people. In DOLCE:\n- The **marriage** would be represented by a relator (i.e., the marriage itself is an entity).\n- Each spouse would be connected to the marriage relator by a **role** (e.g., \"spouse role\").\n- The actual individuals (the spouses) are the entities that play these roles.\n\nIn this case, the **marriage relator** connects the two individuals through their roles as spouses. This allows for adding more detailed information to the marriage (e.g., start date, location, legal status) that would be difficult to represent with just a direct relation between two individuals.\n\n### Formalization:\nIn DOLCE, relators are formalized as follows:\n- A **relator** is a subtype of **non-physical endurant** (meaning it is something that persists over time but is not physical).\n- Relators require at least two **roles** to be associated with them, and each role must be connected to an entity that participates in the relationship.\n- A role mediates between the relator and the specific entities.\n\n### Key Concepts in DOLCE:\n- **Endurants**: Persistent entities, including physical and non-physical ones.\n- **Perdurants**: Events or processes that occur in time (which can also be related via relators).\n- **Roles**: Functions or parts played by entities in the context of a relator.\n\n### Why Relators?\nRelators in DOLCE enable a more detailed and flexible modeling of relationships:\n1. **Contextual Information**: By treating relationships as entities, you can attach information directly to the relationship (e.g., temporal, spatial, or contextual properties).\n2. **Higher-order Relations**: Relators can mediate more than two entities, making them useful for complex n-ary relationships.\n3. **Explicit Role Representation**: By representing roles explicitly, DOLCE ensures clarity in how entities participate in a relationship.\n\n### Comparison with Kosmion:\nIn your **Kosmion ontology**, the use of relators seems aligned with DOLCE’s approach, where relators represent relationships between entities via roles. If you consider facets or aspects for class membership, relators could also manage the dynamics of how entities play certain roles, without committing to rigid class structures. If you decide to use relators for class hierarchies, you might model class relationships similarly to how DOLCE handles roles between entities and relators, giving you a way to represent evolving or contextualized classifications.\n\nWould this approach fit with your current direction for Kosmion? Let me know if you want to explore how these ideas might map onto your ontology!\n\n\n## Yes, I think it fits. One difference we've talked about: Kosmion would use relators even for unary relationships.\n\nGreat! That distinction makes sense, especially if you're aiming for a consistent and flexible way to represent all kinds of relationships, including unary ones, with relators. This could give you more power to manage the context and evolution of even simple relationships, treating them with the same depth as more complex ones. \n\nLet me know if you'd like to explore examples of how Kosmion could handle unary relators, or if you want to work out any specific cases!\n\n## Assuming a file-based repository of RDF data, could every file be considered a dataset?\n\nYes, in a file-based repository of RDF data, every file can be considered a **dataset** depending on how you want to organize and conceptualize the data.\n\nIn RDF terms, a **dataset** generally consists of a collection of **graphs**, which may include a **default graph** and any number of **named graphs**. Here’s how it could map to a file-based system:\n\n### Case 1: Single Graph Per File (Simplest Case)\n- **One file = One graph**: If each RDF file contains a single graph (whether a default graph or a named graph), then the file can be treated as a standalone dataset. This is common when dealing with smaller or more isolated datasets.\n- **Named Graph**: You could define the graph’s name in the file or, depending on the format, assume that the file implicitly represents the default graph.\n\n### Case 2: Multiple Graphs Per File\n- **One file = Multiple graphs**: If a file contains multiple named graphs, this is still aligned with the RDF dataset model. For example, a file could include several named graphs, and this file would represent a single RDF dataset with multiple components.\n- **Formats**: In formats like TriG (or N-Quads), which support multiple graphs in one file, this approach is straightforward. The file would act as a container for all the graphs, meaning each file is effectively a dataset.\n\n### Case 3: Dataset as a Conceptual Group\nEven if a file contains just a fragment of data, you can treat it as part of a larger conceptual **dataset**. In this case, your repository structure might represent:\n- A **collection of datasets**: Multiple files that each represent a part of a larger dataset. Here, files might correspond to different graphs, and the dataset is formed by aggregating these files.\n\n### Considerations:\n- **File Naming and Graph Identification**: If each file represents a named graph, you might want a consistent naming convention that reflects the graph name or a metadata header to identify it.\n- **Performance**: Treating each file as a dataset makes it easier to manage or update specific segments of the RDF data independently. However, performance considerations may arise depending on the number of files and how the data is queried or accessed.\n\n### Kosmion Context\nIn Kosmion, if you're using **relators** and possibly adopting **named graphs** for each relator, treating each file as a dataset containing one or more named graphs could fit well. This approach would allow you to:\n1. **Isolate relator-based clusters** in separate files.\n2. **Version or update individual relators** without needing to modify other parts of the ontology.\n\nThis would work especially well if you're aiming for a decentralized and modular file-based structure where each file represents a specific facet of your ontology.\n\nDoes this align with how you're thinking of structuring RDF data in Kosmion?\n\n## it does++\n\n- dave: So <dave-richardson> would represent an entity, every entity could reference at least one catalog which could \"live\" anywhere but <dave-richardson/catalog> would be a good first choice, and be referenced from the catalog dataset, say <dave-richardson/catalog/dist> which might have a Turtle distribution named <dave-richardson/catalog/dist/ttl>. But the entity itself could (and should, if no data catalog is referenced) identify at least one dataset directly that is considered the \"current\" dataset. So <dave-richardson/datasets/v1> could be the corresponding dataset. The different datasets would primarily be used for versioning or for spreading out data over multiple dataset files (in which case a data catalog should be used). I'm inclined against a dataset per relator. I'm not sure what role the named graphs would play any more if there's a dataset per version. Maybe metadata.\n\n- chatgpt:\n\nIt sounds like you've settled on a clean structure for organizing entities and datasets, where catalogs and datasets play distinct roles. I think your approach strikes a good balance between modularity (with catalogs) and versioning (with datasets like `<dave-richardson/datasets/v1>`). This allows flexibility in terms of data distribution while keeping a \"current\" dataset accessible when necessary.\n\n### Named Graphs and Metadata\nSince you're thinking about named graphs potentially being useful for metadata, that could work well for things like:\n- **Provenance information**: Tracking where the data came from or who created it.\n- **Versioning info**: Storing details about when and how a particular dataset was created or modified.\n- **Contextual data**: If you need to add contextual information (e.g., temporal or spatial data) to a dataset, a named graph could isolate that metadata without cluttering the primary data.\n\nIf you decide to avoid using named graphs for the data itself and instead focus on datasets per version, using them just for metadata makes sense, keeping the structure straightforward.\n\nLet me know if you want to explore any of these aspects further!\n\n\n## Default Representations\n\n- dave: I wouldn't say settled. But certainly a possibility. There's probably value in the idea of a \"default representation\" and \"default catalog\", where the person with access to the IRI-enclosing namespace has control of default and alternate representations , but can delegate total control (by pointing to someone else's data catalog AND default dataset) or partial control (delegating either one). A default catalog could specify its own default represenetation, so there could effectively be two defaults. But that's okay.\n\n- chatgpt: \n\nThat makes sense, especially with the flexibility of delegating control over the catalog or dataset. Having a **\"default representation\"** and **\"default catalog\"** controlled by the namespace owner, while allowing delegation, gives you a powerful mechanism for managing data access and structure. It also opens up the possibility of collaborative or distributed data management without losing control over the core representations.\n\nThe potential for two defaults (one for the representation and one for the catalog) doesn’t seem problematic, especially if each serves a distinct purpose. The default catalog could handle the organization of data, while the default representation could specify how the data is accessed or interpreted.\n\nIf you're still exploring, this setup offers a lot of flexibility. Let me know if you want to dive deeper into specific delegation scenarios or ways to manage defaults!\n\n\n## ontology vs semantic data\n\n- dave: can you provide references to papers, articles, blog posts, or social media where people argue that ontology does not imply \"semantic data\" in general or \"knowledge graphs\" in general? That the term \"ontology\" should be reserved for domain concepts, analagous to a schema?\n\n- chatgpt:\n\nThere are multiple discussions and arguments that highlight the difference between ontologies and the broader concepts of \"semantic data\" or \"knowledge graphs,\" where the term \"ontology\" is often more narrowly defined.\n\n1. **Ontologies as Domain-Specific Models**: Some experts argue that an ontology should primarily be viewed as a structured, domain-specific framework for organizing concepts, more analogous to a schema. This perspective suggests that ontologies provide a controlled vocabulary and relationships specific to a domain, whereas knowledge graphs often involve broader integration of data, including instance-level data, which isn't always tied to an explicit, domain-specific ontology. For example, ontologies like the **Gene Ontology** (GO) are specifically tailored to biological knowledge, focusing on well-defined relationships within that context, distinct from general knowledge graphs that handle diverse or cross-domain data【34†source】【35†source】.\n\n2. **Ontologies vs. Knowledge Graphs**: It is often emphasized that **knowledge graphs** are not synonymous with ontologies. Knowledge graphs may include data representations that don’t leverage full semantic inferencing or may involve vast amounts of instance data (like Google’s Knowledge Graph) without the formal semantics typical of an ontology. Some argue that the **schema** in a knowledge graph can exist without the rich conceptual relationships that define an ontology【33†source】【34†source】.\n\n3. **Schema vs. Ontology**: Ontologies are often described as more flexible and expressive frameworks than rigid schemas, but there are arguments that ontologies should focus solely on domain modeling, similar to a schema, rather than broader tasks like data integration or reasoning across large datasets, which are common use cases for knowledge graphs. In this view, ontologies should serve as a \"blueprint\" for domain concepts, focusing on classes and relationships, rather than extending into instance data and semantic reasoning that knowledge graphs address【35†source】【36†source】.\n\nIn summary, many argue that ontologies should remain more like a **schema**, focused on domain concepts, rather than being conflated with the broader tasks of **semantic data** or **knowledge graphs**, which may encompass much more than what ontologies are intended to model.\n\n## So I want to be able to apply metadata like context (the reality where the statements are asserted true), system-time (the period for which they were asserted), and attribution (who asserted) to be applicable on two levels: the individual relator and the datasets (i.e., all relators in the dataset). Maybe context includes the other. But maybe we need a term other than metadata, because it's really more just data. e.g. :Bart  a :Person in context:Simpsons-World\n\nYour idea of applying context, system-time, and attribution as **data** rather than metadata makes sense, especially given that these elements are intrinsic to the assertions themselves. The distinction you're making is crucial: these aren't just metadata annotations but are part of the core reality being modeled.\n\nTo apply this at **two levels**—for both the **relator** and the **dataset**—you can think of:\n\n### 1. **Relator-Level Context**:\nEach relator would carry its own information about:\n- **Context**: The world or reality where this relation holds true. For example, `context:Simpsons-World` applies directly to a relation like `:Bart a :Person`.\n- **System-Time**: The period during which the relation is valid, possibly encoded as the system-level start and end times.\n- **Attribution**: Who asserted or originated the relation, possibly using a relator-creator property.\n\nExample (relator-level):\n```turtle\n:Relator1 a :KnowsRelator ;\n    :subject :Bart ;\n    :object :Homer ;\n    :context context:Simpsons-World ;\n    :relator-genesis \"2024-10-21T00:00:00Z\"^^xsd:dateTime ;\n    :relator-creator :MattGroening .\n```\n\n### 2. **Dataset-Level Context**:\nFor dataset-level context, which would apply to all relators in a dataset, you might specify a broader context that encompasses all the relations in the dataset. This would be useful for large-scale assertions, like stating that all relations in a file apply to a certain reality, were asserted within a certain time frame, or were all attributed to the same source.\n\nIf you treat context as hierarchical or containing other elements, this could mean that the dataset-level context applies as a broader frame, and the relator-specific context could add nuance or specialize it.\n\nExample (dataset-level):\n```turtle\n:Dataset1 a :Dataset ;\n    :context context:Simpsons-Universe ;\n    :dataset-creator :MattGroening ;\n    :system-time-start \"2024-10-21T00:00:00Z\"^^xsd:dateTime ;\n    :system-time-end \"2024-11-21T00:00:00Z\"^^xsd:dateTime .\n```\n\nAll relators in `Dataset1` would inherit `context:Simpsons-Universe`, unless overridden by individual relators. This allows you to:\n- Apply broad contexts or attribution to all relations.\n- Specialize individual relations with more granular context or time-based assertions if needed.\n\n### Naming Considerations\nYou mentioned looking for another term besides \"metadata.\" Since you're thinking of these as part of the **core data**, you could use terms like:\n- **Contextual Data**: Emphasizing that this is part of the relation itself, not external metadata.\n- **Assertion Context**: This could indicate the reality or system-time in which the assertion is true.\n- **Relational Scope**: To emphasize that context applies to the scope in which relations are true or valid.\n\nThis dual-level structure could work well with your relator-based approach, especially when combined with versioning and system-time management. Let me know if you'd like further refinement on specific areas!\n\n## Actually, I guess there should be three levels. The third is \"[named] graph\"\n\nAdding a **third level** for the **named graph** is a logical extension that helps organize and scope the applicability of context, system-time, and attribution more precisely. Here's how this might break down:\n\n### 1. **Relator-Level Context**:\nAt the most granular level, each individual relator can carry its own context, system-time, and attribution data. This would allow fine-tuned control over the assertions made by that specific relation.\n\nExample:\n```turtle\n:Relator1 a :KnowsRelator ;\n    :subject :Bart ;\n    :object :Homer ;\n    :context context:Simpsons-World ;\n    :relator-genesis \"2024-10-21T00:00:00Z\"^^xsd:dateTime ;\n    :relator-creator :MattGroening .\n```\n\n### 2. **Named Graph-Level Context**:\nNamed graphs serve as a middle layer, where all assertions (relators) within a graph share common metadata. This is ideal when a collection of assertions is being grouped under a particular context, time frame, or source.\n\nExample:\n```turtle\nGRAPH <http://example.com/graph/simpsons> {\n    :Relator1 a :KnowsRelator ;\n    :subject :Bart ;\n    :object :Homer .\n    :Relator2 a :WorksForRelator ;\n    :subject :Homer ;\n    :object :SpringfieldNuclearPlant .\n}\n<http://example.com/graph/simpsons> :context context:Simpsons-World ;\n    :system-time-start \"2024-10-01T00:00:00Z\"^^xsd:dateTime ;\n    :attribution :MattGroening .\n```\n\n### 3. **Dataset-Level Context**:\nAt the highest level, a dataset containing multiple named graphs could also include shared context, system-time, and attribution that apply to all the named graphs and their relations. This can provide a blanket set of metadata for all graphs in a dataset, but individual graphs or relators can still override this if necessary.\n\nExample:\n```turtle\n:Dataset1 a :Dataset ;\n    :context context:Simpsons-Multiverse ;\n    :dataset-creator :Fox ;\n    :system-time-start \"2023-01-01T00:00:00Z\"^^xsd:dateTime .\n\nGRAPH <http://example.com/graph/simpsons> {\n    :Relator1 a :KnowsRelator ;\n    :subject :Bart ;\n    :object :Homer .\n    :Relator2 a :WorksForRelator ;\n    :subject :Homer ;\n    :object :SpringfieldNuclearPlant .\n}\n```\n\n### Usage Breakdown:\n- **Relator Level**: Fine-grained metadata for specific relations, useful for capturing individual attribution or time context.\n- **Named Graph Level**: Shared metadata for collections of relations, allowing you to group relators with common metadata.\n- **Dataset Level**: High-level metadata that applies across multiple named graphs, providing context for versioning or large-scale assertions.\n\nThis structure gives you flexibility at every level, ensuring that metadata (or context) is precisely scoped based on how detailed or broad you want the assertions to be.\n\nWould you like to dive deeper into any particular level or explore specific use cases for managing these contexts across multiple datasets or versions?\n\n\n## It really does get confusing with \"data about the thing\" vs \"data about the data\".  Maybe the default graph is always data about the data, and data about the thing is always contextualized?\n\nYou're absolutely right that the distinction between \"data about the thing\" and \"data about the data\" can get confusing, particularly when modeling metadata in RDF or related structures.\n\nOne way to resolve this is by clearly separating **contextualized data (about the thing)** from **metadata (about the data itself)**. Your suggestion to use the **default graph** for metadata and **contextualized graphs** (e.g., named graphs) for the actual data makes a lot of sense.\n\n### Conceptual Framework:\n\n1. **Default Graph for Metadata**:\n   The **default graph** can contain system-level information, versioning, provenance, or any other data describing the structure or source of the dataset. Essentially, this would be the \"data about the data\" that applies to the entire dataset or specific named graphs.\n\n   Example:\n   ```turtle\n   :Dataset1 a :Dataset ;\n       :creator :Fox ;\n       :version \"v1.0\" ;\n       :generatedAt \"2024-10-21T00:00:00Z\"^^xsd:dateTime .\n   ```\n\n2. **Named Graphs for Contextualized Data**:\n   **Named graphs** would then represent specific chunks of data that are contextualized within a particular reality, time period, or attribution. These named graphs are where the actual domain data (i.e., data about the thing) resides.\n\n   Example:\n   ```turtle\n   GRAPH <http://example.com/graph/simpsons> {\n       :Bart a :Person ;\n           :context context:Simpsons-World ;\n           :livesIn :Springfield .\n   }\n   ```\n\n3. **Separation of Concerns**:\n   - **Default Graph (Metadata)**: Contains all system-level information like who asserted the dataset, when it was generated, version control, etc.\n   - **Named Graphs (Contextualized Data)**: Contains data that is tied to specific domains, contexts, or realities, giving flexibility for handling different \"worlds\" or interpretations of the data.\n\n### Benefits:\n- **Clear separation** between **\"data about the thing\"** (which is in the named/contextual graphs) and **\"data about the data\"** (which is in the default graph).\n- This approach allows **flexibility** for managing multiple contexts or realities while ensuring that system-level metadata is isolated and easy to manage.\n  \n### Possible Pitfall:\nWhile this approach simplifies the structure conceptually, it requires careful handling during **querying** and **data updates**, ensuring the right graph is targeted for different types of information (metadata vs. contextual data).\n\nWould this approach fit with the structure you're envisioning for Kosmion, especially with the relator-based model? Let me know if you'd like to go deeper into any specific scenarios or practical implications!\n\n## If you store a complete snapshot every time (i.e., in a new graph or a new dataset), you don't really need deltas? You could note the delta source and reason per-relator, per graph, or per-dataset.\n\nYes, if you're storing a **complete snapshot** in each new graph or dataset, you effectively eliminate the need for deltas (which track only the changes between versions). Instead, you can still maintain a notion of **delta source and reason** for tracking why certain changes were made, without the complexity of reconstructing deltas for every change.\n\n### Here's how this approach could work:\n\n1. **Complete Snapshots**:\n   - Each version of your data is stored as a full snapshot in either a new **named graph** or a new **dataset**. This means that you have a full, self-contained version of the dataset at every point in time, which simplifies retrieval and avoids the complexity of managing deltas.\n\n2. **Delta Source & Reason**:\n   - Instead of storing explicit deltas, you could track the **source** of changes (who or what initiated the modification) and the **reason** (e.g., typo fix, data update, correction) at different levels: \n     - **Per-relator**: Each relator could carry metadata about its source and why it was updated or created.\n     - **Per-graph**: A named graph could carry metadata about the changes it contains and why the snapshot was made.\n     - **Per-dataset**: The dataset as a whole could track a high-level reason for its creation, versioning, and updates.\n\n### Example:\n```turtle\n:Dataset1 a :Dataset ;\n    :version \"v1.0\" ;\n    :createdBy :Fox ;\n    :reason \"Initial data ingestion\" .\n\nGRAPH <http://example.com/graph/simpsons-v1> {\n    :Bart a :Person ;\n        :livesIn :Springfield .\n}\n\n:Dataset2 a :Dataset ;\n    :version \"v2.0\" ;\n    :createdBy :Fox ;\n    :reason \"Updated location for Bart\" .\n\nGRAPH <http://example.com/graph/simpsons-v2> {\n    :Bart a :Person ;\n        :livesIn :Shelbyville ;\n        :relator-delta-source :User123 ;\n        :relator-delta-reason \"Correction\" .\n}\n```\n\nThis model allows you to retain **complete version histories** while still explaining why changes were made, at whatever level of granularity you need.\n\n### Advantages:\n- **Simplifies management**: No need to compute or manage deltas between versions.\n- **Easy retrieval**: Any version can be retrieved as a full snapshot without needing to reconstruct it from earlier versions.\n- **Context for changes**: You still maintain the ability to explain why changes happened and who made them without adding complexity to the data structure.\n\n### Use Cases:\nThis approach works well when:\n- **Storage** is not a constraint, as you’re storing full snapshots.\n- **Data auditability** is important, and you want to track changes explicitly at various levels.\n  \nWould this fit with your plans for Kosmion? Let me know if you'd like to explore any details further!\n\n## In my Kosmion ontology, where I want to embrace multi-level theory where things are individuals and classes. Can you think of any places \"owl:NamedIndividual\" could be useful. \n\nIn your Kosmion ontology, which aims to embrace **multi-level theory** where things are both **individuals and classes**, **owl:NamedIndividual** could be quite useful in several ways. Here are some key areas where it could be applied:\n\n### 1. **Multi-Level Entities**\nIn a multi-level ontology, entities can exist at different levels (e.g., a template or a prototype that is both an instance and a class). **owl:NamedIndividual** allows you to represent an entity that is both a concrete individual and a class that can have instances. For example, an individual reality like `:RealityPrime` could be both:\n- An **instance** of the class `:Reality` at one level, and\n- A **class** for other, more specific realities (e.g., `:SimpsonsWorld`).\n\nThis dual representation fits with **multi-level modeling**, where levels of abstraction coexist, and something can be a concrete individual while also serving as a type.\n\n### 2. **Relators as Individuals and Classes**\nYour relator-based approach could also benefit from **owl:NamedIndividual** when a relator serves both as a specific instance of a relationship (linking specific entities) and as a general class of relationships. For instance:\n- A specific relationship like `:BartKnowsHomerRelator` could be a **NamedIndividual** while also being a **class** that other similar relationships instantiate (e.g., `:LisaKnowsMargeRelator`).\n\n### 3. **ETDF Datatypes as Individuals and Classes**\nSince you've mentioned EDTF datatypes are both classes and individuals, **owl:NamedIndividual** can allow you to treat a particular date format as both:\n- A **class** representing a general type of date, such as `EDTF_Year`.\n- An **individual**, such as `EDTF_Year2024`, which is a concrete instance of that type.\n\n### 4. **Contexts or Worlds**\nIf you're modeling different **contexts or worlds** (e.g., `:SimpsonsWorld`, `:RealityPrime`), these can be treated as **NamedIndividuals** that are both:\n- **Concrete instances** of broader categories of realities or contexts.\n- **Classes** that further specialize into more specific contexts (e.g., `:SimpsonsSeason1`).\n\n### 5. **Facets as Both Instances and Classes**\nIf you're implementing **facets** (singular properties) as a fundamental unit, a facet can be both an individual and a class. For instance, a facet like `:Gender` can be an individual, but you might also want it to act as a class for more specific instantiations such as `:Male` or `:Female`.\n\nBy using **owl:NamedIndividual**, you can manage this fluid boundary between **types and instances**, allowing entities to operate as both, depending on the context or level in the ontology.\n\nWould this structure align with your multi-level modeling needs in Kosmion? Let me know if you’d like to explore specific examples!\n\n## instead of IRI-naming things with a \"v1\", \"v2\", should we just number consecutively as \"1\", \"2\", skips parsing and eliminates having to look at a lot of \"v\"s, but on the other hand, they do reduce ambiguity\n\n\nUsing consecutive numbering like \"1\", \"2\", instead of prefixes like \"v1\", \"v2\" for versioning has pros and cons depending on your goals:\n\n### Pros of Consecutive Numbering:\n1. **Simplifies Parsing**: Without the \"v\", parsing is easier, especially in automated processes where distinguishing the version number from the rest of the IRI might be unnecessary. It reduces the need to strip characters or check for prefixes.\n2. **Visual Cleanliness**: Eliminates the extra character, making IRIs cleaner, especially when working with long or deeply nested IRI structures.\n\n### Cons of Removing \"v\":\n1. **Potential Ambiguity**: The absence of the \"v\" could lead to confusion if the numbering scheme isn’t immediately clear to users or systems. For example, without the \"v\", it may not be obvious that \"1\" or \"2\" represents a version number.\n2. **Context Clarity**: Using \"v\" explicitly denotes that the number refers to a version, making it clear that you're referring to different snapshots or states of the same entity or dataset, which helps especially in collaborative or public settings where multiple versioning schemes may coexist.\n\n### Trade-off:\n- **Consecutive numbering** is more concise and simplifies processing but may sacrifice some of the clarity provided by explicitly marking versions.\n- **Including \"v\"** helps ensure that it's immediately clear the number is a version, but it introduces a slight increase in complexity for parsing and visual scanning.\n\nIf your environment prioritizes clarity and collaboration across teams or users unfamiliar with the specifics of the system, keeping the \"v\" might be preferable. If you're working in a more controlled, internal system where reducing complexity and maximizing efficiency is key, skipping the \"v\" could be an advantage.\n\nYou could also consider making the decision based on the **context** where the versions will be used.\n\n\n## How can I distinguish between a dataset and thing described by a dataset.\n\nTo distinguish between a **dataset** and a **thing described by a dataset** within an RDF or OWL context, you can follow these guidelines:\n\n### 1. **Dataset as Metadata Carrier**:\nA **dataset** typically represents a collection of statements, which can be about many things (entities, relationships, etc.). The dataset itself can have **metadata** that describes the **provenance**, **versioning**, or **context** of the dataset, separate from the entities it describes. You can represent a dataset as a **container** or **collection** of RDF triples, using something like **VoID (Vocabulary of Interlinked Datasets)** or **DCAT (Data Catalog Vocabulary)**.\n\nFor example, the dataset can be described like this:\n```turtle\n:Dataset1 a dcat:Dataset ;\n    dct:title \"Simpsons Data\" ;\n    dct:created \"2024-10-21\"^^xsd:date ;\n    dct:creator :MattGroening ;\n    dcat:distribution :SimpsonsDatasetDistribution .\n```\n\nThis metadata describes the dataset as a whole, not the entities described within the dataset.\n\n### 2. **Thing Described by a Dataset**:\nThe **things** described by the dataset are the actual entities (e.g., people, objects, concepts) that the RDF triples within the dataset describe. These are the **subject** or **objects** in the RDF data, like a person, organization, event, etc.\n\nFor example, a thing described by the dataset could be `:BartSimpson`, an individual entity that exists **inside** the dataset:\n```turtle\n:BartSimpson a :Person ;\n    :name \"Bart Simpson\" ;\n    :livesIn :Springfield .\n```\n\n### 3. **Using Named Graphs for Context Separation**:\nYou can use **named graphs** to separate **dataset-level** metadata from **entity descriptions**. The named graph contains the **descriptions of entities**, while the dataset itself (which might be the whole graph or collection of graphs) is associated with its own metadata.\n\nExample:\n```turtle\nGRAPH <http://example.com/graph/simpsons> {\n    :BartSimpson a :Person ;\n        :livesIn :Springfield .\n}\n```\n\nAnd then the dataset itself can have metadata:\n```turtle\n:SimpsonsDataset a dcat:Dataset ;\n    dcat:theme :FictionalCharacters ;\n    dcat:distribution <http://example.com/graph/simpsons> .\n```\n\n### 4. **Ontology-Based Differentiation**:\nIf you're working within OWL or another ontology, you can further differentiate the **dataset** from the **things it describes** by classifying them differently:\n- **Dataset**: Use classes like `dcat:Dataset`, `void:Dataset`, or `prov:Entity`.\n- **Things Described**: Use relevant **domain-specific classes**, such as `:Person`, `:Location`, `:Event`, etc.\n\nThis ensures clarity when defining the type of each resource.\n\nIn summary, you distinguish between a dataset and the things it describes by:\n- **Dataset**: Described using **metadata vocabularies** like DCAT, VoID, or PROV, representing the container or structure of the data.\n- **Things**: Represented as **domain-specific classes** that describe actual entities within the dataset. \n\nWould you like more specific examples for your Kosmion ontology?\n\n## IRI conceptual collisions\n\n- dave:\n\nLet me give you more background on my issue. Say there was an IRI \"https://example.org/BartSimpson\" that I want to refer to an individual, (e.g., an owl:Thing). Conventionally, if you retrieved some RDF from that URL, it would return a dataset about Bart Simpson. But then the IRI also refers to a dataset. even if the RDF returned is only a simple statement, e.g. \":BartSimpson a :Person\", that's still a dataset. Even if it's only metadata, e.g. ':BartSimpson rdfs:comment \"a page about Bart\"', it still a dataset. Even if it's a dcat Catalog pointing to places where data and metadata exist, or a pointer to a dcat catalog, that's all a dataset.\n\n- chatgpt:\n\nYou've described a common issue in RDF and linked data, where the **same IRI** is being used to refer both to an **individual** (such as a person, e.g., Bart Simpson) and to a **dataset** that describes that individual. This results in a conceptual collision between referring to an **entity** and referring to **data about the entity**.\n\n### Key Concepts:\n- **Individual (Entity)**: In this case, `:BartSimpson` is an **owl:Thing** (or possibly an `owl:NamedIndividual`), a real or fictional entity being described.\n- **Dataset**: The RDF returned from `https://example.org/BartSimpson` is a dataset, even if it contains only a single RDF statement like `:BartSimpson a :Person`.\n\n### Challenge:\nThe issue is that by convention, the IRI both points to **data about** Bart Simpson (a dataset) and to **Bart Simpson himself** (an individual entity). Even a simple RDF statement such as `:BartSimpson a :Person` can be considered a **dataset**. As a result, the IRI is overloaded with dual meaning, potentially causing confusion.\n\n### Solutions:\n1. **Separation of Concerns: Different IRIs for Entity and Dataset**:\n   A simple approach is to use **different IRIs** for the **individual** and the **dataset** that describes the individual.\n   - For example:\n     - Use `https://example.org/BartSimpson` to refer to **Bart Simpson** the individual.\n     - Use `https://example.org/datasets/BartSimpson` to refer to a **dataset** about Bart Simpson.\n   This way, the distinction is clear: one IRI points to the actual entity, while the other points to the dataset that describes the entity.\n\n2. **Use of Fragment Identifiers**:\n   Another approach is to use **fragment identifiers** (`#`):\n   - `https://example.org/BartSimpson` refers to the **individual** Bart Simpson.\n   - `https://example.org/BartSimpson#data` refers to the **dataset** about Bart Simpson.\n   Fragment identifiers are often used to distinguish between resources while keeping the base IRI the same, allowing a clean distinction between an entity and data about the entity.\n\n3. **Conventional Use of Linked Data Resources**:\n   You could follow the linked data pattern where:\n   - `https://example.org/BartSimpson` is understood to be the **individual** (the actual person or entity), and the RDF data returned provides descriptions **about** Bart Simpson (metadata). \n   In this case, the dataset is implicit, and it's common practice for the IRI to resolve to a dataset that describes the entity.\n   \n   However, this pattern leaves it ambiguous whether the IRI refers to the **entity** or the **dataset**. To resolve this ambiguity, you might:\n   - Include explicit metadata using vocabularies like **DCAT** or **PROV** to indicate that the dataset refers to a description **about** the individual, not the individual itself:\n     ```turtle\n     :BartSimpson a :Person ;\n        rdfs:comment \"This is Bart Simpson, a fictional character from The Simpsons.\" .\n\n     :BartSimpsonDescription a dcat:Dataset ;\n        dct:description \"A dataset about Bart Simpson.\" ;\n        dcat:keyword \"Simpsons, Character\" .\n     ```\n\n4. **Contextualizing Data with Named Graphs**:\n   If the dataset contains more detailed information and metadata, you can use **named graphs** to differentiate between the **data about the entity** and the **entity itself**. For example:\n   ```turtle\n   GRAPH <https://example.org/datasets/BartSimpson> {\n       :BartSimpson a :Person ;\n       :BartSimpson rdfs:comment \"Fictional character from The Simpsons.\" .\n   }\n   ```\n\n### Practical Takeaway:\n- **Different IRIs** for the entity and dataset are the most straightforward solution, ensuring clarity for both human users and machines.\n- **Fragment identifiers** offer a way to distinguish between different aspects (the individual vs. the dataset) while maintaining the base IRI.\n- If you prefer to keep a single IRI, you could lean on linked data conventions but include explicit metadata to clarify whether you're referring to the entity or the dataset.\n\nThis approach should help clarify the distinction between an **individual** and the **dataset** describing it in Kosmion or similar systems.\n\n## HTML is the answer anyhow\n\n- dave:\n\nIf I use different IRIs, how to I make the datasets and data catalogs discoverable from the initial IRI? Maybe just a web page? We've talked about metadata in the <head>, and you could also standardize on machine-readable body html. It's almost a shame that RDF apps would need to parse HTML, but on the other hand, using github for hosting those entity IRIs, it's gotta return HTML anyhow since there's no content negotiation.\n\n- chatgpt:\n\nGiven that you're using different IRIs for entities and datasets, and you're hosting them on platforms like GitHub where content negotiation isn't available, a **hybrid approach** combining **HTML web pages** with embedded **machine-readable metadata** could work well. Here’s a practical strategy for discoverability:\n\n### 1. **HTML as the Primary Content**\nThe entity IRI (e.g., `https://example.org/BartSimpson`) can resolve to a simple **web page** that provides:\n- **Human-readable information** about the entity (Bart Simpson).\n- **Embedded metadata** in the `<head>` using JSON-LD, RDFa, or similar, ensuring that RDF-aware applications can still extract semantic data without parsing the HTML body extensively.\n\nExample for `https://example.org/BartSimpson`:\n```html\n<html>\n<head>\n    <title>Bart Simpson</title>\n    <script type=\"application/ld+json\">\n    {\n      \"@context\": \"http://schema.org\",\n      \"@type\": \"Person\",\n      \"name\": \"Bart Simpson\",\n      \"sameAs\": [\n        \"https://example.org/datasets/BartSimpson\"\n      ]\n    }\n    </script>\n</head>\n<body>\n    <h1>Bart Simpson</h1>\n    <p>This page provides details about Bart Simpson, a fictional character from The Simpsons.</p>\n    <p>Explore related datasets: <a href=\"https://example.org/datasets/BartSimpson\">Bart Simpson Dataset</a></p>\n</body>\n</html>\n```\n\nThis setup:\n- **Human-friendly**: Displays entity information for typical web users.\n- **Machine-readable**: Embeds RDF via JSON-LD or RDFa in the `<head>` so RDF apps can process the structured data.\n- **Linked datasets**: Provides a clear link to the dataset IRI (`https://example.org/datasets/BartSimpson`) in both the **body** for humans and the **metadata** for machines.\n\n### 2. **Embedded Metadata in the `<head>`**:\nEmbedding machine-readable data in the `<head>` section allows RDF-aware applications to extract information without needing to parse HTML. For example, you can use:\n- **JSON-LD** (for its simplicity and wide adoption).\n- **RDFa** (for directly embedding RDF within the HTML).\n\n### 3. **Machine-Readable HTML Body**:\nThough parsing HTML body content isn’t ideal for RDF apps, you can **standardize your HTML output** with structured elements (like `microdata` or well-defined classes) that make it easier for parsers to extract data if necessary. For example:\n```html\n<div itemscope itemtype=\"https://schema.org/Person\">\n    <span itemprop=\"name\">Bart Simpson</span>\n    <link itemprop=\"sameAs\" href=\"https://example.org/datasets/BartSimpson\">\n</div>\n```\n\nThis provides **redundant but accessible metadata**, ensuring RDF-aware systems can work with the data, even if they need to extract it from the body.\n\n### 4. **Discovery Through Data Catalogs**:\nYou can use **DCAT (Data Catalog Vocabulary)** to make the dataset discoverable. The IRI for the dataset itself (`https://example.org/datasets/BartSimpson`) can contain metadata about the dataset, following DCAT or similar vocabularies:\n```turtle\n<https://example.org/datasets/BartSimpson> a dcat:Dataset ;\n    dct:title \"Bart Simpson Dataset\" ;\n    dct:creator :MattGroening ;\n    dcat:distribution <https://example.org/datasets/BartSimpson/dist/ttl> .\n```\n\n### 5. **Advantages of GitHub Hosting with HTML**:\nSince GitHub primarily serves static HTML:\n- **HTML-first**: Ensures that even users who land on the entity IRI will get a useful, human-readable page.\n- **Embedded metadata**: Keeps RDF-aware apps functional without requiring sophisticated content negotiation mechanisms.\n- **Scalability**: This method scales well, as each entity IRI can follow the same structure.\n\n### Conclusion:\nBy delivering **HTML pages** enriched with **embedded RDF metadata**, you ensure both **human usability** and **machine readability**, even when content negotiation isn’t available. This strategy fits well with GitHub Pages and other static hosting platforms, offering flexibility for both web and RDF-based applications.\n\nDoes this solution fit your needs, or would you like to dive deeper into any specific part?\n\n## RDF only available at \"dist\" IRI-URLs\n\n- dave:\n\nI think this approach will work. Let's switch the example from Bart to me. So my IRI is https://djradon.github.io/dave-richardson - it returns HTML pointing to my dataset and catalog distributions, which maybe should have IRIs themselves, but more imporantly, have distribution URLs. <dave-richardson/default/current/dist/> is a \"pointer IRI\" that refers to my \"default\" dataset distributions, which should all represent the same data in different formats, and which are individually pointers, e.g. <dave-richardson/default/current/dist/ttl> to a versioned dataset IRI, e.g. <dave-richardson/default/v1/dist/ttl>. By convention, the default dataset for a Thing should contain references to any data catalogs (which are also datasets), so follow the same convention, e.g. <dave-richardson/default-catalog/v1/dist/ttl>\n\n- chatgpt:\n\nYour approach using **pointer IRIs** to manage dataset and catalog distributions looks solid and provides a clear structure. Let’s break it down using your example for **https://djradon.github.io/dave-richardson**.\n\n### Structure for Dataset and Catalog Distributions\n\n1. **IRI for the Person (you)**:\n   - **https://djradon.github.io/dave-richardson**: This URL will point to an HTML page that contains information about you, Dave Richardson, and provides links to both the dataset and data catalogs. The HTML page will serve both human-readable content and machine-readable metadata using RDFa or JSON-LD.\n\n2. **Pointer IRI for Default Dataset Distributions**:\n   - **<dave-richardson/default/current/dist/>**: This \"pointer IRI\" refers to the **default dataset** distributions (current version) in various formats. Each of these distributions represents the **same data** in different formats like Turtle, JSON-LD, etc.\n   - Example of formats:\n     - **<dave-richardson/default/current/dist/ttl>**: Points to the **Turtle version** of the default dataset.\n     - **<dave-richardson/default/current/dist/jsonld>**: Points to the **JSON-LD version** of the default dataset.\n\n3. **Versioned Dataset IRIs**:\n   Each pointer to a format, like `<dave-richardson/default/current/dist/ttl>`, should in turn point to the **specific versioned dataset**:\n   - **<dave-richardson/default/v1/dist/ttl>**: A specific versioned Turtle dataset.\n   - You can increment these versions as needed (e.g., `v2`, `v3`, etc.).\n\n4. **Pointer IRI for Data Catalog**:\n   - **<dave-richardson/default-catalog/current/dist/>**: This IRI refers to the current distribution of your **default catalog**. Like datasets, the catalog can exist in multiple formats:\n     - **<dave-richardson/default-catalog/current/dist/ttl>**: Points to the **Turtle version** of the catalog.\n     - **<dave-richardson/default-catalog/v1/dist/ttl>**: Points to a specific version of the catalog.\n\n5. **Discoverability via HTML and Metadata**:\n   - The **HTML page** at `https://djradon.github.io/dave-richardson` can contain links and metadata pointing to these datasets and catalogs. Here’s a possible structure for embedding the metadata:\n     ```html\n     <html>\n     <head>\n         <title>Dave Richardson</title>\n         <script type=\"application/ld+json\">\n         {\n             \"@context\": \"http://schema.org\",\n             \"@type\": \"Person\",\n             \"name\": \"Dave Richardson\",\n             \"dataset\": [\n                 {\n                     \"@id\": \"https://djradon.github.io/dave-richardson/default/current/dist/ttl\",\n                     \"name\": \"Turtle Dataset\",\n                     \"distribution\": \"https://djradon.github.io/dave-richardson/default/v1/dist/ttl\"\n                 },\n                 {\n                     \"@id\": \"https://djradon.github.io/dave-richardson/default-catalog/current/dist/ttl\",\n                     \"name\": \"Catalog Distribution\",\n                     \"distribution\": \"https://djradon.github.io/dave-richardson/default-catalog/v1/dist/ttl\"\n                 }\n             ]\n         }\n         </script>\n     </head>\n     <body>\n         <h1>Dave Richardson</h1>\n         <p>This page provides links to my datasets and catalogs.</p>\n         <ul>\n             <li><a href=\"https://djradon.github.io/dave-richardson/default/current/dist/ttl\">Turtle Dataset</a></li>\n             <li><a href=\"https://djradon.github.io/dave-richardson/default-catalog/current/dist/ttl\">Catalog Distribution</a></li>\n         </ul>\n     </body>\n     </html>\n     ```\n\n### Summary:\n- **Entity IRI**: `https://djradon.github.io/dave-richardson` returns HTML with links to datasets and catalogs.\n- **Pointer IRIs**: `default/current/dist/` points to the latest version of the dataset in various formats.\n- **Versioned IRIs**: Versioned datasets (e.g., `default/v1/dist/ttl`) maintain a history of changes.\n- **Metadata in `<head>`**: Use JSON-LD to include machine-readable metadata in the HTML header for RDF apps.\n\nThis method ensures that both human users and RDF applications can easily access and navigate through your data catalogs and datasets.\n\nWould you like to explore any further details or tweaks to this setup?\n\n\n## Seems promising. maybe we'll dispense with default-catalog. Things need to be discoverable purely through RDF too, so maybe we make a set of file \"index.ttl\", \"index.jsonld\", etc available at the root to get things started.\n\n\nYour idea of dispensing with the **default-catalog** and making a set of files like `index.ttl`, `index.jsonld`, etc., available at the root for discoverability through RDF is a practical solution. Here's how you could implement it:\n\n### 1. **Root-Level Discovery Files**:\nProviding **index files** (`index.ttl`, `index.jsonld`, etc.) at the root of your IRI namespace allows RDF-aware systems to start from a known entry point. These files can provide pointers to datasets, distributions, and other relevant resources.\n\nExample of `index.ttl`:\n```turtle\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n@prefix dct: <http://purl.org/dc/terms/> .\n\n<https://djradon.github.io/dave-richardson/index.ttl> a dcat:Dataset ;\n    dct:title \"Index of Dave Richardson's Datasets\" ;\n    dcat:distribution <https://djradon.github.io/dave-richardson/default/current/dist/ttl> ;\n    dcat:distribution <https://djradon.github.io/dave-richardson/default/current/dist/jsonld> ;\n    dcat:distribution <https://djradon.github.io/dave-richardson/default/v1/dist/ttl> .\n```\n\nThis **index file** provides the first entry point for RDF applications, listing the available datasets and distributions in Turtle and JSON-LD formats.\n\n### 2. **File Naming Conventions**:\nBy adopting clear file naming conventions, you make it easy to navigate between different versions and formats. Here’s a breakdown of how files could be structured:\n- `index.ttl`, `index.jsonld`: For the initial discovery of resources.\n- `default/current/dist/ttl`, `default/current/dist/jsonld`: Points to the latest version of the dataset.\n- `default/v1/dist/ttl`, `default/v1/dist/jsonld`: Specific versioned datasets.\n\n### 3. **Self-Descriptive RDF Files**:\nEach file (`index.ttl`, `index.jsonld`, etc.) can include self-descriptive metadata that points to its purpose and other related resources. This way, both RDF and non-RDF-aware systems can start from the **root IRI** and navigate to all necessary datasets, catalogs, and distributions.\n\n### 4. **Discoverability**:\nThis approach ensures that everything is **discoverable purely through RDF** by using standard vocabularies like **DCAT** and **Dublin Core Terms (DCT)**. RDF clients can start with any of the **index files** and follow the links to the appropriate datasets.\n\nExample of how this works:\n- A client retrieves `https://djradon.github.io/dave-richardson/index.ttl`.\n- From there, it discovers links to the Turtle, JSON-LD, and other versions of the dataset (`default/current/dist/ttl`, etc.).\n- The client can follow the links to retrieve the actual data in the desired format.\n\n### 5. **Serving the Human-Readable HTML**:\nYou can still serve a **human-readable HTML page** at the root IRI (`https://djradon.github.io/dave-richardson`), but the RDF files (`index.ttl`, `index.jsonld`) will ensure that everything is also **machine-readable**.\n\nThis approach ensures both RDF and human users can access and navigate your datasets easily. Does this seem like a solid direction for your project?\n\n## maybe we don't need a dist IRI separate from the download IRI, e.g. https://djradon.github.io/dave-richardson/ds/default/v1/index.ttl\n\nBy using a direct download IRI like `https://djradon.github.io/dave-richardson/ds/default/v1/index.ttl` without a separate distribution IRI, you can simplify the structure and make it easier to access the actual dataset files. This approach eliminates the need for an additional \"distribution IRI\" that points to the data, which streamlines the navigation for both human users and machines.\n\n### Benefits of This Approach:\n1. **Simplicity**: Reducing the number of layers between the IRI and the actual data makes it easier to navigate. Users and machines can directly fetch the dataset files.\n   \n2. **Consistency**: By using a single IRI for both metadata and actual data, you maintain a consistent structure across your resources, reducing the complexity of managing multiple IRIs.\n\n3. **Better Alignment with RDF Discoverability**: If RDF clients and applications can directly access the actual files (e.g., `index.ttl`, `index.jsonld`), they don’t need to follow multiple links to get to the download point.\n\n### Updated Structure:\nInstead of:\n- **Pointer IRI**: `<dave-richardson/default/current/dist/ttl>`\n- **Download IRI**: `<dave-richardson/default/v1/dist/ttl>`\n\nYou can just use:\n- **Direct download IRI**: `https://djradon.github.io/dave-richardson/ds/default/v1/index.ttl`\n\nThis streamlined approach ensures that the dataset files are immediately accessible while still maintaining the flexibility to reference different formats and versions.\n\nIf you plan to reference different versions and formats, the URL structure can still maintain clear distinctions:\n- **Turtle**: `https://djradon.github.io/dave-richardson/ds/default/v1/index.ttl`\n- **JSON-LD**: `https://djradon.github.io/dave-richardson/ds/default/v1/index.jsonld`\n\nBy embedding this structure within your metadata or `index.ttl`, you ensure that everything remains discoverable and accessible.\n\nThis seems like a smooth way forward. Does it fit your plans?\n\n## sorry, I still want the pointer IRI to be separate, it's the \"dataset identity\", e.g. <dave-richardson/default/v1/>, but the download IRI is the same as the dataset IRI. it's a special convention, only distributions and similar things (i.e., file-level IRIs). they always refer to a web document, and I ideally also serve as the download IRI.\n\nThanks for clarifying! So your **pointer IRI** (e.g., `<https://djradon.github.io/dave-richardson/ds/default/>`) serves as an alias or reference for the **current** version of a dataset, possibly allowing for version aliasing or dynamic redirection to the latest dataset. \n\n### Usage Breakdown:\n\n1. **Pointer IRI**:  \n   - `<https://djradon.github.io/dave-richardson/ds/default/>`: This pointer IRI represents the **current version** of the dataset, which might alias or redirect to the latest dataset version. This simplifies access to the most up-to-date data without needing to reference specific versions every time.\n   \n2. **Versioned Dataset IRI**:  \n   - `<https://djradon.github.io/dave-richardson/ds/default/v1/>`: This IRI refers to a **specific version** of the dataset (version 1 in this case), which is distinct from the pointer IRI. It provides access to a stable versioned dataset, ensuring that specific versions can be referenced as needed.\n\n3. **File-level IRIs for Distributions**:  \n   Each distribution format (e.g., Turtle, JSON-LD) would be linked under the versioned dataset, like:\n   - `<https://djradon.github.io/dave-richardson/ds/default/v1/index.ttl>`: Turtle format.\n   - `<https://djradon.github.io/dave-richardson/ds/default/v1/index.jsonld>`: JSON-LD format.\n\n### Benefits:\n- **Pointer IRIs** simplify linking to the most recent data, especially in applications or systems that need to always point to the \"current\" version.\n- **Versioned dataset IRIs** ensure that older versions can still be accessed for consistency or archival purposes.\n- **File-level IRIs** offer the flexibility of accessing the data in different formats.\n\nThis approach keeps the flexibility you need for versioning while maintaining simplicity for users and systems looking for the current version of your dataset.\n\nDoes this structure seem right for what you’re aiming to do? Let me know if you'd like further adjustments!\n\n## probably the \"current\" pointer IRI should be <https://djradon.github.io/dave-richardson/ds/default/current> and <https://djradon.github.io/dave-richardson/ds/default/> could be the dataset IRI, which could return an index dataset, analagous to an index.html at index.ttl that could include a \"data catalog\" and pointers to other data catalogs.\n\nThe structure you've described makes sense for handling both the **dataset IRI** and the **current pointer IRI**:\n\n### Updated Structure:\n1. **Dataset IRI** (`<https://djradon.github.io/dave-richardson/ds/default/>`):\n   - This IRI represents the dataset as a whole and can return an **index dataset** (similar to an `index.html`). For example, an `index.ttl` file could serve as the entry point, providing an overview and linking to relevant resources, including pointers to **data catalogs** and other datasets.\n\n2. **\"Current\" Pointer IRI** (`<https://djradon.github.io/dave-richardson/ds/default/current>`):\n   - This IRI specifically points to the **current version** of the dataset, dynamically linking to the most up-to-date version (e.g., the latest version of the Turtle file).\n\n3. **Index Dataset**:\n   - The dataset IRI (`<https://djradon.github.io/dave-richardson/ds/default/>`) would return a **self-contained index**, such as `index.ttl`, which could:\n     - Include a **data catalog** listing all available datasets and distributions.\n     - Provide pointers to other **related catalogs** or datasets, essentially working like a directory or catalog for navigating through the data.\n\n### Example:\nThe `index.ttl` returned at `<https://djradon.github.io/dave-richardson/ds/default/>` could look like:\n```turtle\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n@prefix dct: <http://purl.org/dc/terms/> .\n\n<https://djradon.github.io/dave-richardson/ds/default/index.ttl> a dcat:Dataset ;\n    dct:title \"Index of Dave Richardson's Datasets\" ;\n    dcat:distribution <https://djradon.github.io/dave-richardson/ds/default/current> ;\n    dcat:distribution <https://djradon.github.io/dave-richardson/ds/default/v1/index.ttl> ;\n    dcat:distribution <https://djradon.github.io/dave-richardson/ds/default/v1/index.jsonld> ;\n    dcat:catalog <https://djradon.github.io/dave-richardson/ds/catalog1.ttl> ;\n    dcat:catalog <https://djradon.github.io/dave-richardson/ds/catalog2.ttl> .\n```\n\nThis approach aligns well with your goal of creating a structured, RDF-discoverable framework for datasets and catalogs. It offers flexibility, ease of navigation, and dynamic pointers to the most current data.\n\nWould this setup meet your expectations, or would you like to refine it further?\n\n## what happens when the pages.github.io site like djradon.github.io (which corresponds to the docs folder) has a name conflict with a repo served through github pags like djradon.github.io/wiki\n\nIn GitHub Pages, there can be **name conflicts** between a repository-based site (like `djradon.github.io/wiki`) and the user or organization site (`djradon.github.io`) because GitHub Pages serves different types of sites depending on the repository structure:\n\n1. **User/Organization Site** (`djradon.github.io`):\n   - This site corresponds to the repository named `djradon.github.io`. It is served at the root of the domain (e.g., `https://djradon.github.io/`), and its content typically comes from either the `main` or `master` branch, or a specific branch (e.g., `gh-pages`).\n\n2. **Project Site** (`djradon.github.io/wiki`):\n   - This site corresponds to a repository named `wiki`. Project sites are served in a subdirectory of the user/organization domain (e.g., `https://djradon.github.io/wiki/`).\n\n### **Conflict Scenario**:\nIf you have a folder in your user/organization site (e.g., `djradon.github.io` repository) named `wiki`, and you also have a GitHub Pages site in a repository named `wiki` (e.g., `djradon.github.io/wiki`), there could be a conflict about which content should be served at the URL `https://djradon.github.io/wiki/`.\n\n- **Priority**: GitHub will prioritize **project sites** over any similarly named folders in your user/organization site. This means that the content from the **`wiki` repository** will be served at `https://djradon.github.io/wiki/` rather than any folder named `wiki` in your `djradon.github.io` repository.\n\n### **Solutions**:\n1. **Rename the Folder in the User Site**: If you need to avoid the conflict, you can rename the folder `wiki` in the `djradon.github.io` repository to something else (e.g., `docs-wiki`).\n\n2. **Serve Content from Subdirectories**: If you want both your user site and project site, ensure they serve distinct paths. For example, you can move the conflicting folder to `djradon.github.io/docs/wiki` or some other non-conflicting path.\n\n3. **Different Subdomains**: If you need to maintain distinct content for both the user/organization site and the project site, consider using different subdomains or hosting the conflicting content elsewhere.\n\nLet me know if you'd like more detailed steps for managing this!\n\n## Best to have a relator bring together the class, individual, property, annotation if a thing is more than one of those? Then we might be able to preserve OWL 2 DL and still do multilevel. Just use the multi-alias\n\nUsing a **relator** to bring together the **class**, **individual**, **property**, and **annotation** for an entity that occupies multiple roles (e.g., a class and an individual) could indeed help preserve compatibility with **OWL 2 DL** while supporting **multi-level modeling**. Here's how this might work:\n\n### 1. **Relators as Mediators**:\nBy using a **relator** as the central entity, you can create a structure that ties together the different aspects of an entity, such as:\n- **Class**: Treats the entity as a type.\n- **Individual**: Treats the entity as a specific instance.\n- **Property**: Refers to the relationship the entity has with other things.\n- **Annotation**: Allows you to attach metadata or other annotations to the entity.\n\nThis structure prevents the **direct mixing** of OWL class and individual declarations that could otherwise violate OWL 2 DL constraints.\n\n### 2. **Example with Multi-Alias**:\nEach alias can reference different facets of the entity (e.g., one alias for the class role, another for the individual role). The **relator** can mediate these aspects and still allow inference or querying based on whether the thing is being treated as a class or an individual in a given context.\n\nExample structure:\n```turtle\n:Relator1 a :MultiLevelRelator ;\n    :individualAlias :EntityInstance ;\n    :classAlias :EntityClass ;\n    :annotationAlias :EntityAnnotation ;\n    :propertyAlias :EntityProperty .\n```\n\n### 3. **Preserving OWL 2 DL**:\nOWL 2 DL disallows mixing an entity's role as both a class and an individual, which is where this relator-based design helps:\n- By having the relator **bridge** these roles, you can keep the **class aspect** and **individual aspect** separate within OWL 2 DL but still maintain the **multi-level distinction**.\n- This approach would avoid OWL 2 DL's constraints about not treating the same IRI as both a class and an individual.\n\n### 4. **Multi-Alias**:\nThe **multi-alias** approach helps ensure that the entity is flexible in terms of how it is referenced in different contexts, enabling it to be treated as an individual, class, or annotation as needed.\n\n- **Alias for Class**: Allows the entity to function as a type in one context.\n- **Alias for Individual**: Permits the entity to act as a specific instance in another.\n- **Alias for Property**: Used to represent the entity in a relational context.\n- **Alias for Annotation**: Facilitates the addition of metadata or descriptive notes.\n\n### Benefits:\n- **OWL 2 DL Compliance**: By keeping the roles separated through the relator, you avoid violating OWL 2 DL's constraints, ensuring reasoners can still process the ontology.\n- **Multi-Level Flexibility**: You can manage entities that serve multiple roles without needing to compromise on their representation, achieving the desired multi-level modeling.\n  \nThis seems like a promising way to balance **multi-level theory** with the strict **OWL 2 DL** rules. Would you like to refine this further or explore more detailed examples?\n\n## is it dcat or datasets that differentiate a distribution\n\nThe **DCAT vocabulary (Data Catalog Vocabulary)** is the specification that explicitly defines the concept of a **distribution**. In DCAT:\n\n- **Dataset**: A collection of data, often structured and published in various forms or versions. It is the abstract representation of data.\n- **Distribution**: A specific **representation** or **format** of the dataset. This could be a CSV, JSON, Turtle, etc. The same dataset can have multiple distributions, each with a different media type or access URL.\n\n### How DCAT Differentiates a Distribution:\nDCAT distinguishes between datasets and distributions by associating each dataset with one or more distributions:\n- **dcat:Dataset**: Represents the overall dataset as an abstract entity.\n- **dcat:Distribution**: Represents a specific form in which the dataset is available. Each distribution points to a specific format, access method, or download link.\n\n### Example (in RDF Turtle):\n```turtle\n:daveRichardsDataset a dcat:Dataset ;\n    dct:title \"Dave Richardson's Dataset\" ;\n    dcat:distribution :datasetDistributionTTL ;\n    dcat:distribution :datasetDistributionJSON .\n\n:datasetDistributionTTL a dcat:Distribution ;\n    dct:format \"text/turtle\" ;\n    dcat:downloadURL <https://djradon.github.io/dave-richardson/ds/default/v1/index.ttl> .\n\n:datasetDistributionJSON a dcat:Distribution ;\n    dct:format \"application/ld+json\" ;\n    dcat:downloadURL <https://djradon.github.io/dave-richardson/ds/default/v1/index.jsonld> .\n```\n\nIn this example:\n- The **dataset** `daveRichardsDataset` has two **distributions**: one in **Turtle** format and another in **JSON-LD** format.\n- Each **distribution** specifies the **format** and provides a **download URL**.\n\n### Conclusion:\nIt is **DCAT** that differentiates a **distribution** by providing properties such as `dcat:distribution`, which ties a dataset to its various formats or access points. The **dataset** itself remains an abstract concept, while distributions represent the actual downloadable or accessible versions of the dataset.\n\n\n## in dcat, can catalogs point to other catalogs?\n\nYes, in **DCAT** (Data Catalog Vocabulary), **catalogs** can point to other catalogs. DCAT provides mechanisms to describe hierarchical or interconnected catalogs by linking datasets and catalogs across multiple layers.\n\nThe relevant property is:\n- **dcat:catalog**: This property allows a **dataset catalog** (i.e., an instance of `dcat:Catalog`) to point to other catalogs.\n\n### Example of Nested or Linked Catalogs:\nIn this case, one catalog references another catalog, forming a hierarchical structure.\n\n```turtle\n:catalog1 a dcat:Catalog ;\n    dct:title \"Main Catalog\" ;\n    dcat:dataset :dataset1 ;\n    dcat:catalog :catalog2 .\n\n:catalog2 a dcat:Catalog ;\n    dct:title \"Sub-Catalog\" ;\n    dcat:dataset :dataset2 .\n```\n\nIn this example:\n- **Main Catalog** (`catalog1`) includes both a dataset (`dataset1`) and a reference to another catalog (`catalog2`), which in turn contains its own datasets.\n\n### Use Case:\nThis feature allows you to:\n- Create **federated catalogs** or catalog networks where one catalog aggregates or links to other catalogs.\n- Organize catalogs hierarchically (e.g., a national catalog that links to regional catalogs).\n- Implement **catalog discovery** across multiple domains or repositories, making it easier to locate data across distributed systems.\n\nThis flexibility makes DCAT highly suitable for large or complex data ecosystems where multiple catalogs need to be linked together.\n\n## can dcat catalogue name graphs?\n\n**DCAT** (Data Catalog Vocabulary) does not explicitly provide support for **named graphs**. DCAT is focused on describing datasets, catalogs, and distributions, where a **dataset** refers to a collection of data and a **distribution** refers to the concrete format or access method for that data.\n\n### Workaround for Named Graphs in DCAT:\nYou can, however, model **named graphs** indirectly by treating each **named graph** as a separate **distribution** or **dataset** within DCAT. If a named graph represents a specific subset or version of a dataset, you can describe it as a distribution of a dataset.\n\nHere’s an example of how you might represent a named graph as a distribution:\n```turtle\n:dataset1 a dcat:Dataset ;\n    dct:title \"Main Dataset\" ;\n    dcat:distribution :namedGraphDistribution .\n\n:namedGraphDistribution a dcat:Distribution ;\n    dct:format \"application/n-quads\" ;\n    dcat:downloadURL <https://example.org/namedGraph> .\n```\nIn this case:\n- The **named graph** is treated as a specific **distribution** of the dataset, and its format is specified (e.g., N-Quads, which supports named graphs).\n- The **downloadURL** points to the resource where the named graph is available.\n\n### Custom Extension:\nIf named graphs are central to your use case, you could extend DCAT with custom properties or leverage **RDF Data Cube** vocabulary or **VoID** (Vocabulary of Interlinked Datasets), both of which are better suited for representing fine-grained RDF data structures, including named graphs.\n\nWould you like more details on modeling named graphs in RDF frameworks?\n\n\n## transplantability\n\n- dave:\n\ncould @base be used flexibly somehow, like to make RDF data more transposable? I'd like to be able to for a dataset or entire catalog, host it on a semantic flow site at the github user or organization of my choosing, and not have to manually replace all the prefixes and IRIs in every file.\n\n\n- chatgtp:\n\nYes, you can use **`@base`** in RDF Turtle files to make the data more **transposable** by allowing flexible handling of IRIs across different hosting environments, such as when moving datasets or catalogs between GitHub organizations or users. Here's how it could work:\n\n### Using `@base` Flexibly for Transposable RDF\nThe **`@base`** directive in Turtle allows you to define a **base IRI** that serves as a prefix for all relative IRIs in the file. This makes it possible to use **relative IRIs** instead of hardcoding absolute IRIs. By doing this, you can relocate your RDF data without having to change every IRI, making your datasets or catalogs more portable.\n\n### Example:\n1. **File Hosted at GitHub**:\n   Assume your dataset is currently hosted at `https://user1.github.io/my-dataset/`. You can structure your Turtle file like this:\n   \n   ```turtle\n   @base <https://user1.github.io/my-dataset/> .\n   \n   :Item1 a :Thing ;\n       rdfs:label \"Item 1\" ;\n       foaf:homepage </homepage> .\n   ```\n\n   Here, `</homepage>` resolves to `https://user1.github.io/my-dataset/homepage`.\n\n2. **Transposing to Another Hosting Location**:\n   If you move the dataset to a different GitHub user or organization, say `https://org2.github.io/my-dataset/`, you only need to update the **`@base`** directive in the file, without changing the rest of the IRIs:\n   \n   ```turtle\n   @base <https://org2.github.io/my-dataset/> .\n   ```\n\n   Now, the relative IRI `</homepage>` will resolve to `https://org2.github.io/my-dataset/homepage`.\n\n### Transposing Entire Catalogs:\nIf you're working with **catalogs** that contain multiple files, you can apply this concept at the catalog level as well. Use relative paths within your RDF data files and only adjust the base IRI in each file. By doing so, your entire catalog becomes more **portable** when moved between hosts or locations, with minimal manual adjustments.\n\n### Benefits:\n- **Portability**: You can move your datasets or catalogs across different GitHub repositories, or even other hosting platforms, with minimal changes.\n- **Simplified Management**: No need to manually update each IRI inside your RDF files; just adjust the `@base` directive.\n- **Consistency**: Relative IRIs remain consistent and function as expected regardless of where the dataset is hosted.\n\nThis approach ensures that your RDF files remain flexible and easily transposable, which is especially useful when using platforms like GitHub where the hosting URL may change depending on the user or organization managing the repository.\n\nLet me know if you'd like further guidance on applying this to your Semantic Flow platform!\n\n\n## can you give an example with transposing entire catalogs\n\nSure! Here’s how you could use **`@base`** to transpose an entire **catalog** of datasets across different hosts or platforms.\n\n### Scenario:\nYou have a catalog of datasets initially hosted at `https://user1.github.io/catalog/`, and you want to move it to another GitHub organization at `https://org2.github.io/catalog/`. You want to avoid manually updating every dataset file with the new URLs.\n\n### Original Setup at `https://user1.github.io/catalog/`:\nYou can structure your RDF catalog using **relative IRIs** for datasets and distributions, and leverage `@base` to reference the hosting location.\n\n#### Catalog File (`catalog.ttl`):\n```turtle\n@base <https://user1.github.io/catalog/> .\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n\n<catalog> a dcat:Catalog ;\n    dct:title \"Dataset Catalog for User1\" ;\n    dcat:dataset <dataset1> ,\n                 <dataset2> .\n\n<dataset1> a dcat:Dataset ;\n    dct:title \"Dataset 1\" ;\n    dcat:distribution <dataset1/dist/ttl> .\n\n<dataset1/dist/ttl> a dcat:Distribution ;\n    dcat:downloadURL <dataset1.ttl> ;\n    dct:format \"text/turtle\" .\n\n<dataset2> a dcat:Dataset ;\n    dct:title \"Dataset 2\" ;\n    dcat:distribution <dataset2/dist/ttl> .\n\n<dataset2/dist/ttl> a dcat:Distribution ;\n    dcat:downloadURL <dataset2.ttl> ;\n    dct:format \"text/turtle\" .\n```\n\n#### Dataset 1 (`dataset1.ttl`):\n```turtle\n@base <https://user1.github.io/catalog/dataset1/> .\n@prefix ex: <http://example.org/> .\n\nex:Item1 a ex:Thing ;\n    rdfs:label \"Item 1\" .\n```\n\n#### Dataset 2 (`dataset2.ttl`):\n```turtle\n@base <https://user1.github.io/catalog/dataset2/> .\n@prefix ex: <http://example.org/> .\n\nex:Item2 a ex:Thing ;\n    rdfs:label \"Item 2\" .\n```\n\n### Transposing to `https://org2.github.io/catalog/`:\nTo move this entire catalog and its datasets to a new organization, you only need to update the `@base` directive in each file, without touching any of the relative IRIs.\n\n#### Updated Catalog File (`catalog.ttl`):\n```turtle\n@base <https://org2.github.io/catalog/> .\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n\n<catalog> a dcat:Catalog ;\n    dct:title \"Dataset Catalog for Org2\" ;\n    dcat:dataset <dataset1> ,\n                 <dataset2> .\n\n<dataset1> a dcat:Dataset ;\n    dct:title \"Dataset 1\" ;\n    dcat:distribution <dataset1/dist/ttl> .\n\n<dataset1/dist/ttl> a dcat:Distribution ;\n    dcat:downloadURL <dataset1.ttl> ;\n    dct:format \"text/turtle\" .\n\n<dataset2> a dcat:Dataset ;\n    dct:title \"Dataset 2\" ;\n    dcat:distribution <dataset2/dist/ttl> .\n\n<dataset2/dist/ttl> a dcat:Distribution ;\n    dcat:downloadURL <dataset2.ttl> ;\n    dct:format \"text/turtle\" .\n```\n\n#### Updated Dataset 1 (`dataset1.ttl`):\n```turtle\n@base <https://org2.github.io/catalog/dataset1/> .\n@prefix ex: <http://example.org/> .\n\nex:Item1 a ex:Thing ;\n    rdfs:label \"Item 1\" .\n```\n\n#### Updated Dataset 2 (`dataset2.ttl`):\n```turtle\n@base <https://org2.github.io/catalog/dataset2/> .\n@prefix ex: <http://example.org/> .\n\nex:Item2 a ex:Thing ;\n    rdfs:label \"Item 2\" .\n```\n\n### How it Works:\n- The relative IRIs, such as `<dataset1/dist/ttl>`, remain unchanged, but their resolution changes based on the updated `@base`.\n- By updating the base IRI in both the **catalog** and **dataset files**, all references (e.g., `downloadURL` and `distribution` links) now point to the new hosting location at `https://org2.github.io/catalog/`.\n\n### Advantages:\n- **Minimal Effort**: No need to manually replace IRIs throughout the file. Just change the `@base`.\n- **Portability**: The catalog and its datasets can be moved to any other hosting platform or GitHub organization by updating just the base.\n- **Modular Structure**: Each dataset can maintain its own base IRI, making it easier to manage them separately or host them in different subdirectories.\n\nThis structure helps make RDF catalogs **highly transposable**, providing flexibility for managing datasets across various hosting environments with minimal effort. Let me know if this approach fits what you're aiming for!\n\n## it seemse like you could \"@prefix ex: <ns>\"\n\nYou're right that you can use a **relative IRI** in a **`@prefix`** definition, like this:\n\n```turtle\n@prefix ex: <ns> .\n```\n\nIn this example, `<ns>` is a **relative IRI** that will be resolved against the current **`@base`**. This means the relative IRI `<ns>` in the `@prefix` declaration is treated as a relative reference, and it will be expanded based on the **`@base`** IRI.\n\n### Example:\n```turtle\n@base <https://example.org/base/> .\n@prefix ex: <ns/> .\n\n# Relative IRI using @base\n<> a ex:Thing ;  # resolves to <https://example.org/base/>\n\n# Using prefix\nex:item1 a ex:Item .  # resolves to <https://example.org/base/ns/item1>\n```\n\nHere:\n- The `@base` defines `https://example.org/base/` as the base IRI.\n- The `@prefix ex: <ns/>` defines the prefix `ex:` with a **relative IRI**. This is resolved relative to the base IRI, so `ex:item1` will expand to `https://example.org/base/ns/item1`.\n\nThus, you can indeed use a relative IRI in `@prefix`, and it will be resolved according to the current `@base`. This allows for a flexible and concise way to define prefixes while making the RDF more transposable.\n\n## is there a synonym for pointer or alias or link that starts with a c or a k?\n\nHere are some synonyms for **pointer**, **alias**, or **link** that start with **C** or **K**:\n\n### 1. **Channel**:\n   - Used in the context of a pathway or conduit that directs attention or resources. Could work as a synonym for a reference or pathway to data.\n\n### 2. **Cue**:\n   - Often used to indicate a hint or signal, but in some contexts could be used metaphorically to indicate a reference or point of access.\n\n### 3. **Citation**:\n   - Typically used in academia to refer to a reference or link to a source, it could be repurposed to refer to a dataset or link in an ontology context.\n\n### 4. **Context**:\n   - Although this has a broader meaning, it can imply a reference to the environment or conditions in which something is relevant. It might work as a synonym when the dataset or link provides situational relevance.\n\n### 5. **Key**:\n   - Can be used to indicate something essential for accessing or unlocking something, like a **key** to access a particular dataset or resource.\n\nIf you’re specifically looking for terms in the context of RDF or data catalogs, \"citation\" or \"context\" could work well depending on the framing.\n\n## key might be good. I'm thinking about a level of redirection between the name of a thing (IRI) and the dataset(s) and/or graph(s) that represents it. It might allow you to compose entities.\n\nUsing **\"key\"** as a level of redirection between the name (IRI) and the dataset(s) or graph(s) that represent it could be a powerful way to implement composability in your system. Here's how this concept might work:\n\n### Key as a Redirection Mechanism:\nA **key** could act as an intermediary between the IRI that identifies an entity and the various datasets, graphs, or even other entities that define or extend it. This redirection would enable dynamic composition or swapping of datasets without needing to alter the IRI itself. By modifying the key, you could alter the datasets or graphs referenced, allowing flexibility in how entities are composed or represented.\n\n### Example Use Case:\n1. **Key as an Entity Composer**:\n   - An entity identified by `https://example.org/Person1` could have a **key** like `https://example.org/Person1/key`, which points to datasets or graphs representing different aspects of the entity (e.g., demographic data, social connections).\n   \n   - The key might point to different datasets based on context (e.g., a public-facing dataset versus a more detailed internal dataset).\n\n2. **Composability with Keys**:\n   - Keys can allow you to compose an entity from multiple datasets or graphs. For instance, one dataset might describe the physical properties of an entity, while another describes its social relationships. By managing these connections through the **key**, the entity remains composable and flexible without hard-coding the links in its IRI.\n\n### Advantages of Using a Key:\n- **Separation of Concerns**: You can decouple the **entity** (identified by its IRI) from the specific datasets or graphs that describe it. This keeps the entity's identity stable while allowing the underlying data to be flexible.\n- **Versioning and Context**: Keys can point to different datasets or graphs depending on the context or version needed, giving you fine-grained control over how and when data is used.\n- **Composability**: You can aggregate multiple datasets or graphs to represent an entity in different ways, depending on what is necessary for a particular task or query.\n\nDoes this concept of using **keys** for redirection and composition sound like it fits your needs?\n\n##  \"owl:imports\". Any reason it couldn't be used to compose datasets, \"current pointers\", or catalog composition?\n\nUsing **`owl:imports`** for composing **datasets**, **\"current pointers\"**, or **catalog composition** is technically possible, but there are some important considerations to keep in mind:\n\n### How **`owl:imports`** Works:\nIn **OWL**, the `owl:imports` property is primarily used to **import entire ontologies** into another ontology. When one ontology imports another via `owl:imports`, it essentially merges all the axioms (classes, properties, etc.) from the imported ontology into the importing ontology. This is useful for building modular ontologies and ensuring that definitions from external ontologies are included.\n\n### Challenges for Datasets:\n1. **Designed for Ontologies, Not Datasets**: \n   - **`owl:imports`** is optimized for **ontologies**, not datasets. In practice, this means it's designed to bring in **schema-level** information (concepts, classes, and properties) rather than large volumes of **instance data** (like datasets). This could lead to inefficiencies or challenges when working with large, data-heavy RDF files or catalogs.\n   \n2. **Importing Data**: \n   - While **`owl:imports`** could technically be used to bring in data, it's not the most common or efficient approach. Other RDF-based methods, like **SPARQL** and **named graphs**, or tools such as **DCAT** (for dataset composition), are typically better suited for managing datasets and catalogs.\n\n### Possible Use Cases for **`owl:imports`**:\n- **Composing Ontologies for Data Structure**:\n   - You could use **`owl:imports`** to bring in **shared ontology modules** that define the schema for datasets. For example, if different datasets need to conform to a common structure (e.g., they all use the same class definitions or property constraints), **`owl:imports`** could be useful.\n\n- **\"Current Pointers\" or Dataset Composition**:\n   - In principle, you could use `owl:imports` to create a dataset or catalog that points to other datasets via imports. For example, the \"current\" dataset could import a specific version of another dataset. This would allow you to update or change the source data without needing to modify the main dataset directly. \n   - However, this would be unconventional and might lead to confusion, as `owl:imports` is meant for schema-level reuse and reasoning.\n\n### Better Alternatives for Dataset or Catalog Composition:\nFor **dataset composition**, there are more appropriate mechanisms than `owl:imports`:\n1. **DCAT (Data Catalog Vocabulary)**:\n   - **DCAT** is designed specifically for **composing datasets and catalogs**. It provides mechanisms for linking datasets, distributions, and catalogs, which makes it better suited for your goal of managing datasets, versioning, and catalogs.\n\n2. **SPARQL and Named Graphs**:\n   - **Named graphs** allow you to manage different datasets within a single RDF store, and you can use **SPARQL** queries to compose data dynamically from multiple named graphs.\n   \n3. **Custom RDF Schemas for Versioning**:\n   - You could create a custom RDF-based schema that includes properties for linking different versions of datasets or pointing to the \"current\" version, without needing to rely on `owl:imports`.\n\n### Conclusion:\nWhile **`owl:imports`** could theoretically be used to import or compose datasets, it is not ideal for this purpose. It’s better suited for importing ontology schemas rather than large volumes of data. For managing datasets, catalogs, and \"current pointers,\" tools like **DCAT** and **SPARQL** are more appropriate and flexible options. \n\nLet me know if you'd like further examples or technical details!\n\n## What is an example of dcat vocabulary for composing datasets\n\nTo compose datasets using the **DCAT (Data Catalog Vocabulary)**, you can represent the relationships between datasets, distributions, and catalogs. DCAT provides a flexible way to describe and link datasets and data catalogs, making it ideal for dataset composition.\n\n### Example 1: Basic Composition of Datasets and Distributions\n\nIn this example, multiple datasets are linked through a catalog, and each dataset has multiple distributions (e.g., different formats or versions).\n\n```turtle\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n@prefix dct: <http://purl.org/dc/terms/> .\n\n# Catalog\n<https://example.org/catalog> a dcat:Catalog ;\n    dct:title \"Main Data Catalog\" ;\n    dcat:dataset <https://example.org/dataset1> ,\n                 <https://example.org/dataset2> .\n\n# Dataset 1 with multiple distributions\n<https://example.org/dataset1> a dcat:Dataset ;\n    dct:title \"Dataset 1\" ;\n    dcat:distribution <https://example.org/dataset1/dist1> ,\n                      <https://example.org/dataset1/dist2> .\n\n<https://example.org/dataset1/dist1> a dcat:Distribution ;\n    dct:format \"application/json\" ;\n    dcat:downloadURL <https://example.org/dataset1/data.json> .\n\n<https://example.org/dataset1/dist2> a dcat:Distribution ;\n    dct:format \"text/csv\" ;\n    dcat:downloadURL <https://example.org/dataset1/data.csv> .\n\n# Dataset 2 with a single distribution\n<https://example.org/dataset2> a dcat:Dataset ;\n    dct:title \"Dataset 2\" ;\n    dcat:distribution <https://example.org/dataset2/dist1> .\n\n<https://example.org/dataset2/dist1> a dcat:Distribution ;\n    dct:format \"application/ld+json\" ;\n    dcat:downloadURL <https://example.org/dataset2/data.jsonld> .\n```\n\n### Breakdown:\n1. **Catalog**: The catalog at `https://example.org/catalog` lists two datasets (`dataset1` and `dataset2`).\n2. **Dataset Composition**: \n   - **Dataset 1** is composed of two distributions: one in **JSON** and another in **CSV** format.\n   - **Dataset 2** has a single distribution in **JSON-LD** format.\n3. **Distributions**: Each dataset links to its different representations (or versions) via the `dcat:distribution` property, specifying the **format** and **download URL**.\n\n### Example 2: Composing Multiple Datasets with a Data Catalog\n\nThis example links multiple datasets across catalogs, providing hierarchical composition.\n\n```turtle\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n@prefix dct: <http://purl.org/dc/terms/> .\n\n# Parent Catalog\n<https://example.org/catalog> a dcat:Catalog ;\n    dct:title \"Parent Data Catalog\" ;\n    dcat:dataset <https://example.org/dataset1> ;\n    dcat:catalog <https://example.org/sub-catalog> .\n\n# Dataset in Parent Catalog\n<https://example.org/dataset1> a dcat:Dataset ;\n    dct:title \"Dataset in Parent Catalog\" ;\n    dcat:distribution <https://example.org/dataset1/dist1> .\n\n<https://example.org/dataset1/dist1> a dcat:Distribution ;\n    dct:format \"application/rdf+xml\" ;\n    dcat:downloadURL <https://example.org/dataset1/data.rdf> .\n\n# Sub-catalog with its own datasets\n<https://example.org/sub-catalog> a dcat:Catalog ;\n    dct:title \"Sub Catalog\" ;\n    dcat:dataset <https://example.org/dataset2> .\n\n<https://example.org/dataset2> a dcat:Dataset ;\n    dct:title \"Dataset in Sub Catalog\" ;\n    dcat:distribution <https://example.org/dataset2/dist1> .\n\n<https://example.org/dataset2/dist1> a dcat:Distribution ;\n    dct:format \"text/turtle\" ;\n    dcat:downloadURL <https://example.org/dataset2/data.ttl> .\n```\n\n### Breakdown:\n1. **Parent Catalog**: The parent catalog (`https://example.org/catalog`) references a **sub-catalog** and one of its own datasets.\n2. **Sub-Catalog**: The sub-catalog (`https://example.org/sub-catalog`) contains its own datasets, demonstrating how catalogs can point to other catalogs, allowing for hierarchical or modular data structures.\n3. **Composability**: The parent catalog can point to both individual datasets and other catalogs, allowing for flexible and modular data composition.\n\n### Key Elements:\n- **`dcat:Catalog`**: Used to define catalogs of datasets.\n- **`dcat:Dataset`**: Represents individual datasets.\n- **`dcat:distribution`**: Links a dataset to its various distributions (formats, versions).\n- **`dcat:downloadURL`**: Provides the URL where the distribution can be accessed.\n- **`dcat:catalog`**: Allows catalogs to refer to other catalogs, creating a hierarchical structure.\n\n### Use Cases:\n- **Modular Data Systems**: Organize datasets into catalogs, which can reference other catalogs, creating flexible data systems.\n- **Versioning and Formats**: Manage datasets with multiple distributions across formats (e.g., CSV, JSON, RDF) or versions.\n- **Linked Data Catalogs**: Compose datasets by linking them across various catalogs, facilitating discoverability and reuse.\n\nThis approach using **DCAT** makes it easier to manage and compose datasets, especially when dealing with multiple formats, versions, and catalogs.\n\n\n## entities as keys\n\n### dave\n\nBoth of your examples use catalogs, which I'm not sure I like. It feels like you should be able to compose a dataset of other datasets directly. DCAT's \"dataset series\" doesn't seem quite right either because it has a sense of the elements of the series being similar and perhaps sequential. My idea is that entities have related datasets to hold (all?) their data. Entities become simple names or keys, like in entity component systems.\n\n### chatgpt\n\n## a thing is not a dataset\n\n## dave\n\nI believe a distribution is essentially a distributable version of a dataset, in a specific format. So every distribution should have a corresponding dataset. But the big problem I see with your example is that <https://example.org/entity/123> but it's supposed to be an entity. It exemplifies the issue I was trying to convey to you yesterday, i.e., differentiating a thing from the data that represents it. I don't want to say that an entity is a dataset. I want to provide you with an example that includes multiple files, how should I specify the different files for you? Should I open multiple canvases?\n\n\n## chatgpt\n\nI understand your requirements better now—you want to **distinguish the entity** from the dataset or datasets that represent it, without conflating the **entity** itself with the data. To help demonstrate this concept with multiple files, I think it will be best if I open **multiple canvases**, each representing a different Turtle file or data section. That way, we can visualize how the entity, dataset, and related files can interact without mixing up the roles.\n\nI'll split your request into several components:\n\n1. **Entity Definition**: A Turtle file that defines the entity itself.\n2. **Dataset Metadata**: Another Turtle file that holds metadata about the dataset(s) related to the entity.\n3. **Distribution Files**: Turtle files representing different dataset versions and distributions.\n\nI'll prepare these in separate canvases to clearly show how they can relate while maintaining distinctions between **entity**, **dataset**, and **distribution**.\n\nLet me start drafting these components for you.\n\nI've provided three separate Turtle files across different canvases:\n\n1. **Entity Definition File (`entity_definition`)**: Defines the **entity** (`ex:Person123`) as a `foaf:Person`. This entity has basic attributes, like a name and an email address.\n   \n2. **Dataset Metadata File (`dataset_metadata`)**: Defines a **dataset** (`ex:Person123Dataset`) that describes `Person123`. It contains multiple **distributions** (`ProfileDist` and `StatsDist`), each linking to specific downloadable representations of the entity's data.\n\n3. **Entity Component Data File (`entity_component_data`)**: Describes a more modular dataset for `Person123` that includes different **aspects** (profile and social data). This allows for managing various datasets related to the same entity.\n\nIn these examples, I've kept the **entity** (`ex:Person123`) separate from the **datasets** that describe it. Each dataset or distribution points back to the entity using `dct:subject`, clearly distinguishing the **entity** from the data about it. \n\nThis setup allows the entity to remain a **simple key**, while the different datasets provide the full representation, much like an entity-component system.\n\nLet me know if this aligns with your needs or if you'd like to refine these examples further!\n","n":0.009}}},{"i":4944,"$":{"0":{"v":"16","n":1}}},{"i":4945,"$":{"0":{"v":"Kosmion Development","n":0.707},"1":{"v":"\n## I've been thinking about allowing all entities (aka kosm:Thing) to be a kind of dcat:Dataset (maybe a kosm:RelatorDataset), but I get tangled up because <https://djradon.github.io/dave-richardson/> is supposed to have me as its sense, and I am not a dataset or a distribution. \n\nIt sounds like you're grappling with a conceptual distinction between the representation of an entity and the data about it. In the relator-based approach, the idea of allowing every entity (`kosm:Thing`) to also be a kind of `dcat:Dataset` might get problematic, especially when the nature of the entity isn’t something that could logically be described as a dataset or distribution. For instance, as you noted, you as a person are the \"sense\" of the resource `<https://djradon.github.io/dave-richardson/>`, but that entity doesn't neatly map onto the notion of a dataset.\n\nTo address this, you might consider using a **separate relator for data representation**. Instead of making every entity inherently a dataset, you could define a `kosm:RelatorDataset` that connects entities to their relevant data. This way, `<https://djradon.github.io/dave-richardson/>` could have a relationship to a dataset that contains your knowledge graph data, while `<https://djradon.github.io/dave-richardson/>` itself is allowed to remain conceptually you.\n\nFor example, you could create a new entity to represent the dataset explicitly and use a relator to associate it:\n\n```turtle\n<https://djradon.github.io/dave-richardson/> foaf:primaryTopic <https://djradon.github.io/dave-richardson/dataset> .\n\n<https://djradon.github.io/dave-richardson/dataset> rdf:type kosm:RelatorDataset, dcat:Dataset ;\n    dcterms:title \"Dave Richardson Dataset\" ;\n    dcat:distribution <https://djradon.github.io/dave-richardson/dave-richardson.ttl> .\n```\n\nIn this model:\n- `<https://djradon.github.io/dave-richardson/>` still represents you.\n- `<https://djradon.github.io/dave-richardson/dataset>` is a `dcat:Dataset` that can have associated metadata and distributions.\n- You can maintain a clean separation between entities (things) and datasets (representations of information about those things).\n\nThis way, you get to use the power of the dataset and distribution semantics where they make sense, without overloading the concept of an entity like a person.\n\n\n## OK, I've pasted an example dataset, please think it over and ask me a bunch of questions.\n\n```turtle\n@base <https://djradon.github.io/dave-richardson/> .\n@prefix : <https://djradon.github.io/> .\n@prefix kosm: <https://kosmion.github.io/datasets/ontology/v0/> .\n\n\n## /dave-richardson.ttl\n:dave-richardson a kosm:Thing .\n\n<relator/dr-catalog> a kosm:CatalogRelator ;\n    kosm:subject :dave-richardson ;\n    kosm:object <catalogs/dave-richardson> ;\n    kosm::relator-genesis \"2024-10-16T14:45:00Z\" ;\n    .\n\n<relator/dr-dataset> a kosm:DatasetRelator ;\n    kosm:subject :dave-richardson ;\n    kosm:object <datasets/dave-richardson> ;\n    kosm::relator-genesis \"2024-10-16T14:45:00Z\" ;\n    .\n\n<relator/dr-distribution-ttl> a kosm:DistributionRelator ;\n    kosm:subject :dave-richardson ;\n    kosm:object <distributions/dave-richardson/ttl> ;\n    kosm::relator-genesis \"2024-10-16T14:45:00Z\" ;\n    .    \n\n<relator/dr-label> a kosm:LabelRelator ;\n    kosm:subject :dave-richardson ;\n    kosm:label \"Dave\" ;\n    rdfs:comment \"A relator linking the label “Dave Richardson” to the person Dave Richardson.\" ;\n    kosm:sourceURL \"https://djradon.github.io/dave-richardson/relator/dr-label\" ;\n    kosm::relator-genesis \"2024-10-16T14:45:00Z\" ;\n    .\n\n<relator/dr-name> a kosm:NameRelator ;\n    kosm:subject :dave-richardson ;\n    kosm:name \"Dave Richardson\" ;\n    kosm:sourceURL \"https://djradon.github.io/dave-richardson/relator/dr-name\" ;\n    kosm::relator-genesis \"2024-10-16T14:45:00Z\" ;\n    .\n\n<relator/dr-homepage> a kosm:HomepageRelator ;\n    kosm:subject :dave-richardson ;\n    kosm:homepage \"https://djradon.github.io/\" ;\n    kosm:sourceURL \"https://djradon.github.io/dave-richardson/relator/dr-homepage\" ;\n    kosm::relator-genesis \"2024-10-16T14:45:00Z\" ;\n    .\n\n```\n\n  Here are some questions and points to think through regarding your example dataset:\n\n1. **Relator-Centric Structure**:\n   - Is the use of relators for every relationship (like labels, names, and URLs) creating redundancy or complexity? What benefits do you see in using relators instead of direct properties (e.g., `foaf:name` or `foaf:homepage`) for simpler attributes?\n   - Are you comfortable with the increased verbosity in your Turtle file, or are there potential optimizations to simplify repeated patterns?\n\n2. **Naming and Types**:\n   - How do you envision distinguishing between different kinds of relators, such as `LabelRelator` vs. `NameRelator`? Could these be more generalized if their purpose is similar (e.g., a generic `AnnotationRelator`)?\n   - The property `kosm:relator-genesis` is used in some relators but not others. Should all relators have timestamps for consistency? What rules determine when a timestamp is needed?\n\n3. **Dataset Representation**:\n   - Your dataset uses several relators (`DatasetRelator`, `CatalogRelator`, `DistributionRelator`) linked to `dave-richardson`. This implies multiple perspectives on Dave Richardson (as a catalog, dataset, distribution). Do you see the need for keeping these separate, or could they be integrated into a more cohesive structure that avoids redundancy?\n   - In the `dr-catalog`, `dr-dataset`, and `dr-distribution-ttl` relators, you use `kosm:subject` and `kosm:object`. Would it make sense to extend these relators by specifying more detailed relationships (e.g., `contains`, `describes`, `exports`) to clarify their roles?\n\n4. **Relator-Subject Semantics**:\n   - You mentioned that `:dave-richardson` is a `kosm:Thing` and that the relators connect `dave-richardson` to other pieces of data. Are the semantics of `kosm:subject` and `kosm:object` clear enough in terms of their role in the relator relationship? Should additional properties exist to provide context for why an entity is subject or object in a relator?\n\n5. **DCAT Dataset Compatibility**:\n   - Have you thought about using `dcat:Dataset` for `dave-richardson`, or possibly creating a new subclass like `kosm:RelatorDataset`? This could clarify when an entity is representing data about itself, rather than just being the person or concept in question.\n   - If you want to allow entities like `dave-richardson` to also be datasets, how will you handle situations where this does not make sense (e.g., entities that don't have explicit data representations)?\n\n6. **Generalization of Relators**:\n   - Relators like `dr-label`, `dr-name`, and `dr-homepage` seem specific to `dave-richardson`. Could these be generalized to work for any `kosm:Thing`? For example, could you define relators that are parameterized by the type of relationship and the entity involved?\n   - Have you considered whether certain relators could share a superclass, such as `kosm:DescriptiveRelator`, to group similar functions together (e.g., `label`, `name`, and `homepage` could fall under a descriptive umbrella)?\n\n7. **Source URLs and Provenance**:\n   - The `kosm:sourceURL` is included for some relators. How will you manage provenance and source tracking across multiple relators? Would you want a standardized mechanism to document the provenance for all data in your knowledge graph?\n   - Could there be an easier way to automate the generation of `sourceURL`s to avoid inconsistencies, especially given the repetitiveness of this data?\n\n8. **Catalog, Dataset, and Distribution**:\n   - You seem to have multiple levels of metadata: catalog, dataset, and distribution. Is there a clear separation of what belongs in each, and how they should interrelate?\n   - Is `<catalogs/dave-richardson>` strictly metadata about Dave Richardson, or could it also contain data entities themselves? What happens if your catalog structure grows beyond just `dave-richardson`?\n\n9. **Timestamps and Lifecycle**:\n   - The relators have timestamps, such as `kosm:relator-genesis`, but there's no indication of when they might become obsolete (e.g., a `kosm:relator-tombstone`). Are there lifecycle states for these relationships, or are they intended to be immutable?\n   - Do you need both system-time (internal timestamps) and valid-time (the time when the fact represented is valid in the real world) for your relators? How would these timestamps impact query semantics?\n\n10. **Label and Name Differences**:\n    - There are separate relators for `dr-label` and `dr-name`. Are you distinguishing between a \"label\" and a \"name\" in a significant way, or could these be combined? What criteria guide whether a specific value is a label versus a name?\n\nAddressing these questions will help clarify how your relator-based structure scales, whether it stays flexible for various types of data, and if the distinctions you're making now will hold up as the dataset evolves.\n\n## So this type of dataset could be called a \"Thing snapshot\". It would (almost always) be generated using a RelatorCatalog (which is a subclass of dcat:Catalog) as a blueprint. The catalog would refer to one or more datasets, which could contain current relators and  previous versions of relators. The use of relators for every relationship definitely creates complexity, but please open another canvas for the kosmion ontology which includes a comment that explains the benefits.\n\n```turtle\n@prefix kosm: <https://kosmion.github.io/ont/v0/> .\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n\n## Kosmion Ontology - Benefits of Relator-Based Approach\n# The relator-based approach within Kosmion provides several distinct advantages:\n# 1. **Historical Context**: Relators allow for the explicit representation of relationships over time, providing a mechanism for tracking changes, previous versions, and metadata about each connection.\n# 2. **Decoupling Entities**: Relationships are treated as first-class citizens, decoupling the connections between entities from the entities themselves. This makes it easier to manage and represent the relationships as mutable objects, even if the entities are not.\n# 3. **Multi-perspective Modeling**: By using relators for every connection, it becomes possible to represent different perspectives or interpretations of the same entities, allowing richer semantic descriptions and supporting use cases like storytelling, versioning, or conflicting viewpoints.\n# 4. **Data Consistency and Integrity**: The explicit use of relators helps in maintaining consistency by clearly defining the role and context of each relationship. This also aids in validation, where the presence of expected relators can be used as a check for data integrity.\n# 5. **Provenance and Metadata**: Relators are annotated with metadata (e.g., creation time, source URL), which facilitates auditing, tracking provenance, and managing data lifecycle events.\n\nkosm:Thing a rdfs:Class ;\n    rdfs:label \"Thing\" ;\n    rdfs:comment \"A generic class representing any entity within the Kosmion ontology.\" .\n\nkosm:Relator a rdfs:Class ;\n    rdfs:label \"Relator\" ;\n    rdfs:comment \"A class representing a relationship between entities, providing context and metadata for the connection.\" .\n\nkosm:RelatorCatalog a rdfs:Class, dcat:Catalog ;\n    rdfs:label \"Relator Catalog\" ;\n    rdfs:comment \"A subclass of DCAT Catalog used as a blueprint for generating Thing snapshots.\" .\n\nkosm:RelatorDataset a rdfs:Class, dcat:Dataset ;\n    rdfs:label \"Relator Dataset\" ;\n    rdfs:comment \"A dataset that contains relators, including current and previous versions, to represent an entity's relationships.\" .\n```\n\n","n":0.026}}},{"i":4946,"$":{"0":{"v":"15","n":1}}},{"i":4947,"$":{"0":{"v":"Kosmion Breakthrough Continues","n":0.577},"1":{"v":"\n- interlocutor: chatgpt4.o\n\n## This morning, I'm thinking about using named graphs as the targets of the pointer for versioning/system-time, with relators used within named graphs to express valid time and all the other relator benefits.\n\nThat sounds like a good plan—using **named graphs** to manage the **versioning/system-time** while leveraging **relators within the named graphs** to handle **valid time** and other relational aspects. This hybrid approach makes sense as it separates the **versioning aspects** from the **validity aspects** in a clean, modular manner.\n\n### How This Would Work:\n1. **Named Graphs for System-Time**:\n   - Each **named graph** represents a specific version of a resource and includes **system-time metadata** (e.g., when it was generated or superseded).\n   - Named graphs effectively manage **succession** and **version tracking**, ensuring that the **history of updates** is preserved in an immutable way.\n\n2. **Relators for Valid Time and Relationships**:\n   - **Relators** inside the named graphs capture the **valid-time** details and model other relationships.\n   - This allows each version (named graph) to have a self-contained, valid-time-oriented **relator structure**, maintaining immutability while expressing rich semantic relationships.\n\n### Example Update to Your Turtle Document:\nTo reflect your current thinking, here's an updated example using **named graphs** and **relators**.\n\n#### Named Graph with System-Time Information\n```turtle\n@prefix : <https://djradon.github.io/dave-richardson/> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n@prefix prov: <http://www.w3.org/ns/prov#> .\n@prefix relator: <https://example.com/relator#> .\n\nGRAPH <https://djradon.github.io/dave-richardson/version/1> {\n    <https://djradon.github.io/dave-richardson/> rdfs:label \"Dave Richardson (Person)\" ;\n        a foaf:Person ;\n        foaf:name \"Dave Richardson\" ;\n        foaf:homepage <https://djradon.github.io/> ;\n        prov:generatedAtTime \"2024-10-12T08:00:00Z\"^^xsd:dateTime ;\n        relator:validStart \"2024-10-01\"^^xsd:date ;\n        .\n}\n\nGRAPH <https://djradon.github.io/dave-richardson/version/2> {\n    <https://djradon.github.io/dave-richardson/> rdfs:label \"Dave Richardson (Person)\" ;\n        a foaf:Person ;\n        foaf:name \"Dave Richardson\" ;\n        foaf:homepage <https://new-homepage.com/> ;\n        prov:wasDerivedFrom <https://djradon.github.io/dave-richardson/version/1> ;\n        prov:generatedAtTime \"2024-11-01T09:00:00Z\"^^xsd:dateTime ;\n        relator:validStart \"2024-11-01\"^^xsd:date ;\n        .\n}\n```\n\n#### Key Points:\n- **Named Graphs for Versions**: Each graph (`version/1`, `version/2`) holds a specific version of the **Dave Richardson** entity. These named graphs are immutable and each contains **system-time metadata** (`prov:generatedAtTime`).\n- **Relators Inside Named Graphs**:\n  - Relators such as **`relator:validStart`** are used to manage the **validity** period for each version.\n  - Other **relator-based relationships** can be added as needed, which keeps the validity, context, and detailed semantics **within each named graph**.\n\n### Benefits:\n1. **Separation of System-Time and Valid-Time**:\n   - The **named graphs** manage **system-time**, providing a clear temporal lineage for each entity.\n   - The **relators** inside each graph handle **valid-time** and other relationships, preserving the internal semantic richness.\n\n2. **Modularity**:\n   - Each named graph is a self-contained version of the entity, meaning the history and evolution are managed in modular segments, making it easier to maintain and query.\n\n3. **Temporal Tracking and Immutability**:\n   - By leveraging **system-time metadata** in the named graphs and **valid-time relators** within, you ensure that all updates are immutable.\n   - The **mutable pointer** (such as `:latestVersion`) could be used to point to the latest named graph when practical access to the current state is required.\n\n### Next Steps:\n- Do you want me to incorporate this model into the existing Kosmion example or add this kind of structure to new entities you might have in mind?\n- We could further develop a **SHACL shape** to validate the consistent use of **named graphs** for system-time and **relators** for valid-time relationships if needed.\n\nLet me know how you’d like to proceed!\n\n\n## Is there a mechanism for renaming a named graph?\n\nIn **RDF**, there is no direct built-in mechanism for **renaming a named graph**. Named graphs are essentially IRIs used to identify collections of RDF triples, and the IRI serves as the \"name\" for that graph. If you need to rename a named graph, you generally have to:\n\n1. **Create a New Named Graph** with the new IRI.\n2. **Copy the Triples** from the old named graph to the new one.\n3. **Update References** to the old named graph IRI in your datasets or SPARQL stores to use the new IRI.\n4. Optionally, **delete the old named graph** to fully complete the renaming.\n\n### Renaming in a SPARQL Environment:\nIn an **RDF store** that supports SPARQL (like Apache Jena or Blazegraph), you can effectively rename a graph using SPARQL **update operations**:\n\n1. **Insert Data into the New Graph**:\n   - Use the `INSERT` operation to add all triples from the old named graph to the new named graph.\n2. **Delete the Old Graph**:\n   - After copying, you can use the `DROP GRAPH` command to remove the original named graph.\n\nHere's an example of how you might do this in SPARQL:\n\n```sparql\n# Copy triples from the old named graph to the new named graph\nINSERT {\n  GRAPH <https://new-graph-uri> {\n    ?s ?p ?o .\n  }\n}\nWHERE {\n  GRAPH <https://old-graph-uri> {\n    ?s ?p ?o .\n  }\n};\n\n# Optionally, drop the old graph to remove it\nDROP GRAPH <https://old-graph-uri> ;\n```\n\nThis approach effectively \"renames\" the graph by copying all its contents to a new graph with a different IRI and deleting the original one.\n\n### Considerations:\n- **References to the Old Graph**: If other datasets or queries reference the old named graph IRI, you'll need to update those references manually.\n- **Bitemporality and Provenance**: If you're maintaining **bitemporal or provenance information**, you might need to carry over these metadata properties during the renaming.\n\n### Alternative:\nInstead of **renaming**, consider adding a **mapping or alias** mechanism if the system allows it. This way, the original IRI can continue to be used, but a new name can be associated with it in different contexts. This approach can be simpler, especially when a lot of references to the old graph exist.\n\nWould you like me to add anything about named graph handling or graph management to your Turtle example, or assist in any other way with versioning or named graph concepts?\n\n##  A problem with entities with a lot of updates, you might have to parse a lot of named graph metadata to figure out which named graph is current. I think that indicates a mutable pointer. I do get caught in the github/text-file approach, which is just a storage solution, not a \"live data\" solution, so please keep reminding me of that perspective.\n\nThe description of **`prov:Entity`** in **PROV-O** (\"An entity is a physical, digital, conceptual, or other kind of thing with some fixed aspects\") emphasizes **fixed aspects** because it is trying to distinguish entities in a specific way. Let's unpack why **\"fixed aspects\"** might be emphasized and how it’s relevant in the context of provenance.\n\n### Understanding \"Fixed Aspects\"\n1. **Fixed Aspects** as Unchanging Characteristics:\n   - \"Fixed aspects\" refer to those properties or characteristics of an entity that are **immutable or stable** during a given timeframe. These aspects are important for **identifying** or understanding the entity as it relates to other entities, activities, and agents in a **provenance** context.\n   - For example, in the provenance of a **digital file**, the **content hash** might be considered a fixed aspect that uniquely identifies that particular version of the file.\n\n2. **Contrast with Entities That Are Changing**:\n   - By focusing on \"fixed aspects,\" **PROV-O** highlights that an entity can be referenced in a **consistent manner**. It’s important for **tracking changes** and ensuring that the entity being discussed is understood to have some stable, identifiable qualities.\n   - This distinction helps differentiate between entities and **activities** or **events**. Activities often involve transformation, where inputs change into outputs, and aspects are transient rather than fixed.\n   - **Mutable datasets**, for instance, might lack the fixed aspect necessary to identify them definitively over time, while a version of that dataset (with a fixed timestamp or hash) would qualify as an entity.\n\n3. **Relevance to Provenance**:\n   - In the **provenance model**, the concept of \"fixed aspects\" ensures that entities can be **referenced consistently** throughout the **provenance chain**. Provenance is about understanding how an entity came to be in its current state, and that understanding relies on being able to **trace entities** without ambiguity.\n   - Fixed aspects provide the **anchor** for such tracing: for example, versioning information, creation date, or an identifier that doesn’t change as the entity is used and referenced elsewhere.\n\n### What Kinds of Things Might Not Have Fixed Aspects?\n- **Highly Dynamic Resources**: Resources that **constantly change** might not have any \"fixed\" characteristics. For example:\n  - **Real-time data streams**: Like a live weather feed that continuously changes and may lack a fixed, unchanging characteristic.\n  - **Mutable datasets**: Data that gets updated in-place, without versioning or unique identifiers to distinguish states, lacks those \"fixed aspects\" needed for a stable reference.\n- **Activities**: In **PROV-O**, activities transform entities and do not have \"fixed aspects\" as their characteristics are defined by the processes they undergo (e.g., a process of transformation or computation).\n\n### Fixed Aspects in the Kosmion Context\nFor your **relator-based immutable RDF approach**:\n- Using **named graphs** for versioning ensures that each named graph is an **entity with fixed aspects**—like the **validity period** and **system timestamps**—that can uniquely identify it at that point in time.\n- The use of **immutable pointers** helps identify each version of a resource consistently, ensuring that fixed aspects (e.g., version identifiers or timestamps) allow it to be referenced without confusion.\n\nIn conclusion, \"fixed aspects\" are critical for enabling entities to be traced through their lifecycle within a **provenance framework**. They provide the **ground truth** that allows an entity to be distinguished from other evolving resources, which is fundamental for understanding and documenting how entities are used, transformed, or derived over time.\n\nLet me know if you'd like to explore further how \"fixed aspects\" apply to your entities in Kosmion, or if you have any other questions about PROV-O!\n\n## Any thoughts on the semantic differences between facets and aspects?\n\nThe terms **\"facets\"** and **\"aspects\"** have nuanced differences in their semantic meanings, which can influence how they’re used in ontology design or data modeling.\n\n### **Facets**\n1. **Multi-Dimensional Characterization**:\n   - A **facet** typically represents a **specific dimension** or **property** that can describe an entity from different angles. Facets are often used to support **classification** or **categorization** based on multiple independent attributes.\n   - Example: In e-commerce, facets for a product might include **color**, **size**, **brand**, etc. Each of these dimensions is orthogonal, and users can combine them to refine their search.\n\n2. **Orthogonality and Filtering**:\n   - Facets are often used to enable **filtering** or **search** in a **multi-dimensional space**. Each facet allows an independent view, and entities can have multiple facets simultaneously.\n   - **Facet Stereotypes** in Kosmion, for example, could be a way to assign multiple distinguishing features to an entity without restricting it to a single classification.\n\n3. **Application in RDF**:\n   - In RDF or ontology contexts, facets can be used as **attributes** that describe multiple views of an entity, making them ideal for cases where you need to tag or categorize without committing to a strict hierarchical structure.\n\n### **Aspects**\n1. **Perspective or Fixed Characteristic**:\n   - An **aspect** typically refers to a **specific characteristic** or **quality** of an entity that can be viewed or evaluated. It often implies looking at an entity through a particular **lens** or **perspective**.\n   - Example: If you consider a **painting**, its aspects might include **color composition**, **historical context**, **artistic technique**, etc. Aspects describe features that are observed or analyzed, rather than selected independently.\n\n2. **Not Necessarily Independent**:\n   - Unlike facets, **aspects** may not be **independent** of each other. They provide different perspectives on the **same core entity**, and their meanings may influence one another.\n   - For instance, an aspect like **historical context** might be deeply intertwined with an aspect like **artistic style**.\n\n3. **Fixed Characteristics in Provenance**:\n   - In the context of **provenance** (`prov:Entity`), \"fixed aspects\" refer to those **invariant qualities** that are used to identify the entity or understand its state in a stable manner.\n\n### Comparing Facets and Aspects:\n| Characteristic | **Facets** | **Aspects** |\n|----------------|------------|-------------|\n| **Nature** | Multi-dimensional properties for **categorization** | Perspectives or characteristics for **understanding** an entity |\n| **Usage** | Used for **filtering** and **independent classification** | Used to provide **contextual analysis** or **detailed understanding** |\n| **Independence** | Typically **orthogonal** to each other (each facet is a distinct axis) | Can be **interrelated** and dependent on each other |\n| **Examples** | Color, size, price, genre | Historical context, material composition, aesthetic quality |\n\n### In Kosmion Ontology Context:\n- **Facets** might represent different **dimensions** that entities can have without assuming a strict hierarchy or fixed relationship between those dimensions. For example, **categories** or **roles** assigned to individuals could be facets.\n- **Aspects** could refer to the **stable characteristics** of an entity, much like the \"fixed aspects\" in PROV-O. They would describe something **fundamental** or **constant** that is used to understand the nature of the entity over time.\n\nWould you like to explore using **facets and aspects** in Kosmion for a specific entity type or expand their representation in your current ontology? Let me know if you'd like to take a deeper dive into how to apply them effectively!\n\n","n":0.022}}},{"i":4948,"$":{"0":{"v":"14","n":1}}},{"i":4949,"$":{"0":{"v":"Kosmion Breakthroughs","n":0.707},"1":{"v":"\n## Properties that specify restrictive domain and range... what's the point? It forces people to buy into your class hierarchy. Re-usable properties should have minimal domain restrictions. Datatype properties can understandably have range restrictions, but object properties should have minimal range restrictions too. Show me counter-examples.\n\nYou raise a very good point. **Properties with restrictive domain and range** can limit the **reusability** of those properties across different class hierarchies. Reusable properties should ideally have **minimal or no domain and range restrictions**, particularly if the intent is to encourage broader usage and adoption across ontologies.\n\n### When Restrictive Domain and Range Are Problematic:\n1. **Forced Class Hierarchy Adoption**:\n   - Properties with restrictive domains and ranges force users to adopt your specific **class structure**. If you want to apply those properties in different contexts that don't match the domain or range exactly, you either have to subclass from the defined hierarchy or avoid using the property, both of which can be cumbersome.\n  \n2. **Limits to Reusability**:\n   - **Domain restrictions** require that any subject of a property belongs to a specific class, making it less reusable across different entities.\n   - **Range restrictions** require that any object of the property must belong to a specific class, limiting the types of relationships that can be expressed.\n\n### Examples Where Restrictive Domain and Range Are Reasonable:\n- **Datatype Properties with Range Restrictions**:\n  - For datatype properties, setting a **range** restriction like `xsd:string` or `xsd:dateTime` can be useful to enforce data **consistency**.\n  - Example: A property like `foaf:age` has a range of `xsd:integer` to ensure age values are always represented consistently.\n\n### Examples Where Domain/Range Restrictions Are Problematic:\n1. **FOAF Example**:\n   - **`foaf:knows`**: This property has a domain of **`foaf:Person`** and a range of **`foaf:Person`**. This means:\n     - You can only say that a **person** knows another **person**.\n     - You cannot use `foaf:knows` to relate any other type of entities, even though it might be conceptually reasonable (e.g., a **Syngent** knowing a person).\n  \n2. **Schema.org Example**:\n   - **`schema:parent`**: Has a restrictive domain and range that assumes only people can have parents, but there could be scenarios in a fantasy world where a **character** has a non-human parent. Restricting `schema:parent` to only `schema:Person` would limit how this property could be applied in more complex ontologies.\n\n### Counter-Example: Using Minimal Restrictions\n- **RDFS Properties**:\n  - **`rdfs:label`** and **`rdfs:seeAlso`** are examples of **minimally restricted properties**:\n    - **`rdfs:label`** can be used with any subject, with no domain specified, allowing it to be used in virtually any context where a human-readable label is needed.\n    - **`rdfs:seeAlso`** also has no domain, allowing it to be used to provide additional references for any kind of RDF resource.\n\n### Considerations for Your Use Case in Kosmion:\n- To **maximize reusability**:\n  - Avoid specifying strict **domain** and **range** for properties, especially for **object properties**.\n  - Only enforce **datatype range** when consistency is crucial, such as for numerical or date values.\n- For example, if you want a **relator property** that links any two entities, defining it without a specific domain and range will make it far more reusable across different classes and hierarchies.\n\n### Conclusion:\n- **Restrictive domain and range** can make an ontology more **rigid** and less reusable, often forcing users to buy into a specific class structure.\n- For **reusable properties**, keeping **domain and range minimal** allows for broader applicability and more **flexible integration** across ontologies.\n  \nWould you like to adjust any of the properties in your current ontology draft to make them more reusable by removing restrictive domains or ranges?\n\n\n## To make immutable RDF feasible, there's going to have to be some indirection between an IRI and what you might call a \"relator series\" or a \"relator succession\", i.e., a set of micro-datasets that, when an update needs to be made, a new micro-dataset gets created with the latest data and no tombstone, the previous \"latest dataset\" get a tombstone and successor set,  and then either a pointer gets updated on the entity's IRI entry, or a pointer gets updated on the dataset point to the entity's IRI, or both.\n\n\nThis is an interesting approach to handling **immutable RDF** while maintaining the **succession of states** for entities and their relationships. By introducing indirection and a concept of **relator succession**, you can manage updates efficiently without modifying the original triples, which aligns well with an immutable data philosophy.\n\nHere’s a breakdown of how this approach might work and how it could be integrated into your Kosmion ontology:\n\n### Key Components for Implementing Relator Succession:\n1. **Relator Series/Succession**:\n   - This involves creating a **series of related relators**, each representing an updated state of a particular relationship or entity.\n   - Each new version of a **micro-dataset** that replaces the previous one would include an **updated pointer** that points to the latest version.\n  \n2. **Using Tombstones and Successor Relations**:\n   - When a **new micro-dataset** is created (for an update), the previous version receives:\n     - A **tombstone marker** (e.g., `:tombstone` with a timestamp).\n     - A reference to its **successor** (e.g., `:relator-successor`), pointing to the newly created version.\n   - This effectively chains the datasets, allowing a traversal to find the latest state while preserving historical data.\n\n3. **Indirection and Mutable Pointers**:\n   - **Mutable pointers** could be implemented by having a designated **IRI** that always points to the current/latest micro-dataset for an entity. This IRI would not change, but the underlying **pointer** (an RDF statement) would be updated to reference the latest version.\n   - Alternatively, the **dataset itself** could include a mutable pointer that directs to the entity’s IRI or vice versa.\n\n### Practical Example Using Dave Richardson Data\nTo implement this for the **Dave Richardson** entity, consider introducing a relator mechanism that manages updates:\n\n#### Current Dataset:\n```turtle\n@prefix : <https://djradon.github.io/dave-richardson/> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n@prefix prov: <http://www.w3.org/ns/prov#> .\n\n<https://djradon.github.io/dave-richardson/> rdfs:label \"Dave Richardson (Person)\" ;\n    a foaf:Person ;\n    foaf:name \"Dave Richardson\" ;\n    foaf:homepage <https://djradon.github.io/> ;\n    prov:wasDerivedFrom <https://djradon.github.io/dave-richardson/v0> ;\n    .\n```\n\n#### Next Version with Tombstone and Successor:\nAssume we need to update the homepage. A new micro-dataset would be created:\n\n```turtle\n@prefix : <https://djradon.github.io/dave-richardson/> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n@prefix prov: <http://www.w3.org/ns/prov#> .\n\n<https://djradon.github.io/dave-richardson/v1> rdfs:label \"Dave Richardson (Person)\" ;\n    a foaf:Person ;\n    foaf:name \"Dave Richardson\" ;\n    foaf:homepage <https://new-homepage.com/> ;\n    prov:wasDerivedFrom <https://djradon.github.io/dave-richardson/v0> ;\n    .\n\n<https://djradon.github.io/dave-richardson/v0> :tombstone \"2024-10-12T12:00:00Z\"^^xsd:dateTime ;\n    :relator-successor <https://djradon.github.io/dave-richardson/v1> ;\n    .\n```\n\n#### Indirection Using Mutable Pointer\nInstead of changing `<https://djradon.github.io/dave-richardson/>` directly, it could point to the latest **versioned dataset**:\n\n```turtle\n<https://djradon.github.io/dave-richardson/> :latestVersion <https://djradon.github.io/dave-richardson/v1> .\n```\n\nThis way:\n- The IRI `<https://djradon.github.io/dave-richardson/>` always stays the same, acting as an **anchor** for the entity.\n- The actual data is versioned, and changes are handled through **succession relations** and **tombstones**.\n\n### Benefits of This Approach:\n1. **Immutability**:\n   - RDF data remains **immutable**, ensuring that historical states are preserved.\n  \n2. **Version Control**:\n   - Users or agents querying the data can easily traverse the **succession chain** to understand how the data has evolved over time.\n\n3. **Clear Historical Provenance**:\n   - Using **PROV-O** properties like `prov:wasDerivedFrom` makes it easy to trace the origins of each version.\n\n### Considerations:\n- **Query Complexity**: Tracking the latest state involves traversing the chain of successors or following the **mutable pointer**.\n- **Storage Overhead**: Each update results in a new micro-dataset, which could lead to increased storage requirements, although it guarantees immutability.\n\nThis solution provides a structured way to maintain immutable RDF data while still allowing for updates, and it could be very powerful in the context of **Kosmion**. Would you like to expand on this or add these mechanisms to your current draft?\n\n\n## The IRIs have to stay the same. :latestVersion is one approach, \"mutable pointer\", and it's a good one, but a) you have to keep changing it (so it's not consisten with immutability elsewhere, I guess it's okay to have 2 classes of IRIs, ), b) there's no date information so bitemporal timetravel is tricky. Is there any mechanism in RDF for a \"dataset series\"? Maybe named graphs could work, with the tombstone attached to the named graphs.\n\n### Addressing Immutable RDF and Dataset Series\n\nFor implementing an immutable RDF approach while keeping **IRIs consistent** across versions, here are some mechanisms that could help, including considerations for **dataset series** and how **named graphs** could be leveraged.\n\n### Challenge:\n- **IRIs need to remain consistent** for entities, while **updates** should be managed in a way that preserves immutability.\n- You are considering two classes of IRIs: \n  - **Mutable pointers** (e.g., pointing to the latest version) for practical purposes.\n  - **Immutable identifiers** that do not change, representing entities throughout time.\n- **Bitemporality** complicates matters because tracking both **transaction time** and **valid time** requires information about when the dataset was valid as well as when it was recorded.\n\n### Possible Mechanisms to Implement Dataset Series\n\n#### 1. **Named Graphs for Relator Series**:\n- Use **named graphs** to manage **dataset series**. Each named graph could represent a specific **version** of the data, including metadata such as a **tombstone** or **validity timestamps**.\n- Named graphs make it possible to define the **scope** of triples, allowing you to group all the data about a specific version under a named IRI.\n\n##### Example with Named Graphs:\n```turtle\n@prefix : <https://djradon.github.io/dave-richardson/> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n@prefix prov: <http://www.w3.org/ns/prov#> .\n\nGRAPH <https://djradon.github.io/dave-richardson/v1> {\n    <https://djradon.github.io/dave-richardson/> rdfs:label \"Dave Richardson (Person)\" ;\n        a foaf:Person ;\n        foaf:name \"Dave Richardson\" ;\n        foaf:homepage <https://djradon.github.io/> ;\n        prov:generatedAtTime \"2024-10-12T12:00:00Z\"^^xsd:dateTime ;\n        .\n}\n\nGRAPH <https://djradon.github.io/dave-richardson/v2> {\n    <https://djradon.github.io/dave-richardson/> rdfs:label \"Dave Richardson (Person)\" ;\n        a foaf:Person ;\n        foaf:name \"Dave Richardson\" ;\n        foaf:homepage <https://new-homepage.com/> ;\n        prov:wasDerivedFrom <https://djradon.github.io/dave-richardson/v1> ;\n        prov:generatedAtTime \"2024-11-01T08:00:00Z\"^^xsd:dateTime ;\n        .\n}\n\n<https://djradon.github.io/dave-richardson/v1> :tombstone \"2024-11-01T08:00:00Z\"^^xsd:dateTime ;\n    :relator-successor <https://djradon.github.io/dave-richardson/v2> ;\n    .\n```\nIn this example:\n- Each named graph (`v1`, `v2`) represents a specific version of the **Dave Richardson** dataset.\n- The **IRI** (`<https://djradon.github.io/dave-richardson/>`) remains consistent across versions, but the different graphs manage successive states.\n- The `:tombstone` property marks when the graph version is considered \"invalid\" or \"superseded.\"\n\n#### 2. **Dataset Series Using DCAT and Versioning**:\n- You could use **DCAT (Data Catalog Vocabulary)** to describe a **series of datasets** that make up the entire **relator succession**.\n- Each version can be represented as a **distribution** of a dataset, with specific properties that define its **validity period** and **system time**.\n\n##### Example Using DCAT:\n```turtle\n@prefix dcat: <http://www.w3.org/ns/dcat#> .\n@prefix dct: <http://purl.org/dc/terms/> .\n\n<https://djradon.github.io/datasets/dave-richardson> a dcat:Dataset ;\n    dct:title \"Dave Richardson Dataset Series\" ;\n    dcat:distribution <https://djradon.github.io/datasets/dave-richardson/v1> , <https://djradon.github.io/datasets/dave-richardson/v2> .\n\n<https://djradon.github.io/datasets/dave-richardson/v1> a dcat:Distribution ;\n    dct:issued \"2024-10-12T12:00:00Z\"^^xsd:dateTime ;\n    dct:validUntil \"2024-11-01T08:00:00Z\"^^xsd:dateTime ;\n    dcat:accessURL <https://djradon.github.io/dave-richardson/v1> .\n\n<https://djradon.github.io/datasets/dave-richardson/v2> a dcat:Distribution ;\n    dct:issued \"2024-11-01T08:00:00Z\"^^xsd:dateTime ;\n    dcat:accessURL <https://djradon.github.io/dave-richardson/v2> .\n```\nHere:\n- The dataset (`<https://djradon.github.io/datasets/dave-richardson>`) acts as a **series** of distributions, each representing a **specific version**.\n- **`dct:issued`** and **`dct:validUntil`** help manage the temporal aspects for each version.\n\n#### 3. **Using PROV-O for Temporal Succession**:\n- Use **PROV-O** to manage the relationships between successive versions and handle bitemporal aspects.\n- Each version of a dataset can use properties like:\n  - **`prov:wasDerivedFrom`** to point to the previous version.\n  - **`prov:generatedAtTime`** for system time.\n  - **`prov:invalidatedAtTime`** to mark when a version becomes obsolete.\n\n### Pros and Cons of Named Graphs for Dataset Series\n- **Pros**:\n  - Named graphs allow each version of the data to be **self-contained**, making it easy to represent a **succession of states**.\n  - By attaching metadata like `:tombstone` and `prov:wasDerivedFrom` to the named graph, you can manage both the **valid time** and **system time** aspects, supporting bitemporal requirements.\n- **Cons**:\n  - Managing and querying **multiple named graphs** can become complex, especially if your dataset series grows significantly.\n  - RDF stores must support **named graphs** efficiently for this to be practical.\n\n### Summary\n- The **named graph** approach combined with **PROV-O** and **DCAT** provides a robust way to manage **immutable RDF** while allowing for versioning and temporal tracking.\n- You can manage **IRIs consistently** by having them always point to a conceptual entity, while the **version information** is managed separately in named graphs.\n- The **tombstone** mechanism, along with **mutable pointers** like `:latestVersion`, helps balance immutability with practical requirements for updates.\n\nLet me know if you’d like to incorporate any of these ideas into your Kosmion ontology or if you’d like me to make specific updates to the current draft to reflect this!\n\n\n","n":0.023}}},{"i":4950,"$":{"0":{"v":"12","n":1}}},{"i":4951,"$":{"0":{"v":"Kosmion Conceptual Foundations","n":0.577},"1":{"v":"\n## gufo differentiates between comparative and material relationships. what is the benefit?\n\nIn **gUFO**, the distinction between **comparative** and **material relationships** provides a structured way to represent different types of relationships with distinct characteristics, helping to improve both **semantic clarity** and **ontological rigor**. Here’s a breakdown of the benefits of differentiating between these two types of relationships:\n\n### 1. **Comparative Relationships**:\n- **Definition**: Comparative relationships are used to describe relationships where the connection is established by comparing properties or states between entities. Examples include relationships like \"taller than,\" \"more experienced than,\" or \"closer to.\"\n- **Benefits**:\n  - **Simplifies Modeling Comparisons**: By creating a distinct type for comparative relationships, it becomes easier to model and understand relationships based on **relative characteristics**. This distinction ensures that these relationships are represented more appropriately, without implying material interaction.\n  - **Prevents Confusion with Physical Relationships**: Comparative relationships do not imply any **physical, causal, or social interaction** between entities. By having a separate class for them, it reduces potential confusion between mere comparisons and relationships that have more ontological implications.\n\n### 2. **Material Relationships**:\n- **Definition**: Material relationships represent **actual interactions** or **connections** between entities in a given context. These could include causal, social, or even physical relationships, such as \"employed by,\" \"married to,\" or \"connected to.\"\n- **Benefits**:\n  - **Captures Real Interactions**: Material relationships are meant to capture **meaningful connections** or **interactions** that exist in the real world. This helps in representing the ontological reality more precisely.\n  - **Clearer Modeling of Dependency**: Material relationships often come with implications for the **dependencies** or **commitments** between the entities involved. This is particularly important for modeling scenarios where a change in one entity impacts the other (e.g., a person being **employed** by a company has certain obligations and expectations).\n\n### Key Benefits of Differentiation:\n1. **Semantic Clarity**:\n   - Differentiating between **comparative** and **material** relationships adds **semantic clarity** to an ontology. This distinction ensures that different types of relationships are not misinterpreted, especially when dealing with **complex models** where both types of connections can occur.\n\n2. **Improved Reasoning**:\n   - By defining these distinctions explicitly, it becomes possible to improve the **reasoning** capabilities of an ontology. For instance, comparative relationships typically don’t imply direct changes to the state of an entity, whereas material relationships might. Having these clear distinctions can help reasoners to **infer more accurate implications** based on the type of relationship.\n\n3. **Enhanced Query Capabilities**:\n   - When querying an ontology, users can be more **specific** about the kinds of relationships they are interested in. For example, you could query only **material relationships** to find meaningful interactions, while ignoring **comparative ones** that might not imply a significant link.\n\n4. **Alignment with Foundational Ontologies**:\n   - Many **foundational ontologies** (like **BFO** or **DOLCE**) have similar distinctions to clearly model **types of relations**. Differentiating between comparative and material relationships helps **align** with these existing foundational models, making integration and interoperability with other ontologies smoother.\n\n### Applying to Kosmion:\nIn **Kosmion**, maintaining the differentiation between **comparative** and **material relationships** could enhance the ontology by allowing it to:\n- **Capture different levels of association** between entities more accurately.\n- **Facilitate reasoning** over whether a relationship implies an **actual interaction** or is just a **relative comparison**.\n- **Enhance modularity** by allowing future extensions to specifically address either **comparative** or **material relationships**, depending on the intended use case.\n\nFor example, in Kosmion, if you have two individuals, you might use a **material-relationship-type** to model an employment contract (`:person1 employedBy :company`), whereas a **comparative-relationship-type** might model their height (`:person1 tallerThan :person2`). This differentiation helps prevent modeling confusion and makes sure that the intended meaning of each relationship is clear and appropriately represented.\n\n## what are some edge cases, where relations might be considered either (or both)\n\nThe distinction between **comparative** and **material relationships** can sometimes be ambiguous, and there are edge cases where a particular relationship could be viewed as either or even both, depending on the context. Here are some scenarios where the categorization might be unclear:\n\n### 1. **Family Relationships** (e.g., \"Sibling Of\"):\n- **Material**: Being a sibling can imply an actual, physical relationship, particularly if it involves shared upbringing, inheritance, or obligations.\n- **Comparative**: It can also be seen as comparative if the relationship merely distinguishes certain characteristics (e.g., \"older sibling\" vs. \"younger sibling\") without implying a material interaction.\n  \n### 2. **Spatial Proximity** (e.g., \"Next To\"):\n- **Material**: If two objects are **physically placed** next to each other, this can be seen as a **material relationship** since it involves the physical placement of objects in a spatial context.\n- **Comparative**: However, describing one object as being \"closer\" or \"further\" compared to another object makes it more **comparative**. The relationship here doesn't imply any direct connection or influence, but rather a position relative to something else.\n\n### 3. **Employment Relationships** (e.g., \"Employed By\"):\n- **Material**: Employment is typically seen as a **material relationship** because it involves direct interaction and a reciprocal commitment (wages for work, obligations of employer and employee).\n- **Comparative**: In some situations, one might compare employment **status** across individuals or organizations without focusing on the actual commitments (e.g., comparing rates of employment among different groups). This shifts the context to a comparative one, though not the usual intention of the employment relation.\n\n### 4. **Ownership and Possession** (e.g., \"Owns\"):\n- **Material**: Ownership implies certain rights and obligations, making it a **material relationship** when modeled between entities (e.g., a person owning a house).\n- **Comparative**: However, if you are using ownership as a metric to compare individuals (e.g., \"owns more properties than another person\"), it becomes a **comparative** relationship. Here, the focus is on the relative quantity of possessions rather than a specific interactive connection.\n\n### 5. **Ranking Systems** (e.g., \"Ranked Higher Than\"):\n- **Comparative**: Ranking implies **ordering** based on some criteria (e.g., rank in a competition). It does not necessarily entail interaction but is based on comparing scores, abilities, or other properties.\n- **Material**: However, in some contexts, ranks may imply **material consequences**, such as privileges or responsibilities (e.g., military ranks where being a \"captain\" comes with material responsibilities over a subordinate). This could be seen as having elements of both comparative and material relationships.\n\n### 6. **Social Roles in Organizations** (e.g., \"Manager Of\"):\n- **Material**: A manager has responsibilities for specific people or departments, making this a **material relationship** involving interaction and dependency.\n- **Comparative**: The **status** of \"manager\" could also be used comparatively to distinguish someone's position from others in the hierarchy without implying direct interaction (e.g., \"is more senior than other staff members\").\n\n### Summary of Why Edge Cases Exist:\nThe distinctions can become blurry when relationships contain elements that are both **interactions** and **comparisons**:\n- **Material relationships** generally imply **direct interaction**, obligations, or some physical or causal connection.\n- **Comparative relationships** focus on **relative properties** between entities, without necessarily implying a concrete interaction.\n\nThese edge cases illustrate that whether a relationship is considered **material** or **comparative** can depend largely on **context** and **perspective**. Sometimes, the same relationship can be viewed differently depending on whether we are focusing on its **interactive** aspect or its **relative/comparative** aspect.\n\nFor your **Kosmion ontology**, handling these edge cases might involve:\n- Providing **explicit definitions** for each relationship type.\n- Allowing **dual classification** in specific scenarios, or creating **hybrid** relationship types.\n- Adding **context metadata** to clarify whether the relationship is being considered in a comparative or material capacity.\n\n## I found examples #2 and #5 most compelling. For now, let's get of comparative-relationship-type and material-relationship-type\n\n\n\n## I'm toying with the idea of \"facet-orientation\". Instead of gufo's \"types\" (which can be stereotyped as kind, sub-kind, etc), I'm thinking about making everything have facets, so eschewing most or all of the Sortal stereotypes, and just keeping the nonsortals and aspects.\n\nThe idea of **\"facet-orientation\"** you're toying with could offer a novel and flexible way of modeling entities by **eschewing sortal stereotypes** and focusing on **facets** that describe multiple characteristics or dimensions of a concept. In contrast to the **sortal** stereotypes (like **kinds** and **sub-kinds**) in **gUFO**, which often carry strict identity and rigidity rules, **facet-orientation** could allow for a more dynamic and **multi-perspective** representation of entities, similar to the way that **nonsortals** or **aspects** in gUFO are used. Here's how this approach might look and the possible benefits:\n\n### How Facet-Orientation Differs from Sortals and Types\n- **Sortal Types** in **gUFO**, like **kind**, **sub-kind**, and **role**, come with **identity conditions** that define **what makes an entity the kind of thing it is**. For example, a **Person** as a **kind** has certain properties that rigidly define its identity.\n- In a **facet-oriented** approach, instead of using rigid **sortal stereotypes**, entities could be defined by different **facets** that are **orthogonal** to one another. This allows for a more nuanced view where an entity might be understood through different **characteristics** or **aspects**, without necessarily being forced into a single **sortal type**.\n\n### Benefits of a Facet-Oriented Approach\n1. **Flexibility in Classification**:\n   - Instead of having a rigid identity condition as imposed by **sortal stereotypes**, entities could have **multiple facets** that represent different **contexts** or **roles**. For example, a **person** might have the facets of being a **parent**, an **employee**, and a **mentor** without these facets being mutually exclusive or strictly defining their identity.\n  \n2. **Dynamic and Evolving Characteristics**:\n   - In contrast to **sortals**, which often imply **rigidity**, facets can be **added, changed, or removed** as the context of the entity changes. This fits well with **open-world ontologies** where the **characteristics** of entities are subject to evolution, without having to reclassify them entirely.\n\n3. **Emphasis on Nonsortals and Aspects**:\n   - By focusing on **nonsortals** and **aspects**, you can model entities in a way that emphasizes their **relations** and **qualities** without necessarily grounding them in a rigid class. Aspects like **color**, **age**, or **location** can serve as facets that describe an entity’s state or properties.\n   - This fits well with **relational ontologies**, such as **Kosmion**, where the **relationships** between entities might be more critical to model than the entities themselves.\n\n### Example of Applying Facets in Kosmion\nSuppose you have an entity like a **person**. Instead of defining that person as a **kind** (`gufo:Kind`), which would imply a strict identity condition, you could describe the person with various **facets**:\n- **Social-Facet**: Has relationships such as **friend**, **colleague**, **member**.\n- **Temporal-Facet**: Current **age** or **lifecycle stage** (e.g., child, adult, senior).\n- **Contextual-Facet**: **Employed** by a company, **living** in a particular city.\n\nEach of these **facets** can evolve independently, giving a more flexible and **context-dependent** description of the entity. \n\n### Challenges and Considerations\n1. **Complexity in Reasoning**:\n   - While facets provide **flexibility**, they may introduce complexity when it comes to **reasoning** about entities. Since facets don’t imply a strict identity, it may be harder for automated systems to infer **unique characteristics** of an entity.\n  \n2. **Lack of Identity Constraints**:\n   - Without sortals, it may be harder to impose **identity constraints** on entities. This could be a problem in scenarios where you need to distinguish entities or track them over time with stable criteria.\n  \n3. **Semantic Clarity**:\n   - It may be challenging to maintain **semantic clarity** without sortal stereotypes, as these often help to create **clear boundaries** between different types of entities. Careful use of facets and **metadata** would be needed to ensure clarity when defining relationships or dependencies between entities.\n\n### Moving Forward with Kosmion\nIf you decide to implement **facet-orientation** in **Kosmion**, you could:\n- **Define Facet Classes**: Create different classes representing **facets** (e.g., `kosm:social-facet`, `kosm:temporal-facet`), each with its own properties.\n- **Attach Facets via Relators**: Link entities to different facets through **relators**, which could themselves have **facets** describing **temporal validity**, **context**, etc.\n- **Avoid Sortal-Stereotyped Relationships**: Eliminate the need for entities to have a primary **sortal stereotype** and instead allow **multiple facets** to coexist, representing different perspectives or contexts.\n\nThis approach might lead to a more **relational and contextual** way of describing entities, fitting well with the **open, evolving nature** of the Kosmion ontology.\n\n## OK, let's replace \"kosm:type\" with \"kosm:facet\"\n\n## Let's work on \"facet stereotypes\". So please create a facet-stereotype class. I think \"Category\" is an obvious stereotype. So it should be an instance of facet-stereotype. should it also be a class?\n\nI've added a facet-stereotype class to your ontology, and made category an instance of facet-stereotype. Additionally, I've also made category a class itself, allowing it to classify other facets.\n\nThis structure should provide flexibility in defining facet stereotypes and enable category to serve dual roles: both as an instance and a class, depending on the context. \n\n## instead of \"kosm:category a kosm:facet-stereotype, owl:Class \", maybe it should be a subClass of facet-stereotype? Let's discuss before you make changes.\n\nIf we consider making **`kosm:category`** a **subclass** of **`kosm:facet-stereotype`**, it would indicate that **category** is one of several possible **types of facet-stereotypes**. This aligns with the idea of **hierarchical modeling**, where **category** is a specific kind of **facet-stereotype** that can itself be instantiated or subclassed to represent more specific categories.\n\n### Benefits of Using `kosm:category` as a Subclass:\n1. **More Granular Representation**:\n   - By making **category** a **subclass** of **facet-stereotype**, you allow for more **specific facet-stereotypes** to be defined under **category**. This provides a better structure for creating different types of categories that can organize various **facets**.\n\n2. **Clearer Conceptual Hierarchy**:\n   - Defining **category** as a **subclass** also aligns with best practices for **ontological design**, where general concepts (like **facet-stereotype**) are refined into more specific types (like **category**). This approach makes the **ontology more expressive** without compromising on logical structure.\n\n3. **Consistency in Class Usage**:\n   - Keeping **category** as a **subclass** ensures consistency in how classes are used throughout the ontology. If **facet-stereotypes** are all **classes**, then **category** being a **class** and a **subclass** of `facet-stereotype` preserves this pattern, rather than making **category** both an **instance** and a **class** (which can lead to more complex reasoning, especially in **OWL DL**).\n\n### Challenges of the Current Instance Approach:\n- Having **`kosm:category`** as both an **instance** and a **class** (`owl:Class`) is allowed in **OWL Full** due to the flexibility of **punning** but can introduce complexity for **reasoners** that operate in **OWL DL**, where having the same entity act as both a **class** and an **instance** can cause issues with **inference** and **logic**.\n- This dual nature can also complicate the interpretation of **categories**: Are they concepts that define other classes, or are they objects that you instantiate?\n\n### Recommendation:\nI recommend making **`kosm:category`** a **subclass** of **`kosm:facet-stereotype`**, as it would provide:\n- **A clean hierarchical structure** that is easy to interpret.\n- **Ease of reasoning** and compatibility with existing tools and reasoners.\n- **Flexibility** in extending the ontology, allowing you to add other **facet-stereotypes** or subcategories of **category**.\n\nLet me know if you'd like to proceed with this change, and I can make the necessary updates!\n\n\n## I agree it should be a subclass, but should it still be an instance of facet-stereotype as well? my brain is starting to hurt.\n\nThe idea of making **`kosm:category`** both a **subclass** and an **instance** of **`kosm:facet-stereotype`** is indeed complex, but it can be understood through the lens of **punning** and **meta-modeling**.\n\n### Pros of Keeping `kosm:category` as Both an Instance and a Subclass:\n1. **Meta-Level Modeling**:\n   - Having **`kosm:category`** as both an **instance** and a **subclass** allows you to treat **categories** as something that can **be categorized** themselves and also serve as **categories** for other facets.\n   - This can be useful in **meta-modeling**, where you want to allow **facets of facets** or allow **recursive classification**.\n\n2. **Flexibility in Conceptualization**:\n   - By defining **category** as an instance, you are giving it a concrete role within the **facet-stereotype** framework.\n   - Simultaneously, having it as a **subclass** allows for the creation of more specific types of **categories** within the ontology. This dual role provides greater **flexibility** for future extensions.\n\n### Cons and Challenges:\n1. **Increased Complexity**:\n   - Having **`kosm:category`** be both a **class** and an **instance** can introduce complexity for **reasoning** in an ontology, especially if you plan to use tools that rely on **OWL DL**. Such tools may struggle with entities that occupy multiple levels of abstraction simultaneously, which could hinder **inference**.\n   - This complexity can also make the **conceptual model** more difficult to understand for people not deeply familiar with **meta-modeling**.\n\n2. **Punning**:\n   - Using **punning** in **OWL Full** allows **`kosm:category`** to be treated both as an individual (instance of **`kosm:facet-stereotype`**) and as a class (subclass of **`kosm:facet-stereotype`**). This can be very **powerful**, but it may make the ontology harder to **reason** over for standard tools that are optimized for **OWL DL**.\n\n### Recommendation:\n- **Keep `kosm:category` as a Subclass Only**:\n  - If you want to **avoid complexity** and ensure better compatibility with **reasoners**, I recommend making **`kosm:category`** only a **subclass** of **`kosm:facet-stereotype`**. This approach still allows **categories** to be further specialized without the potential pitfalls of making them both classes and instances.\n\n- **Dual Role Only if Necessary**:\n  - If you really need **`kosm:category`** to act as both a **subclass** and an **instance** (e.g., for **meta-level classification** purposes), then keeping both roles could be justified. This approach is more **expressive** and suitable for complex **ontological models**, but you should be prepared to work with **OWL Full** and understand that this might limit the tools and **reasoners** available to you.\n\n### Next Steps:\n- If you decide to proceed with **`kosm:category`** as a **subclass only**, I can update the ontology accordingly.\n- Alternatively, if you want to explore keeping it as both, I can help refine the approach to manage the potential complexity.\n\nLet me know your preference, and I'll make the appropriate adjustments!\n\n## what are some examples where kosm:category could be used as an instance?\n\nIf **`kosm:category`** were to be used as an **instance** of `kosm:facet-stereotype`, it would represent a **particular type of stereotype** within the facet-stereotype framework. Here are some scenarios where treating `kosm:category` as an **instance** could make sense:\n\n### 1. **Meta-Classification of Facet Types**:\n   - In a **meta-modeling** context, `kosm:category` could serve as an **instance** that helps **classify facets**. For example, it could indicate that a given facet is of type **category**, while other stereotypes might be **aspect**, **role**, or **state**. This way, `kosm:category` can help in tagging or grouping facets under a broader **conceptual umbrella**.\n\n### 2. **Annotation or Documentation**:\n   - When used in documentation or as part of **metadata** in an ontology, `kosm:category` can provide **additional information** about the facet. For instance, `kosm:category` could be used to denote that a particular facet itself belongs to the broader \"category\" type.\n   - Example:\n     ```turtle\n     kosm:facetA a kosm:facet ;\n        kosm:category kosm:category ;\n        rdfs:label \"Facet A\" ;\n        rdfs:comment \"An example facet that is categorized under the category stereotype.\" .\n     ```\n     In this case, **`kosm:category`** acts as an instance of `kosm:facet-stereotype` to provide **annotation** about the nature of `kosm:facetA`.\n\n### 3. **Facet-Type Instance for Reasoning**:\n   - If you want to allow for **reasoning** that distinguishes between **different kinds of facet stereotypes**, having `kosm:category` as an **instance** helps make that explicit. For instance, a **reasoner** could use the fact that `kosm:category` is an instance to make **meta-level inferences** about which other facets are categorized similarly.\n   - You could have rules that apply to **all facets** that are categorized as `kosm:category`, thereby making inferences about their **behavior** or **properties**.\n\n### 4. **Schema-Level Annotations**:\n   - Using `kosm:category` as an instance could also be useful in **schema-level annotations**. For example, if you were describing or generating a UI that helps users interact with the ontology, `kosm:category` as an instance can be used to **define the grouping** or **categorization structure** in that context.\n   - Example:\n     ```turtle\n     kosm:categoryInstance a kosm:category ;\n        rdfs:label \"Person Categories\" ;\n        rdfs:comment \"Categorization for all facets related to person entities.\" .\n     ```\n     Here, **`kosm:categoryInstance`** is an individual instance that provides **categorization for person-related facets** under the `kosm:category` stereotype.\n\n### Summary:\n- **Using `kosm:category` as an instance** makes sense in contexts where you want to **annotate**, **meta-classify**, or add **schema-level meaning** to facets.\n- It provides a way to deal with **meta-information** about facets and helps in **reasoning** at a higher level without explicitly linking everything in a strict class hierarchy.\n- The trade-off is complexity, particularly for **reasoners**, which may need to navigate the **punned** nature of `kosm:category`.\n\nGiven these examples, if you find these types of **meta-level annotations** and **schema-level flexibility** useful, it could be justified to keep `kosm:category` as both a **subclass** and an **instance** of `kosm:facet-stereotype`. However, if these scenarios are not central to your current use case, making it a **subclass** only might simplify the ontology and improve **reasoner compatibility**.\n\n## I didn't find your examples compelling. I believe you can make annotations about classes as well as instances, right? But if we're going to categorize the facet-stereotypes, e.g. as sortals, non-sortals, and aspects they'd have to be instances? Especially if we attach those meta-categories with relators.\n\nYou’re absolutely right; if we want to **categorize** the **facet-stereotypes** (e.g., into **sortals**, **nonsortals**, and **aspects**), they would need to be **instances** to properly serve in that **meta-categorization** role. This is particularly true if we intend to **attach those meta-categories with relators**, which is consistent with your **relator-based modeling** approach.\n\nHere are some specific reasons why having **facet-stereotypes as instances** could be beneficial when applying **meta-categories**:\n\n### 1. **Meta-Category Assignment with Relators**\n- By making **facet-stereotypes** like **category** an **instance**, we can attach **relators** to them, allowing us to describe how these stereotypes relate to **meta-categories** such as **sortal**, **nonsortal**, or **aspect**.\n- For instance, you could create a relator like `kosm:categorized-as` that links an instance of `kosm:facet-stereotype` (e.g., `kosm:category`) to a **meta-category** (e.g., `kosm:nonsortal`). This allows a very flexible way of building and **extending** the ontology without rigidly enforcing class-subclass hierarchies.\n\nExample:\n```turtle\nkosm:category a kosm:facet-stereotype ;\n    kosm:categorized-as kosm:nonsortal .\n```\nThis way, **category** is described as being a **nonsortal**, and these relationships can be updated or extended through **relators** without altering the **core hierarchy** of the ontology.\n\n### 2. **Simpler and More Flexible Annotation**:\n- If **facet-stereotypes** are **instances**, we can easily **annotate** them with additional **properties** using **datatype properties** or **object properties**. This would be simpler compared to adding annotations directly on **classes**, which could otherwise complicate the **model** if many annotations are needed.\n- Making **facet-stereotypes** instances allows them to have their own **metadata**, like definitions, creation dates, or external references, without making them formal **OWL classes** with all the entailments that come with it.\n\n### 3. **Enhanced Reasoning and Meta-Level Querying**:\n- Treating **facet-stereotypes** as **instances** allows for **meta-level reasoning**. For example, we can make inferences about all **nonsortal facet-stereotypes** by querying instances rather than trying to navigate a **class hierarchy**.\n- This distinction also makes it easier to **query** for specific **stereotypes** (e.g., “list all facet-stereotypes categorized as nonsortal”) without needing to worry about hierarchical **inferences** that might complicate things in **OWL DL**.\n\n### 4. **Flexibility for Multiple Facet Categories**:\n- If facet-stereotypes are **instances**, you can assign **multiple categories** to them, if necessary, which would be more complex to achieve in a strict class hierarchy. For example, a particular facet-stereotype could be both an **aspect** and a **nonsortal**, depending on the context, and you can model this through multiple **relators** linking to different meta-categories.\n  \n### Proposed Update:\n- **Keep `kosm:category` as an instance** of `kosm:facet-stereotype` to represent its **meta-level** categorization.\n- Also make **`kosm:category` a subclass** if you want it to classify other **facets** that belong specifically to the **category** type.\n  \nThis approach provides the **best of both worlds**: you get the flexibility of **instances** for **meta-categorization** while still retaining **hierarchical modeling** when needed.\n\nWould you like me to proceed with making these adjustments to `kosm:category`, or would you like to define any **meta-categories** or **relators** that we can use to link these **facet-stereotypes** further?\n\n## Maybe a facet only ever would have one stereotype? Can you think of examples of facets that would have multiple stereotypes. \n\nIf we consider whether a **facet** might have **multiple stereotypes**, it seems plausible but not necessarily common. Let's explore some scenarios where it could make sense:\n\n### Potential Scenarios for Multiple Stereotypes:\n\n1. **Mixed Characteristics of Sortal and Aspect**:\n   - Suppose you have a **facet** that represents **physical presence**. This facet could be seen as an **aspect** (a quality that can change over time) but also as having a sortal nature since it might define identity conditions that are associated with presence (e.g., being a \"resident\").\n   - In this case, the **physical presence facet** might need to be treated both as an **aspect** (describing some state or quality of an entity) and as a **sortal** (implying specific identity conditions or constraints).\n\n2. **Temporary Roles that Impact Identity**:\n   - Consider a **facet** representing a **professional role** that an entity can occupy. For example, the role of **manager** could be stereotyped as:\n     - **Nonsortal**: Since a professional role like **manager** is temporary and does not define an entity's essential identity.\n     - **Aspect**: If this role impacts specific attributes or influences other relationships within the organization, it could also be considered an aspect of the person's career.\n   - Thus, the **manager facet** might need to be categorized under both **nonsortal** and **aspect** stereotypes.\n\n3. **Contextualized Aspects with Shared Identity**:\n   - If you have a **contextual facet** like **ownership** in a cooperative organization, this facet could simultaneously have aspects of both:\n     - **Aspect**: Because **ownership** could be a changeable quality (e.g., the percentage of ownership may change).\n     - **Nonsortal**: Since being an **owner** might not rigidly define the identity of an entity but instead add a role or capacity within a specific context.\n   - Such a facet could therefore embody characteristics that make it both an **aspect** and a **nonsortal**, depending on how the ownership is conceptualized.\n\n### Considerations for Kosmion:\n- **Avoiding Overcomplication**: Assigning multiple stereotypes to a single facet might add **complexity** to the model, which could impact **reasoning** and **ease of understanding**. Keeping **one stereotype per facet** makes it easier to categorize, reason over, and maintain.\n- **Clarity in Modeling**: The use of **multiple stereotypes** could potentially blur the purpose of the facets. It might be more beneficial to **split** complex facets into separate facets, each with a distinct stereotype, rather than attempting to categorize a single facet in multiple ways.\n\n### Proposed Approach:\n- It may be best to assume that each **facet** has only **one stereotype** for clarity and simplicity.\n- If a facet seems to require multiple stereotypes, it might be a sign that it is **too broad** and should be divided into **distinct facets** that each focus on a more specific aspect or role.\n  \nWould you like to proceed with keeping facets to **one stereotype** each, or explore other ways to handle facets that might require **multiple characteristics**?\n\n## maybe valid-time is a facet? \n\n**Valid-time** as a **facet** is an interesting and potentially useful way to handle the **temporal aspects** of your ontology, especially given your focus on **bitemporality**. Here's why modeling valid-time as a **facet** could make sense:\n\n### Why Valid-Time as a Facet?\n1. **Temporal Characteristic**:\n   - **Valid-time** represents the **time period** during which a given relator or entity is **valid in the real world**. By treating it as a **facet**, you can clearly articulate that **temporal applicability** is just one of the **dimensions** or **characteristics** of an entity.\n   - This approach aligns well with your **facet-oriented** modeling, allowing temporal validity to be handled in a consistent way alongside other **facets** like **context**.\n\n2. **Flexible Categorization**:\n   - As a **facet**, valid-time can be categorized under a **specific facet stereotype** (e.g., as an **aspect**). This categorization makes it easy to distinguish **temporal facets** from other types of facets (such as **roles** or **contexts**).\n   - By doing this, you gain the ability to handle **time** in a modular way, where different entities may or may not have valid-time, depending on their role in a given scenario.\n\n3. **Associating with Relators**:\n   - **Relators** can have multiple **facets** associated with them, and valid-time can be one of those facets. This allows a relator to explicitly reference **when** it applies without embedding that information in metadata or attributes directly.\n   - For instance, a **relationship** like \"owns a house\" might only be valid for a specific time range. Treating valid-time as a **facet** means you can describe its **temporal applicability** as a characteristic separate from the **relationship itself**.\n\n### Example Addition to the Ontology:\nWe can define `kosm:valid-time` as a **facet** and link it to `kosm:relator`. Here’s how it might look:\n\n```turtle\n# Define the valid-time facet\nkosm:valid-time a kosm:facet ;\n    rdfs:label \"valid time\" ;\n    rdfs:comment \"A facet representing the temporal validity of an entity or relator.\" .\n\n# Attach valid-time to relators using a relator facet relationship\nkosm:relator a owl:Class ;\n    rdfs:label \"relator\" ;\n    rdfs:comment \"A class representing relators, which describe relationships (including unary relationships) among entities.\" ;\n    kosm:has-facet kosm:valid-time .\n```\n\nIn this example:\n- **`kosm:valid-time`** is defined as a **facet** that represents the **temporal validity** of entities or relationships.\n- We add a link from the **relator class** to **valid-time** via `kosm:has-facet`, signifying that valid-time is a **characteristic** of relators.\n\n### How This Helps:\n- **Clear Separation**: Instead of treating valid-time as metadata or forcing it into every relator, it's treated as an **optional facet**. This makes it **clear and modular**, so only those entities or relationships that require a valid-time need to reference it.\n- **Facilitates Reasoning**: By making valid-time a facet, you allow reasoners to **infer** and **categorize** temporal applicability separately, which could enhance **querying** and **reasoning** about entities based on their valid period.\n\n### Potential Challenges:\n- **Facet Stereotyping**: Valid-time would need a **stereotype** to categorize it. It would likely fit under an **aspect** stereotype, as it describes a state or condition that **applies** to entities over time.\n- **Consistency**: You’d need to make sure that valid-time is handled consistently across different types of entities, relators, or contexts, ensuring the facet model remains cohesive.\n\n### Conclusion:\nModeling **valid-time** as a **facet** is a good fit for your **facet-oriented** ontology, especially given its **temporal focus**. It allows you to manage temporal validity in a flexible and expressive way, making it easier to apply **bitemporality** and to extend the model as needed. If you'd like, I can help integrate this concept into your current **Kosmion ontology** document.\n\n## doing modular ontologies seems confusing. If you import another ontology, won't you need to use different prefixes?\n\nYou're absolutely right, managing **prefixes** when importing multiple **modular ontologies** can indeed be confusing. Here are a few points to consider:\n\n### Issues with Prefixes in Modular Ontologies\n1. **Unique Prefixes Required**:\n   - When you import another ontology, you need to use a **different prefix** for each imported ontology to **avoid collisions** between terms. This ensures that all **IRIs (Internationalized Resource Identifiers)** are distinct. This can make querying and referencing a bit cumbersome, especially if you have to frequently refer to concepts from multiple ontologies with different prefixes.\n\n2. **Namespace Management**:\n   - Different ontologies will often use different **namespaces** as prefixes. When combining them, this can lead to **longer, inconsistent prefixes**, making the modeling experience more cumbersome. For example, importing both **gUFO** and another ontology might lead to having to use `gufo:` alongside another distinct prefix (like `ex:` for a new ontology) every time you reference a class.\n\n3. **Human Readability**:\n   - Having multiple prefixes in a document can reduce **readability** for humans, as it becomes harder to track where each concept originates. If every ontology brings in its own set of prefixes, you end up with a document full of different prefixes, making it easy to get confused about which concept is from which ontology.\n\n### Possible Solutions for Prefix Management\n1. **Prefix Aliasing**:\n   - One common approach to simplifying prefixes is to use **aliasing**. When importing an ontology, you can define a **short alias** for it, which makes it easier to reference throughout the document. This keeps the prefixes short and consistent, improving readability.\n\n2. **Merging Concepts Using Common Namespaces**:\n   - Another approach is to use a **common namespace** for similar concepts across different ontologies. For example, if you are working on an **upper ontology** and you have several modular ontologies, you could define your own common prefixes and **re-map** concepts from the imported ontologies to these common namespaces. This helps unify the vocabulary, although it may require some reengineering and careful checking for semantic differences.\n\n3. **Use of Metadata Comments**:\n   - When importing different ontologies, it can be helpful to use **comments** to annotate which ontology a particular prefix corresponds to. This can help keep track of the origin of terms for future maintenance and for others who may need to understand the ontology.\n\n### Example Consideration for Kosmion\nIn the case of the **Kosmion ontology**:\n- You currently use **`kosm:`** as your main namespace prefix. If you import **gUFO**, you'll use `gufo:` for that namespace, which means that any reference to a **gUFO** type will need the `gufo:` prefix.\n- For example, `gufo:Type` and `kosm:facet` would both need distinct prefixes. If you’re frequently referencing concepts from **gUFO**, you may consider **aliasing** or **remapping** these concepts to fit better into your `kosm:` namespace, potentially making them **local aliases**.\n\n### Pros and Cons of Modular Ontologies with Multiple Prefixes\n- **Pros**:\n  - **Reusability**: Modular ontologies can be reused across different projects, allowing for **greater flexibility**.\n  - **Focused Design**: Each ontology can focus on a specific domain or aspect, keeping complexity low within each module.\n- **Cons**:\n  - **Prefix Management**: Requires careful management of prefixes to avoid name collisions and keep the ontology **understandable**.\n  - **Complexity in Queries**: SPARQL queries can become more complex because every referenced concept might require its **distinct prefix**, complicating query construction.\n\nWould you like to explore possible ways to simplify prefix usage or consider importing other ontologies into Kosmion and managing those imports? I can help outline a strategy to handle modular imports effectively.\n\n\n## It's so annoying that applications and the semantic web community seem to refer to instance data as an ontology\n\nI completely understand the frustration here. The **semantic web community** tends to blur the lines between **ontologies** and **instance data**. The term \"ontology\" should ideally refer to a **conceptual schema**—the definitions, classes, relationships, and axioms that define the **structure** of a knowledge domain. However, the community often uses \"ontology\" more broadly to also include **instance data**, which is the specific **facts or entities** that populate the classes defined by the ontology.\n\nThis can be confusing for several reasons:\n\n1. **Conceptual vs. Actual Data**: \n   - **Ontologies** are supposed to define the **concepts** and the **relationships** between those concepts in a given domain. **Instance data**, on the other hand, populates these concepts with real-world information.\n   - When people refer to **instance data** as part of the **ontology**, they’re mixing the conceptual schema (T-Box in description logic terminology) with the assertional or instance data (A-Box). In theory, these should be clearly distinguished.\n\n2. **Practical Use in Tools**:\n   - Tools like **Protege** handle both **ontologies** (conceptual structures) and **individuals** (instance data) within the same environment. This often leads to users referring to the combined **schema and data** as an \"ontology.\" This is especially true for **OWL ontologies**, where the same RDF framework can represent both the T-Box (conceptual model) and A-Box (instance data).\n\n3. **Naming Issues**:\n   - In practice, importing an \"ontology\" often brings in both **concepts** and **instance data**, which leads to referring to the entire dataset as an \"ontology,\" regardless of whether it contains just schema definitions or also includes entities and individuals. This makes the lines between the **abstract** and **concrete** levels very blurry.\n\n4. **The RDF Data Model**:\n   - In **RDF and OWL**, there isn’t a strong formal distinction between classes, properties, and individuals at the data model level. Since everything is ultimately represented as **triples**, instance data and ontological definitions are treated similarly. This contributes to the tendency of referring to both as an \"ontology\" since the toolset doesn’t enforce a distinction.\n\n### Possible Solutions:\n- **Separate Ontology and Instance Files**: When designing an ontology, you can create **separate files** for the **schema** and the **instance data**. This allows you to more clearly differentiate the **conceptual definitions** from the **facts**.\n- **Naming Conventions**: Use distinct **naming conventions** or prefixes for **ontological definitions** and **instance data** to help maintain clarity.\n- **Explicit Documentation**: In your ontology documentation, explicitly differentiate between the **conceptual schema** (ontology) and the **instance data**. Tools like **Protege** allow you to define these separately, even though they are handled within the same environment.\n\nIf you want to take a more **modular approach** for Kosmion, you could develop distinct **conceptual modules** (like `kosm:facet` and `kosm:relator` definitions) and create separate datasets for the **instance-level data**, possibly referencing these modules without blending them together.\n\n\n## what is the relationship between OntoUML's class stereotypes and relationship stereotypes? \n\n\n## seems like most upper and foundational ontologies define a \"base\" concept. e.g. gUFO has Individual and Type. I suspect that with a facet-based approach, that's not necessary? other than facet, of course.\n\nThe idea of not having a base \"thing\" or **top-level concept** in **Kosmion** makes a lot of sense in the **facet-based approach** you are exploring. Let's analyze why this might be the case and how it differs from the more conventional **sortal-based approaches**:\n\n### 1. **Conventional Upper Ontologies with Base Concepts**:\n   - Many **upper or foundational ontologies** like **gUFO**, **BFO (Basic Formal Ontology)**, and **SUMO (Suggested Upper Merged Ontology)** define top-level **base concepts** such as **\"Individual\"**, **\"Entity\"**, **\"Object\"**, or **\"Type\"**.\n   - These base concepts are intended to provide a **starting point** or **root** for categorizing everything else, giving a **hierarchical structure** to the ontology. For example:\n     - **gUFO** has **Individual** and **Type**, which are fundamental building blocks for distinguishing between **concrete instances** and **conceptual definitions**.\n     - **BFO** has concepts like **\"Continuant\"** and **\"Occurrent\"** that provide broad categorizations of **what exists** either as a persistent entity or an event.\n\n### 2. **Facets vs. Base Concepts**:\n   - In your **facet-based approach**, there’s less emphasis on establishing a single **hierarchical root**. Instead, everything can be described using **facets**, which act as **characteristics** or **perspectives** rather than as rigid categories.\n   - **Facets** themselves are inherently **modular** and **context-dependent**, which allows entities to be described in a more **compositional** manner. Rather than determining \"what an entity fundamentally is,\" the focus is on **which facets** apply to it.\n\n### 3. **Why a Base Concept May Not Be Necessary**:\n   - **Facets Enable Flexibility**: By using **facets** to describe entities, you avoid the need to explicitly classify entities under a root concept like **\"Individual\"** or **\"Entity\"**. This fits well with the idea that **different aspects** of an entity can be relevant in different contexts, without assuming an ontological base for all instances.\n   - **No Rigid Classification**: Unlike sortal approaches, which often have **identity criteria** tied to base classes, the **facet-based model** allows entities to acquire characteristics **dynamically** through the **facets** they possess. Thus, there isn’t a strict need for every entity to fall under an overarching class—each entity is defined by its **collection of facets**.\n   - **No Explicit Subsumption Hierarchy**: Facets do not imply **subsumption** (i.e., they do not inherently classify entities in a strict **type hierarchy**), which means that concepts don’t need to fit neatly under a single base type. This keeps the ontology **open-ended** and more **flexible** for different contexts and purposes.\n\n### Potential Downsides to Not Having a Base Concept:\n1. **Lack of Standardization**: Without a base concept, it may be harder to enforce certain **standardized constraints** across the entire ontology. For example, **global properties** that apply to all individuals may need to be handled differently without a top-level class to attach them to.\n  \n2. **Query Complexity**: In some cases, **SPARQL queries** or other reasoning tasks may become more **complex** since there isn’t a single **\"root class\"** to use for selecting all entities.\n\n### Practical Considerations:\n- In **Kosmion**, you could still add a very **minimal base concept** if you find that it helps with certain **consistency** or **reasoning** tasks. This could be something like an abstract **\"kosm:thing\"** class that serves as an anchor without imposing rigid requirements.\n- Alternatively, **facets themselves** could serve as the common ground that **all entities must have**—essentially, every entity needs to have at least one **facet**. This would functionally serve as your base requirement, without needing a **conventional sortal root**.\n\nIf you decide that a minimal base is useful after all, it could be purely for technical convenience rather than conceptual necessity, which keeps the **facet-oriented** spirit intact while addressing practical concerns. Would you like me to explore adding such a minimal root, or are you leaning towards continuing without one?\n\n## I think the potential downside are mitigated by the fact that kosmion is already non-standardized, and aims for interoperability. Maybe domain applications should define their own top-level constructs, and they can just implement facets instead of having to instantiate someone else's preconceptions. *domain model first*?\n\nYour approach—**domain model first**—makes a lot of sense, particularly for **Kosmion**, where the goal is to be **non-standardized** and to focus on **interoperability**. Here’s why I think this approach could work really well in your ontology:\n\n### **Why Domain Applications Should Define Their Own Top-Level Constructs**:\n\n1. **Avoiding Imposed Semantics**:\n   - By not having a rigid **upper-level concept** like \"Individual\" or \"Entity,\" you avoid imposing any **predefined semantics** on domain applications. This allows each **domain** to define what makes sense in their **context** without inheriting **assumptions** from a foundational ontology that might not align with their specific needs.\n   - This aligns with the principle of **facets**: instead of forcing domain-specific constructs to fit into an overarching type hierarchy, **facets** provide a **modular** way of defining properties and relationships that make sense **locally**.\n\n2. **Interoperability Through Facets**:\n   - **Facets** are inherently **modular**, which helps in building **interoperable models**. By allowing domain-specific models to **implement facets** rather than instantiating someone else’s rigid concept of a top-level entity, different domains can **interoperate** more easily by mapping **shared facets** rather than reconciling different top-level taxonomies.\n   - For instance, if a domain ontology defines its top-level concept, like **\"Character\"** for a role-playing context, it can still **implement facets** like **context** or **temporal aspects** without having to fit into another ontology's conception of **entity types**.\n\n3. **Facilitating Customization**:\n   - With a **domain model first** approach, the **domain ontologies** can define their own **high-level categories** that make sense for their specific context, whether they want to define **physical entities**, **abstract entities**, or even more specialized types.\n   - They can then **add facets** as needed, making it easy to **customize** the ontology for the specific requirements of the domain without having to **inherit** any top-level entity that might add unwanted complexity or assumptions.\n\n4. **Avoiding the \"One-Size-Fits-All\" Problem**:\n   - One of the biggest challenges with foundational ontologies is that they often adopt a **\"one-size-fits-all\"** approach, which can be restrictive. Domains like **medicine**, **geography**, and **fantasy role-play** each have very different needs. By allowing domains to define their **own top-level constructs** and use **facets** to extend them, you avoid forcing all these diverse domains into the same high-level schema.\n  \n### **Implications for Kosmion**:\n- **Kosmion** would effectively provide a set of **facets** that any **domain-specific ontology** could choose from. It’s a **toolkit** rather than a **blueprint**, meaning that domain ontologies can pick and choose which facets they need without worrying about fitting into an existing high-level hierarchy.\n- **Facets** like **context**, **temporal aspects**, or **relationship descriptors** can be seen as **interoperable modules** that any domain can apply, and these can serve as the common ground for cross-domain **integration**.\n\n### **Example**:\n- Suppose you have a domain ontology for **urban planning**. Instead of classifying everything under a foundational concept like **\"Entity\"** or **\"Object\"**, the domain ontology can define its top-level classes, such as **\"Infrastructure\"**, **\"Service\"**, or **\"Citizen\"**. \n- Each of these entities can then **implement facets** like **\"valid-time\"**, **\"context\"**, or **\"category\"**, which allows them to align with other domains that use similar facets without enforcing any kind of **common root**.\n\n### **\"Domain Model First\" and Kosmion’s Development**:\n- This approach also helps when designing **Kosmion** itself. Since Kosmion is designed to provide **relators** and **facets**, it acts as an **interoperable foundation** that different domains can use and extend.\n- The fact that it doesn’t have a strict top-level concept also aligns well with its **non-standardized**, open-ended goals. It essentially pushes the **burden of meaning** onto the **domain-specific ontologies**, which allows Kosmion to remain **lightweight** and **flexible**.\n\n### **Next Steps**:\n- **Focus on Facets**: Continue focusing on defining useful **facets** that can be used across different domains. These should be **modular** and **interoperable** to maximize flexibility.\n- **Domain Implementation**: Let domains develop their **own top-level concepts** and simply implement **facets** as needed. This will keep Kosmion adaptable and suitable for many different contexts.\n\nWould you like me to make changes in the current ontology to emphasize this **facet-only approach**, or perhaps add a comment or metadata indicating this **domain-first philosophy**?\n\n","n":0.012}}},{"i":4952,"$":{"0":{"v":"getting kosmion off the ground","n":0.447},"1":{"v":"\n## Back on the subject of using named graphs for each relator. I guess you can say things about named graphs with RDF statements, but there must be some downsides. What are the benefits?\n\nUsing **named graphs** for each **relator** in your ontology can offer several **benefits** and **downsides** that are worth considering.\n\n### Benefits of Using Named Graphs for Relators:\n\n1. **Contextualization**:\n   - Named graphs allow you to **group** RDF triples and associate them with a **context**. In your relator-based approach, each named graph could represent a specific **relator** (or relationship), meaning you can group all the triples relevant to that relator together. This makes it easier to manage and query relationships as distinct units.\n   - Example: You could store all the facts about a specific collaboration (like participants, roles, and start dates) in one named graph.\n\n2. **Statements About Statements**:\n   - RDF reification allows you to make statements **about** statements (such as who asserted them or when they were asserted), but this can be verbose. Named graphs provide a **more efficient way** to achieve this by letting you attach metadata to the entire group of triples (the graph) rather than reifying each individual statement.\n   - You can add metadata like:\n     - Who created the relator.\n     - The **validity period** of the relator's relationship.\n     - Provenance information (e.g., **who asserted** the relator's facts and when).\n\n3. **Managing Temporal Information**:\n   - Named graphs align well with your goal of managing **bitemporality**. For each relator, you can use named graphs to track **valid-time** and **system-time** for a group of relationships, making it easier to handle historical data.\n   - You could attach temporal metadata to a graph, allowing you to **invalidate** the graph (e.g., by adding a `:system-to` property), rather than modifying individual triples, preserving immutability.\n\n4. **Granular Access Control**:\n   - Named graphs allow for **fine-grained access control**. In systems where you need to control who can read or modify specific relationships or parts of the data, named graphs can be used to restrict or permit access to different users or agents based on the graph.\n   - This can be useful for **multi-tenant systems** where different users should have access to different parts of the RDF dataset.\n\n5. **Simplifying Queries**:\n   - By using named graphs, you can **simplify complex SPARQL queries** by targeting a specific graph rather than filtering out irrelevant triples from the entire dataset. This leads to more efficient and focused queries, particularly when dealing with large datasets.\n   - Example: `GRAPH ?g { ?s ?p ?o }` allows you to query only within a specific named graph `?g` rather than over the entire dataset.\n\n### Downsides of Using Named Graphs for Relators:\n\n1. **Increased Complexity**:\n   - Managing large numbers of named graphs can introduce **complexity** into your system. If every relator has its own named graph, you might end up with a proliferation of graphs, making it harder to manage, query, and maintain consistency across the dataset.\n   - Query complexity could increase, as you'll need to frequently reference the correct graph in your queries.\n\n2. **Compatibility with Tools**:\n   - Not all RDF tools or triple stores offer full support for **named graphs**. While many SPARQL-compliant systems (like **Apache Jena** or **Blazegraph**) support named graphs, some reasoners or data storage systems might not fully leverage named graph semantics, leading to limitations in performance or capability.\n   - Named graphs are often seen as **orthogonal** to reasoning capabilities, so if reasoning across graphs is needed, it may be more complex to implement.\n\n3. **Loss of Granularity for Statements**:\n   - Named graphs are a good way to make statements about **groups of triples** but don’t work well for making statements about **individual triples**. If you need to add metadata to specific statements (for instance, to one triple in a relationship), you may still need to rely on **reification** or another mechanism.\n\n4. **Performance Overhead**:\n   - In some triple stores, using a large number of named graphs can add **performance overhead**, as each named graph is managed separately. Querying across multiple graphs or keeping track of dependencies between them can increase **query execution time** and **memory consumption**.\n\n### Summary:\n\n#### **Benefits**:\n- **Contextualization**: Grouping relationships in a relator-based model.\n- **Statements about statements**: More efficient than reification.\n- **Temporal management**: Simplifies tracking system and valid time.\n- **Granular access control**: Easier security management per relator.\n- **Simplified querying**: Targeting specific graphs for more focused queries.\n\n#### **Downsides**:\n- **Increased complexity**: Managing many named graphs can be cumbersome.\n- **Tool compatibility**: Some RDF tools may not fully support named graphs.\n- **Lack of granularity**: Cannot make statements about individual triples easily.\n- **Performance concerns**: Can cause overhead in some systems.\n\nIncorporating **named graphs** into your **Kosmion** ontology could be beneficial, especially for managing temporal and relational information in a structured way. Just consider the potential for complexity and tool compatibility when scaling your system.\n\n## I think querying might be too tricky with named graphs. Let's try to define kosmion without them for now.\n\nGot it! Let's focus on defining **Kosmion** without relying on named graphs.\n\nSince **Kosmion** involves **relators**, **immutability**, and **bitemporality**, we can still manage all of these elements directly within RDF using standard mechanisms like **triples**, **custom properties**, and **temporal fields** while ensuring the model remains simple to query.\n\n### Key Aspects of Kosmion (without Named Graphs):\n\n#### 1. **Relators as Central Entities**:\n   In Kosmion, **relators** are still the core units for representing relationships between entities. Each relator will be treated as a first-class entity with its own set of properties and relationships. However, instead of grouping these into named graphs, we'll focus on representing them directly within the RDF structure.\n\n   Example:\n   ```turtle\n   :Relator1 a :Relator ;\n             :role1 :Person1 ;\n             :role2 :Person2 ;\n             :relationshipType :Friendship ;\n             :validFrom \"2023-01-01T00:00:00\" ;\n             :validTo \"2024-01-01T00:00:00\" ;\n             :system-from \"2023-01-01T10:00:00\" ;\n             :system-to \"9999-12-31T23:59:59\" .\n   ```\n\n#### 2. **Immutability with System-Time**:\n   Each relator instance is immutable, meaning that once it is created, it cannot be modified. To support immutability, we'll introduce **system-time properties** (`:system-from` and `:system-to`) to record when a relator was valid in the system, as discussed earlier.\n\n   If a relator needs to be \"invalidated,\" a new version of the relator is created, and the `:system-to` field on the old version is updated to mark when it was replaced.\n\n   Example of invalidating a relator:\n   ```turtle\n   :Relator1 a :Relator ;\n             :role1 :Person1 ;\n             :role2 :Person2 ;\n             :relationshipType :Friendship ;\n             :validFrom \"2023-01-01T00:00:00\" ;\n             :validTo \"2024-01-01T00:00:00\" ;\n             :system-from \"2023-01-01T10:00:00\" ;\n             :system-to \"2023-06-01T12:00:00\" .  # Invalidated\n\n   :Relator2 a :Relator ;\n             :role1 :Person1 ;\n             :role2 :Person2 ;\n             :relationshipType :Friendship ;\n             :validFrom \"2023-01-01T00:00:00\" ;\n             :validTo \"2025-01-01T00:00:00\" ;\n             :system-from \"2023-06-01T12:00:01\" ;\n             :system-to \"9999-12-31T23:59:59\" .\n   ```\n\n#### 3. **Bitemporality**:\n   By combining **valid-time** (the time when a relationship is true in the real world) and **system-time** (the time when the information was inserted or updated in the system), you achieve **bitemporality**. These timestamps will be properties on each relator instance, and querying will involve filtering based on these properties.\n\n   Bitemporal queries would use both the **validFrom/validTo** fields and the **system-from/system-to** fields to reconstruct data at any point in the past, both in terms of its real-world applicability and system-level existence.\n\n#### 4. **Querying Without Named Graphs**:\n   You can still structure your **SPARQL queries** to filter for relators and their roles using the **system-time** and **valid-time** fields. Here's an example of a query to retrieve valid relators for a specific time period:\n\n   ```sparql\n   SELECT ?relator ?role1 ?role2\n   WHERE {\n     ?relator a :Relator ;\n              :role1 ?role1 ;\n              :role2 ?role2 ;\n              :validFrom ?vf ;\n              :validTo ?vt ;\n              :system-from ?sf ;\n              :system-to ?st .\n     FILTER (?vf <= \"2023-07-01T00:00:00\"^^xsd:dateTime && ?vt >= \"2023-07-01T00:00:00\"^^xsd:dateTime) .\n     FILTER (?sf <= \"2023-07-01T00:00:00\"^^xsd:dateTime && ?st > \"2023-07-01T00:00:00\"^^xsd:dateTime) .\n   }\n   ```\n\n   This query retrieves relators that were valid both in real-world time and in system time as of July 1, 2023.\n\n### Conclusion:\nBy eliminating named graphs, we simplify the querying process, but still maintain the **relator-based** structure and **bitemporal data handling** through direct RDF properties. This keeps the model straightforward while still enabling powerful temporal reasoning.\n\n## I was thinking instead of \"system-from\" and \"system-to\", maybe use \"genesis\" and \"tombstone\" or maybe \"relator-genesis\" and \"relator-tombstone\". What do you think?\n\nUsing **\"genesis\"** and **\"tombstone\"** (or the more specific **\"relator-genesis\"** and **\"relator-tombstone\"**) instead of **\"system-from\"** and **\"system-to\"** could work well for your approach, especially since these terms can evoke the **lifecycle** of a relator in a more **semantic** and **contextualized** way.\n\n### Pros of \"Genesis\" and \"Tombstone\":\n1. **More Intuitive Meaning**: \n   - **\"Genesis\"** naturally suggests the **beginning** or **creation** of something, making it a clear, human-readable way to indicate when a relator was first created or became valid in the system.\n   - **\"Tombstone\"** effectively conveys the **end** or **termination** of something, hinting that the relator has been \"retired\" or invalidated without deleting the record. The term \"tombstone\" is also commonly used in databases and versioning systems to represent records that are no longer active but still kept for historical reference.\n\n2. **Relational Context**:\n   - Using **\"relator-genesis\"** and **\"relator-tombstone\"** adds specificity, clearly indicating that these fields pertain to the **lifecycle of relators**. This helps maintain clarity in a complex model and avoids any potential confusion about whether these properties apply to the entire entity or just to the relationship.\n   \n3. **Aligns with Bitemporality**:\n   - These terms can still fit into your **bitemporal model**—they essentially function as **transaction-time markers** (system-time) while offering more understandable labels, which is particularly useful when working with ontologies or datasets meant for human interpretation.\n\n### Things to Consider:\n1. **Semantics and Interpretation**:\n   - While **\"genesis\"** and **\"tombstone\"** are intuitive, they could be interpreted as more symbolic than **\"system-from\"** and **\"system-to\"**. However, if your goal is to emphasize the lifecycle of **relators** rather than using a strictly technical nomenclature, these terms might be preferable.\n\n2. **Consistency in Queries**:\n   - Ensure that your terms are consistently used across the ontology. For example, if you use \"genesis\" and \"tombstone,\" they should be applied in contexts where relator lifecycles are being tracked, so that users querying the system know exactly what each term refers to. \n\n3. **Documentation and Usability**:\n   - Since **\"genesis\"** and **\"tombstone\"** are not typical RDF or temporal database terms, good **documentation** will be necessary to clarify the meaning of these properties for users unfamiliar with the terminology.\n\n### Example:\n```turtle\n:Relator1 a :Relator ;\n          :role1 :Person1 ;\n          :role2 :Person2 ;\n          :relationshipType :Friendship ;\n          :validFrom \"2023-01-01T00:00:00\" ;\n          :validTo \"2024-01-01T00:00:00\" ;\n          :relator-genesis \"2023-01-01T10:00:00\" ;\n          :relator-tombstone \"9999-12-31T23:59:59\" .  # Still valid\n```\n\n### Summary:\nUsing **\"genesis\"** and **\"tombstone\"** (or their more specific forms **\"relator-genesis\"** and **\"relator-tombstone\"**) could give your ontology a **clearer**, more **intuitive** way to express the lifecycle of relators, making it more approachable and human-readable while still aligning with the requirements for immutability and bitemporality. If the terms resonate with the overall semantics of your model, they seem like a good choice.\n\n## should class membership for a-box individuals, usually handled by \"rdf:Type\", be handled with a relator? Or both? I'm leaning towards just using a \"type-relator\" superclass, with specializations corresponding to the OntoUML class stereotypes.\n\nYour idea of using a **\"type-relator\" superclass** to handle **class membership** for A-box individuals, instead of the typical `rdf:type`, makes sense in the context of your **relator-based** approach and the specific semantics you're trying to capture. Here's why this could be a compelling approach, along with some considerations for deciding between relators and `rdf:type`:\n\n### Why Use a \"Type-Relator\" Superclass:\n\n1. **Consistency with Relator-Based Approach**:\n   - If your goal is to treat **relators** as central to the ontology and to capture relationships as **first-class entities**, using a **type-relator** to represent **class membership** maintains consistency. Instead of relying on the direct `rdf:type` relation, you're treating the membership as a **relationship** with its own context and attributes.\n   - This approach allows you to enrich the **class membership** with additional metadata (such as **time**, **creator**, or **source**), which would be difficult to capture using `rdf:type` alone.\n\n2. **Specialization with OntoUML Stereotypes**:\n   - The use of specializations for different **OntoUML stereotypes** (e.g., **kind**, **role**, **collective**) allows you to add **semantic richness** to your model, reflecting the different **types of class membership** or the nature of the relationship between the individual and the class. This is particularly valuable if you want to model **contextual or dynamic membership** (e.g., someone’s role changing over time).\n\n3. **Flexibility for Evolving Membership**:\n   - Using a relator for class membership can support **dynamic or conditional class membership** that might change over time or in different contexts. For example, an entity could be linked to a class via a **type-relator** for a certain period (temporal validity) or under certain conditions, without altering the original entity’s definition. This would allow you to represent the **temporality** of class membership.\n\n4. **Extending the Membership Concept**:\n   - A type-relator would allow you to handle more complex **multi-class membership** cases, where an individual may belong to multiple classes under different contexts or with varying roles. Each membership could have its own relator, allowing for a clear and structured representation of **multi-class** individuals.\n\n### Challenges with Replacing `rdf:type`:\n1. **Efficiency**:\n   - RDF's built-in `rdf:type` is optimized for **stating class membership** and is natively supported by RDF triple stores and reasoners. Moving to a relator-based model for class membership could increase **query complexity** and **storage overhead**, as every membership would involve additional triples to describe the relationship.\n   \n2. **Compatibility with Tools and Reasoners**:\n   - Many RDF tools, reasoners, and ontologies expect class membership to be represented via `rdf:type`. Moving to a custom relator-based approach could reduce compatibility with existing RDF tooling, requiring custom logic for inferencing, querying, and reasoning over class memberships.\n\n### Middle Ground (Both Approaches):\nAnother possible option is to **combine both approaches**. You could keep `rdf:type` for **basic class membership** where appropriate (especially when there's no need for additional metadata), and introduce the **type-relator** for cases where **metadata** or **temporal aspects** are necessary.\n\n### Example:\nUsing a **type-relator** to represent the class membership of an individual in a specific context:\n\n```turtle\n:Person1 a :Person .\n\n:TypeRelator1 a :TypeRelator ;\n              :subject :Person1 ;\n              :class :Employee ;\n              :relator-genesis \"2023-01-01T00:00:00\" ;\n              :relator-tombstone \"2023-12-31T23:59:59\" ;\n              :role :FullTimeRole .\n```\n\nThis expresses that **Person1** is an **Employee** via a relator relationship with temporal and contextual attributes.\n\n### Conclusion:\nYour inclination to use a **\"type-relator\" superclass** for handling class membership is a natural fit for your **relator-based ontology**, especially if you're focused on capturing richer metadata, temporal aspects, and contextual class membership. While this approach offers greater **flexibility and expressivity**, it might come at the cost of **efficiency** and **compatibility** with existing tools, so using a hybrid model that also supports `rdf:type` where possible could strike a good balance.\n\n## I'm thinking we should try to only use type-relator for data, but rdf:type can be used for metadata. That could keep relators about relators from spiraling out of control.\n\nYour approach of using **rdf:type** for **metadata** while using **type-relators** strictly for **data** makes a lot of sense, especially in terms of keeping the ontology manageable. This separation can help prevent the complexity of relators referencing other relators, which could lead to spiraling structures and potentially hard-to-manage RDF graphs.\n\n### Key Advantages of This Approach:\n\n1. **Simplifies Metadata Management**:\n   - Using `rdf:type` for **metadata** keeps things simple when assigning metadata properties like `relator-creator`, `relator-genesis`, and `relator-tombstone`. This allows for a straightforward representation without needing additional layers of relators just for metadata.\n   \n2. **Prevents Recursive Complexity**:\n   - Without needing to use relators to describe the **metadata of other relators**, you prevent the complexity that would come from having relators refer to other relators. This ensures that the structure of the ontology remains clear, and querying or reasoning over the data doesn’t become overly complicated.\n\n3. **Optimized for RDF Tools**:\n   - Since most RDF systems are optimized for handling `rdf:type` and metadata properties like **provenance** (e.g., `dc:creator`, `prov:wasGeneratedBy`), this hybrid approach ensures that your ontology remains compatible with existing **reasoners** and **tools** without adding additional query complexity.\n\n### Example Use Case:\n\nFor the **data layer**:\n\n```turtle\n:Person1 a :Person .\n\n:TypeRelator1 a :TypeRelator ;\n              :subject :Person1 ;\n              :class :Employee ;\n              :relator-genesis \"2023-01-01T00:00:00\" ;\n              :relator-tombstone \"9999-12-31T23:59:59\" .\n```\n\nFor **metadata**:\n\n```turtle\n:Relator1 a :TypeRelator ;\n          rdf:type :MetadataRelator ;\n          :relator-creator :UserX ;\n          :relator-genesis \"2023-01-01T00:00:00\" ;\n          :relator-tombstone \"2023-12-31T23:59:59\" .\n```\n\n### Benefits:\n- **Efficiency**: Keeping `rdf:type` for metadata ensures that reasoners and tools can handle the ontology efficiently, without requiring them to resolve complex, relator-based references.\n- **Scalability**: By limiting the use of **type-relators** to only data relationships, you reduce the risk of excessive nesting, which helps ensure the scalability of your system as it grows.\n- **Consistency**: The clear distinction between **data** and **metadata** ensures that you maintain consistency throughout the ontology, making it easier to manage and extend in the future.\n\nIn short, this approach strikes a good balance between **expressivity** and **simplicity**, keeping your ontology well-structured and scalable.\n\n## For your first example, we wouldn't include \":Person1 a :Person .\" because that is data.\n\nThanks for the clarification! You're right—`\":Person1 a :Person .\"` would fall under **data**, so it would be managed by a **type-relator** and not explicitly stated with `rdf:type` in this approach.\n\nHere's the corrected example:\n\n### For **data layer** (using **type-relator**):\n\n```turtle\n:TypeRelator1 a :TypeRelator ;\n              :subject :Person1 ;\n              :class :Employee ;\n              :relator-genesis \"2023-01-01T00:00:00\" ;\n              :relator-tombstone \"9999-12-31T23:59:59\" .\n```\n\n### For **metadata** (using **rdf:type**):\n\n```turtle\n:TypeRelator1 rdf:type :MetadataRelator ;\n              :relator-creator :UserX ;\n              :relator-genesis \"2023-01-01T00:00:00\" ;\n              :relator-tombstone \"2023-12-31T23:59:59\" .\n```\n\nIn this structure:\n- **Type-relator** handles data-level class membership (`:class :Employee`) without involving `rdf:type`.\n- **rdf:type** is reserved for describing the metadata about relators (such as their creation and tombstone information) without complicating the data itself.\n\nThis clear separation of concerns will help keep your model concise, scalable, and easy to query.\n\n## Remind me, is it true annotations can't have IRIs as the object?\n\nYes, it is true that **OWL annotation properties** (which are used for metadata or comments about classes, properties, and individuals) typically **cannot have IRIs (Internationalized Resource Identifiers) as objects** under certain conditions, depending on the version of OWL and the context. However, this restriction can vary slightly based on the specific tools and reasoning capabilities you are using.\n\n### OWL 2 and Annotations:\nIn **OWL 2**, annotations are more flexible, but by default, **annotation values** are expected to be **literals** (e.g., strings or datatypes). However, **IRIs can be used as annotation values** under some conditions, though reasoners may not always support inference over annotations where an IRI is the object.\n\nFor example:\n```turtle\n:Person a owl:Class ;\n        rdfs:label \"Person\" ;\n        rdfs:seeAlso <http://example.org/someDocument> .\n```\nIn this case, the `rdfs:seeAlso` annotation property can have an IRI as its object, and this is legal in OWL 2. The annotation is still not part of the core logical inference process (meaning it doesn’t affect entailments), but the IRI is valid as an annotation object.\n\n### Tool and Reasoner Limitations:\nSome reasoners might not fully support IRIs as objects in annotations or might treat them as non-logical metadata that doesn’t influence reasoning outcomes. Depending on the tools you use (like **Protege**, **HermiT**, or **Pellet**), support for this might vary in terms of how they handle or interpret such annotations.\n\n### Summary:\n- **IRIs** can be used as annotation objects in **OWL 2**.\n- The reasoning and inference processes typically ignore annotations, meaning that while IRIs are technically allowed, they won’t participate in logical entailments.\n- It's important to check if your specific RDF or OWL tools fully support this usage depending on the version of OWL and the reasoning you need.\n\nLet me know if you'd like more details on how different tools handle this or any follow-up questions!\n\n## I'm worried about \"A «Relator» must mediate at least two distinct individuals.\" from the OntoUML docs. Why couldn't a relator apply to unary relationships, i.e., no mediation, just ???\n\nThe requirement from **OntoUML** that \"A «Relator» must mediate at least two distinct individuals\" is intended to align with the **ontological commitment** that relators represent **connections** or **dependencies** between entities. This is a foundational idea in **ontological modeling** where relationships are typically modeled between multiple distinct entities to represent some form of interaction, shared activity, or association.\n\nHowever, in your **Kosmion ontology**, you may wish to represent **unary relationships**—situations where a relator applies to a single individual or even describes something **internal** to that entity. Here are a few reasons why this could make sense:\n\n### Why a Relator Could Apply to Unary Relationships:\n\n1. **Self-Referential States**:\n   - An entity may have internal states, conditions, or **attributes** that do not directly involve other entities. For example, an individual's **status**, such as being \"in a reflective state\" or \"meditating,\" could be seen as a relationship between the entity and itself or its own internal context.\n\n2. **Complexity of Real-World Scenarios**:\n   - In many real-world applications, an entity might have a context-specific **role** or status that doesn't require interaction with another entity. For instance, the **context** of being \"self-employed\" may not directly imply another individual, but it is still meaningful to model as a relational state.\n\n3. **Expressivity in Modeling**:\n   - The **expressivity** you are aiming for, especially in **OWL Full**, blurs the line between instances and classes (A-box and T-box), and allows you to be more flexible with how you model **roles** and **relations**. Allowing unary relationships gives you greater flexibility in capturing **complex** scenarios without forcing the introduction of additional entities unnecessarily.\n\n### Possible Implementation Approaches:\n\n1. **Relaxing the Mediation Constraint**:\n   - You can **relax** the mediation constraint for your **relator** class to allow for the possibility of **unary** relationships. This could mean allowing relators to have a minimum cardinality of **one** (instead of two) on their mediated roles.\n\n2. **Contexts as Unary Relators**:\n   - You have already introduced the concept of **context** in your ontology. It could be useful to allow **contexts** to also be represented as a type of **relator** that applies to a single entity, specifying the **applicable reality** without requiring mediation between two distinct entities.\n\n### Example Revision in Kosmion Ontology:\n\nTo support unary relationships, you could revise the **SHACL constraints** for the relator to allow **at least one** mediated role, rather than **at least two**. You could also add a property for **mediates** that allows for a **single entity** to be referenced.\n\nHere is how you might modify the SHACL constraints for the **relator** class:\n\n```turtle\nkosm:relator-shape a sh:NodeShape ;\n    sh:targetClass kosm:relator ;\n    sh:property [\n        sh:path kosm:relator-genesis ;\n        sh:minCount 1 ;\n        sh:maxCount 1 ;\n        sh:datatype xsd:dateTimeStamp\n    ] ;\n    sh:property [\n        sh:path kosm:relator-tombstone ;\n        sh:maxCount 1 ;\n        sh:datatype xsd:dateTimeStamp\n    ] ;\n    sh:property [\n        sh:path kosm:mediates ;\n        sh:minCount 1 ;\n        sh:nodeKind sh:IRI\n    ] .\n```\n\nIn this revision:\n- **kosm:mediates** represents the connection between the relator and the mediated entity. By setting `sh:minCount 1`, you allow the relator to mediate **at least one** entity, thereby making **unary relationships** possible.\n\n### Summary:\nThe OntoUML requirement that a **relator must mediate at least two distinct individuals** serves a specific philosophical and ontological view, but it is not necessarily suitable for all types of modeling. In your case, you could adopt a more **flexible approach** that supports **unary relationships**, especially for self-referential or contextual scenarios. Modifying the **SHACL constraints** as described could help realize this flexibility while retaining the ability to model **binary or higher-order relationships** where needed.\n\n\n## So , every relator will need at least one \"relata\". So we need a super-property to use for the relationships described by a relator. gUFO uses \"mediates\", but maybe something more generic would be appropriate.\n\n\nI've added a **super-property** called `kosm:relates` to serve as a more **generic** property for capturing entities involved in relationships described by a relator. The **SHACL constraint** has also been updated to enforce that every **relator** must use this property to relate at least one entity.\n\nIf you have any other thoughts on the naming or additional properties you'd like to introduce, just let me know!\n\n\n## Do you think we should add a class \"Type\" which is sameAs http://purl.org/nemo/gufo#Type, and its subclass RelationshipType, and RelationshipType's subclasses ComparativeRelationshipType and MaterialRelationshipType ?\n\nI've added the **Type** class, linking it to **gUFO's Type** (`gufo:Type`), and introduced **RelationshipType** as a subclass of **Type**, along with its subclasses **ComparativeRelationshipType** and **MaterialRelationshipType**.\n\nThis adds more flexibility to your ontology for defining different **types of relationships**, including their specific subtypes. Let me know if you need more refinements or additional classes!","n":0.016}}},{"i":4953,"$":{"0":{"v":"Images","n":1}}},{"i":4954,"$":{"0":{"v":"Vidoq Stops the Music","n":0.5},"1":{"v":"\n![](/assets/images/2024-10-18-16-07-22.png)\n\n- source: [[book.mysteries-of-police-and-crime]]\n- description: [[user.vidoq]] clearing a tavern popular with criminals\n\n## References\n\n- https://publicdomainreview.org/essay/eugene-francois-vidocq-and-the-birth-of-the-detective/","n":0.277}}},{"i":4955,"$":{"0":{"v":"Campfire Site, Yosemite","n":0.577},"1":{"v":"\n- https://www.christies.com/en/lot/lot-4387911\n- painter: [[user.albert-bierstadt]]\n\n![](/assets/images/2024-09-27-09-12-47.png)\n\n## Christie's Lot Essay\n\nFamed for his majestic views of the West, Albert Bierstadt first traveled there in 1859, in 1863 and again from 1871 to 1873. These trips produced nearly all of his most famous compositions. In the majority of these, the grandeur of the landscape and the subtle effects of light, especially luminous light, are a central concern. At times, he also explored more mysterious illumination in his depictions of moonlight and firelight to create a dramatic nocturnal scene, as evident in the present painting.\n\nHere Bierstadt paints an expansive view, the focus of which is his party's encampment, likely in the Hetch Hetchy Valley of California. Trees tower above the campsite, which is lit by the orange and yellow glow of a blazing fire, radiating light off the surrounding rocks and the tree limbs far above. The brilliant light of the moon, partially obscured by clouds, transforms the stream into a silvery ribbon. Men gather around the fire and nearby, others gather around the artist, seated at an easel, painting the moonlit landscape before him. Next to Bierstadt stands a woman in a jacket and skirt, almost certainly his wife, Rosalie Osborne Ludlow, who accompanied the artist on his month-long 1873 trip to the Yosemite Valley, thereby providing a likely date for the creation of this painting.\n\nCampfire Site, Yosemite, relates to an earlier, smaller composition, The Trapper's Camp of 1861 (Yale University Art Gallery, New Haven, Connecticut), which depicts two men and a broadly similar conception of moonlight and firelight in the Rocky Mountain wilderness. Bierstadt expands the theme in The Burning Ship (1871, Shelburne Museum, Shelburne, Vermont), in which flames engulf a whaler ship off the Island of Ascension, lit by the moon, on an otherwise calm evening. The same year, Bierstadt painted perhaps his most monumental campfire and moonlight landscape with his Mountainous Landscape by Moonlight (The Corcoran Gallery of Art, Washington, D.C.), in which a small group of men cluster near a fire and in the distance, a mountain peak looms above the scene.\n\nIn its details, Campfire Site, Yosemite differs from these works in its more personal subject, recording the artist and his wife in rough country. It also provides a vivid image of the now vanished Hetch Hetchy Valley, which was submerged in 1923 with the construction of the O'Shaughnessy Dam. In this work, Bierstadt strives to capture a personal and particular image of Yosemite, possibly his most famous Western subject. In the painting, he bridges the majestic and the personal--creating a unique work that draws upon the iconic images of his celebrated Western landscapes, transformed into a remembrance likely painted for his own pleasure and the enjoyment of his family and friends. Summarizing Bierstadt's public achievement, the art historian, Nancy Anderson writes, \"In paintings that became visual sanctuaries, (much the way national parks became literal sanctuaries), Bierstadt offered safe haven for the wilderness myth that lay at the heart of America's definition of itself.\" (Albert Bierstadt, Art & Enterprise, New York, 1990, p. 105) Here, that haven is also a personal one for the artist.","n":0.044}}},{"i":4956,"$":{"0":{"v":"Baluk Hana and Method of Fishing for the Red Mullet","n":0.316},"1":{"v":"\n- https://www.oldbookillustrations.com/illustrations/fish-house-constantinople/\n- artist: @thomas-allom\n\n![](/assets/images/2024-09-27-06-36-34.png)","n":0.5}}},{"i":4957,"$":{"0":{"v":"Bailie MacWheeble at Breakfast","n":0.5},"1":{"v":"\n- https://image.invaluable.com/housePhotos/kcmgalleries/28/754328/H5976-L345198785.jpg\n- painter: @james-lauder\n- subject: @bailie-macwheeble\n\n![](/assets/images/2024-10-08-10-10-13.png)\n\n## Description\n\n- Antique engraving on wove paper by master engraver Robert Charles Bell (British, 1806-1872)\n\n## References\n\n- https://www.invaluable.com/auction-lot/1800s-james-e-lauder-engraving-bailie-macwheeble--239-c-e13470ab9b\n","n":0.213}}},{"i":4958,"$":{"0":{"v":"Ideas","n":1}}},{"i":4959,"$":{"0":{"v":"Zookos Triangle","n":0.707},"1":{"v":"\n- [[p.hasRelatedTopic]] [[idea.credible-exit]]\n","n":0.577}}},{"i":4960,"$":{"0":{"v":"Write Only Syndrome","n":0.577},"1":{"v":"\n\ncapturing thoughts, but never reviewing, publishing, or using them\n","n":0.333}}},{"i":4961,"$":{"0":{"v":"Winners Curse","n":0.707},"1":{"v":"\n## Thoughts\n\n- \"The same dynamic applies when you’re optimizing for what to say. You have noisy estimates of how good each option will be, and it’s likely that the one that looks best to you will be an overestimate — perhaps because it interacts with some kind of blindspot you have.  If you’re optimizing under shallow honesty, you’re stuck with this problem. With deep honesty, you can hope that you may reveal useful information to people who don’t share your blindspots (even if you don’t know what that information is). And especially when you’re interacting with very competent people, you may not be so good at telling how they will receive any particular message.\"\n\n## References\n\n- https://www.lesswrong.com/posts/szn26nTwJDBkhn8ka/deep-honesty","n":0.093}}},{"i":4962,"$":{"0":{"v":"View Source Kickstarted the Web","n":0.447},"1":{"v":"\n## References\n\n- [[ar.the-rdf-net-challenge#view-source-lesson]]","n":0.577}}},{"i":4963,"$":{"0":{"v":"Tower of Babel Syndrome","n":0.5},"1":{"v":"\n\n- lack of standardization in terminology creates confusion, mis-communication, and errors\n- [[p.hasContext]] medical jargon\n\n## Resources\n\n\n","n":0.258}}},{"i":4964,"$":{"0":{"v":"The Three Uses for Information","n":0.447},"1":{"v":"\n\n- resources:  \n  - [[p.hasAuthor]] @nat-eliason\nThe Three Uses of Information\n\nOnce upon a time, there was a limited amount of new information per day you had access to. You could sit down in the morning and read the paper and you were done. Kind of wild to imagine.\n\nThen with the popularity of radio and television, we had additional variables. You could read the paper, listen to the news, or watch the news. But a dedicated person could probably still get a good chunk of the new information available to them for the day.\n\nNow we have an insane amount of information available to us. There are multiple 24-hour news channels, thousands of digital newspapers, blogs, twitter threads, YouTube videos.\n\nAnd that's just the news. You also have your interests, hobbies, and work information. And unless you're in some extremely small niche, there's probably a month or a year's worth of new information available to you every day.\n\nObviously you can't stay on top of everything. So how do we manage it?\n\nAside from trying to evaluate the quality of the source of information, it's also worth considering the motivation for consuming information.\n\nInformation can generally be lumped into three buckets:\n\n    Useful for day to day life or decision making\n    Useful for gossip or signaling\n    Entertainment\n\nAnd obviously it can satisfy multiple of these criteria at once. Crypto news is all three for me: some of it affects my day to day decision making, some of it helps me not sound like an idiot around my peers, and some of it is just fun to follow.\n\nWatching The Bachelor and reading the info surrounding it is mostly satisfying the Entertainment itch. But depending on your friend group it could be useful for signaling as well. It probably doesn't affect your day-to-day decision-making for most people, but there are certainly some for whom it does (e.g. Bachelor podcasters).\n\nEveryone thinks the information they consume is important. And we're often surprised whenever we find people who don't care about the information we care about because it's hard to imagine not treating that information as valuable. If you tell someone you don't care about Football or The Bachelor they're not likely to get particularly offended or upset. We know that information is mostly entertainment.\n\nThe problem is when we start to misconstrue information we seek for entertainment or gossip/signaling as important for decision making. Tell some people you don't care about the latest news on COVID, politics, or what Joe Rogan said this week, and they might lose their mind.\n\nLet's start with COVID. For anyone who doesn't work in a hospital, there's no utility to getting constant information on COVID deaths or infections. You can look up the case mortality rate for each new variant, assess whether it's something worth worrying about for yourself given the treatments and vaccines and when weighed against all the other ways you could get sick or die, make a decision, and move on with your life.\n\nUnless, of course, you're following COVID data for signaling or entertainment. There are certainly many people following it and posting about it just to signal. And some people just find it really interesting to follow. But pretending following it is important for everyone for day-to-day decision-making is absurd. That utility ended a year and a half ago.\n\nPolitics is another example where this runs rampant. As an ordinary citizen, you have very few political levers you can pull. In most cases, those levers are just how you vote in a given election.\n\nSo following Politics seems important for decision making, but it isn't. Preparing for an election can be an extremely fast process. I'm not particularly aligned with either major party in the US, so for elections, I just read the websites and policies of whoever is running. Then maybe watch through a debate or two to try to get a sense of their leadership capabilities, and find what I can of their political track record. You could do that in a couple of hours, and you'll have more than enough information to make an educated voting decision.\n\nStaying up to date on politics is predominantly about entertainment and gossip/signaling for the vast majority of people. If you're a reporter or work in politics then obviously you need day-to-day information. But as a normal citizen? It's mostly useless. You shouldn't feel pressured by people who love the entertainment to follow it closely any more than you should feel pressured to follow football or The Bachelor.\n\nIt would be one thing if there were finite information to consume, or if you got to vote on democratic policies weekly. But there isn't, and you don't. You have infinite information at your disposal, extremely limited time, and very few uses for most information. You have to guard your time at all costs and only let in the information that's useful or entertaining to you.\n\nSignaling or gossiping in particular is where you can easily end up wasting a ton of time by ingesting useless information. Many people aren't following politics or COVID to affect their day-to-day decision-making, they're following it so they can talk about it with their peers or post virtuous memes on Instagram.\n\nThis is why Chamath got such a ridiculous blowback for his statement about the Uyghurs on the All In Podcast. If you're curious about it, just download the actual episode and listen to what he says and judge it for yourself.\n\nTo paraphrase what he said (again, go listen and judge for yourself), he said he didn't \"care\" about what was going on with the Uyghurs because it didn't affect his day-to-day decision-making. He has a limited amount of time and energy, and that's just not a problem he's focused on. Which is fine! You can't focus on everything.\n\nMost people in the US aren't talking about the Uyghurs because they're going to do anything about it. I doubt they purged their life of products manufactured in China. They're talking about it to signal \"I'm a good person who cares about bad things going on in the world.\" Which is fine, but to Chamath's point, what's the point of staying up to date and constantly talking about something if you aren't doing anything about it or at least enjoying following it.\n\nChamath understands something most people don't: your time and attention are extremely scarce, and if you aren't ruthless about what you spend them on, they will be wasted. You can't try to care about everything everyone cares about because then you'll spend all day absorbing and regurgitating the trivia of the day. You have to triage. And that often means not caring about or not being informed about things other people think are really important.\n\nThen there's the balance of utility and entertainment. I generally think we should lean as heavily towards entertainment as possible, assuming you have the means to. Life is short, and it's easy to get sucked into analysis paralysis when you start downloading information for day-to-day decision-making. The 40-70 rule is a good guideline. If you try to get 100% of the information you might want for every decision you'll go crazy and waste time that could have been spent on entertainment or making more decisions.\n\nOnce you turn off the news, ruthlessly prune your social feeds, and stop feeling guilted into staying up to date on the stuff everyone else cares about, you'll have huge amounts of time for the things you care about.\n\nAnd as long as you're fine asking people to explain stuff, you won't really miss out on not knowing what's going on in Politics, football, or The Bachelor.\n\nHave a great week,\nNat\n\n","n":0.028}}},{"i":4965,"$":{"0":{"v":"The Semantic Web Is Dead","n":0.447},"1":{"v":"\n\n## References\n\n- https://news.ycombinator.com/item?id=20016256\n- [[ar.terminusdb.the-semantic-web-is-dead]]\n- [[ar.topquadrant.why-i-dont-use-owl-anymore]]\n- https://news.ycombinator.com/item?id=31890041\n- [[ar.json-ld-and-why-i-hate-the-semantic-web]]","n":0.378}}},{"i":4966,"$":{"0":{"v":"The Power of Constraints","n":0.5}}},{"i":4967,"$":{"0":{"v":"The Lottery Ticket Effect","n":0.5},"1":{"v":"\n- summary: People support what they help create.","n":0.354}}},{"i":4968,"$":{"0":{"v":"The Garden and the Stream","n":0.447}}},{"i":4969,"$":{"0":{"v":"The Five Commandments of Storytelling","n":0.447},"1":{"v":"\n![[prdct.story-grid#^zyftpukzkst0:#^yrwhvvxp4y9r]]","n":1}}},{"i":4970,"$":{"0":{"v":"The Daily Minimum","n":0.577},"1":{"v":"\n\n\n## References \n\n- https://threetimeswiser.substack.com/p/issue-293-daily-minimum-ambidextrous","n":0.5}}},{"i":4971,"$":{"0":{"v":"Text as Graph","n":0.577},"1":{"v":"\n- [[p.attributedTo]] https://pure.knaw.nl/ws/portalfiles/portal/9465025/HuC_lezing_Text_as_Graph.pdf\n  - ![](/assets/images/2023-01-28-20-04-24.png)","n":0.447}}},{"i":4972,"$":{"0":{"v":"Suspicious Convergence","n":0.707},"1":{"v":"\n## [[p.hadDefinition]]\n\n- https://forum.effectivealtruism.org/posts/omoZDu8ScNbot6kXS/beware-surprising-and-suspicious-convergence","n":0.577}}},{"i":4973,"$":{"0":{"v":"Stylized Fact","n":0.707},"1":{"v":"\n- [[p.hadDefinition]] \"stylized fact is a simplified statement of a larger finding that has been theoretically and empirically substantiated elsewhere.\"\n  - [[p.hasSource]] [[email.how-renaissance-rationalization-and-oceanic-navigation-lock-into-commodotization-takeoff]]","n":0.209}}},{"i":4974,"$":{"0":{"v":"Sententia","n":1},"1":{"v":"\n- aphorisms, proverbs, adages, metaphors, truisms, maxims, et al","n":0.333}}},{"i":4975,"$":{"0":{"v":"Metcalfes Law the Value of a Network","n":0.378}}},{"i":4976,"$":{"0":{"v":"Goodharts Law, When a Measure Becomes a Target","n":0.354},"1":{"v":"\n- paraphrase: \"Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes.\"","n":0.229}}},{"i":4977,"$":{"0":{"v":"Cuninghams Law the Best Way to Get the Right Answer","n":0.316},"1":{"v":"\n- [[p.hasSource]] https://meta.wikimedia.org/wiki/Cunningham%27s_Law","n":0.577}}},{"i":4978,"$":{"0":{"v":"Semiotic Blob","n":0.707},"1":{"v":"\n\nwhen the referents or meanings of a symbol become indistinct \n\n## eg\n\n- [[prdct.markdown]] refers to a language and a class of languages #polyseme\n  - specifically, a lightweight markup language and a set of supersets of that language   ^nuNHaMNu55mc\n\n","n":0.162}}},{"i":4979,"$":{"0":{"v":"Rule of Fun","n":0.577},"1":{"v":"\n\n## Resources\n\n- https://tvtropes.org/pmwiki/pmwiki.php/Main/RuleOfFun\n  - [[p.hasHighlight]]\n    - 'real' swordfights were typically very brutal and incredibly brief, which is the antithesis of 'fun' in an RPG; thus, we have Hit Points.\n      - [[p.provokedThoughts]] \n        - [[game.odyssey]] captures the brutality nicely\n        - maybe a little more strategy that just fight or run\n- [[t.storytelling.fiction.interactive]] might not be fun because reading isn't fun; not to mention the open-world tension","n":0.125}}},{"i":4980,"$":{"0":{"v":"Relentlessly Resourceful","n":0.707},"1":{"v":"\n- url: http://www.paulgraham.com/relres.html\n- author: @paul-graham\n\n## Highlights\n\n- \"To be hapless is to be battered by circumstances—to let the world have its way with you, instead of having your way with the world.\"\n- \"This isn't the recipe for success in writing or painting, for example. In that kind of work the recipe is more to be actively curious. Resourceful implies the obstacles are external, which they generally are in startups. But in writing and painting they're mostly internal; the obstacle is your own obtuseness.\"\n  - not sure I agree. ","n":0.107}}},{"i":4981,"$":{"0":{"v":"Pareto Effort","n":0.707},"1":{"v":"\n- [[p.mentionedOn]] https://medium.com/pragmatic-programmers/patterns-enhance-craft-thoughts-on-patterns-4fa40ed7c9e7\n","n":0.577}}},{"i":4982,"$":{"0":{"v":"No Such Thing as Luck","n":0.447},"1":{"v":"\n- https://www.wired.com/story/secret-to-being-lucky/\n  - \"It may even be the secular answer to grace, but it comes with laughs rather than piety.\"","n":0.224}}},{"i":4983,"$":{"0":{"v":"Night Time is the Write Time","n":0.408},"1":{"v":"\n## Quotes\n\n@franz-kafka: “But sleep? On a night like this? What an idea! Just think how many thoughts a blanket smothers while one lies alone in bed, and how many unhappy dreams it keeps warm.”\n\n## Famous Nocturnal Writers\n\n@chatgpt.4o\n\nSeveral well-known writers have famously worked at night, often finding the quiet and isolation conducive to creativity. Here are a few examples:\n\n1. **Franz Kafka**:\n   - Kafka is perhaps the most famous example of a writer who worked at night. He had a demanding day job as an insurance clerk, so he wrote late into the night, often sacrificing sleep. His nocturnal writing contributed to the surreal, dream-like quality of his works.\n\n2. **Sylvia Plath**:\n   - Plath wrote much of her poetry during late-night hours, especially during periods of emotional intensity. The quiet and solitude of night allowed her to focus on her work.\n\n3. **Marcel Proust**:\n   - Proust was known for his unusual writing habits, which included working at night. His chronic asthma and sensitive disposition led him to create in a darkened, quiet room, often working late into the night to craft his monumental work, **In Search of Lost Time**.\n\n4. **F. Scott Fitzgerald**:\n   - Fitzgerald, known for his wild social life, also worked at night. His late-night writing sessions were often fueled by alcohol, and much of **The Great Gatsby** was written during these hours.\n\n5. **T.S. Eliot**:\n   - Although Eliot had a demanding job during the day, he often composed his poetry at night. The complex, modernist poetry he is known for, such as **The Waste Land**, was partly shaped by his late-night reflections.\n\n6. **George Sand**:\n   - The French writer George Sand (pen name of Amantine Lucile Aurore Dupin) also worked at night. She found the night to be the most peaceful time for uninterrupted creative work, particularly in her country home.\n\nThese authors, and many others, found inspiration and productivity in the late hours, often creating their most famous works in the quiet of the night.","n":0.056}}},{"i":4984,"$":{"0":{"v":"Micro Ontologies","n":0.707},"1":{"v":"\n- the goal of ontology modularity may only be accomplishable if we break concepts/definitions/axioms down into atomss","n":0.243}}},{"i":4985,"$":{"0":{"v":"Mental Lab","n":0.707},"1":{"v":"\n- attributed-to: @david-goggins\n\n## Summary\n\n- Somewhere you can be alone with your thoughts and wrestle with the substance of what and who you want to be in your one short life on earth.\n- If it feels right, create an alter ego to access some of that dark matter in your own mind\n- ","n":0.14}}},{"i":4986,"$":{"0":{"v":"MAYA","n":1},"1":{"v":"\n\n- [[p.attributedTo]] @raymond-loewy\n- resources: \n  - https://www.interaction-design.org/literature/article/design-for-the-future-but-balance-it-with-your-users-present","n":0.378}}},{"i":4987,"$":{"0":{"v":"Man Who Live in Glass House Should Change in Basement","n":0.316},"1":{"v":"\n- apt\n- [[p.attributedTo]] [[user.taras-wenc]]\n\n\n","n":0.5}}},{"i":4988,"$":{"0":{"v":"Longtermism","n":1},"1":{"v":"\n- [[p.instanceOf]] [[BeliefSystem]]\n- [[hasTenet]] nothing matters more, ethically speaking, than fulfilling our potential as a species of ‘Earth-originating intelligent life’.\n  - [[p.attributedTo]] @phil-torres\n","n":0.209}}},{"i":4989,"$":{"0":{"v":"Little Living Is Enough","n":0.5},"1":{"v":"\n- \"Show me a man who drives his truck with integrity and skill and care and you’ve shown me a bigger man than anyone with their name on the door, or that shows up on the first Google search.\"  ^cwge8fz04hc4","n":0.158}}},{"i":4990,"$":{"0":{"v":"Instances Are Sometimes Classes","n":0.5},"1":{"v":"\n## t.2024.03.16.17\n\n- is the solution to all my worrying about [[idea.instances-are-sometimes-classes]] literally just everything non-specific is a class? like topics are classes? things that are just instances:\n  - documents\n  - concrete individuals (but not characters/characterizations)\n  - locations. (but what about [[locale.North-America.coastal]]?)\n    - it depends: \n      - \"coastal north america\" taken as a whole is an instance\n      - \"coastal north-american locations\" is a class\n  - events (but not event types)\n\n## t.2024.08.20.12\n\n- put another way, non-leaf nodes in a hierarchy are classes\n  - not all trees are hierarchies, see [[prdct.abc-ontology]]\n- topics are specific, and not necessarily classes (unless the topic is a class, say, \"north american locations\"). just because you have sub-topics or sub-whatever (i.e., hierarchy) doesn't make something a class. locations aren't classes, location-types or even location-collections are. \n  - for my dendron notes, I've overloaded topics, such that they are both classes and instances. \n\n## Related\n\n- [[t.library-science.work_expression_manifestation_item]]","n":0.082}}},{"i":4991,"$":{"0":{"v":"Golden Algorithm","n":0.707},"1":{"v":"\n- the idea that any problem you’re experiencing has a corresponding emotion you’re trying to avoid. By evading that feeling, you’re actually more likely to amplify it.","n":0.192}}},{"i":4992,"$":{"0":{"v":"First Times Are Interesting","n":0.5}}},{"i":4993,"$":{"0":{"v":"Electric Magic Store","n":0.577},"1":{"v":"\n- related: [[music.the-magic-store]] [[t.drama.interactive]] [[t.storytelling.fiction.interactive]] [[t.storytelling.interactive]]\n- aka: The Digital Dream Factory, digital adventure production, roleplay experience curation\n\n\n## References\n\n- https://scriptmag.com/history/meet-the-reader-the-dream-factory\n","n":0.229}}},{"i":4994,"$":{"0":{"v":"Edges Are Also Nodes","n":0.5},"1":{"v":"\n\n- related: [[idea.beware-the-relationship-as-graph-edge]]\n- [\"edges are also nodes\"](https://www.google.com/search?client=firefox-b-1-d&q=%22edges+are+also+nodes%22)\n  - [[prdct.ktgk]]\n  - [[t.cs.semantic-web.relationship-to-entity-conversion]]\n  ","n":0.302}}},{"i":4995,"$":{"0":{"v":"Dont Repeat Yourself","n":0.577}}},{"i":4996,"$":{"0":{"v":"Defining Done Is Hard","n":0.5},"1":{"v":"\n\n\n- one engineer's \"done\" is another engineer's \"a lifetime of monitoring\"\n","n":0.302}}},{"i":4997,"$":{"0":{"v":"Cursed Problem","n":0.707},"1":{"v":"\n\n\n- [[p.hadDefinition]] an unsolvable game design problem, rooted in a conflict between core player promises\n  - [[p.attributedTo]] @Alex-Jaffe\n    - [[p.attributedBy]] @Andrew-Zuo\n      - [[p.hasURL]] https://medium.com/codex/stop-trying-to-make-flutter-web-happen-its-not-going-to-happen-a29f805df504\n- [[p.hadDefinition]] an unsolvable problem, rooted in a conflict between promises made to the user and/or developer\n  - [[p.hasAuthor]] @Andrew-Zuo\n","n":0.152}}},{"i":4998,"$":{"0":{"v":"Credible Exit","n":0.707},"1":{"v":"\n- [[p.hasExample]]\n  - DNS: lets you move to a new hosting provider\n    - [[p.hasSource]] https://subconscious.substack.com/p/credible-exit\n  - Email: identifiers work across providers\n  - wordpress: move content with XML file\n  - [[Mirror|prdct.mirror]]\n- [[p.hasDimensions]]\n  - export\n  - sync\n  - useful format\n  - local files\n  - \"Multiple apps can share the same data over a permissionless API\"\n  - app is open p.hasSource","n":0.131}}},{"i":4999,"$":{"0":{"v":"Choose Your Table Wisely","n":0.5},"1":{"v":"\n- from [[email.choose-your-table-wisely]], I am at the wrong table. Was even considering a cybersecurity MS from Berkley eLearning. Gak! Horrible idea.\n- from [[email.dont-put-the-tool-before-the-craft]], my whole life, I've been making that mistake! Partly because I didn't choose a craft. Other than IT. Which is a fine craft. But...\n- ","n":0.146}}},{"i":5000,"$":{"0":{"v":"Choose Boring Technology","n":0.577},"1":{"v":"\n- url: https://boringtechnology.club/","n":0.577}}},{"i":5001,"$":{"0":{"v":"Change Is Acheivable","n":0.577},"1":{"v":"\n\r\nchange can be hard, but even hard changes are acheivable\r\n","n":0.316}}},{"i":5002,"$":{"0":{"v":"Beware the Relationship as Graph Edge","n":0.408},"1":{"v":"\n\n- seeAlso: [[t.cs.semantic-web.relator]]\n- [[p.hasCon]] additional complexity/indirection/traversal\n  - boo hoo\n- [[p.hasTopic]] [[t.cs.graph.]]\n- rdf-style semantic graphs (with triple, quads, and maybe-mores) share the unfortunate but understandable mistake of representing the verb or property type as an arc\n- resources:  [\"I think the only mistake you could make is to use the term \"arc\" for undirected graph.\"](https://math.stackexchange.com/q/1441525)\n- some relationships are undirected; deal with it\n  - t.2024.08.20.09 specifically, symmetric relationships;","n":0.124}}},{"i":5003,"$":{"0":{"v":"Beware Archivism","n":0.707},"1":{"v":"\n\n- resist the temptation to fit everything neatly into a taxonomy, with full-specified tags and citations\n- reference notes only need to jog your memory\n","n":0.204}}},{"i":5004,"$":{"0":{"v":"Be Yourself, but Know Your Audience","n":0.408},"1":{"v":"\n\n\n- authenticity:\n  - helps some people be happy with themselves\n  - helps some audiences be happy with you\n- enthusiasm:\n  - can be authentic\n  - can be mustered\n  - can be faked (with difficulty)\n","n":0.174}}},{"i":5005,"$":{"0":{"v":"Batman Effect","n":0.707},"1":{"v":"\n- \"children who were asked to imagine themselves as superheroes or other characters exhibited significantly better self-control, focus, and perseverance\"\n- When we embody the traits of a fearless, confident alter ego, we can tap into a reservoir of courage and determination that we might not feel our regular selves possess.\"\n\n## Mantra\n\nI am confident. I am fearless. I am unstoppable. ^ilmbh27jqeuz\n\n## References\n\nhttps://threetimeswiser.substack.com/p/issue-419-batman-effect-zone-of-genius","n":0.128}}},{"i":5006,"$":{"0":{"v":"Architecture Astronaut","n":0.707},"1":{"v":"\n- \"When you go too far up, abstraction-wise, you run out of oxygen. Sometimes, smart thinkers just don't know when to stop, and they create these absurd, all-encompassing, high-level pictures of the universe that are all good and fine, but don't actually mean anything at all.\" - @joel-spolsky\n\n## References\n\n- https://en.wikipedia.org/wiki/Architecture_astronaut","n":0.141}}},{"i":5007,"$":{"0":{"v":"Games","n":1}}},{"i":5008,"$":{"0":{"v":"Dwarf Fortress","n":0.707}}},{"i":5009,"$":{"0":{"v":"Premium","n":1},"1":{"v":"\n- a GUI! and tutorials","n":0.447}}},{"i":5010,"$":{"0":{"v":"Bioshock","n":1}}},{"i":5011,"$":{"0":{"v":"Bioshock Infinite","n":0.707}}},{"i":5012,"$":{"0":{"v":"Wolves in the Walls","n":0.5},"1":{"v":"\n- platforms: oculus\n- url: https://www.fable-studio.com/wolves-in-the-walls\n- [!] review Wolves in the Walls","n":0.302}}},{"i":5013,"$":{"0":{"v":"Wildermyth","n":1},"1":{"v":"\n## [[c.review]]\n\n- \"It's a sort-of-roguelite sort-of-HOMM-like sort-of-fantasy-XCOM\nWhere characters you play in one campaign ascend to be background/lore characters for following campaigns\nThe story bits are told as cartoon panels where all the characters look exactly like you designed them, including all equipment (and wounds, mutations, ...) they've picked up\nCampaigns have a mix of story quests and side quests randomly picked from a pool of quests written by different authors/quest designers, and the quality of these... varies\nbut it's all very charming and fun.\"\n  - @hendrik-mans in [Javelin/Misc/Gaming](https://discord.com/channels/844566064281026600/847207485965598740/1059014265866035260)","n":0.108}}},{"i":5014,"$":{"0":{"v":"Wildcard","n":1}}},{"i":5015,"$":{"0":{"v":"What Remains of Edith Finch","n":0.447},"1":{"v":"\n## Structure\n\n![[ar.atlantic.video-games-are-better-without-stories#^uintr5ran0xw]]\n\n\n## Review\n\n![[ar.atlantic.video-games-are-better-without-stories#^1dy2vg3q80ks]]\n![[ar.atlantic.video-games-are-better-without-stories#^jhjxrtw7u803]]","n":0.577}}},{"i":5016,"$":{"0":{"v":"Voxelands","n":1},"1":{"v":"\n- dead\n- [[c.game.sandbox]]\n- repo: https://gitlab.com/voxelands/voxelands\n- based_on: [[prdct.minetest]]","n":0.378}}},{"i":5017,"$":{"0":{"v":"Until Dawn","n":0.707}}},{"i":5018,"$":{"0":{"v":"Tyuns","n":1},"1":{"v":"\n## Features\n\n- Conlanging & Culturebuilding, as they are the main focuses of the game.\n\n- Mystery, discovery, and player experience, as they are the base principles we considered when designing it.\n\n- Sick ass maps, as the geography of this planet is what we put the most heart into, with a stylized map and detailed biogeography.","n":0.136}}},{"i":5019,"$":{"0":{"v":"Transylvania","n":1},"1":{"v":"\n- url: https://en.wikipedia.org/wiki/Transylvania_(video_game)","n":0.577}}},{"i":5020,"$":{"0":{"v":"Tosios","n":1},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/halftheopposite/tosios\n- [[p.hasArchitecture]] \n- [[p.builtOn]] [[prdct.colyseus]]\n- [[p.exemplified]] [[t.cs.sd.monorepo]]\n  - \"(with the help of Yarn workspaces). It contains the following packages:\n\n    client - The frontend application using PIXI.js and Colyseus.js.\n    server - The authoritarive server running on NodeJS, Express and Colyseus.\n    common - A collection of constants and methods shared amongst client and server.\"\n\n","n":0.136}}},{"i":5021,"$":{"0":{"v":"The Sims","n":0.707}}},{"i":5022,"$":{"0":{"v":"The Promenade","n":0.707},"1":{"v":"\n- url: https://www.thepromenade.ai\n\n![](/assets/images/2024-03-21-20-07-49.png)\n![](/assets/images/2024-03-21-20-09-24.png)\n\n## Descipriotn\n\n- modes:\n  - exploration\n  - combat\n- events:\n  - action\n    - attack\n    - item\n    - search\n    - explore\n    - move\n    - rest\n  - consequence\n  - choice\n  - dialog\n  - \n\n## Thoughts\n\n- somewhat unsatisfying so far after ~20-30min of play. \n  - abstract map contributes to lack of overientation\n  - there's a single world-seed per chapter, but otherwise no player interaction/tension\n  - combat is abstracted away and not very engaging\n  - could benefit from more player agency/choices that have meaningful consequences\n  - navigation is confusing\n  - why would i care about other players posts?\n  - not clear about search vs explore","n":0.099}}},{"i":5023,"$":{"0":{"v":"The King of Chicago","n":0.5},"1":{"v":"\n## References\n- [[ar.story-vs-game-the-battle-of-interactive-fiction]] ","n":0.577}}},{"i":5024,"$":{"0":{"v":"The Intercept","n":0.707},"1":{"v":"\n- url: https://github.com/inkle/the-intercept\n- written_in: c#","n":0.447}}},{"i":5025,"$":{"0":{"v":"The House of Highfield Lane","n":0.447},"1":{"v":"\n- [[p.hasURL]] http://textadventures.co.uk/games/view/idu7hlna7k2h24ib4ymmrg/the-house-on-highfield-lane0\n- [[p.hasRepository]] https://github.com/ThePix/QuestJS/tree/master/game-house","n":0.447}}},{"i":5026,"$":{"0":{"v":"The Battle for Wesnoth","n":0.5},"1":{"v":"\n- [[c.game.sandbox]]\n- url: https://www.wesnoth.org/\n- repo: https://github.com/wesnoth/wesnoth\n- uses: lua\n- written_in: C++\n\n## Description\n\n### WML\n\nWesnoth Markup Language (WML) is used to code almost everything in Wesnoth, including scenarios, units, savefiles, and the user interface layout. WML files are simple, human-readable text files, usually with the .cfg extension, with similarities to INI files and XML. A major feature in WML are macros, which are alike those found in the C language and similarily are handled by a preprocessor.\n\n## References\n\n- https://wiki.wesnoth.org/ReferenceWML","n":0.115}}},{"i":5027,"$":{"0":{"v":"Tetris","n":1}}},{"i":5028,"$":{"0":{"v":"Storm Kings Thunder","n":0.577},"1":{"v":"\n- superwork: [[game-system.dungeons-and-dragons.forgotten-realms]]\n\n## Expressions: \n\n- https://marketplace.roll20.net/browse/module/42/storm-kings-thunder\n- [[book.storm-kings-thunder]]\n\n## Reviews\n\n- \"needlessly frustrating and complicated campaign\": https://thealexandrian.net/wordpress/47378/roleplaying-games/review-storm-kings-thunder\n\n## References\n\n- https://forgottenrealms.fandom.com/wiki/Storm_King%27s_Thunder","n":0.25}}},{"i":5029,"$":{"0":{"v":"STEPN","n":1},"1":{"v":"\n## [[p.hasRelatedEmail]]\n\n- [[email.will-stepn-bring-crypto-to-the-masses]]","n":0.577}}},{"i":5030,"$":{"0":{"v":"Starship Titanic","n":0.707},"1":{"v":"\n- http://shop.starshiptitanic.com/game/index.html\n- creators: @douglas-adams\n\n\n## Features\n\n- \"The robots are brought to life by a proprietary interactive language engine called SpookiTalk\"\n\n## References\n\n- https://www.popsci.com/technology/douglas-adams-video-game-starship-titanic/?utm_source=pocket-newtab-en-us\n- https://www.alisonhumphrey.com/2023/03/starship-titanic-25th-anniversary.html\n- https://store.steampowered.com/app/467290/Starship_Titanic/","n":0.209}}},{"i":5031,"$":{"0":{"v":"Spacestation14","n":1},"1":{"v":"\n- url: https://spacestation14.io\n- uses: [[prdct.arch]]","n":0.447}}},{"i":5032,"$":{"0":{"v":"Space Traders","n":0.707},"1":{"v":"\n- https://spacetraders.io/\n- [[c.game.programmable]] [[c.game.headless]]\n- docs: https://docs.spacetraders.io/\n![[game.screeps#^zwsvp7ab3c0e]]","n":0.408}}},{"i":5033,"$":{"0":{"v":"Space Truckers","n":0.707},"1":{"v":"\nrepo: https://github.com/jelster/space-truckers/\n\n- [[p.hasLearningResource]] [[book.going-the-distance-with-babylonjs]]","n":0.5}}},{"i":5034,"$":{"0":{"v":"Solid Chess","n":0.707},"1":{"v":"\n- https://pheyvaer.github.io/solid-chess/\n- \n\n## References\n\n- https://pieterheyvaert.com/blog/2019/02/10/solid-world-summary","n":0.447}}},{"i":5035,"$":{"0":{"v":"Skald","n":1},"1":{"v":"\n- \"Skald drops you right into a familiar but well realised world without beating you over the head with (ugh) “lore” or culture you can loosely infer by context.\"\n- \"A straightforward d20 system dictates combat, with rolls to hit vs dodge, damage rolls vs \"soak\", and a big emphasis on positioning thanks to flanking bonuses, limited combat space, and a lack of ability to pass through friendlies. A D&D-ish action economy makes extra attack feats very powerful, but so too are roguey passive skills like free disengage (freely stepping out of melee range, which otherwise ends a turn) and swapping places.\"\n- \"Skald is out of the Ultima lineage -- a bespoke non-random hand-crafted RPG campaign and world for the player to poke around in, with re-playing only necessary if things go very badly or the player wants to try out different possibilities and character types. This family tree of games goes to Baldur's Gate 3 and the like, though again Skald is a throwback to an older branch. (As was Moonring, another recent Ultima-like)\"\n\n## Cons\n\n- You can take all this description as enthusiastic. Please do, while I frown through a list of bugs and annoyances: Information screens sometimes drop to about three frames per second (as did one battle). Nuisances like being unable to split or sell partial stacks are part of why I hoarded so much food (and having two identical magic items is worthless as they don't stack and won't separate), characters occasionally become uselessly stuck targeting one enemy but refuse to attack them. There's a tendency for clicks to sometimes just not register, and no order confirmation system so misclicks can be punishing (and it's sometimes unclear where a spell is targeted). You can't leave the levelling screen to check a character's stats, and I had to bin an entire mage because a bug skipped past his spell selection menu. Fixable, sure, especially the handful of trivial oversights that are symptomatic of a tiny development team, and perhaps even by release. But still a pest.\n- \n\n## References\n\n- https://www.rockpapershotgun.com/skald-against-the-black-priory-review","n":0.054}}},{"i":5036,"$":{"0":{"v":"Silent Hill Ascenscion","n":0.577},"1":{"v":"\n- interactive tv show, except social engagement story","n":0.354}}},{"i":5037,"$":{"0":{"v":"Sil Q","n":0.707},"1":{"v":"\n\n- [[p.hasRepository]] https://github.com/sil-quirk/sil-q\n- resources:  http://roguebasin.com/index.php/Sil  \n- [[p.hasGenre]] [[t.cs.game.roguelike]]\n","n":0.354}}},{"i":5038,"$":{"0":{"v":"Sentou Gakuen","n":0.707},"1":{"v":"\n- https://gakuen.org/\n\n\n## References\n\n- [[ar.dev-to.online-visual-novel-in-godot-case-study-on-sentou-gakuen]]","n":0.5}}},{"i":5039,"$":{"0":{"v":"Screeps","n":1},"1":{"v":"\n- repo: https://github.com/screeps/screeps\n- written_in: javascript\n- similar: [[prdct.robocode]] [[prdct.robocode.tank-royale]] [[game.screeps]] [[prdct.battlecode]] [[game.space_traders]] ^zwsvp7ab3c0e\n\n## Architecture\n\n- ![](/assets/images/2024-04-04-21-40-04.png)\n-   [`launcher`](https://github.com/screeps/launcher) launches the rest of the processes, and it includes the server control GUI.\n    \n-   [`storage`](https://github.com/screeps/storage) contains a LokiJS-based database, a key-value storage, and a Pub/Sub mechanism. The rest of the processes connect to `storage` to exchange data.\n    \n-   [`backend`](https://github.com/screeps/backend-local) contains an HTTP server accessed by clients and a CLI server for administration.\n    \n-   [`engine`](https://github.com/screeps/engine) is the game core. It executes game scripts and interacts with game world objects.\n    \n-   [`driver`](https://github.com/screeps/driver) is a link between the environment-independent `engine` (that is shared for the official server, standalone server, and in-browser simulation) and the immediate environment that hosts the game engine. You can replace this module with your own one, if you wish to use another method of storing and handling data.\n    \n-   [`common`](https://github.com/screeps/common) is a shared code base with useful utilities.\n\n\n- repo: https://github.com/screeps/screeps\n- ","n":0.083}}},{"i":5040,"$":{"0":{"v":"Sauerbraten","n":1},"1":{"v":"\n- http://sauerbraten.org/\n- [[c.game.sandbox]]\n- repo: https://sourceforge.net/projects/sauerbraten/files/","n":0.447}}},{"i":5041,"$":{"0":{"v":"Samurai Gunn 2","n":0.577}}},{"i":5042,"$":{"0":{"v":"Rust","n":1}}},{"i":5043,"$":{"0":{"v":"Roadwarden","n":1}}},{"i":5044,"$":{"0":{"v":"Rival Peak","n":0.707}}},{"i":5045,"$":{"0":{"v":"Putt Club","n":0.707},"1":{"v":"\nurl: https://puttclub.io/ \n\n- [[p.builtOn]] [[prdct.ethereal-engine]] [[prdct.bitecs]]","n":0.408}}},{"i":5046,"$":{"0":{"v":"Proxi","n":1},"1":{"v":"\n- memory-maker listens to your story, pulls out concepts; can listen to how others see you\n- people, places, time, feelings, x, y\n- makes a graph, like a concept heatmaps\n- retells in different styles\n- take memories and out and share them; the world becomes the source for your proxi\n- the proxi can be \"embodied\", say, into a game of survivor with your friends;\n- why a world? above a certain number of items, a zoomable spatial interface is much more usable. makes it more tangible; conceptual things are next to each other; \n- the more memories, the better? two-three dozen is where it gets useful; at 100 it tapered off. importance is well-served with the zoomable as well;","n":0.093}}},{"i":5047,"$":{"0":{"v":"Project Zomboid","n":0.707},"1":{"v":"\n## Features\n\n- skills have to be balanced! i.e., there's a negative skill tree too.","n":0.267}}},{"i":5048,"$":{"0":{"v":"Planet Explorers","n":0.707},"1":{"v":"\n- url https://planetexplorers.pathea.net/\n- description   Planet Explorers is an open world voxel based sandbox adventure rpg game set on a distant planet. The game uses a new [[prdct.opencl]] system based on the Unity 3D engine to allow players to change the terrain in anyway, create new objects in any form, and do it anywhere.","n":0.137}}},{"i":5049,"$":{"0":{"v":"Pizza Legends Thyseus","n":0.577},"1":{"v":"\n- repo: https://github.com/wyze/pizza-legends-thyseus\n- built-on: [[prdct.bun]] [[prdct.thyseus]]\n- written-in: typescript\n\n![](/assets/images/2024-01-30-15-09-18.png)","n":0.354}}},{"i":5050,"$":{"0":{"v":"Pentiment","n":1},"1":{"v":"\n- url: https://store.steampowered.com/app/1205520/Pentiment/\n\n## References\n\n- https://cohost.org/prophetgoddess/post/845893-declarative-crusader","n":0.447}}},{"i":5051,"$":{"0":{"v":"Penrose","n":1},"1":{"v":"\n- [[p.hasURL]] https://penrose.doublespeakgames.com/\n- #summary\n  - a really cool mostly-text interface; you can click words to change your path, and change them back; click character names to switch POVs; click other words to take actions; progress bar shows branches; text isn't literal, selectable text!","n":0.152}}},{"i":5052,"$":{"0":{"v":"Paridot","n":1},"1":{"v":"\n- [[t.cs.augmented-reality]]\n- [[c.publisher]] [[org.niantic]]","n":0.5}}},{"i":5053,"$":{"0":{"v":"Omniblade","n":1}}},{"i":5054,"$":{"0":{"v":"Off Grid","n":0.707},"1":{"v":"\n- #blog https://offgridthegame.blogspot.com/\n- url: http://www.offgridthegame.com/","n":0.447}}},{"i":5055,"$":{"0":{"v":"Odyssey","n":1},"1":{"v":"\n- [[c.documentation]] https://www.mocagh.org/synergistic/odysseycompleat-alt2.pdf\n## Resources\n\n- http://crpgaddict.blogspot.com/2013/05/game-99-odyssey-compleat-apventure-1980.html\n  - \"the men become analogous to hit points in a conventional RPG.\"\n  - \"The opening section is rendered difficult by a few regrettable programming choices.\"\n    - \"Enemies \"level\" with the party in lockstep\"\n    - \"There's a random number roll that affects combat, but it's worth so little compared to the equipment and experience score that every battle is essentially a foregone conclusion from the outset.\"\n    - \"navigation in this section is the most annoying interface I have ever experienced in a CRPG\"\n  - [[c.mention]] [[game.apventure-to-atlantis]]\n  - \"Building the \"biggest army\" is a bad idea in this game because of how quickly it burns through food. I learned that the hard way.\"\n  - [[p.hasComment]] by @robert-clardy\n    - \"I could duplicate that world using that number as the game seed. It was how the saved game was kept small enough - only had to save the party stats, not the world definition.\"\n  - \"Destiny of an Emperor on the NES is an RPG that uses the concept of large armies to represent character hit points\"","n":0.075}}},{"i":5056,"$":{"0":{"v":"Mystery House","n":0.707},"1":{"v":"\n- url: https://en.wikipedia.org/wiki/Mystery_House","n":0.577}}},{"i":5057,"$":{"0":{"v":"Mazmorra.io","n":1},"1":{"v":"\n- dead\n- [[p.hasURL]] https://mazmorra.io/\n- open-source, but not permissive;","n":0.354}}},{"i":5058,"$":{"0":{"v":"Magus Parvus","n":0.707},"1":{"v":"\n- repo: ","n":0.707}}},{"i":5059,"$":{"0":{"v":"Isleward","n":1},"1":{"v":"\n\n\n- [[p.hasLog]] [[game.isleward.log]]\n- [[p.hasURL]] https://play.isleward.com /\n- [[p.hadAnnouncement]] https://www.reddit.com/r/javascript/comments/5v9w0v/my_moddable_multiplayer_roguelike_isleward_is_now/\n- [[p.hasFeature]]\n  - you can plan future moves by extending your path out faster than you can get there, e.g. buffering  \n\n## Resources\n\n- [Building the server infrastructure for an indie MMORPG](https://vildravn.dev/posts/indie-mmo-infra/) 2021-05-25\n","n":0.16}}},{"i":5060,"$":{"0":{"v":"Log","n":1},"1":{"v":"\n\n\n- 2022-01-12 21:20\n  - ![](/assets/images/2022-01-12-21-20-11.png)\n","n":0.447}}},{"i":5061,"$":{"0":{"v":"Island Painter","n":0.707},"1":{"v":"\nrepo: https://github.com/darraghjburke/IslandPainter\nurl: https://darraghjburke.github.io/IslandPainter/ (broken t.2022.12.28)\n\n- [[p.builtOn]]\n  - [[prdct.babylon-js]]\n  - [[prdct.colyseus]]\n  - [[prdct.express]]\n\n## [[p.hasLog]]\n\n### t.2022.12.29 \n  \n- got running locally, needed `nvm use 16` and\n  - ` netsh interface portproxy add v4tov4 listenport=2567 listenaddress=0.0.0.0 connectport=2567 connectaddress=172.19.4.95`\n  - ` netsh interface portproxy add v4tov4 listenport=3000 listenaddress=0.0.0.0 connectport=3000 connectaddress=172.19.4.95`","n":0.147}}},{"i":5062,"$":{"0":{"v":"Internal Audit","n":0.707},"1":{"v":"\n- [[p.hasURL]] http://textadventures.co.uk/games/view/idlwftkafewxlyaxmvsspw/internal-audit\n- [[p.hasScreenShot]]\n  - ![](/assets/images/2022-09-09-13-41-20.png)\n- ","n":0.408}}},{"i":5063,"$":{"0":{"v":"Gone Home","n":0.707}}},{"i":5064,"$":{"0":{"v":"Gameoji","n":1},"1":{"v":"\n- repo: https://github.com/c42f/Gameoji\n- couldn't get it to run with recent Juila","n":0.302}}},{"i":5065,"$":{"0":{"v":"Game of Life","n":0.577},"1":{"v":"\n- [[c.software.cellular-automoton]]","n":0.707}}},{"i":5066,"$":{"0":{"v":"Fps Microgame","n":0.707},"1":{"v":"\n- url: https://learn.unity.com/project/fps-template","n":0.577}}},{"i":5067,"$":{"0":{"v":"Firmament","n":1},"1":{"v":"\n- [[p.hasAuthor]] @kenny-wtf\n- [[p.hasRoadmap]] https://github.com/orgs/wild-magic/projects/1/views/1?visibleFields=%5B%22Title%22%2C%22Assignees%22%2C%22Status%22%2C%22Milestone%22%2C%22Labels%22%5D\n","n":0.447}}},{"i":5068,"$":{"0":{"v":"Fahrenheit Indigo Prophecy","n":0.577},"1":{"v":"\n- https://www.youtube.com/watch?v=rFEVfs1qz54","n":0.707}}},{"i":5069,"$":{"0":{"v":"Remastered","n":1},"1":{"v":"\n- https://store.steampowered.com/app/312840/Fahrenheit_Indigo_Prophecy_Remastered/","n":0.707}}},{"i":5070,"$":{"0":{"v":"Facade","n":1},"1":{"v":"\n- https://www.playablstudios.com/facade\n- creators: @michael-mateas @andrew-stern\n- release: 2005-07-05\n\n![](/assets/images/2024-09-24-03-44-00.png)","n":0.378}}},{"i":5071,"$":{"0":{"v":"Everquest","n":1},"1":{"v":"\n## References\n\n- https://www.pcgamer.com/why-the-original-1999-version-of-everquest-is-still-one-of-the-best-mmos-to-play-today/\n- https://blog.playerauctions.com/others/everquest-progression-server/","n":0.5}}},{"i":5072,"$":{"0":{"v":"Epic Rpg","n":0.707},"1":{"v":"\n- [[p.instanceOf]] [[prdct.discord.activities]]\n- it's stupid what rpg has come to mean","n":0.302}}},{"i":5073,"$":{"0":{"v":"Emergence","n":1},"1":{"v":"\n- repo: https://github.com/Leafwing-Studios/Emergence/\n- written-in: rust","n":0.447}}},{"i":5074,"$":{"0":{"v":"Egg, Inc.","n":0.707}}},{"i":5075,"$":{"0":{"v":"Dungeons and Dragons","n":0.577},"1":{"v":"\n![[game-system.dungeons-and-dragons]]\n\n## Resources\n","n":0.707}}},{"i":5076,"$":{"0":{"v":"Dragons Lair","n":0.707}}},{"i":5077,"$":{"0":{"v":"Dragons Crossing","n":0.707},"1":{"v":"\n- [[c.Software.Web3]]\n- url: https://www.dragonscrossing.com\n\n## Summary\n\n- limited number of actions per day: quests are the resource to be managed\n- w/death you lose all your quests (for the day), everything in the inventory except for 1 thing\n- chose a game for fun, but not 3d MMO because of expense; \n- \"throwback to early RPG\"","n":0.139}}},{"i":5078,"$":{"0":{"v":"Detroit: Become Human","n":0.577},"1":{"v":"\n## References\n\n- https://youtu.be/Ssc6Is2N9vs?si=745BsxzYj3JFMLRB","n":0.577}}},{"i":5079,"$":{"0":{"v":"Death Stranding","n":0.707}}},{"i":5080,"$":{"0":{"v":"Dear Esther","n":0.707},"1":{"v":"\n- https://www.thechineseroom.co.uk/games/dear-esther","n":0.707}}},{"i":5081,"$":{"0":{"v":"Colonizers","n":1},"1":{"v":"\nrepo: https://github.com/sibartlett/colonizers\n\n- [[p.builtOn]] [[prdct.hapi]]","n":0.5}}},{"i":5082,"$":{"0":{"v":"Caves of Qud","n":0.577},"1":{"v":"\n- [[t.cs.game.roguelike]]\n\n## Descriptions\n\n- \"Qud is a roguelike in the full \"descendant of Rogue\" meaning; a game you're expected to start and re-start and re-play different permutations of, similar to the family tree of games that gets us to Slay the Spire and Hades, though Qud is a throwback to an older branch of that tree.\"\n\n## References\n\n- comments on https://www.rockpapershotgun.com/skald-against-the-black-priory-review?view=comments","n":0.13}}},{"i":5083,"$":{"0":{"v":"Blackmoor","n":1},"1":{"v":"\n- creator: @dave-arneson\n- first-play: 1971-04-17\n\n## References\n\n- [[ar.dungeons-deceptions-the-first-d-d-players-push-back]]\n- https://en.wikipedia.org/wiki/Blackmoor_(campaign_setting)","n":0.354}}},{"i":5084,"$":{"0":{"v":"Astroneer","n":1},"1":{"v":"\n- [[c.game.sandbox]]\n- url https://astroneer.space/\n- ","n":0.5}}},{"i":5085,"$":{"0":{"v":"Assassins Creed Odyssey","n":0.577}}},{"i":5086,"$":{"0":{"v":"Arco","n":1},"1":{"v":"\n- https://store.steampowered.com/app/2366970/Arco/  ","n":0.707}}},{"i":5087,"$":{"0":{"v":"Archaic Quest II","n":0.577},"1":{"v":"\n- written-in: [[t.cs.languages.c-sharp]]\n- repo: https://github.com/ArchaicQuest/ArchaicQuest-II\n- [[p.builtOn]] [[prdct.signalr]]\n\n\n## Thoughts\n\n- commands can take indirect objects and prepositions, e.g. \"look [at] crate\" vs \"look in crate\"ge\n- \"look 2.crate\" \n- I've been so ready to give up the [[t.cs.game.persistent-room]] thing... with good auto-DMing, it shouldn't be necessary. \n- \"Don't forget to read descriptions and pay attention it's easy to miss something interesting if you rush.\" - uh, this is a bad sign. i have to read all these boring descriptions. And they persist each time I come back to the \"room\".\n\n## [[c.command]]\n\n### Movement\n\nnorth south east west up down\nnortheast northwest southeast southwest \nrecall sleep wake rest stand enter\n\n### Combat\n\nkill cast skills spells\ndodge parry wimpy flee  \nwands scrolls staves\ndamage death healers\nnosummon PK\n\n### Character\n\ndescription title \nscore report practice train stats\ncommands socials pose emote RP\n\n### Objects\n\nget put drop give sacrifice          \nwear wield hold                     \nrecite quaff zap brandish            \nlock unlock open close pick          \ninventory equipment look compare    \neat drink fill                      \nlist buy sell value\n\n### Group\n\ngroup follow nofollow gtell\n\n### Communication\n\nic ooc newbie gossip yell shout   \nnote idea history change  \nsay tell reply who\n","n":0.076}}},{"i":5088,"$":{"0":{"v":"Apventure to Atlantis","n":0.577}}},{"i":5089,"$":{"0":{"v":"Apico","n":1}}},{"i":5090,"$":{"0":{"v":"Anyland","n":1},"1":{"v":"\n- [[c.game.sandbox]]\n- url http://anyland.com/\n- ","n":0.5}}},{"i":5091,"$":{"0":{"v":"Alien: Isolation","n":0.707},"1":{"v":"\n- [[c.game.horror]] [[c.game.survival]]","n":0.577}}},{"i":5092,"$":{"0":{"v":"Ai Dungeon","n":0.707},"1":{"v":"\n- url: https://aidungeon.com/\n- ","n":0.577}}},{"i":5093,"$":{"0":{"v":"Adventure Construction Se","n":0.577},"1":{"v":"\n\nPros:\n  - can customize pretty much everything in this game: The story, the locations, the items, the creatures/allied creatures/characters, the magic spells and effects created by everything, and even the graphics [^1]\n  - All in one package without you having to resort to a bunch of separate programs, to do every individual thing, and to hunt through forums and websites for assets to build your RPG with, like you have to do with most modern RPG creators today.\n  - allows up to four players to play the game simultaneously, using hot seat\n  - I can't tell you how many competitive adventures I built with this game, where each player was experiencing a different part of the adventure, and it was designed to bring them all together, in a titanic battle to the finish, in the big climactic ending. You don't see that at ALL in ANY modern RPG builders.\n\nReferences:\n  - [^1]: https://www.myabandonware.com/game/stuart-smith-s-adventure-construction-set-1qr","n":0.081}}},{"i":5094,"$":{"0":{"v":"A Dark Room","n":0.577},"1":{"v":"\n- [[p.hasURL]] http://adarkroom.doublespeakgames.com/\n- #summary maybe just filler for [[game.penrose]]","n":0.333}}},{"i":5095,"$":{"0":{"v":"0 A.D.","n":0.707},"1":{"v":"\n- https://play0ad.com/\n- repo: https://trac.wildfiregames.com/\n- written_in: C++\n- ","n":0.408}}},{"i":5096,"$":{"0":{"v":"Game Systems","n":0.707}}},{"i":5097,"$":{"0":{"v":"Year Zero Engine (YZE)","n":0.5},"1":{"v":"\n- publisher: [[org.free-league-publishing]]\n\n## Games\n\n- [[prdct.mutant-year-zero]]\n- [[prdct.tales-from-the-loop]] \n- [[prdct.forbidden-lands]]","n":0.354}}},{"i":5098,"$":{"0":{"v":"Pbta","n":1},"1":{"v":"\n- [[p.comparableTo]] [[game.dungeons-and-dragons]]\n  - \"While there are rules for combat and magic [in DnD], pretty much everything else is done on a case-by-case basis. In a PbtA game, there is a finite set of moves, both unique moves for specific characters and basic moves everyone gets. The moves define everything that the rules cover; if a character wants to do something that isn’t a move, they can do it without rolling.\"\n  - \"when the GM makes a move, it happens, no die roll necessary\"\n  - PbtA games offer a range of mechanics which define how the PCs interact\n\n## Resources\n\n- https://cannibalhalflinggaming.com/2016/12/14/level-one-wonk-a-novices-guide-to-powered-by-the-apocalypse/\n  - [[p.hasHighlight]]\n    - \"the reason Apocalypse World uses authoritative voice in the GM’s section is because without the Agendas and Principles laid out for the GM, the game doesn’t actually work very well. Games that use the PbtA framework well are narrow; that’s the main reason that Apocalypse World and Dungeon World and all the others are published as different games as opposed to splatbooks for some theoretical core system. Part of that narrowness is that these games will only work for primarily story-driven games. What the Agendas and Principles tell the GM is not how to run RPGs, they tell the GM how to run this RPG, and that’s an important distinction.\"\n    - ","n":0.068}}},{"i":5099,"$":{"0":{"v":"Dungeon World","n":0.707},"1":{"v":"\nurl: https://dungeon-world.com/\n\n## Description\n\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^clwr7w4n7iff]]\n\n","n":0.577}}},{"i":5100,"$":{"0":{"v":"Genesys","n":1},"1":{"v":"\n## Description\n\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^sfwe0h0ipn9l]]\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^2oeuqdes6i0x]]","n":0.707}}},{"i":5101,"$":{"0":{"v":"Everway","n":1},"1":{"v":"\n- https://www.drivethrurpg.com/en/publisher/17595/the-everway-company\n\n## Description\n\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^3887hkaim4hv]]\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^w8gaab0id97l]]\n![[ar.theangrygm.a-complete-idiots-guide-to-play-by-post-gaming#^acaknyft4w8p]] ","n":0.577}}},{"i":5102,"$":{"0":{"v":"Dungeons and Dragons","n":0.577},"1":{"v":"\n\n- [[prdct.5e-tools]]","n":0.707}}},{"i":5103,"$":{"0":{"v":"Spellcraft","n":1},"1":{"v":"\n## Resources\n\n- [Costly Spell Components](https://docs.google.com/spreadsheets/u/3/d/e/2PACX-1vQ0PUubejT6BChmPqDHdAizsNkdfn6JsPGWC2BcaykJGzRzZc26TvOCGP_ua9R_6c3DvzIJpZa7yW49/pubhtml)","n":0.447}}},{"i":5104,"$":{"0":{"v":"Multitasking","n":1},"1":{"v":"\n## References\n\n- https://www.rjd20.com/2022/12/DnD-is-the-Best-Time-to-Multitask-Satire.html","n":0.577}}},{"i":5105,"$":{"0":{"v":"Forgotten Realms","n":0.707},"1":{"v":"\n- [[c.Work.superwork]] \n- see also: [[setting.forgotten-realms]]\n\n## Mood\n\n- \"Greenwood has stated that his own version of the Forgotten Realms, as run in his personal campaign, is much darker than published versions.\"\n\n## Lore\n\n- \"When Gary Gygax \"lost control of TSR in 1985, the company saw an opportunity to move beyond Greyhawk and introduce a new default setting\". In 1986, TSR began looking for a new campaign setting for AD&D, and assigned Jeff Grubb to find out more about the setting used by Greenwood as portrayed in his articles in Dragon.\n\nAccording to Greenwood, Grubb asked him \"Do you just make this stuff up as you go, or do you really have a huge campaign world?\"; Greenwood answered \"yes\" to both questions.\"[1]\n\n## Resources\n\n- https://www.wizardtower.com/blog/dungeons-and-dragons/the-forgotten-realms-origins/ mentions @ed-greenwood\n- [1]: https://www.annarchive.com/files/Drmg244.pdf\n- https://www.realmshelps.net","n":0.089}}},{"i":5106,"$":{"0":{"v":"Calendar","n":1},"1":{"v":"\n- \"The year consists of 365 days: 12 months of exactly 30 days each (due to the single moon and its followers), plus 5 days that fall between months. These days are special occasions. Leap year is retained purely for social convenience, and provides a sixth special day that is used as the basis for long-term agreements and such.\"\n- \"Months are subdivided into three ten- day periods. These are known various- ly as ìeves,î ìtendays,î ìdomen,î ìhyrar,î or ìridesî throughout the Forgotten Realms. Rides is the standard term used in Cormyr and the Dalelands, and is used for reference in these texts.\"\n- \"","n":0.099}}},{"i":5107,"$":{"0":{"v":"E6","n":1},"1":{"v":"\n## Cons\n\n- \"Not only do I enjoy taking characters into truly epic spheres of play, but I find the 5th Edition dynamic — where you can trivially dispatch celestial titans and fight your way to the throne of Asmodeus, but knocking down a wooden door? Man, that’s a tough ask! —to be kind of ridiculous. But I would really hate to see the game cripple itself by lopping off the epic modes of play for those of us who enjoy them.\"\n\n## References\n\n- https://www.enworld.org/threads/e6-the-game-inside-d-d.206323/\n- https://thealexandrian.net/wordpress/50073/roleplaying-games/soloing-smaug-the-struggle-for-the-soul-of-dd","n":0.109}}},{"i":5108,"$":{"0":{"v":"Classic","n":1}}},{"i":5109,"$":{"0":{"v":"Alignment","n":1}}},{"i":5110,"$":{"0":{"v":"5e","n":1},"1":{"v":"\n\n## Comparisons\n\n### Saving Throws vs Ability Checks\n\n-  Now, technically, there is no such thing as \"skill check\". There is n ability check, that can be done either using just an ability by itself, or using a specific skill related to that ability. Those are called \"skill checks\" in the informal vernacular, and are not actually called that in the books.\n\nAbility checks are, simply put, is when you want to do something to the world around you - climb a tree, lift a boulder, hide in the darkness, seduce a dragon, etc. Now, saving throws, following that same analogy, are made when the world is doing something to you - a trap opens under your feet, a spell is being cast on you, you ingest poison, etc. \n\n\n\n## References\n\n- https://www.reddit.com/r/DnD/comments/g7kql8/skill_checks_and_saving_throw_differences/\n- https://dnd.wizards.com/sage-advice/ability-check","n":0.088}}},{"i":5111,"$":{"0":{"v":"Crucible","n":1},"1":{"v":"\n- https://foundryvtt.com/packages/crucible\n\n\n## Description\n\nCrucible is an innovative and modern tabletop role-playing game system built exclusively for Foundry Virtual Tabletop as a digital platform. From the ground up, Crucible is designed to leverage the unique capabilities of Foundry VTT to provide gamemasters with a powerful toolset and effortless layers of automation, allowing gamemasters and players to focus on what matters most: telling a compelling story.\n\nThe central focus of Crucible is meaningful and varied character advancement through a class-less system with multiple pillars of character progression. Crucible's system and dice mechanics allow for crunchy and tactically rich encounters featuring combat, exploration, problem-solving, or social challenges.","n":0.099}}},{"i":5112,"$":{"0":{"v":"Events","n":1}}},{"i":5113,"$":{"0":{"v":"Jamstack Conf","n":0.707}}},{"i":5114,"$":{"0":{"v":"Jamstack 2021","n":0.707},"1":{"v":"\n\r\n\r\n- resources:  https://www.netlify.com/blog/2021/10/07/jamstack-conf-2021-instant-replay/\r\n\r\n## mpa vs spa @rich-harris\r\n\r\n- [[p.hasRecording]] [Have Single-Page Apps Ruined the Web? | Transitional Apps with Rich Harris, NYTimes](https://www.youtube.com/watch?v=860d8usGC0o)\r\n- ![](/assets/images/2021-10-31-13-36-29.png)\r\n- Transitional Design\r\n  - best of both worlds\r\n  - transitions\r\n    - object permanence\r\n- hotwire\r\n  - rails\r\n  - github\r\n    - history api to do client-side navigation\r\n    - partial html updates -> inconsistency everywhere\r\n  - svelte with vite\r\n- truth is nuanced\r\n\r\n## astro @matthewcp\r\n\r\n- works with markdown, but also \"more powerful\" astro pages\r\n- embraces mpa\r\n\r\n## supabase\r\n\r\n- cloudified postgresql\r\n- supports GraphQL\r\n\r\n## sanity.io\r\n\r\n- structured content as data\r\n- webhooks\r\n- cool model! github needs webhooks\r\n- \"[portable text](https://github.com/portabletext/portabletext)\" #json #not-for-humans\r\n\r\n## @moriel\r\n\r\n- neutrality.wtf\r\n\r\n## [[prdct.magic]] @seemcat\r\n\r\n","n":0.102}}},{"i":5115,"$":{"0":{"v":"2024","n":1}}},{"i":5116,"$":{"0":{"v":"04","n":1}}},{"i":5117,"$":{"0":{"v":"03","n":1}}},{"i":5118,"$":{"0":{"v":"Ontology Summit Synthesis","n":0.577},"1":{"v":"\n- host: @ken-baclawski @gary-berg-cross\n- url: https://ontologforum.org/index.php/OntologySummit2024/Synthesis\n- contributors: @john-sowa\n- participants: @janet-singer @gary-marcus @mike-bennett @todd-schneider @ravi-sharma @alan-rector @deborah-mcguinness @anatoly-levenchuk @fabian-neuhaus \n\n## @gary-berg-cross\n\n- [[t.cs.ai.neuro-symbolic]] roadmap\n  - [[t.cs.ai.retrieval-augmented-generation]]\n  - tools like [[prdct.ontolearn]]\n\n## @janet-singer\n\nHybrid systems are multi-paradigm systems that could be seen as combinations of data-driven or bottom up and theory-driven or top-down . But ‘Neuro-symbolic’ is unclear by itself: ‘Neuro’ is metaphoric, and contrasting ANNs with ‘symbolic’ is misleading because all IT involves rule-based symbol manipulation\n\n## Mentions\n\n- [[prdct.deeponto]]\n- @gary-berg-cross: From my co-chair Pascal - https://academic.oup.com/nsr/article/9/6/nwac035/6542460 a review of this area.\n\nCognitive Science is:\n- philosophy\n- psychology\n- ai\n- neuroscience\n- anthropology\n- linguistics","n":0.103}}},{"i":5119,"$":{"0":{"v":"03","n":1}}},{"i":5120,"$":{"0":{"v":"21","n":1}}},{"i":5121,"$":{"0":{"v":"Virtual Beings and Virtual Societies Summit","n":0.408},"1":{"v":"\n- location: [[org.founders-inc]]\n- host: @edward-saatchi @hubert-thielblot\n\n- @hubert-thielblot: focused on -1 to 0, crypto, ai, vr/ar\n\n## agenda\n![](/assets/images/2024-03-25-12-12-39.png)\n\n\n## Welcome @edward-saatchi and @hubert-thielblot\n\n- we need to embrace the theme of life-vs-dark\n- transcripts reveal: platitudes\n- ai communities can be as messy and diverse as human ones\n\n## First Panel\n\n- members: @tejas-kulkarni @vish-hari @kevin-fischer @robert-yang\n- @robert-yang: [[t.cs.ai.bender-test]]\n- @kevin-fischer: even children's fairy tales grapple with elements of darkness\n- @vish-hari: wants to bring punk rock back into tech;  giving users the option for violent/dark stories; \n- @tejas-kulkarni: suppressed emotions in society... let people explore their imaginations; content moderation layers\n- @vish-hari: embodiment! june park's paper in 3d, co-founder Peggy's viral \n- @robert-yang: corpus collosum severance means left and right brains are more independent;\n  - agent failure mode is when they don't realize what they're doing, or the think they're doing something they're not\n- @kevin-fischer conversations can have action space; operations over your own internal mental states; want to induce a target state; in the same way you ahve planning and action space in the world, is conversation design\n- @vish-hari: how do you constrain the action space\n- @edward-saatchi: control vs freedom = authorial intent vs emergence; need to give players tools, or better insight into to why?\n- @kevin-fischer: design agentic action spaces; authorial intent is with the designers\n- @vish-hari: constrain action spaces through consent frameworks and value alignment\n  - @june-park controls agents with long-term memory. we often can't measure systematically what emerges; we need a new set of tools to predict how LTM or whatever will change\n- @tejas-kulkarni text adventure games means text is enough to capture abstractions of emergent social dynamics; \n- @edward-saatchi: how do you think about interactions\n- @tejas-kulkarni: goal is to build a world simulator; LLM model doesn't give itself to code injection; temporal sampling for \"enough representation\"; guassian, images, etc come together under a huge\n- @edward-saatchi: have any of your ai's been \"embodied\" by persuading a human to take action. \"we are their embodiment\"\n- @vish-hari \"we haven't experimented on humans yet, but if you want to volunteer, let me know.\"\n- @robert-yang: a true agent has their own desires\n\n### audience questions\n- members: @tejas-kulkarni @vish-hari @kevin-fischer @robert-yang\n\n- what are your tech stack\n- @robert-yang: @chatgpt.3.5\n- @kevin-fischer: building a compelling agent is a state management; we've built a \"react\" \n- @vish-hari: @peggy-wang\n- @robert-yang: why do we speak shorter? theory of mind, it means someone else can't talk.; \n\n## Sim Francisco\n\n- the simulation of something known resonates; \n- for [[prdct.sim-francisco]] some turns are emergent, some are driven by humans\n- \"too boring\" when fully emergent; \n- interactivity vs passivity: \"best first way to connect with a simulation\" is to watch what's happening.\n- simulations don't have conflict\n- \"how do you program comedy\": people are stuck in the boring vanilla mental model. \"we're going there\"\n\n\n## @john-gaeta\n\n- @john-gaeta: \n  - \"I enjoy your provocations. Kinda scared by 'em, but enjoyed\"\n  - where to go? compelled by cinema/storytelling/expressing ideas. was lucky enough to get drawn into filmmaking... \n  - all science fiction is a prelude, a giant suggestion box; builders looks inside these fictional works to find emotional/memory motivation\n- @edward-saatchi:  did virtual humans of the matrix compel you towards [[prdct.unreal]] and [[org.ilm]] and [[org.inworld]] : check https://store.steampowered.com/app/2199920/Inworld_Origins/\n- @john-gaeta: \"the construct\" is more interesting than the holodeck. working on \"volumetric capture\", @keanu only makes sense on a 1-to-1. \"uncanny valley\" is not just visual, it's big. With LLMs you get to \"what's natual\", but it's non-verbal, neurochemical. \n- doing robots is a good start. in star wars, droids are lovable because they love their humans; \n- how will folks trains themselves? language doesn't capture it. often language counter-captures it. skeptical that words can unpack what you are. \n- agree with flaws leading to authenticity. \n- i'm talking to you, but inside my head i have a faint picture. \n- @edward-saatchi: \"why do we need words? word conceal?\" \n- @john-gaeta: it's wonderful to sculpt a story. \"the one button thing will fill the internet with 10,000-fold noise and junk\" - we need \"a new form of live ops\"\n- \"some kind of weighting situation\" for fight or flight nuance\n- the stuff that compells us is what keeps us guessing; the greatest game and fictions always twist you the whole way through; starts with human intuition. \"we're doing all this to land at human again.\" everyone has a different opinion on what consitutes a beautiful virtual being/society. \n- @vish-hari: how do we bring stories and engineering together?\n- @john-gaeta: there's not a lot of people who can do both; i've been lucky to be surrounded by engineers; best chemistry is instinctual and analytical. if we see things we don't like in our platforms... we haven't connected the dots; when there's healthy tension; you can play with the dark side, art-wise; but we have to stay on the light side; there's way more dark side people that need to be mitigated; \n- messaging has to be \"how to amplify and empower\"\n\n## Panel #2: AI Gamesmaker\n\n- @joshua-johnson @hillary-mason @eugene @harvey-michael-pratt @stephan-bugaj @eugenia \n- @harvey-michael-pratt: if you've entertained building a video game, now is the time; interested in games \n- @hillary-mason: opportunity to create new experiences; our approach is collaborative and rigorous; you have to design structures around what these models are really great for. \"imagine your favorite author, could be your [[t.roleplaying.gm]]\"\n- shift the creation of what they see until the moment they see it. in skyrim, side quests don't change the world; players can change their world, their social statuses. \n- @stephan-bugaj: [[game.rival-peak]] and [[game.silent-hill-ascenscion]]\n- @eugenia is wearing a shirt that says \"a machine beautiful enough that a soul would want to live in it\"\n  - most products use off-the-shelf LLMs, audience is used to chatgpt; edge is in building a different conversation; \n- in [[game.silent-hill-ascenscion]] the monster represent trauma; \n- @joshua-johnson: [3d at runtime] we've been able to scale up 3d generation from text prompts within 10-15 seconds; it's going to move very quickly; still some limitation on world building; \n\n### question\n\n- @hillary-mason: what matters isn't stories, but match your resonant stories and friends; \n- @stephan-bugaj: if everything goes well, we'll go back to \"art and play\" and get rid of content\n- @harvey-michael-pratt : harris identified compelling; symbolic structures tend towards entropy, which would be dystopic\n  - \"generally, the audience shouldn't now whether it's ai or non-ai\"\n- @eugene: with our web3 game, tried to hide the web3 tech as much as possible; \"local compute, localized LLMs\"; [[game.ai-dungeon]]\n- @hillary-mason: infrastructure costs; \n- @stephan-bugaj: ai shovel-ware is going to push us to saturation and force us to be good again; \n- consensus: we're headed for the dopamine death spiral; deluge of content; on-edge will help you sift through huge amount of content; eventually, virtual beings will be more compelling than the real thing\n- @harvey-michael-pratt: edtech! make learning as compelling as fortnite\n- @eugenia: nobody is talking about qualitative, which means bad things\n- @hillary-mason: ttrpg is an optimistic space; \n\n## @will-wright\n\n- [[game.proxi]] \n- if you woke up with different memories, you'd be a different person. What kind of maps could we build of your psychology. Conscious stream of thought is a trickle on top of a lot of other \"unseen consciousness\"\n- people have parts of their personality than they can't articulate or communicate, but maybe you could see them through a special microscope machine if you fed it memories and behaviour\n\n- think about actors, how they seem so real; narrative side; no game ever went wrong over-estimating the narcissim of the players;\n- the sims became a scaffolding for fantasy; a spreadsheet of what-ifs, or ice-breakers; \n- you as a platform for gaming; storytelling and play are flipsides of the same coin\n- as a kid, loved building models; apple simulator let model dynamic systems, which pulled him into simulation; toys of the world so you can understand more of the world; \n- sims was really more of a dollhouse\n- proxi more of a high-tech scrapbook\n- looking forward to a \"digital audience\" as a tool; million-ai focus group, and have them automatically tune the game; games have an opportunity to be much more malleable; \n\n- [[book.the-user-is-an-illusion]]\n- \"consciousness\" is one of these useless terms like \"art\"; \n- consciousness is more of a timestamp\nif you have to build a narrative in real time, that basically consciousness \nany narrative form has to leave room for the audience to fill.\nlike Scott mcleods space between the gutters\n\n## industry (venture) voice\n\ninvestors\n- @james-buckhouse at [[org.sequoia]]\n- @amber-atherton at [[org.patron]] w\n- @aaron-sisto for [[org.first-spark-ventures]]\n- @jack-soslow for [[org.andreessen-horowitz]]\nJack... playful constraints\nAron new type of studio\nJames... great day to wake up. language is a game between me and i\nJack. character.ai, the promenade, suck up, digi Isa high quality \nAron what does control mean.... free energy principle.\npromenade guy... use llm to create ontology\nnpcs isn't why people play games\nnever be alone when you're playing\nalways about the inner character with an arc\ndelta in emotion in every scene\nmuch harder problem is inner character \ninvestors looking for an outlier... at sequoia\n@amber-atherton patron looking for core player community with a wedge. E.g. valorant\nAron deep tech... strongest teams have experience in the industry \ngood engineers \nright sized idea for right sized founder\nplus business and product skills\nAron... do the new thing\nJames... agentic work flow. different, not merely better.\nincrease tour def of what game is.\nunshut\ncontent deluge - curation. distribution advantage.","n":0.026}}},{"i":5122,"$":{"0":{"v":"07","n":1}}},{"i":5123,"$":{"0":{"v":"Dapr Actors","n":0.707},"1":{"v":"\n- hosted_by: @marc-duiker\n- example: [[prdct.dapr-actor-demos]]\n\n- use workflows instead for long-running processes\n- turn-based access model\n- idea: maybe the actor is the companion/sidecar to the agent \n- virtual actor: not tied to in-memory representation\n- timers are stateless (lost after actor deactivation)\n- reminders are stateful (persists after deactivation, will rehydrate actor)\n\n## Actors API\n\n- ","n":0.141}}},{"i":5124,"$":{"0":{"v":"A Practical Approach to Implementing Semantic Data Layers","n":0.354},"1":{"v":"\n- a semantic layer is basically an integration framework\n- why?\n  - interoperability\n  - federated access (data managed where it lives)\n  - understandability/explainability\n  - w","n":0.204}}},{"i":5125,"$":{"0":{"v":"2022","n":1}}},{"i":5126,"$":{"0":{"v":"11","n":1}}},{"i":5127,"$":{"0":{"v":"28","n":1}}},{"i":5128,"$":{"0":{"v":"Code Content and Capital Building a Network State on Urbit","n":0.316},"1":{"v":"\n- [[p.hadPresenter]] @justin-murphy\n- flywheel: creators -> community -> developers -> infrastructure -> creators\n- a lot of top engineers don't want to be building skynet for a megacorp\n- easier than ever to be an independent software developer\n- creators still under-monetized\n  - [[p.begsQuestion]] valuable to who?\n  - creators are more like statesmen: provide cognitive, aesthetic and emotional \n- [[prdct.urbit]] is a liberator for the flywheel\n- code = content\n  - what he means is content is software for the human OS.\n  - capital is the fuel that makes code/content run\n- ","n":0.107}}},{"i":5129,"$":{"0":{"v":"09","n":1}}},{"i":5130,"$":{"0":{"v":"01","n":1}}},{"i":5131,"$":{"0":{"v":"Property Graphs Vs Typedb","n":0.5},"1":{"v":"\n\n- [[p.hostedBy]] [[user.tomas-sabat]]\n- \"strongly-typed database\", but close to [[t.cs.data.DBMS.graph]]\n- modeling complex data is difficult in graph (although easy to start)\n  - \"complex data\" means a lot of types\n    - relation types\n    - entity types\n- typedb is a graph engine under the hood, on top is the type system\n- ![](/assets/images/2022-09-01-09-40-25.png)\n  - property graphs: directional, binary, static\n- typedb:\n  - ![](/assets/images/2022-09-01-09-41-14.png)\n  - hyper-relations allow:\n    - ternary\n    - no need for reification\n    - nested relations ()\n  - type hierarchys\n    - in cypher, can't enforce labellings (which apparently is how you do types)\n- Inferencing\n  - most under-rated features of typedb\n  - not machine learning, based on symbolic logic/deductive logic\n\nQuestions:\n- why \"locating\" instead of located\n- rule describes a pattern\n  - ![](/assets/images/2022-09-01-10-00-20.png)","n":0.093}}},{"i":5132,"$":{"0":{"v":"Cybersecurity Summit Los Angeles 2022","n":0.447},"1":{"v":"\n- [[p.hadPresentation]]\n  - [[event.2022.cybersecurity-summit.darktrace-presentation]]\n  - [[event.2022.cybersecurity-summit.google-presentation]]\n  - [[event.2022.cybersecurity-summit.the-future-of-siem]]\n    - [[p.hadPresenter]] @jeannie-warner \n  - [[event.2022.cybersecurity-summit.malwarebytes-presentation]]\n  - [[event.2022.cybersecurity-summit.zscaler-presentation]]\n  - [[event.2022.cybersecurity-summit.securing-the-hybrid-workforce]]\n  - [[event.2022.cybersecurity-summit.zero-trust-session]]\n  - [[event.2022.cybersecurity-summit.future-of-cybersecurity-operations]]","n":0.213}}},{"i":5133,"$":{"0":{"v":"Zscaler Presentation","n":0.707},"1":{"v":"\n- hub-and-spoke with datacenter as the \"center of the universe\"\n- [[t.cs.security.secure-web-gateway]]\n- [[t.cs.security.zero-trust-network-access]]\n- ","n":0.289}}},{"i":5134,"$":{"0":{"v":"Zero Trust Session","n":0.577},"1":{"v":"\n- [[p.hadPresenter]] @den-jones\n  - has deployed [[t.cs.security.zero-trust-network-access]] with three different technologies\n- authentication only focused on the user and ignores the device\n- mistakenly consider the corporate network \"safe\"\n- network perimeter no longer a security boundary\n- \"we don't want to back-haul all the traffic to inspect all the packets\"\n- make the user experience better\n  - \"never enter a password again\"\n    - use a certificate tied to device and user\n  - self-remediation\n  - no more VPN... \"internet facing application, but accessed via reverse-proxy\"\n- ZTNA\n- if you're not using it, remove access\n- \"access proxy is still a VPN, kinda, but the user never logs in\"\n- policy engine:\n  - if you have a cert, edr, and patches, we let you in\n- adobe had 5 data classifications; \"smoking crack\"\n- fewer tools\n- suites don't integrate\n- IDP was big; \n- \"get your cmdb right\" is bullshit, could take 20 years\n- Get started\n  - sell vision, people, process and technology\n  - begin with cross-functional core team\n  - find a concrete use case\n  - start by integration with your existing auth platform\n- \"executive support is essential\"\n- introduce zero-trust principles, but avoid the term zero trust\n- active communication (use a countdown)\n- ","n":0.073}}},{"i":5135,"$":{"0":{"v":"The Future of Siem","n":0.5},"1":{"v":"\n- [[p.hadPresenter]] @jeannie-warner \n- [[p.hasTopic]] \n  - [[t.cs.security.user-and-behavior-analysis]]\n  - need to collect more of the right data including creds\n  - manual investigations lead to an incomplete outcome\n  - \"it's a whole new world\", but our humans have a gap e.g. NTLM vs Kerberos\n  - [[t.cs.security.security-operations-center]]\n- Four Attributes of Success:\n  - \"Assumed Breach\" posture\n    - \"boring\" is what wins\n    - \"offensive posture\" : what if? zero trust initiatives;\n    - NIST-800 needs teeth\n  - Understand What Normal Looks Like\n    - \"over 3/4 of attacks are using valid credentials\"; compromised credentials\n  - Embrace Automation\n    - \"They'll yell at me\" is a real reason IT won't do things\n  - Think Like the Business\n    - speak to the business in a language they understand\n    - adopt a risk-based approach for users, roles, and assets\n    - respond to cybersecurity events the way a good business responds to market conditions\n    - elevate cybersecurity as a strategic partner versus a cost center\n    - constant team education and improvement\n- Where to begin:\n  - audit existing capabilities\n  - assess your staff workflow and workloads\n  - determine the most business-critical use cases by asking\n    - can you support them with your existing skills, technology, data\n    - are you mapping log sources and events to the mitre attach chain\n    - \"[[first times are interesting|idea.first-times-are-interesting]]\"\n  - communicate the business value you are driving\n","n":0.067}}},{"i":5136,"$":{"0":{"v":"Securing the Hybrid Workforce","n":0.5},"1":{"v":"\n- personal laptops are ideal, but people aren't going to separate, especially when travelling; assume people will use it for personal\n- phishing is psychology, will never go away\n- most people just don't know... how do I teach general [[t.cs.security.cyber-hygiene]]\n- make it a safe space","n":0.151}}},{"i":5137,"$":{"0":{"v":"Malwarebytes Presentation","n":0.707},"1":{"v":"\n- [[org.malwarebytes]]\n- 200% increase in 2022 in Windows worms, malware, etc\n- 300% increase in 2022 in cryptomining\n- email threats \n  - spiked with Covid\n  - co-ordinated action by multiple law enforcement agencies cause drop in 1/21\n  - ","n":0.164}}},{"i":5138,"$":{"0":{"v":"Google Presentation","n":0.707},"1":{"v":"- browser is your first line of denfense \n- Chrome browser cloud management\n  - can \"clear cache and cookies\"\n  - can force relaunch\n  - supports user requests for extensions, users get notified\n  - recently released \"connectors\" to \n    - [[prdct.gcp.pub-sub]]\n    - [[prdct.splunk]]\n    - [[prdct.cloudstrike]]\n  - version reporting\n- security reporting to [[prdct.gcp.security-center]]\n  - adding \"extension events\" and \"crash events\"\n- [[p.demonstrated]] [[prdct.chromeos-flex]]","n":0.129}}},{"i":5139,"$":{"0":{"v":"Future of Cybersecurity Operations","n":0.5},"1":{"v":"\n- [[p.hadPresenter]] @jeff-wheat","n":0.577}}},{"i":5140,"$":{"0":{"v":"Darktrace Presentation","n":0.707},"1":{"v":"\n- [[p.hasTopic]]\n  - [[prdct.darktrace-prevent]]\n  - [[prdct.darktrace-detect]]\n  - [[prdct.darktrace-respond]]\n  - [[prdct.darktrace-heal]]\n- [[p.hasFeature]] Cyber AI Loop\n  - [[p.managed]] [[t.cs.security.cyber-risk]]\n    - [[t.cs.security.attack-simulations]]\n    - [[t.cs.itsm.it-asset-discovery]] \n    - [[t.cs.security.attack-surface-management]]\n    - [[t.cs.security.penetration-testing]]\n    - [[t.cs.security.risk-management.prioritization]]","n":0.189}}},{"i":5141,"$":{"0":{"v":"2013","n":1}}},{"i":5142,"$":{"0":{"v":"Gdc","n":1}}},{"i":5143,"$":{"0":{"v":"Architecture Tricks Managing Behaviors in Time Space and Depth","n":0.333},"1":{"v":"\n- presenter: @david-mark\n\n## Overview\n\nWhile the standard AI algorithms we all know (and love?) look good on paper, we often run up against barriers when we put them into practice. Usually, these barriers occur when NP-Hard problems clash with limitations on memory and processing cycles. Add in the necessity to allow for the simple, expandable creation and management of behaviors, and the scope of the problem expands significantly. This lecture will show three different tricks for helping AI solve difficult problems while staying manageable. Dino Dini will show how co-routines can help mitigate the \"polling problem\" in AI behavior. Luke Dicken will show how complex behavior planning can be done off-line and spliced at run-time as necessary. Dave Mark will show his \"infinite axis\" utility system that allows for the simple design and processing of modular reasoners. All three sections will give concrete takeaways that can be applied to a variety of AI applications. \n\n## Highlights\n\n- if \n  - a change in state\n  - dependent on the current state\n  - when the \"if\" is executed\n- when\n  - a change in state\n  - dependent on the resulting state\n  - when a specified state change occurs\n  - \"computers are not really set up for the when\"\n  - typical solution is messages,\n    - but you have to keep polling\n- can have reusable behaviors if the language supports nestable coroutines\n- but messages must be able to change the program counter\n- mentions: PROC system\n\n## Resources\n\n- [[book.behavioral-mathematics-for-game-ai]]","n":0.065}}},{"i":5144,"$":{"0":{"v":"1990","n":1}}},{"i":5145,"$":{"0":{"v":"Bill Watterson Kenyon Commencement","n":0.5},"1":{"v":"\n\n\n- resources: \n  - [[https://www.themarginalian.org/2012/09/12/this-is-water-david-foster-wallace/|ar.the-marginalian.this-is-water-david-foster-wallace-on-life]] #recommended\n  - https://www.themarginalian.org/2014/05/20/the-best-commencement-addresses-of-all-time/\n","n":0.354}}},{"i":5146,"$":{"0":{"v":"Yeehaw Day","n":0.707}}},{"i":5147,"$":{"0":{"v":"Thanksgiving","n":1},"1":{"v":"\n\n\n- [[p.hasRecurrence]] fourth Thursday in November since 1941\n- \"[The first thanksgiving] became a part of popular historical memory not in 1621 but in 1841, the year that Edward Winslow’s account of the Pilgrims’ harvest celebration reentered the historical record.  The key figure in the process was the Reverend Alexander Young, a New England-born Unitarian minister with a passion for local history.  Working with a copy of Mourt’s Relation discovered in Philadelphia a generation earlier, Young included the text of the pamphlet in a compilation of historical documents he titled Chronicles of the Pilgrim Fathers.\"\n  - [[p.hasSource]] https://faithandamericanhistory.wordpress.com/tag/reverend-alexander-young/\n","n":0.102}}},{"i":5148,"$":{"0":{"v":"Textgraphs Conference","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]]\n  - http://www.wikicfp.com/cfp/program?id=2847&s=TextGraphs&f=Graph-based%20Methods%20for%20Natural%20Language%20Processing\n  - https://dblp.uni-trier.de/db/conf/textgraphs/index.html\n","n":0.408}}},{"i":5149,"$":{"0":{"v":"Steve Jobs Stanford 2005 Commencement Speech","n":0.408},"1":{"v":"\n\n- [[p.attributedTo]] @steve-jobs\n\n- believe that your dots will connect, because that will allow you to take chances\n- the only way to do great work is to love what you do; don't settle\n- you'll be dead soon; don't be trapped by dogma; stay hungry; stay foolish\n\n## thoughts\n\n- privileged\n  - it's easy for a billionaire to take chances and \"start fresh\"\n  - it's easy for a kid with nothing to lose to start a company in his parents' garage\n  - it's easy for a fortunate genius to make a living doing what she loves\n","n":0.104}}},{"i":5150,"$":{"0":{"v":"Pacific Coast Reproductive Society","n":0.5}}},{"i":5151,"$":{"0":{"v":"Ludum Dare","n":0.707},"1":{"v":"\n- dead\n- https://ludumdare.com/ \n\n## Related Solutions  \n  \n- https://github.com/SWI-PrologTeamLudumDare32/LudumDare","n":0.333}}},{"i":5152,"$":{"0":{"v":"Knowledge Graph Conference","n":0.577},"1":{"v":"\n\n- [[p.hasSite]] https://knowledgegraph.tech/\n","n":0.577}}},{"i":5153,"$":{"0":{"v":"JS Gamedev Summit","n":0.577},"1":{"v":"\n\n- [[p.hasURL]]  https://jsgamedev.com\n","n":0.577}}},{"i":5154,"$":{"0":{"v":"EMAS","n":1},"1":{"v":"\n- url: https://emas.in.tu-clausthal.de  ","n":0.577}}},{"i":5155,"$":{"0":{"v":"International Conference on Computational Linguistics","n":0.447},"1":{"v":"\n\n\n- [[p.hasConferenceInstance]]\n  - [COLING 2022](https://coling2022.org/)\n    - [[p.hadLocation]]  South Korea","n":0.333}}},{"i":5156,"$":{"0":{"v":"2023","n":1}}},{"i":5157,"$":{"0":{"v":"Typedb","n":1}}},{"i":5158,"$":{"0":{"v":"Why We Need a Polymorphic Database","n":0.408},"1":{"v":"\n\n\n## Issues\n\n- document paradigm references via IDs:\n  - they're not pointers, they're just values and doc dbs aren't designed to use references\n  - \"document object mismatch\"\n- graph dbs have attributes as part of node structure, but relationships (modeled as an edge) leads to object-graph mismatch because a node and two edges represent an atomic relationship; also no n-ary relations, nested relations, or undirected/two-way relations\n  - ? but in object models, two way relations might get modelled with two directions\n\n## Semantic Integrity\n\n- matching integrity of polymorphic data\n- inheritance polymorphism\n  - with relational, patterns are:\n    - single-table pattern (big table with fields for each type)\n      - can't control \"type integrity\" for subtypes\n    - concrete-table pattern (one table for employees, one for contractors)\n      - can't enforce global uniqueness with IDs, so all references need multiple \n    - class-table pattern (employee table, permanent employees table, contractors table)\n      - can't enforce object identity\n    - rows are one-dimensional\n  - with documents\n    - \"polymorphic pattern\" (coupal et al, 2023)\n    - maintaining consistency is difficult\n    - using ObjectIDs are values, not pointers\n      - so deleting the target, there's a null reference\n        - i.e., no cascading delete\n  - graphs\n    - ![](/assets/images/2023-11-30-09-29-47.png)\n    - not possible to control the types of relationships that can be made between nodes\n      - so cannot enforce semantic integrity\n\n## Example: Simple Filesystem\n\n![](/assets/images/2023-11-30-09-32-04.png)\n![](/assets/images/2023-11-30-09-38-17.png)\n![](/assets/images/2023-11-30-09-39-13.png)\n![](/assets/images/2023-11-30-09-47-34.png)\n\n- for docDBs\n  - return types are hardcoded with unmions and lookups\n  - attribute interfaces are hardcoded\n  - ?\n- for graphDBs\n  - can use generic pattern matching for multiple return types, but\n  - attribute interfaces hardcoded\n  - type inheritance hardcoded\n- all require metadata hardcoded into polymorphic queries becuase\n  - queries do not represent the natural language meaning/intent\n\n## Summary\n\n![](/assets/images/2023-11-30-09-54-25.png)\n\n## Questions\n\n- Does TypeDB have Object-PolymorphicDB mapping technology (OPM?), a la ORM/ODM/OGM\n  - not yet\n- Why not just use in-memory object models with object serialization (say, to the filesystem) and then for requests, use streams/filters and programmatic/native code for queries and semantically-consistent updates?\n  - (misunderstood, but) databases are good for sharing the data, persisting it, etc. \n- it seems like you should be able to just update the string-based reference identity everywhere it occurs, just like a dendron Move Note or Refactor\n- ","n":0.053}}},{"i":5159,"$":{"0":{"v":"Type Theory as the Unifying Foundation for Modern Database","n":0.333},"1":{"v":"  \n- [[p.hostedBy]] @alvin-leung\n- [[c.actor.speaker]] @christoph-dorn\n\n- problems with relational, graph, document, triplestore/rdf:\n  - mismatch of conceptual and logical model\n    - object-relational mismatch, reification, multi-valued attributes\n    - lack of support for polymorphic and highly connected data\n  - no easy system extensibility and maintability\n    - imperative, long, complex, brittle queries\n    - no facility for composable, generic queries that are highly reusable\n    - ![](/assets/images/2023-11-16-09-07-33.png)\n  - semantic data integrity is easily violated\n    - no meaningful data validation due to no sufficiently expressive schemas\n    - data redundancies need to be carefully synced\n      - ![](/assets/images/2023-11-16-09-08-22.png)\n- ![](/assets/images/2023-11-16-09-09-55.png)\n- \"general theory of composable structure\" is a natural start point for re-inventing\n  - ![](/assets/images/2023-11-16-09-10-48.png)\n- typedb conceptual data model is a unification of relational, graph, and document\n- Modernization of Math\n  - classical relational algebra: sets and relations (aka predicates and predicate logic)\n  - modeling everything in sets and relations is non-practical\n  - composable systems: types and dependent type\n    - facts become data in types that can be referenced\n    - dependencies can be composed\n    - [[book.practical-foundation-of-modern-mathematics]]\n- crash course in type theory\n  - a type is a description of a domain that a variable can range over\n    - dependent types have definitions that include other variables\n  - in predicate logic, dependent pair types can compose\n- ![](/assets/images/2023-11-16-09-24-46.png)\n- type polymorphism\n  - inheritance polymorphism\n  - interface \"\n  - parametric \"\n    - defines generic functionality for (variabilized) types, enabling semantically generic queries\n- reasoning engine\n- result: a unifying foundation for modern database\n  - ![](/assets/images/2023-11-16-09-42-40.png)\n- summary:\n  - [[prdct.typedb]] implements the unifying type-theoretic, polymorphic paradigm\n  - so extensible, adaptable, safe and robust\n  - fast-evolving ecosystem","n":0.063}}},{"i":5160,"$":{"0":{"v":"The Metaverse Is Coming and It Could Be Dangerous","n":0.333},"1":{"v":"\n- [[p.hostedBy]] @louis-rosenberg\n- we need guardrails\n- people won't have a choice\n- augmented metaverse will follow iphone adoption\n- [[org.responsibile-metaverse-alliance]]; [[xr association|org.xr-association]]","n":0.224}}},{"i":5161,"$":{"0":{"v":"Lamina1 Unreal Workshop","n":0.577},"1":{"v":"\nt.2023.10.26.09\n\n#related: https://discord.com/channels/771063831387439134/1072828679425638430/1167134651035439124\n\n## Speakers\n\n- @ivystive\n- @chris-mahoney\n- @will-carter\n- @beardontheblock\n- @ryan-crucible\n\n## Prerequisites\n\n💫 Download this Unreal Package: https://tinyurl.com/3bh5tvrk\n💫 Set up a LAMINA1 Hub account & connect it to Metamask: https://tinyurl.com/mpsbd8vc\n💫 Have a code editor installed like #VisualStudio or #Rider\n\n## Highlights\n\n- Anyone who wants to request future workshop deep dives from our teams, leave feedback on the workshop, or contact us about working together on an upcoming Space/experience launch on LAMINA1, please fill out this form! https://blocksurvey.io/emergence-workshop-follow-up-form-s7tjFoH3RtO5pghC.Ly0sg?v=o\n- [ ] around 55min, mention of \"json data\"\n- Unity vs Unreal\n  - unreal has a couple more things, like keystore\n  - @will-carter 58:40 - json metadata\n\n## [[c.transcript]]\n\ndjradon\ndjradon\nOnline\nBeforeCrypto\n — \nToday at 9:22 AM\nemergenge sample not apearing in unreal\nAleissia\n — \nToday at 9:23 AM\nDid you download via the link provide or the marketplace? \n\nLink to download is here: https://github.com/CrucibleNetworksLtd/EmergenceSDKUnreal/releases/tag/v0.3.3\nGitHub\nRelease v0.3.3.1 · CrucibleNetworksLtd/EmergenceSDKUnreal\nThe plugin is also on the Unreal Engine Marketplace (for free)!\nAdditional Release files\nA sample project has been made to show how to make use of the Emergence plugin. It is supplied with a specia...\nRelease v0.3.3.1 · CrucibleNetworksLtd/EmergenceSDKUnreal\nBeforeCrypto\n — \nToday at 9:23 AM\ni have both\nAleissia\n — \nToday at 9:23 AM\nYou'll see there's a \"Lamina1UnrealSampleProject.zip\" there\nthat's where the sample project will be\nyou'll want to then open the EmergenceSample.uproject that is in that zip\nBeforeCrypto\n — \nToday at 9:25 AM\nyea i unzipped\nAleissia\n — \nToday at 9:25 AM\nOnce you open the uproject, it will build for you, and then this sample project should open for you inside Unreal. It normally takes a few mins to build the first time around.\nBeforeCrypto\n — \nToday at 9:27 AM\nThe following modules are missing or built with a different engine version:\n\n  EmergenceSample\n  Emergence\n  EmergenceEditor\n  EmergenceEditorMethodGraphPin\n  EmergenceEmailForm\n  EmergenceVRMSupport\n  VRM4U\n  VRM4ULoader\n  VRM4UCapture\n  VRM4UImporter\n  VRM4UEditor\n  VRM4UMisc\n\nWould you like to rebuild them now?\nAleissia\n — \nToday at 9:27 AM\nYes, rebuild\nBeforeCrypto\n — \nToday at 9:27 AM\nIts showing like this\nAleissia\n — \nToday at 9:27 AM\nthat's what takes a few mins to rebuild\nWilson\n — \nToday at 9:28 AM\nis it matic ?\nAleissia\n — \nToday at 9:28 AM\nSo just press YES there to rebuild. Once its done, the sample project will open up\nBeforeCrypto\n — \nToday at 9:28 AM\ndo i need to launch unreal now ?\nAleissia\n — \nToday at 9:28 AM\nNope once its done rebuilding it should auto-open the project for you\nWillCarter\n — \nToday at 9:28 AM\nIf you'd like to run a local RPC node for dev (more responsive) then you can follow the instructions here:  https://docs.lamina1.com/docs/Running-a-Betanet-Node#set-up-your-node and update the Default Node URL in Emergence to http://127.0.0.1:9650/ext/bc/C/rpc \nBeforeCrypto\n — \nToday at 9:28 AM\nok\n@Aleissia is video available for chris done today\nAleissia\n — \nToday at 9:30 AM\nYes this is being recorded as well\nBeforeCrypto\n — \nToday at 9:30 AM\nok\nhow long it will take to build\nEL | MALAMAYA\n — \nToday at 9:30 AM\ndo we still use metamask for l1 tokens?\nAleissia\n — \nToday at 9:30 AM\nand we have the step by step in our dev docs as well. Video for both this and yesterday's will be posted later today. We'll be sure to post in both discord & Twitter (X)\nYes still use MM for L1 Tokens!\nivystive\n — \nToday at 9:31 AM\nYou can definitely use MM to interact with LAMINA1. I've got instructions here on the best way to connect your LAMINA1 Hub account to your MM wallet: https://docs.google.com/document/d/18N2CVhD8xpSQRmaMl6qsM1WO4InGGJNauMFwx63_kFs/edit?usp=sharing\nWillCarter\n — \nToday at 9:32 AM\nSent 2 L1\nEL | MALAMAYA\n — \nToday at 9:32 AM\nthanks for this!\nBeforeCrypto\n — \nToday at 9:32 AM\nStill not build @Aleissia\nSifr\n — \nToday at 9:33 AM\nThe previous wallet address was coinbase\nAleissia\n — \nToday at 9:33 AM\nWhat version of Unreal are you running? And do you see the progress bar going still?\nivystive\n — \nToday at 9:34 AM\nwhooops\nBeforeCrypto\n — \nToday at 9:34 AM\n5.3\nEL | MALAMAYA\n — \nToday at 9:34 AM\nhow do we get to the L1 Betanet network in Metamask?\nSifr\n — \nToday at 9:34 AM\n🤦🏽‍♂️\nAleissia\n — \nToday at 9:34 AM\nUnreal 5 sadly doesn't show the progress when it's building. Meh they removed that in 5. Maybe try reopening the uproject again.\nBeforeCrypto\n — \nToday at 9:35 AM\noh damn'\nit showing to rebauild again\nAleissia\n — \nToday at 9:36 AM\nDo yes again, Unreal is normally smart enough to only rebuild what hasn't been built yet 😉 normally\nWe can also jump on with you directly to help you get setup after this @BeforeCrypto !\nBeforeCrypto\n — \nToday at 9:36 AM\nNormally :sip:\nBeforeCrypto\n — \nToday at 9:37 AM\nIf video guide available that will good\nAleissia\n — \nToday at 9:38 AM\nYup all will be available! Also here's the dev doc that is step by step for getting things setup! \n\nhttps://docs.emergence.site/game-engines/unreal/getting-started\nGetting Started\nRequirements, Installing the plugin and opening the overlay.\nGetting Started\nBeforeCrypto\n — \nToday at 9:38 AM\nEmergenceSample could not be compiled. Try rebuilding from source manually.\nEL | MALAMAYA\n — \nToday at 9:38 AM\nHow do we get to the L1 Betanet network in Metamask?\nBeforeCrypto\n — \nToday at 9:38 AM\nnow showing like this @Aleissia\nJackalgirl (she/her)\n — \nToday at 9:38 AM\nhttps://docs.lamina1.com/docs/the-l1-staking-wallet/#connecting-metamask-to-the-lamina1-betanet - if you need to add it as a custom network.\nOkay, so while we're playing this demo to see how it works, we need to have Polygon (and MATIC tokens) for the Emergence avatar side of things, and the L1 Betanet and L1 Betanet tokens for the trophy minting, is that correct?\nAleissia\n — \nToday at 9:41 AM\nYes that is correct. Neither are musts but there's 2 mint options in this project: \n\n    L1 will allow you to mint the L1 Trophy.\n    Matic will allow you to mint your own VRM Avatar. So you can test out the whole flow of then having an avatar tied to your persona.\n\n\nAs a note, if ever you have another NFT Avatar you would love to use, we can help you get that setup, if it isn't already registered in our Emergence Avatar System.\nAlchemist 19\n — \nToday at 9:44 AM\nYou guys totally rock!!!\nSifr\n — \nToday at 9:44 AM\nJust realised I signed up to Lamina1 through email, so my address is actually 0x676E706aE6a7475bB2629E1011e942e619040fb1\nWillCarter\n — \nToday at 9:45 AM\nYou're bleeding me dry\nAleissia\n — \nToday at 9:45 AM\nGameplay Examples of some things you can do with Emergence. Here you can see examples like: \n\n    Token gated areas\n    Trading with NPCs (NFT Trading)\n    Using our DynamicMetadata to add extra info to your NFTs\n    Picking up collectibles / coins in game.\n    A jukebox that streams your NFT music\n\n\nLoads more you can do! \nhttps://www.youtube.com/watch?v=X5ADCzW9QWs\nYouTube\nOpen Meta\nEmergence Examples in The Lab\nImage\nBeforeCrypto\n — \nToday at 9:46 AM\n@Aleissia looks like emergence pulgin installed, dont know how to open that\nSifr\n — \nToday at 9:46 AM\nIt's betanet so the token is worth null, spread the love brother lol.\nJackalgirl (she/her)\n — \nToday at 9:46 AM\nAwesome, that makes a lot of sense (and gives me something to do to troubleshoot the issue I was having with the Unity demo).  I presume that we could retool the avatar system so that it works on the Lamina1 blockchain (provided that we either provide, or there is present, a comparable contract on Lamina1)?  I know this would not make it work across the whole Emergence ecosystem, but I'm just thinking of ways to keep things simple for Lamina1 users (to keep everything within the Lamina1 network, and users needing only the one token).\nAleissia\n — \nToday at 9:46 AM\nRight after were done here, @Chris could hop on with you! Makes me think it's a 5.3 issue! But i'm sure Chris can get a version working for u once this is done!\nChris\n — \nToday at 9:47 AM\nhttps://youtu.be/X5ADCzW9QWs\nYouTube\nOpen Meta\nEmergence Examples in The Lab\nImage\nAlchemist 19\n — \nToday at 9:48 AM\nHey @Jackalgirl (she/her) make sure you develop a working understanding here.\nI just dropped in. I was teaching a class\nAleissia\n — \nToday at 9:48 AM\nFor Avatars specifically. We currently have our system working for Ethereum and Polygon. But we can def add in support for L1! \n\nSomething we spoke about with @g0rd0 😉\nWe have a custom indexer and I know we both would love to extend it to index all NFTs (avatars included) for L1!\nAlchemist 19\n — \nToday at 9:48 AM\nI am sure I will quickly catch up. Hello @ivystive\nivystive\n — \nToday at 9:49 AM\nHello, Alchemist19! How are you today?\nJackalgirl (she/her)\n — \nToday at 9:49 AM\nGLEE\nAleissia\n — \nToday at 9:49 AM\nLove this example too. Avatars could be used as AI Pets too, not just your own avatar 🙂\nAlchemist 19\n — \nToday at 9:50 AM\n@ivystive just digesting what's here so we can guide the gang\nAleissia\n — \nToday at 9:51 AM\nIn future workshops. We want to dive into loads of these examples! This first 101 was meant to be able to show the basics of getting setup. And the basics of how to use the read / write functionality. From there though, future workshops will show how to use the read / write for loads of gameplay examples!\nAlchemist 19\n — \nToday at 9:51 AM\n@Aleissia awesome work thus far\nAleissia\n — \nToday at 9:54 AM\nWe have a BOUNTY for todays workshop! Make sure to take a screen shot of the super secret code and submit it via this link: https://www.openmeta.xyz/bounties/submit/653a6502825d9fd8c64c5f41\n\nCode will be posted shortly!\nOpen Meta\nOpen Meta\nDominith\n — \nToday at 9:56 AM\nGreat workshops today and yesterday! Thank you all very much for sharing this. 😊\ndjradon\n — \nToday at 9:56 AM\nFrom the Emergence perspective, are there any significant differences between Unity and Unreal?\nivystive\n — \nToday at 9:57 AM\nAnyone who wants to request future workshop deep dives from our teams, leave feedback on the workshop, or contact us about working together on an upcoming Space/experience launch on LAMINA1, please fill out this form! https://blocksurvey.io/emergence-workshop-follow-up-form-s7tjFoH3RtO5pghC.Ly0sg?v=o\nEL | MALAMAYA\n — \nToday at 9:57 AM\nI'm not a really good game developer, but I do make 3D assets. How can I contribute to Lamina1?\nAleissia\n — \nToday at 9:57 AM\n@BeforeCrypto  Chris said he can jump on with you right after this. There was an issue in 5.3 but it was fixed. But he can jump on with you after this to find the issue with you!\nivystive\n — \nToday at 9:57 AM\nReach out to us at ecosystem@lamina1.com. We're also looking for asset collection creators 🙂\nAleissia\n — \nToday at 9:59 AM\nUnity and Unreal are meant to be feature parity, a few additional features today in Unreal but goal is to get to full feature parity for Emergence.\n\nFrom an engine perspective, Unreal is alot more visual designer focused because of blueprints. Which can be great for non-coders. \nChris\n — \nToday at 9:59 AM\nwould you be able to post the log file?\nEL | MALAMAYA\n — \nToday at 9:59 AM\nWhat do I say? I'm keen on making assets for games and metaverse platforms 🍻\nChris\n — \nToday at 10:00 AM\nthere might be a build log file in saved/logs\nivystive\n — \nToday at 10:00 AM\nYes. And share us the kind of assets, tech details, screenshots or images of what you make. Website, etc etc\nBeardOnTheBlock\n — \nToday at 10:00 AM\nSCREENSHOT THIS CODE!!\n\nLAMINA1OPENMETAFRENS\n\n(This is for the bounty)\nivystive\n — \nToday at 10:00 AM\nhttps://hub.lamina1.com/ 💫\nCome visit us!\nBeforeCrypto\n — \nToday at 10:02 AM\nwhen i open emergence sample, It showing \"EmergenceSample could not be compiled. Try rebuilding from source manually.\"\nChris\n — \nToday at 10:03 AM\ndid the saved folder get created?\nivystive\n — \nToday at 10:04 AM\nSurvey: https://blocksurvey.io/emergence-workshop-follow-up-form-s7tjFoH3RtO5pghC.Ly0sg?v=o\nRyanCrucible\n is now a speaker.\n — \nToday at 10:04 AM\nJackalgirl (she/her)\n — \nToday at 10:04 AM\n@ivystive if we filled it out for Unity, do you want it again for Unreal?\nMAiWORLD\n — \nToday at 10:04 AM\nQ: for dynamic metadata, would this be a seperate layer of metadata that can applied to already existing NFT collections?  and this layer of metadata would not be on chain?  i.e. used specifically for in-game logic**\n\nfollow up:  would there be a way to allow this dynamic metadata to be written and thus change an NFT's actual on chain metadata?  like it's artwork or a type of metadata that is already on chain?\n\nhope that makes sense ty \nAleissia\n — \nToday at 10:05 AM\nWould be great if you guys can create a chat together, since this chat will go away once the event is done\nBeforeCrypto\n — \nToday at 10:05 AM\ni can t find any project name with emergence sample in unreal\nChris\n — \nToday at 10:05 AM\ncan you create a thread about this in \n⁠🪧︱emergence-topics pls :)\nEL | MALAMAYA\n — \nToday at 10:06 AM\nI just sent an email! Looking forward to your reply, cheers!\nBeardOnTheBlock\n — \nToday at 10:06 AM\nSCREENSHOT THIS CODE!!\n\nLAMINA1OPENMETAFRENS\n\n(This is for the bounty)\nWillCarter\n — \nToday at 10:06 AM\nThere are some interesting ways to do this by wrapping existing NFTs to extend functionality. It raises questions about who is allowed to extend functionality and how to use that functionality which we're working on\nAleissia\n — \nToday at 10:06 AM\nGreat question! \n\nAs of right now, this is a way to add additional metadata to NFT collections. That is currently saved off-chain with using all the authentication / etc of what the owner of the NFT sets for it. \n\nWe are also building out standard templates so NEW nft creators can utilize that as well. \n\nGoal is to be allow any creator / developer to treat an NFT like a game object. Read/Write based on the permissions the owner sets.\nFuture workshop JUST on Dynamic Metadata would be fun!\nWillCarter\n — \nToday at 10:07 AM\nOh yeah Dynamic Metadata workshop would be cool\nBeforeCrypto\n — \nToday at 10:08 AM\n⁠Unreal 5.3.1\nMAiWORLD\n — \nToday at 10:08 AM\nsuper cool, thank you, and yes need that dynamic metadata workshop haha\n﻿","n":0.022}}},{"i":5162,"$":{"0":{"v":"Lamina1 Unity Workshop","n":0.577},"1":{"v":"\nt.2023.10.25.09\n\n- url: https://www.youtube.com/watch?v=eLpAel6Ao9A\n- [[p.basedOn]] [[prdct.emergence-sdk]] [[prdct.solidity]]","n":0.408}}},{"i":5163,"$":{"0":{"v":"Getting_started_with_fluree","n":1},"1":{"v":"\n\n- Use of Data is evolving\n  - Solution: Collaborative Data Network\n  - semantics of data shouldn't sit in the app\n  - web3 semantics standards (rdf, owl, shacl); [[t.km.knowledge-graph]] [[c.Software.Database.Graph.Property]]; [[prdct.JSON-LD]]; [[prdct.fluree.flureeql]]\n  - decentralization\n    - cryptographically provable identities\n    - real-time distributed ledgers\n    - trustless\n    - programmable logic (i.e., [[t.cs.blockchain.contracts]]\n      -  \"much of programmability can be contained in the data and its constraints\"\n  - ![](/assets/images/2023-12-07-08-10-51.png))\n  - [[t.cs.data.time-travel]]\n- Collaboration\n  - Fluree's immutability allows rewind\n  - Compose Queries across data\n  - future: reasoning and inferencing\n\n\n## Questions\n\n- Q: how do you represent relations, ie. object properties\n  - A: Here's a link to this in our docs, David! https://developers.flur.ee/docs/learn/tutorial/working-with-graph-data/#graph-crawling-in-our-select-clauses\n- Q: can @type have multiple keys, i.e., multiple inheritance/class-membership\n  - A: Yes absolutely! Any instance can explicitly belong to multiple types, and inheritance can be multi-tiered\n- no need for [[t.cs.data.object-relational-mapping]]\n- Q: do you see a need for some kind of object mapping SDK for marshalling data into code? maybe you have recommendation for existing json-to-plain-old-*-objects libraries?\n  - A: It depends on your programming language as to if this is desirable or not. Many today are very comfortable working directly with data structures as a first-class citizen, but we may have some speciifc library support for languages that very object-centric. Even something like Java would be fairly easy to have a contructor to put JSON into an object without a library hopefully.\n- Q: There's Time-Travel support for \"Transaction Time\", but do you have any thoughts about time-travel for \"valid time\", aka \n\n### Other people's questions\n\n- Q: the current example seems related to foaf ontology, do you have predefined vocabularies available like vcard, dc, skos, etc?, or do we have to include them from scratch?\n  - A: The demo isn't using any pre-defined vocabulary, but absolutely can use any RDF-based ontology. Inferencing is largely limited today to RDFS-based descriptions, but we do have some limited OWL-based ontology support which I mentioned will be much more broad shortly (and in a very unique Fluree-like way).\n- Q: is there support for delegation/policy chains? For example: Person A has created the database. Person B gets read and write access to entity type A and B. In the case of a delegation chain; person B would be able to give (a subset of) the rights to what it can do to yet another person\n  - A: Since policies are data, you can make policies about policies\n- Q: Access control?\n  - A: REBAC: relationship-based access control\n    - simple rules\n  - A: multiple policy groups are \"only one has to succeed\" but you can express AND conditions","n":0.049}}},{"i":5164,"$":{"0":{"v":"Gamesbeat Summit","n":0.707},"1":{"v":"\n- [[c.sponsor]] [[org.spectrum]]\n\n## the future of mobile gaming\n\n- leaders are deeply entrenched; [[acquisition|t.cs.game.user-acquisition]] costs rising; innovation is pending/needed to unseat leaders\n- ops is continuous; \n\n## transforming gaming experiences with [[t.cs.ai]]\n\n- [[c.host]] @joost-van-dreunen\n- [[c.panelist]] @john-riccitiello\n  - built an inference engine ([[prdct.unity.barracuda]]) inside the runtime \n  - web3 is not going to be a big impact; vr/xr only by end of decade\n  - creation of content (ways we make games)\n  - games themselves i.e., engagement\n  - \"no one produces code or art in one shot with [[prdct.github.copilot]]\"; takes a lot of iteration\n    - you'll be more productive with the tools\n    - how are fully immersive, customized experiences going to happen?\n      - \"going to take a lot of experimentation, but the world is going to feel alive\" - most creators of open-world-style games have been dreaming about this! \"I can bring life into these characters\"\n      - going to \"lift our world\", more engagement = more revenue, \n      - no more stretching to use \"emergent\" and \"ai\" metaphors, it's going to happen\n  - As a player, how do you choose? role of intellectual property? \n  - Game Developers can do everything; open-source in this arena outperforms close platforms; \"big mega-caps don't have all the advantages they usually have\"; big opportunity for the little gals\n\n\n## Ready Player All: Launching Games at the Forefront of Culture\n\n- [[c.panelist]] @mike-quigley @assaf-sagy @rema-vasan\n- privacy considerations make [[t.cs.game.user-acquisition]] into marketers\n- @rema-vasan\n  - it's discovering through intersectionality (film creator, fashion designer, etc all have a role) beyond core gaming community\n  - \"culture is an esoteric word\" but analytics on hashtags\n- @mike-quigley NPS / Sentiment matters/moves-in-lockstep around live event or a new features; views matter, but need to give users permission to engage with their content! (\"they're going to do it anyway, so you might as well embrace it\")\n- Why is tiktok uniquely good? Flywheel! Brand handle. [[game.paridot]]\n- \"Funnel effect\" 1B views -> actually driving revenue streams\n- @mike-quigley \"building original IP is hard, and getting harder\";  \n  - gives assets to creators; authenticity means giving up control; microcommunities sustain themselves\n- awareness -> engagment -> performance\n- \"go beyond the gameplay\"  - what are the other communities; lean into the power of the creators and communities; experiment\n\n\n## From Niche to Mainstream: The Path to Mass Adoption of Blockchain in Gaming\n\n- [[c.panelist]] @mark-otero\n\n- @paul-bettner\n  - making [[game.wildcard]]\n  - what happens when there's a good web3 game?\n  - AI biggest effect is (game-creation) tools; because the tools are text-oriented, \"not so impactful\"\n- @canaan-linder\n  - new platform can still bring in web2 players\n  - \"bring your identity to the game\"; bringing a history of you enables the NPCs\n- @mark-otero\n  - we all have 24 hours in a day; we look to self-optimize our day; we need to create something so good, it changes your rhythm of life; don't misplace the focus; \"lowest friction possible\"\n  - time-value paradox (a function to zero)\n    - person worth $1000/hr doesn't want to see the emerald sword he worked for on sale for $.25. \"The race to zero\";\n  - character classes:\n    - started with DM and players; now, there's the speculator\n      - need to design a game that appeals to all three, but nobody can wreck it for anybody else\n- @angela-dalton\n  - won't we want to express our social capital with ownership?\n- @mark-otero\n  - \"every game is a miracle that is a string of unknown tragedies\"\n  - needed a tool to see things as they are, so created \"philosophy of fun\"\n    - \"What is the aspiration?\"\n    - spirit of aspirations and dreams; a way to actualize their fantasies, feel powerful.\n    - web3 aspiration: wealth! (it's not traditional entertainment)\n  - AI is seemingly intelligent; has density clusters (intelligence) but not the wisdom \n    - wisdom is required to make the strategic choices\n- @canaan-linder\n  - a streamer can sign your sword. Transparency. Everybody indexing your data. \n  - it's okay not to know what the future holds\n\n## Power to the People\n\n- [[c.panelist]] @emmanuel-de-amistre @jordan-weisman\n- @jordan-weisman ceo of [[org.endless-adventures]]\n  - \"ai-cautious game creator\"; it's about the human artform; it's about how do we empower without overcoming; genies don't go back into bottles\n  - \"I want more people to be gamedevs\"\n  - loves narrative games\n    - \"blank sheet of paper\" is to intimidating; \n    - doesn't believe yet that writers/creators can express enough of the specifics/intent/emotion through the portal of LLM tools\n  - videogames have been exclusionary; AI will drive other voices and innovation\n  - start by making it accessible to \"no-code\"; AI has revolutionized accessibility\n- @emmanuel-de-amistre\n  - first product: lidar + photogrammatry to create 3d objects;\n  - transitioned into facilitating creation via prompt, including [[prdct.midjourney]];\n    - \"easy to create game objects for anybody\"\n    - a private midjourney\n  - 3d is 6 months behind 2d (text to 3d or 2d to 3d)\n  - driven by the players\n  - artists / art directors are the biggest fans of the product\n\n\n## Building the metaverse with open standards\n\n- [[c.panelist]] @marc-petit @royal-obrien @neil-trevett\n- @neil-trevett \n  - metaverse bringing together many disruptive technologies, each field interetsing in its own right \n  - \"open standard\" is just a contract between two entities about how they will communicate / interoperate\n    - scale up the economy\n  - we're trying to scale up more technologies than normal; there's no one standard organization that can solve\n  - open-source is implementation; open standards is still required; game engines \n  - \"where are the portable libraries\"\n  - [[t.cs.augmented-reality]] needs open standards so you can see the hat on different platforms; \n  - [[t.cs.game.user-generated-content]] needs open standards to preserve everyone's ghost\n  - [[t.cs.web3]] is the public ledger for reputation, economy, etc.\n- @royal-obrien\n  - the receipt is separate from the transaction\n  - [[prdct.webgpu]] bridges the gap, there's progress; there's no tax, and it's not going to disappear; but it's complex and lagging;\n- [[user.neil-trevett]] maybe we need a new transport protocol, maybe a new browser application; metaverse will be an interesting darwinian experiment\n- privacy / cybersecurity / identity is at the top of the list for [[org.metaverse-standards-forum]] members; need to build security into the standards\n- [[prdct.hyperledger]] and [[org.open-wallet-foundation]] are examples of open standards\n\n## leverage ai for launch content\n\n- ai so far: machine learning & workflows; generative ai for asset creation; expanded npc roles and realism\n- @daniel-evans\n  - \"emotional response index\" ERI\n  - NLP, Audio & Sentiment analysis\n  - What if... leverage AI to extend the storytelling beyond the game with UGC interactions\n  - DDB Paris created \"NPC campaigns\" for [[game.assassins-creed-odyssey]]\n  - AI builds the backstories (LLM with guardrails), do the marketing\n  - \"everybody can have their personalized trailer\"\n  \n## next-gen mixed reality\n\n- @alexey-menshikov\n- [[t.cs.mixed-reality]]\n- [[t.cs.augmented-reality]] uses [[t.cs.augmented-reality.simultaneous-localization-and-mapping]]\n","n":0.03}}},{"i":5165,"$":{"0":{"v":"Flatiron Tabletop Game Design","n":0.5},"1":{"v":"\n- [[p.hostedBy]] @joshua-robinson @alyssa-osterback\n- [[p.hadPanelist]] @zach-saul @tyler-entingh \n- resources:  https://boardgamegeek.com\n\n- Where is the overlap between product design and tabletop game design\n  - user psychology: \n    - what hooks people\n    - what's too boring/complex\n  - visual design principles\n  - \"exploration and validation\": \n    - design thinking [[double diamond|t.pdm.design.double-diamond]]\n  - system mechanics\n    - comes down to a knowledge of design patterns\n  - user experience\n    - information architecture (IA)\n      - What is the path from A to B\n      - User decision space\n      - outcomes and goals\n    - users come in with preconceived mental models... cognitive load is less when your game fits into their schemas\n- defining the project\n  - ![](/assets/images/2023-01-11-10-18-48.png)\n  - design principles, e.g.:\n    - depth > complexity\n    - simplicity > fidelity\n    - avoid rigid narratives\n    - best strategist should would\n  - constraints\n    - mechanics\n      - e.g.\n        - dice rolling\n        - end game bonuses\n        - grid coverage\n        - hex grid\n        - pattern building\n        - set collection\n        - tile placement\n        - turn order: stat-based\n        - variable set-up\n        - worker placement\n      - complexity and player cognitive capacity\n      - what mechanics are removed/added/changed for different player counts\n      - solo play\n    - categories\n      - ![](/assets/images/2023-01-11-10-23-47.png)\n- [[t.management.swot-analysis]]\n- [[t.pdm.ux.prototyping]] gives you high-level buy-in\n- [[p.mentioned]] [[prdct.tabletopia.workshop]]\n- players get frustrated waiting for other players\n  - like axis&allies\n  - turn-based is inherently frustrating, so give people something else to do when it's not their turn\n- analysis\n  - satisfaction\n  - time to goal\n  - avg # turns/moves/card to goal\n  - qualitative\n    - Did you feel like you agaency\n- \"build your design process around playtesting. everything else is theorycraft\"\n- [[t.pdm.design.visual]]\n  - color can \n    - create categories\n    - indicate interactivity\n    - create separation\n- ![](/assets/images/2023-01-11-10-54-23.png)\n- What is interesting?\n  - fun vs challenging\n  - sweet spot of interestingness\n    - ![](/assets/images/2023-01-11-10-55-12.png)\n      - obvious vs absurd\n      - relevant vs irrelevant\n    - enhances memory\n    - enhances motivation\n    - emotive response\n  - triggers of fascination\n    - pleaure\n    - mystique: puzzling, being part of a secret\n    - alarm\n    - prestige\n    - power\n    - vice\n    - trust\n  - theory of fun:\n    - when we find and master new patterns of thought\n    - to master a game, we have to figure out certain patterns\n    - once we've done it, the game is not as much fun\n    - if we can find any patterns, the game is too difficult and not  fun.\n    - games tend to be most fun when pushing us to the edge of our capabilities while simultaneously giving us a sense that master is a real possibility\n    - ![](/assets/images/2023-01-11-10-59-25.png)\n      - if we are fascinated, we will have fun looking for patterns\n      - disruption is often resisted because it takes energy","n":0.048}}},{"i":5166,"$":{"0":{"v":"Bpmn_for_profit_and_fun","n":1},"1":{"v":"\n- used [[prdct.lucidchart]] to design\n\n![](/assets/images/2023-11-28-09-47-02.png)\n\n- Process, before you start coding, and iterate\n![](/assets/images/2023-11-28-10-00-09.png)\n- use Event Storming\n- try \"tab per process\"\n\n## Pitfalls\n\n- no begin or end event\n- activities do not have action verbs\n  - i.e., commands\n- activities named after technical aspects\n- flows start to have too many elements\n  - add subprocess if necessary\n  - break diagrams out into blackbox, just showing interface points\n\n## Takeaways\n\n- Focus on what matters\n- Capture the dependencies between domains/products\n- add as part of iterative development lifecycle\n\n## Resources\n\n- https://medium.com/ssense-tech/bpmn-for-profit-and-fun-seamless-teams-collaboration-in-software-development-2fdd09d018d8\n- [tutorial](https://www.youtube.com/watch?v=BwkNceoybvA&t=58s)","n":0.111}}},{"i":5167,"$":{"0":{"v":"Emails","n":1}}},{"i":5168,"$":{"0":{"v":"Ontolog","n":1}}},{"i":5169,"$":{"0":{"v":"Technical Question on Protege","n":0.5},"1":{"v":"\n- ironically, quickly evolved into a thread on the importance of [[t.km.formalization]]","n":0.289}}},{"i":5170,"$":{"0":{"v":"Will Stepn Bring Crypto to the Masses","n":0.378},"1":{"v":"\n- [[p.hasAuthor]] @nat-eliason\n\t\nWill STEPN Bring Crypto to the Masses?\nHow I made $357 today on walks with my family\n\t\nNat Eliason\nApr 15\t\n\t\nComment\n\t\nShare\n\nI made $357 from walking today. \n\nI’m not a professional athlete, I don’t have sponsors, I didn’t have to get a brand tattooed on my forehead. I was using STEPN, a new Web3 Fitness app. \n\nSTEPN allows you to earn crypto from walking, jogging, and running. They’ve gamified fitness with a “Move to Earn” model (Play to Earn with extra steps) where the app is able to track your exercise similar to Strava or Map My Run, then reward you with crypto for completing activities. \n\nTo play, you need their special sneaker NFTs. These NFTs have various attributes that affect how quickly and efficiently they earn crypto, and yes, there’s sneaker breeding. \n\nAfter playing for about two weeks now, I’m regularly earning $300-400 a day. That’s a six-figure salary just for going outside and spending time with my wife, kid, and dogs. \n\nThat’s completely insane, totally unsustainable, and a giant Ponzi waiting to collapse. \n\nRight? \n\nThis one’s weird. There’s something here. Something that I honestly haven’t seen with any other Web3 game. STEPN might be the best-designed Play and Earn game to hit the market, and the more I dig in, the more excited I get about what they could be in the future. \n\nThis article is a marathon, not a sprint. We’re going to cover: \n\n    How STEPN Works \n\n    How to Get Started\n\n    STEPN’s Tokenomics\n\n    The STEPN Bear Case\n\n    The STEPN Bull Case\n\n    My Investing & Playing Strategy\n\n    What to Watch\n\nAlso a quick thank you to Matthew Barby of the Decrypting Crypto Podcast for turning me on to STEPN, giving me some initial advice on getting started, and answering my many questions about the game.\nHow STEPN Works\n\nYou use STEPN similar to how you would use any other running app like Strava. \n\nWhen you want to go for a walk, jog, or run, you open the app, select the sneaker that corresponds to the speed you’re going to exercise at, and hit start. The app starts tracking your movement and steps, and awards you GST (their in-game token) based on the duration of your activity. \n\nThe longer you exercise for, the more GST you earn. It doesn’t matter how fast you move, so long as you’re within the acceptable speed range for the shoe you’re wearing (you can’t run with your walking shoes on, for example). \n\nAs you earn GST, you can reinvest it into your shoe to increase its earning potential. You spend GST to level up your shoe, and each time it levels up, you get to increase its stats. The four stats are: \n\n    Efficiency: How much GST you earn\n\n    Luck: How likely you are to get a mystery box\n\n    Comfort: How much GMT you earn after level 30 \n\n    Resilience: How slowly your sneaker degrades\n\nYour shoe also wears down as you use it, and you’ll need to spend GST to repair it. The higher your resilience, the slower it will wear down. \n\nThen the final thing you can spend GST on for your sneaker is minting. If you have two sneakers at level 5, you can spend GST to mint a new sneaker. Minting more sneakers is helpful since the number of sneakers you own determines how much energy you get per day: \n\t\n\t\n\nAs you can see, the additional energy you get per sneaker trends down over time: \n\n    From 0 -> 1, each sneaker is worth 2 energy\n\n    From 1 -> 3, each sneaker is worth 1 energy\n\n    From 3 -> 9, each is worth 0.833 energy\n\n    From 9 -> 15, each is worth 0.5 energy\n\n    From 15 -> 30, each is worth .533 energy \n\nEach energy only gives you so much activity time. So if you have 1 sneaker, you only get to earn for 10 minutes. With 9, you get 45 minutes of Move and Earn time. Getting to 9 sneakers makes sense, then it quickly dies off after that. But having a small army of people with 1 sneaker each would technically be the most efficient. \n\nA basic walker will earn 5 GST per 1 energy, so at today’s price of $4.80, that’s $24 per energy. If you bought the cheapest walker for 10 SOL, approximately $1,050, you could earn that back in about 22 days. Plus you’d still have the sneaker which should be worth the same amount. Imagine if driving your car for 22 days earned you the initial cost of the car!\n\nBut that’s assuming you sell your GST as soon as you earn it. And despite the high value of GST, it’s tempting to use it instead of sell it. \n\nYou’ll want to invest some into leveling up your sneaker so it can earn more and doesn’t wear down as fast. And you’ll have to spend some GST on repairing it. And you might want to save up so you can mint more sneakers. The game is very good at hooking you into spending your GST within the system instead of selling it. \n\nBut the biggest thing you’ll spend GST on is minting. Minting is STEPNs version of breeding, and it lets you create a new shoe from two of the shoes you already have. \n\nThe math on breeding is quite good. It currently costs 200 GST to mint from two commons, and you’ll most likely get another common which will be worth 10-12 SOL. So you’re spending $​​960 to make $1,050. But you can’t do this forever, since the cost increases after the first two mints, and you need to get a sneaker to level 5 before you can mint with it. So there are some checks in place to prevent runaway sneaker breeding. \n\nIn addition to those primary earning elements, they also have a few lottery systems that add to the fun, and make it a little tougher to do simple math on the ROI of various activities. \n\nOne of those lottery systems is Mystery Boxes. If you use more energy, and have a high Luck score on your shoe, you have a chance of getting a mystery box at the end of your run. These boxes contain gems, which you can sell on the marketplace or put into your shoes to increase their stats. My runner, for example, has an efficiency gem which is increasing its efficiency by 2. \n\t\n\t\n\nShoe minting also has some lottery elements attached. When you combine two shoes to mint a new one, what you actually get is a shoebox:\n\t\n\t\n\nThen when you open the shoebox, you have a chance of getting a different rarity shoe than the shoebox: \n\t\n\t\n\nAnd the type of shoe (Walker, Jogger, Runner, Trainer) also affects what type of shoe you unbox:\n\t\n\t\n\nSo it’s not as simple as two common walkers making a new common walker. That’s most likely to happen, but you could get something else entirely! And that chance of getting a super valuable Uncommon or Rare, or getting a Trainer from your Runner (typically Trainers are the most expensive, Runners the least) adds an interesting element of luck to the whole thing. \n\nYour typical workflow to maximize your earnings then is to use up your energy every day, maximizing the GST you earn. Then you spend that GST leveling up your shoes, and when you have two shoes at level 5, you spend GST to mint a new one. Then you can sell a shoe, or save the new one for your collection to try to increase the amount of energy you have. And at some point if you get bored of minting, you can just sell your daily GST earnings.\n\nGetting paid to walk your dog while breeding imaginary sneakers sounds pretty sweet. How do you get all of this started though?\nGetting Started with STEPN\n\nSTEPN is a crypto game, so you need some crypto to play. Specifically you need some SOL on the Solana network. If you’re not already set up on Solana, I have an article for that. \n\nYou’re going to need about 11 to 12 SOL minimum. This is a meaningful upfront cost just to play a game, and I know it will price a lot of people out. STEPN is releasing sneaker “leasing” where you can borrow someone else’s sneakers and split the earnings with them, but that’s not out yet, so if you want to play for free you’ll have to wait a few months. \n\nIf you do want to play now though, you’ll need the STEPN app next. Go to your app store, download STEPN, and create an account. \n\nNow the big barrier you’re going to run into is the Activation Code. You need to get one from someone else who’s playing the game if you want to play. Everyone who already has STEPN gets one activation code per 10 energy they spend exercising, assuming their last code has been used. Here’s one for whoever finds it first: 72886319. \n\nYou can ask in the STEPN Discord for a code, but it’s kinda chaotic. Your best bet is to find a friend who you can ask for one. I’m trying to get a batch for the newsletter as well, and I’ll let you know if I do. It’s a pretty clever system honestly, but makes it hard for me to share codes in a newsletter format like this. I will also periodically share them on my Twitter.\n\nAssuming you’re able to get an activation code, then what? Next you’ll set up a wallet in the app which you can send your Solana to for buying sneakers with. You could import your existing wallet into the app, but that’s not particularly good security so I recommend making a new one in their app like they recommend. \n\nOnce that’s done, you can transfer in some SOL, then transfer it from your Wallet to your Spending account. \n\t\n\t\n\nThe Spending account is basically an off-chain wallet within the game where you can spend SOL and GST for all your game activities. You can buy sneakers with SOL right in their marketplace within the app, without having to confirm transactions or anything. It’s quite slick. One of the better off-chain to on-chain bridges in an app that I’ve seen. \n\nSo once you’ve deposited your SOL to your wallet, and sent it into your spending account, you’ll need a sneaker. Maybe multiple depending on how much daily energy you want. If you want my specific strategy, scroll down to that section of this post. \n\nNow here’s the next barrier: sneakers are expensive. They’re going to introduce Renting at some point, where you can just rent someone else’s shoes and share the proceeds with them, but until then you have to buy them. \n\nThe most basic shoe, with 0 mints and 0 levels, will currently cost 12.5 SOL depending on what speed you get. If you get one that already has 2 mints, you can usually save 1 or 2 SOL, but you won’t be able to mint as cheaply with it. \n\nYou also have to decide what kind of sneaker you want. Runners require you to actually run (8-20 km/hr). Walkers let you walk (1-6 km/hr). And Joggers are in the middle (4-10 km/hr). If you move outside this speed range when exercising you stop earning, so it’s important to pick the right one for how you want to play. \n\t\n\t\n\nIf you just want one sneaker, you’re looking at a $1,000 investment. If you want 20 minutes of activity, you need 3 sneakers, so $3,000. And if you want any uncommon or rare sneakers which can potentially earn much more, you’re looking at a significantly larger investment still. This is also the primary way STEPN makes money. They take a cut of all marketplace fees. \n\t\n\t\n\nWhen I started playing, I bought about $12,000 of sneakers. I know that’s kinda absurd, but it got me an uncommon walker and runner, as well as some commons for minting with. Your number of shoes and their levels determine how much energy you have and what your max GST earnings per day are, so having more and leveling them up makes a big difference. \n\t\n\t\n\nIf the sneaker price sustains for a while, I’ll make that back. But I also could have bought the top and it’s about to crash. Who knows! Crypto is exciting, right? \n\nAnyway, once you have your sneakers, you’re ready to roll! Pick the pair you want to exercise with, hit start, and get moving. You’ll see your rewards accruing as you walk, jog, or run. \n\nFrom there, you’ll just have to decide how to use the GST you’re earning. Do you level your sneakers up? Try minting new ones? Sell it as soon as you get it? It’s all part of the game.\n\nObviously the long-term sustainability of this game relies heavily on their tokenomics, so let’s look at that next. How do their two tokens: GST and GMT work? \nSTEPN Tokenomics\n\nLike Axie, Crypto Raiders, and many games coming into the crypto market, STEPN has a two token model: \n\n    GMT is their governance and value token\n\n    GST is their in-game spending token \n\nYou primarily earn GST from playing the game (though you can eventually earn GMT too), and need to spend it in order to make progress. GMT you can hold as an investment, and will apparently need to spend for certain in-game activities in the future as well (though this is not implemented). \n\nLet’s start with GST since that’s the one you’ll interact with much more in the game economy at first. \nGST Tokenomics\n\nAs soon as you start playing STEPN, you’re earning GST. You earn GST for each minute of activity, depending on the Efficiency of your shoe. \n\nAt the token level, GST is simple. It’s an infinite supply token with constant minting and burning, and it’s not something you should hold as a long term investment. Keep enough for the next use case in the game, and sell the rest. \n\nThe in-game economy around GST is more interesting than the on-chain tokenomics. A walker with 0 efficiency earns about 1 GST per minute, while a runner with 0 efficiency earns 1.3 per minute. \n\nThis is the only “faucet” for GST right now. All GST has to be created by someone going out and walking, jogging or running. As far as I know they don’t sell any into the market, or emit any through other means. \n\nWhy is GST valuable though? Right now GST is trading between $4 and $5 most days, which seems insanely high given you can earn 1 per minute while you have energy.\n\nBut people are buying it because you need GST in order to do anything else in the STEPN economy. Specifically:\n\n    To level up your sneakers\n\n    To mint new sneakers \n\n    To repair your shoes \n\n    To unlock gem sockets\n\n    To create better gems\n\n    To speed up mystery box openings\n\nAll of these use cases increase the amount of GST or other rewards you earn. So while you could just buy a level 0 sneaker, exercise with it every day, and sell your GST on the market, you might do better by investing more into the game first. \n\nFor example, my walkers are level 15 and currently earn 1.4 GST per minute instead of just 1. So by leveling them up over the course of two weeks, I’ve increased their earning rate by 40%.\n\t\n\t\n\nIt costs a total of 145 GST to get to level 15. So after 362 minutes of activity, I’ll have gotten to ROI positive on that investment. I can do 55 minutes of activity per day, so it’ll take me about a week to pay that investment off. That’s pretty good. \n\nYou also have to repair your shoes periodically if you want to keep earning with them. When they get below 50 durability, they lose 10% of their earning power. When they get below 10%, they lose 90% of their earnings. So you’ll have to repair them, and that can get expensive. I repaired my runners last night from 50 to 100, and it cost 31 GST. \n\nThe big cost is minting though. If you want to mint a new sneaker from two commons, it’s going to cost 200 GST. If you want to mint using two uncommons, it’s 800 GST! So like other games, creating new NFTs is still the big sink.\n\nThe variety of sinks is one area where STEPN does a much better job than many other games though. Minting is still the big source of ROI, but they have many many other uses for GST besides just minting. They’re pulling a lot of it out of circulation without increasing the amount of sneakers in circulation, which is great for the sneaker values and sustainability of the game. \n\nBut, every way of using GST increases how much GST you can earn, which is obviously a big problem. That can’t go on forever without crashing in some horrific way, so they’ll need to figure out other ways to pull GST out of the system soon to prevent a future meltdown. \n\nWe’ll talk about that a bit more in the bull and bear cases. Let’s now cover GMT. \nGMT Tokenomics\n\nGMT is the governance and value token for the STEPN ecosystem. It’s the one that’s more like holding stock in the company, so if you want to invest in their token, this is the one you’re looking for. \n\nTheir litepaper shares quite a bit of information about how it’s unlocking. Their allocation is typical, maybe a little light on the community allocation but still pretty good:\n\t\n\t\n\n    30% to Move and Earn\n\n    30% to Ecosystem / Treasury (unclear how this gets used)\n\n    16.3% to Private Sale\n\n    14.2% to Team\n\n    7% to Binance Launchpad Sale (public sale)\n\n    2.5% to Advisors\n\n7% sold publicly, 30% being given away for free, another 30% being used for operations which usually means being sold at local tops to create treasury diversification, and then 33% held by investors, advisors, and team members. \n\nAs I covered in the Supply piece of my Tokenomics series, the way these tokens are emitted makes a big difference. STEPN provides a handy interactive graph to explain all this, including what % of tokens have been released to each group for any month in the future. This is phenomenally transparent and useful, I wish every team did this:\n\t\n\t\n\nOne thing that immediately stands out is their private round tokens are vested over three years, and they don’t start unlocking until 2023. That is honestly kinda insane. I rarely see 3 year vesting with a 1 year cliff on crypto projects, and it shows how committed STEPNs investors are to the long term. \n\nOnce 2023 arrives, there will always be more tokens held by investors and team members than the public, but that’s normal. The slowness of their token emissions, and having it planned out over 8 years, makes me more bullish on the value than the average project. Especially the average Solana project. \n\nThe other interesting thing about GMT is that it will have some utility in the game. They just expanded their GMT tokenomics on the site, and it seems like in the future you’ll be able to (or have to) use it for certain things like:\n\n    Reaching level 5/10/20/29/30\n\n    Upgrading Level 4+ Gems\n\n    Minting Rare, Epic & Legendary Sneakers\n\n    Redistributing Attribute points\n\n    Increasing your GST Earning Cap\n\n    Improving the success rate of ALL Gem upgrade\n\n    Improving the chance to receive a higher quality Sneaker from opening Shoebox\n\n    Improving the chance to receive two Sneakers from minting\n\nI cover this more in the Investing section, but I don’t necessarily think that means it’s a good investment right now. We’ll come back to it. \n\nThe last bit of tokenomics we need to cover are the sneakers. They’re tokens too! \nSneaker Tokenomics\n\nThis is where STEPN runs into some problems. To their credit, it takes a while to make a new sneaker. And it’s expensive. But they have a runaway sneaker breeding problem which they’ll have to address eventually. \n\nYou can’t let players mint new NFTs forever and expect them to hold their value. There has to be some sort of burn mechanism in place for all the excess sneakers, or else they’ll become worthless eventually. \n\nThis problem has plagued Axie, and it might have been avoidable if they’d planned some sorta death mechanic for Axies from the get-go. To give you a sense of the severity, last summer the cheapest Axie went for ~$300. Now they go for ~$22. \n\nI also generally have some concern around P&E games storing most of the value in the NFTs you need to play. This is a model we’ve avoided at Crypto Raiders because we don’t want the game to be prohibitively expensive to join. Genopets is taking another version of this approach, too. So it’ll be interesting to see how the sneaker prices change over time. I’ll write more about this particular issue in a future newsletter. \n\nAlright, we know how the game works, how to start playing, and how their economy works. Let’s talk about the bear and bull case for this, because I know it’s going to get crazy over the next few months. \nThe STEPN Bear Case\n\nI said this in the intro, but the fact that I can earn $400 per day walking my dogs is insane. \n\nThe only reason I can make that much is because other people are willing to pay that much for the GST I’m earning on my walks. \n\nThe only reason they’re willing to pay that much for GST is because they can get a ~20% ROI on using that GST to mint new sneakers, which they can sell to other players. \n\nThe only reason those other players are buying sneakers is because they read an article like this telling them they can earn $400 per day walking their dog. \n\nThis can go on forever, right? Nothing concerning here? Super duper sustainable, it’s the new economy, baby! Why would you take any normal job when you can go walk around outside and earn hundreds of dollars a day? \n\nObviously, something will have to be corrected here. It’s not quite a pyramid scheme or ponzi, but it’s darn close. The only way everyone keeps making money is if other people keep putting more money into the system, which either requires more people or deeper pockets from existing people. \n\nSo how does this collapse? Well as more people enter the game, the demand for sneakers will continue to grow. That growth can sustain the current prices for a while, they’ve actually trended upwards since I started playing. But they can’t go on forever since there’s almost nothing in the game that’s ROI negative. \n\nSo eventually, one of two things will happen:\n\n    Too many people will be minting sneakers, and there won’t be enough new demand to sustain the prices and sneaker prices will fall\n\n    Too many people will have high level sneaker with high earnings, and the GST price will fall\n\nOnce one of those starts to happen, the Play-to-Earn doom cycle will be in full effect. People will see the floor price on sneakers dropping. They’ll dump their sneakers on the market to try to lock in the crazy ROI they’ve been imagining for months. It’ll be a fast and brutal race to the bottom. \n\nAt the end of it, the prices could be 1/10th of where they started. Maybe lower. \n\nThe question is, where are we in that cycle? As with most things, the earlier you are, the safer you are. People who are already playing right now might do quite well. But if this pricing continues for a couple of months and then new people join, those new people could be the exit liquidity. \n\nThis is the metagame of STEPN: how long can you milk the magic money machine before it all comes crashing down? And can they fix their doom loop before it gets triggered? \n\nIf you aren’t comfortable with the prospect of waking up tomorrow and seeing your imaginary sneakers are suddenly worthless, you shouldn’t play. \n\nThere is currently no mechanic in the game to escape this implosion, and unless they implement some creative improvements to their economics, it will break down eventually.\n\nAlso, Apple might just randomly decide to pull them from the app store and destroy everything. So that’s nice. \n\nAnd this is the part where I could get all self-righteous and talk about how selfish and reprehensible you must be to participate in a game where you know it’s an unsustainable flywheel like this, and you should be above that etc but hey, if you know the risks, and you’re being smart, go for it. It’s a game, after all. Don’t put in money you can’t afford to lose, take chips off the table, and have fun. \n\nOkay, that’s the bear case. What’s the bull case? \nThe STEPN Bull Case\n\nI’ve been working in crypto for a bit over a year now. About half of my friends are involved in crypto to some extent or another at this point, and they’re almost exclusively men. \n\nThis is the first time my wife has been interested in crypto. It’s the first time my non-crypto friends have been interested in crypto. It’s the first time my crypto guy friends’ partners have been interested in crypto. \n\nI have never seen a crypto application generate this much outside interest. My wife has been posting her STEPN walks on Instagram, and she gets tons of DMs from friends who aren’t involved in crypto at all asking about how to get set up and play.\n\nOne of my theses with crypto has been that gaming would be what brings in masses of retail users. We saw an early version of that with Axie, but we might see a much bigger version of that with STEPN and other games coming out this year.\n\nIn the last two weeks, I’ve gotten half a dozen friends set up on STEPN, a number of them never having done anything in crypto before. We have group chats where we talk strategy and share our exercises. We go on walks together to hang out and level up our imaginary sneakers. \n\nIt sounds so embarrassingly stupid to say this, but STEPN is literally making me a better person. My dogs get walked more, I get outside more, my wife and I take breaks from work to get some fresh air. I’m cringeing at myself saying this but here we are. \n\nI’m not the only one, too. The STEPN Discord is full of people talking about how it has helped them lose weight, live a better lifestyle, and spend more time with their dogs and families. I’m sure there’s some dark interpretation here about how our collective obsession with money is the only force strong enough to drive us to make positive changes but who cares. I’m having a ton of fun with it, my friends are having fun, people are being healthier, and we’re making money from it. \n\nThe and is really important here. A crypto game has to be a game first. If it’s not something fun to play on its own, without high earning potential, it’s not gonna make it. STEPN is fun. Leveling up your sneakers is fun. Mystery boxes are fun. Optimizing your energy is fun. Minting is fun. It’s addicting, and not just because there’s money attached. It might be the first fun retail-focused crypto game.\n\nThat’s all well and good, but what about the doom cycle? I fully believe what I laid out in the bear case. If STEPN doesn’t fix its economics, it will eventually implode in some awful way. And then I’ll have to deal with a bunch of angry texts from friends who didn’t take money off the table. \n\nCan STEPN avoid imploding? Yes, and it’s because they’re a fun, status-enhancing app that they can do it. \n\nI’m training for a marathon right now, and my app of choice for tracking exercises is Strava. It’s a great app for recording your exercises, and it also has a number of social elements attached to it. Your friends see when you worked out, and they can like and comment and do all the normal things you expect from a social app. \n\nBut Strava is for fitness nerds. It’s for triathletes, runners, and people who already regularly exercise. No one is posting their 10-minute walks on Strava, because taking short walks isn’t cool. STEPN can make walking cool. STEPN can make all exercise cooler. \n\nBy building out their social elements (which are coming after the game is more fleshed out), STEPN has the opportunity to build the first fitness app for non-athletes. It feels meaningful that they went with the name “STEPN” instead of “RUN’N.” It’s for casual use, not necessarily for athletes. \n\nOnce there are social elements, status signaling becomes more valuable. Right now the main way you flex in STEPN is with the rarity, level, and earnings of your shoes. But that’s just the start. There can be many additional ways you can earn status in STEPN, akin to unlocking cosmetic skins in a game like Fortnite. \n\nNon-gamers often think cosmetics are stupid. Why would someone pay a bunch of money just for a different look in a game which gives them no competitive benefit? Well, it turns out people care a lot about status signaling and individuality, to the tune of billions of dollars per year. \n\nIf people are spending billions of dollars per year to look different in a game where you mostly shoot each other, how much will they spend to look different in a game where you also get to show off how healthy of a person you’re being? \n\nHow much will people spend on custom shoes, backgrounds, reactions, stickers, and emojis? There are so many ways STEPN can allow users to enhance their status and claim individuality while also feeling good about themselves. And they can price everything in GST, taking a 4-6% cut of every transaction, and earning free interest on the SOL you’ve stored in the game. \n\nThis is how STEPN escapes the NFT breeding ponzinomics. If all the uses of GST help you earn more GST, they’re headed for disaster. But once you can spend GST to enhance your status in ways that don’t allow you to earn more, they might just make it. \n\nAnd there’s no reason they have to stop with walking and running. Those are just the easiest to verify. But they could build tracking for biking, swimming, and skiing. They could buy a hardware company to start making gym equipment. \n\nBy focusing on casual activity, walking, and getting people hooked on it through crypto incentives, they could build a killer fitness app that actually helps people build a healthier lifestyle. \n\nI can’t understate how strong the pull is to buy more sneakers so I can spend more time walking and running so I can earn more magical internet money so I can buy more sneakers. If they can keep that feeling going, and manage their economy properly, this could honestly be crypto’s killer app.\n\nBUT! There are a lot of ifs there! \n\nIt might not be STEPN, they might crash and burn and someone else picks up the mess and does it better. \n\nThey might open up sign-ups too early and send the economy spiraling out of control. \n\nApple might decide to pull them from the app store and send it all to zero (this is probably my biggest fear).\n\nIf they nail it though… oh boy there’s something here. \n\nI’m insanely bullish on STEPN. And I think one of the reasons it’s working and can work for a while, is the signup gating with activation codes. \n\nIf they open up signups to everyone before they figure out ROI negative GST sinks, they’re probably screwed. It’ll grow too hot too fast and flame out. They have an incredible opportunity hanging in a very delicate balance, and I’m rooting hard for them to pull it off. \n\nBut, again, this is crypto. Shit breaks. Apple could remove them. Solana could melt down. Someone could hack their bridge. \n\nThis is not a free lunch, and if you’re gonna play, you gotta be smart about it. Take money off the table, keep the risks in perspective, and don’t put anything at risk you aren’t prepared to lose. \n\nSo speaking of that, what am I doing with my money in the game? \nMy Investing & Playing Strategy for STEPN\n\nAs usual, what I’m doing with my money is in the paid addendum to this post. \n\nThe one thing I’ll mention in the free part here is: you probably don’t want to buy GMT right now. If you’re not sure why, check out my Tokenomics series again. Especially the Supply one. \nWill STEPN Bring Crypto to the Masses?\n\nI’m excited about STEPN because I do honestly think it could be both a revolutionary fitness app, and it could be the first app that brings a massive number of non-crypto people on-chain. \n\nMy non-crypto friends don’t care about fancy DeFi products or confusing liquidity optimization processes. But they’re very interested in making money from walking. And once they have some SOL and USDC sitting in a wallet, maybe they want to explore how to earn interest on it or borrow against it. DeFi gets more interesting once you have some skin in the game. \n\nSTEPN has a big challenge ahead of it. The concerns I laid out in the bear case are legitimate and could bring it down if they’re not properly managed. This is an unstable economy right now. You can make a lot of money playing, yes, but it could go to zero any minute. Please be responsible if you’re going to play. None of this is financial advice and just because I yolo’d some SOL into it doesn’t mean you should too. \n\nBut there’s also something to the bull case. If they can get people excited about going for walks and being healthier and create a whole status economy around it, that’s kinda magical. That could be one of the biggest crypto projects in the market. \n\nThe main thing I’m watching is their activation code strategy. If that changes, that could precipitate a big shift in the market, and opening their doors fully is going to be the thing they have to be most careful with.\n\nI’m really rooting for STEPN. I’ll definitely be playing more and growing my sneaker collection, and I’m excited for their future features like achievements, challenges, and rentals. And for when the social elements are rolled out and we can start flexing our cool sneakers. \n\nIt might just be the first crypto app with truly mass appeal.\n\n\n","n":0.013}}},{"i":5171,"$":{"0":{"v":"Threetimeswiser","n":1},"1":{"v":"\n- [ ] ","n":0.577}}},{"i":5172,"$":{"0":{"v":"The Three Systems beneath Network Effects","n":0.408},"1":{"v":"\n\n\n# The Three Systems  \nBeneath Network Effects\n\nAn exclusive excerpt from a16z general partner  \nAndrew Chen’s new book, The Cold Start Problem\n\nby [Nathan Baschez](https://every.to/@nbaschez) and [Andrew Chen](https://every.to/@andrewchen)\n\nDecember 6, 2021\n\n[♥ 23](https://every.to/the-three-systems-beneath-network-effects/the-three-systems-beneath-network-effects/feedback?rating=amazing)\n\n![](https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/1949/newsprint_Twitter_post_-_1__1_.jpg)\n\nHello friends!\n\nToday I have something special for you: my favorite chapter of [The Cold Start Problem](https://www.amazon.com/Cold-Start-Problem-Andrew-Chen/dp/0062969749), a new book, coming out tomorrow, that’s one of the more interesting and detailed explorations of network effects I’ve ever read. \n\nAs you will see, it is equal parts love letter and rebuke towards the idea of a “network effect”—a concept that is both indispensable and yet totally oversaturated and misunderstood.\n\nThe author, Andrew Chen, is someone I suspect many of you already know. I first met Andrew back in 2011 when I had recently graduated college and moved to Palo Alto to join a startup. His [essays](https://andrewchen.com/list-of-essays/) shaped my foundational understanding of how startups can get off the ground and grow. So I reached out on a whim and a few weeks later was delighted to find myself wandering around with Andrew on University Ave, asking his advice on everything startups and career-related.\n\nThen, as now, Andrew was absolutely dripping with insights about the forces that create viral success. He’s basically the opposite of the common thing you encounter in Silicon Valley, where people throw around terminology they clearly lack any functional knowledge of. And there’s probably no term more commonly abused than network effects. Yet it remains critical for anyone wanting to understand how market power works.\n\nI was lucky enough to bump into Andrew a few months ago and pestered him to let me share a chapter of his book with you, so here we are!\n\nBefore we begin, let’s quickly set the scene to give you some context for this chapter.\n\nAndrew’s overall goal for The Cold Start Problem iss to propose a new theory of network effects that is more detailed and useful for practitioners than the abstract, academic versions of the idea that have prevailed to date. One classic example is Metcalfe’s law, which claims the value of a network is proportional to the square of its number of participants. Ask anyone in the field and they’ll tell you it’s neither true nor useful.\n\nInstead, Andrew breaks network effects into five stages of development:\n\n1.  Cold start\n2.  Tipping point\n3.  Escape velocity\n4.  Ceiling\n5.  Moat\n\nEach stage of network development has several chapters in the book that consist of case studies with the founders, engineers, marketers, and product managers that have actually worked with these forces.\n\nThe chapter below is from the part of the book covering the third stage of network development: escape velocity. In it, Andrew argues that network effects aren’t one single thing. There are actually three separate forces that benefit businesses in three distinct ways.\n\nI took a lot away from it, and I’m sure you will too.\n\nHere’s Andrew! Enjoy.\n\n___\n\n## Chapter 18: The Trio of Forces\n\nEscape velocity is often described as a kind of end state, the moment when a product becomes dominant in the market, where everything gets easier. These companies are supposed to have uncontested growth based on their strong network effects. Yet look inside any product team that’s reached Escape Velocity and you see something different—what looks so easy on the outside is not so easy on the inside. Thousands of employees are working furiously to scale up the network. Dropbox, for example, employed 2,000+ full-time highly paid designers, engineers, and marketers, doubling or tripling the employee base each year leading up to the 2018 IPO.\n\nWhile you may only need a small handful of employees to achieve product/market fit—famously, Instagram had thirteen employees and 30 million users when it was bought by Facebook—you need a significant coordinated effort to scale a product to its full potential. This is a big contrast to our everyday, overly simplistic explanations of hockey stick growth curves: “They’ve got lightning in a bottle!” Or, for many of the tech products I’m unpacking in this book—from multiplayer games to chat apps to workplace products—sometimes the offhand explanation is: “Of course, they’re growing fast—they have network effects!” But this is superficial.\n\nIt takes a tremendous amount of energy to scale a network—both in playing defense to counteract market saturation and competition, and on the offense, to amplify network effects over time. It’s not just Dropbox with this kind of story \\[Note from Nathan: the previous chapter in the book was about Dropbox\\]—Pinterest, Slack, Zoom, Uber, Airbnb, and others also have thousands (or tens of thousands) of full-time employees, many of them working within the confines of a single app or small family of apps. Ask any of these teams, and they’ll tell you they feel understaffed, and there’s so much more to do. This is what Escape Velocity actually looks like. It heralds a new stage, focused on building up network effects to amplify their strength. It is not a period where teams can coast on their momentum, because inevitably, momentum will slow as market saturation, spam, competition, and other forces appear.\n\nStrengthening network effects is easier said than done. Everyone wants to improve their network effects, but what does that really mean? Product teams work in the concrete—in designing and picking product features, in deciding timelines for launching new products, and in trading off engineering complexity for functionality. Tell a team something abstract like “go improve your network effects!” and you’ll get blank stares. In the coming chapters, I will discuss how to move from strategy to execution. To create a plan to strengthen a product’s network effects, we need to connect the abstract with the concrete, so that the output can reflect the practical reality of picking and prioritizing projects.\n\n## Three Systems Underlying the Network Effect\n\nLet’s start with a surprising idea that goes against the grain of industry jargon: the network effect is not one effect. Instead, the network effect is a broader umbrella term that can be broken down into a trio of underlying forces: the Acquisition network effect, the Engagement network effect, and the Economic network effect. Each one of these can contribute to a business in a different way, and is stronger the more dense a network is.\n\nThe “Acquisition Effect” is the ability for a product to tap into its network to acquire new customers. Any product can buy Facebook or Google advertising, for instance, to attract new users, but only networked products can tap into viral growth—the ability for users in its network to tell others in their own personal networks. This keeps customer acquisition costs low over time, fighting against the natural rise that comes with market saturation and competition. The types of projects that amplify the Acquisition Effect are oriented around viral growth: referral features that reward users when they invite others, tapping into contacts to create suggestions for who to add to an app, and improving conversion along the key moments in the invitation experience. All of these help increase metrics like new user sign-ups, the so-called viral factor of a product, and bring down the cost of acquiring a customer (CAC).\n\nThe “Engagement Effect” describes how a denser network creates higher stickiness and usage from its users—it is a more specific form of the classic description of network effects that I covered at the beginning of the book, “the more users that join the network, the more useful it gets.” However, the classic definition can be refined to include the underlying system that drives the value—use cases and “loops” that define how users derive value when engaging with a product—as well as the specific metrics that increase with a denser network. For example, Twitter is a lot more interesting to use, now with media outlets, celebrities, and politicians on it, than in the early days when you might just have a nerdy friend or two on the platform. Because there’s more types of content creators in the network, what might have felt like an app to stay in touch with friends in the early days might eventually evolve into a diverse set of use cases: tracking political news, keeping abreast of what’s happening in your industry, keeping up with your favorite celebrities, and so on. In turn, these elevated use cases drive key metrics, as more engagement directly maps to the number of sessions per user, or the number of days per month that you’re active in the product. Retention curves, often one of the most important visualizations of how long people are sticking around, can be improved as stickier use cases emerge.\n\nThe “Economic Effect” is the ability for a networked product to accelerate its monetization, reduce its costs, and otherwise improve its business model, as its network grows. Workplace products, for example, often convert to higher tiers of pricing as the number of knowledge workers using them grows within a company. The more workers that adopt a product, the more advanced features they might want to upgrade into, particularly when the features are collaborative in nature—like Slack charging for the ability to search messages from all users across the organizations. Similarly, app stores and other marketplaces will grow their average revenue per user as the number of listings increases. If customers have more choices, they often have a better chance of finding exactly what they’re looking to buy. Then, conversion rates increase.\n\n## The Growth Accounting Equation\n\nI use Engagement, Acquisition, and Economic network effects as the core taxonomy for the reason that they map to the key outputs that product teams care most about: active users and revenue, and the leading indicators to these metrics. Active users are made up of a combination of new users signing up, and how engaged and retained the existing users are. Revenue is a by-product of active users and the average revenue each user is generating, whether that’s from purchases or advertising revenue. Growth rate, another important metric, is the ability to repeatably scale these network effects consistently over time.\n\nThe relationship between these inputs and outputs is just arithmetic. Here is what’s often called the “Growth Accounting Equation,” which shows how these key metrics relate for active users:\n\n_Gain or loss in active users = New + Reactivated − Churned_\n\nThen based on the delta of each time period, you can figure out if you’ll gain or lose active users:\n\n_This month’s actives = Last month’s actives + gain or loss_\n\nThis example uses “Active users”—relevant more for social networks and messaging apps—but it could be “Active subscribers,” too, for a SaaS product like Dropbox or a consumer subscription service like YouTube Red. It’s become a best practice to take this equation and build dashboards out of its inputs, so that in any given month you know how the underlying components are trending. If your goal is to grow 3x year over year, and sign-ups are way down, then it becomes clear how much churn has to be improved in order to still make the target—it’s just some simple math. Overlaying revenue is easy, too. You just add two more variables, multiplying the active users number with the average revenue per active user (ARPU).\n\nEvery product can be thought of in this way, and it’s the product team’s goal to increase each of these metrics. However, networked products are special in how they can leverage their networks to drive up each of these variables—something that traditional products can’t. As they grow and hit Escape Velocity, the density of the network makes the Engagement, Acquisition, and Economics effects more powerful, causing the input metrics to increase. More new users will appear, based on viral growth, and the product will get stickier, decreasing churn. More money will be made, as conversion rates increase. The central inputs into a networked product’s growth equation will improve on their own, as a function of the network as opposed to the features of the product—creating an accumulating advantage over time. This is the magic of network effects.\n\nAnd while I describe each of these network effects independently, in practice they all work together in concert. A more engaged and retained audience will have more opportunities to share the product with their friends, driving up viral growth. A stronger Acquisition Effect means there will be a steady stream of new people to engage the existing community, keeping them more engaged. Stronger monetization might mean that users make more money, which then stimulates more engagement. Amplifying one will often drive the others up as well.\n\n___\n\nNathan here, again! Hope you enjoyed that excerpt!\n\nThis newsletter is already going a bit long so I’ll be brief, but before we part ways for today I wanted to share my take on what you just read.\n\nAndrew frames the “trio of forces” as what’s beneath network effects, and says that the term “network effect” is really an umbrella term to describe three independent forces, but I model it in my own head slightly differently. I think of the effects Andrew explains of decreased acquisition costs, increased user engagement, and increased monetization as actually three _benefits_ that are possible when you have a strong network effect. The core network effect itself—that people want to be on the same systems as other people—is its own thing.\n\nThis is maybe just a tiny nitpick, but I’m curious what y’all think? Click one of the feedback buttons below and leave a comment!\n","n":0.021}}},{"i":5173,"$":{"0":{"v":"The 3 Keys to Character Motivation","n":0.408},"1":{"v":"\n- written-by: @tim-grahl\n\nObjects of Desire.\n\nThese are not just whimsical wants or fleeting desires, they are the driving forces that propel the narrative forward and deepen the audience's engagement with the characters.\n\nLet's break this down the Objects of Desire into three distinct categories:\n\n\n### Objects of Desire\n\n- Conscious Want\n- Unconscious Need\n- Eternal Desire\n\n### Let’s dive in!\n1. Conscious Want: The Clear, Visible Goal\n\nThis is what the character knows they’re trying to achieve. It’s like having a quest in a game with a clear objective: “Win the race” or “Get the treasure.” The character is fully aware of this goal, and it drives their immediate actions.\n\nExamples:\n\n    In The Hunger Games, Katniss Everdeen’s Conscious Want is simple: survive the games. Every action she takes, from forming alliances to setting traps, is about staying alive.\n    In Harry Potter and the Sorcerer’s Stone, Harry’s Conscious Want is to stop Voldemort from getting the Sorcerer’s Stone. It’s a tangible, immediate goal that he understands and works toward.\n\n2. Unconscious Need: The Deeper, Hidden Growth\n\nThis is what the character doesn’t realize they need. It’s like a personal quest they didn’t know they were on. Often, this is a lesson or growth they need to undergo to become a better version of themselves. While the Conscious Want drives their actions, the Unconscious Need pushes them toward personal transformation.\n\nExamples:\n\n    In Pride and Prejudice, Elizabeth Bennet’s Conscious Want is to marry for love, not status. But her Unconscious Need is to overcome her pride and prejudice to truly connect with Mr. Darcy.\n    In The Great Gatsby, Gatsby’s Conscious Want is to reunite with Daisy, but his Unconscious Need is to recognize the emptiness of chasing wealth and status. He needs to understand that the life he’s built around Daisy is hollow.\n\n3. Eternal Desire: The Ultimate Aspiration\n\nThis is the character’s deepest, most profound motivation—their why. It’s what they hope to achieve in the grand scheme of things, even if they can’t fully express it. It’s like the big picture goal that gives meaning to everything else. Think of it as what you’d want written on your tombstone—your legacy.\n\nExamples:\n\n    In The Lord of the Rings, Frodo’s Conscious Want is to destroy the ring, but his Eternal Desire is to restore peace and return to the simple life in the Shire. He longs for normalcy after chaos.\n    In Jane Eyre, Jane’s Conscious Want is to find love and independence. Her Eternal Desire, though, is to live a life where she can maintain her integrity and self-respect, without sacrificing her morals for love or status.\n","n":0.049}}},{"i":5174,"$":{"0":{"v":"Re Rdf Star Multi Level Embedded Triples and Quoted Vs Asserted","n":0.302},"1":{"v":"\n\n\nOn 6/10/2022 6:05 AM, llSouripriya Das wrote:\n> What would be the best ways to represent the two cases of the following sentence in RDF-star:\n>       Alice heard that Bob knew that Cindy read, from email and in paper, that Dan adores Eve\n> i.e.,\n>       Alice heard []\n>                           |\n>                          Bob knew []\n>                                            |\n>                                            Cindy read {from email; in paper} []\n>                                                                                                  |\n>                                                                                                 Dan Adores Eve\n>\n> Case 1: The only asserted triple should be: Alice heard <something>. All the remaining triples (i.e., those that make up the <something> portion) should be quoted triples only (i.e., not asserted triples).\n>\n> Case 2: Every triple used to represent this sentence should be an asserted (i.e., not just quoted) triple.\n>\n> Thanks,\n> Souri.\n>\n\n","n":0.094}}},{"i":5175,"$":{"0":{"v":"Public Rdf Star","n":0.577}}},{"i":5176,"$":{"0":{"v":"Summary Un Asserted","n":0.577},"1":{"v":"\n\nHi Thomas,\n\nFirst, I agree with everything Peter wrote in his (first) reply. (Though, regarding names and definitions, I might put it as: triples as objects (triple terms) simply denote relationships (so we can refer to them directly), whereas triples in graphs simply assert that they hold.)\n\nAgain, you talk about \"unasserted assertions\", as if referring to a triple (term) is somehow affected if that is also asserted (or is not). There is no such interaction a priori, so I don't see the problem with the reifier in \"1/4\". It appears totally abstract and does not relate to any notion of truth; it is not \"about an unasserted assertion\". It is simply relating to what `:s :p :o` means, i.e. the abstract relationship. If what you want is an opaque context, just use a literal with an RDF serialization. If it is about an entity in your domain which reifies falsehoods (like a Myth), it would itself be proven at odds with a world in which those relationships actually hold. That's pretty much the point of referring to relationships, so that you then have something to check if it's true or not. (And monotonicity is not violated here.)\n\nStill, I may understand parts of your discomfort, in *some* cases. I think you might sense a distinction in \"nature\" between kinds of reifiers which mediate what needs to be true for the reifier to \"make sense\" (such as a Purchase), and others which *only* refer to relationships, true or not (such as a Claim).\n\nBut there is no need to add this distinction in the reifying relationship. It is enough to specify the appropriate `rdf:type` of the reifier.\n\nIf you have a simple relationship:\n\n    <Alice> :bought <SomeComputer> .\n\nAnd a reifier which `rdf:reifies` that:\n\n    <purchase1> a :Purchase ;\n        :date \"2014-12-15\"^^xsd:date ;\n        :seller <ComputerStore> ;\n        :cost 2500 ;\n        :currency :USD ;\n        rdf:reifies <<( <Alice> :bought <SomeComputer )>> .\n\nThen the only additional thing needed in RDF 1.2 is to ensure that a triple term entails something understandable by a reasoner, like a classic reification token:\n\n    <purchase1> rdf:reifies [ rdf:subject <Alice> ; rdf:predicate :bought ; rdf:object <SomeComputer> ] .\n\n(This has been suggested (as \"T-entailment\"?). I'm convinced that it is a critical requirement for interoperability (or some variant thereof, such as an rdf:Relationship subclass of rdf:Statement).)\n\nI think what bothers you is that it would reasonably make sense to say that in this case, given the intuitive meaning of a Purchase, the simple `:bought` relationship should also hold (i.e. that triple should be entailed). And I agree, for this specific case. Not for the general use of `rdf:reifies`.\n\n## Relator n-ary entailing simple predicate\n\nSpecifically then, we want to say that IF something is a :Purchase which rdf:reifies a :bought relationship between ?x and ?y, THEN ?x :bought ?y.\n\nAnd we don't need anything more for that. This is already possible using OWL.\n\nWe first need a \"rolification\" property for the :Purchase (that's just an existing \"OWL trick\",\n\n    :Purchase rdfs:subClassOf [ owl:onProperty _:RolifiedPurchase ; owl:hasSelf true ] .\n\nAnd a class for the :bought relationship, which is additionally tied to a \"rolified\" property:\n\n    _:BoughtRelationship owl:equivalentClass [  \n        owl:onProperty rdf:predicate ;\n        owl:hasValue :bought ] ;\n        rdfs:subClassOf [ owl:onProperty _:RolifiedBoughtRelationship ; owl:hasSelf true ] .\n\nThen we can define subproperty chain axioms as needed:\n\n    _:boughtRelation rdfs:subPropertyOf rdf:reifies ;\n        owl:propertyChainAxiom (_:RolifiedPurchase rdf:reifies _:RolifiedBoughtRelationship) .\n\n    :buyer rdfs:domain :Purchase ;\n        owl:propertyChainAxiom (_:boughtRelation rdf:subject) .\n\n    :item rdfs:domain :Purchase ;\n        owl:propertyChainAxiom (_:boughtRelation rdf:object) .\n\nFrom this it is entailed that `<purchase1>` is a full-fledged N-ary relationship:\n\n    <purchase1> a :Purchase ;\n        :date \"2014-12-15\"^^xsd:date ;\n        :buyer <Alice> ;\n        :seller <ComputerStore> ;\n        :item <SomeComputer> ;\n        :cost 2500 ;\n        :currency :USD .\n\nAnd from that, is it easy to define a chain axiom to the simple relationship:\n\n    :bought owl:propertyChainAxiom ( [ owl:inverseOf :buyer ] :item ) .\n\nSo that this is entailed (asserted):\n\n    <Alice> :bought <SomeComputer> .\n\nThis is something the used ontology can define, to clarify the \"intuitions\" on the Purchase class, and also mechanically aid in data interoperability. Not all reifiers (such as data provenance / editorial management) have this \"nature\", so it should really be up to how the type of the reifier is defined. Which the above proves is already possible.\n\nTo see that this works, try it out in an OWL tool such as the OWL-RL reasoner, which is also online courtesy of the Finnish National Library at [1]. That example link uses the example data above, which I put in a gist at [2]. (In that gist there is also a version where the `:seller` is not directly asserted, but `<purchase1>`  instead also reifies `<Alice> :shoppedAt <ComputerStore>`, and rules are added so that the `:seller` and `:shoppedAt` triples are entailed.)\n\nAside: I think it is imperative that reifiers like `<purchase1>` are recognized, as shown above, as standard N-ary relationships. A lot of the *seemingly* simple triple annotations we've seen appear to be of that kind, in \"disguise\" (just a piecemeal description of). And N-aries are a common kind of relationship reification *not* limited to the rather narrow \"triple token\" notion informally defined in RDF. Specifically, the Purchase class is a kind of reifier known as a [[relator|prdct.ontouml#relator]] [2], which mediates the buyer, item, and seller, date, cost, currency. Which I think at least Enrico has been saying all along.\n\nSo with `rdf:reifies`, transparent triple terms as objects, and the addition of a simple \"T-entailment\", we appear to already have all pieces required to cater for the use cases we have deemed reasonable, including ones where reified relationships should also be entailed to hold. With ontology-powered systems, they mighn't need triple terms to begin with. But the annotation syntax is a practical convenience for lots of real world systems, where the above OWL usage is far from prevalent today, or where other concerns are more pressing. As shown above, semantically, OWL has what is needed to make all approaches interoperable. (And a lot more is available, such as cardinality restrictions).\n\nBest regards,\nNiklas\n\n[1]: <https://www.ldf.fi/service/owl-rl-reasoner?text=&source_1=https%3A%2F%2Fgist.githubusercontent.com%2Fniklasl%2F69428b043be6f1d33fd45f89cbe52632%2Fraw%2Fb3352d9648dc7710d7128af6ac731464f54ba836%2Fpurchase-entailments.ttl&iformat=turtle&format=turtle&fullClosure=no&owlClosure=yes&rdfsClosure=yes&owlExtras=yes&axioms=no&daxioms=no>\n[2]: <https://gist.github.com/niklasl/69428b043be6f1d33fd45f89cbe52632>\n[3]: <https://ontouml.readthedocs.io/en/latest/classes/sortals/relator/index.html>\n\n\n\nOn Tue, Jul 9, 2024 at 4:50 PM Thomas Lörtsch <tl@rat.io> wrote:\n>\n>\n>\n> Am 9. Juli 2024 16:07:25 MESZ schrieb \"Peter F. Patel-Schneider\" <pfpschneider@gmail.com>:\n> >There are much better names than \"Unasserted assertions\", largely because it is unclear just what \"assertion\" means and later examples bias its meaning. I see two choices for \"assertion\" - \"embedded triple\" or \"triple occurence\", where the difference is that there is precisely one embedded triple for a combination of subject, predicate, and object but there are multiple triple occurences for a combination.\n>\n> Assertion, the way I try to define it, refers to a triple, or fact, in a graph. The unasserted assertion, as I said, equals the subject of an RDF standard reification quad. However, just speaking of \"facts/triples\" and \"statements\" would most probably not convey the difference in meaning that this discussion centers around.\n>\n> >PROBLEM 1:   This is just yet another example of the problem with the \"seminal example\".   If you want to be able to have separate views of a triple then you have to somehow be able to create separate resources that all somehow refer to the triple.  The working group has already what appears to be a widely-acceptable proposal in this area with both a special prediate - rdf:reifies - and shorthand syntax for Turtle.   So this problem is already solved.\n>\n> This problem is not solved, as IMO my extremely concise example below clearly shows. Please provide a counter example to prove your point.\n>\n> >PROBLEM 2:  This is just yet another complaint about the verbosity of RDF. RDF is indeed verbose (or lacking and thus requiring verbose encoding) for many things - node names, n-ary predicates, literals, lists, sets, alternatives, universals, disjunctions, modals, etc.  Adding some sort of special facility to the core of RDF to overcome this verbosity makes the core of RDF more complex, harder to implement, and probably harder to understand. So, yes, the verbosity of RDF is a problem but reducing verbosity comes at the decided cost of increased complexity.\n>\n> This is a discussion long resolved and the resolution was to set up this working group and have it define an easy way to make statements about statements. I think everybody is aware of the complexity that adds under the hood.\n>\n> >PROBLEM 2 and 3:  A way of getting around verbosity is shorthand syntax.  This has been in Turtle for quite some time, reducing the user-perceived verbosity of several aspects of RDF, particularly lists.   N-triples, of course, does not include shorthands but the fundamental design principle of N-triples is simplicity.  The working group has what appears to be a widely-acceptable proposed shorthand syntax for the common case of an asserted triple with qualifiers, covering by-and-large the LPG and Wikidata.   The shorthand syntax can also be used when querying, in many cases completely eliminating the need to see the expanded version.   There are some aspects of this shorthand that could be improved and there is a proposal already put forward to the working group on this.\n>\n> Problem 3 is not so much about syntax but about how reification is not the right approach to all those use cases that qualify assertions.\n>\n> >PROBLEM 4:  Turtle should be the only syntax that most users, particularly naive users, see.  Tools designed to produce RDF that users see should produce Turtle output and Turtle output that uses the shorthand syntax whereever possible.  Tools that perform differently are to be avoided.  But this is only a small part of the problem of producing readable output for any graph-based structure.  There are few tools that do this in a way that is even somewhat close to acceptable and no tools that I am aware of that do a great job for graphs of any size.  The problem is just very, very, very hard (and probably impossible due to the limited sensory and cognitive capabilities of humans). I would love to be proved wrong and have access to a tool that would provide a usable view on Wikidata for me, even just the ontology part.  In any case, lines of characters is the wrong format for just about all people to see RDF graphs of any size.\n>\n> The importance of N-Triples as the only syntax that really counts in implementation, has been stressed in WG meetings many times. Streaming contexts were mentioned as wasvexchsnge of fata over the wire. I was even asked to provide examples for the Nested Named Graphs proposal in N-Triples instead if TRIG. The different syntaxes should be equally expressive, or what was seemed to conveyed in a shorthand notation gets lost when transmitted over the wire.\n>\n> >In summary, I don't see anything in these problems that have either not been already addressed or are not a true problem at all.  That being the case, why should I bother to examine a proposal that doesn't address anything that has not already been adddressed.   New proposals should build on already-existing work of the working group, using the deliberations that have already been performed and the nomenclature and solutions that have already been proposed, and comparing the new solutions to them.\n>\n> In summary you make claims that are not substantiated (\"solved\") and you argue that if only the world was organized differently, the problems I describe would go away. The latter is not going to happen, the former would need a concrete example to be plausible.\n>\n> I maintain that with the current proposal it is impossible to annotate an unasserted assertion (equal to the subject of an RDF reification quad) AND have that same statement as a fact in the same graph. However, that has repeatedly been claimed to be a use case that we need to address. So, imo we clearly have a problem. And basing the occurrence semantics on  reification instead of instantiation is another problem and my proposed solution solves both in combination.\n>\n> Best,\n> Thomas\n>\n> >peter\n> >\n> >\n> >On 7/9/24 06:43, Thomas Lörtsch wrote:\n> >> Hi all,\n> >>\n> >> as promised in the last WG meeting almost two weeks ago this is a summary of the issues I see with \"unasserted assertions\" and a proposal of how to resolve them and, in the same stroke, some other problems as well.\n> >>\n> >>\n> >>\n> >> DEFINITION\n> >>\n> >> \"Unasserted assertions\" - for lack of a better name - means statements that are described (and probably annotated), but are not contained as facts in the graph. I.e. those statements are talked about, but not endorsed. RDF standard reification is a construct to such effect: the reification quad describes a statement, but it doesn’t entail it.\n> >>\n> >>\n> >> PROBLEM 1/4\n> >>\n> >> Both CG and WG repeatedly and explicity maintained that RDF-star needs to support \"unasserted assertions\". However, the way that RDF-star currently implements them is ambiguous, lossy and non-monotonic even. It relies completely on the absence of a fact from the graph. If however that fact is present, it is no longer possible to talk about it as refering to something unasserted.\n> >>\n> >> For example, we may want to document and comment on a statement without endorsing it. We write\n> >>\n> >>      << :s :p :o >> :a :b .\n> >>\n> >> If however that same statement is also to be part of the graph, for whatever reason, like so:\n> >>\n> >>      << :s :p :o >> :a :b .\n> >>      :s :p :o .\n> >>\n> >> there is no way to express that the annotation is meant to refer to an unasserted statement.\n> >> There are many situations in which this problem might occur: we might want to document different viewpoints or versions, graphs might be merged or updated, adding the fact, etc.\n> >>\n> >>\n> >> PROBLEM 2/4\n> >>\n> >> As a way out of this problem I discussed to require another statement describing if an annotation is meant to annotate an unasserted assertion, like so:\n> >>\n> >>      << :s :p :o >> :a :b ;\n> >>                     a rdf12:UnAssertedAssertion .\n> >>      :s :p :o .\n> >>\n> >> However, this is not a valid solution, because a second problem runs even deeper: the meaning of triple terms is defined as reification. Because of those reification semantics a triple term is always unasserted. By consequence we would rather need to add a statement whenever we intend to anotate a statement that we actually assert, like so:\n> >>\n> >>      << :s :p :o >> :c :d ;\n> >>                     a rdf12:AssertedAssertion .\n> >>      :s :p :o .\n> >>\n> >> In practice this would add considerable load as most annotations will aim to annotate facts in the graph, not e.g. some unendorsed viewpoints. This would also require more effort when querying.\n> >>\n> >>\n> >> PROBLEM 3/4\n> >>\n> >> On the plus side the approach in 2/4 could be considered to be very expressive as the actual fact would now be completely independent from any annotations, on asserted and unasserted assertions alike, adding a new degree of expressivity. However, for many use cases this separation is rather a problem than a feature, because they ask for a clear and solid connection between a fact and \"its\" annotation. All use cases of qualification fall in this category, e.g. Wikidata, LPG, and many more. OTOH, for use cases that aim to annotate statement with rather orthogonal aspects like provenance, refication is the right choice. So just changing the underlying semantics from one to the other is not a solution. We rather need both.\n> >>\n> >>\n> >> PROBLEM 4/4\n> >>\n> >> The shorthand syntax by intuition provides a solid link between a stated fact and its annotation. However, no other syntax does that, so an unassuming user's intuition is betrayed when the data is serialized to e.g. N-Triples. This is a serious usability problem.\n> >>\n> >>\n> >>\n> >> PROPOSAL\n> >>\n> >> To properly support unasserted assertions, and to solve the semantics problems in the same stroke, let's bite the bullet and define two primitives instead of one:\n> >> - an unasserted triple term occurrence with a semantics of reification\n> >> - an asserted triple term occurrence with a semantics of instantiation\n> >> Define those primitives and their semantics not in the abstract syntax, but via the two properties rdf12:reifies and rdf12:instantiates.\n> >>\n> >>\n> >> Abstract Syntax:\n> >>\n> >> graph      ::= triple*\n> >> triple     ::= subject predicate object\n> >> subject    ::= iri | BlankNode\n> >> predicate  ::= iri\n> >> object     ::= iri | BlankNode | literal | tripleTerm\n> >> tripleTerm ::= triple\n> >>\n> >>\n> >> Properties:\n> >>\n> >> To provide the user facing triple term occurrences with their respective semantics (un-/asserted etc) we explicitly (and normatively) define two properties, with different semantics, to be used with abstract triple terms as their rdfs:range:\n> >> - rdf12:reifies defines a reification of an abstract triple term\n> >> - rdf12:instantiates defines an instantiation of an abstract triple term\n> >>\n> >> A reification via rdf12:reifies doesn’t assert the statement described by the triple term, it merely provides an identifier to refer to an occurrence (whereever, whenever) of it. IIUC that is exactly what we have now. A mapping to RDF 1.1 clarifies that:\n> >>\n> >>      :r_1 rdf12:reifies <<( :s :p :o )>> .\n> >>\n> >> in RDF 1.1 would be expressed as\n> >>\n> >>      :r_1 rdf12:reifies [\n> >>          rdf:subject :s ;\n> >>          rdf:predicate :p ;\n> >>          rdf:object :o .\n> >>      ]\n> >>      rdf12:reifies rdfs:range rdf:Statement .    # axiomatic triple\n> >>\n> >> An instantiation via rdf12:instantiates OTOH does indeed assert the statement it annotates, in addition to providing an identifier to annotate that assertion. To make the connection between statement and annotation direct and solid, but not break the set semantics of RDF, the model and semantics mimick the [[singleton property|t.cs.semantic-web.singleton-property]] approach. A mapping to RDF 1.1 clarifies that:\n> >>\n> >>     :i_1 rdf12:instantiates <<( :s :p :o )>> .\n> >>\n> >> in RDF 1.1 would be expressed as\n> >>\n> >>      :i_1 rdf12:instantiates [\n> >>          :s :p_1 :o .\n> >>          :p_1 rdf12:instantiatesProperty :p .\n> >>      ]\n> >>      :s :p :o .\n> >>      rdf12:instantiatesProperty\n> >>          rdfs:subPropertyOf rdf:type .           # axiomatic triple\n> >>\n> >>\n> >> Macro:\n> >>\n> >> An instantiation always entails the triple term, ':s :p :o' in the above example. This is defined as a macro when mapping between concrete syntaxes.\n> >>\n> >>\n> >> Concrete syntaxes:\n> >>\n> >> I see two possible approaches. One is to not change the currently defined syntaxes, but let the shorthand syntax express instantiation, and let the standard syntax express reification. That would align syntaxes as they are defined right now with the intuitions they support, but all modifications would happen \"under the hood\" - e.g.:\n> >>\n> >>      :s :p :o  {| :a :b |}      # rdf12:instantiates, asserted and annotated\n> >>      << :s :p :o >> :d :e .     # rdf12:reifies, not asserted but annotated\n> >>\n> >> Another approach would be to let instantiation be expressed with double chevrons and reification with triple chevrons, e.g.:\n> >>\n> >>      << :s :p :o >> :a :b.      # rdf12:instantiates, asserted and annotated\n> >>      <<< :s :p :o >>> :d :e .   # rdf12:reifies, not asserted but annotated\n> >>\n> >> The first approach, based on the current syntaxes, does more clearly disambiguate the two modes of expression, but it also adds more \"unrest\". The second approach stays closer to the orignal RDF* proposal and is more uniform. The second approach might enable a more usable query interface, e.g.:\n> >>\n> >>      ?s ?p ?o                   # asserted\n> >>      << ?s ?p ?o >> ?a ?b       # asserted and annotated\n> >>      <? ?s ?p ?o ?> ?a ?b       # asserted and optionally annotated\n> >>      <<< ?s ?p ?o >>> ?a ?b     # unasserted and annotated\n> >>      <<? ?s ?p ?o ?>> ?a ?b     # (asserted or unasserted) and annotated\n> >>      <?? ?s ?p ?o ??> ?a ?b     # (asserted or unasserted) and optionally annotated\n> >>\n> >> Occurrence identifiers are omitted in all examples, as they don’t differ from the current proposal. Likewise the mapping to N-Triples doesn’t change, except from the introduction of a new property, rdf12:instantiates.\n> >>\n> >>\n> >>\n> >> DISCUSSION\n> >>\n> >>\n> >> In principle:\n> >> RDF is an Open World technology, designed to facilitate decentralized authoring and integration of data and we can’t rely on the absence of statements to convey meaning (e.g. unassertedness or non-endorsement). Out-of-band arrangements in concrete application may be more specific, but we can not make any claims based on that (and \"RDF-star supports unasserted assertions\" would be such a claim).\n> >> I’d like us to go the extra mile and adopt the above proposal: implement two different kinds of annotation primitives. This also opens the road to a future with more elaborate constructs like quoted versioning.\n> >> I could also live with a scaled down reference to the support of unasserted assertions, on the lines of \"you can emulate a surrogate support for unasserted assertions like this, but be aware that the construct easily breaks in practice if not tightly controlled\".\n> >> However, that would still not solve the other problem, namely that reification is not the right formalisation for most of our use cases.\n> >>\n> >> Properties:\n> >> defining the semantics of triple term occurrences via the properties rdf12:reifies and rdf12:instantiates is a modification of the mechanism introduced by the TEP proposal in the RDF-star CG report.\n> >>\n> >> Instantiation:\n> >> There are different names for the underlying concept. It can also be understood as a form of n-ary relation where the instance-type relationship is modeled via a blank node. So the term \"instantiation\" refers to its most theoretical aspect (which best mirrors \"reification\", and that’s why I chose it in this summary), \"n-ary relation\" would refer to the way of modelling it, and yet another term \"qualification\" would emphasize the meaning of the construct. \"Singleton properties\" is a term that I try to avoid because the proposal has been met with so much resistance, but it is a concrete implementation of the same concept. I provide a very singleton property like mapping to RDF 1.1 above, but slightly different mappings could provide better computational properties, e.g. letting the object refer to the singleton, resulting in better indexing and join performance.\n> >> However, what is most important to me is that the qualifying annotation, by being attached to the instantiation, is unmistakeably annotating a statement that is actually asserted in the graph. The only metaphysical baggage involved is the definition of what a type-instance relation is, and that should be uncontroversial.\n> >> Defining the relation between annotated thing and annotating thing not as a subproperty-relation but as a type-instance-relation follows the idea that those annotated relations are not meant to be annotated any further (that too is possible, but not the norm). So they represent leaves of an inheritance tree rather than knots. In OO tradition leaves are understood as instances, whereas knots would be defined as sub-properties.\n> >>\n> >> Mappings:\n> >> The mappings to RDF 1.1 are provided for two reasons:\n> >> - clarify the meaning of new constructs in terms of well-known ones\n> >> - provide a path to backwards compatability.\n> >> RDF-star implementations should not be required to support them on the implementation level.\n> >>\n> >> Many-to-many:\n> >> The astute reader will have noticed that both mappings to RDF 1.1 are many-to-many. However, owing to the semantics inherent in instantiation, this is a kind of many-to-many relationship that only properly supports co-denoting statements. A common instantiator for :Car and :MotorizedVehicle makes sense, whereas for conceptually very different entities like :Car and :Person it mostly does not. Such a semantics remains true to the integration focus of RDF, but also caters to the more focused approach of LPG. Reification on the other hand rather refers to the statement(s) as a whole, as an entity in their own right. This caters well to use cases that explicitly don’t want to qualify statements but that that try to keep a safe distance between statement and annotation, e.g. provenance and other orthogonal concerns.\n> >>\n> >> Querying:\n> >> Do we currently allow to query for the abstract triple term <<( … )>> or do we plan/have to do so? If yes, that might be a better replacement for the last option above: <?? … ?>>. In any case the above proposal is just a sketch and may not even be helpful. I’m not good at querying.\n> >>\n> >> Abstract triple:\n> >> People can use the abstract triple term as object of whatever statements they like. They are on their own with such freewheeling usage, as no other semantics are defined in the spec than those of rdf12:reifies and rdf12:instantiates. However, this may lead to some fruitful experiments, e.g. with referentially opaque triple terms, and it stays in the spririt of RDF being a pretty open technology.\n> >>\n> >> Fragment identifiers:\n> >> Reification defines a handle to address the whole triple as an object, instantiation rather defines a handle to address the predicate of the triple. Therefore an annotation on a reifier annotates the whole triple as an object, an annotation on an instantiator rather qualifies the relation itself. Both arrangements are not set into stone, and adding more specific properties to explicitly annotate and qualify the subject, predicate, object or whole triple (or a set thereof) may be defined. The RDF reification vocabulary might be reused to that end, but defining a new set of properties seems to be the safer approach. Such properties may be applied to reifications as well as instantiations (and there are use cases for both).\n> >>\n> >> Merging and temporal aspects:\n> >> It was argued that the problems outlined above are not actual problems for us but related to issues outside of RDF-star, i.e. merging is not an issue for RDF-star and temporal aspects are not considered in RDF at all. I disagree with both accounts: RDF is a technology focused on decentarlized data integration. Such integration requires merges, and it leads to the addition of statements in existing graphs. In both cases the situation may arise that a statement that was annotated but not endorsed is added as an actual fact. Then what was meant to be unendorsed suddenly is endorsed. Problems with other use cases, like representing different viewpoints, notwithstanding.\n> >>\n> >>\n> >>\n> >> Best,\n> >> Thomas\n> >\n>\n","n":0.015}}},{"i":5177,"$":{"0":{"v":"Some Notes on the Rdf Star Examples of Profiles","n":0.333},"1":{"v":"\n- to discuss a fraud it is not necessarily essential, and probably often not helpful or even harmful, to suppress co-denotation.\n  - If referentially opaque triple terms would become the standard way to represent LPG data in RDF (or if the recommendation would even suggest such an approach) we would probably shoot ourselves in the foot big time. A conversion of LPG to RDF that looses some or even much of the integration capabilities of RDF is not a compelling value proposition.\n- Referential opacity is useful if one is actually interested in the syntactic representation of referers\n  - in every other case they are not only a nuisance, but outright harmful because they restrict the meaning of what is said in completely counter-intuitive ways. They work diametrically against the core purpose of RDF: concentrating on what is meant, not on how it is expressed.","n":0.083}}},{"i":5178,"$":{"0":{"v":"Rdf Star Vs Wikidata for Modelling Richard Burton","n":0.354},"1":{"v":"\n- [[p.references]] https://lists.w3.org/Archives/Public/public-rdf-star/2021Dec/att-0001/rdf-star-neptune-use-cases-20211202.pdf\n","n":0.577}}},{"i":5179,"$":{"0":{"v":"Log","n":1},"1":{"v":"\n\n\n### 2022-01-04\nHi Thomas\n\n    A side note about what a statement states and what it doesn’t state (unrelated to what I said above, \n    but as the topic came up in this thread recently): the much discussed example\n        <<:Burton :marriedTo :Taylor>> :start 1963; :end 1974 .\n    can be read as \n        \"Let’s assume a statement claiming a marriage relation between Burton and Taylor.\n        That marriage relation starts in 1963 and ends in 1974.\" \n    That’s okay (ignoring for a moment the httpRange-14 issue, that start and end dates could also refer to the statement itself). \n    The second sentence adds detail about which the first sentence makes no claim. It is important that properties are defined in a\n     way that they welcome such additional information, not prohibit it. The design principle that no statement is allowed to alter\n      the truth of another one OTOH also requires that no statement is allowed to forbid the addition of further detail by other \n      statements. If we can’t rely on that we can forget about weaving a semantic web from disparate sources. \n\n\nI'd say most of us on this thread agree by now that that statement is improperly structured. Optional time and space positions, and other fixes I suggested in my two previous messages, seem to solve the problem entirely though. I guess you disagree?\n\nAsserted case:\n:Burton :marriedTo :Taylor 1964 1974\n    {|\n        :stated 2022\n    |}\n\nExpands to:\n\n:Burton :marriedTo :Taylor 1964 1974\n<< :Burton :marriedTo :Taylor 1964 1974 >> :stated 2022\n\nUnasserted case:\n<< :Burton :marriedTo :Taylor 1964 1974 >>\n    {|\n        :stated 2022\n    |}\n\nExpands to:\n\n<< :Burton :marriedTo :Taylor 1964 1974 >> :stated 2022\n\nRegards\nAnthony\n\n### 2022-02-14\n\n- There are three different things that in my view are constantly getting muddled in RDF-star examples. If a triple is in the subject position it's common to see annotations that, in my view, actually have different subjects, but you wouldn't know it from the way they're all grouped together. The subject could be:\n\nThe relationship/event.\nThe abstract description of the relationship/event.\nSpecific occurrences of the abstract description of the relationship/event.\n  - [[p.hasAuthor]] @anthony-moretti\n\n","n":0.055}}},{"i":5180,"$":{"0":{"v":"Diff Ing Rdf Files","n":0.5},"1":{"v":"\n- mentions: [[prdct.ontology-publisher]]\n\n\n## Elissa Kendall\n\n\n\n\n-------- Forwarded Message --------\nSubject: \tRe: Diff'ing RDF files\nResent-Date: \tSat, 14 Sep 2024 20:31:36 +0000\nResent-From: \tpublic-rdf-star-wg@w3.org\nDate: \tSat, 14 Sep 2024 20:31:25 +0000\nFrom: \tElisa Kendall <ekendall@thematix.com>\nTo: \tpublic-rdf-star-wg@w3.org <public-rdf-star-wg@w3.org>\nCC: \tsemantic-web@w3.org <semantic-web@w3.org>\n\n\nHi all,\n\n \n\nThere is an open-source tool available from the EDM Council for converting between RDF/XML, Turtle, and JSON-LD and for consistent serialization of any of these representations of RDF and OWL. The GitHub site for it is https://github.com/edmcouncil/rdf-toolkit. It is actively maintained, freely available, and addresses a number of issues mentioned on the thread, among other things. It also allows users to turn any of its features on/off as desired. It runs on the command line, or can be invoked automatically through GitHub commit hooks, for example.\n\n \n\nFor collaborative work across development teams for large ontology projects, consistent serialization for comparison purposes was one of our first and relatively important issues. It enables visual comparison in GitHub (and likely other source code management systems), so that anyone reviewing the changes can see exactly what changed, down to the single character level. There is also an axiomatic diff tool available via the OBO Foundry that folks might find useful, available at https://robot.obolibrary.org/.  I don’t know how well it works on RDF alone, mainly because I haven’t attempted to use it for that, but it works well as a companion tool to the RDF Toolkit from the EDM Council as needed.\n\n \n\nWe also have a pipeline that looks for a myriad of issues in ontologies, performs regression testing using examples and reference data, and includes an html-based publication process that itself has a comparison feature, enabling comparison of any pull request or prior release with another version or with the latest version. The code for this is also open source, available from the EDM Council GitHub repository, though support is required for hosting and customization.\n\n \n\nBest regards,\n\n \n\nElisa\n\n \n\n \n\n \n## Thomas Pellissier-Tanon\n\nOn 9/13/2024 11:50 PM, thomas@pellissier-tanon.fr wrote:\n>> This is due to the fact that even a small difference can cause the \n> canonicalization to relabel blank node in a completely different way. So even blank nodes that were not impacted by the change may end up with different names, and so the text diff applied to the canonical form will report those as changes.\n>\n> A way to circumvent this issue is to tweak the \"Issue Identifier Algorithm\" part of RDF canonicalization to assign an identifier based on the node hash instead of a global counter. This way only blank nodes that have a path with only blank nodes vertices to the changed triples will get their ids changed and the other ones will stay the same.\n>\n> Thomas\n>\n>\n> Le vendredi 13 septembre 2024 à 20:10, Florian Kleedorfer <florian.kleedorfer@austria.fm> a écrit :\n>\n>>\n>>\n>> Hi,\n>>\n>> Curious this is coming up just as an effort to get consistent formatting\n>> for RDF (TTL for now) out the door on behalf of QUDT.\n>>\n>> Looked into canonicalization but the downside you mention is a\n>> non-starter if you want to track changes with a version control system,\n>> so we're just reproducing the input order of blank nodes by hacking into\n>> the jena TTL parser.\n>>\n>> code: https://github.com/atextor/turtle-formatter\n>>\n>> which is being plugged into\n>>\n>> https://github.com/diffplug/spotless/ (maven plugin for now)\n>>\n>> Bottom line: you'll be able to format TTL consistently with the spotless\n>> maven plugin soonish. Maybe one day, you won't even lose your comments.\n>>\n>> Reach out if you want to help making it work for other formats or if you\n>> want a gradle/sbt plugin\n>>\n>> Best regards,\n>> Florian\n>>\n>> Am 2024-09-13 16:18, schrieb Pierre-Antoine Champin:\n>>\n>>> Dear all,\n>>>\n>>> yesterday during the RDF-star working group call, I mentioned that RDF\n>>> canonicalization [1] can be used to build a crude RDF \"diff\" tool, and\n>>> that I was using a small script that I wrote for that. Other\n>>> participants expressed interest for this script, so I cleaned it up a\n>>> bit and published it here:\n>>>\n>>> https://gist.github.com/pchampin/7017fa5ff607e5bedf65e2f9954cfd46\n>>>\n>>> As indicated at the top, it relies on my Sophia library [2] for parsing\n>>> and canonicalizing, but it can be easily adapted to use other\n>>> command-line tools (for a while, I was using Gregg Kellogg's Ruby\n>>> implementation [3]).\n>>>\n>>> Note that I describe it as a crude tool because\n>>>\n>>> - if the two graphs/dataset are isomorphic (i.e. identical modulo blank\n>>> node labels), it will show no difference,\n>>> - BUT if there is only the slightest difference, the tool may report a\n>>> lot of changes, not all of them relevant.\n>>>\n>>> This is due to the fact that even a small difference can cause the\n>>> canonicalization to relabel blank node in a completely different way.\n>>> So even blank nodes that were not impacted by the change may end up\n>>> with different names, and so the text diff applied to the canonical\n>>> form will report those as changes.\n>>>\n>>> But despite these \"false positives\", I find it quite useful, and you\n>>> might too. In particular, if the changes only impact triples/quads on\n>>> IRIs and literals, the diff will be \"exact\".\n>>>\n>>> best\n>>>\n>>> [1] https://github.com/w3c/rdf-canon\n>>> [2] https://github.com/pchampin/sophia_rs\n>>> [3] https://ruby-rdf.github.io/\n>\n","n":0.035}}},{"i":5181,"$":{"0":{"v":"Para on Paper","n":0.577},"1":{"v":"\n\n|\n\n[![](https://d24ovhgu8s7341.cloudfront.net/static/every-logo.png)](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvLyIsInBvc2l0aW9uIjowfQ==)\n\n[![](https://d24ovhgu8s7341.cloudfront.net/uploads/publication/logo/6/small_EVERY_PRAXIS.png)\n\nPraxis\n\n](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3ByYXhpcyIsInBvc2l0aW9uIjoxfQ==)\n\n[PARA on Paper](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3ByYXhpcy9wYXJhLW9uLXBhcGVyIiwicG9zaXRpb24iOjJ9)\n================================================================================================================================================================================================================================================================================\n\n[How I adapted the PARA process and transformed my knowledge management](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3ByYXhpcy9wYXJhLW9uLXBhcGVyIiwicG9zaXRpb24iOjN9)\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nby [Christina Luo](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL0BjeXhsdW8iLCJwb3NpdGlvbiI6NH0=)\n\n![](https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/1972/newsprint_photo-1494599948593-3dafe8338d71.jpeg)\n\nPhoto by J. Kelly Brito for Unsplash\n\nWhen I first took Tiago Forte's productivity course [Building a Second Brain](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL3d3dy5idWlsZGluZ2FzZWNvbmRicmFpbi5jb20iLCJwb3NpdGlvbiI6NX0=) (BASB) in April 2020, the concept I struggled the most to grasp was [*PARA*](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2ZvcnRlbGFicy5jby9ibG9nL3BhcmEvIiwicG9zaXRpb24iOjZ9). Short for \"projects, areas, resources, and archive,\" PARA is a system for organizing your digital notes around projects you're actively working on. In turn, whether or not certain information inspires action becomes a filter for the kind of content you consume and save. Previously, my digital workspace consisted of tasks, files, and saved articles scattered across my desktop and various apps at worst. At best, they were grouped into arbitrary folders like business, psychology, and history---categories that resembled a college course catalogue. But my goal here wasn't to get a degree in knowledge management or index the web. With PARA, in theory, I knew the acronym and its definitions. In practice, my attempt to perfectly set up this system for actionability was preventing me from *taking* action. \n\nWhat was the difference between a \"project\" and an \"area\"? Was this a hierarchical or nesting situation? How would the system scale across different tools? Which app should I build this out with? These were inconsequential problems I convinced myself I needed to solve before venturing further into the course, believing that the lack of structure was the bottleneck for my personal projects. \n\nIt took me a while to understand that PARA was a framework that would emerge over a need and over time. I often took a case-by-case approach to my projects, customizing or adapting frameworks and workflows around specific contexts. Having experienced how too much structure early on could stifle more than scaffold, I was skeptical of systems that felt prescriptive and standardized to the point of being boilerplate. At the same time, I had felt how time- and energy-consuming it was to start every project from scratch, indecisive on how to save and resurface information for when I needed it.\n\nThroughout the course, I noticed students often progressed through points of:\n\n1.  **Convergence** -following the established frameworks and methods\n2.  **Divergence** - forming your own frameworks and methods\n\nIn convergence, you implement the content to understand what works and doesn't work for you. This looks like following step-by-step directions and mirroring workflows. In the process, you begin to internalize the principles behind a practice. From there, you're free to reshape the rules, which you'll realize were nonexistent to begin with. During BASB, I had focused on convergence. When things didn't click, I assumed I needed to follow instructions more closely. It wasn't until I rejoined BASB as an alumni mentor a few months later that I saw the concepts through the lens of divergence.\n\nAs I was preparing my weekly mentor sessions, I realized my earlier resistance to PARA had less to do with its instructions, and more to do with me ignoring my intuition. As I prepared my lesson plans, I thought about how I would've taught the concepts and the principles behind them to myself. In this way, the four-letter acronym now became the output, not the input.\n\nThat shift in perspective led me to create an exercise I've nicknamed \"PARA on Paper.\" Building on the PARA framework, this activity challenges you to write down what you need to get done on a single page. It's a way to try out PARA at the smallest and most flexible level before scaling the system across software. From that blueprint, it becomes more intuitive to design and integrate PARA within existing workflows.\n\nSince running and refining this exercise in BASB and outside of the course, I've had a chance to record the process, with the goal of showing how both personal and team knowledge management can be emergent and built just-in-time.\n\n### The PARA on Paper Process\n\n#### Timing and Tooling\n\nBefore we begin, a few notes on how long the PARA on Paper process takes, and on what tools you (don't) need. \n\n**Timing:** I usually limit this entire exercise to 10-20 minutes depending on the size of the group, but feel free to adjust. While taking inventory of your current projects feels like it should be a time-intensive and thorough sweep, the constraint of a time crunch is intentional. When you only have a few minutes to list things down, you're forced to let go of definitions and instinctively surface what's top of mind---and often top priority. There's just enough time to capture key points, but not enough time to get into the weeds. Only once you've set up the scaffolding can you go back in and fill the architectural gaps at a later time---but not a moment before. \n\n**Tooling:** This exercise is intended to be done on paper (hence the name), but the idea behind it is that writing out PARA or any organizational framework down on one page allows you to visualize your work at the smallest, most flexible level before you scale it across more complex software. On paper, you can easily scratch, scribble, and move things around with a single stroke. Nothing is permanent, and therefore the pressure for perfection eases up. It can also be sobering to see the extent of your current and upcoming commitments laid out flat, unobstructed by dropdowns, folders, or backlinks, that might otherwise provide a false sense of prioritization and progress. Paper as a medium doesn't have to be prescriptive either. Even a sticky note, napkin, or any no-frills text editor will do. I've tried dozens of note-taking and project management apps, but at the end of the day, I find myself returning to a notepad or Google Doc---at least to start. It lowers the hurdle between planning and producing to the point that I can step over it without worrying about tripping. \n\n#### Begin with questions\n\nThe first adaptation I made was reframing PARA from its original definitions to a series of guiding questions:\n\n[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1972/optimized_Screen%20Shot%202022-01-06%20at%205.23.29%20PM.png)](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2QyNG92aGd1OHM3MzQxLmNsb3VkZnJvbnQubmV0L3VwbG9hZHMvZWRpdG9yL3Bvc3RzLzE5NzIvb3B0aW1pemVkX1NjcmVlbiUyMFNob3QlMjAyMDIyLTAxLTA2JTIwYXQlMjA1LjIzLjI5JTIwUE0ucG5nIiwicG9zaXRpb24iOjd9)\n\n##### Question 1: What are you currently working on? What do you need to get done? \n\n*Suggested time: 5 minutes*\n\nA project preserved within the confines of your mind is in a perfect and protected state. But it's also in its most ineffective form until you write it down. Starting with a blank page, the first step is to list out what you currently have on the go and what you need to get done, mentally scanning the upcoming week, month, and quarter. \n\nStarting out, quantity precedes quality. There's no right or wrong way to phrase each project, no rigid definition of what a \"project\" is, and no set number of projects you should aim to list. This is about getting ideas out of your head and onto the page. What gets forgotten is just as revealing as what gets remembered. The very act of writing down what you're working on is the beginning of organizing your thoughts, and of taking inventory of where you're directing your time and energy. Text is merely a placeholder for what you've always known, always wanted to do, but neglected to articulate. \n\n##### Question 2: How would you group your projects based on common stakeholders, timelines, dependencies, or the amount of context shifting?\n\n*Suggested time: 2-5 minutes*\n\nGoing through the projects listed earlier, notice the common themes and natural groupings. As you filter through your projects list with these questions, your Areas will emerge:\n\n-   From an energy management standpoint, which projects involve similar levels of context switching?\n-   Which projects when grouped together make the most sense?\n-   Are there shared timelines or dependencies between projects? \n-   Which projects have the most stakeholders in common?\n-   Which projects are routine versus one-off?\n-   Can any projects be combined, relegated to a task within a project, delegated, or eliminated?\n\nHere's what I wish I understood earlier: Areas aren't so much defined in advance as they are discovered along the way. My first time in BASB, I followed along as others who seemed to know what they were doing typed out Projects, Areas, Resources, and Archive on a pristine Notion page. New pages were created for Areas like Home and Health, each with its own emoji, cover photo, and linked to a task list or kanban board. I did the same. By the end of the demo, I walked away with an aesthetic and intricately linked dashboard---which I barely revisited. Sure, Home and Health were relevant areas in my life, but they didn't require a digital presence to be managed. By defining and scaling Areas on software before I had a view of my Projects, I wound up pigeonholing the latter. \n\nStarting again, I began with only Projects and Archive (PA) this time, gradually adding Resources (PRA), before eventually getting to a point in my work that a need for Areas even arised. My version of PARA looked vastly different from the examples I saw, but it made sense to me and the just-in-time approach alleviated the need to have everything figured out before starting. With personal knowledge management especially, Areas can be as clear or cryptic as you'd like, categorized into a series of questions to explore or goals to pursue, to a set of emotional, mental, and physical states to maintain.\n\n##### Question 3: What information might you need to get the work done? What artifacts might you produce in the process?\n\n*Suggested time: 3-5 minutes*\n\nIn the process of completing your projects, write out the information you'll need or questions you'll answer along the way.\n\n-   What information, tools, or resources will you need?\n-   What deliverables or artifacts might you generate? \n-   Is there material you can repurpose from previous work?\n\nSimilar to Areas, I only create a heading or folder for Resources once there's actually a file to go in it. Resources might include:\n\n-   Meeting agendas, minutes, and topic banks\n-   Facilitation guides and activities\n-   Standard operating procedures\n-   Research reports and briefing notes\n-   Stock photography, icons, and brand guidelines\n-   Calendars, run sheets, and contact lists\n-   Presentation and report templates\n-   Communication scripts and swipe files\n\nYour Resources may look like creative residue, but they're often the root of future creative output. Creativity and expression as an extension of knowledge management often get boxed into what generates the most noise: reserved for and synonymous with YouTube channels, podcasts, blogs, and other public, prolific forms of media. In contrast, a book highlight, a meeting summary, family recipe, map of a frequented trail, internal company newsletter, or personal mood board are quieter but no less valid as Resources and forms of creative expression. What gets overlooked is often what already exists, just not external facing. While Resources is less actionable than Projects and Areas in terms of order, I believe it is the most action-oriented way of remembering and reviving your past work.\n\n##### Question 4: What and where is everything else that is not a present priority?\n\n*Suggested time: 1-5 minutes*\n\nArchives is the final category in PARA that tends to be the most straightforward to understand while taking the least amount of time to implement digitally. On paper, this is a step I skip. As the name and definition implies, anything and everything that isn't a present priority and doesn't fit the previous three categories goes into this separate folder. It's low-risk: your files aren't deleted, just dormant---and high-reward: your once-cluttered workspace has now cleared up. Out of sight, but still in mind.\n\n#### Adaptations for team knowledge management\n\nI've run variations of this exercise with teams, whether with a work, social, or volunteer group. You could also organize this with family. With teams, I recommend designating a facilitator to guide the group through the mostly silent sprint, as everyone individually lists out what they're working on. From there, projects are pooled into a shared document, where the team discusses how to group them based on common themes, objectives, or priorities. The structure diverges from PARA and may resemble more of a RACI or Gantt chart, but the underlying concept of figuring out what you need to get done before building a system around it remains constant.\n\nI usually start from an outline like this...\n\n[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1972/optimized_Screen%20Shot%202022-01-06%20at%205.23.40%20PM.png)](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2QyNG92aGd1OHM3MzQxLmNsb3VkZnJvbnQubmV0L3VwbG9hZHMvZWRpdG9yL3Bvc3RzLzE5NzIvb3B0aW1pemVkX1NjcmVlbiUyMFNob3QlMjAyMDIyLTAxLTA2JTIwYXQlMjA1LjIzLjQwJTIwUE0ucG5nIiwicG9zaXRpb24iOjh9)\n\n...before building out a basic project plan, which I've formatted in tables in this example:\n\n[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1972/optimized_Screen%20Shot%202022-01-06%20at%205.23.48%20PM.png)](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2QyNG92aGd1OHM3MzQxLmNsb3VkZnJvbnQubmV0L3VwbG9hZHMvZWRpdG9yL3Bvc3RzLzE5NzIvb3B0aW1pemVkX1NjcmVlbiUyMFNob3QlMjAyMDIyLTAxLTA2JTIwYXQlMjA1LjIzLjQ4JTIwUE0ucG5nIiwicG9zaXRpb24iOjl9)\n\nFor team knowledge management, I've tried various apps, but find that if the goal is adoption\n\nand shared ownership, it works best to meet people where they are, using familiar tools. I usually create this on a Google Doc or Sheet, but all of it can be scaled to more sophisticated project management tools. If your team uses a shared drive, this setup can be mirrored across a folder system. The documentation itself becomes a tool that can be repurposed for one-on-ones, project meetings, and cross-team information or collaboration. While some people have successfully merged their personal and team knowledge management systems, I find separating work and personal projects maintains a healthy boundary between the two priorities, even if it means using different tools or accounts for each.\n\n#### Knowledge management as a record of your discovery\n\nThe moment I realized I didn't need PARA---or any organizational framework for that matter---in order to take action, was the moment I began to understand it. Even today, I spend most of my time at the projects and tasks level, with everything else in various stages of archive. By starting at the smallest, most actionable level, and only adding layers when the need arises, your time shifts from maintenance to making things happen.\n\nBuilding a knowledge management system is about leaving a record of your discovery. An idea, once expressed in writing, is no longer just an idea, but something to inspire and take action on. Starting with an inkling of what you need to get done might not seem particularly remarkable, but making sense of it in writing is a remarkable feat. Ordering tasks into a plan is a remarkable feat. Communicating what that plan will help you create is remarkable. All of it is valuable, especially if you get it down on paper. \n\nMy unremarkable epiphany about knowledge management throughout all of this is that it's about subtle shifts in awareness. Moving things from invisible to visible, private to public, and closed to collaborative. Whether that's externalizing intuition into insights or making your projects and priorities known to yourself or your team, shared awareness can be used to show up for yourself, and help others show up at their best.\n\n#### What did you think of this post?\n\n[Amazing](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3ByYXhpcy9wYXJhLW9uLXBhcGVyL2ZlZWRiYWNrP3JhdGluZz1hbWF6aW5nXHUwMDI2aGFzaD0lcmVjaXBpZW50Lmhhc2glIiwicG9zaXRpb24iOjEwfQ==) [Good](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3ByYXhpcy9wYXJhLW9uLXBhcGVyL2ZlZWRiYWNrP3JhdGluZz1nb29kXHUwMDI2aGFzaD0lcmVjaXBpZW50Lmhhc2glIiwicG9zaXRpb24iOjExfQ==) [Meh](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3ByYXhpcy9wYXJhLW9uLXBhcGVyL2ZlZWRiYWNrP3JhdGluZz1tZWhcdTAwMjZoYXNoPSVyZWNpcGllbnQuaGFzaCUiLCJwb3NpdGlvbiI6MTJ9) [Bad](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3ByYXhpcy9wYXJhLW9uLXBhcGVyL2ZlZWRiYWNrP3JhdGluZz1iYWRcdTAwMjZoYXNoPSVyZWNpcGllbnQuaGFzaCUiLCJwb3NpdGlvbiI6MTN9)\n\nYou received this email because you signed up for emails from [Every](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvIiwicG9zaXRpb24iOjE0fQ==). No longer interested in receiving emails from us? Click here to [unsubscribe](https://every.to/emails/click/444aab9bf98e4442781ded6a6300f197cc121842ac0e7da0bced82df3f1596ab/eyJzdWJqZWN0IjoiUEFSQSBvbiBQYXBlciIsInBvc3RfaWQiOjE5NzIsInBvc3RfdHlwZSI6InBvc3QiLCJ1cmwiOiJodHRwczovL2V2ZXJ5LnRvL3Vuc3Vic2NyaWJlP3Bvc3Q9cGFyYS1vbi1wYXBlclx1MDAyNmhhc2g9JXJlY2lwaWVudC5oYXNoJSIsInBvc2l0aW9uIjoxNX0=).\n\n221 Canal St 5th floor, New York, NY 10013\n\n |\n\n![](http://email.mg.every.to/o/eJwVyzsOgzAMANDTNBtR7Jo4HnIYk09hgCCDKvX2bcc3vJq7CCzqtowBMUBgSLMQ-ZhK6jwjF21LWvqDwv7y7d3s4-_h1qxCwEL8pAgkkXvqmFqACgg1SnGWq21lVavXOH5dt662X76M3d35VNNpHNOpZ7O_x3VPIIxf-g8sIA)\n","n":0.02}}},{"i":5182,"$":{"0":{"v":"How Renaissance Rationalization and Oceanic Navigation Lock into Commodotization Takeoff","n":0.316},"1":{"v":"\n- [[p.hasAuthor]] @justin-murphy\n","n":0.577}}},{"i":5183,"$":{"0":{"v":"Gfo Users Gfo Presential Persistent Perpetuant","n":0.408},"1":{"v":"\n## GFO Presential/Persistent/Perpetuant\n\nm I understanding this right (rephrased into my own words)?\n\n- Presential (Queen Elizabeth II) is the physical manifestation of her at a point in time, like (but not equal to) a picture, including her shape/boundary, characteristics, constituent molecules, etc.\n\n- Persistant (QE2) is like her identity or the social concept of her person, essentially a definition of what makes her unique, that she is a person/queen/woman/British, and the characteristics that would allow someone to recognize a presential as presential(QE2). My personal concept of “QE2” is a direct representation of this.\n\n- Perpetuant (QE2) is the actual person  (at the phenomenal level of reality at least) who is moving through time and space. If so, then these correlate most closely with the general concept of endurants.\n\n- To this can be added Process(QE2), her life/living.\n\n\nIf I am on the right track, then this distinction makes perfect sense. However, I am confused as to why the GFO documentation spends very little time talking about perpetuants, giving a half-sentence definition (and the undefined exhib function), but no real explanation or examples, even though they seem to be the most interesting and relevant thing to real life. It isn’t even in the OWL. Conversely, presentials are dealt with at length, and integrated with the rest of the ontology, even though they are arguably the least useful aspect of the three.\n\n \n\nWhat I am looking for is a good formal definition that I can use to create a simple rubric to help normal people quickly determine whether an individual is a process/occurrent or an endurant/P/P/P. In all the top-level ontologies (DOLCE, SUMO, BFO, etc.) and all of the philosophical literature I have been through so far, the definitions (endurants have no temporal parts, endurants are “whole” at t) are never defined in formal logic (BFO’s definition is circular!), and generally discussed with a lot of hand-waving (“isn’t it obvious?”). Well, it turns out that in my domain (geography), there are a lot of cases that are far from obvious.\n\n \n\nI’m hoping that there is other GFO-based literature out there that fleshes this out further. Any hints?\n\n\nThank you,\n\n \n\nBrandon Plewe\n\n## Thoughts\n\n- no follow-up!?\n- can't find any other mentions of \"Perpetuant\", even the \"half-sentence\"\n-  the perpetuant seems abstract-ish. \n\n### Perpetuant vs Life\n\n- @chatgpt.4o: The perpetuant (e.g., the person) is the subject that participates in the process of living. While the perpetuant exists continuously, the process of living is broken into temporal parts (events, stages of life) that the perpetuant experiences.\n\n\n### chatgpt4.o\n\n\"Possible Interpretation: Perpetuants may refer to certain properties or qualities that persist in a timeless or changeless fashion, as opposed to presentials, which exist at a specific moment, or persistants, which endure through time but may change.\"","n":0.047}}},{"i":5184,"$":{"0":{"v":"Dont Put the Tool before the Craft","n":0.378},"1":{"v":"\n- [[p.hasAuthor]] @nat-eliason\n\n\n\n\t\t\n\t\nOpen in browser\nDon't Put the Tool Before the Craft\nBreaking Up with Productivity Advice\n\t\nNat Eliason\nAug 1\t\n\t\nComment\n\t\nShare\n\nI am deeply envious of chefs with great knife skills.\n\nThe precision, the speed, the consistency. The twinge of fear in your fingertips as their blade glides in front of their nails. The satisfaction of a neat pile of green onions at the end of the cutting board. It’s delicious. \n\nI asked Myles Snider if he could teach me or knew where I could learn. But I was shocked when he said “Honestly man, don’t bother.” \n\nDon’t BOTHER? How could a chef tell me not to bother learning advanced knife skills? Surprised, and a little miffed, I asked him to explain.\n\n“Chefs have to learn these crazy knife skills while they’re staging because they might spend hours cutting vegetables every day. You spend, what, ten to twenty minutes a week cutting things? Basic knife skills are gonna be fine for you.”\n\nHm, fair point. I could spend weeks practicing knife skills and it would only save me a few minutes every week. There were other benefits of course, like showing off at dinner parties, but it wouldn’t help me with what I really wanted: to get better at cooking. \n\nMyles helped me avoid an easy error: \n\nPutting the tool before the craft.\nII\n\nI shared a confession last week: I’ve abandoned most of the productivity techniques I blogged and talked about over the last decade. \nTwitter avatar for @nateliasonNat Eliason @nateliason\nI used to be a hardcore productivity nerd, but I’ve abandoned most of it and don’t miss it. \n\n- Random tasks in Things\n- Take most notes in Apple Notes \n- Try to get a few satisfying things done per day \n\nProductivity obsession is often a symptom of deeper dissatisfaction.\n\nJuly 28th 2022\n36 Retweets911 Likes\n\nMy first blog back in 2012 was all about developing good, productive habits. On my old blog, I have a couple dozen articles on productivity. I have tried almost every tool, trick, tactic, and voodoo ritual to David Allen under the sun. \n\nDid they work? Sure, I got really good at checking off boxes and ignoring text messages and breaking my 10 year goals down to minutely goals.\n\nBut did all that technique do anything? That I’m less sure about. It’s not like I’m launching rockets or creating new medicines or running for President. It didn’t make my writing better. Maybe I can squeeze a bit more out of my 16 waking hours a day, but that’s hardly the metric we judge our lives on. For the most part, I was using my vast expertise in productivity to… make more content about productivity.¹ \n\nThere is, of course, a balance. If you learn nothing about working smarter you’ll waste countless hours. But our productivity methodology is just a tool. And it’s a mistake to confuse tool sharpening, or worse, tool buying, with actual work. Playing around with a new writing app feels like it’s going to be the thing you need to finally sit down and write that great novel inside you, even though 99% of all great books were written by hand or typewriter.²\n\nWe can’t be too hard on ourselves for getting distracted by this confusion though. There is so much content focused on trapping the attention of everyone looking for quick fixes. All you have to do is open YouTube or TikTok and you’ll learn more about what people with yachts do for a living, the habits of highly successful people, and what some surprising new study says about focus.³ \n\nBut Myles's advice for knife skills applies even more to productivity. Most of us are wasting time we could be spending learning our craft by playing around with our tools and washing our pickup truck instead of hauling anything.⁴\n\nSo how do we find the right balance? We need to find the minimum viable scaffolding to get our work started and then focus on doing the work from there, making little adjustments as we go.⁵ \n\nTo the extent you’re going back to working on your tools, it should be driven by some noticeable shortcomings in the actual work. Your knife isn’t cutting like it used to. You’re losing too much time to email. Tool work should always be a focused attempt to fix a specific problem, not passive information consumption hoping to find a quick win that will make the work easy.\n\nIf there’s no major problem, stop looking for solutions. Every minute we spend looking for The Right Tool is a minute we’re not using our perfectly good word processor to bang out the next great American novel. \n\nDon’t put the tool before the craft.⁶\n\nIf you enjoyed this post, you’ll love next week’s. Subscribe so you don’t miss it.\n\nSubscribe now\n\t\n\t\nVulcan (aka Hephaestus) at the Forge by Jacopo Bassano. While Achilles's shield is important in the Iliad, Hephaestus is not the hero. Achilles is.\n1\n\nThis is kinda the dark truth with many of these topics, particularly productivity and finance. No amount of goal setting or planning will make up for working on small things or having a low-value skillset. No amount of investing or budgeting will make you rich off a small income. There are usually much higher leverage areas to focus on, but that’s much harder to do and doesn’t get clicks from people looking for easy wins.\n2\n\nAdmit it, you’ve thought about buying a typewriter.\n3\n\nThat is the Jack and the Beanstalk myth after all: Jack wants to get rich quick so he sells the family cow for magic seeds and ends up finding a goose that lays golden eggs. We all want to believe that the right magic beans will save us from a life of arduous farming. It’s weird that we tell this story to kids. Jack should end up obsessed with finding magic seeds and die falling off a beanstalk or something.\n4\n\nI admit to judging anyone who drives around with an exceptionally clean, unscratched, undented pickup truck. For the year or so I had my Tacoma I only washed it once.\n5\n\nAsking an expert to advise you on that minimum viable scaffolding can be a frustrating process though. Here’s Stephen King on how to organize the plot of a novel from “On Writing”: \n\n“I want you to understand that my basic belief about the making of stories is that they pretty much make themselves. The job of the writer is to give them a place to grow (and to transcribe them, of course).”\n\nHe suggests that you don’t try to plot out your novels at all. You just start with a character in a situation and see what happens from there. I fully believe that this is what King does and it works for him, but it’s rough advice for a newcomer. That’s probably something you can do after you’ve written a dozen novels. We all want to get to a point where we don’t need any structure and can just flow in our craft intuitively, but you have to get through the Conscious Incompetence and Conscious Competence phases first. \n6\n\nTo attempt to provide some minimum-viable-scaffolding for productivity, so you can turn off the feed and get back to work, here it is in one sentence:\n\nDo the most important thing for a few high-energy hours, with minimal interruptions, every day.\nLike\n\t\nCommentComment\n\t\nShareShare\n\nYou’re a free subscriber to Infinite Play. For the full experience, become a paid subscriber.\n\nSubscribe\n\n© 2022 Nat Eliason\n548 Market Street PMB 72296, San Francisco, CA 94104\nUnsubscribe\n\nGet the appStart writing\n\t\n","n":0.029}}},{"i":5185,"$":{"0":{"v":"De Atomization Is the Secret to Happiness","n":0.378},"1":{"v":"\n\t\t\n\t\nOpen in app or online\nDe-Atomization is the Secret to Happiness\nIt may be that simple\nNat Eliason\nNov 7\n\t\n \n\t\t\n\t\t\n\t\nSave\n\t\t\n▷  Listen\n \n\t\n\t\n\nThere are at least two kinds of fun: \n\nType 1 fun is fun in the moment. Watching a movie, playing a video game, scrolling TikTok, reading a book. You want to have fun, you do the fun thing, and voilá, it is fun. \n\nType 2 fun is fun in retrospect. Running a marathon is mostly un-fun from moment to moment; you’re often either zoned out or in some form of pain. But in retrospect, it was fun. \n\nI’ve spent over 1,000 hours playing the video game DOTA 2, but I remember almost zero of that time. It was strong type 1 fun but very low type 2 fun.\n\nI once went to a DOTA 2 International tournament with a friend, though, and I remember most of that experience quite vividly. Significant parts were unfun: waiting in line, commuting to the arena, bumping into one of the questionably hygienic gamers whose body must be 63% pizza and getting a whiff of Geneva-violating body odor. But overall, it was very fun. \n\nDespite being moment-to-moment less fun than playing the game, going to the tournament was ultimately more fun. Playing the videogame is very fun, but it’s monolithic. It’s just play, there’s no environmental novelty full of multisensory stimuli to hook your memory into. It blurs from one moment to the next, and like bad American Chinese food, you find yourself paradoxically unsatiated when you’re done. There’s something more fun about complex fun, even if the individual moments might score lower on the hedonometer. \n\nBut fun is just one area where we can see this phenomenon. There is a clear experiential divide between rich multisensory life and what I’ll call “atomized” life. \n\nAnd atomized life is worth avoiding. \nII\n\nWhen I wrote about how much weaker we’ve gotten, several people rightly pointed out that the reason was obvious: most of us no longer do hard labor as our day jobs. When you had to walk or jog 20 miles a day for sustenance or spend all day carrying canoes and packs on your shoulders or drag bricks of limestone around for pharaoh, you were default strong. When you spend all day sitting in a chair getting enraged / entertained / aroused / whatever by algorithms, you are default flabby. \n\nLife and fitness used to be deeply intertwined. You could not live without fitness. Now they are separate: fitness is a cute thing rich people do in their Lululemon after work or while jiggling their mouse to keep the Slack bubble green. You don’t do it to stay alive, you do it to get laid or not resent yourself or maybe if you’re particularly enlightened to “feel good.”\n\nFitness has been atomized: it is no longer part of a cohesive whole life. It’s a separate thing you have to try to “find time for.” When someone says they “don’t have time” to work out, they’re both stating their priorities (obviously, everyone has time)¹ but also stating something about their life. It does not have fitness incorporated into it. \n\nBeyond the atomization separating fitness from normal life, there is also further atomization within fitness. Let’s take biking as an example. First, biking was something you did outside, often with friends. There was scenery, socialization, exploration, sunlight, and exercise. Then the exercise element was captured in stationary bikes, placed in a gym or a spin class, and most of the richness was removed. You still got the exercise, and some socialization from being in the gym or class, but there was no scenery, no exploration, no time in the outdoors. Then we got Peloton. No socialization. No scenery. No exploration. No sunlight. Exercise, sure, and Emma is cute, but that’s it. The richness of biking is gone. \n\nAnd, look, I love my Peloton, but it’s Type 1 exercise. Instead of exercise being a multifaceted activity that incorporates other essential life elements like seeing friends, getting fresh air, and looking away from a screen for a few moments, it reduces it to its simplest element and suggests that’s just as good. Maybe even better because you get a “harder workout.” The most important part of exercise, after all, is INTENSITY.² \n\nWhere else do we see over-atomization? Food comes to mind. A meal should be about more than just food. Relaxation, spending time with your friends and family, fun, maybe joy. If you looked at an Italian neighborhood dinner and said “wow what a waste, don’t they know they could just drink a Huel and get back to work?” then, well, oof.\n\nBut atomization encourages us to reduce multivariate experiences, often the most important parts of life, to their single most obvious element:\n\nBiking is about exercise, and scheduling with friends and planning a route and inflating your tires all get in the way of that. \n\nEating is about sustenance, and inviting friends and getting groceries and cooking all get in the way of that. \n\nRelationships are about talking, and meeting up in person and leaving the house and scheduling are all inconveneiences.\n\nWork is about checking off tasks, so spending time commuting to an office where you might goof off and socialize all get in the way of that. \n\nThen when we feel lonely, painfully isolated by our atomized life, we schedule some atomized social time like going to a bar or coffee to see friends in between our lonely work and lonely dinner because we’ve removed most of the natural socializing elements from all of the other parts of life. Atomization turns an integrated day of socializing, eating, exercising, and working into discrete hurried chunks of trying to move from one thing to another, wondering why we never seem to have time for everything. \n\nAtomization is a global version of the problem I discussed in “work life balance is impossible,” the reason you can never have “work-life balance” is that you’ve placed Work and Life at odds, as ends of a scale that needs to be balanced out lest it tips too far in either direction. \n\nIf you throw Exercise and Socialization and Food and Fun and Hobbies into some complicated hexascale with Work and Life, you suddenly feel overwhelmed and start eyeing the benzos because seriously how can you possibly oh shit did the dogs get fed today ugh when did you last finish a book can you believe she hasn’t called you back is it 5 o’clock yet? \n\nBut at the root of this overwhelm is the language we use around many activities. “I’m going to go workout” feels more responsible than “I’m going to go for a walk with a friend.” We separate “I’m working” and “I’m playing.” We want to make everything extremely efficient, so we opt for going for a run alone instead of trying to link up with people along the way. We need to “be productive” so we don’t work from a coffee shop with friends.\n\nThere is probably some blame to be put on the dumb productivity world for this too. People think they need to focus and give things their full attention as if attention is the most important resource to optimize for. For your hour or two of deep work, sure, but after that, there’s no reason you can’t hang with friends while slowing chugging through shallow work. Obviously, you can multitask. You’ve never talked to someone while walking before? \n\nThe solution to the atomization curse that both gives us significantly more time back, and makes us much happier, is to seek to reintegrate these various foci of life as much as possible. How do you turn food back into a rich, multivariate experience with friends, fun, exploration, and relaxation? How do you blend socialization and exercise and community? How do you spend less time having shallower atomized relationships through a screen, and more time having rich in-person relationships where you get the full experience of other people? \n\nThe challenge is that these “Type 1,” or Atomized, versions of activities are the most immediately appealing. Booting up my computer to play a video game is way easier and sounds more immediately fun than texting some friends to play pickleball. Crushing takeout chips and queso sounds tastier and easier than cooking steak and rice. But I know I’ll feel better afterward with the latter, and that’s what we have to try to optimize for. Integrated living is more satisfying than atomic living. \n\nInstead of looking at some problem like “I don’t see enough friends,” or “I don’t work out enough,” or “I don’t have enough fun,” and then trying to find time to fit those priorities into, we should see how we can incorporate them into what we’re already doing. Could you make your workout less perfectly optimized so you can do it with friends? Can you loosen the reigns on your Super Duper Productive Routine to hang at a coffee shop with friends for a few hours a week? And for the love of God, can you please stop drinking fucking Huel or Soylent at your desk and talk to someone instead? \n\nThe more creatively we can integrate the various parts of life that matter to us, the more satisfied we’ll be in our day to day. \n\nThe more we atomize, the more lonely and overwhelmed we start to feel. \n\nDe-atomization is the secret to happiness.\n\nIf you enjoyed this, join the 36,000 other weekly readers by subscribing.\n\nUpgrade to paid\n1\n\nI started working out in high school after hearing that Obama worked out for an hour a day despite his other duties as President. I figured if he had time to make it a priority, I probably did too.\n2\n\nI’m not sure this is true, either. My best marathon training runs were done with a friend who was training for an Ironman. He kept subtly pushing us faster, and I was always surprised by how well I could keep up under social pressure.\n\nYou’re a free subscriber to Infinite Play. For the full experience, become a paid subscriber.\n\nUpgrade to paid\n \nLike\n\t\t\nComment\n\t\t\nShare\n\t\n \n\n© 2022 Nat Eliason\n548 Market Street PMB 72296, San Francisco, CA 94104\nUnsubscribe\n\nGet the appStart writing\n\t\n","n":0.024}}},{"i":5186,"$":{"0":{"v":"Choose Your Table Wisely","n":0.5},"1":{"v":"\n- [[p.hasAuthor]] @nat-eliason\n\n\n\t\t\n\t\nOpen in browser\nChoose Your Table Wisely\nA subtle constraint on work & life\n\t\nNat Eliason\nJul 25\t\n\t\nComment\n\t\nShare\n\t\nundefined\n\t\n\"A Friend in Need\", 1903 by Cassius Marcellus Coolidge\n\nMy favorite year of college was the year I didn't attend college. \n\nI took a year off to work on a startup while still living on campus. I enjoyed all the perks of college: community, parties, all-you-can-eat omelets, but I didn't have to endure the worst part: classes. \n\nIn the evenings, I hung out with my college friends. But during the day, I was at a startup accelerator, spending time with people older than me and further in their careers.\n\nWhen I shut that company down and went back to school, my perspective on the typical problems of a college student had radically changed. Everything seemed so small, so insignificant. I couldn't relate to my challenges from a year ago. \n\nWhen I went back, the old games weren't interesting anymore. \n\nThey no longer felt worth playing.\nII\n\nIn poker, there's an important concept called \"table selection.\" Your success is not just determined by how good you are but also by the table you choose to play at. \n\nYou can't win as much money if you sit at a table with small blinds. You'll get cleaned out if you sit at a table with players much better than you. To have the best result, you need to find a table where the stakes are high enough to be worth playing and where you have a chance of winning against the other players. \n\nPoker is a fantastic visual for this concept since the results of good or bad table selection are so visceral. But we're all choosing which table we play at every day of our lives, in almost everything we choose to do. \n\nWhen you compare your car to someone else, you're sitting down at the \"best car\" table. When you strive for more Twitter followers, you're sitting down at the \"Twitter influencer\" table. When you start a business, you're sitting down at whatever table is determined by the type of business you're trying to create. \n\nTable selection determines the scope and difficulty of your success. Sometimes you have hyper-competitive tables with low stakes and low potential levels of success. Dropshipping commodity goods on Amazon might be a good example, or competing for $50 freelance writing gigs. \n\nSometimes you have tables with high potential levels of success, massive stakes, and almost no competition. I'll put Varda in this category. There isn't much competition yet among space-factory businesses, and if they pull it off, it could be one of the biggest companies in the world. The stakes are very high, though. They could also end up incinerating a ton of money.\n\nAs a creative, the table you choose to play at is among the most important decisions you can make. You could focus on $50 gig writing, building a productivity blog, or writing the next Harry Potter series. Those are all vastly different tables with vastly different potential outcomes. You better choose carefully. \nIII\n\nTable selection also determines some of your happiness.\n\nThe \"keeping up with the Joneses\" effect is a symptom of table selection. If you compare yourself to your neighbors or people who are \"near\" you in whatever you index your life on, you will find countless ways to make yourself feel insignificant or behind. \n\nDan Wang explores how this phenomenon drives college students crazy in his essay on \"College as an Incubator of Girardian Terror\":\n\n\"It's hard to construct a more perfect incubator for mimetic contagion than the American college campus. Most 18-year-olds are not super differentiated from each other. By construction, whatever distinctions any does have are usually earned through brutal, zero-sum competitions. These tournament-type distinctions include: SAT scores at or near perfection; being a top player on a sports team; gaining master status from chess matches; playing first instrument in state orchestra; earning high rankings in Math Olympiad; and so on, culminating in gaining admission to a particular college.\n\nThere's very little external intermediation, instead all competitive dynamics are internally mediated. The prizes are so obvious. The big companies that come to career fairs soothingly assure high-status jobs; the speakers at convocation tell us that we too will become as successful as them one day; our peers hold leadership positions at clubs, get internships at exciting companies, and earn those chances to have lunch with the university's president.\n\nThe lack of external mediation explains why objects of desire on campus can be seen to have such high worth. And why certain leadership positions on campus are heavily fought over, even though they don't seem to have much influence. It also helps to explain why so many people enter into only a handful of fields.\"\n\nWhen I took that year off from college, I broke out of that competitive environment, and suddenly, the games felt silly. When I was sitting at the \"college student\" table, winning the competition for leadership of a club seemed extremely important and very high stakes. But when I stepped away and sat at other tables, I saw how juvenile that focus was. \n\nWe see examples of this kind of narrow, hyper-local competitive thinking all the time, and depending on what level you're playing the game of life, you may or may not pick up on it. It's easy to snicker at the HOA Karen, who thinks it's SUPER IMPORTANT for everyone to perfectly manicure their Hydrangeas. But you certainly have conflicts that would make someone else snicker. \n\nWhere are you comparing yourself against people overly similar to you instead of setting your sights on a bigger table? \n\nWhat small table are you sitting at that you should have moved on from ages ago?\nIV\n\nI play pickleball with a group of friends on Fridays. A few weeks ago, we had seven people, and an older guy was hanging around waiting for his group. \n\nWe invited him to play, and he destroyed us. I think the game ended with a score of 11-2. He was incredible, but he was also just within reach. I scored a couple of good points on him, and I didn't feel like it was utterly hopeless. Maybe he was going easy, or perhaps he was just at that perfect skill level when he could push me to try my best. \n\nEither way, that's the kind of table I love looking for. One where you have some chance of winning, but not unless you try your hardest. And one where the stakes and potential winnings are much greater than you could achieve at a smaller, easier table. \n\nThis is, of course, the secret to good deliberate practice. You always need to be a little outside your comfort zone if you want to keep learning and improving.\n\nIt's why the \"you always want to be the dumbest person in the room\" advice is mostly good, but only mostly. It's great to be the dumbest person in the room so long as you can keep up. Otherwise, you'll look silly.\n\nIt's a core component to achieving success, whatever your yardstick is. If you pick too small of a table or stay there too long, you'll hamstring yourself. It doesn't matter how good you are if you're playing the wrong game or against the wrong people.\n\nAnd it's essential for understanding our feelings of jealousy, envy, competitiveness, and tension with others. If we can recognize what table we see ourselves competing with them on, it's easier to let those feelings go and decide if that's even a table where we want to play. \n\nWe're all stuck on campus in our own ways. Magnifying little problems and challenges that would seem laughably insignificant if we stepped out to a more meaningful perspective.\n\nThe table you choose sets the boundaries for your success and happiness. Choose wisely.\n\nIf you enjoyed this post, you’ll love next week’s. Sign up to get it in your inbox.\n\nSubscribe now\nLike\n\t\nCommentComment\n\t\nShareShare\n\nYou’re a free subscriber to Infinite Play. For the full experience, become a paid subscriber.\n\nSubscribe\n\n© 2022 Nat Eliason\n548 Market Street PMB 72296, San Francisco, CA 94104\nUnsubscribe\n\nGet the appStart writing\n\t\n","n":0.027}}},{"i":5187,"$":{"0":{"v":"Centralization Is Inevitable","n":0.577},"1":{"v":"\n\n>>>\n\n...but decentralization is right behind it.  ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌\n\t\t\n\t\nOpen in browser\nCentralization is inevitable\n...but decentralization is right behind it\n\t\nGordon Brander\nJun 27\t\tShare\n\nI would like to decentralize the web somewhat. Unfortunately, designing an idealized architecture won’t be enough to do it.\nTwitter avatar for @gordonbranderGordon Brander @gordonbrander\n\"That just sounds like centralization with extra steps.\"\nImage\n\nJuly 9th 2021\n1 Retweet8 Likes\n\nConsolidation tends to sneak into systems, often in surprising places, and frequently through some aspect we might feel is “outside” of the system.\n\nSo, if you happen to want to decentralize, it helps to know how and why centralization happens in the first place.\nCentralization as a spectrum\n\t\t\nBaran, 1964 “On Distributed Communications (Memorandum RM-3420-PR)“\n\nOk, first, what do we mean centralization? One sense of centralization is total centralization, a network with a single hub (leftmost figure). But it’s also common to talk about highly consolidated networks as “centralized”. Think banking systems, social networks, or the smartphone duopoly. These consolidated systems happen have more than just one hub, but not that much more. I want to think about about centralization in this sense. Highly consolidated.\n\nWhat about decentralized networks? We might picture an idealized flat network, fully distributed (rightmost figure). Every node is equal in power and function, evenly, or at least randomly, distributed. There’s just one problem…\nNetworks aren’t evenly distributed IRL\n\nHere is a map of the internet. The first thing you might notice is that the internet is not evenly distributed. Instead, we see the emergence of densely connected hubs—centralized islands in the net.\n\nThis kind of thing is called a scale-free network. It seems that something like scale-free structure emerges repeatedly within evolving networks, including on the internet, the web, social networks, airline routes, co-authorship in scientific papers, power grids, inter-bank payment networks, Bitcoin mining, train routes, gene regulatory networks, protein interactions, ecological food webs, oligarchies, neural networks…\n\n    In fact, it turns out that almost all real-world networks have degree distributions with a tail of high-degree hubs like this. (Newman, 2018. Networks.)\n\nIf you see a pattern emerge over and over, it’s a solid bet there are evolutionary attractors pulling the system in that direction. And yeah, it turns out scale-free networks have strange and important structural properties.\nScale-free networks are power-law distributed\n\t\t\nThe organically evolved network of airline routes between airports is scale-free, while the centrally-planned highway network is not. (Barabasi, 2016. Network Science, ch 4.)\n\nThe defining characteristic of scale-free networks is a power law distribution with a long tail. A small number of nodes with an extremely large number of links, and an extremely large number of nodes with a small number of links. Think Twitter. Most users have a few followers, while a few influencers have millions.\n\t\t\nThe degree distribution of the World Wide Web. Figure from Newman (2018), “Networks”, using data from Broder et al (2000), “Graph structure in the web”\n\nThis power law distribution grants the biggest hubs a lot of power over the network. It also makes hubs important to the functioning of the network in ways that are not immediately obvious, like keystone species in an ecology. But what makes a network evolve this power law distribution?\nScale-free networks emerge due to preferential attachment\n\nPreferential attachment is any rich-get-richer feedback loop. We run into preferential attachment all the time in software, in the form of network effect:\n\n    The value of a telecommunications network is proportional to the square of the number of connected users of the system (n^2). ([[Metcalfe's Law|sententia.metcalfes-law-the-value-of-a-network]])\n\nAnd it’s not just telephone networks. Any snowball will do…\n\nNetwork effect. More users mean more users. Think Facebook or Twitter.\n\nAttention: More attention means more pricing power means more content means more attention. The Netflix model.\n\nTrust: More customers means more social proof means more customers. Dunbar’s Number suggests we can’t keep track of more than 150 people and when it comes to trust, brands are people too. I don’t want to saturate my 150 friend limit keeping track of brands, and so that means hubs. This is one reason why there are just a few big banks, for example.\n\nEarly-mover advantage. Crypto and VC both have this property. Early adopters make much more than late ones. Interestingly, this curve is inverse of the network effect growth curve, so tokens can be used as incentive to bootstrap new networks.\n\nEconomies of scale. More scale means more scale. If you are AWS or Azure, more scale means cheaper unit economics means lower prices means more customers means more scale.\nTwitter avatar for @gordonbranderGordon Brander @gordonbrander\nSoftware is approximately zero marginal cost, but approximately is very different from actually. Centralization and aggregation emerge around the accumulating rounding error.\n\nNovember 11th 2021\n4 Retweets29 Likes\n\nCapital: more money makes more money. Classic.\n\n…That hits a lot of the big ones. In general, look for any rich-get-richer compounding feedback loop.\nScale-free networks emerge because they are efficient\n\nThis is something that p2p projects have repeatedly rediscovered. Flat networks perform poorly. Hubs are efficient.\n\n    Peer-to-Peer (P2P) networks have grown to such a massive scale that performing an efficient search in the network is non-trivial. Systems such as Gnutella were initially plagued with scalability problems as the number of users grew into the tens of thousands. As the number of users has now climbed into the millions, system designers have resorted to the use of supernodes to address scalability issues and to perform more efficient searches.\n\n    (Hadaller, Regan, Russell, 2012. The Necessity of Supernodes)\n\nHubs act as routers through which information can travel from A to B to C, efficiently. Scale-free networks are ultra-small worlds. Hubs let you jump around the network in just a few hops. Distances in a scale-free network are smaller than the distances in a random network. This is why airlines build hubs.\n\nIn fact, while in a random network the average number of hops to get from anywhere to anywhere is log(n), in a scale-free network the number of hops only grows as a function of log(log(n)). Hardly at all.\nScale-free networks emerge because of selection pressure\n\nIn an ideal distributed internet, we might all run personal servers from a closet. But we do not live in an ideal world, and running a reliable server is difficult. Computers crash, hard drives die, traffic will spike and your server get swamped. This is why people don’t want to run their own servers, and never will.\n\nSo, servers go down sometimes, and some go down more than others, and this is another reason scale-free networks emerge. Reliability, scalability are selection pressures. Fitter nodes attract more connections just by virtue of staying alive. Eventually this results in hubs. This is the Fitness Model of scale-free networks.\nScale-free networks emerge because they are resilient to failure (yet vulnerable to attack)\n\n    Ecologists believe that the hubs of food webs are the keystone species of an ecosystem, paramount in maintaining the ecosystem's stability.\n    (Barabasi, 2002. “Linked”)\n\nIf you choose a random node in a scale-free network and knock it out, the network won’t even notice because almost all nodes have just a few connections. You’re unlikely to hit a hub. Random bad luck is a constant, and scale-free networks are robust to bad luck.\n\nYet this same structural property makes scale-free networks very vulnerable to targeted attack. Even so, just knocking out one hub is usually not enough. But knock out a few, and the network collapses (Barabasi 2016. Network Science, ch 8).\n\t\t\n\nGood thing Nature isn’t in the business of targeted attacks! But humans sometimes are. Also sometimes hubs do get wiped out by chance. Asteroids happen! Either way, this destabilizes the entire network. Which brings us to…\nNetworks evolve from distributed to centralized and back again\n\nNetworks also have a time dimension, and the shape of the network changes as it ages. Evolving networks exist in punctuated equilibrium, repeatedly evolving through distinct phases of randomness, growth, consolidation, and collapse.\n\n    (Phase 1) Random: The system is unstructured. Random events occur without particularly changing the structure.\n\n    (Phase 2) Growth: An innovation causes a major phase transition within the structure of the system. The innovation catalyzes other innovations in a positive feedback loop.\n\n    (Phase 3) Consolidation: Growth rates saturate. The ecosystem consolidates into a highly organized network, optimized for efficiency, as each agent seeks to eke out as much as it can from its position in the value chain. Hubs (keystone species) appear at critical points.\n\n    (Phase 4) Collapse: A random shock, or new innovation demolishes one of the keystone species, causing cascade failure within the highly structured network. The ecosystem collapses into a random structure.\n\n    (Repeat): The system begins a slow crawl back up the evolutionary ladder of complexity.\n\n(Jain, Krishna, 2002. Large extinctions in an evolutionary model)\n\nIt’s a good bet to that you’ll experience this cycle of rebirth in any evolving network. We see it in everything from industries to ecosystems.\nHe not busy being born is busy dying\n\nThe key insight is that this process has a direction, from decentralized to centralized, and collapsing back again.\n\nAnd you may ask yourself, why not simply start with a centralized system? But now you’ve built an aging and dying system.\n\nAnd you may ask yourself why not use some mechanism to force decentralization? But given the evolutionary pressures pushing a system in this direction, another network may just outcompete you.\n\nIt seems unlikely that the cycle of network samsara can be broken or reversed.\nTwitter avatar for @michaelgarfieldMichael Garfield 💫 @michaelgarfield\n@ben_mathes @RichDecibels Can't shake economies of scale. Just have to find a new party & reset the knock-on effects clock. Or as Hakim Bey noted, every utopia eventually becomes a dystopia. Enjoy the temporary autonomous zone, but be ready to move on when it's coopted. Fugitivity is a core competency.\n\nSeptember 22nd 2021\n3 Retweets9 Likes\n\nBut perhaps we can lean into this cycle of rebirth and build new decentralized things, throw new parties. Perhaps we can build many decentralized things, and construct a rich ecology of interacting systems at different stages of growth, where any one extinction does not take everything down with it.\nLike\tShareShare\n\nI'm building Subconscious, a new tool for thought. I have a general sense of direction, but will be as surprised as you are at what I discover along the way. Each week, I post project updates, design patterns, and snippets of books and papers.\n\nShare\n\n© 2022 Gordon Brander\n548 Market Street PMB 72296, San Francisco, CA 94104\nUnsubscribe\n\nGet the appStart writing\n\t\n>>>\n","n":0.023}}},{"i":5188,"$":{"0":{"v":"Courses","n":1}}},{"i":5189,"$":{"0":{"v":"Sunsama","n":1}}},{"i":5190,"$":{"0":{"v":"Atomic Habits","n":0.707},"1":{"v":"\n\r\n- [[p.isRelated]] https://jamesclear.com/atomic-habits\r\n\r\n","n":0.577}}},{"i":5191,"$":{"0":{"v":"Pluralsight","n":1}}},{"i":5192,"$":{"0":{"v":"Increase Productivity: Add a Dev Console to Your App with Java Script","n":0.289},"1":{"v":"\n\n- [[p.hasURL]] https://app.pluralsight.com/courses/535bde8a-ace7-4b40-aa90-420f52e0728d/table-of-contents","n":0.577}}},{"i":5193,"$":{"0":{"v":"Microsoft","n":1}}},{"i":5194,"$":{"0":{"v":"Web Development for Beginners","n":0.5},"1":{"v":"\n\n\n- [[p.hasURL]] https://docs.microsoft.com/en-us/learn/paths/web-development-101/\n\n- [[t.cs.web.accessibility]]\n  - [[prdct.aria]]\n  - \"The controls for your page should be listed in the HTML source in the order in which you expect the page to be browsed, while relying on CSS to lay out the page visually to users.\"\n- javascript\n  - `let` is for block variables \n  - `var` is for function-scoped variables\n  - initialize = declare + assign\n  - `const` should get UPPER'd\n    - The presence of const means the reference is protected from reassignment. But the value is not immutable and can change, especially if it's a complex construct like an object.\n- [[t.cs.programming.readability]] \n  - camelCase your beautiful names\n  - why not use verbs?\n- [[t.cs.programming.functions.callbacks]]\n  - no parens! including parens means call it now (and pass return value?)\n- [[t.cs.programming.functions.anonymous]]\n  - use when the func wouldn't be used anywhere else\n  - presumably programmers occasionally convert anonymous functions into named functions\n- [[t.cs.programming.functions.arrow]]\n  - [[p.alsoKnownAs]] fat arrow functions\n  - replace the word `function`\n  - Compared with ordinary functions (declared with the function keyword): [[p.hasSource]] https://javascript.plainenglish.io/3-scenarios-where-you-shouldnt-use-arrow-functions-862388acd05d\n    - An arrow function doesn’t have its own this value\n    - It doesn’t have the arguments object.\n    - It doesn’t have the `construct` internal slot. \n- [[t.cs.programming.loops]]\n  - The for and forEach() loops both let you loop over the array's items, but the difference between them is that the for loop lets you exit if a certain condition is fulfilled\n  - `numbers.forEach((number, index) => console.log(`Number ${number} ${index}`));`\n- [[t.cs.programming.arrays]]\n  - `find()`\n    - e.g. `iceCreamFlavors.find(flavor => flavor === \"Chocolate\") // \"Chocolate\"`\n    -  runs the function that you provided as input for each item. If the operation finds the searched-for element, it returns the element. If it doesn't find the element, it returns undefined.\n -  `filter()`\n    -  e.g. `iceCreamFlavors.filter(flavor => flavor.type === \"Chocolate\")`\n -  `map()` (a projection)\n    -  \"The map() method creates a new array with the results of calling a provided function on every element in this array.\"\n -  `reduce()`\n    -  reduces a long list of items into a single item\n","n":0.055}}},{"i":5195,"$":{"0":{"v":"Ws23 Vvvv Beginner Class","n":0.5},"1":{"v":"\n- url: https://thenodeinstitute.org/product/ws23-vvvv-beginner-class/","n":0.577}}},{"i":5196,"$":{"0":{"v":"USC Masters Game Design","n":0.5},"1":{"v":"\n- url: https://www.cs.usc.edu/academic-programs/masters/game-development/\n\n## Resources\n\n- https://viterbigradadmission.usc.edu/programs/masters/tuition-funding/tuition-funding-masters/tuition-fees-32-unit-program/\n- https://ocw.mit.edu/courses/6-042j-mathematics-for-computer-science-fall-2010/","n":0.408}}},{"i":5197,"$":{"0":{"v":"Shmup Tutorial","n":0.707},"1":{"v":"\n- [[t.cs.game.shoot-em-up]]\n- url: https://blood.church/posts/2023-09-25-shmup-tutorial\n- author: @prophetgoddess\n\n## References\n\n- https://cohost.org/prophetgoddess/post/2964176-i-made-a-tutorial-on","n":0.354}}},{"i":5198,"$":{"0":{"v":"Python 3 Fundamentals","n":0.577},"1":{"v":"\n- author: @fred-baptiste\n\n## 2. Running Python\n\n- python is both a compiler (to bytecode) and interpreter \n## 3. Python Basics\n\n- floats are objects; shouldn't be compared, but they're faster and smaller than decimal\n  - have as_integer_ratio method\n- format() function allows you to specify decimal points\n- abs() is absolute value\n- entities have state (data) and methods (functionality)\n  - \"The method operates the data in the class, while a function is used to return or pass the data. A function can be directly called by its name, while a method can't be called by its name.\"\n- immutable objects: integers, decimals, floats\n- variables \n  - must start with underscore or letter\n  - standard use snake case and lowercase","n":0.094}}},{"i":5199,"$":{"0":{"v":"Multiagent Semantic Web Systems","n":0.5},"1":{"v":"\n\n\n- [[p.hasSite]] https://www.inf.ed.ac.uk/teaching/courses/masws/\n","n":0.577}}},{"i":5200,"$":{"0":{"v":"Learn Smalltalk with Profstef","n":0.5},"1":{"v":"\n- url: https://amber-lang.net/learn.html\n\n## Highlights\n\n- \"Literal arrays are created at parse time:\" \n  - #( 1 2 3 #(4 5 6))\n- \"Dynamic Arrays are created at execution time:\" \n  - { (2+3) . (6*6) }\n- \"Messages are sent to objects. There are three types of message: Unary, Binary and Keyword.\"\n  - unary: anObject aMessage \n  - binary: anObject + anotherObject\"\n  - keyword: anObject akey: anotherObject akey2: anotherObject2\n  - \"Unary messages are executed first, then binary messages and finally keyword messages:\n    - \"Between messages of similar precedence, expressions are executed from left to right\"\n- \"; is the cascade operator. It's useful to send message to the SAME receiver\"\n- Blocks [ ] are anonymous methods that can be stored into variables and executed on demand.\n- |b| is the declaration of a variable named 'b' and that ':=' assigns a value to a variabl","n":0.085}}},{"i":5201,"$":{"0":{"v":"JavaScript Unit Testing","n":0.577}}},{"i":5202,"$":{"0":{"v":"Introduction to Logic Programming","n":0.5},"1":{"v":"\n- http://logic.stanford.edu/epilog/homepage/index.php\n- related: [[prdct.epilog]]","n":0.5}}},{"i":5203,"$":{"0":{"v":"GitHub Learning Lab","n":0.577},"1":{"v":"\n\n\n- [[vcard.hasURL]] https://lab.github.com/\n- [-] evaluate interesting courses \n  - later https://lab.github.com/githubtraining/community-starter-kit\n","n":0.302}}},{"i":5204,"$":{"0":{"v":"GitHub Pages with Jekyll","n":0.5},"1":{"v":"\n\n\n- [link pull requests to issues](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue)\n- [review](https://docs.github.com/en/github/collaborating-with-pull-requests/reviewing-changes-in-pull-requests/about-pull-request-reviews)\n    - Comment: Submit general feedback without explicitly approving the changes or requesting additional changes.\n    - Approve: Submit feedback and approve merging the changes proposed in the pull request.\n    - Request changes: Submit feedback that must be addressed before the pull request can be merged.\n\n> Congratulations @djradon, you've completed this course!\n>\n> Your blog is now live and has been deployed here!\n>\n>Before we finish, let's recap everything you completed in this repository\n>\n>   You used the GitHub Flow like a natural\n>    You enabled GitHub Pages\n>    You selected a theme using the config file\n>    You learned about proper directory format and file naming conventions in Jekyll\n>    You added and modified Jekyll front matter\n>\n>What's next?\n>\n>There's so much more you can do with GitHub Pages, and you have a solid start. Now...what will you learn next?\n\n![](/assets/images/2021-10-01-22-49-32.png)\n","n":0.085}}},{"i":5205,"$":{"0":{"v":"Gamedev Patterns TS","n":0.577},"1":{"v":"\nurl: https://medium.com/@gregsolo/gamedev-patterns-and-algorithms-in-action-with-typescript-d29b913858e\n\n## [[p.used]] \n\n- [[prdct.jest]]\n\n## [[p.hasRoadmapFeature]]\n\n- [ ] add [[t.cs.logging]] with maybe [[prdct.pino]] and [[prdct.sematext]]\n- [ ] add cli\n\n## [[p.recommended]]\n\n- [[ar.blobs-in-games]]","n":0.218}}},{"i":5206,"$":{"0":{"v":"Log","n":1},"1":{"v":"\n## t.2023.01.01\n  \n- Why use getters in Javascript?\n  - [[p.hasAnswers]]\n    - \"So if you decide to add this kind of extra logic to one of the existing object properties that is already being referenced, you can convert it to getter/setter style without altering the rest of the code that has access to that property.\"\n      - https://stackoverflow.com/questions/42342623/why-use-getters-and-setters-in-javascript\n\n    - \"One difference is typeof will actually work as expected when using a getter, that is, it will return the actual type of the primitive returned by the getter, while using a method will always return function\"\n    - \"if you have nested getters, you can call them transparently, which is something that comes in handy if you are navigating an object programmatically\"\n      - https://stackoverflow.com/questions/59569178/whats-the-point-of-a-javascript-getter-method\n- Surprised that this code works:\n```typescript\npublic AddComponent(component: IComponent): void {\n    this._components.push(component)\n    component.Entity = this\n  }\n```\n  - [[p.hasAnswers]]\n    - \"Objects and arrays are pushed as a pointer to the original object . Built-in primitive types like numbers or booleans are pushed as a copy.\"\n      - https://stackoverflow.com/questions/8660901/do-objects-pushed-into-an-array-in-javascript-deep-or-shallow-copy\n- Why generics for functions?\n  - https://www.typescriptlang.org/docs/handbook/2/generics.html\n    - While using any is certainly generic in that it will cause the function to accept any and all types for the type of arg, we actually are losing the information about what that type was when the function returns. If we passed in a number, the only information we have is that any type could be returned. Instead, we need a way of capturing the type of the argument in such a way that we can also use it to denote what is being returned. Here, we will use a type variable, a special kind of variable that works on types rather than values.\n```typescript\nfunction identity<Type>(arg: Type): Type {\n  return arg;\n}\n```\n- [x] @greg-solo uses \".h.ts\" for header files, but should probably be \"[.d.ts](https://www.typescriptlang.org/docs/handbook/declaration-files/templates/module-d-ts.html)\"\n- `unknown` is typesafe version of `any`\n  - https://stackoverflow.com/questions/51439843/unknown-vs-any :\n    - \"unknown is I don't know; any is I don't care\"\n    - \"any value is assignable to unknown; however, unlike any, you cannot access any properties on values with the type unknown, nor can you call/construct them. Furthermore, values of type unknown can only be assigned to unknown or any.\"\n- [[prdct.typescript.barrel-files]] might be over-used\n\n## t.2023.01.02\n\n- [-] would seem to be [[t.cs.game.loop.recursive]], but v8 took out [[t.cs.recursion.tail-call-optimization]]\n- Game has its own entities and all components; both can be awoken.\n\n## t.2023.01.05\n\n- Having a tool that can change the behavior of the game without diving too deep into the code can be a huge time saver.\n\n## t.2023.01.06\n\n- \"Note, I don’t have access to Grid instance since it’s created and encapsulated by the Game. But I can rely on Grid.prototype to access Grid methods without an actual instance.\"\n- \"The Component interface requires specifying which entity the component can be attached to. In this case, it’s the Node entity.\"\n- I questions the utility of \"We don’t have access to the instance of a component, but we can spy on its prototype.\"\n- \"Vector2D, as ECS or lifecycle methods, is a utility. It does not depend on the game\"\n- [[p.begsQuestion]] should the filename match the Class name?\n  - [[p.hasAnswers]]\n    - \"Use kebab-case for all package, folder and file names.\" b/c packages can't have upper case\n- \"keep a constructor lean\"\n- ` can be used for string with variable substitution\n- \"Though neither Canvas nor CanvasLayer are singletons, static CanvasLayer ensures Canvas is instantiated only ones\"\n\n## t.2023.01.07\n\n- [-] how does jest.mock('@/utils') work?\n- integer check: v % 1 !== 0\n- toThrowError is alias for toThrow and takes an optional RegEx, substring, error object or error class\n- Partial: Constructs a type with all properties of Type set to optional. This utility will return a type that represents all subsets of a given type.\n- [x] what does `type constr<T> = { new(...args: unknown[]): T }` (from entity.ts) do really?\n  - it defines a new type\n- `(team = Team.A): Fleet => new Fleet(team)` doesn't need parameter type because it's inferred from Team.A\n- in locomotion, why have the position use pixels? probably just a design choice?\n\n### https://medium.com/swlh/building-a-game-with-typescript-ship-and-locomotion-4f5969675993\n- \"it could use GetComponent, but we better cache the reference instead\"\n- \"Node is not a core feature of the Ship (it’s neither its property nor field)\"\n- after breaking things, and messaging around with git, I did find a working commit in my own history.\n\n## t.2023.01.08\n\n- found it!, missing implementation of awake. wish I'd captured the test failures to confirm. \n- t.2023.01.08.13.23 wound up reverting to ships-3 and had to fix capitalization on Vector2D, so a bunch of git buggery, but I think I learned a little bit, and did my first merge to master\n- \"Since it’s read-only, a constructor is the only place we can do it\"\n- OK, failed at the same place... \"Our code compiles again. Moreover, if you open it in the browser you can see this beautiful picture:\" but this time I'm better off because\n  - I'm looking at the browser console\n  - figured it out, I missed the \"grid\" change change to the \n- [[read|p.read]] https://www.typescriptlang.org/docs/handbook/variable-declarations.html -- good, tricky\n  - \"var declarations are accessible anywhere within their containing function, module, namespace, or global scope... regardless of the containing block.\"\n  - let declarations are block-scoped (aka lexical scoping)\n  - loved [[t.cs.programming.temporal-dead-zone]]\n  - `const` means no re-assignment (which is different from immutable, e.g. you can change properties)\n\n### https://itnext.io/building-a-game-with-typescript-input-system-1-3-46d0b3dd7662\n\n- there are no DOM elements within canvas\n- how do nodes, ships get notified about events? Not [[t.cs.programming.patterns.observer]] because that couples game objects to the GameInputComponent.\n  - instead, Onclick component\n- I'm pleasantly surprised by how easy it is to dereference fields objects, e.g. `this.Entity.Entities`\n- not sure how I feel about multiple files called draw.ts -- I feel like every filename should be unique\n- `type` defines an alias to a type\n- \"When we say Function & { prototype: T } we mean that this “thing” must be a function AND should have a specific T type of parent constructor. In other words, it has to extend that T.\"\n- had to do a separate `import { mockGridFactory } from '@/grid'`, didn't like it in with { Grid }\n\n### https://blog.gregsolo.me/articles/building-a-game-with-typescript-pathfinding-and-movement-17-introduction\n\n- !@#$ capitalization (vector2D folder vs vector2d file)\n\n## t.2023.01.09\n\n### https://blog.gregsolo.me/articles/building-a-game-with-typescript-pathfinding-and-movement-27-highlighting-locomotion-range\n\n- Neighbors[] would not be readonly in my engine because it's fractal-like, invents itself as it goes along\n- pre-decrement useful for recursion `const newRange = --range`\n- recursion can be done with map!\n- I'm just realizing now that @greg-solo capitalizes his public objects and all method names!?\n  - makes his methods stand out\n  - [x] am I crazy\n    - @rvk confirmed\n\n## t.2023.01.10\n\n### https://blog.gregsolo.me/articles/building-a-game-with-typescript-pathfinding-and-movement-37-graph-and-priority-queue\n\n- [[Type Assertions|t.cs.languages.typescript.type-assertions]] in the interface method signature can be linked/referenced internally, e.g. `export interface IPriorityQueue<T>` and `Enqueue(item: T, priority: number): void` means that the implementing class has to have identical type assertion in both places\n\n## t.2023.01.11\n\n### https://blog.gregsolo.me/articles/building-a-game-with-typescript-pathfinding-and-movement-57-finding-the-path\n\n- [[p.learned]] [[t.math.geometry.taxicab-geometry]]\n- [repeating ourselves](https://vscode.dev/github/djradon/gamedev-patterns-ts/blob/cca466d5cb27fafe06de0f08a958434b9bfc9f87/src/fleet/fleet.ts#L45-L46): \n```javascript\nactiveShip.IsActive = true\nthis._grid.ActiveShip = activeShip\n```\n- got stuck, the interactivity is broken, don't have the motivation to find out where, given movement-pathfinding-5 is just sitting there.\n- any change to the source starts the thing over from the beginning; it's gonna be hard to test detailed scenarios\n\n\n","n":0.03}}},{"i":5207,"$":{"0":{"v":"Defi Orientation","n":0.707},"1":{"v":"\n\n\n- [[p.hasAuthor]] @nat-eliason\n- https://learn.nateliason.com/p/defi-orientation \n- [[p.hadCost]] $99 \n","n":0.354}}},{"i":5208,"$":{"0":{"v":"Behaviour Trees","n":0.707},"1":{"v":"\n- url: https://www.udemy.com/course/behaviour-trees/","n":0.577}}},{"i":5209,"$":{"0":{"v":"100 Days of Python","n":0.5},"1":{"v":"\n- author: @angela-yu\n\n## t.2023.09.07\n\n- ","n":0.5}}},{"i":5210,"$":{"0":{"v":"Pledge","n":1},"1":{"v":"\n100 Days of Python Pledge\nI @dave am committed to completing the 100 days of Python challenge.\nI hereby pledge to work for at least 7 hours per week on Python programming for 100 days.\nI will keep myself on track, even though some days I might feel tired or frustrated.\nI will keep myself accountable, even though I have lots of things to do. I will make this a priority in my\nlife.\nI will overcome difficulties and achieve my goal.\nI will become a Python developer.\nI believe in myself.\nDate Signed: _____2023.09.19_______________\nSignature: _________ @dave _____________________","n":0.106}}},{"i":5211,"$":{"0":{"v":"Communities","n":1}}},{"i":5212,"$":{"0":{"v":"GitHub","n":1}}},{"i":5213,"$":{"0":{"v":"Semiceu","n":1}}},{"i":5214,"$":{"0":{"v":"Dcat Ap","n":0.707}}},{"i":5215,"$":{"0":{"v":"Issues","n":1}}},{"i":5216,"$":{"0":{"v":"296 Clarification on Dataset Series as an Ordered or Unordered Collection","n":0.302},"1":{"v":"\n- https://github.com/SEMICeu/dcat-ap/issues/296\n- topics: [[prdct.dcat-data-catalog.application-profiles]] ","n":0.5}}},{"i":5217,"$":{"0":{"v":"W3c","n":1}}},{"i":5218,"$":{"0":{"v":"Dxwg","n":1}}},{"i":5219,"$":{"0":{"v":"Issues","n":1}}},{"i":5220,"$":{"0":{"v":"Dataset series","n":0.707},"1":{"v":"\n- https://github.com/w3c/dxwg/issues/868\n\n## Highlights\n\n@der: \n\n- \"it is relatively rare for a dataset to be a unitary thing which be downloaded in its entirety. More typically the non-realtime datasets we see comprise a series of updates (annual, quarterly, monthly etc as determined by some release cycle). Where possible we provide data services and dumps for the whole series. However, both users and publishers want to explicitly see the series of updates as individual elements they can separately download but regard the collection of those updates as a single dataset with common metadata and want the data, and presentation of it, to reflect that.\"\n\n- want to treat each of our resources as an instance of both dcat:DatasetSeries and dcat:Dataset. That way we could give a distribution (and extent) for the overall aggregate as well as distributions for the individual elements within the series. ","n":0.085}}},{"i":5221,"$":{"0":{"v":"Model Series of Data as Distributions of a single Dataset","n":0.316},"1":{"v":"\n- https://github.com/w3c/dxwg/issues/1429\n\n## Highlights\n\n### riccardoAlebrtoni\n\nIt might be worth noting that the current DCAT Editor Draft and the second DCAT working draft acknowledge some flexibility on what to consider as items of [dcat:datasetSeries](https://www.w3.org/TR/2021/WD-vocab-dcat-3-20210504/#Class:Dataset_Series), which already includes the use of Distributions in place of Datasets.\n\nIndeed, the property [dcat:inSeries](https://www.w3.org/TR/2021/WD-vocab-dcat-3-20210504/#Property:dataset_in_series), which links the items to data series, has no domain specified, and its usage note says\n\n`Normally, child datasets in dataset series are represented as dcat:Dataset. The use of dcat:Distribution for typing child datasets is however recognized as a possible alternative, whenever it addresses more effectively the requirements of a given application scenario.`\n\nI think we can distinguish between informatively equivalent and non-informative equivalent distributions using the properties dcat:distribution and dcat:inSeries.  \nI would expect the informative equivalence holds between distributions of the same dataset, i.e. the distribution linked to the same dataset via dcat:distribution, not between distributions used as items in a dataset Series, i.e., distributions linked via dcat:inSeries to a dcat:datasetSeries.\n\n### matthiaspalmer\n\n```turtle\nex:dataset1 a dcat:Dataset ;\n     dcat:distribution ex:distribution1, ex:distribution2 .\n\nex:distribution1 a dcat:Distribution ;\n     dcterms:title  \"Access via CSV files\" ;\n     dcat:downloadURL  ex:file1,ex:file2 .\n\nex:file1 dcterms:title \"Budget 2019\" .\nex:file2 dcterms:title \"Budget 2020\" .\n\nex:distribution2 a dcat:Distribution ;\n     dcterms:title \"Access via a JSON based API\" ;\n     dcat:accessURL ex:API\n```\n\nThis approach has the following merits:\n\n1.  The distributions are comparable, they contain the same data.\n2.  The amount of duplication of metadata is minimal\n3.  It is relatively easy to explain to data providers what to do\n4.  Providing multiple distributions (e.g. API and file based access) is obvious\n5.  More information can be provided on each file if there is a need.\n6.  There won't be any unneccessary pollution in dataportals of many datasets\n\nIt could be argued that repeating the dcat:downloadURL is bad, that it is not intended to be used that way. The specification says \"the downloadable file\" which indeed seems to indicate there should be a cardinality of one.\n\nHowever, I think it should be investigated if it can easily be tweaked to be compliant.\nFor instance, allowing a dcat:downloadPartURL as an alternative to dcat:downloadURL, maybe introducing a class like dcat:File and just suggesting that it is allowed to provide a dcterms:title on it.","n":0.054}}},{"i":5222,"$":{"0":{"v":"Issue 1409: Using dcat:next and dcat:version in Dataseries","n":0.354},"1":{"v":"\n- https://github.com/w3c/dxwg/issues/1409\n- ","n":0.707}}},{"i":5223,"$":{"0":{"v":"Nemo Ufes","n":0.707}}},{"i":5224,"$":{"0":{"v":"nemo-ufes gUFO discussion","n":0.577},"1":{"v":"\n- https://github.com/nemo-ufes/gufo/discussions\n","n":0.707}}},{"i":5225,"$":{"0":{"v":"Issues 37 Multi Level","n":0.5},"1":{"v":"\n- https://github.com/nemo-ufes/gufo/issues/37\n\n- @andre-demori: \"Hello, I am working on a conceptual model using UFO constructs that is also based on Multi-Level Theory.\n\nHowever, when I import gUFO, I am encountering a problem when defining attribute values ​​(data properties) for Individuals that are also types (punning).\n\nHowever, it seems that gUFO does not support MLT, since properties that are classified as hasQualityValue can only be defined for an Individual and not for a type. When I do this, the reasoner says that there is an ontological inconsistency.\n\nTherefore, I would like to know if you have already encountered this problem and if there is an immediate solution. If not, I would like to leave this recommendation for future extensions.\"\n\n- @joao-paulo-almeida:  Indeed, gUFO enforces a dichotomy between types and individuals. This means that types can't bear aspects (as only concrete individuals can). A workaround is to use regular object/data properties.\n\nWe have been discussing a possible relaxation of some of the domain/range declarations (e.g., the domain of gufo:hasQualityValue and the range of gufo:inheresIn) to include types in addition to concrete individuals. This would be an easy way to accommodate the view of types as endurants and would not impact existing gUFO-based ontologies.\n\n(See [[ar.incorporating-types-of-types-in-ontology-driven-conceptual-modeling]] for how we address types as endurants in UFO more broadly.)","n":0.07}}},{"i":5226,"$":{"0":{"v":"Matrix","n":1}}},{"i":5227,"$":{"0":{"v":"Third Room","n":0.707},"1":{"v":"\n- url: https://matrix.to/#/#thirdroom-dev:matrix.org\n","n":0.577}}},{"i":5228,"$":{"0":{"v":"Xtdb Community","n":0.707}}},{"i":5229,"$":{"0":{"v":"W3","n":1}}},{"i":5230,"$":{"0":{"v":"Autonomous Agents on the Web Community Group","n":0.378},"1":{"v":"\n- https://www.w3.org/community/webagents/\n- related: [[prdct.hyperagents]]","n":0.5}}},{"i":5231,"$":{"0":{"v":"Tools for Thought Rocks (Community)","n":0.447},"1":{"v":"\n\n\n- [[p.interestedIn]]\n  - [[t.km.pkm]]\n  - [[t.org-theory.computer-supported-collaborative-work]]\n  - [[t.cs.hci]]\n  - [[t.km.knowledge-graph]]\n  - [[t.cs.hci.experimental-interface-design]]\n- [[p.hasURL]] https://lu.ma/community/com-mmvGpDTZoRDsxou\n- [[p.hostedOn]] [[prdct.luma]]\n","n":0.25}}},{"i":5232,"$":{"0":{"v":"Strimzi","n":1},"1":{"v":"\nurl: https://strimzi.io/join-us/","n":0.707}}},{"i":5233,"$":{"0":{"v":"Reddit","n":1}}},{"i":5234,"$":{"0":{"v":"Semanticweb","n":1}}},{"i":5235,"$":{"0":{"v":"Lesswrong","n":1},"1":{"v":"\n#effective-altruism\n\ndescription: https://www.lesswrong.com/about\n  ","n":0.707}}},{"i":5236,"$":{"0":{"v":"Human Guild","n":0.707},"1":{"v":"\n- https://t.me/HumanGuildNear ","n":0.707}}},{"i":5237,"$":{"0":{"v":"Discord","n":1}}},{"i":5238,"$":{"0":{"v":"Javelin","n":1}}},{"i":5239,"$":{"0":{"v":"Gamedev","n":1},"1":{"v":"\nt.2023.09.29\n\n- [[p.mentioned]] [[prdct.thyseus]]\n- [[p.recommended]] [[game.wildermyth]]\n\n\n","n":0.447}}},{"i":5240,"$":{"0":{"v":"Fission","n":1}}},{"i":5241,"$":{"0":{"v":"Tools for Thought on Fission Discord","n":0.408}}},{"i":5242,"$":{"0":{"v":"Yuka","n":1},"1":{"v":"\n- https://discord.com/channels/762241368125865984/762265595445248031/974698492595429437 referenced https://sketchfab.com/3d-models/terrain-level-6631c974efde4bb384e2be44293cd7f6 [[prdct.sketchfab]]","n":0.447}}},{"i":5243,"$":{"0":{"v":"Open Meta","n":0.707},"1":{"v":"\n- [[p.supports]] [[org.open-metaverse-foundation]]\n\n![](/assets/images/2023-10-20-12-09-48.png)","n":0.577}}},{"i":5244,"$":{"0":{"v":"Memphis Dev","n":0.707},"1":{"v":"\n- [[p.asked]] Does anyone know if Memphis and Memphis Cloud have websocket (i.e., browser) support? There's https://github.com/nats-io/nats.ws and given that Memphis has NATS at its core, it seems like it might be possible?\n  - https://discord.com/channels/963333392844328961/1114471626210299975/1166085083795566683\n  - @yaniv-ben-hemo : Not at the moment. In case its a must, would love to explore ways to prioritize it\n\n\nt.2023.10.24.12\n\ndjradon — Today at 11:49 AM\nI've been looking for a messaging solution for my product-dream for a while, and was looking at NATS as a \"better Kafka\", so then naturally stumbled onto Memphis.\nYaniv Ben Hemo — Today at 11:51 AM\nThank you, thats great\nMemphis definetly removes much of the heavy-lifting both Kafka and NATS reveal\nCan I ask about the use case? Why WS is needed?\ndjradon — Today at 12:19 PM\nSure! I'm working on a role-playing platform. Not a game, but a way for people to create and play their own games/experiences. So, among other things, it's an agent-based framework where people can build and share their characters, plot lines, societies, and worlds. \n\nIdeally, people will be able to run their own agents, or spawn agents written by others (i.e., directly from github) into a browser. That way, people don't need to run a node.js server locally. We wouldn't want to run arbitrary code in the game service, so just providing access to a queue for agent commands/intent  from the browser and having browser-based agents collecting \"world update events\" and sensory data events from other queues provides a clean separation for agent self-hosting. \n","n":0.064}}},{"i":5245,"$":{"0":{"v":"Lamina1","n":1}}},{"i":5246,"$":{"0":{"v":"Flecs","n":1}}},{"i":5247,"$":{"0":{"v":"Etherealengine Org","n":0.707}}},{"i":5248,"$":{"0":{"v":"Association for Computational Linguistics","n":0.5},"1":{"v":"\n\n\n- [[p.hasConferenceSeries]] [[event.coling]]\n","n":0.577}}},{"i":5249,"$":{"0":{"v":"Classes/Types","n":1},"1":{"v":"\n- probably should be pluralized for readability and sensibility, but that's not the programming convention","n":0.258}}},{"i":5250,"$":{"0":{"v":"Publication","n":1}}},{"i":5251,"$":{"0":{"v":"Rules","n":1}}},{"i":5252,"$":{"0":{"v":"Srd","n":1}}},{"i":5253,"$":{"0":{"v":"Text","n":1}}},{"i":5254,"$":{"0":{"v":"Essay","n":1}}},{"i":5255,"$":{"0":{"v":"Interactive","n":1}}},{"i":5256,"$":{"0":{"v":"Exerpt","n":1}}},{"i":5257,"$":{"0":{"v":"Description","n":1}}},{"i":5258,"$":{"0":{"v":"Abstract","n":1},"1":{"v":"\n- [[p.similarTo]] [[c.summary]]","n":0.577}}},{"i":5259,"$":{"0":{"v":"Software","n":1}}},{"i":5260,"$":{"0":{"v":"Visualization","n":1}}},{"i":5261,"$":{"0":{"v":"Temporal","n":1}}},{"i":5262,"$":{"0":{"v":"Semantic Visualization","n":0.707},"1":{"v":"\n- related: [[t.cs.semantic-web.visualization]]","n":0.577}}},{"i":5263,"$":{"0":{"v":"Plugin","n":1}}},{"i":5264,"$":{"0":{"v":"Protege","n":1}}},{"i":5265,"$":{"0":{"v":"Messaging","n":1}}},{"i":5266,"$":{"0":{"v":"middleware","n":1}}},{"i":5267,"$":{"0":{"v":"message bus software","n":0.577},"1":{"v":"\n## Criteria\n\n-   **Message queuing model:** How are messages passed between two parties? Is it via a stream or a queue?\n-   **Delivery guarantee:** Are messages always delivered at least once, or is this not always the case?\n-   **Ordering guarantee:** Are messages delivered in the order they were sent, or are they not?\n-   **Throughput and latency:** How many messages can the platform handle, and how fast is the communication? Keep in mind that all these systems can scale to handle increased throughput, and that results will vary based on your system configuration.\n-   **Persistence and replayability:** Does the platform store messages and allow for reprocessing if they were missed the first time?\n\n## Resources\n\n- https://gcore.com/learning/nats-rabbitmq-nsq-kafka-comparison/","n":0.095}}},{"i":5268,"$":{"0":{"v":"Game-Service","n":1}}},{"i":5269,"$":{"0":{"v":"Data","n":1}}},{"i":5270,"$":{"0":{"v":"Browser","n":1}}},{"i":5271,"$":{"0":{"v":"Browser Extension (class)","n":0.577},"1":{"v":"\n- [[p.similarTo]] [[c.software.browser.plugin]]\n  - [[p.hasComparison]]\n    - \"Browser plug-ins are a separate type of module. The main difference is that extensions are distributed as source code, while plug-ins are distributed as executables (i.e. object code). Plug-ins are no longer supported by the major browsers, but extensions are widely used.\"","n":0.144}}},{"i":5272,"$":{"0":{"v":"3d","n":1}}},{"i":5273,"$":{"0":{"v":"3D Generators","n":0.707},"1":{"v":"\n\n## Resource Lists\n\n- https://www.unite.ai/best-ai-3d-object-generators/","n":0.5}}},{"i":5274,"$":{"0":{"v":"web","n":1}}},{"i":5275,"$":{"0":{"v":"Website Builder","n":0.707}}},{"i":5276,"$":{"0":{"v":"Web Toolkit","n":0.707}}},{"i":5277,"$":{"0":{"v":"Static Search","n":0.707}}},{"i":5278,"$":{"0":{"v":"Ssg","n":1}}},{"i":5279,"$":{"0":{"v":"Rest Framework","n":0.707}}},{"i":5280,"$":{"0":{"v":"JavaScript Toolkit","n":0.707}}},{"i":5281,"$":{"0":{"v":"API Framework","n":0.707}}},{"i":5282,"$":{"0":{"v":"Animation Library","n":0.707},"1":{"v":"\n\n## Resource Lists\n\n- https://dev.to/vyan/12-best-javascript-animation-libraries-to-supercharge-your-web-projects-in-2024-21ka","n":0.5}}},{"i":5283,"$":{"0":{"v":"Tools","n":1}}},{"i":5284,"$":{"0":{"v":"Testing","n":1}}},{"i":5285,"$":{"0":{"v":"API","n":1}}},{"i":5286,"$":{"0":{"v":"Id Generator","n":0.707}}},{"i":5287,"$":{"0":{"v":"Design","n":1}}},{"i":5288,"$":{"0":{"v":"API Design Tools","n":0.577},"1":{"v":"\n- [[c.software.tools.design.api]]","n":0.707}}},{"i":5289,"$":{"0":{"v":"Modeling Tools","n":0.707}}},{"i":5290,"$":{"0":{"v":"Diagramming","n":1},"1":{"v":"\n## Implementations\n\n- [[prdct.mingrammer-diagrams]]\n- [[prdct.kroki]]\n- [[prdct.ilograph]]\n- [[prdct.structurizr]]\n- [[prdct.d2.studio]]\n- [[prdct.graphviz]]\n- [ ] [[prdct.event-catalog]]\n\n## [[c.implementation.favorite]]\n\n- [[prdct.flowchart-js]] /  [[prdct.js-sequence-diagrams]] / [[prdct.d3-graphviz]]\n\n## Comparison\n\n- https://text-to-diagram.com/\n  - [[p.supports]] [[prdct.webviz]] [[prdct.c4-plantuml]]  [[prdct.mermaid]] [[prdct.d2]]\n- [[vs.structurizr-vs-d2]]\n- https://icepanel.medium.com/top-7-diagrams-as-code-tools-for-software-architecture-1a9dd0df1815\n\n\n## [[c.resource.list]]\n\n- https://modeling-languages.com/text-uml-tools-complete-list/\n- https://icepanel.medium.com/top-7-diagrams-as-code-tools-for-software-architecture-1a9dd0df1815","n":0.183}}},{"i":5291,"$":{"0":{"v":"Theorem Prover","n":0.707}}},{"i":5292,"$":{"0":{"v":"Text Editor","n":0.707}}},{"i":5293,"$":{"0":{"v":"Task and Goal Management","n":0.5}}},{"i":5294,"$":{"0":{"v":"State Store","n":0.707},"1":{"v":"\n## Comparisons\n\n- http://orta.io/notes/games/phaser-redux compares [[prdct.jotai]] [[prdct.mobx]] [[prdct.vuex]] [[prdct.redux-js]] [[prdct.recoil]]\n  - \"a few of these are strongly tied to a UI library to the point where they can't be used without it ( Recoil, Vuex and Jotai )\"\n  - \"What went against MobX was the feeling that introducing reactive programming in one aspect of an app has a tendency to leak into all parts eventually, and I'm wary of that.\"\n- https://hackernoon.com/how-atoms-fixed-flux\n  - mentions: [[prdct.zedux]]\n  - ","n":0.116}}},{"i":5295,"$":{"0":{"v":"Serializer","n":1}}},{"i":5296,"$":{"0":{"v":"Semantic","n":1}}},{"i":5297,"$":{"0":{"v":"Utility","n":1}}},{"i":5298,"$":{"0":{"v":"Solid Server","n":0.707},"1":{"v":"\n## References\n\n- https://indico.cern.ch/event/979244/attachments/2150378/3668572/JanSchill_20201225-Solid-specs-and-implemenations-report.pdf","n":0.577}}},{"i":5299,"$":{"0":{"v":"Search Engine","n":0.707},"1":{"v":"\n## Resource List\n\n- https://nkos.dublincore.org/index.html#registry","n":0.5}}},{"i":5300,"$":{"0":{"v":"Publishing","n":1}}},{"i":5301,"$":{"0":{"v":"Semantic Site Generator","n":0.577},"1":{"v":"\n## Resources\n\n- https://harshp.com/dev/harshp.com/rdf-website-generator\n  - mentions: @ruben-verborgh\n- https://csarven.ca/how-to-create-a-linked-data-site\n  - mentions: \n    - [[ar.w3.design-issues.linked-data]] https://www.w3.org/DesignIssues/LinkedData.html\n    - [[prdct.dokieli]]","n":0.258}}},{"i":5302,"$":{"0":{"v":"Ontology Editor","n":0.707},"1":{"v":"\n\n## [[c.resource.list]]\n\n- https://www.w3.org/wiki/Ontology_editors\n- https://ef.uns.ac.rs/mis/archive-pdf/2013%20-%20No2/MIS2013-2-4.pdf\n","n":0.5}}},{"i":5303,"$":{"0":{"v":"Network","n":1}}},{"i":5304,"$":{"0":{"v":"Linked Data Platform","n":0.577},"1":{"v":"\n- related: [[t.cs.semantic-web.linked-data-platform]]","n":0.577}}},{"i":5305,"$":{"0":{"v":"Semantic Library","n":0.707}}},{"i":5306,"$":{"0":{"v":"Browser","n":1}}},{"i":5307,"$":{"0":{"v":"Semantic Authoring Software","n":0.577},"1":{"v":"\n\n## References\n\n- [[ar.reddit.semanticweb.best_ontology_development_environment_tool]]\n\n","n":0.577}}},{"i":5308,"$":{"0":{"v":"Activity Pub","n":0.707}}},{"i":5309,"$":{"0":{"v":"Security","n":1}}},{"i":5310,"$":{"0":{"v":"Script Engine","n":0.707}}},{"i":5311,"$":{"0":{"v":"Retrieval Augmented Generation","n":0.577}}},{"i":5312,"$":{"0":{"v":"Repository","n":1}}},{"i":5313,"$":{"0":{"v":"Reasoner","n":1}}},{"i":5314,"$":{"0":{"v":"Tableau","n":1},"1":{"v":"\n## @chatgpt.4\n\nThe core principle of tableau reasoning involves the following steps:\n\n    Representation of Logical Expressions: The reasoner represents the logical expressions or statements (such as those in an ontology) in a structured form, often as a tree or a set of interconnected nodes.\n\n    Expansion Rules: The tableau method applies a series of expansion rules to these expressions. These rules systematically break down complex expressions into simpler components.\n\n    Branching: The process often involves creating branches in the tableau, each representing different scenarios or interpretations of the logic. For example, if an expression contains a disjunction (an \"or\" statement), the tableau might branch into two paths, one for each part of the disjunction.\n\n    Checking for Contradictions: The reasoner checks each branch for contradictions. A branch is closed (considered unsatisfiable) if it contains a contradiction.\n\n    Satisfiability Determination: If at least one branch of the tableau remains open (without contradictions), the original set of expressions is considered satisfiable. If all branches are closed, the expressions are unsatisfiable.\n\nIn the context of ontologies and semantic web technologies, tableau-based reasoners are used to check the consistency of ontologies, to infer implicit knowledge, and to classify entities in the ontology. They are particularly well-suited for expressive logic languages like OWL DL and OWL 2, which require sophisticated reasoning capabilities.\n\nExamples of tableau-based reasoners include Pellet, HermiT, and Fact++. These reasoners are integral to many applications in the semantic web, artificial intelligence, and knowledge management, where they help to automate the process of reasoning about complex and interconnected data.","n":0.063}}},{"i":5315,"$":{"0":{"v":"Real Time Framework","n":0.577}}},{"i":5316,"$":{"0":{"v":"object-graph-mapper","n":1}}},{"i":5317,"$":{"0":{"v":"Image Generators","n":0.707},"1":{"v":"\n## Resources\n\n- https://www.tomsguide.com/ai/ai-image-video/i-put-7-leading-ai-image-models-to-the-test-with-the-same-prompt-heres-the-winner","n":0.577}}},{"i":5318,"$":{"0":{"v":"Ide","n":1}}},{"i":5319,"$":{"0":{"v":"Extension","n":1}}},{"i":5320,"$":{"0":{"v":"Jetbrains","n":1}}},{"i":5321,"$":{"0":{"v":"E","n":1}}},{"i":5322,"$":{"0":{"v":"Extension","n":1}}},{"i":5323,"$":{"0":{"v":"VSCode Extension","n":0.707}}},{"i":5324,"$":{"0":{"v":"Gis","n":1}}},{"i":5325,"$":{"0":{"v":"Game Framework","n":0.707},"1":{"v":"\n  - [[p.similarTo]] [[c.software.game-platform]] [[c.software.game-engine]]\n\n","n":0.447}}},{"i":5326,"$":{"0":{"v":"Goal Oriented Action Planning","n":0.5},"1":{"v":"\n## Resources\n\n- https://www.reddit.com/r/gameai/comments/175adnc/is_goap_really_that_bad/\n  - mentions: [[c.software.game-framework.behavior-trees]] [[t.cs.finite-state-machine]] [[c.software.game-framework.goal-oriented-action-planning]] [[t.cs.ai.utility]]","n":0.333}}},{"i":5327,"$":{"0":{"v":"Behavior Trees","n":0.707}}},{"i":5328,"$":{"0":{"v":"Interactive Fiction Framework","n":0.577},"1":{"v":"\n- [[p.subClassOf]] [[c.software.game-framework]]\n\n## Resources\n\n- https://www.ifwiki.org/index.php?title=Engine_List\n- https://www.reddit.com/r/zork/comments/wcm1vo/i_am_writing_an_interactive_fiction_builder_in_c/","n":0.408}}},{"i":5329,"$":{"0":{"v":"Mapper","n":1},"1":{"v":"\n## Resources\n\n- https://www.ifarchive.org/indexes/if-archive/mapping-tools/","n":0.577}}},{"i":5330,"$":{"0":{"v":"Framework","n":1}}},{"i":5331,"$":{"0":{"v":"Digital Experience Platform","n":0.577}}},{"i":5332,"$":{"0":{"v":"Database","n":1}}},{"i":5333,"$":{"0":{"v":"in-memory","n":1},"1":{"v":"\n- \"pretty much all in-memory databases have unsupported platforms or build complications.\"\n  - https://github.com/bevyengine/bevy/pull/8624","n":0.267}}},{"i":5334,"$":{"0":{"v":"Document","n":1}}},{"i":5335,"$":{"0":{"v":"Distributed","n":1}}},{"i":5336,"$":{"0":{"v":"Bitemporal","n":1}}},{"i":5337,"$":{"0":{"v":"Vector Databases","n":0.707},"1":{"v":"\n## Resources\n\n- [Structured Knowledge Extraction: from DbPedia Queries to Llama Index Knowledge Graphs](https://python.plainenglish.io/structured-knowledge-extraction-from-dbpedia-queries-to-llama-index-knowledge-graphs-47899c38e767)\n  - uses [[t.cs.graph.semantic-graph]] model and [[prdct.sparql]]","n":0.229}}},{"i":5338,"$":{"0":{"v":"Multi-Model","n":1}}},{"i":5339,"$":{"0":{"v":"Graph Database","n":0.707},"1":{"v":"\n\n## [[c.list.implementations]]\n\n- https://indiaai.gov.in/article/eight-interesting-open-source-graph-databases\n- https://www.bloorresearch.com/technology/graph-databases/\n\n## Cons\n\n\n## References\n\n- https://www.c-sharpcorner.com/article/what-is-a-graph-database/","n":0.378}}},{"i":5340,"$":{"0":{"v":"RDF Graph Database","n":0.577}}},{"i":5341,"$":{"0":{"v":"Hypergraph","n":1}}},{"i":5342,"$":{"0":{"v":"Property Graph Database","n":0.577},"1":{"v":"\n## [[c.list.implementations]]\n\n- https://tinkerpop.apache.org/providers.html","n":0.577}}},{"i":5343,"$":{"0":{"v":"Embedded Database","n":0.707}}},{"i":5344,"$":{"0":{"v":"Data Management Platform","n":0.577}}},{"i":5345,"$":{"0":{"v":"Data Framework","n":0.707}}},{"i":5346,"$":{"0":{"v":"Streaming","n":1}}},{"i":5347,"$":{"0":{"v":"Sharing","n":1}}},{"i":5348,"$":{"0":{"v":"Data Discovery","n":0.707},"1":{"v":"\n- aka metadata catalog, \n\n## Resources\n\n- You may be familiar with this [popular blog post](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying) on why logs should be at the heart of your data ecosystem. Turns out, the same is actually true about metadata as well. A modern data catalog  should enable real-time subscription to changes in the metadata as a first-class offering.\n- https://www.linkedin.com/blog/engineering/data-management/datahub-popular-metadata-architectures-explained","n":0.134}}},{"i":5349,"$":{"0":{"v":"Content Management System","n":0.577}}},{"i":5350,"$":{"0":{"v":"Business Process Management","n":0.577}}},{"i":5351,"$":{"0":{"v":"Authorization","n":1}}},{"i":5352,"$":{"0":{"v":"Ai","n":1}}},{"i":5353,"$":{"0":{"v":"Speech Recognition","n":0.707}}},{"i":5354,"$":{"0":{"v":"Speech Coach","n":0.707}}},{"i":5355,"$":{"0":{"v":"Development Assistant","n":0.707}}},{"i":5356,"$":{"0":{"v":"Bot Framework","n":0.707}}},{"i":5357,"$":{"0":{"v":"AI Assistant","n":0.707}}},{"i":5358,"$":{"0":{"v":"XMPP-Server","n":1}}},{"i":5359,"$":{"0":{"v":"XMPP-Client","n":1}}},{"i":5360,"$":{"0":{"v":"Web","n":1}}},{"i":5361,"$":{"0":{"v":"Workflow Software","n":0.707},"1":{"v":"\n## Log\n\n- t.2024.03.25.14 discovered [[prdct.conductor]]","n":0.447}}},{"i":5362,"$":{"0":{"v":"Web3","n":1}}},{"i":5363,"$":{"0":{"v":"Protocol","n":1}}},{"i":5364,"$":{"0":{"v":"Web-Framework","n":1},"1":{"v":"\n## Resources\n\n- https://stackoverflow.blog/2020/02/03/is-it-time-for-a-front-end-framework/\n- https://rollbar.com/blog/most-popular-java-web-frameworks/#","n":0.5}}},{"i":5365,"$":{"0":{"v":"Virtual-Reality","n":1}}},{"i":5366,"$":{"0":{"v":"Simulation-Framework","n":1},"1":{"v":"\n- ","n":1}}},{"i":5367,"$":{"0":{"v":"Discrete Event Simulation Framework","n":0.5}}},{"i":5368,"$":{"0":{"v":"Rules-Engine","n":1}}},{"i":5369,"$":{"0":{"v":"RPG Software","n":0.707}}},{"i":5370,"$":{"0":{"v":"Virtual Tabletop","n":0.707}}},{"i":5371,"$":{"0":{"v":"Utilities","n":1}}},{"i":5372,"$":{"0":{"v":"Fat Client","n":0.707}}},{"i":5373,"$":{"0":{"v":"Map Maker","n":0.707}}},{"i":5374,"$":{"0":{"v":"Hosting","n":1}}},{"i":5375,"$":{"0":{"v":"Data Mover","n":0.707}}},{"i":5376,"$":{"0":{"v":"Campaign Manager","n":0.707}}},{"i":5377,"$":{"0":{"v":"RPC Software","n":0.707}}},{"i":5378,"$":{"0":{"v":"Platform","n":1},"1":{"v":"\n- ","n":1}}},{"i":5379,"$":{"0":{"v":"Microservice-Frameworks","n":1}}},{"i":5380,"$":{"0":{"v":"Metaverse Platform","n":0.707},"1":{"v":"\n## [[c.list.implementations]]\n\n- https://www.alchemy.com/alternatives/ethereal-engine","n":0.577}}},{"i":5381,"$":{"0":{"v":"Live Programming","n":0.707}}},{"i":5382,"$":{"0":{"v":"Library","n":1},"1":{"v":"\n\n\n-  [[c.solution]]\n","n":0.707}}},{"i":5383,"$":{"0":{"v":"Temporal","n":1}}},{"i":5384,"$":{"0":{"v":"Metaprogramming","n":1}}},{"i":5385,"$":{"0":{"v":"Language-Workbench","n":1},"1":{"v":"\n## [[c.resource.list]]\n\n- http://dsl-course.org/language-workbenches/\n- https://homepages.cwi.nl/~storm/publications/lwc13paper.pdf\n- https://stackoverflow.com/questions/2603134/what-are-the-main-differences-between-jetbrains-mps-and-eclipse-xtext","n":0.447}}},{"i":5386,"$":{"0":{"v":"Knowledge-Base","n":1}}},{"i":5387,"$":{"0":{"v":"IAM","n":1}}},{"i":5388,"$":{"0":{"v":"Generator","n":1}}},{"i":5389,"$":{"0":{"v":"Game-Platform","n":1},"1":{"v":"\n- ","n":1}}},{"i":5390,"$":{"0":{"v":"Multi-User-Dungeon","n":1}}},{"i":5391,"$":{"0":{"v":"Game-Maker","n":1},"1":{"v":"\n#aka game-making game","n":0.577}}},{"i":5392,"$":{"0":{"v":"Game-Engine","n":1},"1":{"v":"\n![](/assets/images/2024-01-09-13-15-25.png)\n  - Run time game engine architecture, Jason Gregory.\n\n## [[c.resource.list]]\n\n- https://www.incredibuild.com/blog/top-gaming-engines-you-should-consider\n- ","n":0.302}}},{"i":5393,"$":{"0":{"v":"Entity Component System","n":0.577}}},{"i":5394,"$":{"0":{"v":"Enterprise Software","n":0.707}}},{"i":5395,"$":{"0":{"v":"Distributed-Systems-Runtime","n":1}}},{"i":5396,"$":{"0":{"v":"DecisionEngine","n":1}}},{"i":5397,"$":{"0":{"v":"Decision-Engine","n":1}}},{"i":5398,"$":{"0":{"v":"Computational Notebook","n":0.707},"1":{"v":"\n## Cons\n\n- \"Notebooks shouldn't be used, however, as a component of a production system. The notebook structure - with its casual mix of IO, calculation, and UI - is there to encourage interactivity, but works against the modularity needed for code that is used as part of a broader code base. It's best to think of notebooks as a way of exploring logic, once you've found a path, that logic should be replicated into a library designed for production use.\"\n  - https://martinfowler.com/bliki/ComputationalNotebook.html\n## Resources\n\n### [[c.resource.list]]\n\n- https://geekflare.com/best-data-science-notebooks/","n":0.108}}},{"i":5399,"$":{"0":{"v":"Communication-Server","n":1},"1":{"v":"\n- #aka chat server, instant messaging service\n","n":0.378}}},{"i":5400,"$":{"0":{"v":"Cognitive Architecture","n":0.707}}},{"i":5401,"$":{"0":{"v":"Cellular Automoton","n":0.707}}},{"i":5402,"$":{"0":{"v":"CLI-framework","n":1}}},{"i":5403,"$":{"0":{"v":"Authentication","n":1},"1":{"v":"\n## Comparison\n\n- https://www.btw.so/open-source-alternatives/auth0-alternatives","n":0.577}}},{"i":5404,"$":{"0":{"v":"Application-Framework","n":1}}},{"i":5405,"$":{"0":{"v":"Agent Framework","n":0.707},"1":{"v":"\n- ","n":1}}},{"i":5406,"$":{"0":{"v":"Actor Framework","n":0.707}}},{"i":5407,"$":{"0":{"v":"Service","n":1}}},{"i":5408,"$":{"0":{"v":"Startup Formation","n":0.707},"1":{"v":"\n## Resources\n\n- https://jonathanmillspatrick.com/the-best-companies-for-startup-formation/\n  - [[c.mention]] [[prdct.gust]] [[prdct.angel-list-stack]] [[prdct.clerky]]","n":0.354}}},{"i":5409,"$":{"0":{"v":"Grammar","n":1}}},{"i":5410,"$":{"0":{"v":"Controlled Grammar","n":0.707}}},{"i":5411,"$":{"0":{"v":"Abstract Grammar","n":0.707}}},{"i":5412,"$":{"0":{"v":"Account","n":1}}},{"i":5413,"$":{"0":{"v":"Twitter","n":1}}},{"i":5414,"$":{"0":{"v":"Instagram","n":1}}},{"i":5415,"$":{"0":{"v":"Release","n":1}}},{"i":5416,"$":{"0":{"v":"Initial","n":1}}},{"i":5417,"$":{"0":{"v":"Pattern","n":1}}},{"i":5418,"$":{"0":{"v":"Architecture Pattern","n":0.707}}},{"i":5419,"$":{"0":{"v":"List","n":1}}},{"i":5420,"$":{"0":{"v":"Implementations","n":1},"1":{"v":"\n- ","n":1}}},{"i":5421,"$":{"0":{"v":"Feature List","n":0.707}}},{"i":5422,"$":{"0":{"v":"Guess","n":1}}},{"i":5423,"$":{"0":{"v":"Best Guess","n":0.707}}},{"i":5424,"$":{"0":{"v":"Crew","n":1}}},{"i":5425,"$":{"0":{"v":"Director","n":1}}},{"i":5426,"$":{"0":{"v":"Transcript","n":1}}},{"i":5427,"$":{"0":{"v":"Stanford Applicant","n":0.707}}},{"i":5428,"$":{"0":{"v":"Responsibility","n":1}}},{"i":5429,"$":{"0":{"v":"Requirement","n":1}}},{"i":5430,"$":{"0":{"v":"Registry","n":1}}},{"i":5431,"$":{"0":{"v":"Ontology","n":1}}},{"i":5432,"$":{"0":{"v":"Question","n":1}}},{"i":5433,"$":{"0":{"v":"Ontology","n":1}}},{"i":5434,"$":{"0":{"v":"Upper Ontology","n":0.707},"1":{"v":"\n- #definition: identifies those generic types of entities which belong to the formal structure of the world (e.g., OBJECT, PROCESS , SPATIAL REGION ), together with formal specifications of how those types of entities are related to others (e.g., OBJECT participates_in PROCESS ).\n  - https://www.nist.gov/system/files/documents/2021/10/14/nist-ai-rfi-cubrc_inc_004.pdf\n\n## Resources\n\n- [[ar.a-comparison-of-upper-ontologies]]","n":0.146}}},{"i":5435,"$":{"0":{"v":"Mid-level Ontology","n":0.707},"1":{"v":"\n- #definition: A mid-level ontology is one that adds general content to the structure outlined in the upper-level ontology by identifying types of entities which directly specialize the upper- level types, but which are also common to many domains of interest. Classes that appear in mid-level ontologies are still fairly basic with respect to particular knowledge domains and often require further specialization to be useful for data modeling (e.g., PERSON , ACT OF COMMUNICATION , or GEOPOLITICAL ENTITY).\n  - https://www.nist.gov/system/files/documents/2021/10/14/nist-ai-rfi-cubrc_inc_004.pdf\n  ","n":0.112}}},{"i":5436,"$":{"0":{"v":"Lexical","n":1}}},{"i":5437,"$":{"0":{"v":"Fictional Ontologies","n":0.707},"1":{"v":"\n- related: [[t.km.ontology.fictional]]\n\n","n":0.577}}},{"i":5438,"$":{"0":{"v":"Extension","n":1}}},{"i":5439,"$":{"0":{"v":"Events","n":1}}},{"i":5440,"$":{"0":{"v":"Domain","n":1},"1":{"v":"\n- #aka lower-level ontology\n- #definition A domain-level ontology is one that identifies types that further specialize the basic types from one or more mid-level ontologies. Domain ontologies describe objects, events, and relationships that are of interest to a more limited number of knowledge domains (e.g., INTELLIGENCE ANALYST ROLE , PORTION OF AMMONIUM NITRATE , or ACT OF WATERCRAFT REGISTRATION \n  - https://www.nist.gov/system/files/documents/2021/10/14/nist-ai-rfi-cubrc_inc_004.pdf","n":0.127}}},{"i":5441,"$":{"0":{"v":"Rpg","n":1}}},{"i":5442,"$":{"0":{"v":"Dnd","n":1}}},{"i":5443,"$":{"0":{"v":"Creative Work","n":0.707}}},{"i":5444,"$":{"0":{"v":"Methodology","n":1}}},{"i":5445,"$":{"0":{"v":"Semantic Web Methodology","n":0.577}}},{"i":5446,"$":{"0":{"v":"Ontology Engineering","n":0.707}}},{"i":5447,"$":{"0":{"v":"Logic","n":1}}},{"i":5448,"$":{"0":{"v":"Extension","n":1}}},{"i":5449,"$":{"0":{"v":"Investor","n":1}}},{"i":5450,"$":{"0":{"v":"Game","n":1},"1":{"v":"\n\n\n - [[p.correspondsTo]] [[t.rec.game]]\n","n":0.5}}},{"i":5451,"$":{"0":{"v":"Watch to Win","n":0.577}}},{"i":5452,"$":{"0":{"v":"Voxel","n":1}}},{"i":5453,"$":{"0":{"v":"Survival","n":1}}},{"i":5454,"$":{"0":{"v":"Simulation","n":1}}},{"i":5455,"$":{"0":{"v":"Sandbox","n":1},"1":{"v":"\n\n\n- [[p.coreferences]] [[t.cs.game.sandbox]]\n","n":0.577}}},{"i":5456,"$":{"0":{"v":"Programmable Games","n":0.707},"1":{"v":"\n## Resources\n\n- [[ar.toolify.the-future-of-game-development-ai-and-megatrends]]","n":0.577}}},{"i":5457,"$":{"0":{"v":"Peacewager","n":1},"1":{"v":"\n## References\n\n- https://www.lesswrong.com/posts/bF353RHmuzFQcsokF/peacewagers-cohabitive-games-so-far\n- https://www.lesswrong.com/posts/RNbcJedHf4jmZ9GHq/the-point-of-a-game-is-not-to-win-and-you-shouldn-t-even\n  - \"every artful and convincing work, is a work of apologia, to explain its purpose would require wholely translating it into an essay, the author, expert in one medium, may not know how to translate it, and its translation would always be weaker.\" ^shcvozg37jq0","n":0.144}}},{"i":5458,"$":{"0":{"v":"Incremental Game","n":0.707}}},{"i":5459,"$":{"0":{"v":"Horror","n":1}}},{"i":5460,"$":{"0":{"v":"Headless Games","n":0.707}}},{"i":5461,"$":{"0":{"v":"Free to Play","n":0.577},"1":{"v":"\n- \"for a free-to-play game to be successful, it needs to.. offer a balanced and fair gameplay experience, regardless of whether a player makes in-app purchases or not.\"\n\n\n## How do free-to-play game developers make money?\n\n- in-app purchase (often [[t.cs.game.pay-to-win]])\n- advertising\n- subscriptions (additional content, characters, or other features)\n- paid DLC\n- sponsorship and licensing \n\n## Pro\n\n- increased reach/accessibility\n- lower barrier to entry\n- micro\n\n## References\n\n- https://medium.com/illumination/how-do-free-to-play-games-make-money-766f7e3d8c8d","n":0.126}}},{"i":5462,"$":{"0":{"v":"Gacha","n":1},"1":{"v":"\n- description: gacha games entice players to spend in-game currency to receive a random in-game item. Some in-game currency generally can be gained through game play, and some by purchasing it from the game publisher using real-world funds.\n- [[c.reference]] https://en.wikipedia.org/wiki/Gacha_game","n":0.158}}},{"i":5463,"$":{"0":{"v":"Metroidvania","n":1},"1":{"v":"\n- #aka Platform Adventure\n\n\n## Attributes\n\n- large interconnected world map the player can explore, although parts of the world will be inaccessible to the player until they acquire special items, tools, weapons, abilities, or knowledge within the game\n- tighter integration of story and level design\n- careful design of levels and character controls to encourage exploration and experimentation\n- a means for the player to become more invested in their player character through role-playing game elements\n\n## References\n\n- https://platformadventure.weebly.com/","n":0.115}}},{"i":5464,"$":{"0":{"v":"Fantasy Setting","n":0.707},"1":{"v":"\n- aka: shared universe","n":0.5}}},{"i":5465,"$":{"0":{"v":"Description Logic","n":0.707}}},{"i":5466,"$":{"0":{"v":"Creature","n":1}}},{"i":5467,"$":{"0":{"v":"Fictional","n":1}}},{"i":5468,"$":{"0":{"v":"Cool","n":1}}},{"i":5469,"$":{"0":{"v":"Work","n":1}}},{"i":5470,"$":{"0":{"v":"superwork","n":1},"1":{"v":"\n\n## Examples\n\n- [[prdct.icewind-dale-rime-of-the-frostmaiden]]","n":0.577}}},{"i":5471,"$":{"0":{"v":"Website","n":1},"1":{"v":"\n\n\na set of coherent web pages, typically corresponding with a single domain name; but sometimes a single domain can have multiple sites\n","n":0.213}}},{"i":5472,"$":{"0":{"v":"Weather","n":1}}},{"i":5473,"$":{"0":{"v":"Vision","n":1}}},{"i":5474,"$":{"0":{"v":"Verb Forms","n":0.707},"1":{"v":"\n#linguistics\n","n":1}}},{"i":5475,"$":{"0":{"v":"ThirdPersonSingular","n":1}}},{"i":5476,"$":{"0":{"v":"Root","n":1},"1":{"v":"\n#linguistics\n","n":1}}},{"i":5477,"$":{"0":{"v":"PresentParticiple","n":1},"1":{"v":"\n#linguistics\n","n":1}}},{"i":5478,"$":{"0":{"v":"PastTense","n":1},"1":{"v":"\n#linguistics\n","n":1}}},{"i":5479,"$":{"0":{"v":"PastParticiple","n":1},"1":{"v":"\n#linguistics\n","n":1}}},{"i":5480,"$":{"0":{"v":"ValueProposition","n":1}}},{"i":5481,"$":{"0":{"v":"User Story (Class)","n":0.577},"1":{"v":"\n\n\nCaptures aspects of an actual or imagined [[c.feature]], [[c.capability]], [[c.solution]], [[c.problem]] or [[c.opportunity]] from a user's perspective.\n\n- [[p.subClassOf]] [[c.class]]\n- [[p.hasTheme]] [[t.pdm]] \n- [[p.correspondsTo]] [[User Stories|t.pdm.user-stories]]\n\n## User Story Templates\n\n- `In order to <receive benefit> as a <role>, I can <goal/desire>`\n- `As <who> <when> <where>, I want <what> because <why>`\n## Resources\n\n- https://medium.com/agileinsider/five-ws-a-fool-proof-model-to-build-user-stories-187a505d22fe\n","n":0.141}}},{"i":5482,"$":{"0":{"v":"Use Cases","n":0.707},"1":{"v":"\n\n\n- \" a way to capture the high-level objectives of a\" solution\n- we need to consider two concepts, and how they relate:\n\n    the actors\n    the goals\n\n","n":0.196}}},{"i":5483,"$":{"0":{"v":"Topic","n":1},"1":{"v":"\n\n\n## Resources\n\n- ![[daily.journal.2021.09.13#concept-vs-topic,1:#*]]\n","n":0.577}}},{"i":5484,"$":{"0":{"v":"Related","n":1}}},{"i":5485,"$":{"0":{"v":"TimePeriod","n":1}}},{"i":5486,"$":{"0":{"v":"Thoughts","n":1}}},{"i":5487,"$":{"0":{"v":"Thesis","n":1},"1":{"v":"\n\n\nan academic work, usually submitted at the end of a masters program\n","n":0.289}}},{"i":5488,"$":{"0":{"v":"Term","n":1}}},{"i":5489,"$":{"0":{"v":"Summary","n":1}}},{"i":5490,"$":{"0":{"v":"Bot","n":1}}},{"i":5491,"$":{"0":{"v":"Statement","n":1}}},{"i":5492,"$":{"0":{"v":"Sponsor","n":1}}},{"i":5493,"$":{"0":{"v":"Sphere","n":1},"1":{"v":"\n- broader than a domain, a sphere is essentially a \"big-picture adjective\" that can be used for classifying classes, predicates, and maybe topics, etc\n- basically like a hashtag, in their general use case","n":0.174}}},{"i":5494,"$":{"0":{"v":"Specification","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] spec, standard, guideline\n","n":0.447}}},{"i":5495,"$":{"0":{"v":"API Description Specification","n":0.577}}},{"i":5496,"$":{"0":{"v":"Specialization","n":1}}},{"i":5497,"$":{"0":{"v":"Solution","n":1},"1":{"v":"\n\none or more products, services, technologies, applications, libraries, frameworks, methodologies, or specifications that solve a problem or create an opportunity. Or at least has the potential to be useful or entertaining.\n\n","n":0.18}}},{"i":5498,"$":{"0":{"v":"Related","n":1}}},{"i":5499,"$":{"0":{"v":"Possible","n":1}}},{"i":5500,"$":{"0":{"v":"Marketing-Platform","n":1}}},{"i":5501,"$":{"0":{"v":"Dismissed","n":1}}},{"i":5502,"$":{"0":{"v":"Selection","n":1}}},{"i":5503,"$":{"0":{"v":"SKU","n":1}}},{"i":5504,"$":{"0":{"v":"Role","n":1}}},{"i":5505,"$":{"0":{"v":"Review","n":1}}},{"i":5506,"$":{"0":{"v":"Result","n":1},"1":{"v":"\n- [[p.instanceOf]] [[c.class.shapow]]","n":0.577}}},{"i":5507,"$":{"0":{"v":"Responbility","n":1}}},{"i":5508,"$":{"0":{"v":"Resource","n":1},"1":{"v":"\n- I've ended up using this as \"something that a resourceful person might find useful\"\n\n## Related\n\n- [[Resources That Refer Vs Resources That Are|vs.resources-that-refer-vs-resources-that-are]]\n","n":0.209}}},{"i":5509,"$":{"0":{"v":"List","n":1}}},{"i":5510,"$":{"0":{"v":"Learning Resources","n":0.707}}},{"i":5511,"$":{"0":{"v":"Reference","n":1}}},{"i":5512,"$":{"0":{"v":"Quotes","n":1}}},{"i":5513,"$":{"0":{"v":"Publisher","n":1}}},{"i":5514,"$":{"0":{"v":"Project","n":1}}},{"i":5515,"$":{"0":{"v":"ProgrammingLanguage","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.language]]\n","n":0.577}}},{"i":5516,"$":{"0":{"v":"Product","n":1}}},{"i":5517,"$":{"0":{"v":"Related","n":1}}},{"i":5518,"$":{"0":{"v":"Process","n":1}}},{"i":5519,"$":{"0":{"v":"Problem","n":1}}},{"i":5520,"$":{"0":{"v":"Pro","n":1}}},{"i":5521,"$":{"0":{"v":"Principle","n":1},"1":{"v":"\n[[p.subClassOf]] [[c.concept]]\n","n":0.707}}},{"i":5522,"$":{"0":{"v":"Design Principles","n":0.707}}},{"i":5523,"$":{"0":{"v":"Pricing","n":1}}},{"i":5524,"$":{"0":{"v":"Presenter","n":1}}},{"i":5525,"$":{"0":{"v":"Prerequisite","n":1}}},{"i":5526,"$":{"0":{"v":"Prepositional Forms","n":0.707},"1":{"v":"\n#linguistics\n\n","n":1}}},{"i":5527,"$":{"0":{"v":"PredicateTemplates","n":1},"1":{"v":"\n#gd \n\n- [[p.subClassOf]] [[c.class]] \n- [[p.equivalentClass]] [rdf:Property](http://www.w3.org/1999/02/22-rdf-syntax-ns#Property)\n","n":0.378}}},{"i":5528,"$":{"0":{"v":"PredicateForms","n":1}}},{"i":5529,"$":{"0":{"v":"Predicate (Class)","n":0.707},"1":{"v":"\n\n\n\n- [[p.subClassOf]] [[c.class]] \n- [[p.equivalentClass]] [rdf:Property](http://www.w3.org/1999/02/22-rdf-syntax-ns#Property)\n\n","n":0.408}}},{"i":5530,"$":{"0":{"v":"PodcastSeries","n":1},"1":{"v":"\n\nan episodic series of digital audio files\n","n":0.378}}},{"i":5531,"$":{"0":{"v":"Platform","n":1},"1":{"v":"\n\n\n- Platforms might be considered solutions, i.e., for software developers or users, but the salient thing is that they host solutions.\n","n":0.218}}},{"i":5532,"$":{"0":{"v":"Plan","n":1}}},{"i":5533,"$":{"0":{"v":"Paraphrase","n":1},"1":{"v":"\n#linguistics\n","n":1}}},{"i":5534,"$":{"0":{"v":"Paper","n":1},"1":{"v":"\n\n\nAcademic, position, green, and white papers.  \n","n":0.378}}},{"i":5535,"$":{"0":{"v":"Panelist","n":1}}},{"i":5536,"$":{"0":{"v":"Overview","n":1}}},{"i":5537,"$":{"0":{"v":"Organization","n":1},"1":{"v":"\n\n\nA business, community, educational institution, government agency, NGO, or gang.\n","n":0.316}}},{"i":5538,"$":{"0":{"v":"Option","n":1}}},{"i":5539,"$":{"0":{"v":"Opportunity","n":1}}},{"i":5540,"$":{"0":{"v":"Notes","n":1},"1":{"v":"\n## types of notes\n\n### According to @rachel-jepsen\n\n- [[p.hasSource]] https://practiceprocesscraft.substack.com/p/take-note\n\n  -   **Notes of Attention** are observational notes that comes through the senses. They’re fragments or sketches of things you spot or overhear or wonder that are interesting or surprising but you don’t know why or what for yet!\n      \n      1.  These kinds of notes—what you might keep in a pocket note-book or your notes app—can be surprisingly revealing. What do you find yourself interested in repeatedly in your environment? When you travel? What you overhear people say, what people wear or how they move, something in the natural world, something inside? Seeing over time where your interest tends to be drawn will tell you a lot about yourself and your style. Most of my note-taking life has been non-directed notes of interest that become like the nails of the house of my work.\n          \n  -   **Notes of Support** have a specific purpose for an essay, story, or book you’re working on, or to something else you’re building, like a course or company, or to an idea you’re developing.\n      \n      1.  May include notes on **descriptions** of a problem, **solutions** to a problem, **directions** an idea might go, **stories** you can use to explain the idea, and questions related to the idea. Any of these pop into your head day and night!\n          \n      2.  **Observational notes** (using the senses) can help you come up with great metaphors and other ways to explain or translate your ideas.\n          \n      3.  **Discovery notes** are a kind of note-of-support taken during reading, research, or work, to help you record key findings, questions that come up, things you don’t want to forget or want to look up or revisit later. (Discovery notes might appear in your margins, but you may want a specific Discovery note-book.)\n          \n  -   **Notes of Intention** are used when you want to observe something specific to get a better understanding of it—“I’m choosing to pay attention to my feelings today and will sketch a note every time I can feel a new feeling.” Or when there’s a phenomenon you want to get a fuller picture of, maybe for a scene you’re writing—eg. notes on weather, notes on food.\n      \n  -   **Questions**, whether recorded in a single Questions Book or just as a kind of note-taking, can be an incredible resource for you! Record your questions as they occur to you, from the mundane (who was that in that movie?) to the profound (what are my values?).\n      \n  -   **Delights or gratitudes** can be recorded in a note-book designated for this purpose. Keep track of things that make you smile, no matter how small (and the smaller the better)!\n      \n      1.  “Delight” is a word I use a lot. Part of my mission is to help people experience more delight in their lives through writing—writing helps us identify, pay attention to, focus on, and richly describe what makes us happy and brings us joy, giving those things more importance and meaning in our lives.\n          \n      2.  You can learn so much about yourself by tracking delights through simple note-taking, and become grateful for what you’re surprised to find! Keeping a ‘grateful for’ note-book might be another way to go—all on its own, a designated space.\n          \n      3.  Ross Gay [wrote a whole book](https://www.npr.org/2020/03/23/820293500/encore-ross-gay-writes-the-book-of-delights) this way.","n":0.043}}},{"i":5541,"$":{"0":{"v":"Namespace","n":1}}},{"i":5542,"$":{"0":{"v":"Model","n":1}}},{"i":5543,"$":{"0":{"v":"physical","n":1}}},{"i":5544,"$":{"0":{"v":"logical","n":1}}},{"i":5545,"$":{"0":{"v":"licensing","n":1}}},{"i":5546,"$":{"0":{"v":"conceptual model","n":0.707}}},{"i":5547,"$":{"0":{"v":"business","n":1}}},{"i":5548,"$":{"0":{"v":"Middleware","n":1}}},{"i":5549,"$":{"0":{"v":"Mention","n":1}}},{"i":5550,"$":{"0":{"v":"Member","n":1}}},{"i":5551,"$":{"0":{"v":"Meeting","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.encounter]]\n","n":0.577}}},{"i":5552,"$":{"0":{"v":"Location","n":1}}},{"i":5553,"$":{"0":{"v":"LinkingVerb","n":1}}},{"i":5554,"$":{"0":{"v":"Limitation","n":1}}},{"i":5555,"$":{"0":{"v":"Lighting","n":1}}},{"i":5556,"$":{"0":{"v":"Licenses","n":1}}},{"i":5557,"$":{"0":{"v":"Language","n":1}}},{"i":5558,"$":{"0":{"v":"Programming","n":1}}},{"i":5559,"$":{"0":{"v":"Item","n":1}}},{"i":5560,"$":{"0":{"v":"Issue","n":1}}},{"i":5561,"$":{"0":{"v":"Inspiration","n":1}}},{"i":5562,"$":{"0":{"v":"Implementation","n":1}}},{"i":5563,"$":{"0":{"v":"favorite","n":1}}},{"i":5564,"$":{"0":{"v":"Idea","n":1}}},{"i":5565,"$":{"0":{"v":"Product Idea","n":0.707},"1":{"v":"\n\nNew ways to exploit opportunities and solve problems. \n\nAnything from a big-picture invention that could change the world to a small tweak to existing functionality, product ideas capture them all.\n\n- [[p.alsoKnownAs]] product idea, possible feature, potential capability, pi \n- [[p.canBePluralizedAs]] product ideas, feature ideas, \n","n":0.149}}},{"i":5566,"$":{"0":{"v":"Host","n":1}}},{"i":5567,"$":{"0":{"v":"Highlight","n":1}}},{"i":5568,"$":{"0":{"v":"Framework","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.solution]]\n\n","n":0.577}}},{"i":5569,"$":{"0":{"v":"FileFormat","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.solution]]\n\n","n":0.577}}},{"i":5570,"$":{"0":{"v":"Features","n":1},"1":{"v":"\n\n\n- [[p.similarTo]] [[c.capability]]\n\n## [[p.hadDefinition]]\n\n- \"A Feature is a service that fulfills a stakeholder need\"\n  - [[p.hasSource]] https://www.scaledagileframework.com/features-and-capabilities/","n":0.243}}},{"i":5571,"$":{"0":{"v":"Possible","n":1}}},{"i":5572,"$":{"0":{"v":"Frequently Asked Questions","n":0.577}}},{"i":5573,"$":{"0":{"v":"Extension","n":1}}},{"i":5574,"$":{"0":{"v":"Exchange","n":1}}},{"i":5575,"$":{"0":{"v":"Example","n":1}}},{"i":5576,"$":{"0":{"v":"Event","n":1},"1":{"v":"\n\n\n- a thing that happens\n","n":0.447}}},{"i":5577,"$":{"0":{"v":"Encounter","n":1}}},{"i":5578,"$":{"0":{"v":"Elements","n":1}}},{"i":5579,"$":{"0":{"v":"Domain","n":1}}},{"i":5580,"$":{"0":{"v":"Documentation","n":1}}},{"i":5581,"$":{"0":{"v":"Discussion","n":1}}},{"i":5582,"$":{"0":{"v":"Digital Garden","n":0.707},"1":{"v":"\n\n\na website that grows over time\n\n- [[p.subClassOf]] [[c.website]]\n- [[p.hasRelatedTopic]] [[t.km.digital-gardening]]\n","n":0.316}}},{"i":5583,"$":{"0":{"v":"Dependancy","n":1}}},{"i":5584,"$":{"0":{"v":"Definitions","n":1}}},{"i":5585,"$":{"0":{"v":"DataFormat","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.solution]]\n","n":0.577}}},{"i":5586,"$":{"0":{"v":"DSL","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.solution]] [[t.km.kos]]\n","n":0.5}}},{"i":5587,"$":{"0":{"v":"Internal DSL","n":0.707},"1":{"v":"\n- #aka embedded dsl\n- a DSL written in a programming language","n":0.302}}},{"i":5588,"$":{"0":{"v":"CreativeWork","n":1}}},{"i":5589,"$":{"0":{"v":"Copy","n":1}}},{"i":5590,"$":{"0":{"v":"Contributor","n":1},"1":{"v":"\n- [[p.subClassOf]] [[c.actor]]","n":0.577}}},{"i":5591,"$":{"0":{"v":"Conclusion","n":1}}},{"i":5592,"$":{"0":{"v":"Concept","n":1},"1":{"v":"\n## [[p.hasExample]]\n\n- [[t.cs.programming.liskov-substitution-principle]]","n":0.577}}},{"i":5593,"$":{"0":{"v":"Con","n":1}}},{"i":5594,"$":{"0":{"v":"ComputerGame","n":1},"1":{"v":"\n\n\n- [[p.correspondsTo]] [[t.cs.game]]\n","n":0.577}}},{"i":5595,"$":{"0":{"v":"Composition","n":1}}},{"i":5596,"$":{"0":{"v":"Component","n":1},"1":{"v":"\n #product-management #software-development\n  \n- [[p.hadDefinition]] \"entity that is capable of exhibiting an input-output behavior through a well-defined interface\"\n  - [[p.hasSource]] [[book.distributed-simulation]]\n","n":0.218}}},{"i":5597,"$":{"0":{"v":"Comparison","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.class]]\n","n":0.577}}},{"i":5598,"$":{"0":{"v":"Comparand","n":1}}},{"i":5599,"$":{"0":{"v":"Comparable","n":1}}},{"i":5600,"$":{"0":{"v":"Company","n":1},"1":{"v":"\n\n\n- [[p.alsoKnownAs]] business\n- [[p.subClassOf]] [[c.organization]]\n","n":0.447}}},{"i":5601,"$":{"0":{"v":"Community","n":1},"1":{"v":"\n\n\n- [[p.vs]] [[c.organization]]\n  - community: more informal, effortless\n  - organization: more formal; requires definition\n","n":0.267}}},{"i":5602,"$":{"0":{"v":"Command","n":1}}},{"i":5603,"$":{"0":{"v":"Collectors","n":1},"1":{"v":"\n\n\n- [[p.hasSense]] your motivation to acquire things (usually certain classes of things) exceeds an appropriate amount of attention, given their practical value\n  - but collectors are sometime, hopefully motivated by the educational value of centralizing exemplars\n","n":0.167}}},{"i":5604,"$":{"0":{"v":"Class","n":1},"1":{"v":"\n\n\nthe class of classes; \n\n- [[p.subClassOf]] [[c.class]]  ^03d6g645hfzr\n  - arguably you can't be a subclass of yourself, but for clarity, subClassOf class works better in general for classes\n- [[p.equivalentClass]] rdfs:Class \n","n":0.18}}},{"i":5605,"$":{"0":{"v":"Shapow","n":1}}},{"i":5606,"$":{"0":{"v":"Claim","n":1}}},{"i":5607,"$":{"0":{"v":"Caveat","n":1}}},{"i":5608,"$":{"0":{"v":"Capability","n":1},"1":{"v":"\n\n- [[p.similarReferentTo]] [[t.pdm.capability]]\n\n","n":0.577}}},{"i":5609,"$":{"0":{"v":"Calendar","n":1},"1":{"v":"\n- #temporal","n":0.707}}},{"i":5610,"$":{"0":{"v":"Blog","n":1},"1":{"v":"\n\n\n- [[p.identifier]] http://schema.org/Blog\n","n":0.577}}},{"i":5611,"$":{"0":{"v":"Benefit","n":1}}},{"i":5612,"$":{"0":{"v":"Award","n":1}}},{"i":5613,"$":{"0":{"v":"Attribute","n":1}}},{"i":5614,"$":{"0":{"v":"Application","n":1}}},{"i":5615,"$":{"0":{"v":"Analysis","n":1}}},{"i":5616,"$":{"0":{"v":"Agent","n":1},"1":{"v":"\nthe super-class of people, animals, bots, orgs, political parties, communities et al\n\n","n":0.289}}},{"i":5617,"$":{"0":{"v":"AddressableResource","n":1}}},{"i":5618,"$":{"0":{"v":"Actor","n":1},"1":{"v":"\n- [[p.similarTo]] [[c.agent]]\n- [[vs]] [[c.agent]]\n  - a rube goldberg machine\n  - [[ar.c2.actor-vs-agent]]","n":0.289}}},{"i":5619,"$":{"0":{"v":"Speaker","n":1}}},{"i":5620,"$":{"0":{"v":"Presenter","n":1}}},{"i":5621,"$":{"0":{"v":"Activity","n":1},"1":{"v":"\n[[p.equivalentPredicate]] \n: [[p.did]]\n\n- almost unnecessary, I've been using bullet points as an uncategorized default for activity logging\n  - BUT, if you started a new category of stuff, you need a way to re-declare activity items.\n- something you can do is either a plan, or not worth mentioning\n\n\n[[c.timeperiod]]\n\n## Specifications\n\n[[c.domain]]\n: [[c.actor]]\n: [[c.project]]\n\n  - only an actor can undertake activity, but things can be said to have activity that contain actors, like products, places; \n    - I guess mechanical devices are actors; for that matter, the sun could be an actor even though you wouldn't really call it a device","n":0.102}}},{"i":5622,"$":{"0":{"v":"Books","n":1}}},{"i":5623,"$":{"0":{"v":"We Can Remember It for You Wholesale","n":0.378},"1":{"v":"\n- author: @philip-k-dick","n":0.577}}},{"i":5624,"$":{"0":{"v":"Waverly","n":1},"1":{"v":"\n- author: @walter-scott\n- genre: [[t.storytelling.tropes.historical-fiction]]","n":0.447}}},{"i":5625,"$":{"0":{"v":"Virtues of the Mind","n":0.5},"1":{"v":"\n\nAn attempt to establish a theory of knowledge based on the model of virtue theory in ethics.\n\n- [[p.hasAssesment]]\n  - likely to be dense\n  - not closely related to immediate priorities\n  - could inform an in-game model of morality\n","n":0.162}}},{"i":5626,"$":{"0":{"v":"Uncertainty in Games","n":0.577},"1":{"v":"\n- author: @greg-costikyan\n\n## Highlights\n\n### 3. Uncertainty\n\n- @roger-caillois: “Play is . . . uncertain activity. Doubt must remain until the end, and hinges upon the denouement. . . . Every game of skill, by definition, involves the risk for the player of missing his stroke and the threat of defeat, without which the game would no longer be pleasing. In fact, the game is no longer pleasing to one who, because he is too well trained or skilful, wins effortlessly and infallibly.”\n- The goal of Space Invaders is not to “win,” for you cannot, but to achieve a high score—perhaps bettering your own previous score, perhaps achieving a place on the high score list, perhaps outdoing a friend, perhaps achieving the top slot on the list. The uncertainty of the game lies not in its ultimate outcome, but in the final score.\n- not all games have outcomes\n","n":0.083}}},{"i":5627,"$":{"0":{"v":"TypeScript in 50 Lessons","n":0.5}}},{"i":5628,"$":{"0":{"v":"The Year of Magical Thinking","n":0.447},"1":{"v":"\n\n\n- [[p.hasAuthor]] @joan-didion\n","n":0.577}}},{"i":5629,"$":{"0":{"v":"The Wave in the Mind","n":0.447}}},{"i":5630,"$":{"0":{"v":"The User Is an Illusion","n":0.447}}},{"i":5631,"$":{"0":{"v":"The Upside of Uncertainty","n":0.5},"1":{"v":"\nauthor:  @nathan-furr @susannah-harmon-furr\n![[book.the-pathless-path#^dkz40u2pbdkg]]","n":0.577}}},{"i":5632,"$":{"0":{"v":"The Tipping Point","n":0.577}}},{"i":5633,"$":{"0":{"v":"The Pathless Path","n":0.577},"1":{"v":"\nauthor: @paul-millerd\n\n#similar [[book.the-pathless-path]] [[book.the-upside-of-uncertainty]]  ^dkz40u2pbdkg","n":0.447}}},{"i":5634,"$":{"0":{"v":"The Oxford Handbook of 4 E Cognition","n":0.378},"1":{"v":"\n- https://academic.oup.com/edited-volume/28083\n- ","n":0.707}}},{"i":5635,"$":{"0":{"v":"The Outermost House","n":0.577}}},{"i":5636,"$":{"0":{"v":"The Four Category Ontology: a Metaphysical Foundation for Natural Science","n":0.316},"1":{"v":"\n- author: @edward-jonathan-lowe\n\n","n":0.577}}},{"i":5637,"$":{"0":{"v":"The Csharp Players Guide","n":0.5},"1":{"v":"\n- url: https://csharpplayersguide.com\n- ","n":0.577}}},{"i":5638,"$":{"0":{"v":"The C4 Model for Visualising Software Architecture","n":0.378},"1":{"v":"\n- author: @simon-brown\n\n","n":0.577}}},{"i":5639,"$":{"0":{"v":"The 4th Category","n":0.577},"1":{"v":"\n- author: @rob-kuntz\n- topics: [[game-system.dungeons-and-dragons.classic]]\n\n## Highlights\n\n### Chapter 1: Understanding Conceptual Systems\n\n- the phrase that we “play in” an adventure as op- posed to playing a board game wherein we just “play it” separates the two forms as distinct concepts\n- An open system can create, animate and inform a multiplicity of extensible systems while this is never true with a closed system. \n\n### Classic D&D\n\n- directed play with mutable rules intimately leagued with open play forms with no conceptual boundaries. \n  - It brought with it a need to create resources for it to be played, either in pre-game design sessions or during the game itself by way of its participants being able to instantly extrapolate upon what was being conceptualized. \n- merger of conceptual and mechanical systems\n  - resulting “super-system” is in systems theory parlance comprised of non-linear and linear (and/or isolated) systems that have standing relationships with each other. \n  - mechanics often come into focus when there is a need to ascertain the probabilities for success of a player’s interactions within the fantastic surround\n\n### Later variations\n\n-  predominated by mechanics and hard-fast and immutable rules.\n- growing presumption that GM-created game matter was now the province of “professional creators” \n  -  users were being incrementally disfranchised from D&D’s original creative crucible as mere consumers of those creations. \n-  whatever the GMs proposed to their players was being ignored by the latter for scaling up their characters to defeat more and more powerful adversaries\n-  a game’s mode delineates the expression paths for its participants. ^lqmkhcoab660","n":0.063}}},{"i":5640,"$":{"0":{"v":"Structure and Interpretation of Computer Programs","n":0.408},"1":{"v":"\n- #aka SICP\n- url: sarabander.github.io/sicp","n":0.447}}},{"i":5641,"$":{"0":{"v":"Storm Kings Thunder","n":0.577},"1":{"v":"\n## Manifestations\n\n- https://marketplace.dndbeyond.com/category/storm-kings-thunder?pid=SRC-00012\n- https://marketplace.dndbeyond.com/category/storm-kings-thunder?pid=B8669000&Digital%2FPhysical=Physical","n":0.5}}},{"i":5642,"$":{"0":{"v":"Start with the Vision","n":0.5},"1":{"v":"\n\r\n- [[idea.tower-of-babel-syndrome]]\r\n\r\n## [[p.hasExercise]]\r\n\r\n- pg. 42: Start with the Vision\r\n  - to have a well-defined, effective process for managing my tasks, notes, and goals\n","n":0.209}}},{"i":5643,"$":{"0":{"v":"Speech and Language Processing","n":0.5},"1":{"v":"\n### Chapter 20: Semantic Role Labelling\n\n- url: https://web.stanford.edu/~jurafsky/slp3/old_oct19/20.pdf\n- deep roles are specific to each event; Breaking events have Breakers, Opening events have Openers, and so on.\n\n#### Thematic Roles\n\nThematic Role Definition\nAGENT The volitional causer of an event\nEXPERIENCER The experiencer of an event\nFORCE The non-volitional causer of the event\nTHEME The participant most directly affected by an event\nRESULT The end product of an event\nCONTENT The proposition or content of a propositional event\nINSTRUMENT An instrument used in an event\nBENEFICIARY The beneficiary of an event\nSOURCE The origin of the object of a transfer event\nGOAL The destination of an object of a transfer event\n\nThematic Role Example\nAGENT The waiter spilled the soup.\nEXPERIENCER John has a headache.\nFORCE The wind blows debris from the mall into our yards.\nTHEME Only after Benjamin Franklin broke the ice...\nRESULT The city built a regulation-size baseball diamond...\nCONTENT Mona asked “You met Mary Ann at a supermarket?”\nINSTRUMENT He poached catfish, stunning them with a shocking device...\nBENEFICIARY Whenever Ann Callahan makes hotel reservations for her boss...\nSOURCE I flew in from Boston.\nGOAL I drove to Portland.\n\n#### Semantic Roles\n\n- are defined, not by necessary and sufficient conditions, but rather by a set of heuristic features that accompany more agent-like or more patient-like meanings\n- PropBank uses both proto-roles and verb-specific semantic roles. FrameNet uses semantic roles that are spe- cific to a general semantic idea called a frame.\n\n##### PropBank\nArg0: causer (e.g. of increase)\nArg1: thing (e.g. increasing)\nArg2: amount (e.g.increased) by, EXT, or MNR\nArg3: start point\nArg4: end point\n\n###### Arg-Ms\nTMP when? yesterday evening, now\nLOC where? at the museum, in San Francisco\nDIR where to/from? down, to Bangkok\nMNR how? clearly, with much enthusiasm\nPRP/CAU why? because ... , in response to the ruling\nREC themselves, each other\nADV miscellaneous\nPRD secondary predication ...ate the meat raw\n\n\n##### FrameNet\n\n- Whereas roles in the PropBank project are specific to an individual verb, roles in the FrameNet project are specific to a frame. What is a frame? Consider the following set of words: reservation, flight, travel, buy, price, cost, fare, rates, meal, plane There are many individual lexical relations of hyponymy, synonymy, and so on between many of the words in this list. The resulting set of relations does not, however, add up to a complete account of how these words are related. They are clearly all defined with respect to a coherent chunk of common-sense background information concerning air travel. We call the holistic background knowledge that unites these words a frame \n\n- Some of the semantic roles (frame elements) in the frame are.... separated into core roles, which are frame specific and non-core roles, which are more like the Arg-M arguments in PropBank, expressing  general properties of time, location, and so on\n\nCore Roles\nATTRIBUTE The ATTRIBUTE is a scalar property that the ITEM possesses.\nDIFFERENCE The distance by which an ITEM changes its position on the scale.\nFINAL STATE A description that presents the ITEM’s state after the change in the ATTRIBUTE’s value as an independent predication.\nFINAL VALUE The position on the scale where the ITEM ends up.\nINITIAL STATE A description that presents the ITEM’s state before the change in the ATTRIBUTE’s value as an independent predication.\nINITIAL VALUE The initial position on the scale from which the ITEM moves away.\nITEM The entity that has a position on the scale.\nVALUE RANGE A portion of the scale, typically identified by its end points, along which the values of the ATTRIBUTE fluctuate.\n\nSome Non-Core Roles\nDURATION The length of time over which the change takes place.\nSPEED The rate of change of the VALUE.\nGROUP The GROUP in which an ITEM changes the value of an\nATTRIBUTE in a specified way\n\n#### Selectional Restrictions\n\n- SRs are a semantic type constraint that a verb imposes on the kind of concepts that are allowed to fill its argument\nroles.\n- In the earliest implementations, selectional restrictions were considered strict con- straints on the kind of arguments a predicate could take\n  - it became clear that these selectional restrictions were better represented as preferences rather than strict constraints\n    - selectional restriction violations (like inedible arguments of eat) often occur in well-formed sentences, for example because they are negated (20.36), or because selectional restrictions are overstated\n- selection preference strength defines the amount of information that a predicate tells us about the semantic class of its argu-\nments. \n- Most semantic role labeling schemes only work within a single sentence, fo- cusing on the object of the verbal (or nominal, in the case of NomBank) predicate. However, in many cases, a verbal or nominal predicate may have an implicit argu- ment: one that appears only in a contextual sentence, or perhaps not at all and must be inferred. In the two sentences This house has a new owner. The sale was finalized 10 days ago. the sale in the second sentence has no ARG1, but a reasonable reader would infer that the Arg1 should be the house mentioned in the prior sentence. Find- ing these arguments, implicit argument detection (sometimes shortened as iSRL)\n\n#### Primitive Decomposition of Predicates\n\n- The decompositional approach asserts that a single state-like predicate associ- ated with open underlies all of these examples. The differences among the meanings of these examples arises from the combination of this single predicate with the prim- itives CAUSE and BECOME. While this approach to primitive decomposition can explain the similarity be- tween states and actions or causative and non-causative predicates, it still relies on having a large number of predicates like open. More radical approaches choose to break down these predicates as well. One such approach to verbal predicate de- composition that played a role in early natural language understanding systems is conceptual dependency (CD), a set of ten primitive predicates:\n\nPrimitive Definition\nATRANS The abstract transfer of possession or control from one entity to\nanother\nPTRANS The physical transfer of an object from one location to another\nMTRANS The transfer of mental concepts between entities or within an\nentity\nMBUILD The creation of new information within an entity\nPROPEL The application of physical force to move an object\nMOVE The integral movement of a body part by an animal\nINGEST The taking in of a substance by an animal\nEXPEL The expulsion of something from an animal\nSPEAK The action of producing a sound\nATTEND The action of focusing a sense organ\n\nThe verb brought is translated into the two primitives ATRANS and PTRANS to indicate that the waiter both physically conveyed the check to Mary and passed control of it to her.\n","n":0.031}}},{"i":5644,"$":{"0":{"v":"Software Architecture for Developers","n":0.5},"1":{"v":"\n- author: @simon-brown\n\n## Quotes\n\n- \"All architecture is design but not all design is architecture.\"\n  - @grady-booch","n":0.25}}},{"i":5645,"$":{"0":{"v":"Slouching towards Bethlehem","n":0.577}}},{"i":5646,"$":{"0":{"v":"Semantic Web for the Working Ontologist","n":0.408}}},{"i":5647,"$":{"0":{"v":"Semantic Web and Peer to Peer","n":0.408}}},{"i":5648,"$":{"0":{"v":"Semantic Modeling for Data","n":0.5},"1":{"v":"\n\n- url: https://learning.oreilly.com/library/view/semantic-modeling-for/9781492054269/\n\n## Highlights\n\n- Based on these definitions, what do you understand to be a concept in a semantic model? Is it a set of things as the Protégé tutorial suggests, or some unit of thought as SKOS claims? And what should you do if you need to model a concept in OWL that is not really a set of things? Should you still have to make it a class? The answer, as we will see in the rest of the book, is that the SKOS definition is more accurate and useful, and that the “concept = class” claim of the OWL tutorial is at best misleading, causing several semantic modeling errors that we will see later in the book.\n\n### Class or Individual?\n\n; a concept can indeed play the role of a class if its definition implies a set of entities that instantiate it, but this is not always the case. In property graphs, for example, there is no formal distinction between a class and an instance since everything is a node (node labels can play the role of a class but not exclusively in OWL, entities that can be classes are often modeled as individuals because, otherwise, they cannot be related to other entities\n\n- in [[prdct.owl.dl]], you cannot define a class as an instance of another class, nor can you define direct relations between classes and other entities other than some predefined ones. Thus, if you want to say at the same time that John is an instance of Data Scientist, and Data Scientist is an instance of Occupation, you just can’t.\n  - ~~t.2024.04.04.13 but I think you could say that John's occupation is an instance of Data Scientist and DS is a subclass of occupation?~~\n    - t.2024.05.15.08 nope\n      - ~~t.2024.05.24.11 because an individual data scientist would also be an instance of Occupation~~\n    - t.2024.07.14.15 I think I was confusing specialization with instantiation, see [[prdct.unified-foundational-ontology.gUFO#usage-scenarios]]\n\n### First Option: Model as individual and use custom relations\n\ne.g. John is related to the individual Data Scientist via the relation hasProfession.\n\n- you can still position the entity into a hierarchy of similar entities (e.g., saying that a Data Scientist is a kind of Information Technology Professional) by using, for example, the skos:narrower relation or similar.\n- you get the freedom to use the entity in any relations you like, not only instantiation, keeping at the same time its instances in short reach.\n- \n\n#### skos\n\n- you lose some reasoning (how much?) \n\n### Second Option: model the concept as a class and an individual\n\nA second workaround is to model the entity as two entities, one as a class and one as an individual, using different names for each (see approach 3 in [208]). Here are some examples of how this could happen:\n\n    Data Scientist becomes Data Scientist (Profession) as an individual and Data Scientist (Professional) as a class\n\n    Pneumonia becomes Pneumonia (Disease) as an individual and Pneumonia (Incident) as a class\n\n    Eagle becomes Eagle (Species) as an individual and Eagle (Animal) as a class\n\n    Samsung A8 becomes Samsung A8 (Mobile Phone Model) as an individual and Samsung A8 (Mobile Phone Device) as a class\n\nThe advantage of this approach is that you can state almost anything you like for your entity without caring if these statements apply only to classes or individuals. Moreover, having to name your entity in a way that makes explicit its role as a class helps avoid the naming pitfalls that we saw in Chapter 6. \n\nOn the other hand, you still cannot link the two variations of the entity to each other (since one is a class and the other an individual), thus making it harder to keep them in sync with each other.\n\n- t.2024.06.08.21 but you can use annotations to link them\n\n### Third Option: Punning\n\nuse OWL2 and punning, a feature that allows you to use the same entity in your model as both a class and an individual. The trick with punning is that the reasoner decides at runtime whether the entity should be interpreted as a class or individual, based on the entity’s context. Thus if, for example, the entity is linked to a class via an instantiation relation, it is treated as an individual, while if it is related to it via a subclass relation, it is treated as a class. In other words, even though the entity has one single identifier, depending on its context, it is evaluated by the reasoner as a different thing.\n\nKeep in mind that, while punning can be a useful technique, it’s not a free ticket to treating all entities as both a class and an individual. As @michael-uschold rightly argues in [209], punning is more syntactic trickery than an actual solution to the semantic problem of metaclasses, because the only thing it does is raise an invisible wall between the two interpretations of the entity. This wall may relieve you from having to use different names for the same thing, but it can also confuse your fellow modelers and users of your model if you are not careful.\n\n\n## To Subclass or Not to Subclass?\n\n- having the different cuisines embedded within the restaurant class can make it hard to talk directly about them (e.g., you cannot easily say that one cuisine is influenced by another) or link them to other entities (e.g., with recipes). Conversely, the second model allows you to talk about cuisines but takes away from you the convenience of the subclass relation.\n- The key ability that a subclass gives you in a model is that you can define relations, attributes, and other axioms that apply only to the instances of that class and not those of its superclass.\n- low rigidity subclasses require more maintenance\n\n### Things to Remember\n\n- Useful subclasses are those that have additional attributes, relations, or other characteristics compared to their parent class, and these characteristics are commonly used in the domain of discourse\n- Avoid subclasses with low rigidity as they are harder to maintain\n\n\n\n## Fuzzification\n\n- we can assign a real number to a vague statement, within a range from 0 to 1. A value of 1 would mean that the statement is completely true, a value of 0 means that it is completely false, and any value in between that is “partly true” to a given, quantifiable extent.\n- fuzzy truth degrees are not probabilities\n  - A probability statement is about quantifying the likelihood of events or facts whose truth conditions are well defined to come true (e.g., “it will rain tomorrow with a probability of 0.8”), while a fuzzy statement is about quantifying the extent to which events or facts whose truth conditions are undefined can be perceived as true.\n- Truth fuzzification makes sense only when it manages to reduce disagreements over the validity of a model’s vague statements, and the benefits of this reduction outweigh the fuzzification effort and cost\n- t.2024.07.16.10 instead of assigning numeric truth values\n  - for class membership restrictions and you could do \"always, sometimes, sometimes/usually, sometimes/often, sometimes/occasionally, sometimes/rarely, never\" and also perhaps \"periodically, sporadically\"\n\n### Fuzzification Options\n\n- The number and kind of fuzzy degrees you need to acquire for your model’s vague elements depend on the latter’s vagueness type and dimensions.\n- Commonly used fuzzy membership functions: (a) trapezoidal function, (b) triangular function, (c) left-shoulder function, (d) right-shoulder function, and (e) linear function\n- if an element has quantitative vagueness in more than one dimension, then things become a bit more complicated. \n  - One option is to define a multivariate fuzzy membership function like the one in Figure 12-5, i.e., a function with one variable for each dimension. For example, if you have the class CompetitorCompany that you have identified as quantitatively vague in the dimensions of revenue and employee count, then you could define a two-variable function based on these dimensions.\n  - Another option is to define one membership function per dimension and then combine these via some fuzzy logic operation, like fuzzy conjunction or fuzzy disjunction","n":0.028}}},{"i":5649,"$":{"0":{"v":"Robin S Laws of Good Game Mastering","n":0.378}}},{"i":5650,"$":{"0":{"v":"Practical-RDF","n":1},"1":{"v":"\n\n\n##  [RDF Containers](https://learning.oreilly.com/library/view/practical-rdf/0596002637/ch04.html#pracrdf-CHP-4-SECT-1.1)\n\n- bag\n- sequence ^P9k4dBHBIIGI\n- alternative\n\n## References\n\n\nA second type of container is the sequence, or rdf:Seq","n":0.243}}},{"i":5651,"$":{"0":{"v":"Practical Ontologies for Information Professionals","n":0.447},"1":{"v":"\n\n## Issues\n\n- unclear diagarms\n- \"a lot of material which is tangential to ontologies: Linked Data, controlled vocabularies, thesauri, natural language processing, named entity recognition, knowledge graphs, and so on.\"\n\n## References\n\n- https://www.tandfonline.com/doi/full/10.1080/24750158.2018.1430453\n","n":0.18}}},{"i":5652,"$":{"0":{"v":"Practical Microservices with Dapr and Dotnet","n":0.408},"1":{"v":"\n- url: https://learning.oreilly.com/library/view/practical-microservices-with/9781803248127/\n\n\n## Ch. 2\n\n-   How do you scaffold debugging for Dapr in VS Code? \"Dapr Scaffold Tasks\"\n-   How do you compound the debug configuration for multiple Dapr projects? \"compounds\" in launch.json\n-   How do you attach to a running Dapr application with VS Code? \"VS Code Core Attach\" option\n-   How do you configure the Dapr components in Tye? \"tye init\" and adding the dapr extension to tye.yaml","n":0.122}}},{"i":5653,"$":{"0":{"v":"Practical Foundation of Modern Mathematics","n":0.447},"1":{"v":"\n- author: @paul-taylor","n":0.577}}},{"i":5654,"$":{"0":{"v":"Ontology Makes Sense","n":0.577},"1":{"v":"  \n- https://ebooks.iospress.nl/volume/ontology-makes-sense-essays-in-honor-of-nicola-guarino\n- https://drive.google.com/open?id=1-idA5TNhdWwxNYyA1-XY4RXrzzANd09Q&usp=drive_fs","n":0.577}}},{"i":5655,"$":{"0":{"v":"Processes Endure Whereas Events Occur","n":0.447},"1":{"v":"\n- https://philpapers.org/archive/KASPEW-2.pdf\n- keywords: [[c.ontology.events]] \n\n## Abstract\n\nIn this essay, we aim to help clarify the nature of so-called 'occurrences' by attributing distinct modes of existence and persistence to processes and events. In doing so, we break with the perdurantism claimed by DOLCE’s authors and we distance ourselves from mereological analyzes like those recently conducted by Guarino to distinguish between 'processes' and 'episodes'. In line with the works of Stout and Galton, we first bring closer (physical) processes and objects in their way of enduring by proposing for processes a notion of dynamic presence (contrasting with a static presence for objects). Then, on the events side, we attribute to them the status of abstract entities by identifying them with objects of thought (by individual and collective subjects), and this allows us to distinguish for themselves between existence and occurrence. We therefore identify them with psychological (or even social) endurants, which may contingently occur.\n\n## Highlights\n\n- traditionally, the event is conceived as a concrete particular \n- authors attribute to events the status of abstract entity by assimilating them to mental entities, even social entities\n  - the merit of such a conception is to distinguish between two too often confused notions that are the existence and the occurrence (in the sense of realization) of events\n\n### Basic Commitments\n\n- aim is to establish categories and notions that reflect the way in which we conceive the world\n  - in this, we join the orientation also retained by the authors of DOLCE. However, we will see later (Section 4) that the need to assign properties to 'non existant' entities will lead us, beyond a simple 'cognitive bias', to opt for an intentional ontology (or intensional by reference to intensional semantics).\n- adopting a contemporary perspective of ontology, we retain as the main mode of structuring the world three types of reality: physical, mental and social\n- This division of reality is based on the recognition of distinct modes of existence.\n  - t.2024.07.22.22 modalities seems to imply one or the other, but in principle you can have existentially multi-modal entities, like [[loc.fr.shadow-keep]] which has mental, social, and electronic/representational modes; more like mixins\n- invites us to track the border between facts and interpretation\n- According to Galton, this distinction corresponds to two perspectives of description of the world. \n- authors propose to see an opposition between the physical world and the mental and social worlds and, more precisely, to position events conceived as historical entities in the mental and social worlds\n  - i.e., interpretation\n  - \" the history of the world consists of how the world evolves over time; to appreciate changes, or on the contrary stabilities, requires the memory of observers; events are therefore psychological and social constructs.\"\n    - t.2024.07.23.11 or digital\n\n### 3. Our ontological framework (in a nutshell)\n\n- artifacts are physical objects endowed with a social life\n- examples of physical processes are: the movement of a physical object (leading to the displacement or rotation of the object on itself); the growth in size of a physical body; the life process of a person; the ripening of a fruit; oxidation of a ferrous metal object; the melting of a glacier.\n- the cause is part of the process, which process is the ‘engine’ of change\n  -  the change of a process can not itself be explained by a process, unless we create an infinite conceptual regression\n  -  a process is not a continuant floating in the air, but is 'anchored' in a support object which enacts it, aka behavior\n  - ","n":0.042}}},{"i":5656,"$":{"0":{"v":"Ontology Engineering with Ontology Design Patterns Foundations and Applications","n":0.333},"1":{"v":"\n- https://www.iospress.com/catalog/books/ontology-engineering-with-ontology-design-patterns-foundations-and-applications\n- ","n":0.707}}},{"i":5657,"$":{"0":{"v":"Ontology a Practical Guide","n":0.5},"1":{"v":"\n- author: @adam-pease\n\n## Chapter 2\n\n- concerned with knowledge representation languages that allow for deduction. \n  - schema are low-expressivity and low-formality, e.g. relational database, XML\n  - taxonomy are in the middle, e.g. RDF/S, UML, OWL\n  - Logical Theory are high, e.g. [[prdct.knowledge-interchange-format]] and [[prdct.tptp]] are the most expressive and most formal\n- \"every software system has an ontology\", it maybe just isn't made explicit\n- \"semantic networks\" is one of the earliest [[t.km.knowledge-representation]]\n- [[t.cs.object-orientation]] combine procedural specification with a small amount of declarative (e.g., classes, instances, class-subclass relations), i.e., the barest minimum\n- Frame languages lack a facility for expressing rules\n- [[t.km.description-logic]]\n\n### [[t.phil.logic.first-order-logic]] in [[prdct.suo-kif]]\n\n- no embedded formulas/propositions (only in higher-order logics)\n\n### Ontology Development Pitfalls\n\n- Confusing Instance and Subclass\n- Part-of vs. Subclass\n- \n\n### Modeling Events as Relations\n\n- don't do (eats Bill HamSandwich); \n  - presumably, model events as things unto themselves\n- \"Davisonian event representation\" looks a lot like what I was planning to do with hypergraphs\n- most languages that have some use in inference, like OWL, don't allow statements as arguments to relations, because it's extremely difficult to reason with.\n\n\n#### Example\n\n```json\n{\n  \"@id\": \"ex:Brutus-stabbed-Caesar\",\n  \"@type\": \"ont.occurence.\n}\n```\n- another reason to do kebab or snake case... preservation of capitalization (if you wanna go that route)\n\n### Ontological Promiscuity / Confusing Language and Concepts\n\n- terms need to be well-defined\n\n### Modelling Roles as Classes\n\n- yay, typedb\n\n### Modal vs Normative\n\n- can, may, should != obliged to, allowed to\n\n### Chapter 2 Exercises\n\n#### An elephant is a mammal\n\n(forall (?X)\n  (=>\n    (instance ?X Elephant)\n    (instance ?X Mammal)))\n\n#### Bob Likes Sue\n\n(likes Bob Sue)\n\n####  Koko is a gorilla\n\n(instance Koko Gorilla)\n\n#### Every farmer like a horse\n\n(forall (?X)\n  (=>\n    (instance ?X Farmer)\n    (exists (?Y)\n      (and \n        (likes ?X ?Y)\n        (instance ?Y Horse)))))\n\n\n## Chapter 3: Ontologies (in the broadest sense)\n\n- DOLCE universals are only employed in the service of describing particulars\n- SUMO is an ontology of both particulars and universals\n  - SUMO has a hierarchy of properties as well as classes ^79dmzjqovfhx","n":0.056}}},{"i":5658,"$":{"0":{"v":"Olivier De Clisson Connetable De France","n":0.408},"1":{"v":"\n- https://www.google.com/books/edition/Olivier_de_Clisson_Connetable_de_France/X_wsdkD9QzsC?hl=en&gbpv=0\n\n","n":0.707}}},{"i":5659,"$":{"0":{"v":"Object Role Modeling Workbook","n":0.5},"1":{"v":"\n\n- [[p.hasAuthor]] @terry-halpin\n","n":0.577}}},{"i":5660,"$":{"0":{"v":"Nothing Personal","n":0.707},"1":{"v":"\n- https://search.worldcat.org/title/9527856\n\n## Quotes\n\n- \"Four AM can be a devastating hour. The day, no matter what kind of day it was is indisputably over; almost instantaneously, a new day begins: and how will one bear it? Probably no better than one bore the day that is ending, possibly not as well. Moreover, a day is coming one will not recall, the last day of one’s life, and on that day one will oneself become as irrecoverable as all the days that have passed.\"\n- \"Sometimes, at four AM, this knowledge is almost enough to force a reconciliation between oneself and all one’s pain and error. Since, anyway, it will end one day, why not try it — life — one more time?\"\n\n\n## References\n\n- [[ar.the-marginalian.james-baldwin-nothing-personal-4-am]]","n":0.091}}},{"i":5661,"$":{"0":{"v":"Mysteries of Police and Crime","n":0.447},"1":{"v":"\n- author: [[user.arthur-griffth]]","n":0.577}}},{"i":5662,"$":{"0":{"v":"Multi Agent Oriented Programming","n":0.5},"1":{"v":"\n- https://mitpress.mit.edu/9780262044578/multi-agent-oriented-programming/\n- published: 2020\n- newer-than: [[ar.multi-agent-oriented-programming-the-ja-ca-mo-platform]]","n":0.408}}},{"i":5663,"$":{"0":{"v":"Microsoft Orleans for Developers","n":0.5},"1":{"v":"\n- url: https://learning.oreilly.com/library/view/microsoft-orleans-for/9781484281673/\n","n":0.577}}},{"i":5664,"$":{"0":{"v":"Make Something Wonderful","n":0.577},"1":{"v":"\n- url: https://book.stevejobsarchive.com/\n\n\n## Highlights\n\n- \"In most cases, strengths and weaknesses are two sides of the same coin. A strength in one situation is a weakness in another, yet often the person can’t switch gears. It’s a very subtle thing to talk about strengths and weaknesses because almost always they’re the same thing.\"\n- \"My strength probably is that I’ve always viewed technology from a liberal arts perspective, from a human culture perspective.\"\n- \"it’s very hard to get people motivated to make a breakfast cereal.\"\n- “You’ve got to choose what you put your love into really carefully,”\n  - Yeah, but better to have loved...\n  - ","n":0.099}}},{"i":5665,"$":{"0":{"v":"Lonesome Dove","n":0.707},"1":{"v":"\n- author: @larry-mcmurtry\n\n## Highlights\n\n### Pigs Walking\n\n  “Why, they’re the first pigs to walk all the way from Texas to Montana,” Augustus said. “That’s quite a feat for a pig.” \n\n  “What will it get them?” Call inquired. “Eaten by a bear if they ain’t careful, or eaten by us if they are. They’ve had a long walk for nothing.”\n\n  “Yes, and the same’s likely true for us,” Augustus said, irritated that his friend wasn’t more appreciative of pigs.","n":0.113}}},{"i":5666,"$":{"0":{"v":"Knowledge Representation","n":0.707}}},{"i":5667,"$":{"0":{"v":"Influence, the Psychology of Persuasion","n":0.447},"1":{"v":"\n \r\n- [[p.recommendedBy]] Amazon CTO\r\n \n","n":0.408}}},{"i":5668,"$":{"0":{"v":"Implementing Domain Driven Design","n":0.5},"1":{"v":"\n- [[p.hasAuthor]] @vaughn-vernon\n- [[p.hasTopic]] [[t.cs.sd.domain-driven-design]]","n":0.447}}},{"i":5669,"$":{"0":{"v":"Hypermedia Systems","n":0.707},"1":{"v":"\n- https://hypermedia.systems/\n- mentions: [[prdct.hyperview]]","n":0.5}}},{"i":5670,"$":{"0":{"v":"How to Take Smart Notes","n":0.447},"1":{"v":"\n\n- [[p.hasAuthor]] @sönke-ahrens\n\n","n":0.577}}},{"i":5671,"$":{"0":{"v":"Hopscotch","n":1},"1":{"v":"\n\n\n- [[p.isRelated]] https://en.wikipedia.org/wiki/Hopscotch_(Cort%C3%A1zar_novel)#%22Table_of_Instructions%22_and_structure\n","n":0.577}}},{"i":5672,"$":{"0":{"v":"Homotopy Type Theory","n":0.577},"1":{"v":"\n- url: https://homotopytypetheory.org/book/","n":0.577}}},{"i":5673,"$":{"0":{"v":"Hands on Rust","n":0.577},"1":{"v":"\n- url: https://learning.oreilly.com/library/view/hands-on-rust/9781680508796/\n\n## Notes\n\n- ","n":0.5}}},{"i":5674,"$":{"0":{"v":"Handbook of Semantic Web Technologies","n":0.447}}},{"i":5675,"$":{"0":{"v":"Hamlet on the Holodeck","n":0.5},"1":{"v":"\n- author: @janet-murray\n\n\n## References\n\n- [[ar.newyorker.hamlet-on-the-holodeck-twenty-years-later]]","n":0.447}}},{"i":5676,"$":{"0":{"v":"Going the Distance with Babylonjs","n":0.447},"1":{"v":"\n\nurl: https://learning.oreilly.com/library/view/going-the-distance/9781801076586/\n\n- resources:  [[game.space-truckers]]\n\n## Resources","n":0.447}}},{"i":5677,"$":{"0":{"v":"Game Programming Patterns","n":0.577},"1":{"v":"\n- url: https://gameprogrammingpatterns.com","n":0.577}}},{"i":5678,"$":{"0":{"v":"Fundamentals of Adventure Game Design","n":0.447},"1":{"v":"\n## Highlights\n\nMany adventure game purists don’t care for action-adventures; generally, they dislike any sort of physical challenge or time pressure. If you plan to make your game an action-adventure, you should be aware that, although your design might appeal to some action gamers who might not otherwise buy your game, you might also discourage some adventure gamers who would. Without doubt, however, action-adventure hybrids are now more popular than traditional adventure games.\nAt first glance, the lack of replayability seems the greatest disadvantage of adventure games. Most adventure games consist of a sequence of puzzles, each of which has a single solution; when you know the solution, there’s not much challenge in playing it again. An adventure game that requires 40 hours to finish the first time might take only 4 hours the second time.\n\nAt first glance, the lack of replayability seems the greatest disadvantage of adventure games. Most adventure games consist of a sequence of puzzles, each of which has a single solution; when you know the solution, there’s not much challenge in playing it again. An adventure game that requires 40 hours to finish the first time might take only 4 hours the second time.\n\nTo ameliorate this problem, consider making puzzle sequences or challenges that allow the player a choice of solutions. The consequences of the player’s choices can affect not only the game she is playing but also the story itself. The player who chooses to blow up the gate blocking her way might accidentally hurt someone in the process and be chased out of town. The player who needs a specific key might have to steal it and be chased because she’s a thief. Offering alternative solutions adds to the replayability of the game. Adventure game puzzle design and challenges are discussed later in this e-book.\n\nIn practice, however, replayability isn’t much of a problem. Research shows that a great many players never finish these games at all;\n\ndave\nBecause much of the entertainment of an adventure game comes from seeing the avatar explore the world and interact with other characters, the first-person perspective doesn’t offer as many opportunities for visual drama as other perspectives do.\nAs adventure games became larger and began to include a more detailed story, designers started to break them into chapters (see Figure 6). The player could wander around all he liked in the area devoted to a given chapter, but when he moved on to the next chapter, the story advanced and there was no way back\nIn a foldback story, the player has some dramatic freedom, but eventually his options narrow to a single inevitable event before they branch out again. In adventure games, this inevitable event is normally the transition to the next chapter\nShow, don’t tell. Set the mood and amplify the tension in your story using music, well-chosen color palettes, camera angles, lighting, and architecture. Never say that something is scary, make it scary.\nPuzzles present small, individual problems. Your story needs a larger problem that underpins the whole story—something that, even if it isn’t revealed to the player at the beginning of the game, is the reason that there is a story.\nYou can imagine adventure games structured along other lines but will find few on the market that don’t adhere to the heroic quest scenario. It’s possible to write an adventure game that is chiefly about the personalities of the characters (as in Jane Austen’s novels, for example), but they are not the norm.\nOccasionally exceptions to this structure arise, such as in stories in which the hero is abducted at the beginning, escapes, and must return to his home. However, in these stories, the protagonist’s struggles don’t get easier and easier until he just strolls in happily. He often returns home to find that things have changed for the worse and must be corrected, or that he must leave again to hunt down his abductor.\nNowadays, most adventure games adopt a “fair warning” approach, making it clear when an object or action threatens danger and (usually) offering a way of neutralizing or circumventing that danger. If you put a dragon in a cave, it’s a nice touch to litter the entrance with the bones of earlier adventurers.\nUnderstanding personal relationships. The challenges of understanding and perhaps influencing the relationships between people make up a little-explored aspect of adventure game design. Most adventure games limit characters to very simple, mechanical states of mind. If we devote a little more effort, people, rather than objects, could become the primary subject of adventure games, and this would make the\nit’s still a good idea to give the player a map. A few games deliberately deny the player a map to make the game more difficult, but this is poor design. There’s not a lot of fun in being lost. If you force the player to make his own map, he has to constantly look away from the screen to a sketchpad at his side; that’s a tedious business that rapidly destroys suspension of disbelief.\nAutomapping destroys the challenge imposed by mazes, but mazes are one of the most overused and least-enjoyed features of adventure games.\nthe journal gives you an opportunity to define the avatar’s character through his use of language. Journals are ideal for games in which the player must collect informational clues, such as mysteries in the Nancy Drew series.\nThe point-and-click interface is an indirect control mechanism and was for many years the de facto standard for adventure games. It makes the player feel as if the avatar is a person separate from himself rather than a puppet whose every movement is directly controlled, and this contributes to the depth of the character\ndave\nFirst the player clicks, then the avatar walks—if she can; if she can’t, she will usually say so aloud. It works well in traditional adventure games with no action challenges. However, because traditional adventures are increasingly rare and action-adventure hybrids have become more common, the point-and-click interface is gradually being replaced by direct control interfaces.\nIf the game requires the player to move repeatedly through areas he already knows well, the player may find watching the avatar walk deliberately from place to place boring. On the other hand, if you offer a rich, detailed world and your game expects the player to examine everything closely for clues, the user interface must make slow and accurate movement possible.\nDynamically highlighted objects. The active objects in a scene normally look like part of the background but appear highlighted when the mouse cursor passes over them. You can, for example, change the shape of the mouse cursor, have the object light up, or have the object’s name appear momentarily. It still requires the player to do some hunting, but hunting is much easier than hunting and clicking; a quick wave of the cursor tells the player if there’s an active object nearby.\nAvatar-focused highlighting. This mechanism is typically used with handheld controllers when the player doesn’t have a cursor. As the avatar moves around, active objects that he comes near to are highlighted. When he moves away, this highlighting disappears. A related form is focus-of-attention highlighting, in which the avatar must face the object, as if paying attention to it.\nA number of games use a menu to allow the player to select which action to take and which object to manipulate. This gives the player a clear picture of available choices, but the presence of the menu does harm the player’s sense of immersion somewhat. Locating the menu outside the main view of the scene will help with this somewhat, or you can use pop-up menus that appear only when needed (see Figure 8). The player clicks one of the items to perform the desired action. This mechanism in effect shows the player all the available verbs that can be used at a particular time and lets him choose one","n":0.028}}},{"i":5679,"$":{"0":{"v":"Functional and Reactive Domain Modeling","n":0.447},"1":{"v":"\n- author: @debasish-ghosh","n":0.577}}},{"i":5680,"$":{"0":{"v":"Foundations of Semantic Web Technologies","n":0.447},"1":{"v":"\n- https://www.semantic-web-book.org/\n- https://learning.oreilly.com/library/view/foundations-of-semantic/9781420090512/\n- publish-date: 2009\n- authors: @pascal-hitzler\n\n\n## Highlights\n\n\n### Chapter 6: Ontologies and Rules\n\n...the difference between rules and ontologies is not merely pedagogical. In the cases we consider, rules typically can help to express knowledge that cannot be formulated in RDFS or OWL. At the same time, there are also various features of OWL that rule languages do not provide, so a natural question to ask is how the strengths of OWL and of rules can be combined. It turns out that this is indeed possible, but that the added power often also comes at the price of higher complexity and more difficult implementation. The rule languages discussed in this chapter have therefore been chosen to be the ones for which a combination with RDF and OWL is not just possible in principle, but for which this combination is also practically supported by software tools and, in some cases, by upcoming standards.\n\n- How can datalog and OWL be combined?\n  - [[prdct.swrl]]\n\n## References\n\n- https://www.semantic-web-book.org/w/images/5/5e/KI09-OWL-Rules-2.pdf","n":0.079}}},{"i":5681,"$":{"0":{"v":"Forgotten Realms Campaign Set","n":0.5},"1":{"v":"\n- url: https://willmaranto.typepad.com/TSR%201031%20Forgotten%20Realms%20Campaign%20Setting%201st%20Edition.pdf","n":0.577}}},{"i":5682,"$":{"0":{"v":"Flatland","n":1},"1":{"v":"\n- author: [[user.edwin-abbott]]\n- published: 1884\n\n![](/assets/images/2024-09-29-17-06-03.png)","n":0.447}}},{"i":5683,"$":{"0":{"v":"Finite and Infinite Games","n":0.5},"1":{"v":"\n\n- #summary https://www.notion.so/Finite-and-Infinite-Games-by-James-P-Carse-5d7cfbbc8f4841c593dc596bcaf7a30a\n","n":0.577}}},{"i":5684,"$":{"0":{"v":"Fiction and Metaphysics","n":0.577},"1":{"v":"\n- author: [[user.amie-thomasson]]\n\n\n## References\n\n- [[ar.towards-a-semantics-for-the-artifactual-theory-of-fiction-and-beyond]]","n":0.447}}},{"i":5685,"$":{"0":{"v":"Fear and Loathing","n":0.577}}},{"i":5686,"$":{"0":{"v":"Embedding Knowledge Graphs with Rd F2vec","n":0.408},"1":{"v":"\n- http://rdf2vec.org/book/\n\n## Summary\n\nThe book explains the ideas behind one of the most well-known methods for knowledge graph embedding of transformations to compute vector representations from a graph, known as RDF2vec. The authors describe its usage in practice, from reusing pre-trained knowledge graph embeddings to training tailored vectors for a knowledge graph at hand. They also demonstrate different extensions of RDF2vec and how they affect not only the downstream performance, but also the expressivity of the resulting vector representation, and analyze the resulting vector spaces and the semantic properties they encode.","n":0.105}}},{"i":5687,"$":{"0":{"v":"Efficient Node.js a beyond the Basics Guide","n":0.378},"1":{"v":"\n- [[p.hasAuthor]] @samer-buna\n- [[p.hasRepository]] https://github.com/samerbuna/efficient-node","n":0.447}}},{"i":5688,"$":{"0":{"v":"Domain Specific Languges","n":0.577},"1":{"v":"\n- author: \n\n## Chapter 1. Using Modeling Languages\n\n- [[p.mentioned]] [[prdct.osbp]]","n":0.316}}},{"i":5689,"$":{"0":{"v":"Domain Modeling Made Functional","n":0.5},"1":{"v":"\n- https://pragprog.com/titles/swdddf/domain-modeling-made-functional/\n- topics: [[t.cs.languages.f-sharp]]","n":0.5}}},{"i":5690,"$":{"0":{"v":"Domain Driven Design Tackling Complexity in the Heart of Software","n":0.316},"1":{"v":"\n- #aka the Blue Book\n- [[p.hasAuthor]] @eric-evans","n":0.378}}},{"i":5691,"$":{"0":{"v":"Distributed Simulation","n":0.707},"1":{"v":"\n- [[p.hasAuthor]] Okan Topçu, Umut Durak, Halit Oğuztüzün, and Levent Yilmaz","n":0.302}}},{"i":5692,"$":{"0":{"v":"Discrete Event Simulation Engineering","n":0.5},"1":{"v":"\n- https://sim4edu.com/reading/des-engineering/\n- author: @gerd-wagner","n":0.5}}},{"i":5693,"$":{"0":{"v":"Digital Zettelkasten Principles Methods Examples","n":0.447},"1":{"v":"\n\r\nshort book outlining the author's pragmatic [[t.km.zettelkasten]] process. Includes an interesting take on tags.\r\n\r\n- [[p.hasURL]] https://kadavy.net/blog/posts/zettelkasten-method-slip-box-digital-example/\r\n- [[p.hasCreator]] @david-kadavy\r\n- [[p.hasHighlightCollection]] https://readwise.io/bookreview/10829260\r\n## Highlights\r\n\r\n- [[idea.beware-archivism]]\r\n- The activities involved in managing [your zettelkasten] also help solidify your memory, so it needs less jogging in the first place... Search engines and the internet are not a substitute for your notes. Your notes contain more than just simple facts, managing your notes builds your memory, and your notes help you store and develop ideas in-progress.\r\n- \r\n\r\n## [[p.hasCitation]]\r\n\r\n- \"The archivist asks: Which keyword is the most fitting? A writer asks: In which circumstances will I want to stumble upon this note, even if I forget about it?\" [[book.how-to-take-smart-notes]]\r\n","n":0.095}}},{"i":5694,"$":{"0":{"v":"Developing Time Oriented Database Applications in SQL","n":0.378}}},{"i":5695,"$":{"0":{"v":"Developing High Quality Data Models","n":0.447},"1":{"v":"\n- https://learning.oreilly.com/library/view/developing-high-quality/9780123751065/\n- mentions: [[t.cs.sd.modeling.spacetime-diagrams]]\n- related: [[prdct.hqdm-framework]]\n- author: @matthew-west\n- uses: [[prdct.express-modelling-language]]\n\n\n## Issues\n\n- \"So, although we may use a screwdriver to open a tin of paint, it does not thereby become a paint-tin-opener, it remains a screwdriver because that is its intended purpose. Equally, if a screwdriver is never actually used to drive screws, it is still a screwdriver.\"\n  - to a painter, it's a paint-tin-opener except we need a common name, which is based on primary purpose, or historical reasons, or because the word sounds cool\n  - admittedly, \"At what point did it stop being simply a stone on a beach and become a paperweight? That is, when did the paperweight, which is a state of the stone, start? In this case it is actually the act of deciding it was a paperweight that made it one. So a state of a stone is a paperweight because someone (anyone) said so, and while they said so. There are, however, limits to the power of will. If I decide that the Empire State Building would make a nice paperweight, it does not become one simply by my act of will, so the object needs to be fit for purpose as well.\"\n  - \"Although the stone becoming a paperweight is a simple act of will, most functional objects acquire their function by being made or at least shaped to provide features to meet their intended purpose.\"\n\n## Highlights\n\n- ","n":0.065}}},{"i":5696,"$":{"0":{"v":"Developers Guide to the Semantic Web","n":0.408},"1":{"v":"\n- url: \n  - http://b3.stmik-banjarbaru.ac.id/data.bc/20.%20Semantic%20Web/2011%20A_Developers_Guide_to_the_Semantic_Web.pdf\n  - ","n":0.408}}},{"i":5697,"$":{"0":{"v":"Designing Event Driven Systems","n":0.5},"1":{"v":"\n- https://learning.oreilly.com/library/view/designing-event-driven-systems/9781492038252/\n- topics: [[prdct.kafka]]\n- publication-date: 2018.05","n":0.408}}},{"i":5698,"$":{"0":{"v":"Designing Data Intensive Applications","n":0.5},"1":{"v":"\n- author: @martin-kleppmann\n- url: https://learning.oreilly.com/library/view/designing-data-intensive-applications/9781491903063\n\n## Chapter 2: Data models and Query Languages\n\n- \"For a data structure like a résumé, which is mostly a self-contained document, a JSON representation can be quite appropriate\"\n- Graph-like data models: \n  - [[p.mentioned]] [[prdct.infintegraph]]","n":0.16}}},{"i":5699,"$":{"0":{"v":"Design and Implementation of Ontologies in Java and Apache Jena","n":0.316},"1":{"v":"\n- url https://www.amazon.com/DESIGN-IMPLEMENTATION-ONTOLOGIES-JAVA-APACHE/dp/6203402400?asin=6203402400&revisionId=&format=4&depth=1","n":0.577}}},{"i":5700,"$":{"0":{"v":"Demystifying Owl for the Enterprise","n":0.447},"1":{"v":"\n- author @michael-uschold\n- similar: [[book.semantic-modeling-for-data]]","n":0.447}}},{"i":5701,"$":{"0":{"v":"Dave Arnesons True Genius","n":0.5},"1":{"v":"\n- author: @rob-kuntz","n":0.577}}},{"i":5702,"$":{"0":{"v":"C# 11 and .NET 7 – Modern Cross-Platform Development Fundamentals","n":0.316},"1":{"v":"\n- repo:  https://github.com/markjprice/cs11dotnet7\n- author: @mark-price\n","n":0.447}}},{"i":5703,"$":{"0":{"v":"Crucial Conversations","n":0.707},"1":{"v":"\n\n- \"Facebook sends everybody through that training\"\n","n":0.378}}},{"i":5704,"$":{"0":{"v":"C Sharp in Depth","n":0.5},"1":{"v":"\n- url: https://learning.oreilly.com/library/view/c-in-depth/9781617294532/OEBPS/Text/kindle_split_015_split_000.html","n":0.577}}},{"i":5705,"$":{"0":{"v":"Building Tools with Githu","n":0.5},"1":{"v":"\nurl: https://learning.oreilly.com/library/view/building-tools-with/9781491933497/\n#created 2016\n## Highlights\n\n- https://learning.oreilly.com/library/view/building-tools-with/9781491933497/ch09.html#idm139713921554848\n  - If we look at the [GitHub.js JavaScript documentation on GitHub](https://github.com/michael/github) we can see that there are some options for us to pull content from a repository.\n  - [[prdct.github-js]]","n":0.171}}},{"i":5706,"$":{"0":{"v":"Building Ontologies with Basic Formal Ontology","n":0.408},"1":{"v":"\n- [[p.similarTo]] [[book.semantic-web-for-the-working-ontologist]] \n- url: https://direct.mit.edu/books/book/4044/Building-Ontologies-with-Basic-Formal-Ontology","n":0.408}}},{"i":5707,"$":{"0":{"v":"Blue Movie","n":0.707}}},{"i":5708,"$":{"0":{"v":"Bitemporal Data Theory and Practice","n":0.447},"1":{"v":"\n\n- author: @tom-johnson\n- url: https://www.google.com/books/edition/Bitemporal_Data/tF5zAwAAQBAJ?hl=en&gbpv=1&pg=PR3&printsec=frontcover","n":0.447}}},{"i":5709,"$":{"0":{"v":"Behavioral Mathematics for Game Ai","n":0.447},"1":{"v":"\n- url: https://archive.org/details/behavioralmathem0000mark/page/n3/mode/2up\n- ","n":0.577}}},{"i":5710,"$":{"0":{"v":"Atomic Habits","n":0.707},"1":{"v":"\n\r\n\r\n- [[p.hasURL]] https://jamesclear.com/atomic-habits\r\n- [[p.isRelated]] [[course.sunsama.atomic-habits]]\r\n- [[p.hasSample]] https://s3.amazonaws.com/jamesclear/Atomic+Habits/Atomic_Habits_-_Chapter_1_Excerpt.pdf\r\n## Highlights\r\n\r\n- 1% better/day = 3700% better/year\r\n  - but of course, improvement isn't unlimited\r\n- breakthrough moments can happen because the groundwork is in place\r\n  - [[p.hasMetaphor]] \r\n    - Plateau of Latent Potential ![](/assets/images/2021-11-04-14-57-10.png)\r\n    - geological  pressure\r\n  - [[p.hasExample]]\r\n    - Cancer spends 80 percent of its life undetectable, then takes over the body in months. \r\n    - Bamboo can barely be seen for the first five years as it builds extensive root systems under‑ground before exploding ninety feet into the air within six weeks.\r\n\r\n","n":0.106}}},{"i":5711,"$":{"0":{"v":"Art of the Start","n":0.5},"1":{"v":"\n- author: @guy-kawasaki\n\n## Highlights\n\n- \"doing, not learning to do, is the essence of entrepreneurship\"","n":0.267}}},{"i":5712,"$":{"0":{"v":"Apple IIe Applesoft Tutorial","n":0.5},"1":{"v":"\n- https://www.scribd.com/document/49275369/Apple-IIe-Applesoft-Tutorial\n- ","n":0.707}}},{"i":5713,"$":{"0":{"v":"An Introduction to Ontology Engineering Keet","n":0.408},"1":{"v":"\n- url: https://eng.libretexts.org/Bookshelves/Computer_Science/Programming_and_Computation_Fundamentals/An_Introduction_to_Ontology_Engineering_(Keet)/\n- https://people.cs.uct.ac.za/~mkeet/files/OEbook.pdf\n- author: @maria-keet\n- related: [[prdct.onset]]\n\n## Highlights\n\n- if one indeed aims for the purposes of interoperability and reusability across applications by means of an ontology, then don’t use data properties and data types.\n  - The idea is to generalize (more precisely: reify) the attribute into a class so that we can reuse the core notion that is the same throughout (Color and Weight in the examples), and this new entity is then related to the endurants and perdurants on the one side and instead of datatypes, we use value regions on the other side. Thus, an unfolding from one attribute/OWL data property into at least two properties: there is one OWL object property from the endurant/perdurant to the reified attribute—a quality property, represented as an OWL class—and a second object property from quality to the value region. In this way, the shared understanding can be shared, and any specifics on how one has to store the data is relegated to the implementation, therewith solving the problem of the limited reusability of attributes and preventing duplication of data properties. For instance, Color would be a subclass of Quality in DOLCE [MBG+03] and a Specifically dependent continuant in BFO. An example of the approach taken in DOLCE is depicted in Figure 6.1.2: rose1 is an instance of Rose, which is a subclass of NonAgentive Physical Object, and it is related by the qt relation to its colour property, c1, which is an instance of the quality Color that is a subclass of Physical Quality. The actual value—the [measured] redness—of the color of the rose at a given time is a region red color as instance of the Color Region, which is a subclass of Physical Region, and they are related by means of the q|t relation4.\n\n### Using Perdurant/Occurent objects instead of property-verbs\n\n- results in a more compact representation, is intuitively closer to the domain expert’s understanding, and makes it easier to verbalize the ontology, and therefore is likely to be more useful in praxis. The Running option is more generic, and thereby likely to increase reusability of the ontology. No scientific experiments have been conducted to test which way would be better to represent such knowledge, and current mapping tools do not deal with such differences of representing roughly the same knowledge in syntactically very different ways. Theoretical foundations for mappings between such distinct modeling styles have been proposed [^FK17], and this may be resolved soon.\n\n### Time and Temporal Ontologies\n\n- There are multiple requests for including a temporal dimension in OWL. Some of those requirements are described in the ontology’s annotation fields (see the OWL files of BFO and DOLCE), or the labels of the object properties in the BFO v2.1 draft, where they mention temporality that cannot be represented formally in OWL: ^k691d5r7ug82\n  - DOLCE has a temporally indexed parthood in the paper-based version but this could not be transferred into the OWL file.\n- there is no single computational solution to solve these examples all at once in another way beyond OWL. Thus far, it is a bit of a patchwork of various theo- ries and some technologies, with, among many aspects, the [[Allen’s interval algebra|t.cs.time.allens-interval-algebra]] with the core qualitative temporal relations (such as before and during), [[Linear Temporal Logics|prdct.ltl-linear-temporal-logics]] (LTL) and Computational Tree Logics (CTL, with branch- ing time). \n  - some might say [[t.cs.time.allens-interval-algebra]] are all the temporal relations one will ever need, but one may wish to be more specific in specialised subject domains, such as a transformation of a caterpillar into a butterfly, not just that a butterfly was a caterpillar ‘before’, and one thing developed from another thing in developmental biology.\n- Modellers want to do even more than that: temporalising classes and relations. The former is well-known in databases as ‘object migration’; e.g., an active project evolves to a completed project, and each divorcee in the census database must have been married before. Relation migration follows the idea of temporal classes, but applies to n-ary tuples (with n ≥ 2); e.g. ‘during x’s lifetime, it always has y as part’ and ‘every passenger that boards the plane must have checked in before departure of that flight’.\n\n\n#### Temporal DLs\n\n- A very expressive (undecidable) DL language is [[prdct.dlrus]] (with the Until and Since operators), which already has been used for temporal conceptual data modelling [APS07] and for representing essential and immutable parts and wholes [AGK08], which also solves the Boxer example of Section 6.2. It uses linear time and mostly qualitative temporal constraints.\n- [[ar.temporal-representation-and-reasoning-in-owl-2]]\n\n\n## References\n\n[^FK17]: [FK17] Pablo R. Fillottrani and C. Maria Keet. Patterns for heterogeneous tbox mappings to bridge different modelling decisions. In E. Blomqvist et al., editors, Proceeding of the 14th Extended Semantic Web Conference (ESWC’17), volume 10249 of LNCS, pages 371–386. Springer, 2017. 30 May - 1 June 2017, Portoroz, Slovenia.\n- \n","n":0.035}}},{"i":5714,"$":{"0":{"v":"Agents Simulation and Applica","n":0.5},"1":{"v":"\n\n## Chatpers\n\n- 1. [[ar.stigmergic-cues-and-their-uses-in-coordination-an-evolutionary-approach]]","n":0.5}}},{"i":5715,"$":{"0":{"v":"Agent Oriented Constructivist Knowledge Management","n":0.447},"1":{"v":"\n- https://ris.utwente.nl/ws/portalfiles/portal/6042098/r_guizzardi.pdf\n- topics: [[prdct.kare]]\n- publish-date: 2006\n\n## Abstract\n\nIn Ancient Times, when written language was introduced, books and manuscripts were often considered sacred. During these times, only a few persons were able to read and interpret them, while most people were limited in accepting these interpretations. Then, along with the industrial revolution of the XVIII and XIX centuries and especially boosted by the development of the press, knowledge slowly became available to all people. Simultaneously, people were starting to apply machines in the development of their work, usually characterized by repetitive processes, and especially focused in the production of consuming goods, such as furniture, clocks, clothes and so on. Following the needs of this new society, it was finally through science that new processes emerged to enable the transmission of knowledge from books and instructors to learners. Still today, people gain knowledge based on these processes, created to fulfill the needs of a society in its early stages of industrialization, thus not being compatible with the needs of the information society. In the information society, people must deal with an overloading amount of information, by the means of the media, books, besides different telecommunication and information systems technology. Furthermore, people’s relation to work has been influenced by profound changes, for instance, knowledge itself is now regarded as a valuable work product and, thus, the workplace has become an environment of knowledge creation and learning. Modifications in the world economical, political and social scenarios led to the conclusion that knowledge is the differential that can lead to innovation and, consequently, save organizations, societies, and even countries from failing in achieving their main goals. Focusing on these matters is the Knowledge Management (KM) research area, which deals with the creation, integration and use of knowledge, aiming at improving the performance of individuals and organizations. Advances in this field are mainly motivated by the assumption that organizations should focus on knowledge assets (generally maintained by the members of an organization) to remain competitive in the information society’s market. This thesis argues that KM initiatives should be targeted based on a constructivist perspective. In general, a constructivist view on KM focuses on how knowledge emerges, giving great importance to the knowledge holders and their natural practices. With the paragraph above, the reader may already have an intuition of how this work faces and targets Knowledge Management, however, let us be more precise. Research in Knowledge Management has evolved substantially in the past 30 years, coming from a centralized view of KM processes to a distributed view, grounded in organizational and cognitive sciences studies that point out the social, distributed, and subjective nature of knowledge. The first Knowledge Management Systems (KMSs) were centrally based and followed a top-down design approach. The organization managers, supported by knowledge engineers, collected and structured the contents of an organizational memory as a finished product at design time (before the organizational memory was deployed) and then disseminated the product, expecting employees to use it and update it. However, employees often claimed that the knowledge stored in the repository was detached from their real working practices. This led to the development of evolutionary methods, which prescribe that the basic KM system is initially developed and evolves proactively in an on-going fashion. However, most of the initiatives are still based on building central repositories and portals, which assume standardized vocabularies, languages, and classification schemes. Consequently, employees’ lack of trust and motivation often lead to dissatisfaction. In other words, workers resist on sharing knowledge, since they do not know who is going to access it and what is going to be done with it. Moreover, the importance attributed to knowledge may give an impression that these central systems take away a valuable asset from his or her owner, without giving appreciable benefits in return. The problems highlighted in the previous paragraph may be attenuated or even solved if a top-down/bottom-up strategy is applied when proposing a KM solution. This means that the solution should be sought with aim at organizational goals (top-down) but at the same time, more attention should be given to the knowledge holders and on the natural processes they already use to share knowledge (bottom-up). Being active agency such an important principle of Constructivism, this work recognizes that the Agent Paradigm (first defined by Artificial Intelligence and more recently adopted by Software Engineering) is the best approach to target Knowledge Management, taking a technological and social perspective. Capable of modeling and supporting social environments, agents is here recognized as a suitable solution for Knowledge Management especially by providing a suitable metaphor used for modeling KM domains (i.e. representing humans and organizations) and systems. Applying agents as metaphors on KM is mainly motivated by the definition of agents as cognitive beings having characteristics that resemble human cognition, such as autonomy, reactivity, goals, beliefs, desires, and social-ability. Using agents as human abstractions is motivated by the fact that, for specific problems, such as software engineering and knowledge management process modeling, agents may aid the analyst to abstract away from some of the problems related to human complexity, and focus on the important issues that impact the specific goals, beliefs and tasks of agents of the domain. This often leads to a clear understanding of the current situation, which is essential for the proposal of an appropriate solution. The current situation may be understood by modeling at the same time the overall goals of the organization, and the needs and wants of knowledge holders. Towards facilitating the analysis of KM scenarios and the development of adequate solutions, this work proposes ARKnowD (Agent-oriented Recipe for Knowledge Management Systems Development). Systems here have a broad definition, comprehending both technology-based systems (e.g. information system, groupware, repositories) and/or human systems, i.e. human processes supporting KM using non-computational artifacts (e.g. brain stormings, creativity workshops). The basic philosophical assumptions behind ARKnowD are: a) the interactions between human and system should be understood according to the constructivist principle of self-construction, claiming that humans and communities are self-organizing entities that constantly construct their identities and evolve throughout endless interaction cycles. As a result of such interactions, humans shape systems and, at the same time, systems constrain the ways humans act and change; b) KM enabling systems should be built in a bottom-up approach, aiming at the organizational goals, but understanding that in order to fulfill these goals, some personal needs and wants of the knowledge holders (i.e. the organizational members) need to be targeted; and c) there is no “silver bullet��? when pursuing a KM tailoring methodology and the best approach is combining existing agent-oriented approaches according to the given domain or situation. This work shows how the principles above may be achieved by the integration of two existing work on agent-oriented software engineering, which are combined to guide KM analysts and system developers when conceiving KM solutions. Innovation in our work is achieved by supporting topdown/bottom-up approaches to KM as mentioned above. The proposed methodology does that by strongly emphasizing the earlier phases of software development, the so-called requirement analysis activity. In this way, we consider all stakeholders (organizations and humans) as agents in our analysis model, and start by understanding their relations before actually thinking of developing a system. Perhaps the problem may be more effectively solved by proposing changes in the business processes, rather than by making use of new technology. And besides, in addition to humans and organizations, existing systems are also included in the model from start, helping the analyst and designer to understand which functionalities are delegated to these so-called artificial agents. In addition to that, benefits as a result of the application of ARKnowD may be also attributed to our choice of using the proper agent cognitive characteristics in the different phases of the development cycle. With the main purpose of exemplifying the use of the proposed methodology, this work presents a socially-aware recommender agent named KARe (Knowledgeable Agent for Recommendations). Recommender Systems may be defined by those that support users in selecting items of their need from a big set of items, helping users to overcome the overwhelming feeling when facing a vast information source, such as the web, an organizational repository or the like. Besides serving as a case for our methodology, this work also aims at exploring the suitability of the KARe system to support KM processes. Our choice for supporting knowledge sharing through questioning and answering processes is again supported by Constructivism proponents, who understand that social interaction is vital for active knowledge building. This assumption is also defended by some KM theories, claiming that knowledge is created through cycles of transformation between two types of knowledge: tacit and explicit knowledge. Up to now, research on KM has paid much attention to the formalization and exchange of explicit knowledge, in the form of documents or other physical artifacts, often annotated with metadata, and classified by taxonomies or ontologies. Investigations surrounding tacit knowledge have been so far scarce, perhaps by the complexity of the tasks of capturing and integrating such kind of knowledge, defined as knowledge about personal experience and values, usually confined on people’s mind. Taking a flexible approach on supporting this kind of knowledge conversion, KARe relies on the potential of social interaction underlying organizational practices to support knowledge creation and sharing. The global objective of this work is to support knowledge creation and sharing within an organization, according to its own natural processes and social behaviors. In other words, this work is based on the assumption that KM is better supported if knowledge is looked at from a constructivist perspective. To sum up, this thesis aims at: 1) Providing an agent-oriented approach to guide the creation and evolvement of KM initiatives, by analyzing the organizational potentials, behaviors and processes concerning knowledge sharing; 2) Developing the KARe recommender system, based on a semantically enriched Information Retrieval technique for recommending knowledge artifacts, supporting users to ask and answer to each others’ questions. These objectives are achieved as follows: - Defining the principles that characterize a Constructivist KM supporting environment and understanding how they may be used to support the creation of more effective KM solutions; - Providing an agent-oriented approach to develop KM systems. This approach is based on the integration of two different agent-oriented software engineering works, profiting from their strengths in providing a comprehensive methodology that targets both analysis and design activities; - Proposing and designing a socially aware agent-oriented recommender system both to exemplify the application of the proposed approach and to explore its potential on supporting knowledge creation and sharing. - Implementing an Information Retrieval algorithm to support the previously mentioned system in generating recommendations. Besides describing the algorithm, this thesis brings experimental results to prove its effectiveness.","n":0.024}}},{"i":5716,"$":{"0":{"v":"Action Semantics","n":0.707},"1":{"v":"\n- author: @peter-mosses","n":0.577}}},{"i":5717,"$":{"0":{"v":"A Thousand Brains a New Theory of Intelligence","n":0.354}}},{"i":5718,"$":{"0":{"v":"A Practial Guide to Evil","n":0.447},"1":{"v":"\n- url: https://practicalguidetoevil.wordpress.com/2015/03/25/prologue/","n":0.577}}},{"i":5719,"$":{"0":{"v":"Blogs","n":1}}},{"i":5720,"$":{"0":{"v":"The Old Man in the Cave","n":0.408},"1":{"v":"\n- https://theoldmaninthecave.substack.com\n\n![](/assets/images/2024-09-29-13-36-54.png)\n  ","n":0.707}}},{"i":5721,"$":{"0":{"v":"Progress Report for Subscriber","n":0.5},"1":{"v":"\n## Has it been two weeks already?\n\nActually, it’s been three weeks since my first [dev journal post](https://theoldmaninthecave.substack.com/p/lets-reboot-the-semantic-web-with-alternate-realities) and [ general article](https://djradon.substack.com/p/introducing-carpe-noctem).\n\nWhy so long? Writing those two articles left me a little dazed and daunted. Call it writer’s fatigue. I also wanted to get some technical work worth writing about under my belt. I’ve been going from minus one to zero for long enough already. \n\nSo I made some progress on an [[unorthodox foundational ontology|ko]].  I'm calling it Kosmion. Anouncement forthcoming, maybe in a week or three. \n\nProgress might’ve been quicker but I’ve been deep in the gopher holes, including a stand-off with the [[“gentle” Unified Foundational Ontology|prdct.unified-foundational-ontology.gUFO]]; planning for a [[semantic static site generator|sflow]]; a review of [[t.cs.web.w3c.rdf.named-graphs]] and the [[w3c Data Catalog|prdct.dcat-data-catalog]] standard; and posting an article [surveying authoring tools for Semantic Web data](https://theoldmaninthecave.substack.com/p/whats-the-best-semantic-web-authoring).\n\n\n## Moving Forward\n\nI’d like this dev journal to be somewhat frequent and less engrossing (to write, that is). So I might have to rein in the rumination, lower my standards, and just crank out more updates and [[public learnings|t.edu.learning-in-public]], goddammit. I can save the over-polishing for my other blog, [[blogs.carpe-noctem]].\n\nIf you're curious about Kosmion, I’m posting chats with my tireless synthetic co-conspirator [[here|ko.conversations]].\n\n![](/assets/images/2024-10-08-10-10-13.png)\n","n":0.071}}},{"i":5722,"$":{"0":{"v":"What’s the Best Semantic Web Authoring Tool?","n":0.378},"1":{"v":"\n*a grim survey of RDF data management apps*\n\nSo I was chomping at the bit on a [[foundational ontology|t.km.ontology.foundational]] with accompanying example data. Let me just open my go-to RDF tools...\n\n## The Usual Suspects \n\n### VSCode and JetBrains\n\nI’ve been composing little bits of raw RDF in [[Turtle|prdct.rdf.turtle]] “by hand” with my ~~preferred text editor~~ all-time-favorite software, [[VSCode|prdct.vscode]]. Turtle is the most human-readable of the various RDF syntaxes and with the handy [[Stardog RDF extension|prdct.stardog.rdf-grammars]] for syntax checking and highlighting, the experience is pretty good. \n\nIf you prefer the [[org.jetbrains]] IDEs, apparently the [[prdct.rdf-and-sparql]] plugin is the best thing since sliced arrays. For €5 / month, you can query local RDF files with [[SPARQL|prdct.sparql]]. Pretty cool!\n\nI wouldn’t recommend either path for non-coders though. And I’ve definitely found myself wishing for a more purpose-built tool.\n\n### Protégé\n\nFor a little GUI goodness, there’s the hallowed and venerable [[prdct.protege]] “ontology editor.” In the words of [[user.phil-lord]], it’s “[[the Excel of the ontology world|prdct.tawny-owl#^m1l0lh2seh0h]].”\n\nI put ontology editor in quotes here because there’s been an [[annoying blurring of the line|ko.conversations.2024.10.12.conceptual-foundations#its-so-annoying-that-applications-and-the-semantic-web-community-seem-to-refer-to-instance-data-as-an-ontology]] between ontologies (i.e., conceptual schemas, also known as the “terminologic box” or t-box) and the facts and entities that use ontologies, aka instance data or the “assertional box” or a-box. I know it can be a hard line to draw, but apparently everything’s an ontology now. Better to call everything “RDF data” than to call everything an ontology, IMHO.\n\nAnyhow, I know Protégé is commonly used for authoring instance data. Maybe most of the people who create ontology-conforming instance data by hand are the same people who created the ontologies. If the tool you know works, keep using it, right?\n\nProbably the biggest reason is that there aren’t really any other options.\n\nBut Protégé doesn’t have source editing. It’s also complicated and intimidating. It’s just not ideal for actual data management. So let’s at least have a look around.\n\n### Topbraid Composer\n\n[[prdct.topbraid-composer]] is the other well-known GUI tool for the Semantic Web, but the free edition was discontinued in May 2020, and the paid “Maestro Edition” is $3450/year and no longer actively developed. [[org.topquadrant]] is focusing on [[prdct.topbraid-edg]] which has neither a free version nor public pricing.\n\nFor me, not being able to see the source for more than one element at a time is disqualifying, but maybe I was just doing something wrong. Also, the old free edition didn’t seem to work with [[prdct.rdf.trig]] (the “named graph” superset of Turtle), which might be a major issue for me. And like most products based on the [[Eclipse IDE|prdct.eclipse]], learning Composer might be a challenge for non-programmers.\n\nEven so, Composer Free might be your best option for affordable, GUI-based RDF data management. You can find the slightly-hidden download [here](https://archive.topquadrant.com/topbraid-composer-install/).\n\n\n## A Frustrating Search\n\nI started looking for a friendlier, purpose-built [[authoring tool|c.software.semantic.authoring]]. Surely there’s something that allows you to *browse, create, and update RDF data* with a GUI!? Like [[prdct.datagrip]], but for the Semantic Web. I mean, people have been doing this for 25 years!\n\nYou would expect a user-friendly data management app to have a simple means of entering and updating data. Helpful graph and hierarchy visualizations would be nice. It should also have guardrails:\n  - consistency checks\n  - a revision history or per-object undo mechanism\n  - wizards and other user-experience affordances for common workflows like setting up projects, commiting changes, and publishing datasets\n\nA lot of tools interface with RDF data via [[prdct.sparql]], so require backing from a compliant [[triple store|c.software.database.graph.rdf]]. I’m envisioning using git to store RDF data, so for that use case an authoring tool has to work with text files. Ideally, I’d want a stand-alone application that you can run disconnected on a laptop. (Local-first forever!)\n\nThere must be some good options, right?\n\n### Fluent Editor\n\nThe only stand-alone alternative to Protégé and Composer that I could find was [[prdct.fluent-editor]]. It’s quirky, doesn’t have direct source editing that I could find, and hasn’t been updated since 2015. I love the idea of using Controlled English for knowledge modeling, but LLMs are poised to do that in any language, controlled or not. \n\n![](/assets/images/2024-10-18-12-56-20.png)\n\n\nFluent Editor was definitely ahead of its time, but I’d be suprised to hear of anyone using it in 2024.\n\n## Reddit To the Rescue?\n\nWhile researching this article, I stumbled on a recent “[[reddit post entitled Best Ontology Development Environment Tool?|ar.reddit.semanticweb.best_ontology_development_environment_tool]]”. [[user.daniel-bakas]] of *[[ar.best-rdf-triplestore-graph-database]]* fame mentioned he’s looking for tools suitable for “high-impact big scale projects.” Whatever the scope, his considerations are largely the same as mine.\n\n### Atomic \n\nOne of the threads in Daniel’s post, from the creator of [[prdct.atomic-data]], [[user.joep-meindertsma]], mentioned [[prdct.atomicserver]]. \n\nAtomic Data is an exciting RDF-based alternative to the conventional semantic web. I particularly love its use of [[t.cs.sd.event-sourcing]].\n\nAccording to Joep, Atomic Server “now has an ontology editor with a nice UI, even shows the UML diagram.” \n\nSounds great, but...\n\nI have some [[hesitations about the Atomic approach|prdct.atomic-data#thoughts]], especially in view of my [[democratized alternate realities use case|blogs.the-old-man-in-the-cave.2024-09-27-lets-reboot-the-semantic-web-with-alternate-realities]]. Primarily, it is too restrictive about being able to say anything about anything. My users have to be able to pick up other peoples’ content and riff on it. \n\nAnother restrictive aspect of Atomic is that all data requires validation with an Atomic Schema before it’s stored on an Atomic-compatible service. I want something flexible where data can be created by hand, stored in Git repositories, and get forked easily. \n\nStill, I admire the ambition, love the [strategy](https://docs.atomicdata.dev/roadmap), and depending on your use case, it might work for you.\n\n\n### Overkill Options\n\nThe Reddit thread mentioned a few other web-based possibilities: LinkedDataHub, Metaphactory, and Semaphore. They’re more platforms than authoring tools.\n\n[[prdct.linkeddatahub]] is an impressive, web-based, open-source Knowledge Graph platform that deserves an article of its own. Its target audience includes “researchers and data scientists” and “developers and data publishers.“ It inspires you, as a developer, to base your application on it. But while it could be used for authoring RDF data, that is not its focus. As an authoring too, it is probably overkill.\n\n[[prdct.metaphactory]] is similar, but not open-source. And pricing isn’t cheap, [“starting from $13.03/hr or from $52,900.00/yr”](https://aws.amazon.com/marketplace/seller-profile?id=a04eaa90-2616-469a-a304-96d35bd77641) on AWS.\n\n[[prdct.semaphore]] is probably expensive and definitely overkill.\n\nThe consensus in the Reddit discussion seemed to be: if you’re comfortable using an IDE, making RDF data by hand is probably your best option.\n\n## Anything Else?\n\n### VocBench\n\n[[prdct.vocbench]] might be the best web-based option. You can install it locally and it seems to have caching and other support for mixing local development with connected resources. It has options for history, validation, and undo. But it doesn’t seem to have a source editor and it has some [[other limitations|pub.question-log.2024.10.16#limitations-of-vocbench]].\n\n### Open Link Structured Data Editor\n\nThere’s also the [[prdct.open-link-structured-data-editor-osde]], which hasn’t seen an update in two years and doesn’t work with text files.\n\n### Stardog\n\n[[prdct.stardog.studio]] looks slick and might fit the bill for an authoring tool if it worked with text files or even non-Stardog triple stores. I love that they have a free cloud offering though, and am forever grateful for the VSCode extension.\n\n### Fluree\n\n[[prdct.Fluree-db]] is an inspiring take on RDF graph databases, with immutability and time travel. I keep eyeing Fluree because of its potential as a game-changing graph database. The Fluree cloud offering, [[Nexus|prdct.fluree.nexus]], has a modern GUI for data management. Like Datadog Studio, it doesn’t support text files or other triple stores.\n\n### rdf4j Workbench\n\nFinally, there’s [[prdct.rdf4j.workbench]]. If you’re not familiar with [[prdct.rdf4j]], it’s the Eclipse Foundation’s open-source triple database, analogous to Apache’s [[prdct.jena]] with its [[prdct.jena.fuseki]] SPARQL engine. (The Fuseki web UI doesn’t support text editing.)\n\nIn terms of rdf4j’s source support, you can enter RDF directly into an HTML &lt;textarea&gt;. \n\n![](/assets/images/2024-10-17-12-06-02.png)\n\nA picture is worth a lot of words here, but I’ll spend some anyhow: If your text-oriented application has to be web-based, please use [[prdct.monaco-editor]].\n\n### Solid?\n\nAt this point, I should probably mention [[prdct.solid]], an initiative/specification/platform that lets people store their data securely in decentralized data stores called Pods. The vision is data is decoupled from applications, so that people are no longer locked into specific platforms simply because their data is held there. \n\nIt’s similar to Atomic Data and also exciting and ambitious, with a large and active developer community and commercial backing to boot. But while Solid is built on RDF, it’s not viable as a general RDF authoring tool. \n\nIt could benefit from one though.\n\n## Prognosis\n\n![](/assets/images/2024-10-18-16-07-22.png)\n\nThe situation is discouraging to say the least.\n\nIf we’re going to [[reboot the semantic web|blogs.the-old-man-in-the-cave.2024-09-27-lets-reboot-the-semantic-web-with-alternate-realities]], we’ll want a usable data editor that supports [[local-first|t.cs.sd.local-first]] authoring, guided workflows, and data guardrails.\n\nFor now, I guess I’ll be sticking with VSCode, but let me know if I’ve missed something. I’d love to be wrong here. \n\nAlso, let me know if you’re interested in buildinng or backing a [[modern RDF data editor|wanted.modern-rdf-data-editor]]! That’s a project I could sink my teeth into.\n\n","n":0.026}}},{"i":5723,"$":{"0":{"v":"Enter Kosmion","n":0.707}}},{"i":5724,"$":{"0":{"v":"Let’s Reboot the Semantic Web with Alternate Realities","n":0.354},"1":{"v":"\n*I’d bet the Old Man in the Cave can help us out.*\n\n![](/assets/images/2024-09-13-16-11-46.png)\n\n>“Friends, Romans, Farm Animals! We are now going up to the cave and check your favorite recluse. We’re gonna bring him out in the sunshine and get a good look at him. And then we’re gonna decide if he’s worthwhile keeping alive.” \n> \n> -Major French, The Twilight Zone: [[video.twilight-zone.s05e07-the-old-man-in-the-cave]]\n\n## Greetings!\n\nWelcome to my developer journal. I’ve been wanting to try [[learning in public|t.edu.learning-in-public]] and I hope this thing will boost my motivation, improve my writing, and put a finer point on some of my ideas. I’m also looking to make connections that could lead to collaboration. So here we are.\n\n## Spoiler Alert: It’s a Machine\n\nIn the eponymous Twilight Zone episode from 1959, the old man in the cave is secretly a computer that keeps the local townsfolk alive by giving them the information they need (through an intermediary, their leader Goldsmith) to survive in a radioactive, post-apocalyptic world. They end up destroying the computer in the name of freedom, and then everyone except Goldsmith dies of radiation poisoning. \n\nIt’s a story about secular faith and a nice example of the [[t.storytelling.tropes.benevolent-ai]] trope.\n\nIn the context of this developer journal, the Old Man is a metaphor for synthetic intelligence and how we can use digital tools and digitized information to help humanity.\n\n## My Mission: A Blossoming of Alternate Realities\n\nI’m on a mission to help people build, deconstruct, remix, and engage with the [[cultural multiverse|t.multiverse]] through [[computer-assisted roleplay|t.roleplaying.computer-assisted]], [[interactive drama|t.drama.interactive]], and [[applied ontology|t.km.ontology.applied]]. \n\nThe dream: playable alternate realities that draw on our collective cultural history and inspire our engagement. Anyone can enjoy these realities, even the non-technical can create them, and the overall experience can easily be meaningful and immersive. It might look like a drama-filled version of the [[metaverse|t.cs.metaverse]], although [[I do not love that term|t.cs.metaverse#^pdbekjzfr2l0]]. \n\nBut it could also look like [[improv theater|t.drama.theater.improvisational]] or [[pen-and-paper roleplaying|t.roleplaying.pen-and-paper]], perhaps with software standing by inobtrusively, documenting and ready to assist.\n\nIt’ll be made possible by a corresponding, new-ish art form. Call it digital adventure production, roleplay experience curation, or [[the electric magic store|idea.electric-magic-store]]. It will weave together aspects of film, video games, immersive theatre, and role-playing. You can think of it as the spiritual successor of today’s [[virtual tabletops|t.roleplaying.virtual-tabletop]].\n\nIn additional to imagination, artistry, production skills, and some supporting software, this dream requires distributed, interoperable, and well-defined data. Which just happens to be the vision of the [[t.cs.semantic-web]].\n\nSo in addition to my main mission to make this dream a reality, I have a technical side-quest to reboot the Semantic Web. \n\n## Making the Semantic Web Usable\n\nAs I mentioned, the vision of the Semantic Web is simple: distributed, interoperable, and well-defined data.\n\nThe threads of the Semantic Web are [[prdct.rdf]] statements composed of a subject, a predicate, and an object. The form is beautiful in its simplicity. For example:\n\n```turtle\n:the-old-man-in-the-cave :helped :goldsmith .\n:goldsmith :helped :the-townsfolk .\n```\n\nTheoretically, you can say anything with an interlinked collection of subject-predicate-object triples. It’s a graph-based universal data language. But of course, the devil is in the details.\n\nI want to heed [[Manu Sporny|user.manu-sporny]]’s 2014 [[call-to-arms|ar.json-ld-and-why-i-hate-the-semantic-web]]:“If you want to make the Semantic Web a reality, stop making the case for it and spend your time doing something more useful, like actually making machines smarter or helping people publish data in a way that’s useful to them.” \n\nTurns out that making machines smarter was the easy part!\n\nWith the current state of the art, publishing *any* semantic data, let alone useful data, is hard. In a word, the most important theme for wider SW adoption is **usability**. \n\nI’ve got some ideas for how to make data publishing free and easy for everyone. So that should help usability.\n\nTo make the data useful, we’ll need to address some long-simmering issues around RDF: [[temporality|t.cs.data.temporality]], [[provenance|t.km.meta-knowledge.provenance]], hypotheticals, [[probabilities|t.cs.data.probability-claims]], [[n-ary relationships|t.cs.semantic-web.n-ary-relationships]], and [[multi-level theory|t.km.ontology.multi-level-theory]].\n\nDon’t even get me started on the state of [[prdct.RDF-star]].\n\nThere are also plenty of gaps around SW infrastructure and best practices that have had me searching for solutions and dreaming up my own. \n\nIn the trenches of academia, industry, open-source, and the World Wide Web Consortium, the Semantic Web has gotten bogged down. I guess we should’ve expected it to take a while to iron the kinks out of something as ambitious as a universal data language. Still, it’s been almost 25 years!\n\nThe time is right to forge a path forward. And I’d bet the old man in the cave can help us out.\n\n## Other Likely Topics\n\nI’m interested in and wary of AI (better termed [[synthetic intelligence|t.cs.synthetic-intelligence]]) and how it can help people create [[interactive drama|t.drama.interactive]] and [[virtual worlds|t.cs.virtual-worlds]]. Things like [[t.cs.ai.retrieval-augmented-generation.graphrag]] and [[agentic systems|t.cs.agents]] are highly relevant.\n\nAt the moment, I’m especially interested in *data modeling* and how to represent things like characters, scenarios, play histories, and evolving worlds. \n\nIn the near term, I’m hoping to start developing some open upper-level and meta-conceptualizations, i.e., ontologies, and weave together some publishing infrastructure. After that, I aim to start making software that can use these ontologies to support roleplaying.\n\nI enjoy [[astronaut architecture|idea.architecture-astronaut]] but want to actually build stuff too. So I intend to touch on relevant topics in [[data science|t.cs.data.science]] and [[software development|t.cs.sd]] including [[visualization|t.cs.data.visualization]], [[home-cooked software|t.cs.sd.home-cooked-software]], and [[geographic information systems|t.cs.gis]]. \n\n## Next Steps\n\nIf you might be interested in the less-technical aspects of my mission, or [[story-telling|t.storytelling]] and the [[digital humanities|t.humanities.digital]] in general, check out my other blog, [Carpe Noctem](https://djradon.substack.com/p/introducing-carpe-noctem).\n\nAs I mentioned, I’m looking to make connections that could lead to collaboration. If our interests overlap, please reach out!\n\nNow, let’s go pull the old man out of his cave and have a good look.\n\n\n","n":0.033}}},{"i":5725,"$":{"0":{"v":"Carpe Noctem","n":0.707},"1":{"v":"\n- https://theoldmaninthecave.substack.com\n\n![](/assets/images/2024-10-16-10-00-09.png)","n":0.707}}},{"i":5726,"$":{"0":{"v":"djradon 😍 chatgpt","n":0.577},"1":{"v":"\n- as an reviewing editor, it's only okay at best\n  - \"Consider specifying what exactly is holding you back from fully endorsing Atomicserver to give readers a clearer understanding of the drawbacks.\"\n  - \"Consider explaining why VocBench stands out compared to the other tools you've mentioned to help readers understand its strengths.\"\n  - \"Consider giving a specific example of what 'guided workflows and data guardrails' would look like to make your point more tangible.\"","n":0.116}}},{"i":5727,"$":{"0":{"v":"Introducing... Carpe Noctem","n":0.577},"1":{"v":"\n*An Explorer’s Guide to Collaborative Imagination*\n\nGood evening from Los Angeles. I’m a creative technologist and a role-player, and I’m on a mission to help people navigate the [[cultural multiverse|t.multiverse]]. Hopefully, we’ll be leaving good stories in our wake.\n\n## What’s This All About, Then?\n\n*Carpe Noctem* (loosely translated as “harvest the night”) will be a series of articles and letters about storytelling, good gaming, [[alternate realities|t.storytelling.alternate-reality]] and [[roleplaying|t.roleplaying]] of all kinds, but especially [[digital storytelling|t.storytelling.digital]] and [[computer-assisted roleplay (CARP)|t.roleplaying.computer-assisted]].\n\n### The Cultural Multiverse\n\nIn physics, the term *multiverse* refers to a “patchwork quilt of separate universes all bound by the same laws of physics.” It’s not so much that anything is possible, but that everything possible actually happens, somewhere. \n\nI use the term *[[cultural multiverse|t.multiverse]]* to refer to the complete set of worlds and world-fragments that have ever been conceived and shared. It includes representations of “real” reality (e.g., a news story or a recounted memory, accurate or otherwise), but also the representations of more fantastical realities in folklore, literature, film, video games, and roleplaying.\n\nThe cultural multiverse is a lot smaller than the physical multiverse, but as evidenced by books like [[book.flatland]] or games like [[game.bioshock.infinite]], the laws of physics have way more flexibility.\n\n\n### Simple Roleplaying\n\n“Playing pretend” with roles is something that kids start doing by the age of 18 months. It emerges spontaneously across cultures, which suggests that role-playing is an intrinsic part of human development. It seems to serve the evolutionary functions of developing empathy and social problem-solving skills. \n\nSimple roleplaying reaches its peak in the preschool years (ages 3-6), where children start to create elaborate scenarios. From the ages of 7 to 11, kids become more focused on structured activities.\n\nAfter that, playing pretend usually becomes internalized or just fades away.\n\nBut for some people, imaginitave play and simple roleplaying evolve into creative writing, acting, or organized role-playing games, also known as RPGs.\n\n### Tabletop Roleplay Gaming\n\nEven if you’ve never tried it, you probably know what’s involved with [[pen and paper (“tabletop”) roleplaying games|t.roleplaying.pen-and-paper]] like old-school Dungeons & Dragons: folks sitting around a table, “inhabiting” a fantasy scenario with characters of their own devising, figuring out what those characters should try to do, and rolling dice to add an element of chance to their imaginary efforts. A facilitator, commonly known as [[the Game Master|t.roleplaying.gm]] (or GM for short) sets the scenes and keeps things moving while the players keep track of their characters’ statuses on pieces of paper known as character sheets.\n\nTabletop roleplaying grew out of the combat-based board games of the late 1960s. *Dungeons & Dragons* (1974) is commonly credited as the progenitor, but it seems more accurate to say that one of D&D’s co-creators, [[user.dave-arneson]], established the genre with his [[game.blackmoor]] game on April 17, 1971. \n\nFor a great short history of the subject, I highly recommend [Dungeons & Deceptions: The First D&D Players Push Back On The Legend Of Gary Gygax](https://kotaku.com/dungeons-deceptions-the-first-d-d-players-push-back-1837516834).\n\n\n### CARP\n\nYou can think of computer-assisted roleplay as digital Dungeons & Dragons, but any genre will work. Alien space horror, cyberpunk dystopia, and supernatural gothic are some of the more popular flavors. But also, and more practically: psychotherapy, job training, and language learning. \n\nProducing a role-playing campaign is analagous to making a TV series. After an initial flurry of developmet (i.e., planning, writing, and finding the right players), you settle into a session-oriented (episodic) rhythm: pre-production, production, and post-production.\n\nIn preparing for a classic tabletop RPG campaign, the players might have to break out the Player's Handbook if they're not already up on the rules. The GM has to either create an alternate reality with maps, notes, and illustrations, or purchase a ready-made module and get familiar with it. The GM might want to distribute a \"pre-read\" to set the stage for the players. And the players have to create their characters, one of the most enjoyable parts of the whole experience. \n\nComputers can help us create alternate realities, concot role-playing scenarios, manage characters, and teach the rules, and those are just a few examples.\n\nThen, before each session, the GM prepare handouts, sets up battles and maps, maybe practices some voice acting, and tries to imagine some of the places the players might try to go. Computers can help with all of that pre-production.\n\nAs the session begins and the GM shepherds the players along, computers can provide a simulation medium where “in-game” events transpire. They can help trigger visuals, audio, and special effects. They can support public and private communication. Dynamic maps are a popular recent innovation. And filling the role of metaphorical camera, computers can record the happenings on multiple levels. That’s production.\n\nAfter the fact, computers can help us shape the experience into good stories and package the results for reflection and to share with others.\n\nThere's already a vibrant software ecosystem fulfilling some of CARPs potential. But things are not very integrated, there's not much data sharing, and there's not much orchestration.\n\nSo half the dream, and maybe it‘s a [[pipe-dream|ar.atlantic.video-games-are-better-without-stories]], is that you can mix a roleplaying experience with player freedom (i.e., an open-ish world) and the [[principles of good gaming|t.rec.game.principles]], sprinkle in a little CARP, and at least get a decent story out of it. And there’s certainly the potential for highly elaborate and cinematic stories, if that appeals. Taken to the extreme: if you’ve seen [[Cronenberg’s|user.david-cronenberg]] [[video.existenz]], that’s where this dream becomes a nightmare.\n\n![](/assets/images/2024-09-26-17-40-04.png)\n\n\n> Ted: Free will is obviously not a big factor in this little world of ours.\n> \n> Allegra: It’s like real life. There’s just enough to make it interesting.\n>\n> -[[video.existenz]] (1999)\n\n\nThe other half of the dream is using technology to make the enjoyment and curation of these role-playing productions more accessible.\n\nRight now, CARP is fraught with technical challenges that detract from the experience. It looks and plays a lot like “drama club meets AV geeks meets primitive video games.” Which is great. Beautiful, even! I’m glad we’ll always have “retro-carp” as an option. \n\nBut when we start to realize the dream, we’ll have better playability, easy sharing, content marketplaces, and a lot more variety. The cultural multiverse is going to blossom with alternate realities, we’ll see a profusion of play-styles, and improved accessibility will lead to greater player diversity. Things are going to get real.\n\n### Modeling the Imaginary\n\nTo coordinate all the CARP software and be able to share and sell scenario elements and fit them together, we’re going to need conceptual modeling. We’ll have to settle on some shared high-level vocabularies and think about how to model things as varied as character motivations, trap mechanics, weather patterns and alternate realities.\n\nHow do we express these things digitally? One approach involves a controversial data-modeling technology called the [[Resource Description Framework|prdct.rdf]]. We’ll talk more about RDF shortly.\n\nIntellectually and practically speaking, conceptual modelling is a gold mine. Two rich veins concern the modelling of time and space, and how to model change. If you’re not even remotely interested in how to represent imaginary, evolving spatio-temporal entities, don’t worry... you will be! \n\n### Other Relevant Topics\n\nClosely-related art forms that bear investigation include [[live-action roleplay|t.roleplaying.live-action-larp]] (LARP), [[interactive drama|t.drama.interactive]], [[interactive fiction|t.storytelling.fiction.interactive]], and [[interactive theater|t.drama.theater.interactive]] which, surprisingly, are all quite different. \n\nI also intend to take little bites out of philosophy, psychology, literary theory, and library science. So things like [[narratology|t.storytelling.narratology]], [[theories of creativity|t.phil.creativity]], and the [[philosophy of fictional entities|t.phil.fiction.entities]]. (Spoiler alert: They’re all real.)\n\n## It All Started Around A Gypsy Caravan Campfire\n\n![](/assets/images/2024-09-26-21-11-06.png)\n<small>*[[images.campfire-site-yosemite]]*, [[user.albert-bierstadt]]</small>\n\nEight quick years ago I got in on the ground floor of a geographically-distributed Dungeons & Dragons game. Our crew is four players plus a heroic, multi-talented GM.\n\nBecause we live far apart, we’ve almost always used a [[virtual tabletop|t.roleplaying.virtual-tabletop]] called [[prdct.roll20]] to facilitate the sessions. Our game (or “campaign” in D&D-speak) is set in a well-known alternate reality known as [[the Forgotten Realms|game-system.dungeons-and-dragons.forgotten-realms]] and our GM kicked things off with a homebrew prelude set around a gypsy caravan campfire before launching us into a popular commercial adventure scenario called [[game.storm-kings-thunder]]. \n\n(For those who aren’t familiar, the Forgotten Realms is without doubt one of the richest fictional worlds ever brought forth, with its own detailed [geography](https://forgottenrealms.fandom.com/wiki/Portal:Geography), [hundred of settlements](https://forgottenrealms.fandom.com/wiki/Category:Settlements), [dozens of deities](https://screenrant.com/dungeons-dragons-deities-gods-forgotten-realms-fifth-edition/), and a truly [fantastical history](https://forgottenrealms.fandom.com/wiki/Portal:History). The fan base is huge, so in addition to over 300 official published novels, close to 100 different roleplaying adventure modules, and a pretty decent [[movie|video.dungeons-and-dragons-honor-among-thieves]], it’s inspired countless works of homebrew content and [fan fiction](https://www.fanfiction.net/book/Forgotten-Realms/).)\n\nIn the hands of our highly-capable [[GM|t.roleplaying.gm]], the campaign transcended even the vastness of the Forgotten Realms and became a bespoke, time-travelling, genre-bending epic. \n\nPerhaps the biggest challenge for us hapless players was keeping track of all the items, places, characters, factions, plotlines, and quests we came across. \n\nSo I started an “as-we-played” written narrative, frantically transcribing memorable dialog, summarizing battles, and generally documenting our adventures from the perspective of my character, an axe-wielding barbarian. After our sessions, I would email these summaries to my eager and grateful crew. \n\nIt was a great opportunity to flex my writing skills.\n\nIt also allowed me to experiment with different narrative styles and forms. My summaries evolved from simple text into an interlinked wiki where I’ve been trying to capture the relationships between places, characters, etc. It was essentially a semantic web: a textual network of inter-linked concepts, entities, and happenings.\n\nAnd it helped me realize that role-play gaming and alternate realities in general could benefit from some good [[conceptual modeling|t.cs.sd.modeling.conceptual-modeling]].\n\n## Whither the Semantic Web?\n\nMy original project to keep track of our Forgotten Realms adventures exploded and seeped into countless gopher holes, including a deep one known as the [[t.cs.semantic-web]]. With a capital ‘S’ and a capital ‘W’.\n\nWhat’s that?\n\nThe threads of the Semantic Web are RDF statements (known as triples) of the form subject-predicate-object. They look like this:\n\n```turtle\n:ted :likes :allegra\n```\n\nYou can say anything about anything with these triples. When they’re backed by commonly understood conceptualizations (which are called [[ontologies|t.km.ontology]] and also expressed using triples), they are an elegant means of representing and sharing knowledge.\n\nTo borrow from [[user.gavin-mendel-gleason]], the vision of the Semantic Web is distributed, interoperable, and well-defined data. It’s a solution, in his words, to “literally the most central problem for the current and near-future human economy,” i.e., how to make our data, knowledge and ideas accessible and understandable to each other and our computers.\n\nThe Semantic Web has had its best success in the fields of [[bioinformatics|t.km.bioinformatics]] and medecine. It’s also used in [[library science|t.library-science]], healthcare, financial services, and e-commerce.\n\nBut despite its promise and having been around for 25 years, the Semantic Web hasn’t caught on widely or lived up to its potential. We can explore some of the reasons later, but in my opinion, it’s a technology that needs a killer app.\n\n## Can Alternate Realities Bring the Semantic Web to Life?\n\n![](/assets/images/2024-09-27-06-15-27.png)\n<small>*Young Frankenstein* (1974)</small>\n\nPeople and their software could use good semantic conceptualizations and shared knowledge to track and understand what happens in games and stories of all kinds. \n\nBut beyond this documentary function, virtual tabletops, game engines, reality simulators, and authoring software all based on shared conceptualizations would empower writers, artists, and producers to share and remix alternate realities across platforms and art forms. It’s the “distributed, interoperable, and well-defined” vision of the Semantic Web applied to the realm of imagination, and the results would be magical.\n\nFor example, according to [[user.adetayo-oludare-alade]], authors “simply make-up or stipulate [fictional] entities and their properties into existence” using linguistic devices like referring expressions and descriptions. With language, we create alternate realities and populate them with imagined creatures. You can call them fictional, but if we can describe those realities and creatures in ways that computers can process and simulate, once we set the computational wheels in motion things take on an life of their own. [[Arguably|ar.aeon.is-life-a-complex-computational-process]], we can literally bring our creations to life and experience drama with them.\n\nAs a side-effect, I think the innovations and momentum these roleplaying applications would generate for Semantic Web technologies could bring its promise to life for other domains as well.\n\n## Why Is the Metaverse Boring?\n\nIn the words of [[user.ian-bogost]], “3-D worlds seem more and more real. But those worlds feel even more incongruous when the people that inhabit them behave like animatronics and the environments work like Potemkin villages.” Realistic graphics don’t make characters and situations interesting. Conceptual depth is the key.\n\nTraditional roleplaying is engaging because good writers author good characters and situations, and then a good GM and the players’ imaginations bring them to life. \n\nMaybe virtual reality and modern roleplaying video games leave too little to the imagination? \n\nBut certainly, the [[metaverse|t.cs.metaverse]] currently lacks other essential elements of D&D as originally conceived: the crafting of interesting scenarios and characters; a framework for collaborative play; the simplicity of pen-and-paper; the ease with which you can transcend the system; and the benevolent shepherding of a human behind the curtain.\n\nWith traditional roleplaying, GMs can easily make anything happen, answer questions, change the pace, call for a snack break, incorporate player feedback, and fill in gaps with a little improv and some [[t.drama.theater.theater-of-the-mind]]. They run the magic store. \n\nThe metaverse needs something like that.\n\n## Will AI Ruin the Fun?\n\nWith the recent dramatic improvements in generative AI, we can foresee more realistic synthetic dialogue in virtual worlds and video games. We can foresee less-dismaying and less-sterile synthetic artwork. And it’s not too hard to imagine a near future where new innovations will support the generation of synthetic-yet-compelling creatures, worlds, and stories. \n\nBut do we want that? \n\nThere’s a very tricky [[tension|ar.screenrant.dnd-ai-controversy-dungeons-and-dragons-fans-hasbro]] between getting digital assistance and preserving the joy and humanity we find in the DIY crafting of creative works. You can expect that to be one of *Carpe Noctem*’s recurring themes.\n\n\n## Who Are You?\n\nMy intended audience here is a general one: people who might be interested in storytelling, roleplaying, game studies, alternate realities, or synthetic life. \n\nIf you're curious about the technical details of my mission, check out my developer journal: [The Old Man in the Cave](https://theoldmaninthecave.substack.com/p/lets-reboot-the-semantic-web-with-alternate-realities). \n\nI’m looking to make connections that could lead to collaboration. If our interests overlap, I’d love to hear from you!\n\n<br><br><br>\n\n\n## Postscript: Why *Carpe Noctem*?\n\n![](/assets/images/2024-09-26-21-25-06.png)\n<small>*[[images.baluk-hana-and-method-of-fishing-for-the-red-mullet]]*, [[Thomas Allom|user.thomas-allom]]</small>\n\n\nAt least since [[video.dead-poets-society]], the Latin phrase *[[Carpe Diem|t.ling.latin.carpe-diem]]* has come to mean “seize the day.” Essentially, grab life by the horns before it slips away.\n\nAs [[Jack Shepherd|user.jack-shepherd]] says in [“Carpe Diem” Doesn’t Mean “Seize the Day,”](https://medium.com/the-cellar-door/carpe-diem-doesnt-mean-seize-the-day-770fbf63a820) a more accurate translation is “pluck the day.” It’s a horticultural metaphor about gathering or harvesting the fruits of life.\n\nBut what about the night? \n\nLike most entertainment, roleplaying games are often fitted in after the sun goes down. Typical sessions last three to five hours and often stretch past midnight. All-nighters are glamorized legend-fodder. Pluck those zombies, harvest the magic items, and seize the stronghold before the sun comes up!\n\nWriting also has its nocturnal mystique. [[user.james-baldwin]] wrote in [[book.nothing-personal]] about how the grim realizations of 4am (a “devastating hour”), could in turn be a source of strength. [[Kafka|user.franz-kafka]] wrote ruefully of sleep: “Just think how many thoughts a blanket smothers while one lies alone in bed.” Proust, Plath, Fitzgerald, T.S. Eliot and George Sand are among the many writers famed to do their best work at night. \n\nRegardless of quality, as the father of a wakeful two year old, [[night time is often the write time|idea.night-time-write-time]] for me.\n\n","n":0.02}}},{"i":5728,"$":{"0":{"v":"Addressable Resources","n":0.707}}},{"i":5729,"$":{"0":{"v":"GitHub","n":1}}},{"i":5730,"$":{"0":{"v":"Nemo Ufes","n":0.707}}},{"i":5731,"$":{"0":{"v":"Gufo","n":1}}},{"i":5732,"$":{"0":{"v":"Are All Relations Instances of Either Material Relationship Type or Comparative Relationship Type","n":0.277},"1":{"v":"\n- https://github.com/nemo-ufes/gufo/discussions/33","n":0.707}}},{"i":5733,"$":{"0":{"v":"Stanford","n":1}}},{"i":5734,"$":{"0":{"v":"Encyclopedia of Philosophy","n":0.577}}},{"i":5735,"$":{"0":{"v":"Abstract Objects","n":0.707},"1":{"v":"\n- https://plato.stanford.edu/archives/win2018/entries/abstract-objects/\n\n## Highlights\n\n### Introduction\n\n- A philosopher may find himself asking questions like, ‘What is idealism?’ or ‘What is a substance?’ and treating these questions as difficult questions about the underlying nature of a certain determinate philosophical category. A better approach is to recognize that in many cases of this sort, we simply have not made up our minds about how the term is to be understood, and that what we seek is not a precise account of what this term already means, but rather a proposal for how it might fruitfully be used in the future.\n\n### Historical Remarks\n\n- Locke’s conception of an abstract idea as one that is formed from concrete ideas by the omission of distinguishing detail was immediately rejected by Berkeley and then by Hume.\n  - But even for Locke there was no suggestion that the distinction between abstract ideas and concrete or particular ideas corresponds to a distinction among objects. “It is plain, …” Locke writes, “that General and Universal, belong not to the real existence of things; but are Inventions and Creatures of the Understanding, made by it for its own use, and concern only signs, whether Words or Ideas” (III.iii.11).\n- Frege does not say that senses are ‘abstract’. He says that they belong to a ‘third realm’ distinct both from the sensible external world and from the internal world of consciousness.\n- The common theme in these developments is the felt need in semantics and psychology as well as in mathematics for a class of objective (i.e., non-mental) supersensible entities. As this new ‘realism’ was absorbed into English speaking philosophy, the traditional term ‘abstract’ was enlisted to apply to the denizens of this ‘third realm’.\n- platonism is the thesis that there is at least one abstract object; nominalism is the thesis that the number of abstract objects is exactly zero (Field 1980)\n\n### The Way of Negation\n\n- To call an object ‘mind-dependent’ in a metaphysical context is to suggest that it somehow owes its existence to mental activity, but not in the boring ‘causal’ sense in which ordinary artifacts owe their existence to the mind.\n  - One promising approach is to say that an object should be reckoned mind-dependent when, by its very nature, it exists at a time if and only if it is the object or content of some mental state or process at that time.\n- A similar problem arises for so-called abstract artifacts, like Jane Austen’s novels and the characters that inhabit them.\n","n":0.049}}},{"i":5736,"$":{"0":{"v":"Blcklst","n":1}}},{"i":5737,"$":{"0":{"v":"Gointothestory","n":1}}},{"i":5738,"$":{"0":{"v":"Writing Advice from Matt Stone and Trey Parker","n":0.354},"1":{"v":"\n- https://gointothestory.blcklst.com/writing-advice-from-matt-stone-and-trey-parker-30941b2cd98c\n\n## Highlights\n\n-   “It’s amazing how a deadline gets your creative juices going.\n-   “In our writers room, you never say ‘no.’ You almost never go, ‘No, that won’t work because of this.’ You don’t need that energy.”\n-   “Each individual scene \\[in _South Park_\\] has to work as a funny sketch.”\n-   “We found out this really simple rule… We can take these beats… of your outline and if the words ‘and then’ belong between those beats, you’re fucked. You’ve got something pretty boring. What should happen between every beat you’ve written down is the word ‘therefore’ or ‘but.’” ^4360o9zslnyw\n    -   (and because)\n\n\n","n":0.1}}},{"i":5739,"$":{"0":{"v":"Zettelkasten","n":1}}},{"i":5740,"$":{"0":{"v":"Luhmann Folgezettel Truth","n":0.577},"1":{"v":"\n\n\n- [[p.hasURL]] https://zettelkasten.de/posts/luhmann-folgezettel-truth/\n- [[p.refutes]]\n  - [[p.attributedTo]] @daniel-lüdecke\n    - 1. What most people think Luhmanns Zettelkasten is about: It is the linking through tags and cross-references.\n    - 2. What it is actually about: It is mainly about the concept of Folgezettel. This means that you develop an idea in a linear way and branch off if the next thought doesn’t fit into the previous string of ideas.\n- [[p.argues]] no good reason for [[t.km.folgezettel]]\n  - \"We don’t have a physical Zettelkasten and we can connect notes with links. The intent of a Folgezettel is not always clear, so we can even improve the situation by creating annotated links.\"\n","n":0.097}}},{"i":5741,"$":{"0":{"v":"Youtube","n":1}}},{"i":5742,"$":{"0":{"v":"Platform as a Reflection of Values","n":0.408},"1":{"v":"\n- https://www.youtube.com/watch?v=Xhx970_JKX4\n\n## Examples\n\n### Nu\n\n- from https://github.com/bryanedds/Nu/wiki/What-is-Nu-and-What-it-Can-Do\n![](/assets/images/2024-05-08-09-01-49.png)","n":0.408}}},{"i":5743,"$":{"0":{"v":"Ycombinator","n":1}}},{"i":5744,"$":{"0":{"v":"The Semantic Web Is Now Widely Adopted","n":0.378},"1":{"v":"\n- https://news.ycombinator.com/item?id=41307011\n- mentions: [[ar.hatoeas-is-for-humans]]\n- topic: [[ar.being-on-the-semantic-web-is-easy-and-frankly-well-worth-the-bother]]\n\n## Discussion\n\n- @openrisk: \"incompleteness of vision: if you dig to their nuclear core, semantic apps offer things like SPARQL queries and reasoners. Great, these functionalities are both unique and have definite utility but there is a reason (pun) that the excellent Protege project [1] is not the new spreadsheet. The calculus of cognitive cost versus tangible benefit to the average user is not favorable. One thing that is missing are abstractions that will help bridge that divide.\"\n  \n- @tannhaeuser: \"And it fails to address why SemWeb failed in its heyday: that there's no business case for releasing open data of any kind \"on the web\" (unless you're wikidata or otherwise financed via public money) the only consequence being that 1. you get less clicks 2. you make it easier for your competitors (including Google) to aggregate your data. And that hasn't changed with LLMs, quite the opposite.\"\n\n\n### @thomastjefferey\n\nI don't think I'll live up to \"brilliant ontologist\", but here goes:\n\nFirst of all, what's the problem? Computing human-written text.\n\nWhat's the problem domain? Story. In other words: intentionally written text. By that, I mean text that was written to express some arbitrary meaning. This is smaller than the set of all possible written text, because no one intentionally writes anything that is exclusively nonsensical.\n\nSo what's my solution? I call it the Story Empathizer.\n\n---\n\nEvery time someone writes text, they encode meaning into it. This even happens on accident: try to write something completely random, and there will always be a reason guiding your result. I call this the original Backstory. This original Backstory contains all of the information that is not written down. It's gone forever, lost to history. What if we could dig it up?\n\nBackstory is a powerful tool. To see why, let's consider one of the most frustratingly powerful features of Story: ambiguity. In order to express a unique idea in Story, you don't need an equivalently unique expression! You can write a Story that literally already means some other specific thing, yet somehow your unique meaning still fits! Doesn't that break some mathematical law of compression? We do this all day every day, so there must be something that makes it possible. That thing is Backstory. We are full of them. In a sense, we are even made of them.\n\nWe can never get the original Backstory back, but we can do the next best thing: make a new one. How? By reading Story. When we successfully read a Story, we transform it into a new Backstory. That goes somewhere in the brain. We call it knowledge. We call it memory. We call it worldview. I call this process Empathy.\n\nEmpathy is a two way street. We can use it to read, and we can use it to write. When two people communicate, they each create their own contextual Backstory. The goal is to make the two Backstories match.\n\n---\n\nSo how do we do it with a computer? This is the tricky part. First, we need some fundamental Backstories to read with, and a program that uses Backstory to read. Then we should be able to put them to work, and recursively build something useful.\n\nI envision a diverse library of Backstories. Once we have that, the hardest part will be choosing which Backstory to use, and why. Backstories provide utility, but they come with assumptions. Enough meta-reading, and we should be able to organize this library well enough. The simple ability to choose what assumptions we are computing with will be incredibly useful.\n\n---\n\nSo that's all I've got so far. Every time I try to write a real program, my surroundings take over. Software engineering is fraught with assumptions. It's very difficult to set aside the canonical ways that software is made, and those are precisely what I'm trying to reinvent. I'm getting tripped up by the very problem I intend to solve, and the irony is not lost on me.\n\nAny help or insight would be greatly appreciated. I know this idea is pretty out there, but if it works, it will solve NLP, and factor out all software incompatibility.","n":0.038}}},{"i":5745,"$":{"0":{"v":"Xtdb","n":1}}},{"i":5746,"$":{"0":{"v":"Strength of the Record","n":0.5},"1":{"v":"\n- https://v1-docs.xtdb.com/concepts/strength-of-the-record/\n\n## Highlights\n\n- Object mapping is a broken metaphor.\n- When we pick apart a label like \"system bus\", and thus the [etymology of \"omnibus\"](https://www.merriam-webster.com/dictionary/omnibus), we begin to see the exercise of _naming things_ in two parts. The first, and more obvious, is the coining of terms. The more important second part is the construction of metaphors.\n- Object DBs simply never took off. An object isn’t a simple or intuitive concept; an object is type-matching dynamic dispatch implemented over a collection of closures which in turn share a second collection of lexically-bound variables which themselves are — you guessed it — more objects.\n- @kevin-feeny: \"Object DBs simply never took off. An object isn’t a simple or intuitive concept; an object is type-matching dynamic dispatch implemented over a collection of closures which in turn share a second collection of lexically-bound variables which themselves are — you guessed it — more objects.\"\n\n### Triples\n\n- Roughly, there are two categories of triples: RDF triples, which attempt to encode relationship semantics, and EAV triples,\n- purity can be a dangerous waste of time\n- triples by their very nature only describe relationships. Despite their name, relational databases consign the very notion of a \"relationship\" to the realm of the derivative. Triples have the opposite problem. Triples treat nouns as second-class citizens.\n  - If triples are to say anything about the form of the data they contain, we must slather them in complicated ontologies.\n\n## Mentions\n\n- [[prdct.prevayler]]","n":0.066}}},{"i":5747,"$":{"0":{"v":"Embracing Imperfection","n":0.707},"1":{"v":"\n- https://www.juxt.pro/blog/embracing-imperfection/\n\n## Highlights\n\n- If I had a time machine and was allowed to experiment with forking history, I would go back to this time in my career. I’d make the schema, that was hard-baked into shippable code, live in the system as data instead, which could be updated via user configuration.","n":0.14}}},{"i":5748,"$":{"0":{"v":"Writingcooperative","n":1}}},{"i":5749,"$":{"0":{"v":"Why I Shifted from Pure Writing to Documenting Instead","n":0.333},"1":{"v":"\n- https://writingcooperative.com/why-i-shifted-from-pure-writing-to-documenting-instead-f894bb5a040f\n\n## Highlights\n\n- Your readers don’t want more arbitrary advice; they want to know what you have done and why it did or didn't work.","n":0.2}}},{"i":5750,"$":{"0":{"v":"Wirfs Brock","n":0.707}}},{"i":5751,"$":{"0":{"v":"Design and Reality","n":0.577},"1":{"v":"\n\n- [[p.hasURL]] http://www.wirfs-brock.com/blog/2021/09/13/design-and-reality/\n- [[p.hasAuthor]] @rebecca-wirfs-brock\n- [[p.hasSummaryPoints]]\n- [[p.hasTopic]]\n  - [[t.cs.sd.design.domain-language]]\n  - [[t.cs.sd.design.ubiquitous-language]]\n","n":0.302}}},{"i":5752,"$":{"0":{"v":"W3","n":1}}},{"i":5753,"$":{"0":{"v":"Design Issues","n":0.707}}},{"i":5754,"$":{"0":{"v":"Linked Data","n":0.707},"1":{"v":"\n- https://www.w3.org/DesignIssues/LinkedData.html\n- authors: @tim-berners-lee\n\n## Highlights\n\n- there should be metadata about your dataset\n\n### Four rules\n\n\n\n    Use URIs as names for things\n\n    Use HTTP URIs so that people can look up those names.\n\n    When someone looks up a URI, provide useful information, using the standards (RDF*, SPARQL)\n\n    Include links to other URIs. so that they can discover more things.\n","n":0.132}}},{"i":5755,"$":{"0":{"v":"Describing Linked Datasets with the VoID Vocabulary","n":0.378},"1":{"v":"\n- https://www.w3.org/TR/void/\n\n## Highlights\n\n### Metadata\n\n#### Root Resources\n\nMany datasets are structured in a tree-like fashion, with one or a few natural “top concepts” or “entry points”, and all other entities reachable from these root resources in a small number of steps.\n\nOne or more such root resources can be named using the void:rootResource property. Naming a resource as a root resource implies:\n\n    that it is a central entity of particular importance in the dataset; and\n    that the entire dataset can be crawled by resolving the root resource(s) and recursively following links to other URIs in the retrieved RDF responses.\n\nRoot resources make good entry points for crawling an RDF dataset.\n\nThis property is similar to void:exampleResource. While void:exampleResource names particularly representative or typical resources in the dataset, void:rootResource names particularly important or central resources that make good entry points for navigating the dataset.","n":0.085}}},{"i":5756,"$":{"0":{"v":"Vocab Data Cube","n":0.577},"1":{"v":"\n- https://www.w3.org/TR/vocab-data-cube/\n\n## Abstract\n\nThere are many situations where it would be useful to be able to publish multi-dimensional data, such as statistics, on the web in such a way that it can be linked to related data sets and concepts. The Data Cube vocabulary provides a means to do this using the W3C RDF (Resource Description Framework) standard. The model underpinning the Data Cube vocabulary is compatible with the cube model that underlies SDMX (Statistical Data and Metadata eXchange), an ISO standard for exchanging and sharing statistical data and metadata among organizations. The Data Cube vocabulary is a core foundation which supports extension vocabularies to enable publication of other aspects of statistical data flows or other multi-dimensional data sets.\n\nThe namespace for all terms in this ontology is: http://purl.org/linked-data/cube#\n\n## Issues\n\n- overloads the term Dataset\n\n## Highlights\n\n### Introduction\n\nAt the heart of a statistical dataset is a set of observed values organized along a group of dimensions, together with associated metadata. The Data Cube vocabulary enables such information to be represented using the W3C RDF (Resource Description Framework) standard and published following the principles of linked data. The vocabulary is based upon the approach used by the SDMX ISO standard for statistical data exchange. This cube model is very general and so the Data Cube vocabulary can be used for other data sets such as survey data, spreadsheets and OLAP data cubes [OLAP].","n":0.066}}},{"i":5757,"$":{"0":{"v":"RDF 1.1 Primer","n":0.577},"1":{"v":"\n## Cons\n\n- https://www.w3.org/TR/rdf11-primer/#fig4\n  - ![](/assets/images/2023-12-05-09-28-27.png)\n  - implies that Bob's interest in the mona lisa is the subject_of ","n":0.243}}},{"i":5758,"$":{"0":{"v":"Rdf Identifiers","n":0.707},"1":{"v":"\n\n\n- [[p.hasAuthor]] @sandro-hawke\n- [[p.hasURL]] https://www.w3.org/2002/12/rdf-identifiers/\n\n## [[p.references]] [RDF Concepts 2.4.3:  Interaction between social and formal meaning](https://www.w3.org/TR/2002/WD-rdf-concepts-20021108/#section-Interaction)\n\n### [[hasSummary]]\n\n- [ ] [[p.summarized]]\n","n":0.229}}},{"i":5759,"$":{"0":{"v":"Linked Data Best Practices","n":0.5},"1":{"v":"\n- https://www.w3.org/TR/ld-bp/","n":0.707}}},{"i":5760,"$":{"0":{"v":"Delta an Ontology for the Distribution of Differences between Rdf Graphs","n":0.302},"1":{"v":"\n- https://www.w3.org/DesignIssues/Diff\n\n## Highlighs\n\n- concurrent changes may be completely irreconcilable\n  - (so live with it)\n- Problems with the line-oriented approach:\n  - However, when files are edited by hand, small changes to the data naturally result in small textual diffs. But since the difference is expressed as the difference between two text files, not the difference between two graphs, the delta is dependent on the graph serialization. It's not enough to have the original graph to use the delta; one needs a copy of the particular serialization.\n  - Pretty-printing algorithms reduce the large number of possible serializations of an RDF graph to a few actual serializations.\n  - The difference engine[Kly04] produces human-readable difference descriptions using an algorithm analogous to comparing pretty-printed graphs; its descriptions are not sufficient to reconstruct one graph from the other, however.\n  - The straightforward pretty-printing algorithm works in the obvious way when all the nodes are named (either with URIs or literals): triples are sorted by subject, and those that share a subject are grouped together. \n  - Notation3 has syntax for grouping triples that shared predicates.","n":0.075}}},{"i":5761,"$":{"0":{"v":"Cool Uris","n":0.707},"1":{"v":"\n- url: https://www.w3.org/TR/cooluris/\n- related: https://www.w3.org/Provider/Style/URI.html\n\n## Solutions\n\n- [[prdct.virtuoso]]\n- [[prdct.wordpress.lh-tools]]\n\n## Issues\n\n- \"According to W3C guidelines ([AWWW], section 2.2.), we have a Web document (there called information resource) if all its essential characteristics can be conveyed in a message. Examples are a Web page, an image or a product catalog.\"\n\n\n## Resources\n\n- https://stackoverflow.com/questions/46705136/how-to-make-an-ontology-public-accessible\n\n\n## References\n\n- https://unterwaditzer.net/2023/cool-uris.html","n":0.14}}},{"i":5762,"$":{"0":{"v":"Best Practice Recipes for Publishing Rdf Vocabularies","n":0.378},"1":{"v":"\n- url: http://www.w3.org/TR/swbp-vocab-pub/\n- related: [[prdct.lode]]","n":0.447}}},{"i":5763,"$":{"0":{"v":"Twilio","n":1}}},{"i":5764,"$":{"0":{"v":"How to Build a CLI with Node.js","n":0.378},"1":{"v":"\nurl: https://www.twilio.com/blog/how-to-build-a-cli-with-node-js\n\n## [[p.hasRelatedSolution]]\n\n-   [`inquirer`](http://npm.im/inquirer \"inquirer\"), [`enquirer`](http://npm.im/enquirer \"enquirer\") or `[prompts](https://npm.im/prompts \"prompts\")` for complex input prompts\n-   [`email-prompt`](http://npm.im/email-prompt \"email-prompt\") for convenient email input prompts\n-   [`chalk`](http://npm.im/chalk \"chalk\") or `[kleur](https://npm.im/kleur \"kleur\")` for colored output\n-   [`ora`](http://npm.im/ora \"ora\") for beautiful spinners\n-   [`boxen`](http://npm.im/boxen \"boxen\") for drawing boxes around your output\n-   [`stmux`](http://npm.im/stmux \"stmux\") for a `tmux` like UI\n-   [`listr`](http://npm.im/listr \"listr\") for progress lists\n-   [`ink`](http://npm.im/ink \"ink\") to build CLIs with React\n-   [`meow`](http://npm.im/meow \"meow\") or [`arg`](http://npm.im/arg \"arg\") for basic argument parsing\n-   [`commander`](http://npm.im/commander \"commander\") and [`yargs`](https://www.npmjs.com/package/yargs \"yargs\") for complex argument parsing and subcommand support\n-   [`oclif`](https://oclif.io/ \"Open CLI Framework (oclif)\") a framework for building extensible CLIs by Heroku (`[gluegun](https://infinitered.github.io/gluegun/#/ \"gluegun\")` as an alternative)\n\n","n":0.1}}},{"i":5765,"$":{"0":{"v":"Towardsdatascience","n":1}}},{"i":5766,"$":{"0":{"v":"Representation Learning on Rdf and Lpg Knowledge Graphs","n":0.354},"1":{"v":"\n\n- [[p.hasURL]] https://towardsdatascience.com/representation-learning-on-rdf-and-lpg-knowledge-graphs-6a92f2660241\n- [[p.hasTopic]] [[t.km.knowledge-graph.lpg]]\n- [[p.hasHighlight]]\n  - it’s important to notice that Wikidata (and generally the hyper-relational paradigm) does not separate between entities and predicates used exclusively in the main triples or qualifiers, i.e., \"all predicates and entities can be used either in triple terms or qualifiers\"\n  - The field of [[graph representation learning|t.cs.ml.grl]] (GRL) is one of the fastest-growing 🚀 areas of machine learning, there is a handful of articles (a series of [posts by Michael Bronstein](https://towardsdatascience.com/@michael.bronstein), reviews ([mine](https://medium.com/@mgalkin/knowledge-graphs-iclr-2020-f555c8ef10e3), [Sergey’s](https://towardsdatascience.com/top-trends-of-graph-machine-learning-in-2020-1194175351a3)) from ICLR’20 and [NeurIPS’19](https://medium.com/mlreview/machine-learning-on-graphs-neurips-2019-875eecd41069) papers), books (by [William Hamilton](https://www.cs.mcgill.ca/~wlh/grl_book/), by [Ma and Tang](http://cse.msu.edu/~mayao4/dlg_book/)), courses ([CS224W](http://cs224w.stanford.edu/), [COMP 766](https://cs.mcgill.ca/~wlh/comp766/index.html), [ESE 680](https://gnn.seas.upenn.edu/lectures/)), and even a [GraphML Telegram channel](https://t.me/graphML) (subscribe 😉) covering basic and advanced topics.\n","n":0.094}}},{"i":5767,"$":{"0":{"v":"N Ary Relationships in Graph Databases","n":0.408},"1":{"v":"\n- [[p.hasURL]] https://towardsdatascience.com/n-ary-relationships-in-graph-databases-81ca596dac48\n- [[p.hasAuthor]] @victor-morgante\n","n":0.447}}},{"i":5768,"$":{"0":{"v":"Avoid Building a Data Platform in 2024","n":0.378},"1":{"v":"\n- https://towardsdatascience.com/avoid-building-a-data-platform-in-2024-56f0ee95da42\n- mentions: [[prdct.bpmn]] [[prdct.bpel]]\n\n## Highlights\n\n- the cloud computing model of a platform: provides developers with a platform to build, deploy, and manage applications without dealing with the underlying infrastructure.\n- The fact that we distinguish between logic and data should not steer our thinking towards an architecture with a separate application platform and data platform.\n- The business is process-driven and not data-driven as all companies eagerly try to transform to.","n":0.12}}},{"i":5769,"$":{"0":{"v":"An Enterprise Data Stack Using Typedb","n":0.408}}},{"i":5770,"$":{"0":{"v":"A Guide to Knowledge Graphs","n":0.447},"1":{"v":"\n- https://towardsdatascience.com/a-guide-to-the-knowledge-graphs-bfb5c40272f1\n\n\n![](/assets/images/2024-09-13-14-01-42.png)","n":0.707}}},{"i":5771,"$":{"0":{"v":"Topquadrant","n":1}}},{"i":5772,"$":{"0":{"v":"Why I Use Shacl for Defining Ontology Models","n":0.354},"1":{"v":"\n- https://www.topquadrant.com/resources/why-i-use-shacl-for-defining-ontology-models/\n- author: @irene-polikoff\n\n## Highlights\n\n- \"When you create a model in SHACL, you do not need to think whether you should use rdfs:subClassOf or owl:equivalentClass in defining restriction on property values.\"\n  - related: https://stackoverflow.com/questions/65052036/what-is-the-difference-between-owlequivalentclass-and-rdfssubclassof-when-maki\n    - \"Semantically, you are defining the class as Primitive (subClassOf) versus Defined (equivalentClass). The main difference is in inferencing in one or both directions.\n\n    The Primitive class is single direction:\n\n        any Thing with ShipsTo with values from Italy can be inferred to be a deliversToItaly \n    \n    The Defined class is both directions:\n        as above, and\n        any Thing that is a deliversToItay can be inferred to have shipTo with values from Italy\n\n    A Defined class is used when you are confident that you have necessary and sufficient rules for class membership - otherwise Primitive is used for necessary rules only.\"\n  - t.2024.07.11.12 but OWL doesn't define restriction in the same way as shacl\n- [ ] While you could use types from OWL to say that a property is an Object or a Datatype property, SHACL does not consider this. It will be looking only at the constraints specified in the shape e.g., datatype and class constraints!","n":0.073}}},{"i":5773,"$":{"0":{"v":"Why I Dont Use Owl Anymore","n":0.408},"1":{"v":"\n- https://www.topquadrant.com/resources/why-i-dont-use-owl-anymore/\n- author: @irene-polikoff\n- related: [[ar.topquadrant.why-i-use-shacl-for-defining-ontology-models]]\n\n## Highlights\n\n- \"The only parts of RDFS I use are subclasses.\"\n- \"OWL reasoning is primarily about classification e.g., given information about a resource we can infer what class or set it belongs to.\"\n- Key Issues:\n  - open world assumption\n  - confusion around reasoning\n  - having too much (features) and yet not enough\n\n### Open World Assumption\n\n\n### Confusion around Reasoning\n\n\n### Not Enough Features\n\n- there is still no way in it to make definitions that are very commonly needed. For example, you can’t say that:\n\n* person’s full name must equal a concatenation of their first and last names\n* duration is the difference between the end and start dates\n* start date can’t be greater than the end date\n\n  - Anything that involves some operations can’t be stated. This means that key parts of what one would commonly want to express in a model can only be written in either application code or a rules language proprietary to a given RDF tool.","n":0.079}}},{"i":5774,"$":{"0":{"v":"Toolify","n":1}}},{"i":5775,"$":{"0":{"v":"The Future of Game Development Ai and Megatrends","n":0.354}}},{"i":5776,"$":{"0":{"v":"Today","n":1}}},{"i":5777,"$":{"0":{"v":"Personality Types Average Self Centered Role Model or Reserved","n":0.333},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.today.com/health/personality-types-average-self-centered-role-model-or-reserved-t137902\n- [[p.hasAuthor]] @Meghan-Holohan\n- [[p.hasSource]] [A robust data-driven approach identifies four personality types across four large data sets] https://www.nature.com/articles/s41562-018-0419-z\n","n":0.224}}},{"i":5778,"$":{"0":{"v":"Thinkmind","n":1}}},{"i":5779,"$":{"0":{"v":"The Typed Graph Model","n":0.5},"1":{"v":"\n\n- [[p.hasURL]] http://www.thinkmind.org/articles/dbkda_2020_1_30_50016.pdf\n- [[p.hasAuthor]] @fritz-laux\n\n#hard-reading\n\n\n## #summary\n\nIn recent years, the Graph Model has become increasingly popular, especially in the application domain of socialnetworks. The model has been semantically augmented with properties and labels attached to the graph elements. It is difficult to ensure data quality for the properties and the data structure because the model does not need a schema. In this paper, we propose a schema bound Typed Graph Model with properties and labels. These enhancements improve not only data quality but also the quality of graph analysis. The power of this model is provided by using hyper-nodes and hyper-edges, which allows to present a data structure on different abstraction levels. We demonstrate by example the superiority of this model over the property graph data model of Hidders and other prevalent data models, namely the relational, object-oriented, and XML model.\n\n","n":0.085}}},{"i":5780,"$":{"0":{"v":"Theverge","n":1}}},{"i":5781,"$":{"0":{"v":"How an Excel TikToker manifested her way to making six figures a day","n":0.277},"1":{"v":"\n\n- @kat-norton [[p.used]] [[prdct.thinkific]]\n- [[p.hasHighlight]]\n  - it's all about the energy (i.e., enthusiasm, relatability, goofiness, originality) and making people feel good\n    - of course, different audiences respond differently to different energies, so\n    - it's about understanding your audience \n    - [[idea.be-yourself-but-know-your-audience]]\n  - \"My overall purpose on this planet is to light up as many people as I can while I’m here. I want everyone living their authentic purpose — feeling good, showing up, doing what they love.\"\n","n":0.114}}},{"i":5782,"$":{"0":{"v":"Thenewstack","n":1}}},{"i":5783,"$":{"0":{"v":"If I Could Start over a Real World Coder on How to Learn","n":0.277},"1":{"v":"\n- #summary\n  - believe you can\n  - humility\n  - keep learning, keep solving problems\n  - choose one language to learn deeply\n  \n","n":0.213}}},{"i":5784,"$":{"0":{"v":"Theangrygm","n":1}}},{"i":5785,"$":{"0":{"v":"A Complete Idiots Guide to Play by Post Gaming","n":0.333},"1":{"v":"\n- https://theangrygm.com/a-complete-idiots-guide-to-play-by-post-gaming/\n- topics: [[t.roleplaying.play-by-post-pbp]]\n\n## Highlights\n\n### No Dynamic Exchanges\n\n- because of the slow and asynchronous nature of the game, you need to avoid back-and-forth exchanges. It’s kind of like the difference between a debate and a negotiation.\n  - In a negotiation, there are a lot of low-content messages flitting back and forth. Negotiation is basically two people firing proposals and counter-proposals at each other over and over again until they hit one they both agree on. Messages are short and there are lots of them.  ^3i9ekyfm2c0l\n  - Contrast that with a structured debate. There’s a single talking point and each participant then delivers a speech about the topic. When they’re done, the next participant gets to deliver their own speech responding to the previous one. Then the first participant responds. And then topic is closed and a new one begins. You thus end up with small number of high-content messages. ^n4877p2jlmwz\n- There are lots of little fiddly bits like that in D&D that would make it hard to cut out the negotiational nature of action resolution. There’s lots of shit on the character sheet that interrupts and affects action resolution at various stages. Everything from, “After you roll the die, you can…” to “As a reaction, when a creature…” Not to mention all the fiddly little buffs and debuffs and conditions people can give each other.\n\n### It's Bigger Than You Think\n\n- Real, actual conversation is a rapid-fire slew of low-content messages and so are the best social interaction scenes in tabletop roleplaying games.\n- By necessity, I can’t imagine playing a naturalistic conversation in a PbP game just because it’d take a week and there is a limit on patience and pacing even for a low-commitment activity. There comes a point where every human gets bored with being trapped in the same scene for four days.\n- you’ve got to accept that things like conversations are going to play out very differently so, for example, conversations are going to be more like each characters taking turns delivering speeches and you have to play into that with how you narrate shit or you’ve got to do a mix of both. I would probably land on doing both. I’d definitely shy away from naturalistic conversation and combat both \n- But there’s another victim here because there’s another kind of low-content negotiational dynamic exchange that happens frequently at the game table and which I’d say is core to the roleplaying game experience. I’m talking here about intraparty, interplayer communication. Those are exchanges between the players as they work out their plans or try to solve problems together.\n  - e.g. hat happens at a normal game table when the party comes to an intersection and you, the GM say, “Left or right guys?” Now take that committee debate and insert four to twenty-four hours for every statement every player makes.\n- **if I were running a PbP game, I’d probably have two communication channels. One is the official channel where I narrate and adjudicate and players act and the other would be a chatter channel where the players can talk among themselves whenever and however often they want.** ^upk3ov92hyah\n\n### There’s Such a Thing as Too High-Content\n\n- a player will describe an entire sequence of actions. “I’ll say this and then do this and if that works, I’ll follow it up with this,” and so on. I have to say something like, “Let’s see how that first thing works out and then you can continue.”\n\n### Go Ahead and Split the Party\n\n- simultaneous independent actions\n  - Once I’ve got an action queued up for everyone, then I describe all the results and poll for new actions\n\n### Dungeon World or Genesys\n\n- [[game-system.pbta.dungeon-world]] \n  - Resolving an action in Dungeon World involves recognizing the moment when a player says something that requires a resolution and then using a chunk of mechanics called a Move to resolve it. So, when a player says something like, “I’ll smack the goblin with my sword” or “I examine the weird statuette to see what I can make of it,” the Game Master says, “It sounds like you’re Hacking and Slashing, roll plus Strength” or, “You’re trying to Discern Realities, roll plus Wisdom.” ^clwr7w4n7iff\n  - There’s not a lot of negotiational back-and-forth in basic action resolution and the whole game is based on just listening to natural descriptions of actions to decide how things play out.\n- [[game.genesys]]\n  - you resolve actions in Genesys by building pools from lots of different dice of different sizes marked with different symbols. There are dice for Attribute scores and dice for Skills, dice for positive and negative circumstances, and dice that represent the task’s Difficulty. The pool provides a high-content result. Success and failure are measured in degrees and you can have lucky or unlucky happenstances ride along with them. Not to mention crits and fumbles that sometimes just add to the results rather than overriding them. ^sfwe0h0ipn9l\n  - kind of clunky and clumsy to work with. Building pools takes time, interpreting the results carries a learning curve, basically everything you’d expect. But with slow, asynchronous play, those downsides don’t matter. Especially if you, the Game Master, handle the rolling yourself. You don’t work through building the pool with the player and then have them roll it — and you skip any mechanics that require negotiational back-and-forth that affect the roll or else require players to pre-choose those things — and instead just build the pool, resolve the action, and describe the result. ^2oeuqdes6i0x\n\n### Everway\n\n- [[game-system.everway]] is a weird fantasy multi-verse adventure game very steeped in a variety of ancient Earthly mythologies — particularly non-Western mythology — and based strongly on the Hermetic elements, astrology, and Tarot cartomancy. Especially Tarot cartomancy. The game comes with a special, in-universe Tarot-like deck called The Fortune Deck, which is used in character generation, plot and adventure planning, and action resolution. ^3887hkaim4hv\n- the Game Master has to focus on resolving shit a little above the individual action level. When a fight breaks out, for example, you don’t resolve individual maneuvers and attacks, but rather, you resolve gambits or sorties. ^w8gaab0id97l\n  - say the party encounters a dragon. The warrior charges into battle, the wizard casts a protection spell, and the dragon readies a gout of flame. The Game Master would resolve that whole round of action and determine how it works out for everyone involved. Depending on the card pulls, maybe the warrior is held at bay by the dragonfire, but the worst of the blast is stopped by the wizard, and the dragon is now on the offensive. \n- You resolve situations rather than individual actions. ^acaknyft4w8p\n\n## Comments\n\n- I tried PbP in the past because of its allegedly low commitment, but the reality of reading several long posts and coming up with my own paragraph of prose every day led me to bail on it within a couple of weeks. If I could get by on reading a single Discord page or less of interactions and posting a couple of sentences of my own, I would probably enjoy PbP.\n- , I could see maybe something really zoomed out, where every player contribution represents an extended amount of time. Something like The Quiet Year or some multiplayer version of Thousand Year Vampire. But at that point you’re doing a collaborative writing exercise that’s so different from a TTRPG that it’s silly to even consider it the same activity.\n- it’s a good thing real time gaming doesn’t have that prose\n\n## Thoughts\n\n- running combat by post seems horrible!\n- \n\n- [[vs.debate-vs-negotiation]]","n":0.028}}},{"i":5786,"$":{"0":{"v":"The Crazy Ones","n":0.577}}},{"i":5787,"$":{"0":{"v":"The Misfit Who Built the Ibm Pc","n":0.378},"1":{"v":"\n- https://every.to/the-crazy-ones/the-misfit-who-built-the-ibm-pc\n- topics: @don-estridge \n\n## highlights\n\nEstridge was hugely charismatic, although his personal magnetism was drawn from a different source than that of Steve Jobs at Apple or Adam Osborne at Osborne Computing. They were men who sold their own visions. They could create “a reality distortion field” around themselves (a term coined by Apple’s Bud Tribble about Jobs). They could convince you of the value of their ideas and inspire you to give everything in their service.\n\nEstridge was the polar opposite. He listened and supported. His role was to set objectives and provide people with the resources or political cover they needed. This approach inspired a different kind of loyalty from those who worked for him, but it was just as fierce. And it delivered results.\n\nSydnes, for example, recognized that competing for the home computer market meant going up against Atari and Commodore, and facing off against sharp operators like Commodore’s ruthless founder, Jack Tramiel. In order to beat the master of bargain-basement computing, IBM would have to sink down to Tramiel’s level and sell machines in the kind of discount electronics chains that IBM had always shunned. Estridge, too distant from the minutiae of the project to understand this, vetoed Sydnes’s plans.","n":0.07}}},{"i":5788,"$":{"0":{"v":"The Alexandrian","n":0.707}}},{"i":5789,"$":{"0":{"v":"Soloing Smaug the Struggle for the Soul of Dd","n":0.333},"1":{"v":"\n- url https://thealexandrian.net/wordpress/50073/roleplaying-games/soloing-smaug-the-struggle-for-the-soul-of-dd\n\n\n## Issues\n\n\n- The game holds out the promise of characters advancing into truly epic levels of power — founding kingdoms in AD&D, becoming literal gods in Basic D&D, the Epic Level Handbook in 3rd Edition, the Paragon and Epic tiers of 4th Edition — but a significant portion of the fanbase has mostly been interested in playing Aragorn and Conan\n\n## Possible Solution\n\n- Eliminate all of those high-level abilities that shred dungeons and low-level structures of play\n\n\n## References\n\n- https://www.enworld.org/threads/e6-the-game-inside-d-d.206323/","n":0.112}}},{"i":5790,"$":{"0":{"v":"Game Structures","n":0.707},"1":{"v":"\n- https://thealexandrian.net/wordpress/15126/roleplaying-games/game-structures\n- aka: scenario structure\n\n## Highlights\n\n### Two Fundamental Questions of Scenario Structure\n\n- What do the characters do?\n- How do the players do it?\n\n#### Example\n\n- a very different game structure than the traditional D&D dungeoncrawl:\n\n**Player**: I want to explore the dungeon.\n\n**GM**: Okay, make a Dungeoneering check.\n\n**Player**: I succeed.\n\n**GM**: Okay, you kill a tribe of goblins and emerge with 546 gp in loot.\n\n- that example already assumes that the PCs are fantasy heroes who do things like dungeoncrawling. Given the exact same setting and the exact same game system, they could just as easily be monarchs, dragons, farmers, magical researchers, planar travelers, gods, military masterminds, or any of a dozen other things for whom these dungeoncrawling game structures are irrelevant.\n\n### Board and Card Games\n\n","n":0.091}}},{"i":5791,"$":{"0":{"v":"Dungeons Player Mapping","n":0.577},"1":{"v":"\n- https://thealexandrian.net/wordpress/51040/roleplaying-games/dungeons-player-mapping\n\n\n## Highlights\n\n### PLAYER BEST PRACTICES\n\nFirst: Do you need a map?\n\nIf you’re a dungeon delver, only make a map if you feel like you’re getting value from it. There are plenty of smaller dungeons and dungeon-like environments where you won’t need a map. (On the other hand, if you’re having fun making the map, then have fun! That’s reason enough.)\n\nSecond: Focus on functionality over trying to capture the precise measurements and angles of the dungeon.\n\nIn fact, in many cases, you don’t need measurements at all. You can get most or all of the benefits of mapping from a simple network map: Just draw a circle for each room and then draw lines showing how it connects to other rooms.\n\nThis doesn’t mean you need to give up on the graph paper entirely, of course. It just means recognizing that most of the time the difference between a hallway that’s twenty-five feet long and a hallway that’s thirty feet long just isn’t important.\n\nOf course, there may be times when you actually need that type of precision. (For example, you might suspect that there’s a secret room hidden somewhere in the haunted house and you want to figure out where it might be.) When that happens, make a point of seeking that precision in character: What is your character actually doing to get the precise measurement that you want?\n\nThird: Map in pencil.\n\nYou’re going to make mistakes. As you explore and revisit sections of the dungeon, your knowledge of how everything fits together will grow over time. You’ll want to be able to easily adjust your maps to make all the pieces fit together.\n\nFourth: Let the GM see your map.\n\nIf the GM can easily see your map — e.g., it’s sitting on the table in front of you — it will let them quickly notice errors and give you the necessary corrections.\n\nDon’t expect the GM to fix all of your mistakes, of course. Just the ones that you wouldn’t have made if you were actually standing in the dungeon instead of just listening to a description of it.\n\nFifth: Make sure to actually USE the map.\n\nThis might seem obvious, but your goal is to not to produce an immaculate cartographical masterpiece. Take notes directly on the map, and make sure you’re sharing the map with the rest of the group as a reference and resource for decision-making: Where have we been? Where should we be going? What do we know? What do we want to find out?\n\nSixth: The map is an artifact that actually exists in the game world.\n\nYou’re mapping in the real world just like your character is mapping in the game world. Make sure your character has the supplies they need to actually make the map. Think about where and how the map is being stored.\n\nThese are small details, but you’ll find they make a big difference in letting the map literally draw you into your character.\n\nSeventh: Try not to let your mapping disrupt or distract from the rest of the game.","n":0.045}}},{"i":5792,"$":{"0":{"v":"Terminusdb","n":1}}},{"i":5793,"$":{"0":{"v":"The Semantic Web Is Dead","n":0.447},"1":{"v":"\n- https://terminusdb.com/blog/the-semantic-web-is-dead/\n- author: @gavin-mendel-gleason\n- mentions: \n  - [[t.phil.logic.doxastic]]\n  - [[ar.elaboration-in-dependent-type-theory]]\n\n## Highlights\n\n### Issues\n\n- no unique name assumption\n  - \"Aliasing is a nightmare, computationally expensive, and leads to difficult-to-understand reasoning.\"\n- [[t.cs.web.w3c.rdf.open-world-assumption]]\n- \"things are too far apart\": class definitions require \"lots of separately defined properties, each of which is verbose. When you add restrictions to them it becomes even worse\"\n- \"polluting the data with inference\"\n  - \"In [[prdct.owl]] we entail things into the graph which then looks just like the data from which it was entailed.\"\n  - \"The dream of computers that reasoned about data as it arrived to create some great symbolic AI, without a Doxastic approach is frankly silly.\"\n    - t.2024.09.12.15 so take a doxastatic approach!\n- \"Not much in the way of useable constraints, sorry\"\n  - [[prdct.shacl]] goes a long way to alleviating this problem with OWL, but then it doesn’t replace OWL. Instead of giving us a schematic ontology language, we are left with two different languages which must now be kept in sync.\n\n### The Right Way\n\n- \"Instead of all of this complexity, we should just have a standard schema language, which can be written in JSON or YAML. It should allow us to describe all of the data models in human language. It should make it easy for this to be internationalized.\"\n- \"What we need is a Literate Type Theory for JSON, which allows us to specify typed references\"\n\n## References\n\n- https://www.reddit.com/r/semanticweb/comments/wkz8un/the_semantic_web_is_dead_long_live_the_semantic/","n":0.066}}},{"i":5794,"$":{"0":{"v":"Telicent","n":1}}},{"i":5795,"$":{"0":{"v":"4d Ontology","n":0.707},"1":{"v":"\n- author: @ian-bailey\n- url:\n  - https://telicent.io/news/4d-ontology-pt1-the-why/\n  - https://telicent.io/news/4d-ontology-pt2-spacetime/\n  - https://telicent.io/news/4d-ontology-pt-3-youre-not-my-type/\n- mentions: \n  - [[prdct.information-exchange-standard-ontology]]\n  - [[prdct.business-objects-reference-ontology]]\n\n![](/assets/images/2024-07-08-13-53-16.png)\n\n## Highlights\n\n- The goal of a good ontology is provide a high fidelity model of the world you’re interested in. ^ouwrk5oa8bs3\n- 4D ontologies are extensional — objects’ extensions in spacetime define their identity.\n- Spacetime diagrams are similar to [Minkowsi diagrams](https://en.wikipedia.org/wiki/Spacetime_diagram) used in physics, but with time on the x axis and space on the y. The spatial dimension is topological, and is not attempting to reflect any distances between objects, however if an object is stationary relative to another, their [world-lines](https://en.wikipedia.org/wiki/World_line) should be parallel. In the above example, the facilities (grey world lines, strictly “world volumes”) do not move relative to each other or our frame of reference (the earth), so are parallel and flat. Spacetime diagrams feature extensively in the books [[book.developing-high-quality-data-models]] by @matthew-west and [Business Objects:re-engineering for re-use](https://borosolutions.net/sites/default/files/Business%20Objects%20-%20Re-Engineering%20for%20Re-Use%20%283rd%20Ed%20-%20early%20draft%20-%2020140927%29.pdf) by Chris Partridge.\n- Categories, sets, classes. In the various 4D ontologies that have been published, these terms have been used quite liberally with not much attempt to distinguish between them — though there are papers on this on the BORO site which provide a proper treatment. One possible reason is that the original authors of those ontologies were dabbling with different approaches to see which ones fitted the 4D approach best. There was general [set theory](https://en.wikipedia.org/wiki/Set_theory), [category theory](https://en.wikipedia.org/wiki/Category_theory), and [Martin Löf type theory](https://en.wikipedia.org/wiki/Intuitionistic_type_theory), just to mention three intersecting theories\n- The really neat thing about having an extensional approach to individuals and sets means you can ground your ontology in reality.\n- \n\n## References\n\n- [[ar.spatio-tempoarl-extents]]","n":0.064}}},{"i":5796,"$":{"0":{"v":"Swyx","n":1}}},{"i":5797,"$":{"0":{"v":"Learn in Public","n":0.577},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.swyx.io/learn-in-public/\n- [[p.hasCreator]] @swyx\n\n","n":0.447}}},{"i":5798,"$":{"0":{"v":"Substack","n":1}}},{"i":5799,"$":{"0":{"v":"Threetimeswiser","n":1}}},{"i":5800,"$":{"0":{"v":"Issue 439 Mental Lab 4-4-4 Principle","n":0.408},"1":{"v":"\n- https://threetimeswiser.substack.com/p/issue-439-mental-lab-4-4-4-principle\n- topics: [[idea.mental-lab]]","n":0.5}}},{"i":5801,"$":{"0":{"v":"Issue 422 - Attention Residue, God-of-the-Gaps Argument & Necker Cube","n":0.316},"1":{"v":"\n- https://threetimeswiser.substack.com/p/issue-422-attention-residue-god-of\n\n\n## Highlights\n\n- [[t.psych.escapism.digital]] \"...drains our [[t.psych.cognitive-bandwidth]], leaving us with less focus and genius to accomplish amazing feats\"\n  - t.2024.09.04.09 but all forms of digital escapism are not created equal.","n":0.183}}},{"i":5802,"$":{"0":{"v":"Issue 327 Stress Bucket Lottery Ticket","n":0.408},"1":{"v":"\n- https://threetimeswiser.substack.com/p/issue-327-stress-bucket-lottery-ticket","n":0.707}}},{"i":5803,"$":{"0":{"v":"Subconscious","n":1}}},{"i":5804,"$":{"0":{"v":"The Minimal Definition of User Agency","n":0.408},"1":{"v":"\n## minimal definition of user agency\n\n- Own your ID\n- Own your content\n- Own your contacts","n":0.258}}},{"i":5805,"$":{"0":{"v":"Ritual Technology","n":0.707},"1":{"v":"\n## Thoughts\n\n-   Rituals are the feedback loops we construct to construct ourselves.\n    \n-   Rituals shape the medium of time.\n    \n-   Rituals orient us.\n    \n-   Rituals are protocols.\n    \n-   Ritual is a form of play.\n    \n-   Rituals take place in a world set apart.\n    \n-   Rituals make meaning.\n\n## Highlights\n\n- \"Like all play, rituals require a suspension of disbelief. We have to be willing to play. In games studies, this stance is called the lusory attitude.\"\n- \"    All play moves and has its being within a playground marked off beforehand either materially or ideally, deliberately or as a matter of course. Just as there is no formal difference between play and ritual, so the “consecrated spot” cannot be formally distinguished from the playground. The arena, the card table, the magic circle, the temple, the stage, the screen, the tennis courts, the court of justice, etc, are all in form and function playgrounds, i.e. forbidden spots, isolated, hedged round, hallowed, within which special rules obtain. All are temporary worlds within the ordinary world, dedicated to the performance of an act apart.\n    (Johan Huizinga, 1938, “Homo Ludens”)\"\n-\"In [[t.rec.game.studies]], these worlds-within-a-world are called [[magic circles|t.rec.magic-circles]]\"","n":0.073}}},{"i":5806,"$":{"0":{"v":"Llms and Hyper Orality","n":0.5},"1":{"v":"\n- url: https://subconscious.substack.com/p/llms-and-hyper-orality\n  - \"To solve effectively the problem of retaining and retrieving carefully articulated thought, you have to do your thinking in mnemonic patterns, shaped for ready oral recurrence. Your thoughts must come into being in heavily rhythmic, balanced patterns, in repetitions or antithesis, in alliterations or assonances, in epithetic and other formulary expressions... Serious thought is intertwined with memory systems.\"\n    - _(Walter J. Ong, 1982, [Orality and Literacy](https://www.amazon.com/Orality-Literacy-30th-Anniversary-Accents/dp/0415538386))_","n":0.12}}},{"i":5807,"$":{"0":{"v":"Layered Protocols","n":0.707},"1":{"v":"\n\n- [[p.hasURL]] https://subconscious.substack.com/p/layered-protocols\n- [[p.hasAuthor]] @gordon-brander\n","n":0.447}}},{"i":5808,"$":{"0":{"v":"Decentralization","n":1},"1":{"v":"\n- https://subconscious.substack.com/p/decentralizability\n- \n\n## Highlights\n\n### What is the minimum set of mechanisms we need to make software decentralizable?\n\nSome answers will vary from project-to-project, but I see some common patterns:\n\n- Immutable data\n- Universal identifiers\n- User-controlled keys\n\n### Things fall out of sync, or rather, they were never in sync to begin with. \n\nSo, we often need mechanisms to resolve conflicting understandings of the world.\n\nInstead of trying to modify a single shared state, just pass messages. Each message is immutable—it doesn’t change after being sent. That means the message can be sent to many different places and these places don’t need to coordinate to find out if the message has changed. It won’t.\n\nHow do you represent change? Multiple messages can tell a story about how something changes. This is how Git, CRDTs, [[prdct.nostr]], and [[prdct.noosphere]] model changes.\n\n### Universal Identifiers\n\nAt some point you’re going to want to be able to identify some data independent of where it lives.\n\n  - UUID4\n  - Content hashes\n    - have a 1:1 correspondence with content\n    - self-verifying\n    - not friendly\n\n- t.2024.04.14.17 why no mention of URIs?\n\n\n## References\n\n- [[ar.substack.subconscious.the-minimal-definition-of-user-agency]]","n":0.075}}},{"i":5809,"$":{"0":{"v":"If50","n":1}}},{"i":5810,"$":{"0":{"v":"2006 Dwarf Fortress","n":0.577},"1":{"v":"\n\r\n\"a glorious celebration of the possibilities and complexities of emergent behavior, taken to a level few if any other games have achieved\"\r\n\r\n- [[p.hasURL]] https://if50.substack.com/p/2006-dwarf-fortress\r\n- [[p.isRelated]] [[game.Dwarf-Fortress]]\r\n\r\n## [[hasQuotes]]\r\n\r\n- > the game’s design is deeply informed by a practice its creators have carried out since before its first release: writing short stories set in its world, then analyzing them to see what kinds of narrative situations the game’s simulation cannot yet handle. [More than forty such stories](https://www.bay12games.com/dwarves/dev_story.html) have been posted to the Bay 12 website along with the follow-up analyses. One of the earliest, “[Cold Fire](https://www.bay12games.com/dwarves/story/tt_cold_fire.html),” begins in winter:\r\n","n":0.102}}},{"i":5811,"$":{"0":{"v":"Edge","n":1}}},{"i":5812,"$":{"0":{"v":"A New Series about Graph Neural Networks","n":0.378},"1":{"v":"\n\n- [[p.hasURL]] https://thesequence.substack.com/p/-edge195-a-new-series-about-graph?s=r\n- [[p.hasTopic]] [[t.cs.ai.neural-net.gnn]]\n","n":0.447}}},{"i":5813,"$":{"0":{"v":"Using Procrastination for Practice","n":0.5},"1":{"v":"\n- https://substack.com/@seyekuyinu/p-149233017\n\n\n## Conclusion\n\nMaybe what’s necessary is being present to every single aspect of our lives, offering even the most mundane pieces of ourselves to the Great Unknown.","n":0.192}}},{"i":5814,"$":{"0":{"v":"Provocation Driven Development","n":0.577},"1":{"v":"\n- url: https://open.substack.com/pub/subconscious/p/provocation-driven-development","n":0.577}}},{"i":5815,"$":{"0":{"v":"Distroid Issue 13 Digital Gardens","n":0.447},"1":{"v":"\r\n- [[p.hasURL]] https://distroid.substack.com/p/distroid-issue-13-digital-gardens\r\n- [[p.hasTheme]] [[t.km.digital-gardening]]\r\n","n":0.447}}},{"i":5816,"$":{"0":{"v":"Cheating Zookos Triangle","n":0.577},"1":{"v":"\n- url: https://subconscious.substack.com/p/cheating-zookos-triangle\n\n## Summary\n\n- There are three ideal properties you want from a good naming system:\n  -   **Secure.** The name reliably points to what it is supposed to, and not to an imposter.\n  -   **Decentralized**. there is no central authority in the naming system that can fail, or be corrupted.\n  -   **Human-meaningful**. The name makes sense and is memorable. [gordonbrander.com](https://gordonbrander.com/), or [@gordonbrander](https://twitter.com/gordonbrander), for example.","n":0.125}}},{"i":5817,"$":{"0":{"v":"Carpe Noctem","n":0.707}}},{"i":5818,"$":{"0":{"v":"Stanford Daily","n":0.707}}},{"i":5819,"$":{"0":{"v":"Ice Hockey to Host Lumberjacks, Sjs","n":0.408},"1":{"v":"\n\n- [[p.hasURL]] https://archives.stanforddaily.com/1995/10/19?page=8&section=MODSMD_ARTICLE28#article\n\nThis weekend, the Stanford\nice hockey team will play its\nthird consecutive set of home\ngames, hosting Northern Ari\nzona on Friday evening at 7\np.m. and San Jose State on Sat\nurday at 7:40 p.m. Leading the\nCardinal through an increas\ningly difficult schedule, head\ncoach Ernie Ferrari expects\nthis weekend's battles to be\nhard-fought and intense.\n\"I didn't think our play was\nparticularly deficient when we\nlost to Utah State, but then San\n.Jose defeated them handily,\"\nFerrari said. \"So at practice on\nMonday night, I worked our\nguys pretty hard. Pain is a\ngreat motivator, so I think we'll\nbe up for this weekend's chal\nlenge.\"\nWhile two wins would push\nthe team's record to a\nformidable 5-1, two losses\nwould leave the Cardinal at 3-3,\nand severely handicap its pur\nsuit of a berth at the national\ntournament.\nOne complicating factor in\nthis weekend's effort may be\nthe depletion of the Cardinal\ndefensive corps. With sopho\n\nmore Matt Blythe's medical\nstatus in limbo and returning\nsenior Eric Haug away inter\nviewing at medical schools, the\nteam will be expecting a stellar\ndefensive performance from\nboth its goaltenders and its\nremaining defenseman.\n\"Eric is the man,\" said for\nward Mintak Joo. \"When some\none goes in one-on-one with\nhim, you know that guy will be\ncoming out disappointed at\nbest, injured at worst — or\ninjured at best, depending on\nhow you look at it.\"\nIce-time figures reveal the\nCardinal's heavy reliance on\nHaug. In four games this season,\nhe has logged much more ice\ntime than bench time, something\nextraordinarily rare in a game as\naerobically demanding as hock\ney. Haug himself acknowledges\nthe hyperbole of his situation.\n\"What may look like unorthodox\nplay on my part may really be\nexhausted delirium,\" he said. \"I\ndon't know how long I can keep\nthat up.\"\nHut team captain Stefan\nTeitge is confident in the team's\npotency, even without Haug\nand Blythe. \"Man for man,\nwe're better than any team in\nthe league,\" he said.\n\n- [[p.creditedTo]] @elisabeth-krebs\n\n","n":0.061}}},{"i":5820,"$":{"0":{"v":"Cardinal Ice Hockey Splits Weekend Games","n":0.408},"1":{"v":"\n\nThis past weekend, the Stanford ice hockey\nteam faced off against two Utah teams at\nhome, winning the first game against Weber\nState by a score of 8-5 but losing the second to\nUtah State 7-5. With the previous weekend's\nvictories over UCLA and USC, the Cardinal\nrecord now stands at 3-1.\nStanford dictated play in the first game,\nhosted Friday night on the Cardinal's home\nice at Ice Oasis in Redwood City. Weber State\ndid not present much of a challenge to Stan\nford's offensive abilities, but it did provide a\nphysical challenge to the Cardinal constitu\ntion.\n\"Put simply, they were a dirty team,\" said\nwinger Brian Browder. \"They were all hack,\nslash, trip, clutch and grab. They play a very\n\nold-school Canadian brand of hockey, and it\nhelped them compensate for a lack of defen\nsive ability.\"\nBy way of contrast, the Cardinal faced a\nmuch more talented team on Saturday night.\nAfter jockeying for position the whole game,\nStanford found itself down by one goal in the\nclosing minutes of the third period. Coach\nErnie Ferrari tried the classic strategy of\npulling the goaltender with one minute left in\nthe game, but the extra player seemed to con\nfuse the team more than it added to its offen\nsive puissance. In the remaining seconds of\nthe match, Utah State scored on an empty net\nto clinch the victory.\n\"I don't like to lose,\" Ferrari said, \"but that\ngame was a good learning experience for us.\nUtah State is the kind of fast-skating, high\ncaliber team that Stanford is going to have to\n\ncontinue to play as we generate more atten\ntion across the nation.\"\nOne decidedly negative outcome of the\nweekend series was an injury to Cardinal\ndefenseman Matt Blythe. With a stress frac\nture to his left shin, Blythe only managed to\nplay a part of the second contest, and that\nagainst his doctor's orders.\n\"Matt is a key member of the defensive\ncorps,\" said teammate Kevin Weitske. \"Our\nother guys are good, but not so good they can\nplay without him. We can try to convert one of\nour versatile centers to compensate, but\nthey'll never have Matt's good-natured ebul\nlience.\"\nWith or without Blythe, the ice hockey\nteam will host traditionally competitive\nNorthern Arizona State this Friday evening in\nthe Lumberjacks' season opener.\n\n- [[p.hasURL]] https://archives.stanforddaily.com/1995/10/17?page=7&section=MODSMD_ARTICLE28#article\n","n":0.054}}},{"i":5821,"$":{"0":{"v":"Cardinal Ice Hockey Splits Matches against Spartans and Lumberjacks","n":0.333},"1":{"v":"\n\n- [[p.hasURL]] https://archives.stanforddaily.com/1995/10/25?page=11&section=MODSMD_ARTICLE31#article\n\nStanford's ice hockey team split its\ngames this past weekend, winning 5-3\nagainst Northern Arizona's grinding\nteam on Friday night, but falling 9-5\nto nemesis San Jose State on Satur\nday. The Cardinal now stands at 4-2, a\nrecord which assistant coach Eric\nIsrael calls \"respectable, but not com\npelling.\" Indeed, with an upcoming\nweekend series at almost unassailable\nArizona, Stanford faces the discourag\ning prospect of a .500 mark after four\npromising weeks of play.\nFriday night, the Cardinal was in\nhigh form, beating the Lumberjacks\nand receiving a rock-solid perfor\nmance by netminder Nick Lemieux.\nThe freshman goaltender repelled\nshot after shot.\n\"He played really well in his first\ngame,\" said team captain Stefan\nTeitge, \"but we thought that was just\n\na fluke. After Friday night's game,\nNick has made it clear that he is the\nnew force to be reckoned with in the\nPacific 8 Conference.\"\nOther standouts in the match\nincluded junior David Richardson,\nwho has been playing center ice on the\nchecking line this year.\n\"Dave's a killer,\" said freshman\nTom Terbell. \"Dave's a mess. But I\ncan honestly say, even though I just\njoined the team a few weeks ago, that\nFriday night's game was the best\ngame of his career. [Head] coach\n[Ernie] Ferrari stopped yelling at him\nand even gave him some time on the\npenalty kill.\"\nBut on Saturday, the Cardinal\nplayed undisciplined hockey. After\nfalling behind 4-1 in the first period,\nthe team pulled off a comeback, rally\ning to tie the score at five going into\nthe third frame. Unfortunately, the\nSpartans scored four unanswered\ngoals before the clock expired, leaving\nthe Cardinal thoroughly deflated.\n\"I'm feeling a bit acrimonious about\nthe loss,\" Ferrari said, \"especially since\nwe'll be playing the toughest team in\nthe West this weekend.\nAt Arizona, they usually have about\n5,000 belligerent fans. If I have any say\nin it, there are going to be about 5,000\npeople crying in the streets next Satur\nday night.\"\n\n","n":0.06}}},{"i":5822,"$":{"0":{"v":"Stackoverflow","n":1}}},{"i":5823,"$":{"0":{"v":"What S the Precisest Term for Verbs That Belong to the Same Stem without Any Affixes","n":0.25},"1":{"v":"\n\nWhat's the precisest term for verbs that belong to the same stem without any affixes\n","n":0.258}}},{"i":5824,"$":{"0":{"v":"Squishy","n":1}}},{"i":5825,"$":{"0":{"v":"The Zombocom Problem","n":0.577},"1":{"v":"\n- https://newsletter.squishy.computer/p/the-zombocom-problem\n- author: @gordon-brander\n\n\n## Highlights\n\nMany attempts at no-code, [[t.cs.sd.low-code]], nodes-and-wires, end-user programming, wikis, malleable software, [[t.cs.sd.moldable-development]], super apps, protocols, and platforms have failed because of the Zombocom Problem.","n":0.189}}},{"i":5826,"$":{"0":{"v":"Nature’s Many Attempts to Evolve a Nostr","n":0.378},"1":{"v":"\n- https://newsletter.squishy.computer/p/natures-many-attempts-to-evolve-a\n- author: @gordon-brander\n\n## Highlights\n\n- [[prdct.nostr]] is [[t.cs.sd.architecture.relay]]: ^1fayi8skch8g\n  -   **Relays are simple**. They use boring technology, like plain old servers. You benefit from all of the tailwinds of traditional app development.\n      \n  -   **Relays take advantage of economies of scale**. Big dumb servers in the cloud have high availability and high uptime, and they’re commodity infrastructure.\n      \n  -   **Relays sidestep the N^2 scaling problem**: Relays don’t talk to each other, and users only need to join a few relays, and will probably join less than a dozen. We never really hit the scale where the n^2 scaling problem matters.\n      \n  -   **Relays support user-ownership**. Users own their data, own their account, and most importantly, [they own their keys](https://newsletter.squishy.computer/p/the-minimal-definition-of-user-agency). If a relay goes down or shuts you down, no problem! Your account doesn’t change, and your data is mirrored to other relays. [Credible exit](https://newsletter.squishy.computer/p/credible-exit)!","n":0.083}}},{"i":5827,"$":{"0":{"v":"Sparna","n":1}}},{"i":5828,"$":{"0":{"v":"Semantic Markdown","n":0.707},"1":{"v":"\n\n- [[p.hasURL]] http://blog.sparna.fr/2020/02/20/semantic-markdown/\n- [[p.references]] https://blogs.pjjk.net/phil/metadata-for-markdown-mkdocs/\n- mentions [[prdct.ocxmd]]\n\n## Issues\n\n\n","n":0.354}}},{"i":5829,"$":{"0":{"v":"Smashing","n":1}}},{"i":5830,"$":{"0":{"v":"Thoughts on Markdown","n":0.577},"1":{"v":"\n- url: https://www.smashingmagazine.com/2022/02/thoughts-on-markdown/\n- ","n":0.577}}},{"i":5831,"$":{"0":{"v":"Multiplayer Text Adventure Engine Node.js","n":0.447},"1":{"v":"\n- url: https://www.smashingmagazine.com/2018/12/multiplayer-text-adventure-engine-node-js/\n- author: @fernando-doglio\n\n","n":0.447}}},{"i":5832,"$":{"0":{"v":"Semiceu","n":1}}},{"i":5833,"$":{"0":{"v":"DCAT-AP 3.0","n":0.707},"1":{"v":"\n- https://semiceu.github.io/DCAT-AP/releases/3.0.0/","n":0.707}}},{"i":5834,"$":{"0":{"v":"Sebaslab","n":1}}},{"i":5835,"$":{"0":{"v":"Whats New in Svelto Ecs 3 0","n":0.378},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.sebaslab.com/whats-new-in-svelto-ecs-3-0/\n- [[p.hasSubject]] [[prdct.svelto-ecs]]\n- [[p.hasHighlight]]\n  - SECS has been designed to push the user mentality away from the classic definition of an entity being just an ID. SECS instead promotes the conceptual aspect of an entity. Personally, I like to have the rule that an entity must reflect a design entity that the user can experience. In doing so, the name of the entity usually comes from the Game Design Document. This also promotes ubiquitous language between designers and coders. \n","n":0.11}}},{"i":5836,"$":{"0":{"v":"The Quest for Maintainable Code and the Path to Ecs","n":0.316},"1":{"v":"\n\n\n- [[p.hasTopic]] [[t.cs.programming.code-reuse]] [[t.cs.entity-component-system]] [[t.cs.programming.SOLID]]\n- [[p.recommended]] [Entity Component System - A Different Approach to Game / Application Development](https://www.youtube.com/watch?v=lt4eL4RSx7k)\n- [[p.hasAuthor]] @sebas77\n","n":0.224}}},{"i":5837,"$":{"0":{"v":"Screenrant","n":1}}},{"i":5838,"$":{"0":{"v":"D&D Using AI Is More Proof That Hasbro Doesn't Understand Dungeons & Dragons Fans","n":0.267},"1":{"v":"\n- https://screenrant.com/dnd-ai-controversy-dungeons-and-dragons-fans-hasbro/\n- author: @lee-damato\n\n## Highlights\n\n- The problem, though, is that for most players, imagination and creativity are half the fun of D&D. At the end of the day, a D&D campaign fills the same niche as an impromptu playground game. The only difference between running around the schoolyard playing cops and robbers and a high-level D&D campaign is the scant structure provided by the latter's rules - and most DMs are even willing to bend those in favor of the rule of cool. The most delightful parts of every D&D session always hinge on players' creative solutions to a campaign's conundrums, and the most exciting parts on a story's carefully crafted twists and turns.\n- Relying on generative AI sucks all the fun out of these best aspects of a D&D campaign. Even the worst player-made art is a source of joy and inspiration; AI-generated portraits are sterile by comparison, lacking the character of a shoddily-drawn Microsoft Paint portrait. Even the most [[contrived plot|t.storytelling.plot.contrived]] twist can provoke gasps from a sufficiently invested table; AI-generated emergent storytelling is cheap by comparison, and that's assuming it's even capable of coming up with sensible plots. Even the most cliché D&D character idea can serve as a jumping-off point for a complex arc filled with deep, emotionally fraught character development; AI-generated characters are distant by comparison.\n- Ultimately, [[org.hasbro]] overestimates the importance of D&D's rules to the average player's enjoyment. If all the official and officially licensed D&D tools like Roll20, Avrae, and Beyond become laden with useless AI tools that clog up their interfaces and stifle player creativity, many will choose to look elsewhere. After all, the one thing every tabletop RPG has in common, from high fantasy alternatives like Pathfinder to complete genre upsets like Call of Cthulhu or Deadlands, is an encouragement of creativity. And players who appreciate that won't hesitate to look elsewhere.\n- Executives in every quadrant of the gaming industry continue to insist that AI is here to stay. But a large segment of players have consistently made it clear that they don't want generative AI in games. When used in the actual process of development, it decreases the quality of art and writing, and takes lucrative work opportunities away from talented artists. When used in the creation of homebrew tabletop content, it's simply not as fun. Whether each individual player decides to use Dungeons & Dragons' AI features will come down to personal preference, but Hasbro may be overestimating the number of players who will opt in.\n","n":0.049}}},{"i":5839,"$":{"0":{"v":"Risingstack","n":1}}},{"i":5840,"$":{"0":{"v":"Event Sourcing with Examples Node.js at Scale","n":0.378},"1":{"v":"\n- [[p.hasURL]] https://blog.risingstack.com/event-sourcing-with-examples-node-js-at-scale/","n":0.577}}},{"i":5841,"$":{"0":{"v":"Reddit","n":1}}},{"i":5842,"$":{"0":{"v":"Semanticweb","n":1}}},{"i":5843,"$":{"0":{"v":"Best Ontology Development Environment Tool?","n":0.447},"1":{"v":"\n- https://www.reddit.com/r/semanticweb/comments/1fqec66/best_ontology_development_environment_tool/\n- mentions: [[prdct.atomicserver]]\n- posted: 2024-09-26\n- creator: @daniel-bakas\n\n\n## Discussion\n\n### Protege limitations according to @speckledlemon:\n\n-   The visualization and most of the UI is intuitive for me as someone who prefers CLIs, but there are no ways to visualize the ontology graph (doesn't bother me much) and the distinction between what options are available in the main menus versus context menus is unclear (bothers me a lot). The UI for saving to different formats is annoying.\n    \n-   No SHACL support.\n    \n-   Integration with reasoners seems good, though I've only used Hermit. I like the UI for inference explanations.\n    \n-   My main problem is that it is decently buggy (views don't update without manually clicking) and, when the reasoner is active, painfully slow. Some of it may be due to a poorly-constructed ontology, but it's noticeable even with the pizza example just clicking between the different classes. Imports of ontologies from other local files doesn't happen automatically even though Protege knows about them in the catalog. I'm sure there are other things.\n\nIf there was another option that cost money but would tell me up front how much a personal license cost, I'd probably go for that. For \"high-impact big scale\" projects I would definitely not be using Protege.\n\n","n":0.07}}},{"i":5844,"$":{"0":{"v":"Net Compatible Scripting Languages for Users to Write Their Own Scripts to Query Manipulate Objects Properties in the App","n":0.229},"1":{"v":"\n- url: https://www.reddit.com/r/csharp/comments/whkweb/netcompatible_scripting_languages_for_users_to/\n- ","n":0.577}}},{"i":5845,"$":{"0":{"v":"Are There Game Engines That Use a Functional Programming Language for Scripting","n":0.289},"1":{"v":"\n- https://www.reddit.com/r/gamedev/comments/17jl96h/are_there_game_engines_that_use_a_functional/\n- mentions: [[prdct.nu]] [[prdct.game-oriented-assembly-lisp]] [[prdct.skookumscript]] [[prdct.godot-kotlin-jvm]]","n":0.378}}},{"i":5846,"$":{"0":{"v":"Readwise","n":1}}},{"i":5847,"$":{"0":{"v":"A System for Writing","n":0.5},"1":{"v":"\n- https://read.readwise.io/read/01j3b1jhcfgdn26wacyba1670t\n- author: @bob-doto\n\n## Summary\n\n- Capture ideas in the form of fleeting and/or reference notes.\n- Turn these captures into individual main notes.\n- Establish connections between the ideas recorded in these main notes.\n- Keep track of developing trains of thought in hub notes, structure notes, and indexes.\n- Turn these trains of thought into writing.","n":0.137}}},{"i":5848,"$":{"0":{"v":"Qz","n":1}}},{"i":5849,"$":{"0":{"v":"Decades of Failing to Recognize Adhd in Girls Has Created a Lost Generation of Women","n":0.258},"1":{"v":"\n\n- [[p.hasURL]] https://qz.com/592364/decades-of-failing-to-recognize-adhd-in-girls-has-created-a-lost-generation-of-women/\n- [[p.hasTheme]] [[t.psych.attention-deficit-disorder]]\n- [[p.hasHighlight]]\n  - symptoms in girls:\n    - a tendency toward daydreaming\n    - trouble following instructions\n    - making careless mistakes on homework and tests.\n","n":0.192}}},{"i":5850,"$":{"0":{"v":"Psychologytoday","n":1}}},{"i":5851,"$":{"0":{"v":"The Sixth Model of Personality","n":0.447},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.psychologytoday.com/us/blog/rethinking-mental-health/202110/the-sixth-model-personality\n- [[p.hasAuthor]] @eric-maisel\n","n":0.447}}},{"i":5852,"$":{"0":{"v":"Psu","n":1}}},{"i":5853,"$":{"0":{"v":"Decision Time in Temporal Databases","n":0.447},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.paper]]\n- [[p.hasURL]] https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.50.8187&rep=rep1&type=pdf\n- [[p.hasAuthor]] @mario-nascimento @margaret-eich\n- [[p.hasTheme]] [[t.cs.data.temporality]]\n- [[p.hasSubject]] [[t.cs.data.temporality.decision-time]]\n- [[p.hasTopic]] [[t.cs.data.temporality.valid-time]] [[t.cs.data.temporality.transaction-time]]\n- [[p.hasSummaryPoints]]\n  - [[p.proposedSolution]] combining the transaction-time index and the decision-time index into a single index\n    - [[p.hasApplication]] [[t.cs.data.DBMS.RDBMS]]\n\n![](/assets/images/2021-11-29-05-35-58.png)\n\n![](/assets/images/2021-10-18-22-33-28.png) \n","n":0.171}}},{"i":5854,"$":{"0":{"v":"Pragmaticengineer","n":1}}},{"i":5855,"$":{"0":{"v":"Job Ads for Software Engineers","n":0.447},"1":{"v":"\n- url: https://blog.pragmaticengineer.com/job-ads-for-software-engineers/\n  \n\n---\n# Job Ads to Hire Software Engineers: My Advice\n\nI've been running [The Pragmatic Engineer Job board](https://pragmatic-engineer.pallet.com/jobs) for several months. This is a job board targeted at software engineers and engineering managers. It's one of the few job boards with a money-back guarantee in case of no qualified applicants: and I've issued 4 full refunds from about ~100 job posts. I've analyzed posts that have done exceptionally well, and those that did poorly.\n\n**This post collects my advice on how to write a job posting that is more likely to get qualified applicants in the current, hot hiring market.** I also share reasons I observed job posts get no qualified applicants.\n\n## Characteristics Well-Performing Job Ads Share\n\nThe best-performing job posts shared several of these:\n\n-   **Above market salary, advertised.** The simplest and most effective way to get an outsized number of applicants - and many qualified ones - is to pay well, and be specific about it. For examples of the ranges that are competitive, see my article [A CTO's Guide to Remote Compensation Strategies](https://newsletter.pragmaticengineer.com/p/remote-compensation-stratgies?s=w).\n-   ****Salary range.**** Posts that listed a range got **3-5x** as many applications as ones that do not list one. The more competitive the range, the more applications. My theory is that when a company not known to most people does not post a range, most people assume that the range is low. Saying salary is \"competitive\" makes people assume the salary is in the bottom tier of the [trimodal compensation model](https://blog.pragmaticengineer.com/software-engineering-salaries-in-the-netherlands-and-europe/).\n-   **A strong brand**. For companies which are well-known tech organizations, they see far more inbound even if they ignore much of the advice in this list. Even more, many of these companies see healthy traffic for their own career pages, making it less important to advertise roles that are not specialist ones. If your company is a startup or lesser known, this naturally does not apply.\n-   ****Reduce the number of \"must have\".**** The more expectations you list, the fewer applicants will apply. Try to keep this list as low and reasonable as possible.\n-   ****Selling as well, not just listing expectations.**** Unless your company is well-known in the industry, sell the position in the posting as well. The mission, what people joining will own and what they will learn.\n-   ****Interview process lightweight enough and explained****. Posts that make it clear what the interview process is tend to get more applications - especially when the process is lightweight. While there is no shortage of people who will go through an 8-step process at Google to get a $500K/year position, most people will not engage with places that have heavyweight processes and do not compensate similar to Big Tech.\n-   **Offer remote and target a larger region.** If you can accommodate remote applicants from a region like the US or EU, you'll see more response than if you're only hiring in a given city. While it's understandable to have preferences, posts that get better response rates which are hybrid setups often list their main city and leave a remote option within the timezone open as well, as they feel out the market.\n-   **Inclusive language**. Avoid language that puts off certain groups from applying. Read more advice about [hiring - and retaining - a diverse engineering team](https://blog.pragmaticengineer.com/hiring-a-diverse-engineering-team/).\n-   **Get in front of more eyeballs.** Once you have a job ad, you need to get it in front of many people so it catches the attention for those who are passively - or actively looking. To get the attention of those looking actively: post on job boards. To capture passive folks: post on channels they are present. For example, my featured jobs show up on the bottom of this blog and on my Twitter. There are other job boards which advertise on surfaces outside the job board.\n\nFor more advice on writing a job advert and defining a hiring process, see my articles [Hiring a Software Engineer](https://newsletter.pragmaticengineer.com/p/hiring-software-engineers?s=w) and [Hiring an Engineering Manager](https://newsletter.pragmaticengineer.com/p/hiring-engineering-managers?s=w).\n\n## Characteristics Poorly Performing Job Ads Share\n\nThe type of job ads that got very few, or no qualified candidates typically had one or more of these:\n\n-   **Targeting small markets (cities) AND no salary or low salary.** A company listing a posting for a software engineer to work from _only_ from onsite in Amsterdam, listing a salary considered low for a senior engineer (€50-70K) saw no applicants. Another listing to hire only in Lisbon and Barcelona, and with no salary range also saw no applicants.\n-   **Asking for too many expectations  AND not sharing a competitive salary range.**\n\n<iframe id=\"twitter-widget-0\" scrolling=\"no\" allowtransparency=\"true\" allowfullscreen=\"true\" class=\"\" style=\"position: static; visibility: visible; width: 550px; height: 719px; display: block; flex-grow: 1;\" title=\"Twitter Tweet\" src=\"https://platform.twitter.com/embed/Tweet.html?creatorScreenName=GergelyOrosz&amp;dnt=false&amp;embedId=twitter-widget-0&amp;features=eyJ0ZndfdGltZWxpbmVfbGlzdCI6eyJidWNrZXQiOltdLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X2ZvbGxvd2VyX2NvdW50X3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0ZndfdHdlZXRfZWRpdF9iYWNrZW5kIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd19yZWZzcmNfc2Vzc2lvbiI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0Zndfc2hvd19idXNpbmVzc192ZXJpZmllZF9iYWRnZSI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfbWl4ZWRfbWVkaWFfMTU4OTciOnsiYnVja2V0IjoidHJlYXRtZW50IiwidmVyc2lvbiI6bnVsbH0sInRmd19leHBlcmltZW50c19jb29raWVfZXhwaXJhdGlvbiI6eyJidWNrZXQiOjEyMDk2MDAsInZlcnNpb24iOm51bGx9LCJ0ZndfZHVwbGljYXRlX3NjcmliZXNfdG9fc2V0dGluZ3MiOnsiYnVja2V0Ijoib24iLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3ZpZGVvX2hsc19keW5hbWljX21hbmlmZXN0c18xNTA4MiI6eyJidWNrZXQiOiJ0cnVlX2JpdHJhdGUiLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3Nob3dfYmx1ZV92ZXJpZmllZF9iYWRnZSI6eyJidWNrZXQiOiJvbiIsInZlcnNpb24iOm51bGx9LCJ0ZndfbGVnYWN5X3RpbWVsaW5lX3N1bnNldCI6eyJidWNrZXQiOnRydWUsInZlcnNpb24iOm51bGx9LCJ0Zndfc2hvd19nb3ZfdmVyaWZpZWRfYmFkZ2UiOnsiYnVja2V0Ijoib24iLCJ2ZXJzaW9uIjpudWxsfSwidGZ3X3Nob3dfYnVzaW5lc3NfYWZmaWxpYXRlX2JhZGdlIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH0sInRmd190d2VldF9lZGl0X2Zyb250ZW5kIjp7ImJ1Y2tldCI6Im9uIiwidmVyc2lvbiI6bnVsbH19&amp;frame=false&amp;hideCard=false&amp;hideThread=true&amp;id=1514531916610998275&amp;lang=en&amp;origin=https%3A%2F%2Fblog.pragmaticengineer.com%2Fjob-ads-for-software-engineers%2F&amp;sessionId=b9c7a46fdeea2696298d2afc26e0cbfdd2434589&amp;siteScreenName=GergelyOrosz&amp;theme=light&amp;widgetsVersion=aaf4084522e3a%3A1674595607486&amp;width=550px\" data-tweet-id=\"1514531916610998275\" frameborder=\"0\"></iframe>\n\n-   **Offer too low a salary.** A company in the US advertising a mid-level position as \"$100K+\" got no qualified candidates. Most candidates assumed they pay $100K, which is too low for this market. If you can pay up to $180K, say \"$100-180K\". A wide range is not ideal: but it is better than a very low number.\n-   **Suggest that knowing the local language is a massive advantage.** A company that added how speaking fluent Turkish is a big plus saw no qualified applicants. They were basically telling people if you don't speak Turkish you'll be singled out, as everyone else already does.\n-   **80% asking for things, and 20% or less selling the position**. Unless you're a well-known brand you need to sell yourself as part of the job ad. This job market is not a company's market: it's a job seeker's market.\n\nI hope these pieces of advice help in crafting a great job ad. For more tips, see my article [Hiring Software Engineers](https://newsletter.pragmaticengineer.com/p/hiring-software-engineers?s=w).\n\nIf you're a hiring manager working at a company with a great engineering culture, and want to reach software engineers and engineering managers both actively and passively looking: consider posting a featured job on [The Pragmatic Engineer Job Board](https://blog.pragmaticengineer.com/job-board-testimonials/).\n\n___\n\n### Featured Pragmatic Engineer Jobs\n\n1.  [Founding Engineer, Front End and API](https://pragmatic-engineer.pallet.com/jobs/8ce9f426-1323-4da4-93b6-8e089a7674e7) at Causal. **$175-225K** + equity. Boston.\n2.  [Senior Software Engineer](https://pragmatic-engineer.pallet.com/jobs/46f63163-1fd2-4cbf-9f8d-9fb9cd15e2fb) at Portchain. Coppenhagen or Remote (EU).\n3.  [Engineering Team Lead](https://pragmatic-engineer.pallet.com/jobs/86ba267b-fb57-4381-8df3-627d65ca3eea) at Portchain. Coppenhagen or Remote (EU).\n4.  [Software Engineer - Infrastructure & SRE](https://pragmatic-engineer.pallet.com/jobs/4d5adfdb-9633-43cd-bce2-794751ddef19) at Koyeb. **€71-105K** + equity. Remote (Global).\n5.  [Software Engineer - Service Mesh & Networking](https://pragmatic-engineer.pallet.com/jobs/6f867847-1640-468d-887d-801cac7839d1) at Koyeb. **€75-105K** + equity. Remote (EU).\n6.  [Security Lead](https://pragmatic-engineer.pallet.com/jobs/36918cfe-c66a-4150-8f6b-2ffda7cb7bcb) at Conjecture. **£85-210K**. London.\n7.  [Senior Software Engineer](https://pragmatic-engineer.pallet.com/jobs/70971a38-1888-4372-830e-a9ee1da1b6fc) at Consensus. Boston, MA or Remote (US).\n8.  [Senior Frontend Engineer](https://pragmatic-engineer.pallet.com/jobs/cbde1b5c-b402-4b3d-b973-dafa086adcef) at Plain. **£75-110K**. Remote (Europe / 2 hours within GMT).\n9.  [Lead iOS Engineer](https://pragmatic-engineer.pallet.com/jobs/ca11f2d5-c0a1-4c58-a09a-58ad81ca8c17) at Polarsteps. Amsterdam or the Netherlands.\n10.  [Distributed Systems Staff Engineer](https://pragmatic-engineer.pallet.com/jobs/82ce46c2-ab1b-4191-9e0b-0cd3468c977e) at Reframe Technologies. Remote (Global).\n11.  [Senior Software Engineer](https://pragmatic-engineer.pallet.com/jobs/d466aa9a-f383-4906-8e8a-b66ea7a2df2a) at Karat Financial. **$160-225K**. Remote (US time zones).\n12.  [Senior Backend Engineer - Ruby](https://pragmatic-engineer.pallet.com/jobs/4557e9e7-89d3-42ad-a9d0-eae5717c9497) at Rise Calendar. **€80-120K** + equity. Remote (Europe). [I'm an investor.](https://blog.pragmaticengineer.com/investing)\n13.  [Senior DevOps Engineer](https://pragmatic-engineer.pallet.com/jobs/92ebbb09-bc98-49b1-8ca8-a280434c490a) at Droit. **$170-205K**. New York.\n14.  [Senior DevOps Engineer](https://pragmatic-engineer.pallet.com/jobs/227a06a0-801c-4bd9-a6c1-03b7f82e384c) at Droit. London.\n15.  [Full Stack Engineer](https://pragmatic-engineer.pallet.com/jobs/87f450db-98bc-4eec-b517-4f938d96b6d9) at Applied. **£45-69K**. London or Remote (UK).\n16.  [Solution Engineer](https://pragmatic-engineer.pallet.com/jobs/796be272-f2e7-4f6b-8361-49db49dce543) at Pigment. **$90-180K**. New York or Toronto.\n17.  [Senior Backend Engineer](https://pragmatic-engineer.pallet.com/jobs/95cfdba7-26cf-4ed9-8b8b-ac81ee7edcd1) at Pigment. **€60-130K**. Paris.\n18.  [Senior Engineering Manager](https://pragmatic-engineer.pallet.com/jobs/2ac8b7d9-1884-45de-be3f-83955485764f) at Whimsical. **$185K** + equity. Remote (US, Canada).\n19.  [Engineering Manager](https://pragmatic-engineer.pallet.com/jobs/06cc5003-00b1-4647-a0d1-7fdb96c1842a) at Bobsled. **$170-190K**. Remote (US, Europe, South America).\n\n_The above jobs score at least 10/12 on [The Pragmatic Engineer Test](https://blog.pragmaticengineer.com/pragmatic-engineer-test/). Browse more senior engineer and engineering leadership roles with great engineering cultures, or add your own on [The Pragmatic Engineer Job board](https://pallet.xyz/list/pragmatic-engineer/jobs) and apply to join [The Pragmatic Engineer Talent Collective](https://pragmatic-engineer.pallet.com/talent)._\n","n":0.029}}},{"i":5856,"$":{"0":{"v":"Potsdam","n":1}}},{"i":5857,"$":{"0":{"v":"Abedjan_diss","n":1},"1":{"v":"\n\n\n- [[p.subClassOf]] [[c.thesis]]\n\n- [[p.hasURL]] https://publishup.uni-potsdam.de/opus4-ubp/frontdoor/deliver/index/docId/6955/file/abedjan_diss.pdf\n","n":0.447}}},{"i":5858,"$":{"0":{"v":"Plainenglish","n":1}}},{"i":5859,"$":{"0":{"v":"Composition Alone Cant Replace Inheritance","n":0.447},"1":{"v":"\n\n- [[p.hasURL]] https://javascript.plainenglish.io/composition-alone-cant-replace-inheritance-606760f03d60\n- [[p.hasTopic]] javascript [[t.cs.programming.code-reuse]]\n- [[p.hasSummaryPoints]]\n  - Sometimes, you simply want to have all of your shared methods exist flat on the same object as you would get with inheritance.\n    - But with P.A.I.L restrictions: \n      - private\n        - You are using inheritance purely for code reuse, not for public hierarchies.\n      - base classes abstract\n      - Isolate your base and child classes. Your base and child classes should be completely oblivious of the properties the other class provides. A child class should never override a base class’s methods or even access a property inherited from the base class, and a base class should never expect a child class to provide a missing method implementation\n      - last resort. Only use restricted inheritance when no other options are good enough. Inheritance should be a dusty tool in the far corner of your tool shed\n\n","n":0.084}}},{"i":5860,"$":{"0":{"v":"Pjjk","n":1}}},{"i":5861,"$":{"0":{"v":"Fruitful Rdf Vocabularies Are like Cherries Not Bananas","n":0.354},"1":{"v":"\n## Highlights\n\n- \"“don’t cherry-pick”, that is: when you borrow or reuse a term from a vocabulary you must comply with everything that the–let’s use the O word here–ontology in which it was defined says about it. That’s not just the textual definition of the term but all that is entailed by statements about domain, range, relationships with other properties and so on. If the original ontology defines, directly or indirectly, “familyName” as being the name of a real person, then don’t use it for fictional characters.\"\n- \"Define terms in such a way that they are free from too much baggage: you can always add that later, if you need it, but others can be left to add their own. One example of this is the way in which many Dublin Core Terms are defined without a rdfs:domain declaration.\"\n- \"The approach taken by schema.org in some ways goes further by not using rdfs:domain and rdfs:range but instead defining domainIncludes and rangeIncludes where the value is “a class that constitutes (one of) the expected type(s)” (my emphasis): by being non-exclusive domainIncludes and rangeIncludes provide a hint at what is expected without saying that you cannot use anything else.\"","n":0.071}}},{"i":5862,"$":{"0":{"v":"Osti","n":1}}},{"i":5863,"$":{"0":{"v":"Phoenix a Scalable Streaming Hypergraph Analysis Framework","n":0.378},"1":{"v":"\n- url: https://www.osti.gov/servlets/purl/1830117\n- [[p.mentioned]] [[prdct.hypernetx]]","n":0.447}}},{"i":5864,"$":{"0":{"v":"Opencog","n":1}}},{"i":5865,"$":{"0":{"v":"Graphs, Metagraphs, Ram, Cpu","n":0.5},"1":{"v":"\n\n- [[p.hasURL]] https://github.com/opencog/atomspace/blob/master/opencog/sheaf/docs/ram-cpu.pdf\n- [[p.hasAuthor]] @linas-vepstas\n- [[p.hasSummaryPoints]]\n  - there are two kinds of metatrees:\n    - data (immutable)\n    - databases (mutable)\n  - atoms: nodes (vertexes) or links (edges)\n- [[t.psych.motivation]] (seeing the judge call for the next case after a lawyer drops dead) vs inspiration","n":0.154}}},{"i":5866,"$":{"0":{"v":"Ontopia","n":1}}},{"i":5867,"$":{"0":{"v":"Curing the Web's Identity Crisis","n":0.447},"1":{"v":"\n\n\n- [[hasSubHeading]] Subject Indicators for RDF\n- [[p.hasURL]] https://ontopia.net/topicmaps/materials/identitycrisis.html\n- [[p.hasAuthor]] @Steve-Pepper @Sylvia-Schwab\n\n## [[p.makesDebatableClaim]]\n\n- > Ontologies and taxonomies will not be reusable unless they are based on a reliable and unambiguous identification mechanism for the things about which they speak. \n\n## [[p.hasSource]]\n\n- [Identity Crisis](https://www.xml.com/pub/a/2002/09/11/deviant.html)\n\n## [[p.hasCitation]] \n\n- [[[Published Subjects - Definitions, Requirements and Examples]()]]\n\npublished-subjects-definitions-requirements-and-examples\n","n":0.14}}},{"i":5868,"$":{"0":{"v":"Ontologist","n":1}}},{"i":5869,"$":{"0":{"v":"Classes Categories Types and Shapes","n":0.447},"1":{"v":"\n- https://ontologist.substack.com/p/classes-categories-types-and-shapes\n\n## Summary\n\n- \"an instance describes a given entity describing relevant characteristics (properties + values), while a class is an abstraction of that entity describing relevant properties alone.\"\n  - t.2024.10.14.10 what?! posted a request for clarification.\n- bottom-up approach - the subordinate class or concept is the originator of the relationship (in the subject or first position), and the superordinate class or concept is in the right-hand position.\n\n### category vs class\n\nWhat differentiates a category from another class is that the instances of that class are themselves classes:\n\n```turtle\nCategory: rdfs:subClassOf rdfs:Class .\nDomestication: a Category: .\nDomestication:Wild a Domestication: .\n```\n\nThis relationship is different than for entities:\n\n```turtle\nEntity: a rdfs:Class .\nAnimal: rdfs:subClassOf Entity: .\nAnimal:Fox a Entity: .\n```\n\nThis distinction is subtle but important. Entity classes are specialized through subclass inheritance (an `Animal:` and a `Fox:` are both entities with a `Fox:` being a specialized kind of `Animal`:) and can be quite deep. Categories generally have a few broad specializations (such as units or enumerations), but are typically quite shallow.","n":0.079}}},{"i":5870,"$":{"0":{"v":"Ontola","n":1}}},{"i":5871,"$":{"0":{"v":"Ordered Data in Rdf","n":0.5},"1":{"v":"\n- https://ontola.io/blog/ordered-data-in-rdf\n\n## Highlights\n\n- json-ld arrays are rdf:List\n\n### tl;dr\n\n**RDF Containers:**\n\n-   Come in three forms: `rdf:Seq` (ordered), `rdf:Bag` (unordered), `rdf:Alt` (alternatives with default)\n-   You can add new items by simply adding RDF triples\n-   Inserting items is hard: requires rewriting _many_ statements\n-   Must be stored in a single graph / machine / server (centralized)\n-   Have a formally unknown ending (open world assumption)\n\n**RDF Collections:**\n\n-   An ordered chain of `rdf:List` resources\n-   You have to edit / remove statements before you can add new items\n-   Inserting items is easy: requires changing _just a few_ statements\n-   Can span many graphs / machines / servers (decentralized)\n-   Have a known ending (the `rdf:nil`)","n":0.098}}},{"i":5872,"$":{"0":{"v":"Full Stack Linked Data","n":0.5},"1":{"v":"\n- https://ontola.io/blog/full-stack-linked-data\n- related: [[prdct.ndjson]]\n\n\n## Highlights\n\n- CTO @thom-van-kalkeren thoroughly studied the principles behind REST, HATEOS and Hypermedia, and concluded that we need to give everything URLs. Not just the pages that we present to our users, but every single thing that can be used by a client - including menu items, buttons, actions and form fields.\n- [[prdct.linked-delta]]\n- the RDF representation of data can be created during serialization - so your app can create linked data without using a triple store! ^mzabxzsavtsd\n\n### Why Linked Data?\n\n-   **Browsable**. Using links for everything in data, means that data can be surfed like how web pages work: just follow the URLs. That's actually really helpful in a web application, since this means that the client no longer needs to be aware of your routing logic.\n-   **Flexibility**. Everything can be serialized to various formats (JSON, XML, Turtle, N-Triples, and [more](https://ontola.io/blog/rdf-serialization-formats/)), which gives some really nice and flexible export functionality.\n-   **Self-describing APIs**. Simply use content-type negotiation to fetch a resource as HTML or some RDF format, and browse the data like you would browse a website: by following the links. API docs become kind of unnecessary, since navigating the website shows you all the endpoints.\n-   **Re-use other linked data**. Because links can point to _anywhere_ (not just your server), you can use all the publicly available linked data! This, for me, has always been the number one reason to believe in Linked Data.\n-   **Enables true data ownership**. Because of this, it enables _decentralized networks_ where people _own their data_, which can help to combat the existing web oligopoly. That's what the [Solid project](https://ontola.io/solid) is all about.\n-   \n\n### Why not use SPARQL?\n\n- [[prdct.sparql]] is the de facto query language for RDF data, so it seems logical to use it somewhere in our stack. However, we don't. \n  - Getting SPARQL performant is actually pretty difficult, and we don't need the powerful query options that it provides. \n  - Most of the requests from the front-end just ask for all triples about one or multiple subjects, and these kind of queries don't require SPARQL. \n  - SPARQL is useful for more complex graph property traversal queries, but is not necessarily the best approach for simpler queries.","n":0.052}}},{"i":5873,"$":{"0":{"v":"API Design","n":0.707},"1":{"v":"\n- https://ontola.io/blog/api-design/\n","n":0.707}}},{"i":5874,"$":{"0":{"v":"Ontogen","n":1}}},{"i":5875,"$":{"0":{"v":"Introducing Ontogen","n":0.707},"1":{"v":"\n- https://ontogen.io/introduction/part-1, https://ontogen.io/introduction/part-2, \n- written-by: @marcel-otto\n\n## Highlights\n\n### Source Control Management vs. Data Control ManagementPermalink\n\n- Roles: In an SCM, the committer is the crucial role. While SCMs recognize the difference between author and committer, in practice, this is usually of little importance. For a dataset, however, authorship, i.e., the exact source of datasets, is of greater importance, and many other roles are relevant and should be differentiable, such as data processors (people or systems that transform, clean, or enrich raw data), data curators (experts who organize, categorize, and enrich data with metadata), data protection officers, etc.\n-   Lack of metadata: Datasets often require extensive metadata (e.g., origin, license, timestamps) that are not natively supported in SCMs.\n-   Granularity of changes: SCMs often work at the file level, while for datasets, individual records or fields may be relevant.\n-   Database integration: DCMs should ideally be able to interact directly with database systems, which is not provided for in SCMs.\n\n### Problems with previous versioning systems for rdf\n\n- The main problem with named graphs for versioning is that parts of a graph simply cannot be addressed directly.\n  - This forces us to create a separate named graph for every small group of triples we want to version, which can quickly lead to a flood of graphs and thus an unwieldy RDF dataset.\n  - This becomes particularly problematic when working with different named graphs for content purposes, which then become difficult to distinguish among this flood.\n- With RDF-star, \"it is now trivial to define virtual, URI-identifiable sets of statements, i.e., partial graphs within a graph\" by assigning the statement to a common resource using a property.\n\n### RTC\n\npublished the [[prdct.rdf-triple-compounds]] (RTC) vocabulary last year\n\n## RDF Speech Acts\n\n- An og:SpeechAct represents a very specific form of speech act: the utterance of RDF statements or modification.\n  - allows us to capture not just the content of RDF data, but also the act of asserting or changing that data, along with all the contextual information that surrounds that act.\n  - an action that does not represent the actual addition or modification of the dataset (we will continue to call this action a commit, following the usual versioning terminology)\n  - Instead, it represents the act of the original utterance of the statements in this dataset or subsequent acts that supplement, revise, confirm, etc. the original statements. \n    - This is because the central questions of provenance, i.e., the origin of the data, revolve around these acts.\n- our aim is to provide a model that allows us to capture information related to all possible questions about these utterances and record them as metadata.\n- we don’t need to develop a new ontology from scratch to model these metadata. There is already an excellent and standardized basis: the [[prdct.prov-o]] vocabulary\n- we define our og:SpeechActs as a special manifestation, i.e., a subclass of prov:Activity\n  - allows us to leverage the extensive semantics of the PROV vocabulary while modelling our specific concept of speech acts for RDF data.\n\n## Propositions\n\n- An og:SpeechAct is thus a prov:Activity that can be associated with triple compounds with different pragmatics via four properties, the so-called action properties\n  -   `og:add`: A triple compound, i.e., a set of statements that is simply asserted without any further intentions. When persisted to a dataset in a triple store, these statements should be added.\n  -   `og:update`: A triple compound, i.e., a set of statements that is asserted with the intention to overwrite all previous statements with the same subject and predicate. When persisted to a dataset in a triple store, these statements should be added and the existing statements with the same subject and predicate should be overwritten.\n  -   `og:replace`: A triple compound, i.e., a set of statements that is asserted with the intention to overwrite all previous statements with the same subject. When persisted to a dataset in a triple store, these statements should be added and the existing statements with the same subject should be overwritten.\n  -   `og:remove`: A triple compound, i.e., a set of statements that should be retracted (“negated”). When persisted to a dataset in a triple store, it should remove these statements.\n- the action properties do not associate the og:SpeechAct with triple compounds in general, but with og:Propositions, a subclass of rtc:Compound\n  - i.e., a special kind of triple compound that should exhibit some particular properties in this versioning context. \n  - We achieve this by using URI-encoded SHA256 hashes of the statement set for the URIs of the og:Propositions.\n- This approach allows us to achieve some important properties for our use case.\n  - we have a method to automatically generate the URIs of the og:Propositions\n  - the authenticity of the statement set of the og:Proposition is verifiable, as we can detect whether the statement set is unchanged\n    - Each og:Proposition can be verified by recalculating the hash of its canonicalized triple sets\n    - Changes or manipulations to the data would inevitably lead to a change in the hash and thus an inconsistent URI, which would be easily detectable.\n  - the og:Propositions exhibit an interesting identity property: propositions with the same set of statements receive the same URI\n    - This means that if the og:Proposition statement set appears in different og:SpeechActs, for example, because it was og:added once and og:removed once, the same statement set should not be duplicated a third, fourth, or fifth time, etc., in the rtc:elements of different og:Proposition compounds, but should reference the same og:Proposition.\n- Thus, og:Propositions represent immutable, abstract sets of statements that can be used in different, independent contexts and always have the same URI. \n  - one problem: if two og:Proposition statement sets contain blank nodes and differ only in the local names used for the blank nodes, but are otherwise isomorphic, they are actually the same abstract statement set, which should therefore lead to the same URI.\n- So, og:Propositions are an abstraction over concrete statement sets: the same statement set in different triple stores, with potentially different blank nodes, are all identified by the same URI of a resource.\n  - These og:Proposition compounds are thus, like the propositions of logic, abstract entities that are not bound to any utterance.\n  - Only through the utterance within an og:SpeechAct do they become time- and context-bound.\n  - As abstract entities, unlike RTC compounds in general, the og:Proposition compounds usually do not contain metadata, as the interesting metadata is utterance-related and therefore belongs to the og:SpeechAct\n- The URI of the speech act itself in Ontogen is:\n  -   the URI-encoded SHA256 hash of all `og:Proposition`s linked through its action properties (i.e., their SHA256 URIs),\n  -   the `prov:endedAtTime` timestamp,\n  -   and the `og:speaker` (a subproperty of `prov:wasAssociatedWith`) of the `og:SpeechAct`, or the `og:dataSource` (a subproperty of `prov:used`) if the speaker is unknown.\n   \n### Example\n\n```turtle\n@prefix : <http://example.com/> .\n@prefix og: <https://w3id.org/ontogen#> .\n@prefix rtc: <https://w3id.org/rtc#> .\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n@prefix prov: <http://www.w3.org/ns/prov#> .\n@prefix dc: <http://purl.org/dc/terms/> .\n\n<urn:hash::sha256:b1f9fb63d4cbfcc48c9da35c0526a1aeb394dce9f6fc10368d5ec3d248a8f070>\n    a og:SpeechAct ;\n    dc:description \"Update of Sarah Miller's personal information following her marriage\" ;\n    og:add <urn:hash::sha256:3e9347bcd3f39fba5afc5a4b2f132bb2468cf399a4dfa6e34f52aea85e755a6e> ;\n    og:update <urn:hash::sha256:4d33b032442d54f94052b55643240adf79dbea7ae635c5fb167a124dc3d6444a> ;\n    og:speaker :JaneSmith ;\n    prov:startedAtTime \"2023-07-26T09:30:00Z\"^^xsd:dateTime ;\n    prov:endedAtTime \"2023-07-26T09:31:15Z\"^^xsd:dateTime ;\n    prov:wasInformedBy :MarriageCertificateSubmission ;\n    prov:used :MarriageCertificate20230725  .\n\n<urn:hash::sha256:3e9347bcd3f39fba5afc5a4b2f132bb2468cf399a4dfa6e34f52aea85e755a6e>\n    rtc:elements \n        << :employee39 :emailAddress \"sarah.johnson@example.com\" >>, \n        << :employee39 :marriageDate \"2023-07-25\"^^xsd:date >> .\n\n<urn:hash::sha256:4d33b032442d54f94052b55643240adf79dbea7ae635c5fb167a124dc3d6444a>\n    rtc:elements \n        << :employee39 :familyName \"Johnson\" >>, \n        << :employee39 :maritalStatus :Married >> .\n\n:JaneSmith a prov:Person ;\n    foaf:name \"Jane Smith\" ;\n    foaf:mbox <mailto:jane.smith@example.com> .\n\n:MarriageCertificate20230725 a prov:Entity ;\n    dc:title \"Marriage Certificate for Sarah Miller and Michael Johnson\" ;\n    prov:generatedAtTime \"2023-07-25\"^^xsd:date .\n\n:MarriageCertificateSubmission a prov:Activity ;\n    prov:wasAssociatedWith :employee39 ;\n    prov:generated :MarriageCertificate2023-07-25 ;\n    prov:endedAtTime \"2023-07-26T09:00:00Z\"^^xsd:dateTime .\n```\n\n## Commits\n\n- In Ontogen, commits represent the actual changes made to a repository, resulting from applying an og:SpeechAct to this repository with its existing data.\n  - Like an og:SpeechAct, og:Commits are a prov:Activity.\n  - However, they represent the act of adding or modifying data in a dataset within a triple store in a specific state, rather than the act of uttering these statements, which may have occurred at a much earlier time and by a different speaker.\n- Like an og:SpeechAct, an og:Commit is a structure composed of og:Propositions linked through various action properties.\n- However, since they have a slightly different pragmatics here and a different rdfs:domain, different properties and an additional one are used for this purpose.\n  - The semantics of this set of properties is characterized by encoding repository-relative changes, i.e., expressing the minimal changes relative to the current state of the dataset.\n  - This is crucial to ensure that og:Commits are revertible, as otherwise ambiguities in the history would arise:\n    - Can we simply remove every statement added by a commit from the triple store during a revert?\n    - The same applies to removals of statements that do not actually exist in the current dataset and therefore should not be restored during a revert.\n    - Additionally, the specific statements implicitly deleted by og:updates and og:replace must be explicitly recorded in an additional proposition so that they can be restored during a revert.\n- To ensure the reversibility of commits, the internally so-called “effective changeset” must be determined.\n- From this, corresponding propositions are then generated and linked to the og:Commit via the following action properties, along with the og:SpeechAct that this commit reproduces on the repository:\n  -   `og:committedAdd`, `og:committedRemove`, `og:committedUpdate`, `og:committedReplace`: These action properties represent the minimal sets of statements as propositions necessary to change the state of the repository to match the corresponding `og:Proposition`s of the `og:SpeechAct`. They contain only the actually required changes.\n  -   `og:committedOverwrite`: This property contains a set of statements as a proposition that represents the statements to be implicitly deleted due to updates or replacements.\n- If none of the changes conflict with existing triples (or in the case of deletions, with non-existing triples) in the triple store, the og:Propositions of the og:Commit are the same as the og:Propositions in the og:SpeechAct and do not require additional space for dedicated modified og:Propositions.\n- Theoretically, we could rely on two simple sets for additions and deletions to determine the statement sets of the effective changes. However, to increase the chance of reusability of og:Propositions, we continue to use the same actions for commits, so that only in case of overlap with existing data, a separate, dedicated og:Proposition for the commit must exist.\n- a commit is, of course, like in other version control systems, a sequential, uni-directionally linked list of commits to the respective predecessor commits.\n  - The predecessor commit is defined in Ontogen via the og:parentCommit property.\n- The automatically generatable identifiers of an `og:Commit` are, like those of `og:SpeechAct`s and `og:Proposition`s, again URI-encoded SHA256 hashes, in this case of:\n  -   the hash URI of the parent commit\n  -   the hash URIs of the propositions of the commit\n  -   the URI of the committer\n  -   the timestamp of the commit\n  -   and the commit message\n\n## Ontogen’s Repository and Service Model\n\n### Isolated history graph\n\n- A distinctive feature of storing versioning information in Ontogen is the strict separation between the actual data and the versioning artifacts.\n  - **Ontogen stores all versioning information in a separate graph, the so-called og:History graph.**\n  - this history graph stores the proposition compounds with the RDF-star statements and the assertions of all higher-level resources such as speech acts and commits.\n  - This approach ensures that the actual data of the RDF dataset remains completely free of version control artifacts.\n  - The implementation is achieved through the use of RDF-star and the RTC vocabulary. \n    - We use the inverse rtc:elements property of the rtc:elementOf property and store the RDF-star assertions as “unasserted” in the history graph.\n  - the current version of Ontogen only supports versioning of individual RDF graphs. Managing changes across different graphs of an RDF dataset is planned for future versions.\n\n### Ontogen repositories as DCAT catalogs\n\n- [[prdct.dcat-data-catalog]] is suitable:\n  -   Flexibility and extensibility: DCAT provides a basic vocabulary that can be easily adapted and extended to specific needs.\n  -   Hierarchical structuring: DCAT allows the modeling of nested catalog structures, which is ideal for organizing complex RDF datasets.\n  -   Comprehensive metadata: DCAT offers a rich set of properties for describing datasets, including license information, access rights, and temporal aspects, some of which can even be provided automatically in the context of Ontogen, as these can be derived from the speech act and commit history (authors, creation period, data sources, etc.)\n  -   Support for versioning and integration with PROV: The soon-to-be-completed version 3 of DCAT introduces a comprehensive [versioning concept](https://www.w3.org/TR/vocab-dcat-3/#dataset-versions) that is particularly relevant for Ontogen’s use case. This extension also seamlessly integrates the PROV vocabulary, which forms the basis for Ontogen’s RDF speech act and commit history. This integration enables the direct derivation and modeling of provenance information and version metadata from the version history. For example, authors, creation dates, and other relevant metadata for specific revisions of a dataset can be automatically generated and presented in a standardized form. This close intertwining of versioning and provenance tracking makes DCAT 3 an ideal vocabulary for metadata description in Ontogen, as it can precisely map the complex temporal and authorial aspects of versioned RDF datasets.\n  -   Standardization and interoperability: As a W3C standard, DCAT enjoys wide acceptance and support in the data management community. This promotes Ontogen’s compatibility with other systems and tools in the field of data management. For example, DCAT has gained great importance in the European Union, where it serves as the basis for DCAT-AP (DCAT Application Profile for data portals in Europe) and is supported in prominent data catalog platforms. The use of DCAT in Ontogen thus allows seamless integration into existing data ecosystems and facilitates the exchange of metadata with a variety of platforms and services.\n- we define an og:Dataset as a subclass of dcat:Dataset. In fact, we can define it even more specifically as a subclass of dcat:Catalog, because according to the above broader definition, one can also consider a single graph of an RDF dataset as a dcat:Dataset and thus define it as a collection of these.\n- we define an `og:Repository` as a DCAT catalog around such an og:Dataset, supplementing it with two additional entries, so that an og:Repository as a DCAT catalog consists of exactly two explicit DCAT dataset entries and one implicit graph:\n  -   One entry for the `og:Dataset` DCAT catalog with the pure user-defined graphs (which is defined using the `og:repositoryDataset` property, a sub-property of `dcat:dataset`).\n  -   One entry for the `og:History` graph with the provenance history of the speech acts and commits as PROV activities, including the linked PROV entities and PROV agents (which is defined using the `og:repositoryHistory` property, a sub-property of `dcat:dataset`).\n  -   A repository graph that contains the DCAT metadata description of the `og:Repository` itself, including the DCAT metadata description of the `og:Dataset` catalog. This graph poses a particular challenge as it is both part of the repository and its description. This self-referencing leads to a conceptual ambiguity: on the one hand, the graph is a `dcat:Dataset`, on the other hand, it contains the description of the entire repository including itself. In the current DCAT specification, there is no clear solution for this problem of self-description as an explicit part of a `dcat:Catalog`. Therefore, in the current version of Ontogen, this graph is treated implicitly as part of the definition of an `og:Repository`, without an explicit `dcat:dataset` entry for it in the catalog. This solution is pragmatic, but ultimately not really satisfactory. Better suggestions for solving this problem would be very welcome.\n\n### Ontogen instances as DCAT services\n\n  - An `og:Service`, which is defined as a subclass of dcat:DataService, is a resource that structurally consists of two elements:\n  -   The `og:Repository` linked via the `dcat:servesDataset` sub-property `og:serviceRepository`\n  -   An `og:Store` linked via the property `og:serviceStore`, which represents the locally running SPARQL triple store in which the repository is stored\n-   While the same Ontogen repository can exist on different computers, the various Ontogen instances on these computers operate as different Ontogen services with different stores but the same repository.\n\n## Ontogen Configuration with Bog\n\n- [[prdct.bog]] has `bog:ref`, whereby a blank-node resource can be given a locally-valid name\n\n```turtle\n# we omit this prefix in the following code snippets\n@prefix : <https://w3id.org/bog#> .\n\n[ :ref \"this-service-instance\" ; a og:Service ] .\n```\n  - When first interpreted by the Bog interpreter, this is interpreted as minting a new, locally named resource. A random salt is then stored in a file with the specified name.\n  - The interpreter then replaces the blank node with a generated UUIDv5 URI\n  - For each subsequent interpretation, loading the salt reproduces exactly the same UUIDv5 URI, allowing for consistent translation to the same graph.\n- Bog offers another solution to avoid name changes: the indexical `bog:this` property.\n  - The concept of [[t.phil.language.indexicality]] comes from the philosophy of language and refers to linguistic expressions whose meaning depends on the context of their utterance.\n  - It allows referencing individual instances of classes that represent a unique individual relative to this instance in the context of the executing instance.\n  - Consequently, these quasi-relative singletons can also be referenced directly via their class in the context of the executing instance.\n\n### Example\n\n- In the context of execution on an Ontogen instance, there is exactly one distinguished individual of the class `og:Service` that represents this very instance as an `og:Service`. Thus, in Bog, it can also be referenced using the `bog:this` property as follows:\n\n```turtle\n[ :this og:Service ] .\n```\n\n- This is interpreted by the Bog interpreter as follows:\n\n```turtle\n[ :ref \"service\" ; a og:Service ] .\n```\n\n### Bog Future\n\n- It is planned to spin off Bog as its own project with expanded functionality in the next version of Ontogen. In particular, it should be possible to give the resources managed with Bog proper Linked Data URIs at a later point in time if needed. ^ezq1fl2ro8qr\n\n## Store Adapters\n\n- triple store adapters are implemented as subclasses of og:Store\n  - This solution is not only conceptually very simple but also provides a comprehensive basis for solving this problem thanks to [[prdct.grax]] and its support for polymorphic links\n    - (In particular, we overcome the [“Walled Gardens within Elixir”](https://marcelotto.medium.com/the-walled-gardens-within-elixir-d0507a568015), which potentially allows store adapters to be developed and versioned as separate Hex packages if their complexity should increase over time, which might happen quickly when triple store-specific extensions are implemented in a store adapter.)\n\n\n## References\n\n- https://ontogen.io/introduction/part-2","n":0.018}}},{"i":5876,"$":{"0":{"v":"Oasis Open","n":0.707}}},{"i":5877,"$":{"0":{"v":"Published Subjects Definitions Requirements and Examples","n":0.408},"1":{"v":"\n\n\n\nmaybe you just need publishers to say \"this is a published subject indicator\"\n\n- [[p.hasURL]] https://www.oasis-open.org/committees/tm-pubsubj/docs/recommendations/general.htm\n- [[p.hasEditor]] @Bernard-Vatant\n- [[p.hasTheme]] [[t.cs.web.topic-maps]]\n- [[p.hasHighlight]]\n  - \"Subjects\": \"can be anything deserving to be identified, named, represented and generally talked about - otherwise said a subject of conversation\"\n  - \"topic\": \" the representation, inside an application, of an unique, well-defined, and non-ambiguous subject\"\n  - \"Published Subject Identifier\" is a URI that resolves to a \"human-interperable\" \"Published Subject Indicator\": basically just provide an enumeration of \"published subjects\" which is an improvement because \"publisher's statement of purpose, disambiguation of the subject, and stability. \n  - Recommendations:\n\n> Recommendation 1 :\n>\n    A Published Subject Indicator should provide human-readable metadata.\n> \n> Recommendation 2 :\n>\n>    A Published Subject Indicator should provide machine-processable metadata.\n>\n> Machine-processable metadata is recommended so that applications can use more information on the subject than solely URI identification.\n>\n>Human-readable as well as machine-processable metadata can be included in the Subject Indicator itself (e.g. RDF metadata), or in a separate resource referenced from the Subject Indicator (e.g. XTM metadata).\n>Deliverable 2 will provide complementary recommendations on the nature of those metadata.\n>\n>Recommendation 3 :\n>\n>    Metadata defined in 1 and 2 should be consistent, but not necessary equivalent.\n>\n>Consistency between human-readable and machine-processable metadata is the warrant of consistent \"interpretation\" by applications and humans. This can be achieved, for example, by human-readable metadata being an expression of machine-processable metadata. This issue will be addressed by Deliverable 2.\n>\n>Recommendation 4 :\n>\n>    Published Subject Indicator should indicate that it is intended to be a PSI.\n>\n>This statement of purpose has to be clearly endorsed by the publisher (see below).\n>\n>Recommendation 5 :\n>\n>    Published Subject Indicator should identify its publisher.\n>\n> Publisher is to be understood here in its Dublin Core definition: \"An entity responsible for making the resource available.\"\n> \n>Statement of purpose and Publisher identification are the warrants of trust, fundamental to efficient PSI mechanism.\n\n\n[[t.cs.sd.architecture.event-driven.event-broker]]","n":0.057}}},{"i":5878,"$":{"0":{"v":"Nytimes","n":1}}},{"i":5879,"$":{"0":{"v":"Politics Genetics Research","n":0.577},"1":{"v":"\n- [[p.hasURL]] https://www.nytimes.com/2022/06/01/opinion/politics-genetics-research.html\n- [[p.hasHighlight]] \"the underlying connection between the core issues that are important to humans, revolving around cooperation, defense, reproduction, resources, and survival remain.\n\" #shapow\n\n","n":0.196}}},{"i":5880,"$":{"0":{"v":"Why We All Need to Have More Fun","n":0.354},"1":{"v":"\n- [[p.hasAuthor]] @katherine-price\n- [[p.hasURL]] https://www.nytimes.com/2021/12/23/well/mind/having-fun-suceeding-coronavirus-pandemic.html\n- [[p.hasHighlight]]\n  - \"true fun... materializes when we experience the confluence of three psychological states: [[playfulness|t.psych.playfulness]], [[connection|t.psych.connectedness]] and [[flow|t.psych.flow]].\"\n  - “Fake” fun is my term for activities that take up our leisure time, but they don’t inspire playfulness or connection, or result in the total engagement that happens with flow. \n  - Try to create as much connection, playfulness and flow in your everyday life as possible, whether it’s by sharing a smile with a stranger, calling a colleague instead of emailing or doing something nice for a friend. Every time you do so, take note of how it affects your mood.\n","n":0.097}}},{"i":5881,"$":{"0":{"v":"Newyorker","n":1}}},{"i":5882,"$":{"0":{"v":"Hamlet on the Holodeck Twenty Years Later","n":0.378},"1":{"v":"\n- https://www.newyorker.com/books/second-read/hamlet-on-the-holodeck-twenty-years-later\n- topics: @janet-murray [[book.hamlet-on-the-holodeck]]\n- author: @matt-margini\n\n## Highlights\n\n- though there is a tendency to think of the computer as “the enemy of the book,” it is in fact “the child of print culture,” a powerful representational medium of its own that promises to continue the evolution of storytelling and “reshape the spectrum of narrative expression.”\n- Books are good at delivering essentially linear stories, she insists, while computers are good at telling stories of a different kind: procedural, participatory, encyclopedic, and spatial. And they’re particularly good at telling stories that reflect the digital age—stories about fractured realities, complex systems, and networked ways of being in the world.\n- Murray became devoted to creating “incunabula,” a term meaning “swaddling clothes” that is used by book historians to describe awkward experiments produced just after the invention of the printing press.\n  - She compares Myst, for instance, a seminal first-person adventure game from 1993, to the juvenilia of the Brontë sisters, who told stories to one another about tense dungeon-crawls in a “regressive, violent, overheated emotional universe.”\n- “walking simulator” was likely pejorative at first, rooted in a “misconception that there are two different categories, narrative and game, and you’re either one or the other.”\n- there is \"a largely tortuous debate in game-studies circles between so-called ludologists [[t.cs.game.ludology]] and narratologists: people who wanted to study games as abstract systems, on the one hand, and people who wanted to study them as narrative experiences on the other.\"\n  - the prominent video-game critic @ian-bogost, a colleague of Murray’s at Georgia Tech, assailed her book one more time—without naming her or it directly—in a widely shared piece that was provocatively, if misleadingly, titled [[ar.atlantic.video-games-are-better-without-stories]].\n  - ludologists want Tetris—or Candy Crush, or perhaps the screen itself—to be a refuge from narrative, she argues, because they’re embroiled in too much narrative already.\n  - For some, “objections to the possibility of deeply meaningful digital narrative forms” are rooted in “empty expressions of nostalgia for older media artifacts.” \n  - But for others it seems to be something else: a need to keep digital technology away from “the cultural and narrative dimensions of representation” altogether, as if it could remain a realm of pure function.","n":0.053}}},{"i":5883,"$":{"0":{"v":"Could Elaine May Finally Be Getting Her Due","n":0.354},"1":{"v":"\n- https://www.newyorker.com/culture/the-front-row/could-elaine-may-finally-be-getting-her-due?utm_source=pocket-newtab-en-us\n\n## Highlights\n\n- The raw materials for a movie aren’t film and a camera but the sense of life that flows from and around a filmmaker, which also include the choice of and relations with the cast and crew. ^my0l948uqa93\n- she dictated freedom, a shared search for the reality contained in fictional premises\n- May achieved an extraordinary tone of comedic realism—of a fragile equilibrium between the recognizable and the ridiculous, by means of which the film captured something essential about the times.\n- ","n":0.11}}},{"i":5884,"$":{"0":{"v":"Neo4j","n":1}}},{"i":5885,"$":{"0":{"v":"RDF Triple Stores vs. Labeled Property Graphs: What’s the Difference?","n":0.316},"1":{"v":"\n\r\n\r\na biased comparison of the two prevailing graph data models\r\n\r\n- [[p.hasURL]] https://neo4j.com/blog/rdf-triple-store-vs-labeled-property-graph-difference/\r\n\r\n## [[p.provokedThoughts]]\r\n\r\n### RDF vs GraphDown\r\n\r\n- relationships can be uniquely identified via\r\n## [[p.hasSummaryPoints]]\r\n## Issues\r\n\r\n- `edges` are portrayed as relationships, but in an important sense, edges express part of a relationship.  \r\n","n":0.156}}},{"i":5886,"$":{"0":{"v":"Nautilus","n":1}}},{"i":5887,"$":{"0":{"v":"Our Brains Tell Stories So We Can Live","n":0.354},"1":{"v":"\n\n\nstories are a part of science. (and reality.) they complement the data and should be judged critically.\n\n- [[p.hasURL]] https://nautil.us/issue/75/story/our-brains-tell-stories-so-we-can-live\n- [[hasSubTitle]] Without inner narratives we would be lost in a chaotic world. \n\n- > Just as proper pattern recognition results in the reward of an increased release of dopamine, faulty pattern recognition is associated with decreased dopamine release. \n\n- > ike a literary critic, we should assess the preciseness of language, the tightness of structure, the clarity and originality of vision, the overall elegance and grace of the study, the restraint with which they present moral issues, how they place their studies in historical, cultural, and personal context, and their willingness to entertain alternative opinions and interpretations.\n","n":0.093}}},{"i":5888,"$":{"0":{"v":"Narratively","n":1}}},{"i":5889,"$":{"0":{"v":"The Pirate Queen Who Avenged Her Husband's Death on the High Seas","n":0.289},"1":{"v":"\n- https://getpocket.com/explore/item/the-pirate-queen-who-avenged-her-husband-s-death-on-the-high-seas\n- potentially a great [[t.roleplaying.scenario]]\n\n\n## References\n\n- [[book.olivier-de-clisson-connetable-de-france]]","n":0.354}}},{"i":5890,"$":{"0":{"v":"Microsoft","n":1}}},{"i":5891,"$":{"0":{"v":"TypeScript Tutorial","n":0.707},"1":{"v":"\nurl: https://code.visualstudio.com/docs/typescript/typescript-tutorial\n","n":0.707}}},{"i":5892,"$":{"0":{"v":"Mdpi","n":1}}},{"i":5893,"$":{"0":{"v":"Knowledge Representation and Data Integration Language for the Web","n":0.333},"1":{"v":"\n\n- author [[user.dominik-tomaszuk]]\n- [[p.subClassOf]] [[c.paper]]\n- [[p.hasURL]] https://www.mdpi.com/2073-8994/12/1/84/htm\n## Highlights  \n\n- > JSON-LD is a RDF syntax. However, it also extends the RDF data model, e.g., in JSON-LD predicates can be IRIs or blank nodes whereas in RDF have to be IRIs. JSON-LD can serialize generalized RDF triples, where subjects, predicates, and objects can be IRIs, blank nodes or literals.\n","n":0.131}}},{"i":5894,"$":{"0":{"v":"Maverickphilosopher","n":1}}},{"i":5895,"$":{"0":{"v":"Predicates and Properties","n":0.577},"1":{"v":"\n\n\n- [[p.hasURL]] https://maverickphilosopher.typepad.com/maverick_philosopher/2010/06/predicates-and-properties.html\n  ## Highlights\n\n- Predicates are linguistic while properties are extralinguistic.\n- some predicates pick out properties and some don't...  It then becomes a matter of investigation, not of terminology, whether or not there is a property for a given predicate.\n","n":0.156}}},{"i":5896,"$":{"0":{"v":"Martinfowler","n":1}}},{"i":5897,"$":{"0":{"v":"Data Mesh Principles","n":0.577},"1":{"v":"\n- publish-date: 2020-12-03\n- author: @zhamak-dehghani\n- topics: [[t.cs.data.data-mesh]]\n\n## Highlights\n\n- data mesh follows a distributed system architecture; a collection of independent data products, with independent lifecycle, built and deployed by likely independent teams.\n  - However for the majority of use cases, to get value in forms of higher order datasets, insights or machine intelligence there is a need for these independent data products to interoperate; to be able to correlate them, create unions, find intersections, or perform other graphs or set operations on them at scale.\n    - For any of these operations to be possible, a data mesh implementation requires a governance model that embraces decentralization and domain self-sovereignty, interoperability through global standardization, a dynamic topology and most importantly automated execution of decisions by the platform.\n\n### federated computational governance\n\n- global standards, local decisions","n":0.087}}},{"i":5898,"$":{"0":{"v":"Linkedin","n":1}}},{"i":5899,"$":{"0":{"v":"The Open World Assumption in Modeling. What does it mean to you?","n":0.289},"1":{"v":"\n- https://www.linkedin.com/pulse/open-world-assumption-modeling-what-does-mean-you-irene-polikoff/\n- author: @irene-polikoff\n\n## Highlights\n\n![[t.cs.web.w3c.rdf.open-world-assumption#irenes-principles]]\n\n### CWA\n\n![[prdct.shacl#^6uscvziiubke]]\n![[prdct.sparql#^sjsxjl2oyczk]]\n- \"Additionally, the key principles of the OWA mean that with it, reasoning is monotonic—no new information can invalidate existing information, and the deductive conclusions which can be drawn from it (Sowa 2000). Conversely, nonmonotonic reasoning under the CWA is revisionary—new facts can revise existing conclusions. In practice, this is often necessary when working with real world data.\"\n- ","n":0.126}}},{"i":5900,"$":{"0":{"v":"Semantics Mans Search Computational Meaning Joshua Reuben","n":0.378},"1":{"v":"\n- url: \n- mentioned: [[prdct.amr]] and [[prdct.framenet]] and [[prdct.grammatical-framework]] [[t.cs.ai.frame]]\n","n":0.316}}},{"i":5901,"$":{"0":{"v":"Lesswrong","n":1}}},{"i":5902,"$":{"0":{"v":"Where Do Selfish Values Come From","n":0.408},"1":{"v":"\n- url: https://www.lesswrong.com/posts/Nz62ZurRkGPigAxMK/where-do-selfish-values-come-from\n- author: @wei-dai\n- [[t.phil.decision-theory.updateless]]","n":0.408}}},{"i":5903,"$":{"0":{"v":"The Best Tacit Knowledge Videos on Every Subject","n":0.354},"1":{"v":"\n- author: @parker-conley  \n\n## Software Engineering\n\n### Machine Learning\n\n-   Andrej Karpathy, [**<u>Neural Networks: Zero to Hero</u>**](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ).\n    -   10+ years: Stanford PhD, research scientist at OpenAI & Tesla. ([<u>Website</u>](https://karpathy.ai/))\n-   Jeremy Howard, [**fast.ai live coding & tutorials**](https://www.youtube.com/playlist?list=PLfYUBJiXbdtSLBPJ1GMx-sQWf6iNhb8mM).\n    -   \"He is the co-founder of fast.ai, where he teaches introductory courses, develops software, and conducts research in the area of deep learning. Previously he founded and led Fastmail, Optimal Decisions Group, and Enlitic. He was President and Chief Scientist of Kaggle\" ([Wikipedia](https://en.wikipedia.org/wiki/Jeremy_Howard_(entrepreneur))).\n\n### Competitive Programming\n\n-   Neal Wu, [**<u>competitive programming</u>**](https://www.youtube.com/@NealWuProgramming).\n    -   CS at Harvard; SWE 1 year at startup; 4 years at Google ([<u>LinkedIn</u>](https://www.linkedin.com/in/nealwu/)).\n-   Errichto Algorithms, [**<u>competitive programming</u>**](https://www.youtube.com/@Errichto).\n    -   Peak rating of 3053 (legendary grandmaster) on [<u>Codeforces</u>](https://codeforces.com/profile/Errichto).\n\n### Game Design\n\n-   Jonathan Blow, [**<u>programming livestreams</u>**](https://www.youtube.com/@UNOFFICIALJonathanBlow).\n    -   Creator of Braid and The Witness.\n-   Casey Muratori (Molly Rocket), [**<u>ongoing project [...] to create a complete, professional-quality game accompanied by videos that explain every single line of its source code</u>**](https://hero.handmade.network/episode/code).\n    -   “\\[P\\]ast projects include The Granny Animation SDK, Bink 2, and The Witness” ([<u>Website</u>](https://caseymuratori.com/about)).\n-   Gareth Murfin, [**<u>looks at some reverse engineered GTA Vice City code</u>**](https://www.youtube.com/watch?v=SebVNodMV4Q).\n    -   He was a programmer on the project. He now has 20 years of mobile development experience ([<u>LinkedIn</u>](https://www.linkedin.com/in/androidguy)).\n-   Freya Holmér, explaining [**math**](https://www.youtube.com/@acegikmo/streams) **/** [**shaders**](https://www.youtube.com/playlist?list=PLImQaTpSAdsCnJon-Eir92SZMl7tPBS4Z) and [**coding**](https://www.youtube.com/playlist?list=PLImQaTpSAdsBzCxgPRYIrQZXiukNRaMr7). (via [@talelore](https://www.lesswrong.com/users/talelore?mention=user))\n    -   Co-founder of an indie game development studio since 2012 and game developer since 2020 ([LinkedIn](https://www.linkedin.com/in/acegikmo)).\n\n### Other \n\n-   George Hotz, [**<u>programming livestreams</u>**](https://www.youtube.com/@geohotarchive). (via [@RomanHauksson](https://www.lesswrong.com/users/r-2?mention=user))\n    -   “He is known for developing iOS jailbreaks, reverse engineering the PlayStation 3, and for the subsequent lawsuit brought against him by Sony. From September 2015 onwards, he has been working on his vehicle automation machine learning company comma.ai. Since November 2022, Hotz has been working on tinygrad, a deep learning framework\" ([<u>Wikipedia</u>](https://en.wikipedia.org/wiki/George_Hotz)).\n-   Matt Layman, [**\"How To Build SaaS with Python and Django\"**](https://www.youtube.com/playlist?list=PLFcKEo4b_n1wQA6lKtSqCq1dTMq1c2Lmw). (via [roshan\\_mishra/X](https://x.com/roshan_mishra/status/1775332267721666673))\n    -   Software Engineer since 2006 at Lockheed Martin, Storybird Inc., Serenity Software, Doctor on Demand, and Included Health ([LinkedIn](https://www.linkedin.com/in/mattlayman/)).\n-   Tim Ruscica, [**<u>Tech with Tim livestreams</u>**](https://www.youtube.com/results?search_query=Tech+With+Tim+live).\n    -   3 years SWE; Microsoft Intern ([<u>LinkedIn</u>](https://www.linkedin.com/in/tim-ruscica/)).\n-   Alex Denisov, [**<u>low level programming</u>**](https://www.youtube.com/@LowByteProductions/streams).\n    -   17 years of research, 10 years of web dev ([<u>LinkedIn</u>](https://www.linkedin.com/in/alexdenisov/)).\n-   Jon Gjengset, [**<u>implementing a BitTorrent client in Rust</u>**](https://www.youtube.com/watch?v=jf_ddGnum_4).\n    -   PhD at MIT; 3 years SWE, some at Amazon ([<u>LinkedIn</u>](https://www.linkedin.com/in/jonhoo/)).\n-   Shashank Kalanithi, [**<u>Day in the Life of a Data Analyst</u>**](https://www.youtube.com/playlist?list=PL-u09-6gP5ZNXNcED3EOQj0mMNIByVkZM).\n    -   Software/data stuff for 3 years at companies I've never heard of ([<u>LinkedIn</u>](https://www.linkedin.com/in/shashankkalanithi)).\n-   Dennis Ivanov, [**<u>live programming</u>**](https://www.youtube.com/playlist?list=PL-51WBLyFTg261ZnHdaNC3M5safpAgC4J).\n    -   Dev for 5 years at random company ([<u>LinkedIn</u>](https://www.linkedin.com/in/dennis-ivanov)).\n-   Dave's Garage, [**<u>exploring Windows 11</u>**](https://www.youtube.com/watch?v=go1Iffj3asM&t=1710s).\n    -   Former Microsoft shell developer.\n-   Joel Grus, [**live programming**](https://www.youtube.com/@JoelGrus/streams).\n    -   Software Engineer since 2008 at companies such as Microsoft, Google, Allen Institute for AI, and Goldman Sachs ([LinkedIn](https://www.linkedin.com/in/joelgrus/)).\n\n## Research, Studying, & Problem Solving\n\n### Research\n\n-   Neel Nanda, [**<u>Mechanistic Interpretability Research Walkthroughs</u>**](https://www.youtube.com/playlist?list=PL7m7hLIqA0hr4dVOgjNwP2zjQGVHKeB7T). (via [@RomanHauksson](https://www.lesswrong.com/users/r-2?mention=user))\n    -   Leads the Google DeepMind mechanistic interpretability team; worked at Anthropic with Chris Olah; interned at Jane Street and Jump Trading ([<u>Website</u>](https://www.neelnanda.io/about)).\n-   Andy Matuschak, doing [**<u>research live</u>**](https://youtu.be/DGcs4tyey18?si=ymarQW6n15EeFpjd).\n    -   Crowdfunded researcher. “\\[H\\]elped build iOS at Apple and led R&D at Khan Academy” ([<u>Website</u>](https://andymatuschak.org/)).\n-   JoVE, [**<u>a “Peer Reviewed Scientific Video Journal”</u>**](https://app.jove.com/)<u>.</u>\n    -   “18,000+ videos of laboratory methods and science concepts”, though most are paywalled and seem to require an institutional subscription.\n-   Steven Kenneth Bonnell II (Destiny), [**doing research for debates**](https://www.youtube.com/playlist?list=PLdAZsbpWCH4N8SlRuNG7zNzltk5Lk17v5).\n    -   \"\\[L\\]ive-streamer and political commentator\" ([Wikipedia](https://en.wikipedia.org/wiki/Destiny_(streamer))). Has debated/talked with, eg, Jordan Peterson, Lex Fridman, Bryan Caplan, and Ben Shapiro.\n\n### Studying\n\n-   Andy Matuschak, [**<u>studying Quantum Mechanics with Dwarkesh Patel</u>**](https://www.youtube.com/watch?v=OFuu4pesKf0&pp=ygUOYW5keSBtYXR1c2NoYWs%3D)<u>.</u>\n    -   Crowdfunded researcher. “\\[H\\]elped build iOS at Apple and led R&D at Khan Academy” ([<u>Website</u>](https://andymatuschak.org/)).\n-   Justin Sung, [**<u>Study With Me</u>**](https://www.youtube.com/watch?v=5JJnBuTQahs).\n    -   Learning coach and YouTuber ([<u>Website</u>](https://icanstudy.com/)).\n\n### Problem Solving\n\n-   Tim Gowers, [**thinking about math problems in real-time**](https://www.youtube.com/@TimothyGowers0/videos) (via [@jsd](https://www.lesswrong.com/users/jsd?mention=user), [@depressurize](https://www.lesswrong.com/users/depressurize?mention=user))\n    -   [@depressurize](https://www.lesswrong.com/users/depressurize?mention=user) specifically liked [this series](https://www.youtube.com/watch?v=fl4xw8293QI). \n    -   \"He is Professeur titulaire of the Combinatorics chair at the Collège de France, and director of research at the University of Cambridge and Fellow of Trinity College, Cambridge. In 1998, he received the Fields Medal for research connecting the fields of functional analysis and combinatorics\" ([Wikipedia](https://en.wikipedia.org/wiki/Timothy_Gowers)).\n-   Evan Chen, solving [**Math**](https://www.youtube.com/playlist?list=PLi6h8GM1FA6weD_GuJh3A9_0tH-z91dzO) [**Olympiad**](https://www.youtube.com/playlist?list=PLi6h8GM1FA6yfhMMNqJi1mht4KmZnXpj6) [**problems**](https://www.youtube.com/playlist?list=PLi6h8GM1FA6yHh4gDk_ZYezmncU1EJUmZ). (via [@jsd](https://www.lesswrong.com/users/jsd?mention=user))\n    -   \"Evan is a math PhD student at MIT, and a math olympiad coach. In addition to helping train the United States team, Evan runs his own training program \\[...\\] Evan was an IMO gold medalist and a winner of the 2014 USA math olympiad, \\[...\\] He also wrote the popular textbook Euclidean Geometry in Math Olympiads while in high school, which was published in 2016\" ([Website](https://web.evanchen.cc/)).\n-   Tom Crawford [**<u>taking Oxford Admissions Interview</u>**](https://youtu.be/efXbABwhCtE?si=-Xd7_I3tVU_oWE_8).\n    -   Math communicator. Oxford math tutor for 6 years; Cambridge math PhD; Oxford math undergrad. ([<u>LinkedIn</u>](https://www.linkedin.com/in/tom-crawford-maths))\n-   Blackpenredpen, [**<u>solving 100 integrals</u>**](https://www.youtube.com/watch?v=dgm4-3-Iv3s).\n-   Struggling Grad Student, [**<u>doing math</u>**](https://www.youtube.com/@PhDVlog777)<u>.</u>\n    -   Current math PhD.\n\n## Business & Business Communication\n\n-   Elie Hassenfeld, Holden Karnofsky, Timothy Ogden, Rob Reich, Tom Rutledge, Brigid Slipka, Cari Tuna, Julia Wise: [**<u>GiveWell's Public Board Meetings (2007–2020 have audio)</u>**](https://www.givewell.org/about/official-records#Boardmeetings).\n    -   Holden Karnofsky. “Director of AI Strategy (formerly CEO) of Open Philanthropy and Co-Founder of GiveWell” ([<u>Website</u>](https://www.cold-takes.com/about/)).\n    -   Elie Hassenfeld. Co-Founder and CEO of GiveWell ([<u>LinkedIn</u>](https://www.linkedin.com/in/elie-hassenfeld-92072a9/)).\n    -   Timothy Ogden. Chief Knowledge Officer at Geneva Global, Inc.; founding editor of Gartner Press; founder of Sona Partners; chairman of GiveWell ([<u>Aspen Institute</u>](https://www.aspeninstitute.org/people/tim-ogden/)).\n    -   Rob Reich. Political Science professor at Stanford for 26 years ([<u>Stanford</u>](https://politicalscience.stanford.edu/people/rob-reich)).\n    -   Tom Rutledge. Has worked in finance since 1989 ([<u>LinkedIn</u>](https://www.linkedin.com/in/trutledge/)). \n    -   Brigid Sliplka. Director of Philanthropy at ACLU ([<u>LinkedIn</u>](https://www.linkedin.com/in/brigidslipka/)).\n    -   Cari Tuna. President at Open Philanthropy and Good Ventures ([<u>Wikipedia</u>](https://en.wikipedia.org/wiki/Cari_Tuna)).\n    -   Julia Wise. Community Liaison at Centre for Effective Altruism ([<u>LinkedIn</u>](https://www.linkedin.com/in/juliawise/)).\n-   Stephen Wolfram, [**<u>“Live CEOing”</u>**](https://livestreams.stephenwolfram.com/category/live-ceoing/).\n    -    “Fellow of the American Mathematical Society. \\[…\\] founder and CEO of the software company Wolfram Research where he works as chief designer of Mathematica and the Wolfram Alpha answer engine.” ([<u>Wikipedia</u>](https://en.wikipedia.org/wiki/Stephen_Wolfram)).\n-   Sam Altman, Paul Graham, others; [**<u>live Y Combinator office hours</u>**](https://www.youtube.com/playlist?list=PLyrzRJBw8IRT8vzL2hVAF_btt3lTCIZcL).\n    -   Sam Altman. CEO of OpenAI; former President of Y Combinator ([<u>Wikipedia</u>](https://en.wikipedia.org/wiki/Sam_Altman)).\n    -   Paul Graham. Co-founder of Y Combinator ([<u>Wikipedia</u>](https://en.wikipedia.org/wiki/Paul_Graham_(programmer))).\n    -   Other YC employees.\n-   Ray Dalio, [**“case study” recordings of business meetings**](https://apps.apple.com/us/app/principles-in-action/id1211294305) and interviews with employees at Bridgewater on App Store app <u>Principles In Action</u>; I do not know of a way to access these through a web browser.\n    -   Founder of Bridgewater Associates.\n-   Tegus, [**<u>a library of expert interviews for finance professionals</u>**](https://www.tegus.com/). Unfortunately, its price [<u>seems</u>](https://inex.one/expert-network-directory/tegus-expert-network) to start at $20-25,000 per user and year.","n":0.032}}},{"i":5904,"$":{"0":{"v":"Larb","n":1}}},{"i":5905,"$":{"0":{"v":"Philosophy Creative Writing","n":0.577},"1":{"v":"\n- https://lareviewofbooks.org/article/philosophy-creative-writing/\n\n## Highlights\n\n- The unofficial publicist of the new humanist movement, Foerster specialized in the manifesto. In 1929, he published American Scholar, in which he argued that literature should not serve to inspire, as Emerson had it, but as a record of “the strivings of Mankind to know and express itself.\n- Stegner hated the social novel as much as Babbitt had, advising his students that their ideas should live in “the attic” of their writing and show themselves at most “like ghosts flitting past the windows after dark.”\n- The old new humanist principles of self-knowledge (write what you know) and self-discipline (show, don’t tell) found a home in the creative writing workshop and, as Engle’s and Stegner’s students went off to form their own programs, turned into common sense.\n- In 1930, Lewis worried about an “American fear of literature” — of readers who didn’t want to grapple with social novels and the issues they raised. Ninety years later, we should worry about why we stopped fearing it.","n":0.077}}},{"i":5906,"$":{"0":{"v":"Knowledgegraph","n":1}}},{"i":5907,"$":{"0":{"v":"Lexrdf Can Owl Class Be a Subclass of One of Its Own Instances","n":0.277},"1":{"v":"\n- https://answers.knowledgegraph.tech/t/lexrdf-can-owl-class-be-a-subclass-of-one-of-its-own-instances/4651\n\n## Discussion\n\n- @antoine-zimmermann: First of all, when you talk about the semantics of OWL, there can be ambiguity because OWL has two different semantics. There is the direct semantics, which is based on Description Logics and applies to onolotgies that can be expressed in the functional syntax 1 of OWL, and the RDF-based Semantics 1, which is based on RDF and apply to any RDF document. In the case of your example, it does not make sense to talk about the direct semantics, as your ontology is not valid according to the functional syntax, but it represents a valid RDF document.\n\nNow, in the [[RDF semantics|t.cs.semantic-web.owl.rdf-based-semantics]], classes are instances of rdfs:Class and rdfs:Class is also a class so it is an instance of itself. No problem with that as RDF differenciates the class itself from the set of its instances. In the RDF-based semantics of OWL, owl:Class is equivalent to rdfs:Class so it is an instance of itself as well.","n":0.079}}},{"i":5908,"$":{"0":{"v":"Juliandunn","n":1}}},{"i":5909,"$":{"0":{"v":"What's a Solution Vs a Product?","n":0.408},"1":{"v":"\r\nsolution -> product(s) -> capabilities (for SKUs) -> features\r\n\r\n- [[p.hasURL]] https://www.juliandunn.net/2021/09/17/whats-a-solution-vs-a-product/\r\n- [[p.hasCreator]] @julian-dunn \r\n- [[p.hasSummaryPoints]] \r\n  - capability is a logical aggregation of features that allow you to perform a task\r\n  - [[p.vs]] [sonatype which has solutions that look like SKUs][3]\r\n  - [don't mix up benefits and [[p.hasFeature]]][4]\r\n- a solution is one or more products that can be applied to solve a problem\r\n  - [[p.begsQuestion]] is every product (that can solve a problem on its own) also a solution?\r\n    - likely! especially if you specify the problem\r\n      - e.g. vscode is a product; vscode is a solution to the problems \"software developers need a way to \r\n  - further elaborated by comparing to use case:\r\n    - \"commonly-accepted way to apply your product to solve an oft-seen business problem\"\r\n- solutions can have two senses:\r\n  - functional (e.g. devops)\r\n  - industry (vertical)\r\n\r\n![](/assets/images/2021-10-10-07-29-05.png)\r\n\r\n- [4]: https://www.wordstream.com/blog/ws/2017/02/21/features-vs-benefits\r\n","n":0.084}}},{"i":5910,"$":{"0":{"v":"Isko","n":1}}},{"i":5911,"$":{"0":{"v":"Work","n":1},"1":{"v":"\n- https://www.isko.org/cyclo/work\n\n## Highlights\n\n- \"the essence of a creation, such as a novel, a symphony, a painting, a statue, a thesis, etc., intended by its creator to be communicated with some audience\"\n  - maybe the creator is his own audience\n- consists of abstract intellectual content that is distinct from any object that is its carrier\n\n### Properties of works\n\n- For every two or three one-off books there is a work like Steinbeck’s Grapes of Wrath that exists in hundreds of editions, and translations, and becomes a screenplay, a motion picture, and so on\n  - The first-published iteration of a work in such a set has been termed the **progenitor**\n- We have seen above the two main categories of instantiation — derivation and mutation. From research it has been demonstrated that bibliographic works have at least the following types (Smiraglia 2002, 11):\n\n    Derivations\n        simultaneous editions\n        successive editions\n        predecessors\n        amplifications\n        extractions\n        accompanying materials\n        musical presentation\n        notational transcription\n        persistent works\n    Mutations\n        translations\n        adaptations\n        performances\n- Furner demonstrates that the relationship between two documents that might be instantiations of the same work has the same identity as the relationship between two documents that might be about the same concept, because they are both members of the same class (12):\n\n> If I decide that Doc 1 instantiates Work A, what that amounts to is a judgment — an entirely subjective judgment made by me on a particular occasion — that Doc 1 has the property of being an instance of Work A, that Doc 1 is a member of the class of documents that share the property of instantiating Work A \\[…\\] These are just different ways of saying the same thing, and again we can also say that Doc 1 and Doc 2 are similar in the sense that they share the same property or that they are members of the same class. And again, if it turns out that Work B has exactly the same extension as Work A does — in other words, if it turns out that all and only the documents that instantiate Work A instantiate Work B — then we can say that Work A is the same work as Work B.\n\nA related aspect of the phenomenon of instantiation is the re-presentation of content, and it is this property that is endemic in the incorporation of information objects in retrieval systems in which large clusters of seemingly similar content must be simultaneously gathered and disambiguated. Empirical analysis of this phenomenon in museums and archives demonstrated the means by which not only visual representations of specific objects but also metadata associated with them require control — gathering and disambiguation — around a nominal anchor that usually is the identifier for the work \n\n- probably the most important empirical finding from the empirical research is the discovery that there is a cultural catalyst for the growth of a family of works all derived from a common progenitor. Initially, borrowing a phrase from Wilson (1968), these were called “bibliographic families”. In Functional Requirements for Bibliographic Records (FRBR, IFLA 1998) they are called “superworks”. These are works like Gone with the Wind that have achieved iconic status, and thus for which potentially thousands of iterations have come forth, all of which can be associated with a common progenitor through shared ideational and semantic content (Smiraglia 2007a). Nonetheless, not everything in the superwork set Gone with the Wind is equivalent with Margaret Mitchell’s novel. Instead, ideational nodes within the set (such as a screenplay) are related works that have their own instantiation sets. The problem for information retrieval, as stated earlier, is to simultaneously collocate and disambiguate these large sets of instantiations.\n\n![](/assets/images/2024-08-22-09-20-48.png)\n\n\n## The FRBR conceptual model and RDA\n\n- for [[prdct.frbr]], manifestations reside in specific, physical items\n- Change in ideational content results in a new work, change in semantic content results in a new expression, and the role of the publisher who brings an expression to market is recognized in the production of manifestations.\n\n### Issues with FRBR\n\n- precise implementation of the expression entity\n- gaps in the model, principally for aggregate works\n  - A conceptual model consisting of three types of aggregation — collections, augmentation aggregates and parallels — was reported in O’Neill and Žumer (2012)\n- Many of these problems have been tackled in a reinterpretation of the FRBR conceptual model from its original entity-relationship model into an object oriented model, FRBRoo or [[prdct.lrmoo]]  ","n":0.037}}},{"i":5912,"$":{"0":{"v":"Hashnode","n":1}}},{"i":5913,"$":{"0":{"v":"ECS in JS Storage Mechanisms","n":0.447},"1":{"v":"\n\n\n- [[p.hasURL]] https://javelin.hashnode.dev/ecs-in-js-storage-mechanisms\n- [[p.hasAuthor]] @eric-mcdaniel\n- [[p.hasTopic]] [[t.cs.entity-component-system]]\n","n":0.378}}},{"i":5914,"$":{"0":{"v":"Hapgood","n":1}}},{"i":5915,"$":{"0":{"v":"The Garden and the Stream a Technopastoral","n":0.378},"1":{"v":"\n\n\n- [[p.hasURL]] https://hapgood.us/2015/10/17/the-garden-and-the-stream-a-technopastoral/\n- [[p.hasCreator]] @mike-caufield\n- [[p.isRelated]] \n  - [[The Garden and the Stream|idea.the-garden-and-the-stream]]\n  - [[video.the-garden-and-the-stream-a-technopastoral]]\n- [[p.references]] [[ar.atlantic.as-we-may-think]]\n## Highlights\n\n- \"our survival as a species depends on us getting past the sweet, salty fat of “the web as conversation” and on to something more timeless, integrative, iterative, something less personal and less self-assertive, something more solitary yet more connected\"\n","n":0.132}}},{"i":5916,"$":{"0":{"v":"Hal","n":1}}},{"i":5917,"$":{"0":{"v":"Publishing Uncertainty on the Semantic Web Blurring the Lod Bubbles","n":0.316},"1":{"v":"\n\n- [[p.hasURL]] https://hal.inria.fr/hal-02167174/file/Publishing_Uncertainty_on_the_Semantic_Web__Bursting_the_LOD_bubbles__Final_Version_.pdf\n","n":0.577}}},{"i":5918,"$":{"0":{"v":"Golangexample","n":1}}},{"i":5919,"$":{"0":{"v":"A Lightweight Client Server Rpc Framework Tailored for Modern Webapps","n":0.316},"1":{"v":"\n\n- [[p.hasURL]] https://golangexample.com/a-lightweight-client-server-rpc-framework-tailored-for-modern-webapps/\n","n":0.577}}},{"i":5920,"$":{"0":{"v":"Gnomestew","n":1}}},{"i":5921,"$":{"0":{"v":"Entertainment Is Key","n":0.577},"1":{"v":"\n- url: https://gnomestew.com/entertainment-is-key/\n- mentions: [[book.robin-s-laws-of-good-game-mastering]]\n\n## Summary\n\n-  **Emotional Beats** Don’t be afraid to hit your characters in the feels. Some of these emotional beats will bleed through to the players, and give them feels as well.","n":0.169}}},{"i":5922,"$":{"0":{"v":"Gamedeveloper","n":1}}},{"i":5923,"$":{"0":{"v":"What I've Learned about Designing Multiplayer Games so Far","n":0.333},"1":{"v":"\n- https://www.gamedeveloper.com/design/what-i-ve-learned-about-designing-multiplayer-games-so-far\n- author: @daniel-cook","n":0.5}}},{"i":5924,"$":{"0":{"v":"Q&A Dissecting the Development of Dwarf Fortress with Creator Tarn Adams","n":0.302},"1":{"v":"\n- url: https://www.gamedeveloper.com/design/q-a-dissecting-the-development-of-i-dwarf-fortress-i-with-creator-tarn-adams\n- #highlight \n  - \"In gaming, there's the balance between Narrative and Simulation, between the pre-written story most games have, and making a deep world with a set of rules that can make many stories possible. Dwarf Fortress is one of the greatest arguments towards Simulation\" \n  - we want the player to be the \"official will of the fortress\" while the dwarves also exercise the autonomy they should be expected to have outside of their official duties.  This allows them to be actors in their own stories, which is a large part of where emergent narrative comes from.  At the same time, the player should be able to direct the general flow of their part of the game (this isn't crucial, really, but it's thought to be more fun than just watching a simulation, oftentimes, ha ha.)\n- [[p.hasSubject]] [[game.Dwarf-Fortress]] @tarn-adams","n":0.084}}},{"i":5925,"$":{"0":{"v":"Fortelabs","n":1}}},{"i":5926,"$":{"0":{"v":"Getting Things Done Personal Knowledge Management","n":0.408},"1":{"v":"\n\n\n- [[p.hasURL]] https://fortelabs.co/blog/gtd-x-pkm/\n- [[p.hasCreator]] @tiago-forte\n\n## importance of reference info\n\n> the relative importance of “non-actionable information” is rising. We can now expect to spend only a few months to a few years with one organization, which means our ability to capture, organize, and retrieve our ideas, and transfer them effectively from project to project and company to company, becomes more important than ever.\n\n> Allen's integrated total life-management system... \n\n> write-only syndrome:\n","n":0.12}}},{"i":5927,"$":{"0":{"v":"Forbes","n":1}}},{"i":5928,"$":{"0":{"v":"When Graphs Collide the Coming Merger of Property and Semantic Graphs","n":0.302},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.forbes.com/sites/cognitiveworld/2019/03/17/when-graphs-collide-the-coming-merger-of-property-and-semantic-graphs/\n\n- [[p.hasHighlight]]\n  - javascript may displace python as the default language for semantic applications\n\n","n":0.25}}},{"i":5929,"$":{"0":{"v":"Fluree","n":1}}},{"i":5930,"$":{"0":{"v":"Working with Graph Data","n":0.5},"1":{"v":"\n## Highlights\n\n- \"the notion of an entity as a container is useful and it feels intuitive. If we're modeling customer data, we want to be able to talk about a customer as an actual thing that has properties or attributes. The resolution here is to just acknowledge that you can impose that kind of organization onto an RDF graph, but it's a convenience for your thinking and communication, and not something that's technically reflected in the way RDF data is structured.\n\nWe also need to contend with the practical fact that we are representing our data using JSON objects, which actually are containers. How do we bridge this gap between RDF's notion of data as a non-hierarchical collection of nodes and arcs, and JSON's inherently hierarchical structure?\"\n","n":0.089}}},{"i":5931,"$":{"0":{"v":"Fast Company","n":0.707}}},{"i":5932,"$":{"0":{"v":"AI is going to transform Hollywood—but it won’t be a horror story","n":0.289},"1":{"v":"\n- url:\n  - https://www.fastcompany.com/90978537/ai-in-hollywood\n  - https://www.magzter.com/stories/Business/Fast-Company/Hollywood","n":0.408}}},{"i":5933,"$":{"0":{"v":"Farkouh","n":1}}},{"i":5934,"$":{"0":{"v":"Interactive Drama","n":0.707},"1":{"v":"\n- https://chris.farkouh.net/blog/interactive-drama\n- topics: #game-design [[t.drama.interactive]]  [[t.storytelling.fiction.interactive]] [[t.storytelling.interactive]]\n- author: @chris-farkouh\n- mentions: [[game.facade]] [[t.drama.theater.immersive]]\n\n## Highlights\n\n### Immersion Tactics in Theater\n\n- the spectators are not placed in front of a narrative unfolding in a linear progression.\n- The narrative premise is to actively explore the extents of the playing area in an attempt to reach its edges and unravel the story.\n- In that regard the story is presented to you as a puzzle, and it is for you the participant to piece it together in your own unique way. You experience the story as though you are part of the story, following the protagonist on a pathway to achieving their goal.\n- The use of suspense and anxiety can be used to guide an audience member through the narrative. By removing the participant from their comfort zone, their actions and reactions become influenced by both their instincts and the prompts that the storytelling experience gives them, creating a profound sense of non-cognitive ‘phenomenological’ immersion. Meanwhile the act of experimentation with the narrative structure and the temporal order of reception leaves the participant questioning their own subjective conclusion of the events they just experienced.\n\n## OK, but what makes a Video Game an Interactive Drama?\n\n### Storytelling Driving Player Emotion\n\n\n### Meaningful Interactions\n\n\n### Quick Time Events\n\n- context sensitive gameplay in which the player performs actions on the control device shortly after the appearance of an on screen instruction\n  - \"They are the key method of interaction within all story-driven games.\"\n  - t.2024.09.24.12 ugh\n\n### Emotive Character Roleplay\n\n### Steer Your Own Story\n\n### An Immersive Narrative Future\n\n- [[game.until-dawn]] introduced an emerging social concept: people were no longer exclusively playing these games, they were now willing to watch the gameplay as the moment to moment narrative and interaction was so compelling\n  - Bear in mind too that this immersive video game experience was underpinned by a 10,000 page script.\n- [[game.death-stranding]] (2019) is a hugely immersive story-driven game, blending the genres of Interactive Drama and RPG playability simultaneously to great effect. This is certainly the early signals of a new era of advanced narrative interaction occurring across video game genres.","n":0.054}}},{"i":5935,"$":{"0":{"v":"Emotional State Machine","n":0.577},"1":{"v":"\n- https://chris.farkouh.net/blog/emotional-state-machine\n\n\n\n## Highlights\n\n- Rather than producing vast branches of storyline that alternate based on player activity, what if the interactions within the story are bent as a reaction by the game to the way in which the player is perceived by the virtual world according to their actions?\n  - In other words, the sequential presentation of key events does not necessarily change drastically in this scenario and as such the player is a guaranteed recipient of all of the core content which is produced by the studio as part of the game production, but the experience that the player receives within that narrative structure is significantly tempered with during the course of the gameplay by an underlying ‘game intelligence’.\n  - In support of this @keith-stuart cited in 2019, ‘the mainstream future of interactive storytelling is likely to be a clever combination of A.I and authored content: we still get a gripping handwritten plot, but we also get characters and story elements that seem to be reactive to us as individuals’.\n  - @emily-short, a prolific writer, game designer and academic of the subject of narrative structure within interactive storytelling, brings reference to this concept in an article from 2016 in which she coins the phrase ‘Salience-based narrative’, or put simply ‘interactive narratives that pick a bit of content out of a large pool depending upon which content element is judged to be most applicable at the moment’.","n":0.065}}},{"i":5936,"$":{"0":{"v":"Eventiotic","n":1}}},{"i":5937,"$":{"0":{"v":"Development of Multi Agent Framework in Java Script","n":0.354},"1":{"v":"\n- url: https://www.eventiotic.com/eventiotic/files/Papers/URL/540b95d8-b703-47c2-96b8-ad5131ab67ed.pdf\n- subject: [[prdct.siebog-lite]] ([[prdct.xjaf]] and [[prdct.radigost]]) \n- [[p.supports]] [[prdct.fipa]]\n- [[p.presented]] \n\n## [[p.thought]]\n","n":0.267}}},{"i":5938,"$":{"0":{"v":"Enterprise Knowledge","n":0.707}}},{"i":5939,"$":{"0":{"v":"What Software Engineering Can Teach Knowledge Engineers about Version Control","n":0.316},"1":{"v":"\n- https://enterprise-knowledge.com/what-software-engineering-can-teach-knowledge-engineers-about-version-control/\n- mentions: [[prdct.protege.web]] [[prdct.pool-party]]\n\n\n- yada yada","n":0.378}}},{"i":5940,"$":{"0":{"v":"Top 5 Tips for Managing and Versioning an Ontology","n":0.333},"1":{"v":"\n- https://enterprise-knowledge.com/top-5-tips-for-managing-and-versioning-an-ontology/\n- related: [[ar.enterprise-knowledge.what-software-engineering-can-teach-knowledge-engineers-about-version-control]]\n\n## Summary\n\n- Track Version Information within the Ontology\n  - Tracking the version number in the URL means that the namespace changes with every new update, which can cause difficulties with software integrations. As a result, this method of version tracking is generally not recommended.\n- Use the Semantic Versioning (SEMVER) Standard\n- Have a Plan for Deprecation\n- Keep a changelog\n- Deliver the right version\n  - t.2024.07.16.11 seems slightly inconsistent with not tracking version number in the URL ","n":0.113}}},{"i":5941,"$":{"0":{"v":"Dolthub","n":1}}},{"i":5942,"$":{"0":{"v":"so You Want Git for Data","n":0.408},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.dolthub.com/blog/2020-03-06-so-you-want-git-for-data/\n- [[p.isRelated]] [[prdct.dolt]]\n\n## Aspects of \"Git\" that you might want for data \n\n- [[t.cs.version-control]] ^aMM7kNHdxfTR\n  - rollbacks\n  - diffs\n  - lineage\n  - branch-merge\n  - sharing\n  - addressability\n  - multiple remotes\n  - staging area\n- [[t.cs.data.catalog]]\n  - thriving open data community\n  - collaborate remotely and asynchronously\n  - pull requests\n  - create issues referring to certain parts of the data\n- [[t.cs.data.types]]\n- transformation can happen externally\n- [[t.cs.data.labelling]] can happen as statement metadata? ^FJEbyfH4liTs\n\n## Three types of solutions\n\nThe products fell into three general categories:\n\n    1. [[Data catalogs|t.cs.data.catalog]]\n    2. Data pipeline versioning\n    3. Versioned databases\n","n":0.105}}},{"i":5943,"$":{"0":{"v":"Dev To","n":0.707}}},{"i":5944,"$":{"0":{"v":"Online Visual Novel in Godot Case Study on Sentou Gakuen","n":0.316},"1":{"v":"\n- https://dev.to/godot/online-visual-novel-in-godot-case-study-on-sentou-gakuen-33ce\n\n\n## Contents\n\n-   [Traditional Visual Novels](https://gakuen.org/posts/online-visual-novel//#traditional-visual-novels)\n-   [Gameplay: Dynamic vs. Static](https://gakuen.org/posts/online-visual-novel//#gameplay-dynamic-vs-static)\n-   [Interactive Visual Novels](https://gakuen.org/posts/online-visual-novel//#interactive-visual-novels)\n-   [Key Challenge: A Persistent World](https://gakuen.org/posts/online-visual-novel//#key-challenge-a-persistent-world)\n    -   [The Problem: Synchronization in a Dynamic World](https://gakuen.org/posts/online-visual-novel//#the-problem-synchronization-in-a-dynamic-world)\n    -   [The Solution: Real-Time Synchronization Using Unix Timestamps](https://gakuen.org/posts/online-visual-novel//#the-solution-real-time-synchronization-using-unix-timestamps)\n-   [Key Challenge: Keeping the World Alive](https://gakuen.org/posts/online-visual-novel//#key-challenge-keeping-the-world-alive)\n    -   [The Problem: Making it Feel Lively](https://gakuen.org/posts/online-visual-novel//#the-problem-making-it-feel-lively)\n    -   [The Solution: The World Full of Happenings](https://gakuen.org/posts/online-visual-novel//#the-solution-the-world-full-of-happenings)\n-   [Key Challenge: Chat System Integration](https://gakuen.org/posts/online-visual-novel//#key-challenge-chat-system-integration)\n    -   [The Problem: Managing Concurrent Chats](https://gakuen.org/posts/online-visual-novel//#the-problem-managing-concurrent-chats)\n    -   [The Solution: Transition to a “Chat Box”](https://gakuen.org/posts/online-visual-novel//#the-solution-transition-to-a-chat-box)\n-   [Key Challenge: Player versus Player](https://gakuen.org/posts/online-visual-novel//#key-challenge-player-versus-player)\n    -   [The Problem: Can this be done?](https://gakuen.org/posts/online-visual-novel//#the-problem-can-this-be-done)\n    -   [The Solution: Asynchronous PvP](https://gakuen.org/posts/online-visual-novel//#the-solution-asynchronous-pvp)\n-   [Key Challenge: What Engine to Choose?](https://gakuen.org/posts/online-visual-novel//#key-challenge-what-engine-to-choose)\n-   [Wrappping Up](https://gakuen.org/posts/online-visual-novel//#wrappping-up)","n":0.101}}},{"i":5945,"$":{"0":{"v":"Cnbc","n":1}}},{"i":5946,"$":{"0":{"v":"What Good Leaders and Managers Look like According to a Top Ceo of 14 Years","n":0.258},"1":{"v":"\r\ndetail-orientation correlates? with performance highly for entry-level managers\r\n\r\n![](/assets/images/2021-10-16-17-21-45.png)\r\n\r\n## Thoughts\r\n\r\n- entrepreneur CEOs (with small or no teams, like @kevin-lin ) need #detail-orientation as well as #adaptability, #curiosity, #ambiguity-tolerance and #risk-tolerance\r\n","n":0.186}}},{"i":5947,"$":{"0":{"v":"Cmu","n":1}}},{"i":5948,"$":{"0":{"v":"RTI Synopsis - the Role of Time","n":0.378},"1":{"v":"\n\n- [[p.hasURL]] https://www.cs.cmu.edu/afs/cs/academic/class/15413-s99/www/hla/doc/rti_synopsis/03-The_Role_of_Time/The_Role_of_Time.html\n","n":0.577}}},{"i":5949,"$":{"0":{"v":"Ceur Ws","n":0.707}}},{"i":5950,"$":{"0":{"v":"R43ples Revisions for Triples","n":0.5},"1":{"v":"\n\n\n- [[p.hasURL]] http://ceur-ws.org/Vol-1215/paper-03.pdf\n- [[p.hasFeature]]\n  - uses named graphs to semantically store the differences between revisions. Furthermore it\n  -  allows direct access and manipulation of revisions with SPARQL. \n","n":0.189}}},{"i":5951,"$":{"0":{"v":"Cameronneylon","n":1}}},{"i":5952,"$":{"0":{"v":"Semantics in the Real World Part I Why the Triple Needs to Be a Quint or a Sext","n":0.236},"1":{"v":"\n\n\n- [[p.hasURL]] http://cameronneylon.net/blog/semantics-in-the-real-world-part-i-why-the-triple-needs-to-be-a-quint-or-a-sext-or/\n- [[p.hasTopic]] [[t.km.reification]] [[t.km.attribution]] [[t.km.lineage]] [[t.km.ambiguity]] [[t.km.uncertainty]] ?\n\n- [[p.thought]]\n  - all you need is reification\n    - but arbitrary number of terms is a nice convenience \n","n":0.189}}},{"i":5953,"$":{"0":{"v":"C2","n":1}}},{"i":5954,"$":{"0":{"v":"Actor Vs Agent","n":0.577},"1":{"v":"\n- [[p.hasURL]] https://wiki.c2.com/?ActorVsAgent\n- [[p.excerptedFrom]] [[book.efficient-node-js-a-beyond-the-basics-guide]]\n- [[p.hasTopic]] [[t.cs.actors]] [[t.cs.agents]]\n\n## [[p.hadContent]]\n\n\nActor Vs Agent\nAn 'Actor' from ActorsModel is similar to objects in OOP:\n\n  passive between processing messages; presence of object in system is irrelevant unless hooked into a framework that will send messages to it\n    communicate to an actor by sending a message to it; you must know the actor exists\n    while processing a message, an actor may send more messages, create more actors, or update local state\n    actors that need extra information in order to complete a task must store it locally or gather it via messages with replies\n    actors tend to process inputs one at a time, and thus need to coordinate permutations\n    actors using replies must wait upon them; without discipline, this can result in cyclic waits.\n\nAn 'Agent', as from ConcurrentConstraintProgramming or ReactiveDemandProgramming, is different:\n\n  active continuously - making observations on an environment, constraint store, or perhaps other agents\n    presence of agent may also affect the system, i.e. applying a rule or demand; nature of effect distinguishes Agent systems\n    communicate to an agent by modifying something that it is observing; you do not need to know that the agent exists\n    upon observing certain conditions, in some systems agents might spawn new agents or update local state\n    the information that agents need to perform their jobs is continuously maintained by their runtime environment\n    agents tend to process all relevant information at once, and thus need consider only combinations\n    it takes some discipline to prevent 'feedback' systems, similar to placing a microphone near a speaker\n\nThey also share a number of similarities: concurrency, TuringComplete.\n\nOne can emulate Agents using Actors, but doing so requires a lot of framework and complexity. In particular, in Agent systems the specification of what data the framework must provide to a given agent is implicit in the source-code - and is easily subject to ad-hoc queries and calculations to allow different 'views' of the system. When emulating agents with actors, this information must usually be represented twice (once in the source code, once to hook the framework) and is often subject to a rigid view (though some systems do support flexible scripting languages to gather the data; at least one supports ad-hoc distributed SQL). These frameworks that allow us to treat Actors as Agents are often called PublishSubscribeModels. A standardized pubsub model is DataDistributionService by ObjectModelingGroup. Related is the ObserverPattern, TupleSpace, BlackboardMetaphor, ComplexEventProcessing.\n\nIt seems to me that, as far as SoftwareEngineering properties go, Agents are superior to Actors in every way. Agents are generally 'pluggable' - you can easily drop them onto a system, or just as easily pull them out; many are even hot-pluggable or subject to LiveProgramming, which allows a shorter edit-test-debug cycle. **Dealing with combinations of continuous inputs, rather than permutations of concurrent messages, dodges a great deal of complexity (roughly '2^N' instead of 'N!') without preventing agents from introducing a bit of ordering where critical.** Agents avoid a considerable amount of state associated with hooking into a system, cache management, and concurrency control (i.e. where Actors would require use of serializers).\n\nA weakness of many agent systems is the use of a shared data space (tuple space, blackboard, constraint store) which raises many concurrency-control, authority, and confidentiality issues. Basically, with a central shared space, you must be very careful about inclusion of untrusted code. If one is not careful, it may also lead to a CentralPointOfFailure or a bottleneck, though those problems can be mitigated by distribution and replication of the space. But, if we reject a shared space, then we must answer: what do agents observe, how do agents affect the system, and how do we handle concurrency?   ^q42yd20t54qm\n\nHybrid Actor-Agent Models\n\nIf we want to avoid a common data-space, then one obvious possibility is that agents could observe one another.\n\nTo support security we don't allow agents unrestricted access to one another (since an agent might contain sensitive information), so instead we support InformationHiding: agents may expose a function of their state and observations. To achieve security, we utilize ObjectCapabilityModel security patterns. For example, one can use FacetPattern to narrow the interface from one agent to another. ObserverPattern and signal libraries might be considered a naive implementation of this design. They have been used to good effect, but are inflexible and rigid: they don't allow effective support for functions of another actor's state and observations. Done well, we could presumably have an agent represent the state of an entire SQL database, with the argument to the function being an ad-hoc SQL query.\n\nBut this leaves unanswered the challenges of affecting the system, and handling concurrency.\n\nIf we were only interested in observation and analysis, it would be sufficient to update some local state. Observers could be scheduled to recompute their observations as needed. This corresponds, roughly, to FunctionalReactiveProgramming. But agents need non-local SideEffects, lest you harm their utility as \"pluggable\" units that will affect a system.\n\nFor non-local SideEffects, many systems have resorted to old faithful MessagePassing. Upon observing certain conditions or changes in the environment, the 'agent-actor' hybrid sends some messages to affect other agent-actors in the environment. In addition to observing one another, agents-actors directly receive and send messages. One gets the expressiveness of Actors, and the pluggable nature of agents. Unfortunately, as is the common case with hybrid designs, you also accept the complexities of both: message loss, GarbageCollection issues, order of message arrival, concurrency control. If one isn't very careful, using type and effect systems and such, then a lot of potential optimizations are also hurt. But the combination is promising, and in some ways pays for itself; e.g. it is very easy to create an observable queue and have a bunch of pluggable actor-agents reacting to whether it is full or empty. That is simpler than the queue itself knowing about which actors need to use it, simpler than working with threads.\n\nI pursued a hybrid design, focusing on the ad-hoc observer functions, with a bit of type-system layering to ensure I could still achieve various optimizations. It was, I thought, the best I'd be able to do: distributed actors with access to FunctionalReactiveProgramming-style ad-hoc distributed query functions. I was wrong!\n\nReactiveDemandProgramming\n\nSuppose instead that agents affect one another through a mechanism just as declarative, reactive, and continuous as the observation itself. In fact, assume observation is a potential source of effect, since that allows some sane behaviors, like demand-driven sensors: one could easily represent an agent that powers up a security camera only while another agent is trying to see the feed. Let's call these 'demand-effects', a limited class of SideEffect that occurs between agents. The resulting paradigm is ReactiveDemandProgramming.\n\nIn RDP, all side-effects between agents are demand-effects. Demand-effects are indistinguishable from observer-effects. Observations are reactive and continuous, changing over time, and so are the demand-effects. Demand-effects are idempotent, which allows a huge range of optimizations; for example, ten demands for the same information can be combined into one, with MultiCast, rather than processing the same request ten times. Or if ten different agents share partial structure and state, then they can be partially combined into a single agent with multiple active states. Demand-effects are continuous and concurrent - they are all active at once.\n\nBut local effects are still possible.\n\nBased on observations, agents may perform a transition to a new state. During transition, they may spawn new agents or perform other 'discrete' activities. The understanding of events, thus, is entirely local to each agent. The 'new state' allows an agent to keep some memory. Unlike actors, however, RDP doesn't need much non-regenerable memory. Actors programs use a lot of memory for hooking into frameworks, explicit caching, patterns for managing concurrent requests, and for message-queues. RDP agents are hooked in by default, have implicit caching, handle concurrent requests without patterns, and 'agents maintain' communications rather than fire-and-forget, and so all connections are implicit in the actor state and source-code. (This also supports resilience after disruption or persistence.)\n\nThus, while RDP agents in general are reactive StateMachines, RDP programs in-the-large can get by with very little use of internal state. A bit of short-term memory at the sensors wouldn't hurt, though. And demands can 'drive' real-world state easily enough.\n\nTo abstract the construction of agents, one uses an agent that will spawn new agents upon observing the demand. This is a FactoryPattern. The signature I'm considering is Agent -> Agent -> Agent (called Factory -> Spec -> Product). The use of an Agent as a Spec is optional, but does avoid a few semantic issues with a 'continuous, time-varying demand' potentially producing a logically infinite set of Products. Instead, one agent input results in up to one agent output. (No guarantee the result is 'new', and the Product may also be time-varying.)\n\nImplementation isn't anything special. One uses bi-directional subscriptions (use ID to both push the changes to 'demand' and to receive updates). The receiving agent is allowed to use your demands to both control systems and to answer other queries. Thus, supposing we have various agents asking for F(X), F(Y), and F(Z) for some confined and stateless agent F, then the results would be F(X,{X,Y,Z}), F(Y,{X,Y,Z}), and F(Z,{X,Y,Z}). Of course, that is only for confined and stateless agent. A stateful agent could include information from past demands. An unconfined agent could be observing yet another agent G, and be getting results such as: G(X,{X,Y,L,M,N}) and G(Y,{X,Y,L,M,N}).\n\nWith the advent of ReactiveDemandProgramming, I think ActorsModel should be retired, along with similar MessagePassing systems - such as ObjectOrientedProgramming. I cannot think of any SoftwareEngineering aspect where ActorsModel or MessagePassing is superior.\n\nLast edit June 1, 2010\n","n":0.025}}},{"i":5955,"$":{"0":{"v":"Bobdc","n":1}}},{"i":5956,"$":{"0":{"v":"Using Owlincludes","n":0.707},"1":{"v":"\n- https://www.bobdc.com/blog/using-owlincludes/\n\n## Highlights\n\n- [[prdct.pellet]] gives me a report on the non-DL aspects of my ontology and what I can add to make it more DL compliant ^hjoz18cgiza1\n\n## Discussion\n\n\n### Why do you include the data in the ontology rather than the other way around?\n\nWhat makes the most sense to me, which would be easy enough using owl:includes, would be to have a separate skeleton document that has one pointer to the data document and another pointer to the ontology to say that, for a given processing need, these two are to be used together.\n\n- t.2024.10.12.17 I agree with the poster, just include the ontology in the data","n":0.097}}},{"i":5957,"$":{"0":{"v":"Bitsrc","n":1}}},{"i":5958,"$":{"0":{"v":"Sometimes JavaScript Is Not the Right Answer","n":0.378},"1":{"v":"\n- [[p.hasURL]] https://blog.bitsrc.io/sometimes-javascript-is-not-the-right-answer-959abb115693\n- [[p.hasSummaryPoints]]\n  - javascript [[p.isCounterIndicatedFor]]\n    - [[t.cs.data.science]] [[t.cs.ml]] \n","n":0.302}}},{"i":5959,"$":{"0":{"v":"Bbc","n":1}}},{"i":5960,"$":{"0":{"v":"The Secret to Living a Meaningful Life","n":0.378},"1":{"v":"\n\n\n- [[p.hasURL]] https://getpocket.com/explore/item/the-secret-to-living-a-meaningful-life\n- [[p.hasSubject]] [[t.pm]] \n- [[p.hasHighlight]]\n  -  Personal Projects Analysis: meaning, manageability, connection (to others), negative emotions and positive emotions. \n  -  free traits: not in our nature, but can still express them if the time/project/motivation is right\n  -  Choose the right projects, and approach them in the right way, and you can make your life richer and more enjoyable. \n  -  romantic partners tend to be happier together if they share some of the same personal projects\n  -  \"concept matching\": find metaphoric parallels between the stalled project and something you know how to succeed at\n  -  lives are governed by three forces:\n     -  biogenic\n     -  sociogenic (how we were raised; culture; the company we keep)\n     -  idiogenic (projects and free traits)\n  -  “Whereas contexts embed us, projects pull us forward into new possibilities,”\n","n":0.086}}},{"i":5961,"$":{"0":{"v":"Balisage","n":1}}},{"i":5962,"$":{"0":{"v":"Transcending Triples","n":0.707},"1":{"v":"\n\n\n- https://www.balisage.net/Proceedings/vol10/html/Dubinko01/BalisageVol10-Dubinko01.html is slightly interesting\n  - Trust, Security, and [[t.km.meta-knowledge.provenance]]\n  - Asserting facts over time\n","n":0.258}}},{"i":5963,"$":{"0":{"v":"Au","n":1}}},{"i":5964,"$":{"0":{"v":"Semantics of Temporal Models with Multiple Temporal Dimensions","n":0.354},"1":{"v":"\n\n\n- [[p.hasURL]] https://pure.au.dk/ws/files/307/0003104.pdf\n- [[p.hasAuthor]] @Peter-Kraft @Jens-Otto-Sørensen\n- [[p.subClassOf]] [[c.paper]]\n","n":0.354}}},{"i":5965,"$":{"0":{"v":"Atlantic","n":1}}},{"i":5966,"$":{"0":{"v":"Video Games Are Better Without Stories","n":0.408},"1":{"v":"\n- https://www.theatlantic.com/technology/archive/2017/04/video-games-stories/524148/\n- author: @ian-bogost\n\n## Highlights\n\n- A longstanding dream: Video games will evolve into [[interactive stories|t.storytelling.interactive]]\n  - players could interact with computerized characters as round as those in novels or films, making choices that would influence an ever-evolving plot. It would be like living in a novel, where the player’s actions would have as much of an influence on the story as they might in the real world. ^6abg9iz5r68q\n- It’s an almost impossible bar to reach, for cultural reasons as much as technical ones.\n  - [[t.storytelling.environmental]] is a shortcut\n    - Are the resulting interactive stories really interactive, when all the player does is assemble something from parts?\n    - Are they really stories, when they are really environments?\n    - And most of all, are they better stories than the more popular and proven ones in the cinema, on television, and in books?\n      - alas, the best interactive stories are still worse than even middling books and films\n- the first 3-D games were designed to be empty so that they would run.\n- \"To dream of the [[t.storytelling.holodeck]] is to dream a complicated dream of the novel.\"\n- Left less explored were the other aspects of realistic, physical environments. The inner thoughts and outward behavior of simulated people, for example, beyond the fact of their collision with other objects.\n- \"Incremental improvements in visual fidelity make 3-D worlds seem more and more real. But those worlds feel even more incongruous when the people that inhabit them behave like animatronics and the environments work like Potemkin villages.\" ^k9b2u20i0q0o\n- the very concept of a Holodeck-aspirational interactive story implies that the player should be able to exert agency upon the dramatic arc of the plot. ^0mdcsuektdle\n- Environmental storytelling offers a solution to this conundrum.\n  -  Instead of trying to resolve the matter of simulated character and plot, the genre gives up on both, embracing scripted action instead. The player’s experience becomes that of a detective, piecing together narrative coherence from fragments conveniently left behind in the game’s physical environment. ^a497l444fdio\n- As in Doom and BioShock and almost every other first-person game ever made, the emptiness of the environment becomes essential to its operation. 3-D games are settings as much as experiences—perhaps even more so.\n- [[game.what-remains-of-edith-finch]] \n  - a series of a dozen or so narrative vignettes, in which Edith accesses prohibited parts of the unusual house, finally learning the individual fates of her forebears by means of the fragments they left behind—diaries, letters, recordings, and other mementos. ^uintr5ran0xw\n  - aesthetically coherent, fusing the artistic sensibilities of Edward Gorey, Isabel Allende, and Wes Anderson. The writing is good, an uncommon accomplishment in a video game. On the whole, there is nothing to fault in What Remains of Edith Finch. It’s a lovely little title with ambitions scaled to match their execution. Few will leave it unsatisfied. ^1dy2vg3q80ks\n  - The story is entirely linear, and interacting with the environment only gets in the way, such as when a particularly dark hallway makes it unclear that the next scene is right around the corner. ^jhjxrtw7u803\n  - invites players to abandon the dream of [[t.storytelling.interactive]] ^0m07hy7u97bv\n- Think of a medium as the aesthetic form of common materials. Poetry aestheticizes language. Painting aestheticizes flatness and pigment. Photography does so for time. Film, for time and space. Architecture, for mass and void. Television, for economic leisure and domestic habit. Sure, yes, those media can and do tell stories. But the stories come later, built atop the medium’s foundations. ^vcp7i03sguei\n- Players and creators have been mistaken in merely hoping that they might someday share the stage with books, films, and television, let alone to unseat them.\n  - To use games to tell stories is a fine goal, but it’s also an unambitious one. ^1zkjt6vkyokj\n    - Games are not a new, interactive medium for stories.\n    - games are the aesthetic form of everyday objects. ^k9bfngdvg41y\n      - Games show players the unseen uses of ordinary materials.\n  - As the only mass medium that arose after postmodernism, it’s no surprise that those materials so often would be the stuff of games themselves. More often than not, games are about the conventions of games and the materials of games—at least in part. Texas Hold ’em is a game made out of Poker. Candy Crush is a game made out of Bejeweled. Gone Home is a game made out of BioShock.\n  - Yes, sure, you can tell a story in a game. But what a lot of work that is, when it’s so much easier to watch television, or to read.\n  - A greater ambition, which the game accomplishes more effectively anyway: \n    - to show the delightful curiosity that can be made when stories, games, comics, game engines, virtual environments—and anything else, for that matter—can be taken apart and put back together again unexpectedly.\n  - To dream of the Holodeck is just to dream a complicated dream of the novel. ^am8zjmvo93jr\n  - If there is a future of games, let alone a future in which they discover their potential as a defining medium of an era, it will be one in which games abandon the dream of becoming narrative media and pursue the one they are already so good at: taking the tidy, ordinary world apart and putting it back together again in surprising, ghastly new ways.\n\n## Thoughts\n\n- from D&D experience, I know that we can generate narratives from gaming\n  - possibly they're not good stories to anyone except the players involved","n":0.033}}},{"i":5967,"$":{"0":{"v":"The Great American Novels","n":0.5},"1":{"v":"\n- url: https://www.theatlantic.com/books/archive/2024/03/best-books-american-fiction/677479/\n\n## Selections\n\nThe Great Gatsby\n\nF. Scott Fitzgerald\n\n1925\nAn American Tragedy\n\nTheodore Dreiser\n\n1925\nThe Making of Americans\n\nGertrude Stein\n\n1925\nDeath Comes for the Archbishop\n\nWilla Cather\n\n1927\nA Farewell to Arms\n\nErnest Hemingway\n\n1929\nPassing\n\nNella Larsen\n\n1929\nThe Sound and the Fury\n\nWilliam Faulkner\n\n1929\nAbsalom, Absalom!\n\nWilliam Faulkner\n\n1936\nNightwood\n\nDjuna Barnes\n\n1936\nEast Goes West\n\nYounghill Kang\n\n1937\nTheir Eyes Were Watching God\n\nZora Neale Hurston\n\n1937\nU.S.A.\n\nJohn Dos Passos\n\n1937\nAsk the Dust\n\nJohn Fante\n\n1939\nThe Big Sleep\n\nRaymond Chandler\n\n1939\nThe Day of the Locust\n\nNathanael West\n\n1939\nThe Grapes of Wrath\n\nJohn Steinbeck\n\n1939\nNative Son\n\nRichard Wright\n\n1940\nThe Heart Is a Lonely Hunter\n\nCarson McCullers\n\n1940\nA Time to Be Born\n\nDawn Powell\n\n1942\nAll the King’s Men\n\nRobert Penn Warren\n\n1946\nThe Street\n\nAnn Petry\n\n1946\nIn a Lonely Place\n\nDorothy B. Hughes\n\n1947\nThe Mountain Lion\n\nJean Stafford\n\n1947\nThe Catcher in the Rye\n\nJ. D. Salinger\n\n1951\nCharlotte’s Web\n\nE. B. White\n\n1952\nInvisible Man\n\nRalph Ellison\n\n1952\nFahrenheit 451\n\nRay Bradbury\n\n1953\nMaud Martha\n\nGwendolyn Brooks\n\n1953\nThe Adventures of Augie March\n\nSaul Bellow\n\n1953\nLolita\n\nVladimir Nabokov\n\n1955\nGiovanni’s Room\n\nJames Baldwin\n\n1956\nPeyton Place\n\nGrace Metalious\n\n1956\nDeep Water\n\nPatricia Highsmith\n\n1957\nNo-No Boy\n\nJohn Okada\n\n1957\nOn the Road\n\nJack Kerouac\n\n1957\nThe Haunting of Hill House\n\nShirley Jackson\n\n1959\nCatch-22\n\nJoseph Heller\n\n1961\nA Wrinkle in Time\n\nMadeleine L'Engle\n\n1962\nAnother Country\n\nJames Baldwin\n\n1962\nOne Flew Over the Cuckoo’s Nest\n\nKen Kesey\n\n1962\nPale Fire\n\nVladimir Nabokov\n\n1962\nThe Zebra-Striped Hearse\n\nRoss Macdonald\n\n1962\nThe Bell Jar\n\nSylvia Plath\n\n1963\nThe Group\n\nMary McCarthy\n\n1963\nThe Crying of Lot 49\n\nThomas Pynchon\n\n1966\nA Sport and a Pastime\n\nJames Salter\n\n1967\nCouples\n\nJohn Updike\n\n1968\nDo Androids Dream of Electric Sheep?\n\nPhilip K. Dick\n\n1968\nDivorcing\n\nSusan Taubes\n\n1969\nPortnoy’s Complaint\n\nPhilip Roth\n\n1969\nSlaughterhouse-Five\n\nKurt Vonnegut\n\n1969\nAre You There God? It’s Me, Margaret\n\nJudy Blume\n\n1970\nDesperate Characters\n\nPaula Fox\n\n1970\nPlay It as It Lays\n\nJoan Didion\n\n1970\nLog of the S.S. The Mrs Unguentine\n\nStanley Crawford\n\n1972\nMumbo Jumbo\n\nIshmael Reed\n\n1972\nSula\n\nToni Morrison\n\n1973\nThe Revolt of the Cockroach People\n\nOscar Zeta Acosta\n\n1973\nOreo\n\nFran Ross\n\n1974\nThe Dispossessed\n\nUrsula K. Le Guin\n\n1974\nWinter in the Blood\n\nJames Welch\n\n1974\nCorregidora\n\nGayl Jones\n\n1975\nSpeedboat\n\nRenata Adler\n\n1976\nCeremony\n\nLeslie Marmon Silko\n\n1977\nSong of Solomon\n\nToni Morrison\n\n1977\nA Contract With God\n\nWill Eisner\n\n1978\nDancer From the Dance\n\nAndrew Holleran\n\n1978\nThe Stand\n\nStephen King\n\n1978\nKindred\n\nOctavia E. Butler\n\n1979\nThe Dog of the South\n\nCharles Portis\n\n1979\nHousekeeping\n\nMarilynne Robinson\n\n1980\nThe Salt Eaters\n\nToni Cade Bambara\n\n1980\nLittle, Big: Or, the Fairies’ Parliament\n\nJohn Crowley\n\n1981\nOxherding Tale\n\nCharles Johnson\n\n1982\nMachine Dreams\n\nJayne Anne Phillip\n\n1984\nBlood Meridian\n\nCormac McCarthy\n\n1985\nA Summons to Memphis\n\nPeter Taylor\n\n1986\nWatchmen\n\nAlan Moore and Dave Gibbons\n\n1986\nBeloved\n\nToni Morrison\n\n1987\nDawn\n\nOctavia E. Butler\n\n1987\nGeek Love\n\nKatherine Dunn\n\n1989\nTripmaster Monkey\n\nMaxine Hong Kingston\n\n1989\nDogeaters\n\nJessica Hagedorn\n\n1990\nAmerican Psycho\n\nBret Easton Ellis\n\n1991\nHow the García Girls Lost Their Accents\n\nJulia Alvarez\n\n1991\nMating\n\nNorman Rush\n\n1991\nBastard Out of Carolina\n\nDorothy Allison\n\n1992\nThe Secret History\n\nDonna Tartt\n\n1992\nSo Far From God\n\nAna Castillo\n\n1993\nStone Butch Blues\n\nLeslie Feinberg\n\n1993\nThe Shipping News\n\nAnnie Proulx\n\n1993\nNative Speaker\n\nChang-rae Lee\n\n1995\nSabbath’s Theater\n\nPhilip Roth\n\n1995\nUnder the Feet of Jesus\n\nHelena María Viramontes\n\n1995\nInfinite Jest\n\nDavid Foster Wallace\n\n1996\nI Love Dick\n\nChris Kraus\n\n1997\nUnderworld\n\nDon DeLillo\n\n1997\nThe Intuitionist\n\nColson Whitehead\n\n1999\nBlonde\n\nJoyce Carol Oates\n\n2000\nHouse of Leaves\n\nMark Z. Danielewski\n\n2000\nThe Amazing Adventures of Kavalier & Clay\n\nMichael Chabon\n\n2000\nThe Last Samurai\n\nHelen DeWitt\n\n2000\nThe Quick and the Dead\n\nJoy Williams\n\n2000\nErasure\n\nPercival Everett\n\n2001\nI, the Divine\n\nRabih Alameddine\n\n2001\nThe Corrections\n\nJonathan Franzen\n\n2001\nCaramelo\n\nSandra Cisneros\n\n2002\nPerma Red\n\nDebra Magpie Earling\n\n2002\nThe Russian Debutante’s Handbook\n\nGary Shteyngart\n\n2002\nThe Namesake\n\nJhumpa Lahiri\n\n2003\nVeronica\n\nMary Gaitskill\n\n2005\nThe Brief Wondrous Life of Oscar Wao\n\nJunot Díaz\n\n2007\nA Visit From the Goon Squad\n\nJennifer Egan\n\n2010\nI Hotel\n\nKaren Tei Yamashita\n\n2010\nOpen City\n\nTeju Cole\n\n2011\nSalvage the Bones\n\nJesmyn Ward\n\n2011\nThe Round House\n\nLouise Erdrich\n\n2012\nAmericanah\n\nChimamanda Ngozi Adichie\n\n2013\nNevada\n\nImogen Binnie\n\n2013\nA Brief History of Seven Killings\n\nMarlon James\n\n2014\nFamily Life\n\nAkhil Sharma\n\n2014\nFates and Furies\n\nLauren Groff\n\n2015\nThe Fifth Season\n\nN. K. Jemisin\n\n2015\nThe Sellout\n\nPaul Beatty\n\n2015\nThe Sympathizer\n\nViet Thanh Nguyen\n\n2015\nAmiable With Big Teeth\n\nClaude McKay\n\n2017\nLincoln in the Bardo\n\nGeorge Saunders\n\n2017\nSabrina\n\nNick Drnaso\n\n2018\nSeverance\n\nLing Ma\n\n2018\nThere There\n\nTommy Orange\n\n2018\nLost Children Archive\n\nValeria Luiselli\n\n2019\nNothing to See Here\n\nKevin Wilson\n\n2019\nThe Old Drift\n\nNamwali Serpell\n\n2019\nNo One Is Talking About This\n\nPatricia Lockwood\n\n2021\nThe Love Songs of W. E. B. Du Bois\n\nHonorée Fanonne Jeffers\n\n2021\nBiography of X\n\nCatherine Lacey\n\n2023","n":0.048}}},{"i":5968,"$":{"0":{"v":"The Dark Side of Emotional Intelligence","n":0.408},"1":{"v":"\n\n\nEQ is a great power that should come with great responsibility\n\n\n- [[p.hasURL]] https://www.theatlantic.com/health/archive/2014/01/the-dark-side-of-emotional-intelligence/282720/\n\n## [[hasQuotes]]\n\n- > when people hone their emotional skills, they become better at manipulating others. When you’re good at controlling your own emotions, you can disguise your true feelings. When you know what others are feeling, you can tug at their heartstrings and motivate them to act against their own best interests \n- > when a leader gave an inspiring speech filled with emotion, the audience was less likely to scrutinize the message and remembered less of the content. Ironically, audience members were so moved by the speech that they claimed to recall more of it.\n- > Salespeople, real-estate agents, call-center representatives, and counselors all excelled at their jobs when they knew how to read and regulate emotions—they were able to deal more effectively with stressful situations and provide service with a smile...\n  > \n  > However, in jobs that involved fewer emotional demands, the results reversed. The more emotionally intelligent employees were, the lower their job performance. For mechanics, scientists, and accountants, emotional intelligence was a liability rather than an asset. Although more research is needed to unpack these results, one promising explanation is that these employees were paying attention to emotions when they should have been focusing on their tasks. If your job is to analyze data or repair cars, it can be quite distracting to read the facial expressions, vocal tones, and body languages of the people around you.\n\n\n","n":0.064}}},{"i":5969,"$":{"0":{"v":"As We May Think","n":0.5},"1":{"v":"\n- [[p.hasURL]] https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/\n- [[p.hasAuthor]] @vannevar-bush\n- resources:  https://www.youtube.com/watch?v=c539cK58ees","n":0.378}}},{"i":5970,"$":{"0":{"v":"The Personality Trait That Makes People Feel Comfortable Around You","n":0.316},"1":{"v":"\n\n\nPeople who consistently make others feel good are more central to their social networks\n\n- [[p.hasURL]] https://www.theatlantic.com/family/archive/2019/01/affective-presence-how-you-make-other-people-feel/579643/ \n\n## [[hasQuotes]]\n\n- > Throughout the day, one experiences emotional “blips” as Elfenbein puts it—blips of annoyance or excitement or sadness. The question is, “Can you regulate yourself so those blips don’t infect other people?” she asks. “Can you smooth over the noise in your life so other people aren’t affected by it?”\n\n->  Psychopaths are notoriously charming, and may well use their positive affective presence for manipulative ends. [[t.psych.psychopathy]] \n\n\n","n":0.108}}},{"i":5971,"$":{"0":{"v":"Arxiv","n":1}}},{"i":5972,"$":{"0":{"v":"The Emotion Frame Ontology","n":0.5},"1":{"v":"\n- https://arxiv.org/pdf/2401.10751\n- author: @stefano-de-giorgis @aldo-gangemi","n":0.447}}},{"i":5973,"$":{"0":{"v":"Shacl a Description Logic in Disguise","n":0.408},"1":{"v":"\n- https://arxiv.org/abs/2108.06096\n\n## Abstract\n\n- SHACL is a W3C-proposed language for expressing structural constraints on RDF graphs. In recent years, SHACL's popularity has risen quickly. This rise in popularity comes with questions related to its place in the semantic web, particularly about its relation to OWL (the de facto standard for expressing ontological information on the web) and description logics (which form the formal foundations of OWL). We answer these questions by arguing that SHACL is in fact a description logic. On the one hand, our answer is surprisingly simple, some might even say obvious. But, on the hand, our answer is also controversial. By resolving this issue once and for all, we establish the field of description logics as the solid formal foundations of SHACL.\n\n## References\n\n- [[ar.hackernews.semantic-web-is-like-the-guy-that-tells-everyone-that-he-is-an-asshole]]","n":0.089}}},{"i":5974,"$":{"0":{"v":"Semantic Hypergraphs","n":0.707},"1":{"v":"\n- url: https://arxiv.org/abs/1908.10784\n- author: @camille-roth @telmo-menezes\n- #related \n  - [[t.social-science.computational]]\n  - [[t.ling.syntax.annotation]]\n  - [[ar.universal-dependencies]]\n\n## Highlights\n\n- symbolic methods possess several proper and important features, namely that they can offer human-readable knowledge representations ofknowledge, aswell as language under- standing through formal and inspectable rule-based logical inference.\n- Initial approaches to NLP were of a symbolic nature, based on rules written by hand, or in algorithms akin to the ones that are used for pro- gramming language interpreters and compilers, such as recursive descent parsers. It became apparent that the  diversity of grammatical constructs that can be found in natural language is too large to be tackled in such a way. ^np3lx0oiy2qs\n  - [[p.provokedThoughts]]\n    - Maybe, but with [[gd]] I've gotten 95% of what I need already\n- SHs can represent semantic information that is lost in the graphic representation, for example the ability to express n-ary relationships, propositions about propositions and constructive definitions of concepts.\n- [[t.ling.nlp.argumentation-mining]]\n- hyperedges may be ordered [23] and recursive [32]. Ordering entails that the position in which a vertex participates in the hyperedge is relevant (as is the case with directed graphs). Recursivity means that hyperedges can participate as vertices in other hyperedges.\n- Metatrees and metagraphs are themselves too low a level to be suitable as a programming language which human beings would want to use on a daily basis. Instead, they have more in common with compiler intermediate languages, which are term rewriting systems used by machines (compilers) to perform transformations on data.\n## Comparable\n\n- [[prdct.cyc]]\n- [[prdct.atomspace]] / [[prdct.opencog]]\n- [[prdct.amr]]\n- [[prdct.opennlp]]\n- [[prdct.conceptnet]]","n":0.063}}},{"i":5975,"$":{"0":{"v":"Sandra a Neuro Symbolic Reasoner Based on Descriptions and Situations","n":0.316},"1":{"v":"\n- https://arxiv.org/pdf/2402.00591\n- authors: @nicolas-lazzari @stefano-de-giorgis @aldo-gangemi @valentina-presutti\n\n## Abstract\n\nThis paper presents sandra, a neuro-symbolic reasoner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and performs reasoning over it. The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations. Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics. Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information. We prove that our method is correct with respect to the DnS model. We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is designed a priori.\n\n\n## Highlights\n\n![](/assets/images/2024-07-02-12-02-15.png)\n- \" hence they provide two different perspectives from\nwhich the situation can be interpreted\"\n  - isn't it more like they provide two different possible descriptions? why ","n":0.075}}},{"i":5976,"$":{"0":{"v":"Hypergraph Ego Networks and Their Temporal Evolution","n":0.378},"1":{"v":"\n- url: https://arxiv.org/pdf/2112.03498.pdf\n- different:\n  - star ego-networks\n  - radial ego-networks\n  - contracted ego-networks\n- ![](/assets/images/2023-05-02-20-51-56.png)","n":0.267}}},{"i":5977,"$":{"0":{"v":"Generative Agents Interactive Simulacra of Human Behavior","n":0.378},"1":{"v":"\n- url: https://arxiv.org/pdf/2304.03442.pdf\n\n## Highlights\n\n- \"Our architecture comprises three main components. The first is the memory stream, a long-term memory module that records, in natural language, a comprehensive list of the agent’s experiences. The retrieval model combines relevance, recency, and importance to surface the records that are needed to inform the agent’s moment-to-moment behavior. The second is reflection, which synthesizes memories into higher-level inferences over time, enabling the agent to draw conclusions about itself and others to better guide its behavior. The third is planning, which translates those conclusions and the current environment into high-level action plans and then recursively into detailed behaviors for action and reaction. These reflections and plans are fed back into the memory stream to influence the agent’s future behavior.","n":0.09}}},{"i":5978,"$":{"0":{"v":"Arstechnica","n":1}}},{"i":5979,"$":{"0":{"v":"John Carmack Sounds a Skeptical Note over Metas Metaverse Plans","n":0.316},"1":{"v":"\n\r\n- [[p.hasURL]] https://arstechnica.com/gaming/2021/10/john-carmack-sounds-a-skeptical-note-over-metas-metaverse-plans/\r\n- [[p.hasAuthor]] @Kyle-Orland\r\n- related @john-carmack\r\n- [[p.hasHighlight]]\r\n  - a single application can't scale to that level of complexity\r\n  - a single company with a walled-garden approach can't make all the right decisions, i.e., it has to happen organically\r\n  - metaverse \"a honeypot trap for 'architecture astronauts.'\"\r\n    - \"high-level\" stuff isn't important for getting stuff built\r\n    - [[idea.Build-products-not-architecture]]\r\n  - \"Sometimes these things that just add people are not always a positive, especially for people that are a little more on the introverted side of things.\"\r\n  - shouldn't be built around 3D models and recreations of physical objects, since that throws out too much assets, and places a high barrier to entry for people with cameras\r\n","n":0.093}}},{"i":5980,"$":{"0":{"v":"From Infocom to 80 Days an Oral History of Text Games and Interactive Fiction","n":0.267},"1":{"v":"\n- https://arstechnica.com/gaming/2024/06/from-infocom-to-80-days-an-oral-history-of-text-games-and-interactive-fiction/","n":0.707}}},{"i":5981,"$":{"0":{"v":"Andrewzuo","n":1}}},{"i":5982,"$":{"0":{"v":"A Eulogy for Serverless","n":0.5},"1":{"v":"\n- https://andrewzuo.com/a-eulogy-for-serverless-2ef70cfdee8f\n\n## Highlights\n\n![[t.cs.sd.architecture.serverless#^s9iot2yvvndt]]\n![[t.cs.sd.architecture.serverless#^dirgz2zn129f]]\n![[t.cs.sd.architecture.microservices#^p4h5j6adklcs]]","n":0.577}}},{"i":5983,"$":{"0":{"v":"Acm","n":1}}},{"i":5984,"$":{"0":{"v":"An Initial Comparison of Selected Agent Based Simulation Tools in the Context of Industrial Health and Safety Management","n":0.236},"1":{"v":"\n- url: https://dl.acm.org/doi/fullHtml/10.1145/3543712.3543745\n- [[p.hasComparand]] [[prdct.gama]] [[prdct.repast-simphony]][[prdct.netlogo]]\n\n## Highlights\n\n- The fact that GAMA's [[prdct.gama.gaml]] uses the concept of an agent in a broader way makes it a little more complex than NetLogo but also more flexible insofar as that it supports the composition of different models [11, p. 241] which the user is advised to exploit when generating more complex models [40, p. 308].\n- While NetLogo and ReLogo are limited to the four classical types (patch, turtle, link and observer), GAML enables its user to create their own agent types. However, note that when using Repast Simphony-Java agents do not need belong to a parent class\n- While Repast Simphony comes with Eclipse and its features, it separates the runtime interface for model visualization which makes modeling less comfortable compared to NetLogo and GAMA.","n":0.087}}},{"i":5985,"$":{"0":{"v":"Academia","n":1}}},{"i":5986,"$":{"0":{"v":"Ontology and Dynamic Systems","n":0.5},"1":{"v":"\n\n- [[p.hasURL]]\n  - https://www.academia.edu/letters/submissions/4AzNMD\n- [[p.hasAuthor]] @bart-nooteboom\n- [[p.hasTopic]] \n  - [[t.systems.dynamic-systems]]\n  - [[t.km.ontology]]\n\n## [[p.hasSummaryPoints]]\n\n- The dominant ontology is \"things have boundaries\"\n- a second ontology is \"things are networked\"\n- a third ontology is \"things have internal forces and may adapt to external changes\"\n\n## [[p.provokedThoughts]]\n\n- I'm on the right track with the hyper-accounting of actions. \n\n## [[p.hasMemorableUtterance]]\n  \n- \"Some rules may arise for trial randomly, as in in the form of ‘genetic algorithms’ that mimick therandom generation of new forms of life in the ‘crossover’ between chromosomesin the sexual reproduction of animals. They may, when succesful, grow to dominance. This dynamic ontology is redolent of previous ontologies of adaptiveforce, such as @nietzsche’s ‘will to power’.\"\n","n":0.094}}},{"i":5987,"$":{"0":{"v":"Aboutdata","n":1}}},{"i":5988,"$":{"0":{"v":"Categorization of Data Structuring Methods","n":0.447},"1":{"v":"\n\n\n- [[p.hasURL]] http://aboutdata.org/methods.html\n- [[p.hasAuthor]] @jakob-voss\n\n## Categorization of Data Structuring Methods\n\n- encodings\n    - primarily express data (Unicode, Base64,…) \n- storage systems\n    - primarily store data (NTFS, RDBMS, …) \n- identifier and query languages\n    - primarily refer to data (URI, XPath, …) \n- structuring and markup languages\n    - primarily structure data (XML, CSV, RDF, …) \n- schema languages\n    - primarily constrain data (BNF, XSD, OWL…) \n- conceptual models\n    - primarily describe data (Mind Maps, ERM, …) \n\n\n","n":0.115}}},{"i":5989,"$":{"0":{"v":"WorryDream","n":1},"1":{"v":"\n- [[p.hasCreator]] @bret-victor\n- [[p.hasURL]] http://worrydream.com/","n":0.447}}},{"i":5990,"$":{"0":{"v":"Learnable Programming","n":0.707},"1":{"v":"\n- [[p.hasURL]] http://worrydream.com/LearnableProgramming/ \n- mentions: [[t.cs.live-coding]]","n":0.408}}},{"i":5991,"$":{"0":{"v":"A Brief Rant on the Future of Interactive Design","n":0.333},"1":{"v":"## Highlights\n\n![](/assets/images/2022-11-30-02-41-56.png)","n":0.707}}},{"i":5992,"$":{"0":{"v":"Works Expressions Manifestations Items an Ontology","n":0.408},"1":{"v":"\n- https://journal.code4lib.org/articles/16491\n- author: @karen-coyle\n- publish-date: 2022-05-09\n- mentions: [[prdct.fabio]] \n\n## Highlights\n\n### Why a new model is needed\n\n- library ontologies include library business rules\n- this proposal implements a theory of ontology development known as _minimal ontological commitment_. ([Gruber, 1993](https://journal.code4lib.org/articles/16491#note9))\n  - minimum semantics also means that the various community-supported vocabularies that derive from these terms may not be interoperable between them when their community-specific constraints are applied.\n\n### CWO/OpenWEMI\n\n- [[prdct.openwemi]] metadata description of a created resource does not require the existence of the full WEMI stack, but it does require adherence to the logical order of the entities.\n- The relationships can be between any more abstract levels in the stack to those more concrete.\n- These entities are not defined as disjoint, as they are in FRBR. Disjointness is a restriction that would limit the ways that the entities can be defined and whether they can share attributes\n- ","n":0.084}}},{"i":5993,"$":{"0":{"v":"Working Simulations with a Foundational Ontology","n":0.408},"1":{"v":"\n- url: https://www.sfbtr8.spatial-cognition.de/ailog-2010/ailog-downloads/paper12.pdf\n- similar: [[ar.towards-an-ontological-foundation-of-discrete-event-simulation]]\n- authors: @robert-porzel @tobias-warden\n\n## Highlights\n\n- for more complex models, sequential ([[t.cs.simulation.discrete-event]]) simulation will exhibit poor runtime performance (compared to [[t.cs.agents.agent-based-simulation]])\n- \" our choice of employing [[prdct.dolce]] as foundational ontology was motivated by the need to enable agents to adapt their conceptualizations and create new ones on the fly because several dedicated DOLCE-modules provide a corresponding framework\"\n- we have chosen to employ a set of ontological modules which have been designed along with the DOLCE framework, namely:\n- the [[prdct.ontology-of-information-objects]];\n- the [[prdct.ontology-of-plans]] **\n- the Core Software Ontology [29]\n- the Descriptions and Situations module [13].\n","n":0.102}}},{"i":5994,"$":{"0":{"v":"Wonder Web Deliverable D18","n":0.5},"1":{"v":"\n- http://wonderweb.man.ac.uk/deliverables/documents/D18.pdf\n\n\n## Highlights\n\n- OWL is intended to be used as a language for representing and querying ontologies on the Web, and has been carefully designed in order to offer the best possible tradeoff between expressivity and computational efficiency, while guaranteeing at the same time important logical properties such as inferential completeness. The result is a layered logical language allowing for different degrees of expressivity, which is however much less expressive than first-order logic. Using such a language for specifying foun- dational ontologies would be non-sensical: because of their very goals and nature, these ontologies need an expressive language, in order to suitably characterize their intended models.\n  - [upper ontology] computational requirements are less stringent, since they only need to be accessed for meaning negotiation, not for terminological services where the intended meaning of terms is already agreed upon.\n  - The strategy we have devised to solve this expressivity problem is the following:\n    1. Describe a foundational ontology on paper, using a full first-order logic with modality;\n    2. Isolate the part of the axiomatization that can be expressed in OWL, and implement it;\n    3. Add the remaining part in the form of KIF3 comments attached to OWL concepts.\n\n### Comparing DOLCE, OCHRE, and BFO: The Statue and the Clay\n\n“A statute of clay exists for a period of time going from t1 to t2. Between t2 and t3, the statue is crashed and so ceases to exists although the clay is still there.”\n\n#### DOLCE\n\n- there is a perdurant, the crashing (crash), that lasts during all the period of time (from t1 to t3), and two endurants, the statue (statue) and the clay (clay), which are participants in the perdurant. \n  - More precisely, the crashing is an accomplishment (ACC), the statue is a non-agentive physical object (NAPO), and the clay is an amount of matter (M).\n- In DOLCE, endurants have only direct spatial qualities and perdurants only temporal qualities. The temporal regions of endurant and the spatial regions of perdurants are inherited by means of the participation relation \n\n","n":0.055}}},{"i":5995,"$":{"0":{"v":"Where to Publish and Find Ontologies a Survey of Ontology Libraries","n":0.302},"1":{"v":"\n- url: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3293483/","n":0.577}}},{"i":5996,"$":{"0":{"v":"What People Said about the Missing Tools and Some That Arent Missing at All","n":0.267},"1":{"v":"\n- https://emshort.blog/2014/03/29/what-people-said-about-the-missing-tools-and-some-that-arent-missing-at-all/\n- related: [[event.ludum-dare]]\n\n## Highlights\n\n- **A system supporting multiplayer IF**, especially something resembling the Twine MMO [Naked Shades](http://www.ludumdare.com/compo/2013/04/30/naked-shades-the-worlds-first-twine-mmo/). Andi McClure mentioned that she is working on a relevant toolset. There are also a few other extant multiplayer options: [Guncho](http://www.guncho.com/) is an open-source MUD allowing for multiplayer Inform games, while [Fallen London](http://fallenlondon.storynexus.com/signup?RouteValueDictionary=Syste) offers some features for social interaction between players. There’s also [The Yawhg](http://www.theyawhg.com/), a 1-to-4-player CYOA that came out recently (Windows only, alas, so I haven’t had a chance to play it yet). However, I think it’s fair to say that there aren’t any toolsets that are in very widespread use for this. ^a33tby9d5vda\n- **Tools for more systematic, simulationist, or procedural games**. IF games have mostly not done much with procedurally generated worlds and maps, autonomous character behavior, and RPG-like features... \n  - For parser-based games, heavy simulation or randomization also means that the parser has to be more sophisticated about how it interprets noun phrases. Inform gets part of the way there by being able to understand object properties as part of the object’s name, but overall, this needs to be able to track exactly with whatever text generation tricks we’re doing. If we’re calling any short, wide object “stumpy”, then the parser needs to know to read “stumpy” as referring to short wide things. Moreover, the bigger and more complicated the text simulation work we’re doing, the more important that the author doesn’t have to write gazillions of lines of code of the form “Understand “stumpy” as a thing if it is short and wide.” — that becomes unmaintainable. We need, in other words, a more systematic and high-level way of expressing these ideas.\n    - [[p.provokedThoughts]]\n      - i.e., a collective, open, composable ontology; probably the predicate templates could be universal; synonymy is a gradient \n- For Inform specifically to handle the back-end simulations well, it would likely need dynamic object generation (a long-running request, with an impressive 65 votes on the Uservoice tracker).\n\n","n":0.055}}},{"i":5997,"$":{"0":{"v":"Webseitz","n":1},"1":{"v":"\n- [[p.hasSite]] http://webseitz.fluxent.com\n- [[p.hasCreator]] @bill-seitz\n- [[p.instanceOf]] [[c.digitalgarden]]\n","n":0.378}}},{"i":5998,"$":{"0":{"v":"WeaKG-MF: a Knowledge Graph of Observational Weather Data","n":0.354},"1":{"v":"\n- https://2022.eswc-conferences.org/wp-content/uploads/2022/05/pd_Ayadi_et_al_paper_215.pdf\n- topics: [[t.km.knowledge-graph]] [[t.km.modeling]] [[t.geo.meteorology]]\n\n## Abstract\n\nIn this paper, we present the WeaKG-MF Knowledge Graph constructed from open weather observations published by Météo-France institution. WeaKG-MF relies on a semantic model that formalizes knowledge about meteorological observa- tional data. The model is generic enough to be adopted and extended by meteorological data providers to publish and integrate their sources while complying with Linked Data principles. WeaKG-MF offers access to a large number of meteorological variables described through spatial and temporal dimensions and thus has the potential to serve several scientific case studies from different domains including agriculture, agronomy, environment, climate change and natural disasters.\n\n","n":0.099}}},{"i":5999,"$":{"0":{"v":"Water Fowl a Compact Self Indexed Rdf Store with Inference Enabled Dictionaries","n":0.289},"1":{"v":"\n- https://www.researchgate.net/publication/259804916_WaterFowl_a_Compact_Self-indexed_RDF_Store_with_Inference-enabled_Dictionaries\n- published: 2014-01\n- \n","n":0.447}}},{"i":6000,"$":{"0":{"v":"Voc Bench 3 a Collaborative Semantic Web Editor for Ontologies Thesauri and Lexicons","n":0.277},"1":{"v":"\n- https://www.semantic-web-journal.net/system/files/swj2143.pdf\n- authors: @armando-stellato\n\n## Abstract\n\nVocBench is an open source web platform for the collaborative development of datasets complying with Semantic Web standards. Since its public release – five years ago – as an open source platform, VocBench has attracted a growing user community consisting of public organizations, companies and independent users looking for open source solutions for maintaining their thesauri, code lists and authority resources. The focus on collaboration, the differentiation of user roles and the workflow management for content validation and publication have been the strengths of the platform, especially for those organizations requiring a distributed, yet centrally controlled, publication environment. In 2017, a new, completely reengineered, version of the system has been released, broadening the scope of the platform: funded by the ISA2 programme of the European Commission, VocBench 3 offers a general-purpose collaborative environment for development of any kind of RDF dataset (with dedicated facilities for ontologies, thesauri and lexicons), improving the editing capabilities of its predecessor, while still maintaining the peculiar aspects that determined its success. In this article, we review the requirements and the new objectives set for version 3, and then introduce the new characteristics that were implemented for this new incarnation of the platform\n\n","n":0.071}}},{"i":6001,"$":{"0":{"v":"Vlad's Roam Garden","n":0.577},"1":{"v":"\n- [[p.hasURL]] https://vlad.roam.garden\n- [[p.instanceOf]] [[c.digitalgarden]]","n":0.447}}},{"i":6002,"$":{"0":{"v":"Virtual and Real World Ontology Services","n":0.408},"1":{"v":"\n- url: https://csce.uark.edu/~cwt/DOCS/IEEE%20IC/2011-09--IEEE%20IC--Virtual%20and%20Real%20World%20Ontology%20Servicess.pdf\n- ","n":0.577}}},{"i":6003,"$":{"0":{"v":"Valid Time RDF","n":0.577},"1":{"v":"\n- url: https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=5097&context=gc_etds\n\n## Log\n\n- t.2024.04.01.11: re-reading this on the plane, I'm amazed how much more helpful and concrete this seems now.\n- t.2024.07.24.13 as much as I want it, I'm concerned that valid time is not existence time.\n  - at the very least, it shouldn't mean birth-death\n    - what if John comes back from the dead?\n  - in an immutable data store, valid time needs to be reserved for \"this fact was considered valid\", from interpretation of \"database\"\n  - doesn't make sense to apply vt to (some) resources, because they are eternal\n  - if we use relators, same thing\n  - singleton predicates, maybe\n  - classic predicates/properties might be interesting... valid time properties \n  - you still need a way to refer to resources/entities at a given time, but probably an instant not an interval. \n\n## Highlights\n\n- proposals of temporal extensions to RDF reported in the\nliteratures mostly use RDF reification explicitly or implicitly\n\n### Implicit Reification Based Temporal Model\n\nimplicit reification based models use different types of abstraction for handling reification. They do not employ reification vocabularies of RDF specifications. Two subcategories follow.\n\n#### Instantiating-Identifying Concept/Relationship (IIR)\n\nIn IIR models, a concept or relationship is reified and further temporalized. Either such relationship is abstracted as a new object, or a concept is viewed as four dimensional and instantiated to have temporal extents. Singleton Property converts each relationship to be universally unique. 4D fluents use concepts that view each resource as a perdurant. Fluents represent properties that change over time\n\n#### Singleton Property\n\nThe formal semantics of the [[singleton property|t.cs.semantic-web.singleton-property]] is derived from the standard RDF and RDFS semantics with the additional semantics extension for the vocabulary rdf:singletonPropertyOf. The singleton property gives rises to three cases of query patterns: data, metadata and mixed patterns which SPARQL supports. \n\n#### 4D Fluents\n\n- Perdurantism is a philosophical theory of persistence and identity [34], and it is closely related to four dimensionalism. In the four dimensional view, an object that persists through time has distinct temporal parts at every time instant through its existence in time. Furthermore, each persisting object can be considered a four dimensional spacetime worm that stretches across space-time. Slicing the worm at a specific time interval or instant of the time dimension yields a temporal part.\n  - t.2024.03.21.08: and endurant \n  \n![[t.phil.logic.situational-calculus#^vmhpi7mrf12z]]\n- In 4D Fluents model, fluents are properties that change over time [73]. These properties are special cases in that both the domain and range of them are temporal parts of the corresponding entities. TemporalPart is the main class for converting regular entities to 4D spacetime worm ones. OWL-Time ontology of [37] is used as time domain in 4D Fluents model. Particularly, a class TimeInterval derived from the equivalent class of OWL-Time is used for all temporal terms.\n![](/assets/images/2024-04-01-11-15-48.png)\n- In Figure 3.5, individuals :John and :SW are two 4D entities. Each entity has temporal parts,\n:John@i1 and :SW@i1 respectively. The property :enrolled is transformed to a fluent whose domain and range are both temporal parts. Each temporal part is associated with a specific temporal extent , i.e., time interval, that denotes its valid time. One fluent property requires two extra ob- jects, i.e., temporal parts, and two properties, in contrast to reification, that uses one extra object and four properties as illustrated in Figure 2.10. \n\n##### Advantages\n\n- \"OWL inverse operator and cardinality constraints are available and standard OWL reasoners can be used for inferencing.\"\n- The 4D Fluents model is within standard RDF and OWL-DL. \n- The running example\nquery can be written in SPARQL 4D Fluents model:\n```sparql\nSELECT ?ti ?tf\nWHERE {?ts1 :temporalPartOf :John.\n?ts2 :temporalPartOf :SW.\n?ts1 :enrolled ?ts2.\n?ts1 :temporalExt ?i.\n?ts2 :temporalExt ?i.\n?i :hasBeginning ?ti.\n?i :hasEnd ?tf.\n}\n```\n- Since the 4D Fluents model imports OWL-Time [37], :i1 in Figure 3.5 is an OWL-Time interval, while ?ti and ?tf in the above query are two OWL-Time instants.\n\n#### Extended 4D Fluents \n\n- [[Batsakis|user.sotiris-batsakis]] et al. [[extended 4D Fluents|ar.representing-temporal-knowledge-in-the-semantic-web-the-extended-4d-fluents-approach]] model to incorporate qualitative temporal relations that have unknown temporal information... Semantics of the extended 4D Fluents model is based on the original 4D Fluents model, with the additional temporal semantics needed for qualitative temporal relations.\n\n![](/assets/images/2024-04-01-11-24-36.png)\n\n- [[TOQL|prdct.toql]] [5] is the SQL-like query language for Extended 4D Fluents model. To accommodate querying qualitative temporal relations, additionally query constructs, such as ”AT” clause and Allen temporal operators [4], such as before, after, meets, etc., are included in TOQL.\n\n#### Temporal Web Ontology Language\n\n![[prdct.owl.towl#^927zza20f03z:#^b8t2dt9958m2]]\n\n### Relationship to Entity Conversion (REC)\n\nIn REC models, a relationship is transformed to a composite entity. The transformed entity comes in two forms: a new entity that implicitly reifies the original triple, or an abstract object that becomes a term for further use. As an example of REC models, N-ary relations provide a main modeling concept: a triple is objectified as a new entity and can further be associated to properties, such as time.\n\n#### N-ary relations\n\nIn principle, the N-ary relation is a generalization of reification. For each N-ary relation, a new class with an instance is introduced for it as if the relation is objectified. Further property assertions can be made with respect to the newly introduced instance. Figure 3.8 gives the running example in N-ary relations.\n\n![](/assets/images/2024-10-21-03-01-13.png)\n\nThe resource :enrolled1 in Figure 3.8 is introduced as a new instance encapsulating both the course name value, SW, and its valid time interval through two properties, :hasCourse and :hasVT. The relation (:John, :enrolled, :SW) is converted to an entity class :Enrollment. The property :enrolled is overloaded, so its range becomes the newly introduced class :Enrollment. Adding time to the original triple, i.e., (John, enrolled, SW), requires three more triples.\n\nN-ary relation approach does not require extension to RDF, RDFS or OWL vocabularies. It simply converts relationships to entities that encapsulate properties. The semantics for N-ary relation approach is based on RDF and RDFS semantics. In Figure 3.8, the new object :enrolled1 may also be represented by a blank node. A blank node does not have any meaning, but acts like a wrapper for grouping related objects.\n\n```sparql\nSELECT ?ti ?tf\nWHERE {\n:John :enrolled ?e.\n?e rdf:type :Enrollment.\n?e :hasCourse :SW.\n?e :hasVT ?i.\n?i :hasBeginning ?ti.\n?i :hasFinish ?tf.\n}\n```\nWhile N-ary relation approach can be applied to OWL, it would incur overheads. For instance, multiple inverse properties are needed for a N-ary relation. Moreover, the use of cardinality re- strictions becomes limiting on some roles that depend on the class of some other roles [^53].\n\n#### Valid-Time Temporal Model\n\n- O’Connor et al. propose a valid-time temporal model and a SWRL-based [40] query mechanism for manipulating temporal knowledge in OWL ontologies\n- In the valid-time temporal model, any existing OWL class can have temporal aspects as long as it subclasses temporal:Fact, which is the super class of all temporal facts. This avoids significant ontology rewriting in converting an ontology to a temporal version.\n- The temporal expressivity of this model is further enhanced by using SWRL [40] to construct temporal rules. A set of temporal operators that includes Allen’s operators [4] is implemented as library-like built-ins for SWRL rules.\n- Querying the temporal ontology is done by [[prdct.sqwrl]]\n\n#### Named Graphs\n\n- all triples share the same temporal extent are grouped in the same graph\n- In an extreme case that each triple requires a different time reference, a significant\namount of named graphs is needed. \n- When triples may need multiple metadata annotation, using Named Graphs model becomes complex.\n- τ SPARQL \n\n## RDF+ \n\nRDF+ model [62] uses named graphs and triple-level identifiers. Named graphs are used in place of RDF reification. Triple identifiers allow explicit annotation of meta knowledge. RDF+ model has two type of statements: literal and meta knowledge statement. A RDF+ literal statement is a quintuple form (g, s, p, o, θ) where g is the graph’s IRI, s,p,o are standard RDF triple compo- nents, and θ is a statement identifier. Based on the triple identifier in the RDF+ literal statement, the RDF+ meta knowledge statement can be formed as (θ, π, ω). θ is the literal statement identifier, π is the meta knowledge property and ω is the range value of π. The set K of RDF+ literal statements and the set M of RDF+ meta knowledge statements constitute a RDF+ theory, \n\n## Discussion\n\n- There are two temporal models in Instantiating-Identifying Concept/Relationship models. 4D Fluents [73, 6, 7] introduces temporal part for an entity changing over time. Each temporal part corresponds to a distinguishable timestamp. A fluent property associates two temporal parts. On the other hand, Singleton Property [52] ensures every relationship to be universally unique. As a result, an ordinary relationship, such as enrolled, becomes a relationship type.\n\n## Valid Time RDF\n\n- \"As a result, a binary relationship actually incurs three timestamps: the valid\ntime of the relationship and two participating entities.\"\n  - t.2024.07.10.10 really? Do entities have timestamps? John might have a birth and death, but relationships involving John don't need to know that. \n  - Also, birth-death are not the same as valid. \n  - There's an asymmetry with valid time in open-world. if there's no valid-to, can you assume ***now***? not in open-worlds. If there's no valid-from, you just assume it's missing. \n    - t.2024.08.03.16 seems like you could use SWRL or \n\n## Valid Time RDF\n\n- In this thesis, we adopt a modeling approach that employs ideas from the 4D view and originated from the study in [66], and propose the Valid Time RDF, or [[prdct.vtrdf-valid-time-rdf]] in short\n- VTRDF is based on temporal resource and temporal relationship or temporal fact.\n  - **temporal resource**: RDF-compliance resource equipped with a timestamp to denote its existence in time\n    - Each temporal resource is a coalesce of all its temporal parts\n      - i.e. wholly present during its existence in time\n    - Temporal parts are derived by slicing or projecting a temporal resource on to the time dimension.\n  - **temporal relationship**: a factual assertion that relates qualified temporal resources, formed between either temporal parts or temporal resources provided that the participating parts or resources coexist in time\n- We introduce VTR, an infinite set of valid time resources, as the building block for VTRDF triples and VTRDF graphs ^6x6gy39e5d24\n  -  valid time resource is a resource with its existence time or valid time\n  -  In VTRDF, we consider a valid time resource as a collection of all its temporal parts.\n  -  Assertions can be made with respect to both the collection and any individual temporal part.\n  -  A temporal resource is a master resource, whereas all its temporal parts are member resources.\n  -  Projections from the master resource to its temporal parts are possible via projection functions.\n  -  The temporal aspects of the resources can use valid time, transaction time, or bitemporal.\n     -  In this research, we focus on the valid time.\n     -  Hence, we would use valid time resources and temporal resources interchangeably as appropriate\n\n### Notations, Namespace, and Time Domain\n\n- vtrdf: and vtrdfs: refer to the namespace of VTRDF vocabulary and VTRDF Schema vocabulary\n- While the symbol # is used to denote an additional part of the primary resource in the standard RDF model, VTRDF requires a second fragment identifier to accommodate the valid time dimension.\n  - t.2024.07.24.11 with slash IRIs, could work too\n  - The symbol • is used as a delimiter that separates the first fragment identifier from the valid\n- T is the set of time points with a linear order less-than (<). For simplicity, we use the standard U.S. calendar dates as the unit of time points in the format of month/day/year, such as 1/10/1995\n- Tɪ is the set of time intervals defined over T\n- 0 is the lower bound of the time axis whose interpretation is open for user’s need of data\nmodeling.\n- now is a special constant that represents the current time. Its value will change as time\nadvances.\n- ∞ is a constant that represents the upper bound of the time axis.\n- [0, ∞] is a special interval used to represent the maximal interval\n\n### Running Example\n\n- John enrolled in the Semantic Web course\n(SW), lived in New York City (NYC), and had a valid time [2/1/2016, 5/31/2016).\n  - t.2024.07.24.12 kinda weird choice, seems like enrolled and livedIn are unrelated\n![](/assets/images/2024-07-24-12-52-39.png)\n\n\n### Definitions\n\n#### valid time IRI\n\n- a valid time IRI consists of:\n  - resource\n  - valid time\n  - http://example.org/temporal-SW#John•[01-10-1995–now]\n\n####  Valid Time Literal\n\n- Let L be an infinite set of standard literals, [0, ∞] the maximal interval, and V T L = L × [0, ∞]\nbe the Cartesian product.\n-  A valid time literal lt ∈ V T L represents a literal that is always valid in\ntime.\n  - That is, all literals assume a default maximal interval [0, ∞] unless otherwise specified.\n\n#### Valid Time Data Type\n\n- Let D be an infinite set of standard data types, [0, ∞] the maximal interval, and V T D =\nD × [0, ∞] be the Cartesian product. A valid time data type dt ∈ V T D is a data type recognized\nin the standard RDF with a default maximal interval [0, ∞].\n  - Valid time data types are used to annotate valid time literals.\n  - A special data type vtrdf:langString[0, ∞] can also be used to denote a language-tagged string value.\n\n#### Lexical-to-Value Mapping Function V T L2V\n\n- V T L2V is a partial mapping from the lexical space of valid time literals to the value space V. A valid time literal lt with a valid time data type dt denote the mapped value obtained from the value space. That is, V T L2V (lt, dt) = v where v ∈ V.\n\n\n#### Valid Time Property\n\n- Let P be the set of any properties, including those defined in RDF and RDFS vocabularies [16], TI be the set of intervals, and V T P = P × TI be the Cartesian product of them. A valid time property pt ∈ V T P is any property that is valid during a specified interval i ∈ TI .\n\n#### Valid Time Blank Node\n\n- Let B be an infinite set of blank nodes, TI be the set of intervals, and V T B = B × TI be the Cartesian product. A valid time blank node bt ∈ V T B denotes the existence of a resource whose valid time may or may not be known. For simplicity, every valid time blank node in the VTRDF model assumes a default maximal valid interval [0, ∞] unless otherwise specified. A valid time blank node is usually identified by a local identifier.\n\n#### Valid Time Resource Projection Function\n\n- A valid time resource projection function...\n\n#### Valid Time RDF Triple\n\nA Valid Time RDF triple (st, pt, ot) satisfies the temporal constraint, called Temporal Triple Integrity,such that pt is bounded by the interval that is formed by the common valid time of st and ot.\n  - In other words, the temporal triple integrity requires that a valid time relationship can only be established between two existing resources with non-disjoint valid time\n\n#### Predicate Defining Time (PDT) and Resource Modeling Time (RMT)\n\n- rt takes PDT when it is used in a VTRDF triple as a predicate to define the time of a re- lationship. In this case, PDT corresponds to the interval during which the relationship is valid\n- rt takes RMT when it is used in a VTRDF triple as a subject or an object that eventually involves in a relationship.\n  - \"RMT is the time that we want to store about the facts into the database.\"???\n\n#### Valid Timeslice Operator\n\n- Given a VTRDF graph Gt and an interval i = [l, u), the valid time slice operator, TS, returns a temporal subgraph of Gt at i\n![](/assets/images/2024-07-24-12-55-11.png)\n  - t.2024.07.24.12 i.e., it cuts everything down to the interval)\n\n#### VTRDF Subgraph\n\n- in addition to the common-sense definition, a \"valid timeslice of a VTRDF graph Gt is a **temporal subgraph** of it.\"\n- ![](/assets/images/2024-07-24-12-53-09.png)\n  - t.2024.07.24.12 is it a typo that fig 4.3 has \"now\" and fig.4.5 has \"infinity\"\n\n#### VTRDF Underlying Triple/Graph\n\n- basically, de-temporalizing\n- \"If two or more triples agree on the subject or object, they are combined to one triple. \"\n  - t.2024.07.24.13 typo, should be \"subject and object\"\n\n#### VTRDF Graph Vocabulary\n\n- the set of valid time IRIs that appear in Gt excluding valid time literals.\n\n#### Ground VTRDF Graph\n\n- no valid time blank nodes\n\n\n### VTRDF Vocabulary\n\n- VTRDF Vocabulary is formulated as layers and RDF-compliant.\n\n\n## References\n\n[^53]: [[ar.defining-n-ary-relations-on-the-semantic-web]]","n":0.019}}},{"i":6004,"$":{"0":{"v":"UX Patterns CLI Tools","n":0.5},"1":{"v":"\n\n- [[p.hasURL]] https://lucasfcosta.com/2022/06/01/ux-patterns-cli-tools.html\n- [[p.hasSummaryPoints]]\n  - implement interactive usage modes\n  - [[p.wasInspirationFor]] using shell instead of mattermost\n  - you can even have beautiful animated charts if you use libraries like Go’s termui\n  - favourite part of walking into a treadmill is watching the completion indicator move forward to the right\n  - Using exit codes correctly is elementary because it allows your users to combine your tool with others’ and write useful scripts to automate their tasks.\n  - Like having an interactive shell, having consistent sub-commands is excellent for discoverability. When you have a consistent command tree, users can guess how to do things.\n","n":0.099}}},{"i":6005,"$":{"0":{"v":"Using the Unified Foundational Ontology Ufo as a Foundation for General Conceptual Modeling Languages","n":0.267},"1":{"v":"\n- https://www.researchgate.net/publication/227248566_Using_the_Unified_Foundational_Ontology_UFO_as_a_Foundation_for_General_Conceptual_Modeling_Languages\n- ","n":0.707}}},{"i":6006,"$":{"0":{"v":"Using Metagraph Approach for the Big Data Based Graph Processing","n":0.316},"1":{"v":"\n\n- [[p.hasURL]] http://ceur-ws.org/Vol-2514/paper112.pdf\n- [[p.hasTopic]]\n  - [[t.cs.graph.metagraph]]\n  - [[t.cs.graph.hypergraph]]\n\n## Highlights\n\n- \"Thus, the metagraph is a complex graph model, whereas the hypergraph is a near flat graph model that does not fully implement the emergence principle.\"\n\n## [[c.conclusion]]\n\n- The key element of the metagraph model is metavertex. From the general system theory point of view, a metavertex is a particular case of the manifestation of the emergence principle, which means that a metavertex with its private attributes and connections becomes a whole that cannot be separated into its component parts.\n- The metagraph model is a complex graph model, whereas the hypergraph is a near flat graph model that does not fully implement the emergence principle. Also, the metagraph model is more flexible than the hypernetwork model.\n- The main elements of the metagraph data model may be represented in textual form using the predicate description.\n- The metagraph model may be transformed into a flat graph model based on the multipartite graphs.\n- The generalized structure of the metagraph Big Data processing engine makes it possible to process the metagraph datausing the traditional “Big Data flat graph processing engine.”\n","n":0.074}}},{"i":6007,"$":{"0":{"v":"Using a Trope Based Foundational Ontology for Bridging Different Areas of Concern in Ontology Driven Conceptual Modeling","n":0.243},"1":{"v":"\n- https://www.sciencedirect.com/science/article/pii/S0167642314000896\n- authors: @giancarlo-guizzardi @veruska-zamborlini\n- publish-date: 2014\n- topics: [[prdct.ontouml]]\n\n## Abstract\n\nIn recent years, ontology-driven reference models have gained much attention in the literature due to their potential key role in activities such as complex information modeling and semantic interoperability. The engineering process of these conceptual models should account for different phases addressing different areas of concern. In an initial phase of conceptual domain modeling, the target modeling artifacts should be constructed with the goal of maximizing quality attributes such as expressivity and truthfulness to the represented domain in reality. In a subsequent development phase, the resulting domain models can be used to guide the design decisions in the construction of different implementation artifacts addressing different computational concerns. In this paper, **we present a philosophically sound, cognitively-oriented and formally characterized foundational theory of objects and tropes (property-instances)**. Moreover, we use this theory to bring about engineering contributions to both the aforementioned phases of ontology-driven conceptual modeling. Firstly, we show how this theory has been used to (re)design a system of modeling primitives underlying the conceptual domain modeling language OntoUML. Furthermore, we provide precise directives on how to map conceptual domain models in this language to their implementation in less-expressive computationally-oriented codification languages. In particular, we address here a mapping strategy to OWL (Web Ontology Language) that partially preserves the modal-temporal semantics of OntoUML. Finally, we discuss computational support for the proposed approach in terms of conceptual model construction, automatic transformation and temporal querying.\n\n\n","n":0.064}}},{"i":6008,"$":{"0":{"v":"Universal Dependencies v1","n":0.577},"1":{"v":"\n- url: https://aclanthology.org/L16-1262.pdf","n":0.577}}},{"i":6009,"$":{"0":{"v":"Unifying Component Based Gameobject Systems and Mixin Based Inheritance","n":0.333},"1":{"v":"\n- https://blog.varunramesh.net/posts/unifying-component-based-gameobject-systems-and-mixin-based-inheritance/","n":0.707}}},{"i":6010,"$":{"0":{"v":"Understanding the Semantic Web through Descriptions and Situations","n":0.354},"1":{"v":"\n- https://www.researchgate.net/publication/225119791_Understanding_the_Semantic_Web_through_Descriptions_and_Situations/\n\n## Highlights\n\n- scalability requirements will push towards the use of automated methods to acquire, translate or merge ontologies. Such methods are known to degrade the level of formality of ontologies, resulting in the prevalence of lightweight ontologies [3]. We believe that such limitation is fundamental rather than technical; we refer the reader to the paper of Elst and Abecker for a detailed treatment of the contradiction of sharing scope, stability and formality of knowledge in information systems [4]\n- Formal principles are needed to allow an explicit comparison between alternative ontologies. Exam- ples of formal principles are spatio-temporal localization, topological closure, heterogeneity of parts, dependency on the intention of agents, etc\n- While formalizing the principles governing physical objects or events is (quite) straightforward, intuition comes to odds when an ontology needs to be extended with non-physical objects, such as social institutions, organizations, plans, reg- ulations, narratives, mental contents, schedules, parameters, diagnoses, etc. In fact, important fields of investigation have negated an ontological primitiveness to non-physical objects [7], because they are taken to have meaning only in combination with some other entity, i.e. their intended meaning results from a statement\n  - ex: a norm, a plan, or a social role are to be represented as a (set of) statement(s), not as concepts\n  - This position is documented by the almost exclusive attention dedicated by many important theoretical frameworks (BDI agent model, theory of trust, situation calculus, formal context analysis), to states of affairs, facts, beliefs, viewpoints, contexts, whose logical representation is set at the level of theories or models, not at the level of concepts or relations.\n  - On the other hand, recent work (e.g. [7]) addresses non-physical objects as first-order entities that can change, or that can be manipulated similarly to physical entities. This means that many relations and axioms that are valid for physical entities can be used for non-physical ones as well\n  - Interrelations between theories are notoriously difficult to be manipulated, then it would be an advantage to represent non-physical objects as instances of concepts instead of models satisfying some theory\n\n### D&S\n\n- D&S axioms try to capture the notion of “situation” as a unitarian entity out of a “state of affairs”\n- A state of affairs is any non-empty set SoA of assertions a1..n that are individually coherent with the axioms in a first-order theory O, called a “ground ontology”. A SoA is a second-order entity, therefore it cannot be represented (as such) as an individual in O. Examples: a clinical data set, a set of temperatures with spatio-temporal coordinates, etc\n- A description is an entity that partly represents a (possibly formalized) theory T (or one of its elements) that can be “conceived” by an agent: either human, collective, social, or artificial. A description can be an individual in O. Examples: a diagnosis, a climate change theory, etc.\n- A situation is constituted by the entities and the relations among them that are mentioned in assertions a1..n from a SoA, and it is an entity in O that partly represents a (possibly formalized) model M for T, according to the axioms in O\n  - A situation can be an individual in O. \n  - a1..n must be systematically related to the components of a description in order to constitute a situation\n    - eg: a clinical condition, a climate change history, etc.\n- Intuitively, when a description is applied to a state of affairs, some structure (a “situation”) emerges (this reflects the cognitive structuring cognitive process [6]). The emerging structure is not necessarily equivalent to the actual structure\n\n![](/assets/images/2024-06-04-10-12-29.png)\n\n\n### Communication\n\n- The generic schema for our communication ontology combines two skeletal descriptions as shown in Figure 2. The description for communication consists of communication parameters valued by communication regions, communication roles played by endurants and communication turns that sequence a communi- cation event according to some method of communication. The description for interpretation concerns semiotic parameters, roles and semiotic tasks according to some interpretation method\n\n![](/assets/images/2024-06-04-10-14-31.png)\n\n#### Web's Identity Crisis\n\n- resulted from the vague definition of Universal Resource Identifiers (URI). In practice, symbols of Semantic Web ontologies are often used to denote documents, in other cases documents containing definitions of concepts or the concepts themselves. A further difficulty with the URIs of the last type is that they cannot be denoted (resolved) by machines\n  - see [[vs.resources-that-refer-vs-resources-that-are]]\n\n#### Jakobson's Model of Communication\n\n-  all acts of\ncommunication are contingent on six constituent elements [13]\n  - the addresser or encoder [speaker, author]\n  - a message [the verbal act, the signifier)\n  - the addressee or decoder\n  - context (a referent, the signified)\n  - a code (shared mode of discourse, shared language)\n  - a contact or channel.\n- Using the ontology of descriptions, all six constituents are modelled as functional roles: the encoder and decoder are agentive roles, while the other elements of theory are non-agentive functional roles. The method of communication is represented as a course.\n![](/assets/images/2024-06-04-10-22-57.png)","n":0.035}}},{"i":6011,"$":{"0":{"v":"Ufo Unified Foundational Ontology","n":0.5},"1":{"v":"\n- http://www.inf.ufes.br/~gguizzardi/Applied_Ontology__UFO__Unified_Foundational_Ontology.pdf\n-  authors: @giancarlo-guizzardi\n- published: 2021\n\n## Introduction\n\nFor almost two decades now, the Uniﬁed Foundational Ontology (UFO) has been the focus of a long-term research program on ontological foundations for conceptual modeling. UFO (Guizzardi, 2005; Guizzardi et al., 2015b) was developed by consistently putting together theories from formal ontology in philosophy, cognitive science, linguistics, and philosophical logic. UFO is a [[t.km.ontology.four-category]] ontology that addresses fundamental conceptual modeling notions via a set of micro-theories, including: –a theory of types and taxonomic structures (Guizzardi and Wagner, 2004a; Guizzardi et al., 2021) that is connected to a theory of object identiﬁers, including a formal semantics in a sortal quantiﬁed modal logic (Guizzardi, 2015); –a theory of part-whole relations (Guizzardi, 2007, 2009, 2011; Guizzardi et al., 2016); –a theory of particularized intrinsic properties, attributes and attribute value spaces (Guizzardi et al., 2006; Guizzardi and Zamborlini, 2014), which includes a view on datatypes as semantic reference structures (Albuquerque and Guizzardi, 2013); –a theory of particularized relational properties and relations, (Guarino and Guizzardi, 2015, 2016; Guizzardi and Wagner, 2008; Fonseca et al., 2019), including a proposal for Weak Truthmaking (Guarino et al., 2019) connecting particularized properties to propositions; –a theory of roles (Guizzardi, 2005, 2006; Masolo et al., 2005); –a theory of events (Guizzardi et al., 2013a; Almeida et al., 2019; Benevides et al., 2019b; Guarino and Guizzardi, 2016; Benevides et al., 2019a; Guizzardi et al., 2016), including aspects such as event mereology, temporal ordering of events, object participation in events, causation, change, and the connection between events and endurants via dispositions; –a theory for multi-level modeling (Carvalho et al., 2017, 2016; Guizzardi et al., 2015a; Fonseca et al., 2021a)\n\n","n":0.061}}},{"i":6012,"$":{"0":{"v":"Tutorial Conceptual Simulation Modeling with onto Uml","n":0.378},"1":{"v":"\n- https://informs-sim.org/wsc12papers/includes/files/inv284.pdf\n- authors: @giancarlo-guizzardi @gerd-wagner\n\n## Abstract\n\n- Conceptual modeling is of great importance not only to Information Systems and Software Engineering, but also to Simulation Engineering. It is concerned with identifying, analyzing and describing the essen- tial concepts and constraints of a real-world domain with the help of a (diagrammatic) modeling language that is based on a set of basic modeling concepts (forming a metamodel). In this tutorial, we introduce the ontologically well-founded conceptual modeling language Onto-UML and show how to use it for making conceptual simulation models as the basis of model-driven simulation engineering.\n\n## Highlights\n\n### MODEL-DRIVEN SOFTWARE AND SIMULATION ENGINEERING\n\nTwo most important viewpoints:\n1. information modeling, which is concerned with the state structure of the domain;\n2. process modeling, which is concerned with the dynamics of the domain.\n\n- It is natural to apply the general methodology of Model-Driven Engineering (MDE) also to sim-\nulation engineering.\n- Unfortunately, the results obtained in the conceptual modeling field of IS&SE have largely been\nignored in M&S. Still today, conceptual modeling is often confused with design modeling in\nM&S.\n- A conceptual model is a solution-independent description of a problem domain expressed in a\nwell-defined (diagrammatic) modeling language.\n- In model-driven simulation engineering, we first make a conceptual system model, from which\nwe derive a (platform-independent) simulation design model, which is then transformed into one\nor more (platform-specific) simulation models.\n- A conceptual modeling language is a representation of a meta-conceptualization of a viewpoint\nof the real world. A system conceptualization, which exists in the mind of the modeler and con-\ntains a number of system concepts, instantiates a meta-conceptualization. It is represented in the\nform of a conceptual system model expressed in the conceptual modeling language representing\nthe meta-conceptualization.\n- We propose to use improved variants of UML Class Diagrams and BPMN, which are based on a\nfoundational ontology, for conceptual information and process modeling","n":0.058}}},{"i":6013,"$":{"0":{"v":"Turing Post","n":0.707}}},{"i":6014,"$":{"0":{"v":"#2: Your Go-To Vocabulary to Navigate the World of AI Agents and Workflows","n":0.277},"1":{"v":"\n- https://www.turingpost.com/p/agentsvocabulary\n- authors: @ksenia-se\n\n","n":0.5}}},{"i":6015,"$":{"0":{"v":"Tr Owl Tractable Owl 2 Reasoning Infrastructure","n":0.378},"1":{"v":"\n- http://knowledge-representation.org/j.z.pan/pub/TPR2010.pdf","n":0.707}}},{"i":6016,"$":{"0":{"v":"Towards Ontological Foundations for the Conceptual Modeling of Events","n":0.333},"1":{"v":"\n- https://www.researchgate.net/publication/290226494_Towards_Ontological_Foundations_for_the_Conceptual_Modeling_of_Events\n\n\n## References\n\n- https://github.com/nemo-ufes/gufo/issues/11\n- [[ar.representing-a-reference-foundational-ontology-of-events-in-sroiq]]","n":0.447}}},{"i":6017,"$":{"0":{"v":"Towards Ontological Foundations for Conceptual Modeling the Unified Foundational Ontology Ufo Story","n":0.289},"1":{"v":"\n- https://drive.google.com/file/d/1w7hXNsX3JWdqXvGKTh7LUSyEjc-nYGcj/view?usp=drive_link\n- authors: @giancarlo-guizzardi\n- topics: [[prdct.unified-foundational-ontology]] [[t.km.ontology]]\n\n## Abstract\n\nThis paper describes a long-term research program on developing ontological foundations for conceptual modeling. This program, organized around the theoretical background of the foundational ontology UFO (Unified Foundational Ontol- ogy), aims at developing theories, methodologies and engineering tools with the goal of advancing conceptual modeling as a theoretically sound discipline but also one that has concrete and measurable practical implications. The paper describes the historical context in which UFO was conceived, briefly discusses its stratified organization, and reports on a number of applica- tions of this foundational ontology over more than a decade. In particular, it discusses the most successful application of UFO, namely, the development of the conceptual modeling language OntoUML. The paper also discusses a number of methodological and computational tools, which have been developed over the years to support the OntoUML community. Examples of these methodological tools include ontological patterns and anti-patterns; examples of these computational tools include automated support for pattern-based model construction, formal model verification, formal model validation via visual simulation, model verbalization, code generation and anti-pattern detection and rectification. In addition, the paper reports on a variety of appli- cations in which the language as well as its associated tools have been employed to engineer models in several institutional contexts and domains. Finally, it reflects on some of these lessons learned by observing how OntoUML has been actually used in practice by its community and on how these have influenced both the evolution of the language as well as the advancement of some of the core ontological notions in UFO\n\n## Highlights\n\n- our first attempt was to unify DOLCE and GFO to produce a reference foundational ontology for conceptual modeling (hence, the name Unified Foundational Ontology) (Guizzardi & Wagner, 2004). Both theories were philosophically sound and formally characterized. Moreover, they were both based on the so-called Aristotelian Square, i.e., “[[t.km.ontology.four-category]] Ontologies”.\n- ontological foundations for conceptual modeling would demand micro-theories to address conceptual modeling’s most fundamental constructs, namely, Entity Types and Relationship Types (hence, the name of the so-called Entity-Relationship ap- proach that gives the name to the most important conference in conceptual modeling!). So, any reference theory for conceptual modeling would need a rich theory of entity (object) types and a rich theory of domain (also called material) relations. In the case of the former, we needed something in the spirit of the ontology of universals underlying the OntoClean methodology (Guarino & Welty, 2009) in order to systematize a number of notions that were pervasive in the conceptual modeling literature (e.g., types, roles, phases or states, mixins) but for which there were no precise definitions or consensus (Guizzardi et al., 2004a). \n  - GFO’s theory of universals still does not recognize these notions and DOLCE does not include universal as a category (DOLCE was designed as an ontology of particulars).\n    - DOLCE still does not include a theory of particularized relational properties (relational qualities) and the GFO theory of relations is subject to the so-called Bradley Regress (Bradley, 1893) and, hence, it can only be instantiated by infinite (logical) models. This feature makes it unsuitable for conceptual modeling applications. \n- Finally, there were many additional specific aspects needed for a general ontology for conceptual modeling that were not addressed by the existing approaches (e.g., attributes and datatypes, different types of specialization relations between relations, a rich theory of cognitively/linguistically motivated part-whole relations). We needed to develop a full-blown foundational ontology specifically created to address these conceptual modeling requirements","n":0.042}}},{"i":6018,"$":{"0":{"v":"Towards Ontological Foundations for Agent Modeling Concepts Using Ufo","n":0.333},"1":{"v":"\n- https://www.researchgate.net/publication/228699330_Towards_Ontological_Foundations_for_Agent_Modeling_Concepts_using_UFO\n- publish-date: 2014?\n- topics: [[prdct.gfo]] [[prdct.dolce]]\n- related:\n  - [[ar.towards-an-ontological-foundation-of-agent-based-simulation]]\n\n## Abstract\n\nFoundational ontologies provide the basic concepts upon which any domain-specific ontology is built. This paper presents a new foundational ontology, UFO, and shows how it can be used as a foundation of agent concepts and for evaluating agent-oriented modeling methods. UFO is derived from a synthesis of two other foundational ontologies, GFO/GOL and OntoClean/DOLCE. While their main areas of application are the natural sciences and linguistics/cognitive engineering, respectively, the main purpose of UFO is to provide a foundation for conceptual modeling, including agent- oriented modeling.","n":0.103}}},{"i":6019,"$":{"0":{"v":"Towards GFO 2.0: Architecture, Modules and Applications","n":0.378},"1":{"v":"\n- url: \n  - https://drive.google.com/open?id=1-OOQt_5pxTc_CuSEEusmJ6kYvRVlQgBL\n  - https://ebooks.iospress.nl/doi/10.3233/FAIA200658\n- authors: @patryk-burek @frank-loebe @heinrich-herre\n- keywords: [[sh.ontology.upper]] [[prdct.gfo]]\n\n## Abstract\n\nThe General Formal Ontology (GFO) is a top-level ontology that has been developed by the Onto-Med Research Group since the early 2000s. Since that time several new theoretical results have been achieved as well as numerous projects have utilized the ontology, especially in complex domains such as bioinformatics and medical computer science. This leads to the need for an up-to-date overview of GFO and access to its applications. This paper represents the first step towards introducing the GFO 2.0 framework, which aims at the integration of the work that is already present, but scattered in various publications, and its provision as a ready-to-use and reusable framework. For this purpose we summarize key features of GFO so far, outline a novel modular architecture and survey first modules for GFO 2.0, linking to applications. Finally, a rigorous and systematic development process is indicated.\n\n\n## ","n":0.08}}},{"i":6020,"$":{"0":{"v":"Towards an Ontological Foundation of Discrete Event Simulation","n":0.354},"1":{"v":"\n- url: https://www.researchgate.net/publication/224209121_Towards_an_ontological_foundation_of_discrete_event_simulation\n- topics: [[prdct.unified-foundational-ontology]] [[prdct.deso]]\n\n## Abstract\n\nThis paper is an attempt to transfer some results in the meta-theory of conceptual modeling of software systems to discrete event simulation modeling. We present \n\n![](/assets/images/2024-04-17-11-01-49.png)\n\n## Highlights\n\n- using an ontologically well-founded modeling language seems to be even more relevant for simulation engineering than for software system engineering ^zfbe99hkh7b3\n- DES is the most fundamental simulation paradigm ^f4xouwm2jcoa\n- both UML and BPMN, with suitable modifications and enhancements based on their ontological analysis and im- provement, have a high potential as simulation modeling languages.\n\n\n## Related Work\n\n- [[prdct.demo-project]]\n- [[ar.an-ontology-for-agent-based-modeling-and-simulation]]\n- [[ar.tutorial-conceptual-simulation-modeling-with-onto-uml]]","n":0.104}}},{"i":6021,"$":{"0":{"v":"Towards an Ontological Foundation of Agent Based Simulation","n":0.354},"1":{"v":"\n- https://www.informs-sim.org/wsc11papers/024.pdf\n- topics: [[t.cs.agents.agent-based-simulation]] [[t.km.ontology]] [[t.km.ontology.foundational]] [[prdct.unified-foundational-ontology.eUFO]]\n- author: @giancarlo-guizzardi @gerd-wagner\n\n## Abstract\n\nA simulation model is intended to capture a real-world system. Consequently, the modeling language used for making the simulation model should have a “real-world semantics” guaranteeing some kind of ontological faithfulness for the models made with it. In this paper, we propose to use ABDESO, a foundational ontology for agent-based discrete event simulation, for evaluating agent-based simulation languages.\n\n## Highlights\n\n### Events\n\n- Events are individuals that may be composed of temporal parts. They happen in time in the sense that they may extend in time accumulating temporal parts. \n- An event cannot exhibit change in time like a substance individual\n  - t.2024.07.27.23 don't tell @ned-markosian","n":0.094}}},{"i":6022,"$":{"0":{"v":"Towards a Semantics for the Artifactual Theory of Fiction and Beyond","n":0.302},"1":{"v":"\n- https://shs.hal.science/halshs-01216164/\n\n## Highlights\n\n- According to @amie-thomasson, fictional entities are\ninhabitants of the actual world just as non-fictional ones are. On the one hand, they are creations, or more precisely, artifacts, and as such, existent objects, like tables or buildings. On the other hand, they are abstract creations, like marriages, universities and theoretical entities postulated by physical theories, and are tied to the everyday world by their dependence on readers, authors and copies of texts.\n- Ingarden made a distinction:\n  - derivation, i.e., the dependence of an entity on another in order to\ncome into existence\n  - contingency, or the dependence of an entity on another in order to\nremain in existence.\n  -  a fictional character is created by an author who constructs sentences about it. Fictional entities thus have a derivative dependence on their creators. Yet they are considered to be kept in existence thereafter not by the imagination of any individual, but by words and sentences\n-  Thomasson combines the notions of historical and constant dependence with the idea of rigid and generic dependence.\n-  according to the Artifactual Theory, this fixed point in time is the time of the creation of a fictional entity, but this might give rise to the objection d mentioned in section 4 that some fairy-tale characters, such as Snow White, do not appear to have been created by any specific person at any specific time\n-  What the author does when he writes the story is to fix a codex, or\nset a canon","n":0.064}}},{"i":6023,"$":{"0":{"v":"Towards a Plan Ontology","n":0.5},"1":{"v":"\n- https://www.aiai.ed.ac.uk/project/oplan/documents/1996/96-aiia-plan-ontology.pdf\n\n\n## Highlights\n\n- the core activity mo del within this ontology draws on the <inova> (Issues-Nodes-Orderings/Variables/Auxiliary) constraint model of plans proposed recently to integrate a number of perspectives on plan and process representation\n- A Plan is a Specialised Type of Design\n\n### Principal Denition of a Plan\n- a PLAN is a SPECIFICATION of BEHAVIOUR for some PURPOSE(s)\n  - A PLAN may or maynot be EXECUTABLE\n- BEHAVIOUR is something that one or more AGENTs PERFORM\n- AGENT is an entity that can do one or both of the following:\n  - PERFORM or participate in the PERFORMance of BEHAVIOUR \n    - It can be a supplier of force behind BEHAVIOUR\n    - HOLD some PURPOSE(s)\n- EXECUTABLE means a PLAN can be PERFORMed by some AGENT(s)\n- PURPOSE is a CONSTRAINT which is HELD by one or more AGENTS\n- CONSTRAINT is a RELATIONSHIP. It expresses an assertion that can be evaluated with respect to a given PLAN as something that may hold and can be elaborated in some language\n- SPECIFICATION is a set of CONSTRAINTs\n\n### Agent to Constraint Relationships\n\n- INTEND\u0001 DESIRE\u0001 ENFORCE\u0001 SYNTHESIZE\n- INTENDED CONSTRAINT\n- DESIRED CONSTRAINT","n":0.075}}},{"i":6024,"$":{"0":{"v":"Towards a New Foundational Ontology of Properties Attributives and Data","n":0.316},"1":{"v":"\n- included-in: [[book.ontology-makes-sense]]","n":0.577}}},{"i":6025,"$":{"0":{"v":"Towards a Consistent Logical Framework for Ontological Analysis","n":0.354},"1":{"v":"\nhttps://www.cs.rochester.edu/~schubert/projects/papers/fois01.pdf\n\n## Abstract\n\nIn their framework for ontological analysis, Guarino and Welty provide a number of insights that are useful for guiding the design of taxonomic hierarchies. However, the formal statements of these insights as logical schemata are flawed in a number of ways, including inconsistent notation that makes the intended semantics of the logic unclear, false claims of logical consequence, and definitions that provably result in the triviality of some of their property features. This paper makes a negative contribution, by demonstrating these flaws in a rigorous way, but also makes a positive contribution wherever possible, by identifying the underlying intuitions that the faulty definitions were intended to capture, and attempting to formalize those intuitions in a more accurate way.\n\n\n## Conclusions\n\n(1) Guarino and Welty’s notation and associated descriptions indicate a confusion\nbetween between modal logic on the one hand, and temporal logic with explicit tem-\nporal arguments on the other, with the result that their formulae are uninterpretable by\nany standard semantics. The way to alleviate this confusion with the least disturbance\nto their framework would seem to be to replace all modal operators with explicit quan-\ntification over times, and to state explicitly that terms like “necessary,” “rigid,” and\n“essential” are related to persistence over time, rather than across worlds.\n(2) The claim that an anti-rigid property can’t subsume a rigid one is false. Incorrect\nintuitions about this issue probably indicate a confusion between subsumption and\nnecessary subsumption, since it is true that an anti-rigid property can’t subsume a rigid\none necessarily.\n(3) The meta-properties +/-I and +/-/∼U, indicating whether or not a property car-\nries identity or unity conditions, turn out to be useless for constraining taxonomic\nrelationships, as they are defined by Guarino and Welty. However, the property of\ncarrying a particular identity or unity condition does place useful constraints on taxo-\nnomic relations between properties","n":0.058}}},{"i":6026,"$":{"0":{"v":"Toql Temporal Ontology Querying Language","n":0.447},"1":{"v":"\n- https://www.researchgate.net/publication/221471747_TOQL_Temporal_Ontology_Querying_Language\n- authors: @evdoxios-baratis @euripedes-petrakis @sotiris-batsakis @nikos-maris @nikos-papadakis\n\n## Abstract\n\nWe introduce [[TOQL|prdct.toql]], a query language for querying time information in ontologies. TOQL is a high level query language that handles ontologies almost like relational databases. Queries are issued as SQL-like statements involving time (i.e., time points or intervals) or high-level ontology concepts that vary in time. Although indepen- dent from TOQL, this work suggests a mechanism for representing time evolving concepts in ontologies based on the four-dimensional perduran- tist mechanism. However, TOQL prevents users from being familiar with the representation of time in ontologies. To show proof of concept, an ap- plication has been developed that supports translation and execution of TOQL queries on temporal ontologies combined with a reasoning mech- anism based on event calculus. A real world temporal ontology is also implemented on which several TOQL example queries are processed and discussed.\n\n## Highlights\n\n- TOQL handles ontologies almost like relational databases. Queries in TOQL are issued as SQL statements involving time and high-level ontology concepts that (may) vary in time. TOQL maintains the basic structure of an SQL language (SELECT - FROM - WHERE) and treats the classes and the properties of an ontology almost like tables and columns of a database\n- TOQL syntax is independent of any temporal representation and can work with any other mechanism (e.g., versioning). As such, the 4D fluent ([[perdurantist|t.phil.perdurantism]]) mechanism is not part of the language and it is not visible to the user (so the user need not be familiar with peculiarities of the underlying mechanism for time information representation)\n- In the accompanying implementation, TOQL queries are first translated into equivalent statements in [[SeRQL|prdct.serql]] which are then executed on the underlying OWL temporal ontology. ","n":0.06}}},{"i":6027,"$":{"0":{"v":"Time Traveling in Graphs Using a Graph Database","n":0.354},"1":{"v":"\n- url: https://ceur-ws.org/Vol-1558/paper21.pdf\n\n## Highlights\n\n- Historical graph queries are graph queries applied at past snapshots. For example, a historical graph reacha- bility query may ask whether two nodes were reachable at some time interval in the past. \n- Historical time queries are graph queries that ask about the time point or the time interval that a query had a specific result. For example, a historical time reachability query may ask for the time point at which two nodes become reachable for the rst time. \n- Finally, historical top-k queries ask for the nodes that had a property for the longest period of time. For example, a his- torical top-k reachability query may ask for the k pairs of nodes that remained connected for the longest interval.\n\n### single and multi edge representation\n\n- the single-edge approach: the lifespan of a node or edge is modeled using a label (i.e., an attribute or property) of the corresponding node or edge. Figure 1 shows an example of edge lifespans represented by a single label of type String. For example, the co-authorship between authors A, C in 2010, and 2012, is represented by the edge with label \"2010,2012\". Graph evolution can be tracked by processing the node and edge lifespan labels. Thus, to obtain the graph snapshot Gt for a time point t, we get all edges and nodes and then keep only those edges and nodes whose lifespan label contains t.\n  - for second-level precision, seems incredibly wasteful\n- the multi-edge approach uses a different edge type between two nodes for each time point of the lifespan of the edge. For instance, in order to represent co-authorship between authors A, B, C in 2010, 2012, and 2014, we use three different labeled types of edges to connect A, B, and C.","n":0.058}}},{"i":6028,"$":{"0":{"v":"Time Clocks and the Ordering of Events in a Distributed System","n":0.302},"1":{"v":"\n- url: https://www.microsoft.com/en-us/research/uploads/prod/2016/12/Time-Clocks-and-the-Ordering-of-Events-in-a-Distributed-System.pdf\n- foreward: https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/?utm_source=substack&utm_medium=email\n\n## Highlights\n\n- There is only a partial order in which an event e1 precedes an event e2 iff e1 can causally affect e2\n-  A system is distributed if the message transmission delay is not negligible com- pared to the time between events in a single process.","n":0.141}}},{"i":6029,"$":{"0":{"v":"Third Generation Web Apis Bridging the Gap between Rest and Linked Data","n":0.289},"1":{"v":"\n- https://www.markus-lanthaler.com/research/third-generation-web-apis-bridging-the-gap-between-rest-and-linked-data.pdf\n- author: @markus-lanthaler\n\n## Highlights\n\n### Basic Concepts and Technologies\n\nOn the Web, contracts are based on media types and protocols. Applications can thus be built by composing various well-defined build- ing blocks. Media types define the data and processing models as well as the serialization formats. Protocols describe interaction models that extend the capabilities of (the more or less generic) media types...\n\nthe contracts are centrally owned instead of being owned by the server. This allows the independent evolution of clients and servers as both are coupled to these central contracts instead of being coupled to each other.\n\ninstead of relying on upfront agreement of all aspects of interaction, parts of the contract can be communicated or negotiated at runtime.\n\ninstead of relying on implicit state control-flows as described above, all communication is stateless, meaning that each request from the client to the server must contain all the infor- mation necessary for the server to understand the request\n\nThe challenge in designing RESTful systems is to select the most appro- priate media type(s) as the core of the application-specific contract.","n":0.076}}},{"i":6030,"$":{"0":{"v":"Theory Framework Knowledge Hub Message 1","n":0.408},"1":{"v":"\n- https://www.researchgate.net/publication/374265191_Theory_framework_-_knowledge_hub_message_1\n- author: @alex-shkotin\n- topics: [[t.km.formalization]] [[t.km.modeling]]\n\n\n## Abstract\n\nStoring the theory of a particular subject area in one place and maintaining it (including formalization) through collective efforts is easily possible with the modern development of technology. The concentration and verification of knowledge achieved in this case should give a powerful ordering of theoretical knowledge, which will facilitate their formalization, i.e. mathematical notation, and therefore algorithmic processing in many cases, up to the semi-automatic proof of various kinds of consequences, for example, theorems. This message describes what the framework of the theory is, intended for unified storage and collective accumulation of its results.\n\n## Issues\n\n### UGraph\n\n- @alex-shkotin: Let me propose to keep it in a knowledge hub form of framework. Like for ugraph theory [[here|ar.theory-framework-knowledge-hub-message-1]].  Today when we have GenAI as an alternative knowledge concentrator we at least know that it is possible to put ALL our theoretical knowledge in one \"computer\".\n\n- @john-sowa: No, no, no absolutely NOT!   Only a tiny fraction of logicians have ever seen ugraph.\n\nOnly until there is a formal translation to and from FOL, we have ZERO evidence that ugraph is precise and reliable.  And if anybody can demonstrate that such a translation is possible, then that is a proof that we don't need ugraph.  We can continue to use FOL.\n\nBut there is also a standard for the superset of FOL called DOL, which is an official standard of the Object Management Group.  For a summary of the [[prdct.distributed-ontology-modeling-and-specification-language-dol]] standard, see slides 8 to 12  of  https://jfsowa.com/talks/eswc.pdf .  That talk (with a subset of the slides) won the best presentation award at the 2020 European Semantic Web Conference.\n\n## References\n\n[^4]: [[ar.guidelines-for-writing-definitions-in-ontologies]]","n":0.061}}},{"i":6031,"$":{"0":{"v":"The Web after Tomorrow","n":0.5},"1":{"v":"\n- url: https://tonsky.me/blog/the-web-after-tomorrow/\n- [[p.mentioned]] [[prdct.datomic]]\n\n## Highlights\n\n- The big data source on the top is all the data we have in the project. Before reaching the client, it must come through two filters. First one is a security filter. It filters out all the data user is not authorized to see, leaving out just personal, shared and public rows. The second filter leaves only the parts user is interested in. For UI it means parts which are required to render current page. Everything that passes these two filters should be pushed to the client instantly, in real time. It is, by definition, everything client needs to render a page. ^9f1qxkkh215s\n- \"Query is a recipe to get the data from the storage. To get real-time, we need these queries to work the other way around. Client still defines its needs via query. This query might be used for initial data fetch, just as usual. The same query will then be used to filter whole-DB changelog and decide what parts of it server should push to which client. Fetch is about trying to get the data given the query. Push is about finding the affected subscriptions given the changed data.\" ^sw5qa6c54na5","n":0.071}}},{"i":6032,"$":{"0":{"v":"The TOQL System","n":0.577},"1":{"v":"\n- https://www.researchgate.net/profile/Euripides-Petrakis/publication/221471770_The_TOQL_System/links/09e4150ffae13e7574000000/The-TOQL-System.pdf\n- authors: @evdoxios-baratis @nikos-maris @euripedes-petrakis @sotiris-batsakis @nikos-papadakis","n":0.354}}},{"i":6033,"$":{"0":{"v":"The Temporal Logic of Actions","n":0.447},"1":{"v":"\n- https://lamport.azurewebsites.net/pubs/lamport-actions.pdf\n- author: @lesley-lamport\n- topics: [[t.cs.software-analysis]]\n\n## Abstract\n\nThe temporal logic of actions (TLA) is a logic for specifying and reasoning about concurrent systems. Systems and their properties are represented in the same logic, so the assertion that a system meets its specification and the assertion that one system implements another are both expressed by logical implication. TLA is very simple; its syntax and complete formal semantics are summarized in about a page. Yet, TLA is not just a logician’s toy; it is extremely powerful, both in principle and in practice. This report introduces TLA and describes how it is used to specify and verify concurrent algorithms. The use of TLA to specify and reason about open systems will be described elsewhere.\n\n","n":0.091}}},{"i":6034,"$":{"0":{"v":"The Rise of the Knowledge Graph","n":0.408},"1":{"v":"\n- https://www.ontotext.com/blog/the-rise-of-the-knowledge-graph/\n- ","n":0.707}}},{"i":6035,"$":{"0":{"v":"The Rdf Net Challenge","n":0.5},"1":{"v":"\n- https://www.tbray.org/ongoing/When/200x/2003/05/21/RDFNet\n- topics: [[idea.view-source-kickstarted-the-web]]\n- \n\n## Highlights\n\n### View Source Lesson\n\n\"**How to Fix It** · RDF has ignored what I consider to be the central lesson of the World Wide Web, the “View Source” lesson. The way the Web grew was, somebody pointed their browser at a URI, were impressed by what they saw, wondered “How'd they do that?”, hit View Source, and figured it out by trial and error.\n\nThis hasn't happened and can't happen with RDF, for two reasons. First of all, the killer app that would make you want to View Source hasn't arrived. Second, if it had, nobody could possibly figure out what the source was trying to tell them. I don't know how to fix the no-killer-apps problem, but I'm pretty sure it's not worth trying until we fix the uglified-syntax problem.","n":0.086}}},{"i":6036,"$":{"0":{"v":"The Psychology of Human Misjudgment","n":0.447},"1":{"v":"\n## Highlights\n\n- \"I have succeeded mostly by restricting action to jobs and methods in which I was unlikely to fail\"\n- \"I may have been lucky to avoid for so long the academic psychology that was then laid out in most textbooks. These would not then have guided me well with respect to cults and were often written as if the authors were collecting psychology experiments as a boy collects butterflies—with a passion for more butterflies and more contact with fellow collectors and little craving for synthesis in what is already possessed.\"\n- \"Psychological tendencies tend to be both numerous and inseparably intertwined, now and forever, as they interplay in life.\"","n":0.096}}},{"i":6037,"$":{"0":{"v":"The Psychological Needs of the Extremely Ambitious","n":0.378},"1":{"v":"\n## Highlights\n\n- \"If you’ve never tried to [“make your venture-backed startup profitable”], you probably under-appreciate just how psychologically demanding it is—in particular, how much fresh and unfettered thinking, win-win relationship building, emotional self-management, authentic conviction, earned self-trust, intellectual ambitiousness, and disciplined focus it requires.\"\n- 'people either get it or they don’t'—a kind of fixed mindset applied to the talents and capabilities of others.\n- [[p.references]] [[vs.fixed-vs-growth-mindset]]\n\n### Psychological Needs\n\n-   Beyond “setting more realistic [goals](https://www.psychologytoday.com/us/basics/motivation),” my clients need help balancing wildly ambitious goals with honesty about the low probability of success.\n-   Beyond “reappraising their catastrophic thoughts,” they need help recognizing when their “reappraisal” is just a [rationalization](https://www.psychologytoday.com/us/basics/rationalization) of what is in fact a [looming catastrophe that needs to be solved](https://a16z.com/2019/10/17/how-to-be-effective-ceo-leader/).\n-   Beyond “taking other people’s perspectives,” they need help disconnecting long enough to work out their own.\n-   Beyond “asserting themselves,” they need help seeking out relationships and communities that offer them closeness without assimilation.\n-   Beyond “learning [mindfulness](https://www.psychologytoday.com/us/basics/mindfulness) skills to manage their stress,” they need help recognizing when they're using these skills as a procrastination tool.\n-   Beyond “scheduling self care,” they need help powering through a week without rest for the sake of a valued endeavor.\n-   Beyond identifying generic values to guide their choices, they may need help articulating a mission statement that captures their aspirations, while still allowing flexibility in execution.\n-   Most of all, they need help developing the self-awareness and [self-honesty](https://genagorlin.com/2020/03/08/self-honesty-pt-1-knowing-versus-pretending-to-know/) to determine which skills they need when","n":0.065}}},{"i":6038,"$":{"0":{"v":"The Ontology of Relations","n":0.5},"1":{"v":"\n- url: https://academic.oup.com/mit-press-scholarship-online/book/29912/chapter-abstract/253560399\n\n## [[c.text.abstract]]\n\nThe is_a (or subtype) relation is the central structuring relation of an ontology. Ontologies also use other relations to link their categories together, for example the location and parthood relations, relations of participation and temporal precedence, and so forth. This chapter introduces ontological relations in general and the BFO treatment of relations in particular. Conventions for representing relations are introduced and specific ontological relations are defined and explained, including is_a, continuant_part_of, and occurrent_part_of. We explain the all-some rule for relations and outline the role of relations in defining ontological categories is highlighted. We also address specific properties of relations such as reflexivity, symmetry, and transitivity.\n","n":0.096}}},{"i":6039,"$":{"0":{"v":"The Ontology of Fiction a Study of Dependent Objects","n":0.333},"1":{"v":"\n- https://www.proquest.com/openview/ebd1dec3a8998aedc0380061db73da7e/1?pq-origsite=gscholar&cbl=18750&diss=y\n- author: @amie-thomasson\n\n## Artifactual Theory of fiction\n\n- fictional characters are non-concrete entities dependent (in different ways) on authors, texts and readers.\n- they share important features with other dependent entities such as stories, works of music, theories, tools, churches, and universals.\n- since fictional objects fall into the same category as literary works, one gains no parsimony by rejecting fictional objects and rephrasing apparent talk about them in terms of talk about stories\n\n## Similar\n\n### Similar books and articles\n\n[The Ontology of Fiction.](https://philpapers.org/rec/GETTOO)[Michael Edward Gettings](https://philpapers.org/s/Michael Edward%20Gettings \"View other works by Michael Edward Gettings\") - 1999 - Dissertation, University of California, Santa Barbara\n\n[Fictional entities.](https://philpapers.org/rec/THOFE)[Amie Thomasson](https://philpapers.org/s/Amie%20Thomasson \"View other works by Amie Thomasson\") - manuscript\n\n[Towards a semantics for the artifactual theory of fiction and beyond.](https://philpapers.org/rec/FONTAS)[Matthieu Fontaine](https://philpapers.org/s/Matthieu%20Fontaine \"View other works by Matthieu Fontaine\") & [Shahid Rahman](https://philpapers.org/s/Shahid%20Rahman \"View other works by Shahid Rahman\") - 2014 - _Synthese_ 191 (3):499-516.\n\n[A Defense of Causal Creationism in Fiction.](https://philpapers.org/rec/SACADO)[David Sackris](https://philpapers.org/s/David%20Sackris \"View other works by David Sackris\") - 2013 - _Philosophical Writings_ 41 (1):32-46.\n\n[Fictional objects, non-existence, and the principle of characterization.](https://philpapers.org/rec/SAUFON)[Andrea Sauchelli](https://philpapers.org/s/Andrea%20Sauchelli \"View other works by Andrea Sauchelli\") - 2012 - _Philosophical Studies_ 159 (1):139-146.\n\n[Fictional characters and literary practices.](https://philpapers.org/rec/THOFCA)[Amie L. Thomasson](https://philpapers.org/s/Amie L.%20Thomasson \"View other works by Amie L. Thomasson\") - 2003 - _British Journal of Aesthetics_ 43 (2):138-157.\n\n[The creationist fiction: The case against creationism about fictional characters.](https://philpapers.org/rec/BROTCF)[Stuart Brock](https://philpapers.org/s/Stuart%20Brock \"View other works by Stuart Brock\") - 2010 - _Philosophical Review_ 119 (3):337-364.\n\n[Actualisme et fiction.](https://philpapers.org/rec/PELAEF)[Jérôme Pelletier](https://philpapers.org/s/Jérôme%20Pelletier \"View other works by Jérôme Pelletier\") - 2000 - _Dialogue_ 39 (1):77-.\n\n[Fictional Entities.](https://philpapers.org/rec/SALFE)[Fiora Salis](https://philpapers.org/s/Fiora%20Salis \"View other works by Fiora Salis\") - 2013 - _Online Companion to Problems in Analytic Philosophy_.\n\n[Fictional characters.](https://philpapers.org/rec/FRIFC)[Stacie Friend](https://philpapers.org/s/Stacie%20Friend \"View other works by Stacie Friend\") - 2007 - _Philosophy Compass_ 2 (2):141–156.\n\n[Pretense, existence, and fictional objects.](https://philpapers.org/rec/EVEPEA)[Anthony Everett](https://philpapers.org/s/Anthony%20Everett \"View other works by Anthony Everett\") - 2007 - _Philosophy and Phenomenological Research_ 74 (1):56–80.\n\n[Speaking of fictional characters.](https://philpapers.org/rec/THOSOF)[Amie L. Thomasson](https://philpapers.org/s/Amie L.%20Thomasson \"View other works by Amie L. Thomasson\") - 2003 - _Dialectica_ 57 (2):205–223.\n\n[Deflacyjne (redukcyjne) koncepcje przedmiotów fikcyjnych. Przegląd i analiza.](https://philpapers.org/rec/GURDRK)[Jacek Gurczyński](https://philpapers.org/s/Jacek%20Gurczyński \"View other works by Jacek Gurczyński\") - 2011 - _Filozofia Nauki_ 19 (1).\n\n[Ingarden versus Meinong o logice fikcji.](https://philpapers.org/rec/SMIIVM-2)[Barry Smith](https://philpapers.org/s/Barry%20Smith \"View other works by Barry Smith\") - 1998 - In Z. Muszyński (ed.), _[Z badań nad prawdą i poznaniem](https://philpapers.org/rec/MUSZBN)_. Wydawnictwo UMC-S. pp. 283–296.\n\n[Reference and Meinongian Objects.](https://philpapers.org/rec/HUNRAM)[Daniel Hunter](https://philpapers.org/s/Daniel%20Hunter \"View other works by Daniel Hunter\") - 1981 - _Grazer Philosophische Studien_ 14 (1):23-36.","n":0.051}}},{"i":6040,"$":{"0":{"v":"The Marginalian","n":0.707},"1":{"v":"\n- [[p.instanceOf]] [[c.digitalgarden]] [[c.blog]]\n- [[p.hasSite]] https://www.themarginalian.org\n- [[p.hasAuthor]] @maria-popova\n- [[p.hasHighlight]] \n  - https://www.themarginalian.org/2022/10/23/16-learnings/\n","n":0.289}}},{"i":6041,"$":{"0":{"v":"Ursula K Le Guin Gender","n":0.447},"1":{"v":"\n- [[p.hasURL]] https://www.themarginalian.org/2014/10/17/ursula-k-le-guin-gender/\n#funny\n","n":0.577}}},{"i":6042,"$":{"0":{"v":"This Is Water: David Foster Wallace on Life","n":0.354},"1":{"v":"\n- [[p.hasHighlight]]\n  - The really important kind of [[t.phil.freedom]] involves attention and awareness and discipline, and being able truly to care about other people and to sacrifice for them over and over in myriad petty, unsexy ways every day.\n  - ","n":0.158}}},{"i":6043,"$":{"0":{"v":"James Baldwin Nothing Personal Love","n":0.447},"1":{"v":"\n- https://www.themarginalian.org/2022/01/31/james-baldwin-nothing-personal-love/?mc_cid=0a608dbd09&mc_eid=0fe640d99e\n- topics: @james-baldwin, [[book.nothing-personal]]","n":0.447}}},{"i":6044,"$":{"0":{"v":"James Baldwin Nothing Personal 4 Am","n":0.408},"1":{"v":"\n- https://www.themarginalian.org/2020/04/23/james-baldwin-nothing-personal-4-am/\n- topics: @james-baldwin, [[book.nothing-personal]], [[t.psych.faith]]\n\n\n## Highlights","n":0.378}}},{"i":6045,"$":{"0":{"v":"Henry Beston Night Outermost House","n":0.447},"1":{"v":"\n- https://www.themarginalian.org/2015/06/04/henry-beston-night-outermost-house/\n- topics: @george-beston, [[book.the-outermost-house]]\n\n## Highlights\n\n- \"Primitive folk, gathered at a cave mouth round a fire, do not fear night; they fear, rather, the energies and creatures to whom night gives power;\"","n":0.177}}},{"i":6046,"$":{"0":{"v":"The Implementation of Metagraph Agents Based on Functional Reactive Programming","n":0.316},"1":{"v":"\n- url: https://fruct.org/publications/volume-26/fruct26/files/Cher.pdf\n\n## Highlights\n\n- the metagraph model is more flexible and convenient than a hypergraph and hypernetwork model for use in information systems.","n":0.209}}},{"i":6047,"$":{"0":{"v":"The Bdi Model of Agency and Bdi Logics","n":0.354},"1":{"v":"\n- url: http://www.loa.istc.cnr.it/old/Files/bdi.pdf\n- topics: [[t.cs.agents.bdi]]\n\n![](/assets/images/2024-04-07-17-33-09.png)\n\n## Highlights\n\n- practical reason or will consists in the combination of deliberating and planning\n- Desires and beliefs range over states of affairs, while intentions range over actions and by extension, plans.\n- Intentions are persistent, whereas desires can be dropped at any time.\n- Intentions need not be holded forever.\n- Intentions drive means-end reasoning.\n- Beliefs constrain desires.\n- Intentions constrain future deliberation and planning.\n- Intentions influence beliefs upon which future practical reason is based.\n- Intentions imply a degree of commitment to a goal.\n- Intentions, beliefs and desires are required to be consistent. Beliefs are required to be consistent with other beliefs. Intentions with goals and beliefs and goals (analogously) with beliefs and intentions. We can thus say (so to speak) that the former are strongly consistent while the latter are weakly consistent 1. This condition is assumed to imply that of rationality.\n- Intentions, beliefs and desires need not be complete or, to put it simply, all-encompassing 2.\n- Beliefs are subject to revision.\n- Intentions and hence plans can be reconsidered","n":0.077}}},{"i":6048,"$":{"0":{"v":"The Acimov Methodology Agile and Continuous Integration for Modular Ontologies and Vocabularies","n":0.289},"1":{"v":"\n- https://www.emse.fr/~zimmermann/Papers/mk2023.pdf\n- topics: [[t.km.ontology.modular]]\n- publish-date: 2023\n- mentions: [[prdct.ontoology]] [[prdct.ontology-development-kit]] [[prdct.case-ontology]] [[prdct.samod-methodology]]\n\n## Abstract\n\n- This work describes the Agile and Continuous Integration for Modular Ontologies and Vocabularies (ACIMOV) ontology engineering methodology for developing ontologies and vocabularies. ACIMOV extends the SAMOD agile methodology to (1) ensure alignment to selected reference ontologies; (2) plan module development based on dependencies; (3) define ontology modules that can be specialized for specific domains; (4) empower active collaboration among ontology engineers and domain experts; (5) enable application developers to select views of the ontology for their specific domain and use case. ACIMOV adopts the standard git-based approach for coding, leveraging agility and DevOps principles. It has been designed to be operationalized using collaborative software development platforms such as Github or Gitlab, and tooled with continuous integration and continuous deployment workflows (CI/CD workflows) that run syntactic and semantic checks on the repository, specialize modules, generate and publish the ontology documentation.\n\n\n## [[prdct.coswot-ontology]] Requirements\n\n- O1 The ontology must align to reference IoT ontologies;\n- O2 The ontology must be modular, including modules that cover knowledge common to all IoT platform components;\n- O3 The ontology must reuse some identified ontologies for the application domains at stake;\n- O4 The ontology must have a homogeneous and predictable structure, such that similar concepts for different domains are described the same way;\n- O5 Different alternative representations must be possible to account for the need to manipulate small knowledge graphs in constrained devices;\n- O6 One must be able to select a subset of the ontology (a view) that covers the needs of a specific application.\n\n## Methodological Requirements\n\n- M1 Agile principles must be adopted to improve collaboration between ontology engineers, domain experts, and end-product owners, with short cycles, and working increments;\n- M2 Regular meetings with all parties must be held to help prioritizing the requirements stemming from use cases, and choosing the target for the next iteration;\n- M3 Regular meetings among ontology engineers must be held, to help prioritizing the modules to work on, and ensuring work on different modules can be led in parallel;\n- M4 Collaborative software development platforms with code versioning and issue tracking shall be adopted;\n- M5 DevOps principles must be adopted to enable continuous integration and deployment of the ontology artifacts (e.g., ontology modules, documentation, examples)\n \n## Highlights\n\n### Agile ontology engineering methods\n\nMany ontology engineering methodologies have been proposed over time, including [[prdct.methontology]] [ 9], On-To-Knowledge [ 10], DILIGENT [ 11 ], the “Ontology Development 101” [ 12], NeOn [ 13]. Some directly transpose software engineering methodologies, for example UPON Lite [ 14] is based on Rational Unified Process. The LOT methodology [ 15] adopts a V-model approach with conditional feedback at upstream development stages. Other early methods pro- posed to rely and align with existing ontologies to bootstrap new ontologies as in SENSUS [16 ]. More recently, methodologies are inspired by the principles of Agile software engineering, which promote collaboration between developers and stakeholders by producing regular updates of the product1. Among these methods, AMOD [ 17 ] and CD-OAM [ 18 ] are based on SCRUM. AMOD is the first method that describes the cycle of ontology development in a SCRUM sprint. CD-OAM enriches AMOD by describing the management the ontology commitment user community. XPOD [ 19 ] and eXtreme ontology method [ 20] are based on eXtreme Programming. The Lean Ontology Development (LOD) [21] is inspired by the Lean approach: Build-Measure- Learn. SAMOD [ 1 ] is revisiting the motivating scenarios and competency questions of Uschold and Gruninger [22], additionally considering ontology modules and test-driven development.\n\n### Git and CI/CD for ontology engineering\n\nBefore the democratization of these frameworks, a few preliminary approaches such as VoCol [ 23 ] or OnToology [ 24] were proposed in the ontology engineering community using Github applications2. [[prdct.ontology-development-kit]] (ODK) [ 25] uses Travis CI to run workflows with the ROBOT tool [ 26 ] developed by the Open Biological and Biomedical Ontologies (OBO) community. CI/CD pipelines are reported for the publication of different ontologies, such as the Financial Industry Business Ontology (FIBO) in [ 27], the International Data Spaces Information Model (IDSA) in [ 28], and the CASE Cyber Ontology3. Specific Github actions are available on the Github marketplace for running RDFLint4, validating RDF syntaxes5,6, or validating RDF files against SHACL shapes7 or ShEx [29].\n\n## Methodology\n\nStep 1 Collect requirements and identify reference ontologies.\nStep 2 Review meeting (an event)\nStep 3 Select relevant modules from reference ontologies\nStep 4 Manage modelet backlog\nStep 5 Modelet development meeting (an event)\nStep 6 Develop and test modelets\nStep 7 Integrate modelet and release ontology artifacts\n\n\n","n":0.037}}},{"i":6049,"$":{"0":{"v":"Texts as Hypergraphs an Intuitive Representation of Interpretations of Text","n":0.316},"1":{"v":"\n- url: https://journals.openedition.org/jtei/3919","n":0.577}}},{"i":6050,"$":{"0":{"v":"Temporalising Owl 2 QL","n":0.5},"1":{"v":"\n- https://www.dcs.bbk.ac.uk/~roman/papers/TemporalOWL2QL.pdf\n\n## Abstract\n\n- We design a temporal description logic, TQL, that extends the standard ontology language OWL 2 QL, provides basic means for temporal conceptual modelling and ensures first-order rewritability of conjunctive queries for suitably defined data instances with validity time.\n\n## Highlights\n\n- [[prdct.owl.ql]] does not support temporal conceptual modelling and, rather surprisingly, no attempt has yet been made to lift ontology-based data (obda) acces based on query rewriting to temporal ontologies and data","n":0.117}}},{"i":6051,"$":{"0":{"v":"Temporal Representation and Reasoning in Owl 2","n":0.378},"1":{"v":"\n- https://www.semantic-web-journal.net/system/files/swj1118.pdf\n- authors: @sotiris-batsakis\n\n\n## Abstract\n\nThe representation of temporal information has been in the center of intensive research activities over the years in the areas of knowledge representation, databases and more recently, the Semantic Web. The proposed approach extends the existing framework of representing temporal information in ontologies by allowing for representation of concepts evolving in time (referred to as “dynamic” information) and of their properties in terms of qualitative descriptions in addition to quantitative ones (i.e., dates, time instants and intervals). For this purpose, we advocate the use of natural language expressions, such as “before” or “after”, for temporal entities whose exact durations or starting and ending points in time are unknown. Reasoning over all types of temporal information (such as the above) is also an important research problem. The current work addresses all these issues as follows: The representation of dynamic concepts is achieved using the “4D-fluents” or, alternatively, the “N-ary relations” mechanism. Both mechanisms are thoroughly explored and are expanded for representing qualitative and quantitative temporal information in OWL. In turn, temporal information is expressed using either intervals or time instants. Qualitative temporal information representation in particular, is realized using sets of SWRL rules and OWL axioms leading to a sound, complete and tractable reasoning procedure based on path consistency applied on the existing relation sets. Building upon existing Semantic Web standards, tools and recommendations (like OWL 2, SWRL), as well as integrating temporal reasoning support into the proposed representation, are important design features of our approach.","n":0.063}}},{"i":6052,"$":{"0":{"v":"Temporal Interval Reasoning with Clp Q","n":0.408},"1":{"v":"\n- https://kt.ijs.si/personal-pages/igor_mozetic/papers/Mozetic-CLPq-SiKDD-05.pdf\n- topics: [[prdct.sumo]] [[prdct.clp-q]]\n\n## Highlights\n\n- to the best of our knowledge, there is no\ntheorem prover or interpreter of the KIF language publicly available ^ox70bpj41vs6","n":0.2}}},{"i":6053,"$":{"0":{"v":"43 Years of Actors - A Taxonomy of Actor Models and Their Key Properties","n":0.267},"1":{"v":"\n- [[p.hasURL]] https://drive.google.com/open?id=1-vN5Ue6m63HksjPNH_bZMu3jHtZlRzSr\n","n":0.577}}},{"i":6054,"$":{"0":{"v":"Task Taxonomies for Knowledge Content","n":0.447},"1":{"v":"\n- http://www.loa.istc.cnr.it/old/Files/D07_v21a.pdf\n\n## Highlights\n\nIn the section 2.2, an overview is provided of the following Ontological approaches to\nPlanning:\na. the BDI paradigm.\nb. planners constructed through Problem Solving Methods.\nc. the Act Formalism.\nd. the Shared Planning and Activity Representation.\ne. the Core Plan Representation.\nf. the Process Specification Language.\ng. the PLAN semantic NET.\nh. the Enterprise Ontology.\ni. the Ontology with Polymorphic Types.\nj. the Core Ontology of Services.\nk. an Ontological Formalization of the Planning Task","n":0.123}}},{"i":6055,"$":{"0":{"v":"Systematic Review on Ontology Applications in Virtual Reality Training Domain Design Components Roles and Research Directions","n":0.25},"1":{"v":"\n- url: \n  - https://ui.adsabs.harvard.edu/abs/2023JEI....32b1403B/abstract\n  - https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-32/issue-02/021403/Retracted-Systematic-review-on-ontology-applications-in-virtual-reality-training/10.1117/1.JEI.32.2.021403.full#_=_\n- retracted\n\n## Abstract\n\nEven though ontology and virtual reality training (VRT) are subjects that have been explored in various areas over the years, there is an absence of a systematic approach that gives an overview on how both have been utilized together. We aim to explore how ontologies have been applied in VRT technology in recent times. Therefore, the systematic literature review methodology was carried out to collect studies between 2014 and 2021 from various databases. To summarize, the main findings of this research are as follows: (1) the majority of the studies concerns two roles, i.e., either capturing and structuring knowledge or separating domain knowledge and operational knowledge; (2) all ontologies apply deficient foundational ontologies, languages, and methodologies when developing ontologies for VRT; (3) there is a general lack of capturing perdurant knowledge in ontology design; and (4) there are key design elements that are considered crucial for designing an ontology for VRT. Further directions have been provided to contribute to the body of knowledge by recommending the right design elements that could produce idealistic and ubiquitous ontologies to facilitate VRT development throughout its life cycle.\n\n\n## Highlights\n\nAccording to [[Guarino|ar.formal-ontologies-and-information-systems]] ontology can be classified based on the level of abstraction\ninto four categories including: top-level ontologies (upper ontology), domain ontology, task\nontology, and application ontology. A variety of entities and engineering components of ontol-\nogy are employed to design ontology depending on the problem that it is being addressed. These\ninclude endurants, perdurants, methodologies, tools, and languages.","n":0.064}}},{"i":6056,"$":{"0":{"v":"Superorganizers","n":1}}},{"i":6057,"$":{"0":{"v":"The Fall of Roam","n":0.5},"1":{"v":"\n- url: https://every.to/superorganizers/the-fall-of-roam","n":0.577}}},{"i":6058,"$":{"0":{"v":"Ai and the Age of the Individual","n":0.378},"1":{"v":"\n\nSuperorganizers\nAI and the Age of the Individual\nWhen intelligence is cheap individuals win\n\nby Dan Shipper\n\"a man with four arms typing on four typewriters at once, hyperrealistic\"\n\nPeople think AI is going to replace individuals and create gigantic trillion dollar megacorporations that will upend Google. But I think there’s a strong case to be made that rather than replacing individuals, recent advances in AI will empower them to make an impact on a scale matching some of the biggest businesses, research labs, and creative organizations of today. \n\nWhy? What businesses and research labs and movie studios purchase with their cash flow is intelligence. Organizations large and small are responsible for coordinating the intelligence of individual employees together to make products, discover new knowledge, and create new works of art. \n\nAI pushes the cost of intelligence toward zero. And as this happens, domains of achievement that were previously unavailable to individuals and small teams—because they required the marshaling and coordination of a large amount of intelligence—suddenly open up.\n\nIf you want to understand what will happen when the cost of intelligence goes to zero, you should look at what people who can afford the currently high cost of intelligence do with it today. What they do with it today, will be what individuals will be able to do with AI tomorrow.\n\nLet’s start with writers.\nHow this will work for writers\n\nIf you’re a writer today, you’ve got to do a lot to stay on top of your game. \n\nTake someone like Ryan Holiday. Ryan runs:\n\n    A daily email called the Daily Stoic\n    A Daily Stoic podcast\n    A Daily Stoic YouTube channel\n    A daily email called the Daily Dad\n    Oh and he's also written something like 5 books in the last 2 years\n    (I honestly think I’m missing a few things here—he has another newsletter on book recommendations that comes out monthly)\n\nHow does he do it? Well, first, an insane work ethic. Second, he has a very well-established content format and pipeline: he reads a lot, he takes a lot of notes on what he reads, and he’s quite good at translating little bits of reading into short, punchy essays that become newsletters or book chapters. These bits of writing then get translated into different formats: YouTube videos, a podcast, and more.\n\nThird, and most importantly, although he’s involved in everything that goes out, Ryan doesn’t do all of it himself. He has writers on staff that help him research and flesh out ideas and outlines into full-fledged posts. He has video editors and producers that help him translate his written pieces into videos. And he has podcast editors who help him turn his writing into audio. \n\nIf you want to have a level of output equal to Ryan, you need to not only have his rare combination of drive, writing skills, and intelligence. But you also have to have the resources and reach to recruit and pay the team that helps you output so much writing consistently, and then translate it into new formats.\n\nAI tools change this dynamic considerably. \n\nFor one, text-based large language models are already quite good at filling a research assistant or co-writer role. They’re happy to help look up facts and quotes, or to create an outline based on a simple idea. Of course, they’re not as good as a human at these tasks yet—but they’re good enough to have changed my writing process already through Lex, and their rate of improvement is high enough that in a year or two I think we’ll be shocked that we ever wrote without them. Going back will feel like trying to hike a mountain in high heels. \n\nBut that’s just how these tools will change the actual writing. They’ll also change writers’ ability to produce content for different formats. Text to speech models are already able to turn essays into human-like narration—just check out tools like Murf.\n\nVideo is a tougher nut to crack, but it’s definitely on the way. It’s already trivial to turn text into images using DALL·E and Stable Diffusion. It’s also trivial to use AI to interpolate between two images to create a rough animation. Tools like Runway are advancing rapidly in this space—and I don’t see any reason why these models won’t be able to create high-quality, format driven YouTube videos from an essay in a few years.\n\nAI tools will allow solo creators to run a Ryan Holiday-style business—but much more cheaply, and without a large team.\n\nI think the same thing is true for small teams of people who are trying to start startups. \nHow this will work for founders\n\nPeople who are looking to start startups usually think a lot about productivity. Many of us get very into taking lots of notes, reading widely, trying various todo list apps, and trying out new calendar and inbox techniques to get more done.\n\nBy contrast, founders who already have successful startups don’t seem to think about that stuff very much.\n\nIn short, productivity seems to follow a midwit curve:\n\nAndrey Zagoruiko 🇺🇦@andreyzagoruiko\n\naccurate\n\nJuly 26th 2022, 7:19pm EST\n1k Retweets16k Likes\n\nWhy is this? To some extent, the midwit curve is a normal learning curve. You try lots of things and settle on a few simple ideas that work well for you as you get further into your career and your company. \n\nBut what people forget is that founders at successful companies have another reason not to have to take so many notes or use so many productivity systems:\n\nThey have an entire organization that acts as an extension of their intelligence. In a sense, the organization itself is the biggest productivity hack of all—rendering cheap alternatives like note-taking systems or pomodoros obsolete.\n\nPeople who are just starting out on their company-building journey can’t afford and won’t be given the opportunity to marshal or coordinate intelligence yet. So they have to start by learning to coordinate cheaper options—like note taking systems, and todo list software. As they get good at those, they end up leaning less heavily on them because they can lean on the people around them to perform many of the same functions:\n\n    Executive assistants and chiefs of staff are in charge of keeping track of your calendar, and culling your email—so calendaring, scheduling, and inbox techniques are less of a focus\n    Direct reports are largely responsible for gathering, synthesizing, and presenting you with information about the status of ongoing work—and for updating systems of record with the status of that work—so note-taking is less important than asking concise questions and driving toward an overall vision or set of goals through regular checkpoints\n\nThe same thing is soon going to be available to anyone at a far cheaper price. Rather than spending time gathering, organizing, and recording information for later use, productivity-obsessed business-people in their 20s and 30s will instead be getting far better at asking the right questions, getting good answers back from the system, and learning to guide it toward what they want.\n\nBut that’s just the start. Founders usually start out doing every function inside of a company:\n\n    Product\n    Design\n    Engineering\n    Sales\n    Marketing\n    Ops / Finance\n    Customer service\n\nAt the beginning of a company the customer service work might only take a few minutes a day—you have very few customers, and their requests take only a short time to respond to. Even better, if they ask for new features in the product, you might be able to build and ship them in a few hours because the codebase isn’t particularly complicated and you know exactly what needs to be built because you’re the one who was talking to the customer.\n\nAs time goes on, each of these tasks grows in its complexity and the time required to do it. Instead of customer service taking a few minutes a day, by the time you reach scale it might be the job of an entire team of people to respond to only one kind of customer service request. Similarly, an entire team might be responsible for a single feature of the product.\n\nEven the limited models we have today change the equation for startups at an early stage:\n\n    Chatbots are already being used at scale to respond to repetitive customer requests\n    Tools like AskViable aggregate customer feedback and respond intelligently to questions about what people want so that it can be acted on\n    GitHub CoPilot significantly reduces the time it takes to build new features\n\nThe curve of improvement here is quite steep, and the trend is clear. \n\nWhat these models will become in a few years is a chatbot that can get stuff done: you tell it what you want and it does it. If it has questions it will ask them, and you’ll have the opportunity to provide feedback as the task is completed to make sure it’s done right.\n\nI think in a few years this will mean founders will be able to scale a product to millions of users without requiring a huge team. \nWhat's next though?\n\nThis vision of the future brings up a bunch of obvious questions. \n\nFor one, what sorts of skills are still important in a world where AI can do many tasks—including creative tasks—for us? For another, if you buy the argument above it’s clear that AI will empower some individuals—but what about the people it replaces?\n\nI don’t know the answer to either of these questions! But I do have a few guesses.\n\nFor one, these kinds of skills are always going to be quite important:\n\n    Vision\n    Taste\n    Ability to prioritize\n\nIn other words, you’re still going to have to have some idea what you want the model to do and not do. You also need to have some idea whether it’s doing the job well or not. I think this is true even of models that are self-improving—at some point, someone’s got to look at it and decide whether or not to keep it plugged in.\n\nAs to the second question, my theory of all of this is that work tends to be fractal. Having bots that can do tasks for us doesn’t necessarily mean a net-loss in jobs—instead the kinds of jobs and the skills they require will change significantly.\n\nIf we go back to the Ryan Holiday example, it seems clear that someone like him might be able to use AI to create a similar amount of output with a smaller team. But once you can produce more with less, the usual move is to create more until hit another constraint.\n\nFor example, maybe instead of having two daily emails, someone like him will be able to have four with the same budget. And as he creates more, he’ll still need to hire people to train and manage the models that are doing a lot of the work. Ultimately, people are still required. There’s just way more leverage on their time. \n\nThat doesn't mean things are just going to work out automatically. These kinds of technology shifts can cause significant harm to people whose jobs and skillsets need to change dramatically. It will require good policy and regulation to catch up with the shift, and significant conversations at the societal level about how humans should function and relate to each other in concert with these tools.\n\nAs that's happening, though, individuals who are familiar with and skilled at using them have an opportunity to do better and more impactful work than they ever have before. And that opportunity is distributed to anyone with an internet connection, a laptop, and a desire to play around with these models. I think that’s pretty exciting.\n\n\nWhat did you think of this post?\nAmazing Good Meh Bad\n\nYou received this email because you signed up for emails from Every. No longer interested in receiving emails from us? Click here to unsubscribe.\n221 Canal St 5th floor, New York, NY 10013\n","n":0.023}}},{"i":6059,"$":{"0":{"v":"Story Vs Game the Battle of Interactive Fiction","n":0.354},"1":{"v":"\n- author: @doug-sharp\n- http://web.archive.org/web/20040404061317/www.channelzilch.com/doug/battle.htm\n","n":0.5}}},{"i":6060,"$":{"0":{"v":"Stigmergic Cues and Their Uses in Coordination an Evolutionary Approach","n":0.316},"1":{"v":"\n- https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=408f4e86dda4187f1021d2432602224271d855ea","n":0.707}}},{"i":6061,"$":{"0":{"v":"Star Vers Versioning and Timestamping Rdf Data by Means of Rdf Star an Approach Based on Annotated Triples","n":0.236},"1":{"v":"\n- https://www.semantic-web-journal.net/system/files/swj3506.pdf\n- https://www.semantic-web-journal.net/content/starvers-versioning-and-timestamping-rdf-data-means-rdf-star-approach-based-annotated\n- authors: @filip-kovacevic @fajar-ekaputra @tomasz-miksa @andreas-rauber\n- topics: [[prdct.RDF-star]] [[prdct.GraphDB]] [[prdct.jena]] [[prdct.yago.4.5]] [[prdct.rdf3x]]\n- implementation: [[prdct.starvers]]\n\n\n## Abstract\n\nIn the era of data-driven research, we are confronted with the challenge of preserving datasets utilized in experiments for an extended duration. As a result of unretrievable datasets, research cannot be reproduced nor verified. One of the specific challenges is the preservation of the history of evolving datasets. To tackle this challenge, we nowadays use versioning mechanisms on datasets so that each version or revision can be identified. The retrieval of specific versions usually requires queries to be enhanced with some form of version identifiers in order to target specific snapshots. What these version identifiers look like depends on the versioning policy. In timestamp-based policies we would use timestamps in order to retrieve datasets as they were at a specific point in time. The implementation of such policies again depends on the type of data and more importantly on the database system. In the context of RDF data, researchers have contributed with countless temporal RDF models and RDF versioning systems over the last two decades. Many well-known RDF metadata representation models, such as named graphs, reification, n-ary and singletons have simply been applied to represent temporal metadata. However, only little reserach has been done in this direction with one of the more recent RDF extensions with the capability of representing metadata, namely RDF-star. In this paper, we explore the possibilities of RDF-star as basis of a timestamp-based versioning framework. We show how temporal metadata can be represented by utilizing RDF-star's nested triples and stored within RDF-star stores. Moreover, we develop and showcase timestamp-based SPARQL-star templates that can be used to 1) transform RDF datasets into RDF-star datasets 2) update and thereby evolve RDF dtasets and 3) query RDF subsets of time-specific snapshots. We also explain our utilization of the SPARQL query algebra for the purpose of translating SPARQL queries into SPARQL-star queries and link our python-based API that is capable of automatically generating and executing latter queries. Finally, we evaluate our work with datasets and queries from the BEAR benchmark and two RDF stores, namely, Jena TDB2 and GraphDB. Our results suggest that our solution is preferable if the frequency and manner of dataset evolution are uncertain, implying that it outperforms the baseline approaches in sum. However, in cases where datasets are prone to high change rates between consecutive updates our approach does not outperform the baseline approaches in terms of storage consumption. Moreover, the choice of RDF store is significant as the query performance differs vastly between the evaluated RDF-star stores. Our reproducible evaluation process is available on: https://github.com/GreenfishK/starvers_eval\n\n\n## Highlights\n\n- When it comes to RDF datasets, we will find three approaches, namely, 1) independent copies (IC) or snapshots 2) change-based\n(CB) approaches and 3) timestamp-based (TB) approaches to be the most common ones in the literature\n  - IC takes a lot of space\n  -  as opposed to the IC paradigm, we have higher reconstruction costs which add up to the retrieval of a specific dataset version. Also, CB apporaches are not nateively supported by SPARQL, i.e. there is no way to retrieve and apply a number of patches to reconstruct a dataset version purely with SPARQL as it is lacking procedural features\n  - TB approaches assign timestamps or validity intervals to data on different granularity levels that can range from statement to dataset level so that a dataset can be retrieved as it was at a certain point in time\n    - by implementing clever temporal indexes and partitioning methods we can achieve fast retrievals that add only little query performance overhead compared to querying isolated snapshots directly\n\n\n### Versioning\n\n- [[prdct.rdf3x]] approach to continuous validity is to leave out the deletion timestamp for the most recent version of the triple, which is different from our approach \n  - Another difference to our approach is that their solution is built for RDBMS systems and not for RDF stores\n\n## SQT Limitations\n\n- As long as each data triple has only one time interval, i.e. only one pair of the previously mentioned temporal properties, this model is solid for representing temporal metadata about facts\n  - with the SQT-based representation, distinguishing which quoted triples belong together, i.e. form a pair, becomes problematic.\n\n## NQT-SP temporal metadata representation model\n\nA triple can be annotated with our two temporal properties using the NQT-SP pattern as follows:\n\n`<< << tr1 >> vers:valid_from t1 >> vers:valid_until tE .`\n\nIf we replay the same scenario as in the previous section, just with the new pattern, we get following dataset:\n\n```\nnqtsp1: << << tr1 >> vers:valid_from t1 >> vers:valid_until t2 .\nnqtsp2: << << tr1 >> vers:valid_from t3 >> vers:valid_until tE .\n```\n\n### Property Path issues\n\n- Our approach, however, reaches its limit when it comes to property paths of arbitrary length, such as ?x foaf:knows+/foaf:name ?name. \n\n### Protocol to transform SPARQL queries into timestamped SPARQL-star queries\n\n- rule1: Property paths of fixed length must be resolved to an alternative form.\n- rule2: Each data triple pattern must be annotated with a unique pair of temporal information variables within the scope of a SPARQL SELECT-query.\n- rule3: In every BGP a ?ts variable must be in-scope. If there are more ?ts variables in the query, they all must bind to the same timestamp literal. \n- rule4: Each NQT-SP pattern must have a unique FILTER condition which reduces the solution mappings of that pattern to only those triples where ?ts is in between its temporal information variables. \n- rule5: The timestamp variable ts and temporal information variables must only be purposed for what is described in rule2 and rule3, respectively, and should otherwise not be used.","n":0.033}}},{"i":6062,"$":{"0":{"v":"Spatio Tempoarl Extents","n":0.577},"1":{"v":"\n- author: @matthew-west\n- https://www.sciencedirect.com/science/article/abs/pii/B9780123751065000117\n\n## Summary\n\nThis chapter focuses on spatio-temporal extents and describes some of the basic kinds of spatio-temporal extents that are commonly found. It examines the space-time patterns that different kinds of spatio-temporal extents exhibit. The most important relationship between spatio-temporal extents is that of one being part of another. This is called aggregation when the whole is the sum of the parts. An aggregation is a relationship where one spatio-temporal extent is a part of another such that the whole is the sum of the parts. This key relationship is also examined in the chapter. Sometimes, the whole is more than the sum of its parts. The parts compose something that has emergent properties that result from the way that the parts are arranged. This is called composition. A composition is an aggregation where the parts are arranged in such a way that the whole is more than the sum of the parts. Finally, there is the case where the part is the full spatial extent for a period in the; that is, the part is a state of the whole. This is termed temporal composition. A spatio-temporal extent may be part of one or more other spatio-temporal extents.","n":0.071}}},{"i":6063,"$":{"0":{"v":"Spacetime a Two Dimensions Search and Visualisation Engine Based on Linked Data","n":0.289},"1":{"v":"\n- https://fabiovalse.github.io/data/MasterDegree_thesis.pdf\n\n\n## Prior Art\n\n- [[prdct.timelinejs]]\n- [[prdct.timeliner-js]]\n- https://tympanus.net/Tutorials/LateralOnScrollSliding/","n":0.378}}},{"i":6064,"$":{"0":{"v":"Some Open Issues after Twenty Years of Formal Ontology","n":0.333},"1":{"v":"\n- file:///C:/Users/drichardson/Downloads/FAIA306-0001.pdf\n- authors: [[user.stefano-borgo]] @pascal-hitzler\n\n## Highlights\n\n- \"If we use a decidable logical language, for technical reasons the capacity of the language to express the needed information is limited and the logical theory will not be able to include basic information (for instance, these languages have limitations in coding ternary relations like “z is between x and y” or “x counts as y at time t”).\"\n  - t.2024.07.22.14 Really?!? @chatgpt thinks you can use a relator without losing decidability\n- Another issue regards the proposal presented in [9] to separate ontologies in four types: top-level, domain, task and application ontologies.\n\n### Distinction between types of ontologies\n\n- As proposed in [[ar.formal-ontologies-and-information-systems]]\n  - Top-level ontologies are devoted to “describe very general concepts like space, time, matter, object, event, action, etc., which are independent of a particular problem or domain”; domain ontolo- gies “describe [...] the vocabulary related to a generic domain (like medicine, or automo- biles)”; task ontologies “a generic task or activity (like diagnosing or selling)”; finally application ontologies “describe concepts depending both on a particular domain and task, which are often specializations of both the related ontologies. These concepts often correspond to roles played by domain entities while performing a certain activity, like replaceable unit or spare component.\n    -  today domain ontologies and application ontologies are largely used as synonyms, task ontologies are rarely addressed and the most recognized (and perhaps useful) separation is between top-level ontologies and application ontologies\n    -  the practitioner often finds it hard to distinguish the classification of entities by type and by role.\n    -  the ontology is naturally influenced by the observer’s perspective and this freezes the entities into their contextual roles. Once an entity is seen as main- taining the same role across any scenario in the application at stake, the importance of the theoretical distinction between the entity and its role fades away.\n\n### foundational ontology and philosophy\n\n- while a top-level ontology is a classification system that deals with general domain-independent categories only, a [[t.km.ontology.foundational]] is a top-level (formal) ontology that has been built and motivated by the upfront and explicit choice of its core principles. \n  - principles are about fundamental choices: the understanding of space/time, the relationship between entities and space/time, the existence of objects and/or events, the existence of abstract entities, of possibilia, of types of properties, the relationship between objects/events and their properties, the identity conditions, the dependence relationships and so on\n- Some of the existing formal ontologies go further and explicitly adhere to specific philosophical schools. \n  - [[prdct.basic-formal-ontology]] is an attempt to translate an interpretation of scientific realism into logical form,\n  - [[prdct.gfo]] relies in a form of conceptual realism called [[t.phil.realism.integrative]]\n  - We note that today no philosophical school recognizes these systems as truly representative of (a form of) realism\n  - unclear whether these philosophical stands have a technical impact. \n- conceptualist approach: [[prdct.unified-foundational-ontology]]\n- [[prdct.dolce]] requires only ontological coherence and lets users maintain their world\nview by showing how to integrate different modeling perspectives within a single formal\nontology\n- [[prdct.sumo]] was developed by assembling off-the-shelf formal theories\nthat together could cover the most general categories. \n  - [[prdct.iso-15926]] is 4D\n\n### do philosophical distinction matter?\n\n- Given this brief outlook of some formal ontologies, one wonders whether their different stands have a real impact in the use of the formalized systems. Here things are less clear. Generally speaking, where something cannot be modeled directly because of an ontological distinction (e.g. the sharp distinction between material and information objects blocks the simple representation of common-sense objects like a book), these ontologies propose reformulation patterns that are often successful (e.g. the distinction of the book as the material entity and the book as the information entity among which a representation relation holds). Yet, this method cannot always work due to the idiosyncrasy of some application domains and the complexity of some concepts used in applications. To state it briefly, all these ontologies explicitly state their core principles but then allow the user to add arbitrary categories even though these are not ontologically justified or justifiable. While this is built-in in ontologies like DOLCE and GUM, unprincipled ex- tensions should be alien to formal ontologies that adhere to some philosophical school. For the latter systems, the actual exploitations of the ontology in application domains are philosophically wrong but practically accepted, and since an applied ontology has its raison d’être in its use, they make a virtue out of necessity.\n- [[prdct.dol-distributed-ontology-model-and-specification-language]]\n\n### Conclusion\n\n#### formal vs. ad-hoc\n\n- highly formal ontology modeling leads more likely\nto robust ontologies, which by construction are reusable in many contexts, their genera- tion also requires significant efforts. \n- ad-hoc computational ontologies are rather cheap to produce, but tend not to follow quality principles and are extremely limited in terms of reusability, which in turn means that it often seems to be easier to make a new ontology rather than attempt to reuse or modify such an ad-hoc ontology. \n  - One important reason is that ad-hoc ontologies tend to be developed taking a particular viewpoint or purpose, and this makes it hard to adapt them to different contexts or uses. \n  - Consequently, ad-hoc ontologies have a significant cost factor in terms of time and expertise required when they are to be updated, modified, or repurposed. \n- We still do not have an active line of research on how to achieve such a favorable trade-off, nor even a list of quality metrics to evaluate such result.\n\n#### comprehensive vs shallow axiomatization\n\n- relates to both:\n  - choice of logical knowledge representation language used for the encoding (which sometimes is driven by application constraints),\n    - both description logics and rules have been posited as favorable for several reasons [28], however hardly any research has been done on this question.\n  - how deeply axiomatized\n    - Few axioms thus lead to ambiguities, while many axioms put hard constraints on reusability\n\n","n":0.032}}},{"i":6065,"$":{"0":{"v":"Socially Grounded Analysis of Knowledge Management Systems and Processes","n":0.333},"1":{"v":"\n- https://www.researchgate.net/publication/27713553_Socially_Grounded_Analysis_of_Knowledge_Management_Systems_and_Processes\n- proposes [[prdct.arknowd]]\n\n","n":0.5}}},{"i":6066,"$":{"0":{"v":"Semantic Modeling with Sumo","n":0.5},"1":{"v":"\n- url: https://arxiv.org/ftp/arxiv/papers/2012/2012.15835.pdf\n- author: @robert-alan\n- keywords: [[prdct.sumo]] \n\n## Highlights\n\n- \"While the SUMO ontology allows states and state changes, states in themselves are not distinct, “real” entities. Thus, they are not accepted into so-called realist ontologies such as BFO.\"\n- ","n":0.162}}},{"i":6067,"$":{"0":{"v":"Semantic Modeling of Events Using Linked Open Data","n":0.354},"1":{"v":"\n- https://www.techscience.com/iasc/v29n2/42943/html\n- has-comparands: [[prdct.lode-ontology]] [[prdct.cidoc-crm]] [[prdct.simple-event-model-ontology]][[prdct.event-ontology]]\n\n![](/assets/images/2024-07-26-22-17-49.png)\n","n":0.408}}},{"i":6068,"$":{"0":{"v":"Sciencedirect","n":1}}},{"i":6069,"$":{"0":{"v":"A Systematic Comparison of Roundtrip Software Engineering Approaches Applied to Uml Class Diagram","n":0.277},"1":{"v":"\n- url: https://www.sciencedirect.com/science/article/pii/S1877050921002830/pdfft?md5=28f7e79b53ec6be950f5eeaab2b5a9e6&pid=1-s2.0-S1877050921002830-main.pdf\n\n## [[c.comparand]]\n\n- Papyrus, Modelio, BoUML, [[prdct.metaedit]], [[prdct.visual-paradigm]], [[prdct.acceleo]] ","n":0.316}}},{"i":6070,"$":{"0":{"v":"A Quadtree Based Synchronization Protocol for Inter Server Game State Synchronization","n":0.302},"1":{"v":"\n- url: https://www.sciencedirect.com/science/article/pii/S1389128620313177\n- [[c.mention]] [[prdct.named-data-networking]] [[t.cs.game.world.quad-tree-synchronization-protocol]]\n- repo: https://github.com/phylib/QSPArtifacts\n\n\n## Highlights\n\n- \"the quadtree is built as a Merkle tree, meaning that every non-leaf node of the tree is assigned a cryptographic hash value, which is calculated by hashing the child nodes of the corresponding node. Thereby, a single changed object somewhere in the overall region is recognized by a change of the tree’s root hash. Starting from the root, it is possible to track the change down to the single leaf node that changed.\"","n":0.11}}},{"i":6071,"$":{"0":{"v":"Scala for Game Server Development","n":0.447},"1":{"v":"\n- url: https://tech.devsisters.com/posts/scala-for-game-server-development/\n- author: @pierre-ricadat","n":0.447}}},{"i":6072,"$":{"0":{"v":"Sapphire Generating Java Runtime Artefacts from Owl Ontologies","n":0.354},"1":{"v":"\n- https://simondobson.org/softcopy/sapphire-odise11.pdf\n- topics: [[prdct.owl]] [[t.km.ontology]] [[prdct.sapphire]]\n- authors: @graeme-stevenson @simon-dobson \n\n## Abstract\n\nThe OWL ontology language is proving increasingly popular as a means of crafting formal, semantically-rich, models of information systems. One application of such models is the direct translation of a conceptual model to a set of executable artefacts. Current tool support for such translations lacks maturity and exhibits several limitations including a lack of support for reification, the open-world assumption, and dynamic classification of individuals as supported by OWL semantics. Building upon the state-of-the-art we present a mapping from OWL to Java that addresses these limitations, and its realisation in the form of a tool, Sapphire. We describe Sapphire’s design and present a preliminary evalua- tion that illustrates how Sapphire supports the developer in writing concise, type safe code compared to standard approaches while maintaining competitive run- time performance with standard APIs.\n\n\n## Highlights\n\n- Mapping OWL Classes to Java interfaces is an established technique for approxi- mating OWL’s multiple inheritance [4, 5]. However, in generating implementation classes, schemes described in the literature provide no support for dynamic classifi- cation of OWL individuals.\n- Puleston et al. [25] present a case study supporting an approach that conflates both domain-specific and ontology-agnostic aspects within a single API. Applications con- structed using this technique are assumed to be structured around a static core that is accessed in a domain-specific manner, with highly dynamic concepts at its edges that are accessed via a generic API.","n":0.065}}},{"i":6073,"$":{"0":{"v":"Rustconf Talk","n":0.707},"1":{"v":"\n- url: https://kyren.github.io/2018/09/14/rustconf-talk.html\n- [[c.actor.speaker]] @kyren\n\n## [[c.text.exerpt]]\n\n- [with oo] \"It feels like every time a new requirement comes in, you have to take what may have once been sane interfaces and “poke more holes through them”.\"\n- Data hiding has very limited utility for a game outside of just maintaining invariants at the edges of the code, where things are smaller and more contained. A lot, possibly even the vast majority of the interesting behavior in your game ends up spanning many data types, and does not naturally “belong” to any specific entity. Lots of entity types are 80% or 60% similar to others and its hard to re-use code, and the more modules we add inside our entities to help reuse code, the more layers are added.\n\n- Not everybody entirely agrees with what OO is, but I’m including some basic hopefully non-controversial points: ^hkms0rjrw5lz\n  -   Single responsibility principle - Objects should have a single logical set of responsibilities, and methods should perform one operation inside that set of responsibilities. \n  -   Encapsulation - You should bind data together with the functions that operate on it, keeping both safe from outside interference and misuse. This allows for refactoring by changing the internal representation of a class without changing its behavior.\n  -   Abstraction, or “Liskov Substitution Principle”, or similar - You should be able to substitute one derived class for another, as long as they share the same base and are used through that base class (or interface, or whatever).\n  -   Interface segregation, or principle of least coupling, etc - The dependency on one class to another should use the smallest possible interface. \n\n- there are at least a few good ideas that are sort of related to OO or kind of came out of OO (all of which Rust has and can perform admirably). ^c47v165vrmv6\n  -   The dot operator or “postfix functions”. If you’re a haskeller this is “type directed name resolution” as opposed to the normal state of affairs which is “name directed type resolution”. A “powerful” way to avoid having to scope 100 different functions with very short common names, or have C style prefixes for everything. Great for IDEs too!\n  -   Interfaces with laws (contracts) - Rust traits! No inheritance in sight, and they’re best when they’re small and come with meaningful rules around them, but if you squint they’re kind of C++ pure virtual classes. They’re _awesome_ in the same way Haskell typeclasses are awesome.\n  -   Data hiding - Being able to hide data to maintain invariants is invaluable, making a safe interface to unsafe code would not be possible without it. Very useful in the small, and with “library” code.\n\n","n":0.048}}},{"i":6074,"$":{"0":{"v":"Roles and Their Three Facets a Foundational Perspective","n":0.354},"1":{"v":"\nhttps://content.iospress.com/articles/applied-ontology/ao210244\n\n## Abstract\n\nRoles remain nebulous entities, notwithstanding their extensive interdisciplinary research. This paper argues through a meta-ontological conceptual tool of grounding that there are three key facets of roles: a role position, a role specification, and a role potential. A foundational perspective on roles can be specified by “role choices” as to which facet of roles is primary. Role choices are illustrated with theories of roles that are built in compliance with four well-known upper ontologies: [[prdct.gfo]], [[prdct.dolce]], [[prdct.basic-formal-ontology]], and [[prdct.unified-foundational-ontology]]. The relationship between such three facets of roles and the GFO-based three kinds of roles (relational, processual, and social) is closely examined. These three facets are also comparatively studied from linguistic (e.g. ‘have a role’ versus ‘play a role’) and methodological (realism versus conceptualism regarding ontology design) perspectives. Furthermore, the family resemblance view of roles as “epistemic trackers” is proposed: the general notion of role is merely (partially) unified by its three facets and helps to keep track of some entity with respect to its role-related aspects. Finally, defining characteristics of roles in conceptual modeling are considered in terms of the three-facet theory. This work provides the grist for future practical development of an ontological module for generic role representation","n":0.071}}},{"i":6075,"$":{"0":{"v":"Rockpapershotgun","n":1}}},{"i":6076,"$":{"0":{"v":"How One of the Finest Rpgs Ever Made Thinks about Money and Magic","n":0.277},"1":{"v":"\n- url: https://www.rockpapershotgun.com/how-one-of-the-finest-rpgs-ever-made-thinks-about-money-and-magic\n- subject: [[game.roadwarden]]\n\n## Highlights\n\n- \"There is often minimal sense that money really exists within the world, that it means anything to the residents. It's just a convenient framework for player progression - certainly, not the basis for a story.\"\n\n","n":0.156}}},{"i":6077,"$":{"0":{"v":"Representing Time in Rdf","n":0.5},"1":{"v":"\n- url:\n  - https://blog.iandavis.com/2009/08/representing-time-in-rdf-part-1/\n  - https://blog.iandavis.com/2009/08/representing-time-in-rdf-part-2/\n\n## Approaches\n\n### Approach 1: Conditions and Time Slices\n\nConditions were my invention to model the state of being of an individual at a point in time. They are basically time slices as used in OpenCyc (the original CYC notion of subAbstractions seems to be missing from OpenCyc).\n\n### Approach 2: Named Graphs\n\nphysically divide my data up into separate graphs. Each graph contains triples that hold true for a specified time interval. One graph is designated as holding the time interval information for all the other graphs.\n\n### Approach 3: Reified Relations\n\nI reify every triple that is time-dependent. That means every triple is split out into its constituent parts which will obviously lead to an explosion of triples.\n\n### Approach 4: N-ary Relations\n\na new class is created for each time-dependent predicate. This new class represents the context of the property and allows more specific predicates to be used that provide extra meaning.\n\n## Conclusions\n\n### Approach 1: Conditions and Time Slices\n\nThis approach seems very workable and there is a large body of philosophical work pertaining to this view of the world. In RDF terms though, there seems to be a problem with the domains of properties. Using the properties as I have done here implies that the \"conditions\" are both intervals of time and real-world things which seems awkward to me. I could separate the time intervals into new resources linked to the conditions with some kind of \"existed during\" predicate. This would complicate things a little, but perhaps not too greatly.\n\n\n### Approach 2: Named Graphs\n\nNamed graphs appear to partition the data very nicely. However it seems that they don't make the querying any simpler. If it were possible to define a merge of all possible graphs that cover the time interval of interest and query that directly then it could be possible to write very natural queries and completely ignore the time component. This could be possible with a two-phase approach to running the queries or perhaps SPARQL sub-queries might help.\n\nThe main problem with named graphs is that they lie outside of the standard RDF model. In fact they are only really formalised by the SPARQL specification. There are no standardised serialisations for named graph data so it is not generally possible to query a SPARQL service and retrieve the named graph information. The TRIG and TRIX serialisations do support named graphs but they are not widely implemented in comparison to RDF/XML, Turtle or Ntriples, none of which support anything beyond the standard RDF model. I don't know of any reasoners that can work across multiple named graphs like this either.\n\n### Approach 3: Reified Triples \n\nApproach 3 avoids the domain and range problem experienced by Approach 1 where the conditions were being used with properties whose domains were foaf:Agents. In Approach 3, properties are used with the appropriate resource types when they are timeless and never actually asserted when they are time-dependent. However, this approach is tedious for large quantities of data. The semantics are all locked away behind the reified triples. Once again I don't know of any reasoners that could work with this kind of data.\n\n\n### Approach 4: N-ary Relations\n\nin the examples shown here Approach 4 is identical to Approach 3 in complexity. In fact the key difference is the use of rdf:type rather than ex:property to distinguish the different types of relationships. In this respect it seems to offer no advantage over Approach 3 and adds the complexity of specific property names for each context relationship.\n\nHowever, it does potentially offer a wider use beyond simply recording time-varying properties. A context could include other factors such as provenance or location. Also it could be easier to model multi-agent contexts such as a marriages with predicates to represent the bride and groom separately.\n\n\n\n## References\n\n-   [Refactoring BIO with Einstein Part 1: First Steps](http://blog.iandavis.com/2005/04/refactoring-bio-with-einstein-part-1-first-steps) — my first post that touches on modelling of time in genealogy. At this point I was attempting to model it simply using an event model, i.e. a sequence of things that happen to people and places.\n-   [Refactoring BIO with Einstein Part 2: Conditions](http://blog.iandavis.com/2005/10/refactoring-bio-with-einstein-part-2-conditions) — this is the post in which I first introduced Conditions (i.e. Approach 1). The post uses almost exactly the same example as Scenario 1.\n-   [Refactoring Bio With Einstein Part 3: Temporal Invariants](http://blog.iandavis.com/2006/03/refactoring-bio-with-einstein-part-3-temporal-invariants) — in the third part of the series I explored those properties of a person that are timeless, or \"temporally invariant\".\n-   [Refactoring BIO with Einstein Part 4: Employment and Families](http://blog.iandavis.com/2006/03/refactoring-bio-with-einstein-part-4-employment-and-families) — in this post I continue the theme of part 2 and demonstrate how employment periods could be described using conditions and events that mark transitions between conditions.\n-   [Temporal Scope for RDF Triples](http://www.jenitennison.com/blog/node/101) — in this blog post Jeni Tennison describes her attempts to model time for the London Gazette data she is working with. She describes the reified approach (Approach 3) as unacceptable because most triple stores do not deal with reified data (i.e. don't allow you to query it in its un-reified form). She describes two acceptable approaches which are N-ary relationships (Approach 4) and named graphs (Approach 2) with a preference for the latter. Some useful comments point to other examples of these approaches.\n-   [RDF and the Time Dimension Part 1](http://oxforderewhon.wordpress.com/2008/11/28/rdf-and-the-time-dimension-part-1/) — in this post the author explains succinctly where the problem lies although the example used is flawed because it contains hidden context (i.e. \"August is a summer month...\" is not true in general and needs the context \"...for those in the Northern Hemisphere\", which can be modelled in RDF). The post also settles on named graphs as a solution but claims they cannot be used for continuous dimensions such as time (missing the solution of using something like OWL-Time to represent intervals and relative timings).\n-   [RDF and the Time Dimension Part 2](http://oxforderewhon.wordpress.com/2008/12/10/rdf-and-the-time-dimension-part-2/) — in this follow-up post the author proposes reifying statements and adding a new predicate to relate the reified statement to the context. (A hybrid of Approach 3 and Approach 4?). A second and preferred solution using named graphs is also presented. The author also demonstrates how to obtain a snapshot of all triples that held true at a specific time under both approaches (a \"snapshot\").\n-   [OWL Time](http://www.w3.org/TR/owl-time/) — an ontology of time concepts\n-   [Property Reification Vocabulary](http://esw.w3.org/topic/PropertyReificationVocabulary) — a proposal for mapping between reified properties and classes that represent the reifications (i.e. between Approach 3 and Approach 4)\n-   [Temporal RDF](http://www.dcc.uchile.cl/~cgutierr/papers/temporalRDF.pdf)\n-   [Music Ontology Events](http://motools.sourceforge.net/event/event.html)","n":0.031}}},{"i":6078,"$":{"0":{"v":"Representing Temporal Knowledge in the Semantic Web the Extended 4d Fluents Approach","n":0.289},"1":{"v":"\n- https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=113df74931c45355921ecfe27d3ebda1f9142005\n- authors: @sotiris-batsakis @euripedes-petrakis\n- related: [[ar.toql-temporal-ontology-querying-language]]\n- \n## Abstract\n\nRepresenting information that evolves in time in ontologies, as well as reasoning over static and dynamic ontologies are the areas of interest in this work. Building upon well established standards of the semantic Web and the 4D-fluents approach for representing the evolution of temporal information in ontologies, this work demonstrates how qualitative temporal relations that are common in natural language expressions (i.e., relations between time intervals like “before”, “after”, etc.) are represented in ontologies. Existing approaches allow for representations of temporal information, but do not support representation of qualitative relations and reasoning.\n\n## Highlights\n\n### Introduction\n\n- All approaches suffer from data redundancy as several objects are created for each binary relationship changing in time\n- ","n":0.091}}},{"i":6079,"$":{"0":{"v":"Representing Temporal Information in Lexical Linked Data","n":0.378},"1":{"v":"\n- https://aclanthology.org/2020.ldl-1.3.pdf\n- author: @anas-fahad-khan\n\n## Introduction\n\n- The difficulties of representing relationships that change with time – also referred to as fluents or diachronic rela- tions in the literature – in RDF have been by now well- rehearsed ( @christopher-welty et al., 2006)\n\n##  Temporal Information in Lexical Datasets\n\n- in previous related work we have looked at how to represent etymologies, viewed as hypotheses about word histories, explictly both in RDF (Khan, 2018) and in the Lexical Markup Framework (Khan and Bowers, 2020).\n- temporal information is not always explicitly included in the form of an etymology.\n- common for resources to list the senses in each lexical entry in some order of temporal precedence\n- Other resources in- clude descriptions of the semantic shift processes which led from temporally antecedent senses to subsequent senses;\n- others mark senses (or forms, etc) as obsolete and/or give some basic information on the time period in which a sense or form (or grammatical construct) was in use or was most commonly in use\n  - in fact, in these and in other contexts, one frequently finds reference to a particular historical stage of a language, such as Old French or Middle English, something which also helps to group together lexical phenomena in time.\n\n## \"Our approach\"\n\n- firstly, we propose the use of qualitative intervals to model temporal vagueness in lexical data;\n-  secondly, we define a ‘perdurantist’ version of certain classes in the ontolex-lemon model in order to allow lexical entries, senses, etc, to each have a ‘lifespan’ as well as temporal parts.\n-  there already exists a set of SWRL rules which allow for reasoning over data that describes intervals qualitatively using these relations (Batsakis et al., 2017)\n-  \n\n## Perdurantism v. Endurantism\n\ntopics: [[t.phil.perdurantism]] [[t.phil.endurantism]]\n\n- Perdurantism by treating people, animals, and things in general like processes, only parts of which exist at different times, has the clear shortcoming that it can be unintuitive and difficult to understand.\n  - countierintuitive\n  - helps to resolve a number of longstanding metaphysical conundrums relating to change over time.\n  - provides a very useful way of modelling vagueness\n  - able to meet several of the challenges raised against more traditional the- ories of time and change by the theory of special relativity (Effingham, 2012)\n- Note that although the names ‘three- dimensionalism’ and ‘four-dimensionalism’ might suggest that we are only dealing with ‘concrete’ objects, namely those that occupy a continuous physical portion of space, this is not in fact the case and perdurantism has in fact been applied to musical works (Caplan and Matheson, 2006) and institutional objects (Hansson Wahlberg, 2014)\n- Our proposal in this work is to apply it to language and linguistic phenomena.\n\n### non-liguistic Example: capitalCity of Italy\n\n- Turin from 1861 to 1865 (period t1), Florence from 1865 to 1871 (the period t2), and Rome from 1871 to the current day (the interval t3).\n- We define separate time slices (or temporal parts) TurinCapital, FlorenceCapital, RomeCapital of each of the Italian cities mentioned above, Turin, Florence, Rome respectively. Note that each of these time slices are also typed as cities, e.g., city(Turin) and city(TurinCapital)\n- We relate the temporal parts of these cities to- gether with their wholes using the property tem- poralPartOfwhich relates a perdurant together with another perdurant of which it is a temporal part, i.e., temporalPartOf(TurinCapital, Turin), temporalPartOf(FlorenceCapital, Florence), and temporalPartOf(RomeCapital, Rome)\n- Each of these timeslices is associated with its lifespan using the temporalExtent property which relates a perdurant together with the interval during which it exists, i.e., temporalExtent(TurinCapital, t1), temporalExtent(FlorenceCapital, t2), temporalExtent(RomeCapital, t3).\n- We also create time slices of Italy for each of these periods, Italyt1,Italyt2 and Italyt3 where: temporalExtent(Italyt1,t1),temporalExtent(Italyt2,t2), and temporalExtent(Italyt3,t3)\n- Finally we relate these timeslices of Italy using the capitalCity relation: capitalCity(TurinCapital,Italyt1), capitalCity(FlorenceCapital,Italyt2), capitalCity(RomeCapital,Italyt3)\n- This is a version of the kind of perdurantist approach initially proposed for RDF in (Welty et al., 2006);\n  - ? [[ar.a-reusable-ontology-for-fluents-in-owl]]\n  - our version is more directly based on (Krieger, 2014) [[ar.detailed-comparison-of-seven-approaches-for-the-annotation-of-time-dependent-factual-knowledge-in-rdf-and-owl]]\n  - HOWEVER, when it comes to creating diachronic versions of relationships between a lexical entry and its lexical senses and forms we can make a simplification: since the lifespan of a sense/form is necessarily contained in the lifespan of an entry, when it comes to perdurants versions of these classes, to define sense as holding between lexical entries and senses (and form as holding between lexical en- tries and forms) rather than timeslice of these, as in the case of capitalCity.\n\n### First Defintions\n\n- perdurantist sub-classes of the ontolex-lemon classes Lexical Entry, Lexical Sense, and Lexical Form; these are pLexical Entry, pLexical Sense, and pLexical Form\n- In order to define these classes we will make use of the new object property mentioned above, temporalExtent, whose range is the owl-time class time:Interval, and whose purpose is to relate a perdurant to its temporal dimension\n  - thereafter we impose the restriction that each member of the p-classes is related to exactly one time:Interval individual via the property temporalExtent\n\n### Girl\n\n- we start by defining the entry as a pLexicalEntry with an associated temporal extent (girl_time) and relating the entry with its forms using the (non-fluent) ontolex-lemon property lexicalForm\n\n```turtle\n:girl rdf:type :pLexicalEntry ;\n  :temporalExtent :girl_time;\n  ontolex:lexicalForm :garl_form ,\n    :garle_form ,\n    :geerl_form , ... .\n```\n- The first two forms which we will look at from the list given in Listing 7 are garl and girle, the first of which the OED tells us was in use during the Middle English period and the second of which was in use from the Middle English period through to the 15th century.\n- after we introduce them as elements of type pForm we thereafter associate them with a given temporal interval using the property temporalExtent. \n```turtle\n:garl_form rdf:type :pForm ;\n  ontolex:writtenRep \"garl\";\n  :temporalExtent :enm_interval .\n\n:girle_form rdf:type :pForm ;\n  ontolex:writtenRep \"girle\";\n  :temporalExtent :ME-16 .\n```\n\n- we have added a new datatype property hasUsageNote to our model; this allows for the encoding of geographical and dialectal constraints on the usage of a lexical element as free text.\n- we model the temporal interval associated with gurl_form as consisting of two separate temporal part: relating it to the interval enm_interval using interval- StartedBy and the interval 18- using intervalFinishedBy\n\n```turtle\ngurl_form a :pForm ;\n  :hasTemporalPart :gurl_form_IEN , :gurl_form_ME ;\n  :temporalExtent [\n    a owl-time:Interval;\n    owl-time:intervalStartedBy :enm_interval;\n    owl-time:intervalFinishedBy :18-;\n  ];\nontolex:writtenRep \"gurl\"@en .\n\n:gurl_form_ME a :pForm ;\n  :temporalExtent :enm_interval .\n\n:gurl_form_IEN a :pForm ;\n  :temporalExtent :18- ;\n  :hasUsageNote\n    \"chiefly Irish English and nonstandard\"@en .\n```\n\n- the entry for this sense also identifies a temporal part of this sense with a particular quality not shared by the whole: that of being limited to a certain geographically defined dialect (Irish English, or more precisely the dialect of Wexford)\n\n```turtle\n:girl ontolex:sense :sense_I1 ,\n    :sense_I1_irish_english .\n\n:sense_I1 a :pLexicalSense ;\n  :hasTemporalPart :sense_I1_irish_english ;\n  :temporalExtent :sense_I1_interval .\n\n:sense_I1_irish_english :pLexicalSense ;\n  :temporalExtent :sense_I1_irish_english_interval ;\n: hasUsageNote \"Irish English (Wexford)\"@en .\n```\n\n- then we use the temporal examples to enrich the representation of each sense\n\n```turtle\n:sense_I1_interval a owl-time:Interval ;\n  owl-time:hasEnd :present ;\n  owl-time:intervalFinishedBy\n\n:sense_I1_irish_english_interval;\n  owl-time:intervalContains\n    :a1475 , :circa_1300 , :year_1996 .\n\n:sense_I1_irish_english_interval a owl-time:Interval;\n  owl-time:intervalFinishes :sense_I1_interval ;\n  owl-time:intervalContains :a1827 .\n```\n\n\n### Modeling semantic shifts\n\n- given two lexical senses l_1, l_2 which have un- dergone a process of semantic shift of type s, to model the typed sense shift relationship semanticShift between them: semanticShift (l_1, l_2, s)\n- We can also choose to make this a fluent, a diachronic relationship and add a temporal parameter, i.e., semanticShift (l_1, l_2, s, t)\n  - decided not to\n  - We also introduce a new object property between senses senseShiftsTo which enables us to model the fact that one sense ‘gives birth to’ another","n":0.029}}},{"i":6080,"$":{"0":{"v":"Representing Organizational Structures in an Enterprise Architecture Language","n":0.354},"1":{"v":"\n- http://web.archive.org/web/20171115162404/http://ceur-ws.org/Vol-1333/fomi2014_2.pdf\n- @diorbert-pereira @joao-paulo-almeida\n\n\n## Abstract\n\nEnterprise Architecture (EA) promotes the establishment of a holistic view of the structure and way of working of an organization. One of the aspects covered in EA is associated with the organization’s “active structure”, which concerns “who” undertakes organizational activities. Several approaches have been proposed in order to provide a means for representing enterprise architectures, among which the ArchiMate, an EA modeling language. In this paper, we present a semantic analysis of the fragment of the ArchiMate metamodel related with the representation of active structure. In addition, we present a proposal to extend the metamodel based on a well-founded ontology for the organizational domain. Our objective is to enrich the language with important capabilities to represent organizational structures using a principled ontology-based approach.\n\n## Highlights\n\n### Introduction\n\n-  the description of an EA usually “takes the form of a comprehensive set of cohesive models that describe the structure and functions of an enterprise”\n-  majority of EA frameworks considers an organization as a system whose elements include: (i) organizational activities structured in business processes and services; (ii) information systems supporting organizational activities; (iii) underlying information technology (IT) infrastructures, and (iv) organizational structures (organizational actors, roles and organizational units)\n   -  This last domain of elements is also called “active structure” [2] and concerns “who” undertakes organizational activities.\n   -  Active structure focuses on the business agents that perform tasks and seek to achieve goals, encompassing the definition of business roles, authority relationships, communication lines, work groups, etc.\n   -   from the perspective of enterprise information systems, organizational actors can be considered as system owners, system maintainers, system users or simply system stakeholders in general, affecting the usage and evolution of such system","n":0.06}}},{"i":6081,"$":{"0":{"v":"Representing Narratives in Digital Libraries the Narrative Ontology","n":0.354},"1":{"v":"\n- https://www.semantic-web-journal.net/content/representing-narratives-digital-libraries-narrative-ontology-1\n- authors: @carlo-meghini @valentina-bartalesi @daniele-metilli\n- related: [[prdct.narrative-ontology-nont]] [[t.storytelling.narratology]]\n\n## Abstract\n\n- Digital Libraries (DLs), especially in the Cultural Heritage domain, are rich in narratives. Every digital object in a DL tells some kind of story, regardless of the medium, the genre, or the type of the object. However, DLs do not offer services about narratives, for example it is not possible to discover a narrative, to create one, or to compare two narratives. Certainly, DLs offer discovery functionalities over their contents, but these services merely address the objects that carry the narratives (e.g. books, images, audiovisual objects), without regard for the narratives themselves. The present work aims at introducing narratives as first-class citizens in DLs, by providing a formal expression of what a narrative is. In particular, this paper presents a conceptualization of the domain of narratives, and its specification through the Narrative Ontology (NOnt for short), expressed in first-order logic. NOnt has been implemented as an extension of three standard vocabularies, i.e. the CIDOC CRM, FRBRoo, and OWL Time, and using the SWRL rule language to express the axioms. An initial validation of NOnt has been performed in the context of the Mingei European project, in which the ontology has been applied to the representation of knowledge about Craft Heritage.\n\n## Highlights\n\n- formal narratives should not replace traditional, informal narrat- ives: rather, they should enhance them, by adding a formal dimension to the existing one.\n\n### Russian Formalists\n\n- According to the Russian formalists, a narrative consists of:\n  – the fabula, i.e., the story itself as it happened, in reality or in fiction;\n  – the narrations, i.e., one or more expressions, each in its own language and medium, that narrate the fabula. Each narration corresponds to Bal’s definition of presentation [4];\n  – the plot, i.e., the story as it is narrated by the narrator. The plot corresponds to the syuzhet of the Russian formalists and to Aristotle’s logos.\n    - @chatgpt.4o: \"the sjuzhet is the narrative structure, including flashbacks, flashforwards, and other non-linear storytelling techniques.\"\n- current digital libraries only contain the \"narration\" level.\n\n### The Proposal\n\n- \"we propose adding a formal expression of the fabula and the plot\"\n  - knowledge extraction methods from media\nobjects are central to our proposal - expressed in first-order logic, using [[prdct.swrl]] to express the axioms\n- On the basis of the ontology, we have developed the Narrative Building and Visualising (NBVT) tool [6], and applied it in four case studies.  \n  - [[prdct.story-map-building-and-visualising-tool-smbvt]]\n- includes predicates for representing qualitative temporal knowledge about the intervals of occurrence of events\n  - relies on Allen's 13 basic temporal relations (BTRs for short)\n    - Allen also provided transitivity rules that allow deriving implicit temporal relations from known ones, which can be expressed in SWRL\n    - the temporal relations between two intervals become exponentially many if disjunctions of BTRs are used to state temporal knowledge\n      - we were able to find a tractable subset of BTRs\n- @seymour-chatman: the elements of a story can be distinguished in: (i) characters, (ii) elements in the scenario.\n\n#### From Event Calculus\n\n- [[t.km.event-calculus]]\n\n### Fluent\n\n- a function or a predicate that varies over time, and is used to describe the effects of actions\n\n### Events\n\n- represent changes performed over time\n- In the EC, the terms Actions and Events are interchangeable\n- Davidson’s theory defines action as a particular subclass of event that is endowed with intentionality.\n\n#### Generalised Event\n\n- a space-time chunk which generalises concepts like actions, locations, times, and physical objects such as things, animals, agents, humans\n- @chatgpt.4o: composite events, parameterized events, continuous or ongoing events, abstract events\n\n#### Other Models\n\n- [[prdct.event-ontology]]\n- [[prdct.lode-ontology]]\n- [[prdct.event-model-f]]\n- [[prdct.simple-event-model-ontology]]\n\n- we chose the [[prdct.cidoc-crm]] as reference vocabulary for our ontology for narratives, and we took inspiration in particular from the LODE and SEM ontologies in order to represent the factual components of events\n\n### Conceptualization\n\n#### Narrative\n\n- a story told by and reflecting viewpoint of a narrator (indiv or group)\n  - stories have to be consistent with the axioms on physical reality that our ontology is able to capture. \n    - This excludes stories in which, for instance, effects precede causes, events nest circularly, or objects bilocate\n- consists of:\n  - fabula\n  - narrations: correspond to [[pub.question-log.2024.08.26.narratology#bals-definition-of-presentation]]\n  - reference: a relation that connects\n(fragments of) the narrations to (fragments\nof) the fabula, allowing the derivation of the\nplot (or syuzhet) of the narrative.\n\n\n#### Fabula\n\n- significant events of the story\n  - t.2024.08.26.13 but \"significance\" implies narrative viewpoint\n  - event: a group of coherent phenomena situated in space and time\n    - contextualised in terms of the entities that participate in it.\n      - in addition to space and time, the other entities that participate in the event can be identified as having persistent characteristics of structural nature.\n- the events in a fabula participate in three main relations\n  - **mereological**: connecting events to other events that include them as parts\n    - event composition relation is a strict partial order, i.e. it is an irreflexive and transitive relation over the fabula’s events; consequently, it is asymmetric, and more generally acyclic, so that no event is a sub- or super-event of itself or some other event.\n  - **temporal occurrence**: associating each event with a time interval during which the event occurs\n    - total function\n    - each pair of events is connected by one and only one Allen relation\n    - Each time interval has exactly one starting time point and one ending time point. \n      - Time points are connected to each other through before, after, or equals relations\n    - t.2024.08.26.13 seems potentially naive/overly rigid/digitally over-specified\n  - **causal dependecy**: relating pairs of events such that the occurrence of the former causes the occurrence of latter\n    - strict partial order\n      - acyclicity guarantees that no event is at the same time cause and effect of itself or some other event.\n  - In addition to the features of the individual relations in a fabula stated so far, the following conditions are met by every fabula:\n    1. The period of occurrence of an event is included in the period of occurrence of any of\n    its super-events.\n    2. The beginning of occurrence of an event precedes the beginning of occurrence of any event that causally depends on it.\n\n#### Narrations\n\n- a fabula may have any number of narrations, each of which has the obvious characteristic of being about the fabula\n  - aboutness is a notion of _representation_\n  - \"any narration of the fabula must somehow represent the fabula\"\n    - any proposition in the narration, whether explicitly or implicitly stated, must be true in the fabula.\n    - t.2024.08.26.13 again seems naive; narration can represent the narrator's feelings about the fabula\n- Each narration has one or more narrators, the authors of the narration, and of a narration content. \n  - the narration content is a message, and it may take any form in which a fabula can be communicated, ranging from text, to audio-visual message, to theatrical enactment, etc\n  - we are interested in narrations that have at least one digital representation\n    - whether that's the carrier of a non-digital or a born-digital\n  - the content will therefore be any media object, i.e. a text, an image, an audio-visual object, or any complex multimedia object that a particular narrator, or group of narrators, choose to tell their version of the fabula\n\n#### Reference\n\n- **reference**: a relation that connects regions of narrations, which we call narrative fragments (or simplify fragments), to events of the fabula\n  - Each fragment is maximal, in that it comprises all portions of the narration that narrate the same event.\n  - A fragment is identified in ways that depend on the structure of the narration. \n    - For instance, a textual fragment will be a set of disjoint intervals, each giving the boundaries of texts narrating the same event. \n  - A fragment that narrates an event necessarily narrates any of its super-events, and no other event.\n- Using the reference relation, it is possible to reconstruct the plot of the narrative, i.e. the sequence of fragments in the order established in the narration by the narrator.\n- Because a fabula is identified by its composing events, two narrations of the same fabula may differ for any combination of the following:\n  1. the set of events of the fabula narrated by the narrations; each narration may pick a different subset of events, as a way of giving more  emphasis to certain aspects of the story;\n  2. the order in which the selected events are narrated;\n  3. the expressions used for the narration.\n\n### Representing Narratives in Digital Libraries\n\n- While it is expected that a DL already possesses narrations in digital form, our work is motivated by the target of lifting such narrations into narratives, endowing them with a formal representation of the corresponding fabulae, acting as a semantical counterpart of those narrations\n  - t.2024.08.26.13 narration -> narrative means adding fabula and references\n- this two-level representation of the narrative allows supporting the union of the use cases supported by the purely syntactical (i.e. based solely on narrations) and the purely semantical (i.e. based solely on fabulae) representations\n- A narrative may be constructed in at least two\ndifferent ways:\n  - **formalisation**: starting from a narration and associating it to a fabula, or\n  - **documentation**: starting from a fabula and associating it to a narration of the fabula.\n- It must be noted that either the narration or the fabula of a narrative may provide an incomplete, or even inaccurate, account of the story that the narrative is about.\n  - t.2024.08.26.13 maybe not surprising, given that fabula means \"representation of the fabula\" at this point\n  - for this reason, the fabula of a narrative must be treated as a knowledge base, i.e., set of statements giving the best available approx- imation of the fabula according to the narrator of the narrative.\n- The relationship between the real fabula and its representation may be precisely characterised from a logical point of view as follows:\n  - A real fabula _f_ may be seen as a set of possible worlds, namely of the worlds that are compatible with the events in the fabula and the relationships that link these events to each other and to their factual components\n  - Let S<sub>f</sub> be the maximal set of formal fabula statements that are true in every world in f\n  -  Let k be a non-empty KB with the formal representation of _f_\n  -  Then,\n     -  k is an accurate representation of f iff every statement in k is true in the fabula, formally iff k |= S f , where |= is the logical implication relation\n     -  k is a complete representation of f iff k says everything about f, formally iff S f |= k.\n  -  the presence of different versions of the same story is not to be seen as accidental or undesirable in a DL\n     - the arising of logical contradictions in a KB is highly undesirable, because it makes the KB unusable\n- we view each narrative as a separate KB, and a DL as a set of narratives, possibly sharing a common set of factual components that occur in the fabulae of these narratives\n\n### The NOnt Ontology\n\n![](/assets/images/2024-08-26-16-26-58.png)\n\n- Narrations will be treated as “black boxes”, each represented by a different identifier and characterised as an instance of a special class.\n  - Such class will be an extension point of NOnt, in the sense that it is the part of the ontology where the classes and properties for representing narrations can be plugged, for example by drawing them from other standard ontologies.\n- Two parts:\n  - **NOntNar**: classes, properties and axioms for expressing individual narratives\n  - **NOntDL**: classes, properties and axioms for expressing the knowledge in the global KB of a DL\n\n#### Temporal reasoning in narratives\n\n- need a conceptualisation of time that supports both time points and intervals, and absolute and relative relations between them ^qqplujg84n9e\n- the relations between the time intervals in a narrative are maintained in a network, which will be called Qualitative Temporal Knowledge network (QTK for short)\n  - the nodes of a QTK represent the time intervals in the narrative, while the arcs represent relations between the intervals corresponding to the conjoined nodes. The arcs are labelled with non-empty sets of BTRs (basic temporal relations), and each such set represents the union of its member relations. \n  - In order to compute the restrictions (on relations between nodes), composition rules are used\n    - A composition rule is a statement about three intervals I, J and K. The statement has a premise and a conclusion as follows:\n      1. the premise gives a set of temporal relations between intervals I and J, and a set of temporal relations between intervals J and K;\n      2. the conclusion gives a set of temporal relations between intervals I and K.\n    - millions of composition rules, but\n    - the conclusions of the rules having non-singleton premises can be efficiently computed from those of the rules having singleton premises. \n    - issue: it may take an exponential amount of time to compute the QTK resulting from an update. ","n":0.022}}},{"i":6082,"$":{"0":{"v":"Representing Literary Characters and Their Attributes in an Ontology","n":0.333},"1":{"v":"\n- authors: @janna-hastings @stefan-shulz\n- topics: [[t.humanities.digital]] [[t.km.ontology]] [[t.storytelling.character]] [[prdct.basic-formal-ontology]]\n\n## Abstract\n\nThe digital humanities is a burgeoning field of research, bringing computational methods to literary investigations. Ontologies are computational structures that contain descriptions of entities and relations in a domain, and as such they form natural hubs for indexing, search and retrieval as well as enable sophisticated automated inferencing applications. Ontologies are widely used in the medical and biological domains, and are beginning to be adopted in other disciplines such as the social sciences. However, there are unique challenges with the adoption of ontologies for the representation of the elements of literary works. Literary meanings are subjective to some extent, and the ontological mode of being of fictional entities is different from that of the entities in the real world that are the subject matter of the sciences. We focus here on elucidating these challenges through the lens of fictional characters (such as, for example, Macbeth) and the social and personal attributes they are described as having (e.g. age and nationality). We develop a detailed representational strategy – a pattern – for representing fictional characters and their attributes in OWL, in applied ontologies.\n\n\n## Highlights\n\n### 1. Introduction\n\n- Ontologies and ontology- based terminologies and indexing vocabularies are widely used throughout the natural sciences, medical and engineering domains [2], but they have not yet seen adoption to the same extent in the social sciences and humanities. One of the possible reasons for this is that the types of entities and relations the social sciences and humanities deal with are more complex, controversial and open to subjective interpretations.\n- In this contribution, we attempt to address the question of how best to represent fictional entities and their attributes. We consider it undesirable to create a parallel hierarchy for fictional attributes which mirrors the hierarchy of attributes which real people can have and are the subject of ontologies in e.g. behavioural science (fictional age vs age as an attribute of people), but we also consider it undesirable to accidentally entail bizarre claims that cross over between the fictional and the real worlds.\n\n\n\n## References\n\n[^8]: [[ar.noctua-literaria-a-computer-aided-approach-for-the-formal-description-of-literary-characters-using-an-ontology]]","n":0.054}}},{"i":6083,"$":{"0":{"v":"Representing Classes as Property Values on the Semantic Web","n":0.333},"1":{"v":"\n- https://www.w3.org/TR/swbp-classes-as-values/\n- authors: @natasha-noy @michael-uschold @christopher-welty\n- topics: [[t.km.ontology.multi-level-theory]] [[t.cs.semantic-web.class.class-as-values]]\n- published-by: [[org.w3c.semantic-web-best-practices-working-group-swbp]]\n\n## Abstract\n\nThis document addresses the issue of using classes as property values in OWL and RDF Schema. It is often convenient to put a class (e.g., Animal) as a property value (e.g., topic or book subject) when building an ontology. While OWL Full and RDF Schema do not put any restriction on using classes as property values, in OWL DL and OWL Lite most properties cannot have classes as their values. We illustrate the direct approach for representing classes as property values in OWL-Full and RDF Schema. We present various alternative mechanisms for representing the required information in OWL DL and OWL Lite. For each approach, we discuss various considerations that the users should keep in mind when choosing the best approach for their purposes.\n\n## Highlights\n\n### Approach 1: Use classes directly as property values\n\n- The resulting ontology is compatible with RDF Schema and OWL Full, but it is outside OWL DL and OWL Lite.\n- This approach is probably the most succinct and intuitive among all the approaches proposed here.\n- Applications using this representation can directly access the information needed to infer that Lion (the subject of the LionsLifeInThePrideBook individual) is a subclass of Animal and that AfricanLion (the subject of the TheAfricanLionBook individual) is a subclass of Lion.\n- If we need to restrict the range of values for the dc:subject property, then we need to create an additional class for such a restriction. For instance, we may want to define a class of all books about animals—BookAboutAnimals—that our animal books will be instances of and we want to restrict the range of values for the dc:subject property for the BookAboutAnimals class to the class Animal and its subclasses. One way to define such restriction is as follows:\n\n```turtle\n:BookAboutAnimals\n      a       owl:Class ;\n      rdfs:subClassOf :Book ;\n      rdfs:subClassOf\n              [ a       owl:Class ;\n                owl:unionOf ([ a       owl:Restriction ;\n                               owl:onProperty dc:subject ;\n                               owl:hasValue Animal\n                             ] \n                             [ a       owl:Restriction ;\n                               owl:onProperty dc:subject ;\n                               owl:someValuesFrom\n                                    [ a       owl:Restriction ;\n                                      owl:onProperty rdfs:subClassOf;\n                                      owl:hasValue Animal \n                                    ]\n                          ])\n              ] .\n```\n\nSummary: this approach is a good one to use if you care about simplicity, do not have to be in OWL DL, and either do not need to limit the range of the dc:subject values or do not care that you also need to use classes as subjects to implement this restriction.\n\n### Approach 2: Create special instances of the class to be used as property values\n\nWe can treat the hierarchy of animal species as a hierarchy of subjects, create individuals corresponding to all the subjects and use these individuals as values for the dc:subject property (Figure 2).\n\n- The resulting ontology is compatible with RDF Schema and OWL Lite (and hence OWL DL)\n- The class Lion has an instance that is the subject lion. Creating an instance of the Lion class to represent a specific lion at the zoo would be inconsistent with this interpretation. Therefore, we will need to have a different class to represent  lions at the zoo. This change has important implications if the hierarchy of animals is not created by us, but we imported it from somewhere else. Applications will interpret the reference to imported classes according to their original definitions. Other ontologies importing the same hierarchy of animals will in fact use the original definition. Therefore, there may be inconsistency not only in our own interpretation but also when our ontology is integrated with others importing the same resource. This consideration is not a problem when interoperability is not an issue.\n- In this approach, there is no explicit direct relation (i.e., a relation that a general-purpose reasoner can readily identify) between the LionSubject individual defined above and, for example, an AfricanLionSubject individual, which is an instance of AfricanLion... An application trying to utilize this relation (for example, to extract books about African lions when asked for books about lions), will need to be aware of this specific approach and know to trace back to the corresponding classes, their subclasses, and respective instances. A general-purpose reasoner will not be able to use this information directly. Note however that the individual AfricanLionSubject is also an instance of the Lion class. Therefore, if we ask for all books where dc:subject is an instance of the Lion class we will get the books that are annotated with AfricanLionSubject.\n- There is a maintenance penalty: We need to maintain a set of instances for all subjects in addition to the hierarchy of subjects and ensure that the two sets—classes representing subjects and corresponding individuals—are consistent with each other (e.g., that they have the same names, etc.). However, developers can instrument tools that would maintain this consistency automatically.\n- Some may consider this approach to be \"too messy\" for the simple task at hand\n- Defining a range restriction for the dc:subject property for the class BookAboutAnimals is straightforward.\n\n![](/assets/images/2024-10-21-03-31-41.png)\n\n### Approach 3: Create a parallel hierarchy of instances as property values\n\n![](/assets/images/2024-10-21-03-32-10.png)\n\n- The resulting ontology is compatible with RDF Schema and OWL Lite (and hence OWL DL). However, note that RDF Schema does not have transitive properties, thus we will not be able to express the transitivity of the parentSubject property in RDF Schema.\n- Most DL reasoners will be able to infer transitive relations between subjects, such as the fact that AnimalSubject is a parentSubject of AfricanLionSubject. However, a DL reasoner will not be able to infer that a book that has LionSubject as the value for dc:subject is also about Animals. More specialized reasoners may be able to infer this information.\n- The resulting hierarchy of subjects is not related to or dependent on the class hierarchy representing the same topics (in this case, animals), except through an annotation property rdfs:seeAlso. Annotation properties however, are usually ignored by inference engines.\n- Some may consider the approach of having two parallel hierarchies representing essentially the same information to be too complicated and difficult to maintain for the simple task at hand\n- This approach explicitly separates the subject terminology from the corresponding ontology. Many consider this separation a good modeling practice: the semantics of a subject Lion can be different from the semantics of the class of lions. Having subjects in a separate hierarchy, would allow us to define for example that the subject Africa is a parent subject of the subject AfricanLion.\n- The separation of the subject terminology from the corresponding ontology incurs a serious maintenance penalty: We need to maintain a set of instances for all subjects in addition to the hierarchy of subjects. In many applications, we may also need to ensure that the two sets—classes representing subjects and corresponding individuals and values for the parentSubject property—are consistent with each other. However, developers can instrument tools that would maintain this consistency automatically.\n- Defining a range restriction for the dc:subject property for the class BookAboutAnimals is straightforward\n\nSummary: This approach may be a good one to use if staying within OWL DL is important. It also allows you to use a DL reasoner to infer transitive relationships between subjects. It does carry the penalty of having two parallel \"hierarchies.\"\n\n### Approach 4: Create a special restriction in lieu of using a specific value\n\nThis approach enables us to use a DL reasoner to infer, for example, that a book that has Lion as a subject also has Animal as its subject. In this approach, we create a new class to represent a class of all books with a particular subject. For example, we create a class BookAboutLions to represent all books that have Lion as one of their subjects. We then assign a subject to a specific book by making the book an instance of one of these classes, instead of explicitly setting a property value for the instance. Thus, for example the individual LionsLifeInThePrideBook will be an instance of the class BookAboutLions (Figure 4). We create similar classes for any subject category of books that we are interested in, such as BookAboutAnimals, BookAboutAfricanLions .\n\n![](/assets/images/2024-10-21-03-36-31.png)\n\nThis approach _approximates_ the interpretation that we used in the previous approaches by using unspecified members of a class rather than the class itself as property values.\n\nA DL reasoner will be able to classify LionsLifeInThePrideBook as an instance of the class BookAboutAnimals.\n\nNote that there a correspondence between the hierarchy of classes of books on specific subjects (such as BookAboutAnimals, BookAboutLions, and BookAboutAfricanLions) and the classes in the species hierarchy that we use as subjects (Animal, Lion, AfricanLion). The hierarchy of books essentially parallels the hierarchy of subjects, although it does not have to have a book class corresponding to each subjects—only the subjects that we are interested in. If the book classes are defined as above, a DL reasoner will be able to infer automatically the hierarchy of book classes, based on the hierarchy of subjects.\n\nA DL reasoner will be able to classify LionsLifeInThePrideBook as an instance of the class BookAboutAnimals.\n\nNote that there a correspondence between the hierarchy of classes of books on specific subjects (such as BookAboutAnimals, BookAboutLions, and BookAboutAfricanLions) and the classes in the species hierarchy that we use as subjects (Animal, Lion, AfricanLion). The hierarchy of books essentially parallels the hierarchy of subjects, although it does not have to have a book class corresponding to each subjects—only the subjects that we are interested in. If the book classes are defined as above, a DL reasoner will be able to infer automatically the hierarchy of book classes, based on the hierarchy of subjects.\n\nThere is a variant to this approach in which we merge the two steps into one. Instead of creating an explicit named class, BookAboutLions, and then creating an instance of this class, we create the instance and assign its type to be an anonymous class of type owl:Restriction. In this variant, there is no explicitly named class corresponding to BookAboutLions\n\n#### Considerations for approach 4\n\n- \n- The resulting ontology is compatible with OWL DL. Since this approach uses restrictions, which do not have any semantics in RDF Schema, we cannot use this approach for RDF Schema.\n- The interpretation of this pattern is different from interpretations of the other patterns in this note: the subject of the book is one or more specific lions—individuals in the Lion class—rather than the Lion class itself . In this case, a book about lions is a book about some lions, even if that happens to be all lions.\n- A Description Logic reasoner will be able to classify automatically the individual LionsLifeInThePrideBook that has an instance of a Lion class as its subject as an instance of both the class BookAboutLions and BookAboutAnimals. It will also be able to classify the class BookAboutLions defined above as a subclass of the class BookAboutAnimals (defined in a similar way).\n- This approach is likely to be the easiest approach to use if you would like to employ DL reasoning to classify books based on their subjects.\n- Many would consider it more cumbersome to express a simple fact that the subject of a book is \"lions\" by creating a new (usually, anonymous) restriction class and making that class to be the type of the book.\n\nSummary: This approach can make the most use of DL reasoners. It represents a different interpretation of the subject as being a prototypical instance of a class rather than a whole class of things or a specific subject corresponding to that class. With the understanding that you are using a different interpretation, this approach may be a good one to use if using DL reasoners to classify individuals based on their subjects (or another property used in its place) is important.\n\n\n### Approach 5: Use classes directly as annotation property values\n\n![](/assets/images/2024-10-21-03-51-14.png)\n\n\n\n- In OWL DL, annotation properties cannot at the same time be defined either object properties or datatype properties. Thus, if dc:subject (or another property you want to use) is defined elsewhere as an object property or a datatype property, it cannot be used as an annotation property.\n- In OWL DL, annotation properties cannot have any restrictions, such as cardinality or domain/range restrictions, or subproperties. Thus, if you use this approach, you cannot specify that each book should have at least one subject for example or that individuals that are instances of BookAboutAnimals must all be subclasses of the Animal class.\n- Even if the ontology is in OWL DL (i.e., the annotation properties are used consistent with OWL DL restrictions), DL reasoners will not use the information in annotation properties for reasoning. Thus, in order to extract a book about lions when queried for animal books, one would need to use special-purpose reasoning that uses annotation properties and can perform reasoning with them.\n\nSummary: This approach allows you to use classes directly as property values while staying in OWL DL. However, the properties that will have classes as values will have to be defined as annotations and therefore cannot have any additional restrictions defined on them (and should not be declared as object or datatype properties elsewhere). DL reasoners will not use values of annotation properties.","n":0.022}}},{"i":6084,"$":{"0":{"v":"Representing a Reference Foundational Ontology of Events in Sroiq","n":0.333},"1":{"v":"\n- https://content.iospress.com/download/applied-ontology/ao190214?id=applied-ontology%2Fao190214\n- topics: [[prdct.alloy-specification-language]] [[prdct.sroiq]] [[prdct.unified-foundational-ontology.ufo-b]]\n\n## Abstract\n\n- In recent years, there has been a growing interest in the application of foundational ontologies, i.e., formal ontological theories in the philosophical sense, to provide a theoretically sound foundation for improving the theory and practice of conceptual modeling and knowledge representation. This paper addresses one particular foundational theory of events termed UFO-B, which has been successfully employed as a reference model for addressing problems from complex media management, enterprise architecture, software engineering, and modeling of events in petroleum exploration. Despite its success, there is still no formalization of UFO-B in a decidable knowledge representation language that could support reasoning about complex events and event relations. We address this gap by proposing a number of alternative translations from UFO-B’s original axiomatization (in first-order logic and in the Alloy formal language) to the description logic SROIQ, which is the formal underpinning of OWL 2 DL. Additionally, to support practical applications, we translated these SROIQ theories to OWL 2 DL TBoxes, which were validated by showing that all the intended models of UFO-B (the logical models of the UFO-B specification in Alloy) that we generated are consistent with these UFO-B TBoxes. In a sense, the specification in Alloy implements the specification in first-order logic, while the OWL 2 TBoxes implement the SROIQ specifications. Incidentally, the methodology that we designed for the translation from UFO-B’s original axiomatization in FOL and Alloy to SROIQ came to be a key contribution of this work by providing us evidence of the inadequacy of DLs for the specification of comprehensive foundational ontologies.\n\n## Highlights\n\n- the expressive power of OWL-like languages is rather restricted and too limited for expressing relational aspects of formal ontology as well as aspects that go beyond what can be formulated as a classification problem (Bittner and Donnelly, 2007).\n- it is widely believed that the language of first order predicate logic is sufficiently powerful for formalizing formal ontologies (Smith, 2003). This may be true. The aim of this paper is it, however, to make the case that for the development, the presentation, and the computer-assisted verification of formal ontologies the usage of higher-order languages and associated tools is highly beneficial.\n- uses Isabelle/HOL/Isar (Paulson and Nipkow, 2017; Paulson, 1994; Nipkow, 2003) \n  - [[prdct.hol]] ","n":0.052}}},{"i":6085,"$":{"0":{"v":"Representation and Querying of Valid Time of Triples in Linked Geospatial Data","n":0.289},"1":{"v":"\n- https://strabon.di.uoa.gr/files/eswc2013.pdf\n\n## Abstract\n\nWe introduce the temporal component of the stRDF data model and the stSPARQL query language, which have been recently proposed for the representation and querying of linked geospatial data that changes over time. With this temporal component in place, stSPARQL becomes a very expressive query language for linked geospatial data, go- ing beyond the recent OGC standard GeoSPARQL, which has no support for valid time of triples. We present the implementation of the stSPARQL temporal component in the system Strabon, and study its performance experimentally. Strabon is shown to outperform all the systems it has been compared with.\n\n\n## Highlights\n\n-  Gutierrez et al. [8, 9] were the first to propose a formal extension of the RDF data model with valid time support. They also introduce the concept of anonymous timestamps in general temporal RDF graphs, i.e., graphs containing quads of the form (s, p, o)[t] where t is a timestamp or an anonymous timestamp x stating that the triple (s, p, o) is valid in some unknown time point x\n-  the version of the system Strabon presented in [14], which implements stRDF and stSPARQL, does not implement the temporal dimension of this data model and query language. In this paper we remedy this situation by introducing all the details of the temporal dimension of stRDF and stSPARQL and implementing it in Strabon.\n-  With the temporal dimension presented in this paper, stSPARQL also becomes more expressive than the recent OGC standard [[prdct.sparql.geosparql]]\n-  we evaluate the performance of our implementation on two large real-world datasets and compare it to three other implementations: (i) a naive implementation based on the native store of Sesame [[prdct.rdf4j]] which we extended with valid time support, (ii) [[prdct.allegrograph]], which, although it does not offer support for valid time of triples explicitly, it allows the definition of time instants and intervals and their location on a time line together with a rich set of func- tions for writing user queries, and (iii) the Prolog-based implementation of the query language AnQL, which is the only available implementation with explicit support for valid time of triples. Our results show that Strabon outperforms all other implementations.\n-  values of the datatype strdf:period can be used as objects of a triple to represent user-defined time. In addition, they can be used to represent valid times of temporal triples which are defined as follows.\n   -  A temporal triple (quad) is an expression of the form s p o t. where s p o. is an RDF triple and t is a time instant or a time period called the valid time of a triple. An stRDF graph is a set of triples and temporal triples. In other words, some triples in an stRDF graph might not be associated with a valid time.\n-  we do not have support (yet) for quantitative temporal constraints in queries (e.g., T1 − T2 ≤ 5).\n","n":0.046}}},{"i":6086,"$":{"0":{"v":"Reification and Truthmaking Patterns","n":0.5},"1":{"v":"\n- http://www.inf.ufes.br/~gguizzardi/ER2018-Truthmaking.pdf\n- keywords: [[t.cs.sd.modeling.conceptual-modeling.ontology-driven]] [[prdct.ontouml]] [[prdct.dolce]] [[prdct.unified-foundational-ontology]]\n\n## Abstract\n\n- Reification is a standard technique in conceptual modeling, which consists of including in the domain of discourse entities that may otherwise be hidden or implicit. However, deciding what should be reified is not always easy. Recent work on formal ontology offers us a simple answer: put in the domain of discourse those entities that are responsible for the (alleged) truth of our propositions. These are called truthmakers. Re-visiting previous work, we propose in this paper a systematic analysis of truthmaking patterns for properties and relations based on the ontological nature of their truthmakers. Truthmaking patterns will be presented as generalization of reification patterns, accounting for the fact that, in some cases, we do not reify a property or a relationship directly, but we rather reify its truthmakers.\n\n## Highlights\n\n- strong view: events\n- weak view: qualities\n\n### Search for TMs\n\n-  our cognitive domain is much bigger than our domain of discourse\n   - e.g., when we say that John and Mary are married, our language only refers to them, although we know that there has been a wedding event and that there is an ongoing marriage relationship. It is up to us to introduce these further entities in our domain of discourse, should we need to represent and reason about them. \n   - Such process of making hidden entities explicit is called reification. ^r9mf84mrcvyu\n     - Note that the new entities do not originate from a generic decision to expand the domain, but rather from a transformation of a language construct (typically, a predicate) into a domain element (a “first class citizen”).\n - the basic questions we need to ask to analyze a proposition P are similar to the famous Wh-questions: What is responsible for making P true? When and Where will P be true? \n\n### Properties and Their Truthmakers\n\n-  only propositions have TMs (they are the only truthbearers) but we shall talk interchangeably of TMs of properties or relations (holding for certain entities), and TMs of propositions\n-  take e.g. \"a is a rose\" vs \"a is red\"\n   -  Strong TM: \"existence\" (non-descriptive) and \"a particular occurrence of redness, that is, a particular event (intended in the most general sense that includes states)\" (descriptive)\n- non-descriptive properties account for\nwhat something is, on the basis of its nature and structure; descriptive properties\naccount for how something is, on the basis of its qualities.\n- Weak TM makes a proposition true not just because of its existence (i.e., because of its essential nature), but because of the way it contingently is (i.e., because of its actual nature).\n  - e.g. Suppose that a is red at time t1, and becomes brown at time t2. \n    - According to the mainstream TM theory, the strong TM of a is brown at t2 will be very different from that of a is red at t1 (i.e., 2 strong TMs)\n    - Parsons: the weak TM at both times is the rose itself: since the rose changes while keeping its identity, it is the very same rose, in virtue of the way it (contingently) is at t1 and at t2 (i.e., 1 weak TM)\n\n#### Individual qualities, descriptive properties, intrinsic properties\n\n##### Individual qualities\n\n- This color is modeled as an individual quality in [[prdct.dolce]] and in [[prdct.unified-foundational-ontology]].\n- qualities inhere in things, where inherence is a special kind of existential dependence relation, which is irreflexive, asymmetric, anti-transitive and functional\n- They are directly comparable, while objects and events can be compared only with respect to a certain quality kind (e.g., to compare physical objects, one resorts to the comparison of their shapes, sizes, weights, and so on\n-  Qualities are distinct from their values (a.k.a. qualia), which are abstract entities representing what exactly resembling qualities have in common, and are organized in spaces called quality spaces; each quality kind has its own quality space\n   -  e.g. weight is a quality kind, whose qualia form a linear quality space\n      -  t.2024.07.14.17 maybe quantitave weight; \n-  quality spaces may have a complex structure with multiple dimensions, each corresponding to a simple quality that inheres in a complex quality.\n   -  typical example:  colors and taste\n   -  but also mental entities such as attitudes, intentions and beliefs as complex qualities, collapsing, for the sake of simplicity, UFO’s distinction between qualities and modes\n      -  t.2024.07.26.09 qualities are descriptive, so I guess intentions could be descriptive, but couldn't you say \"having an intent is non-descriptive since it holds in virtue of the object that has the intent\"\n-  relational qualities are existentially dependent on the thing they inhere in, but also something else, e.g. John's love for Mary\n   -  typical come in bundles called relators\n-  summary: individual qualities are weak TMs for descriptive properties\n  - note:  looking for qualities as minimal weak TMs has a clear advantage over looking for strong TMs: while negative truths are notoriously a problem for the strong truthmaking view, so that it is difficult to individuate the strong TM of *a is not red*, it is immediate to see that its minimal weak TM is its color, and not, say, its weight.\n  \n##### descriptive properties\n\n- we may define them as properties holding in virtue of one or more inhering qualities\n  - seems plausible to assume that a descriptive property may hold for an object x in virtue of a quality inhering in a proper part of x, rather than in x itself\n    - So, having a big nose counts as descriptive since it holds in virtue of the nose’s size, while having a nose is non-descriptive since it holds in virtue of the object that has the nose, which is not a quality.\n  - we should account also for descriptive properties that hold in virtue of relational qualities. \n  - 3 possibilities:\n    - the weak TM consists of just one rela-\ntional quality inhering in John, as in the case of being in love with Mary;\n    - the truthmaking qualities are distributed between John and an external entity. This is the case of being married with Mary, which presupposes the existence of commitments and obligations (and possibly love) inhering in Mary and depending on John, as well as reciprocal ones inhering in John\n    -  there is only one truthmaking quality inhering in something external to John, and existentially depending on it. This is the case of so-called Cambridge properties [5], like being loved by Mary.\n- To include the last two cases, we refine our definition as follows: a property P is descriptive iff, for every x, P(x) holds in virtue of (at least) a quality q being existentially dependent on x.\n\n##### intrinsic properties\n\n-  a property holding for x is extrinsic iff it requires the existence of something else external to x in order to hold\n-  Being red and being married are examples of, respectively, intrinsic descriptive and extrinsic descriptive properties\n  - In the former case the minimal weak TM is a non-relational quality\n    - t.2024.07.26.09 why non-relational? only if red isn't \"something else\"\n  -  in the latter it is a relational quality\n-  The intrinsic/extrinsic distinction turns out to be orthogonal to the descriptive/non-descriptive one, and each of the four combinations has its own peculiarities in terms of TMs\n   -  e.g. \n      -  Being red and being married are examples of, respectively, intrinsic descriptive and extrinsic descriptive properties.\n         -  In the former case the minimal weak TM is a non-relational quality\n         -  in the latter it is a relational quality. \n      -  Being an apple or having a nose are examples of intrinsic non-descriptive properties, whose argument coincides with the minimal weak TM\n      -  being Italian is an extrinsic non-descriptive \"historical\" property, with minimal weak TM of a birth event.\n-  \n\n#### Truthmaking patterns for properties\n\n- no reification is necessary for intrinsic non-descriptive properties (their weak TM being already present in the domain of discourse)\n- extrinsic descriptive properties is very similar to that of external descriptive relations \n- three broad classes of TMP:\n  - partial TMPs\n    - strong partial\n    - weak partial\n  - full TMPs, including both strong and weak TMs as well as the relationship between them\n\n##### Intrinsic descriptive properties\n\n- rarely correspond to classes, because they do not carry a principle of identity\n  - e.g. a rose's redness is typically expressed as a attribute-value pair within the class Rose, where the attribute name implicitly de- notes the color quality\n\n![](/assets/images/2024-07-14-21-22-28.png)\n\n- We have three reification options, corresponding to different TMPs:\n  - A weak TMP emerges when the quality is reified as a separate class\n    - Note the 1-1 cardinality constraint, showing that a quality in- heres in exactly one object, and an object has exactly one quality of a given kind\n      - t.2024.07.26.09 but what if the rose is partially brown?\n    - generally more flexible, making it possible\nto describe the way the quality interacts with the world (Mary likes the color of\nthis rose), or further information about the quality itself (the color of a rose is\nlocated in its corolla)\n  - a strong TMP emerges when the event of a \"color occurrence\" emerges  \n    - necessary when we need to\naccount for temporal information (e.g., how long the redness lasted), or for the\nspatiotemporal context (what happened meanwhile and where...\n  - a full TMP, including both strong and weak TMs plus the relationship among them\n    - maximum expressivitiy\n- events can be seen as manifestations of qualities, and qualities as the focus of events.\n\n##### Extrinsic non-descriptive properties\n\n- For those of them that are anti-rigid, it certainly makes sense to reify the event during which they hold, i.e., their strong TM. \n  - example: \n![](/assets/images/2024-07-15-09-56-03.png)\n    - t.2024.07.26.10 the labels for b and c are mixed up. \n\n##### Intrinsic non-descriptive properties\n\n- [ ] exercise for the reader\n\n##### Extrinsic descriptive\n\n- [ ] exercise for the reader\n\n\n## Relations and their TMs\n\n- In his early work, Guizzardi borrowed from [16] a crisp distinction between formal and material relations \n  - formal are holding between two or more entities “directly without any further intervening individual\"\n  - ;atter requiring the existence of an intervening individual\n  - t.2024.07.26.10 reminds me of [[ar.github.nemo-ufes.gufo.are-all-relations-instances-of-either-material-relationship-type-or-comparative-relationship-type]]","n":0.025}}},{"i":6087,"$":{"0":{"v":"Reducing Accidental Complexity in Domain Models","n":0.408},"1":{"v":"\n- https://www.researchgate.net/publication/225173448_Reducing_accidental_complexity_in_domain_models\n- published: 2008","n":0.5}}},{"i":6088,"$":{"0":{"v":"Reconceptualizing Superwork for Improved Access to Popular Cultural Objects","n":0.333},"1":{"v":"\n- https://cpb-us-e1.wpmucdn.com/sites.uw.edu/dist/2/3760/files/2019/09/Reconceptualizing-Superwork-for-Improved-Access.pdf\n\n- topics: [[t.library-science.superwork]] [[sh.t.multiverse]]\n\n## Highlights\n\n- several researchers such\nas Carlyle (1996), Svenonius (2000), Antelman (2004), Smiraglia (2007), Kemp (2008), and Smiraglia et al. (2014) have discussed this concept. Similar or relevant concepts also exist in current bibliographic standards such as [[prdct.frbr]], FRBROO, and BIBFRAME 2.0. \n  - Smiraglia (2007) states that the notion of the superwork describes “the abstract intellectual concept of a given work that is the principle node around which all iterations of that work may be collocated”\n  - Antelman (2004) and Kemp (2008) have used the term in the context of overarching super-serials that span across all of the title changes that a serialized work might have undergone during the timeline of its publication\n    - Example: Dr. Strange, a work which begins as part of Marvel Comics’ science-fiction/horror anthology Strange Tales (in issue #110), eventually expanding to the point of being the whole of the content of Strange Tales (by issue #169), before being renamed as Dr. Strange (also issue #169)\n      -  a superwork in this sense would encompass some of Strange Tales and all of Dr. Strange\n-  [[prdct.frbroo]] provides a rich set of tools with which the bibliographic universe can be modelled\n   -  e.g. F15 Complex Work\n      -  t.2024.08.22.10 now part of [[prdct.pressoo]]\n      -  While the term complex work does not evoke the grand scope that a term like superwork does, the definition, scoping notes, and examples provided in the FRBROO document seem to, at first, closely align to the definition of superwork and scope of the examples provided later in this paper\n      -  it does not seem as though works that are not intended by the creators to be part of one another... are to be modelled using the complex work entity mode\n-  [[prdct.bibframe]] hasDerivative and derivativeOf\nproperties\n- we define superwork as an aggregate entity related by:\n  - their origins (i.e., derivative works from some ur-work), or\n  - shared characteristics, such as theme, characters and world/universe.\n\n### Properties/Characteristics of Superwork\n\n- hasMember: A Superwork is a kind of aggregate.\n  - At the very least they stand in a “hasPart” mereological relationship with the individual works that they are made of. \n  - More specifically, the individual works that make up a superwork stand in a mereonymic relationship with the superwork. \n  - If one models a superwork as the kind of thing that derives its identity from the works that compose it, then this narrower relationship is membership\n  -  If one models a superwork as the kind of thing that is constituted of the works that compose it, then this relationship is constitution.\n  -  If one believes that the works that compose a superwork are brought together through curatorial intervention, then the relationship is the much narrower gathered-into relationship and superworks are identical to bibliographic collections.\n-  includesFormat: A Superwork encompasses multiple works in multiple formats related to one another in a multitude of complex ways\n   - t.2024.08.22.11 disagree\n   - items in a superwork aggregation are related to one another beyond the curatorial sense of membership or the editorial sense of arrange- ment (i.e., they are not the same as collections or series\n - hasCreator: A Superwork will frequently contain works by several (and sometimes hundreds of) authors.\n   - it is possible for a superwork to emerge based on works by a single author\n - hasTheme: A Superwork is aggregated around some theme or group of closely related themes.\n   - shared fictional universes\n   - brands\n   - topics\n\n### Challenges\n\n#### Superworks as (non-)Bibliographic Entities\n\n- Reconceptualizing superwork as an aggregation that primarily reflects something that users believe to be true about the bibliographic universe is a useful goal\n- better conceptualized as a kind of super-topic? (as opposed to a bibliographic aggregate)\n  - \"After all, existing cataloging practices and digital information systems have well-developed senses of topical, genre-based, and agent-based access points\"\n    - While these access points suffice for querying a catalog system we found that they lacked the essential conceptual substance that differentiates bibliographic aggregations from mere search query results— **conceptual mass**\n- An alternative is to represent the superwork entity as an abstract entity to which multiple relevant works belong (akin to FRBR Group 1 entities). A benefit here would be a more straightforward collocation of these works under the superwork entity rather than users having to access the network of works that may be grouped under a shared concept, place, and other elements. \n\n\n#### Superworks as Bibliographic Aggregates\n\n- the items in a superwork do not seem to be grouped together through the curatorial process of selection. Therefore, it does not seem to be the case that superworks are the same kind of aggregation as a collection.\n\n#### Specialized Relationships among Superwork Members\n\n##### Conceptualizing Crossover superworks\n\n- the mixed presence of characters from two different superworks in a crossover superwork made it feel unnatural to categorize the crossover superwork under one or the other superworks from which the characters originate.\n  - t.2024.08.22.12 should be both... categories does kinda imply exclusive, but probably should be modelled as a mixin (RoleMixin)\n\n## Conclusion\n\n","n":0.035}}},{"i":6089,"$":{"0":{"v":"Reality of Group Agents","n":0.5},"1":{"v":"\n- url: https://www.princeton.edu/~ppettit/papers/2009/Reality%20of%20Group%20Agents.pdf","n":0.577}}},{"i":6090,"$":{"0":{"v":"Real Time Multiplayer Colyseus Tutorial","n":0.447},"1":{"v":"\n\n- [[p.hasURL]] https://developer.playcanvas.com/en/tutorials/real-time-multiplayer-colyseus/ ","n":0.577}}},{"i":6091,"$":{"0":{"v":"Rdf for Temporal Data Management a Survey","n":0.378}}},{"i":6092,"$":{"0":{"v":"Py Graft Configurable Generation of Synthetic Schemas and Knowledge Graphs at Your Fingertips","n":0.277},"1":{"v":"\n\n- https://arxiv.org/pdf/2309.03685.pdf\n- topics: [[t.km.knowledge-graph]] [[t.cs.semantic-web]] [[prdct.pygraft]]\n\n## Abstract\n\n- Knowledge graphs (KGs) have emerged as a prominent data\nrepresentation and management paradigm. Being usually underpinned\nby a schema (e.g., an ontology), KGs capture not only factual informa-\ntion but also contextual knowledge. In some tasks, a few KGs established\nthemselves as standard benchmarks. However, recent works outline that\nrelying on a limited collection of datasets is not sufficient to assess the\ngeneralization capability of an approach. In some data-sensitive fields\nsuch as education or medicine, access to public datasets is even more\nlimited. To remedy the aforementioned issues, we release PyGraft, a\nPython-based tool that generates highly customized, domain-agnostic\nschemas and KGs. The synthesized schemas encompass various RDFS\nand OWL constructs, while the synthesized KGs emulate the character-\nistics and scale of real-world KGs. Logical consistency of the generated\nresources is ultimately ensured by running a description logic (DL) rea-\nsoner. By providing a way of generating both a schema and KG in a\nsingle pipeline, PyGraft’s aim is to empower the generation of a more\ndiverse array of KGs for benchmarking novel approaches in areas such\nas graph-based machine learning (ML), or more generally KG process-\ning. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby\ngoing beyond the limited collection of available benchmarks. PyGraft is\navailable at: https://github.com/nicolas-hbt/pygraft","n":0.07}}},{"i":6093,"$":{"0":{"v":"Psyche","n":1},"1":{"v":"\n\n\n\n- [[p.hasSisterPublication]] [[ar.aeon]]\n- [[p.publishedBy]] [[org.aeon-media]]\n","n":0.447}}},{"i":6094,"$":{"0":{"v":"How to Maintain a Healthy Brain to Reduce the Risk of Dementia","n":0.289},"1":{"v":"\n\n\n- [[p.hasURL]] https://psyche.co/guides/how-to-maintain-a-healthy-brain-to-reduce-the-risk-of-dementia\n## Highlights\n\n- develop cognitive reserve\n  - conditions: novelty, diversity, repeated practice, complexity, progression of complexity\n- memory optimization techniques\n  - peg method\n    - choose pegs, eg. gun, a shoe, a tree and a door\n    - entwine the things you have to do\n      - make it memorable, e.g. funny\n  - Memory Palace (Method of Loci)\n    - highly familiar places\n    - e.g. locations similar to pegs\n- recommendations\n  - socialize\n  - Foods to include:\n    -   Green leafy vegetables and other preferably non-starchy vegetables\n    -   Spices and herbs\n    -   Legumes and beans\n    -   Wholegrains\n    -   Cold-water fish – salmon, tuna, sardines and the like\n    -   Olive oil\n    -   Poultry\n    -   Nuts and seeds\n    -   Berries\n  - Foods to be wary of:\n    -   Processed and sugary foods\n    -   Dairy and red meat\n","n":0.088}}},{"i":6095,"$":{"0":{"v":"Programming Jade and Jason Agents Based on Social Relationships Using a Uniform Approach","n":0.277},"1":{"v":"\n- url: https://www.lancaster.ac.uk/~chopraak/mfsc-2015/baldoni.pdf\n- topic: [[prdct.Jade]] [[prdct.jason]]\n\n## Abstract\n\n2COMM as a framework for defining social relations among parties, represented by social commitments. Starting from the definition of interaction protocols, 2COMM allows to decouple interaction design from agent design, an advantage that simplifies agent programming, in- dependently of the chosen agent platform. A comparison between real implementations using 2COMM is provided for JADE and Jason agents.\n\n\n## Highlights\n\n- In order to reify the social relationships we rely on the [[Agents & Artifacts meta-model (A&A)|prdct.agents-and-artifacts-metamodel]] \n\n### Modeling Social Relationships\n\n- We propose to explicitly represent social relationships among the agents. By social relationships we mean normatively defined relationships, between two or more agents, resulting from the enactment of roles, and subject to social control. Thus, we encode social relationships as commitments. A commitment [19] is rep- resented with the notation C(x, y, r, p), capturing that the agent x commits to the agent y to bring about the consequent condition p when the antecedent con- dition r holds. Antecedent and consequent conditions generally are conjunctions or disjunctions of events and commitments. When r equals >, we use the short notation C(x, y, p) and the commitment is said to be active. Commitments have a regulative nature, in that debtors are expected to behave so as to satisfy the engagements they have taken. This practically means that an agent is expected to behave so as to achieve the consequent conditions of the active commitments of which it is the debtor.\n\n- it's necessary to provide the agents the means to create, to manipu- late, to observe, to monitor, to reason, and to deliberate on social relationships. We do so by exploiting properly defined artifacts, that reify both interaction pro- tocols, defined in terms of social relationships, and the sets of social relationships, that are created during the protocols execution, available to agents as resources\n\n  -  The semantics of the social actions is given in terms of commitment operations (as usual for commitments, create, cancel, release, discharge, assign, and delegate).\n-  From an organizational perspective, a protocol is structured into a set of\n\n\n## References\n\n- [[ar.agents-and-artifacts-a-meta-model-for-agent-oriented-computing]]\n\nWe assume that roles cannot live autonomously: they exists","n":0.053}}},{"i":6096,"$":{"0":{"v":"Processes as Variable Embodiments","n":0.5},"1":{"v":"\n- https://link.springer.com/article/10.1007/s11229-024-04505-2\n- authors: @nicola-guarino @giancarlo-guizzardi\n\n## Abstract\n\nIn a number of papers, @kit-fine introduced a theory of embodiment which distinguishes between rigid and variable embodiments, and has been successfully applied to clarify the ontological nature of entities whose parts may or may not vary in time. In particular, he has applied this theory to describe a process such as the erosion of a cliff, which would be a variable embodiment whose manifestations are the different states of erosion of the cliff. We find this theory very powerful, and especially appropriate to capture the intuition that the same process may go on at different times. However, its formal principles have been subject to some criticisms, mainly concerning the mereological structure of a variable embodiment. Moreover, since the notion of variable embodiment is very general, simply saying that processes are variable embodiments is not enough to understand their ontological nature. To address these concerns, in this paper we proceed in two phases: first, we propose a revised version of Fine’s original theory adapted to the case of processes, which adopts a classical mereology instead of Fine’s hylomorphic mereology, and a temporalized constitution relation in place of Fine’s function of variable embodiment; second, we go deeper into the ontological nature of processes by revisiting the notions of homogeneity, intentionality, and telicity discussed in the literature, and propose an account based on ontological principles and not on semantic properties of predicates. This allows us to organize processes into a novel taxonomy based exclusively on their unity and individuation principles","n":0.063}}},{"i":6097,"$":{"0":{"v":"Process and Causality","n":0.577},"1":{"v":"\n- http://www.jfsowa.com/ontology/causal.htm\n- author: @john-sowa\n- topics: [[t.km.ontology.processes]] [[t.phil.causality]]","n":0.378}}},{"i":6098,"$":{"0":{"v":"Postgresql Oracle Graph Query Language Standards Adoption Green","n":0.354},"1":{"v":"\n- url: https://www.linkedin.com/pulse/postgresql-oracle-graph-query-language-standards-adoption-green/\n\n[[c.reference]]\n\n- \"graph-level attributes\" in [Relational inductive biases, deep learning, and graph networks](https://arxiv.org/abs/1806.01261)","n":0.267}}},{"i":6099,"$":{"0":{"v":"Pellet an Owl Reasoner","n":0.5},"1":{"v":"\n- https://ceur-ws.org/Vol-104/30Sirin-Parsia.pdf\n- subject: [[prdct.pellet]]\n\n## Highlights\n\n-  many existing OWL documents are nominally OWL Full, even though their authors intend for them to be OWL DL. Pellet incorporates a number of heuristics to detect “DLizable” OWL Full documents “repair” them.","n":0.162}}},{"i":6100,"$":{"0":{"v":"Owl T a Task Ontology Language for Automatic Service Composition","n":0.316},"1":{"v":"\n- similar: [[ar.an-ontology-for-collaborative-tasks-in-multi-agent-systems]]","n":0.577}}},{"i":6101,"$":{"0":{"v":"Owl Profiles Rule Based Reasoning and Handling Reasoning with the Jena API","n":0.289},"1":{"v":"\n- https://www.dbis.informatik.uni-goettingen.de/Teaching/SWPr-SS20/f-jena-reasoning.pdf\n\n## Highlights\n\n- From practical considerations, the OWL profiles are more important:\nhttp://www.w3.org/TR/owl2-profiles/\n  – OWL2-EL: for ontologies that contain very large numbers of properties and/or classes.\n  Basic reasoning problems can be performed in time that is polynomial with respect to\n  the size of the ontology – not to the data\n  – OWL2-QL: applications that use very large volumes of instance data, and where query\n  answering is the most important reasoning task. Conjunctive query answering can be\n  implemented using conventional relational database systems.\n  – OWL-RL: scalable reasoning without sacrificing too much expressive power. OWL 2\n  RL reasoning systems can be implemented using rule-based reasoning engines.\n\n## OWL2-RL\n\n- the DL-Prover [[prdct.hermit]] (DL only, no SPARQL) provides better functionality (than [[prdct.pellet]])for ontology\nmanagement.","n":0.092}}},{"i":6102,"$":{"0":{"v":"Otherlife","n":1},"1":{"v":"\n\n- [[p.hasSite]] \n- [[p.hasCreator]] @justin-murphy\n- [[p.basedOn]] [[prdct.urbit]]","n":0.378}}},{"i":6103,"$":{"0":{"v":"The Freedom-Specificity Tradeoff","n":0.577},"1":{"v":"\n\n- [[p.hasURL]] https://www.otherlife.co/fst/\n- [[p.provokedThoughts]]\n  - you should have a blog/twitter account for each topic of interest, and aggregate them somewhere else (for followers that want to follow the whole person)\n","n":0.183}}},{"i":6104,"$":{"0":{"v":"Personal Knowledge Management is Bullshit","n":0.447},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.otherlife.co/pkm/\n- [[p.hasTopic]] [[t.km.pkm]]\n- [[p.hasHighlight]] \n  - The problem with the Knowledge Graph ideology is that everything in your mind is already situated in a graph structure. That is precisely the problem. It’s big and complicated, with way too many connections everywhere. There’s no good in replicating that web in digital form.\n  - Almost anyone you know and respect as a writer is known and respected because they're able to muster brute, linear willfulness.\n  - @niklas-luhman is an exception that proves the rule.\n","n":0.109}}},{"i":6105,"$":{"0":{"v":"Otherlife - Francis Bacon","n":0.5},"1":{"v":"\nurl: https://www.otherlife.co/francisbacon/\nauthor: @justin-murphy\n\n- [[p.hasHighlight]]\n  - [These notes posted around his space] were not \"to-do lists.\" These were guardrails for his attention.\n  - [[Lebenswelt|t.phil.lifeworld]]: The sum total of all immediate phenomena which constitute the world of an individual or of a corporate life; life-world.","n":0.152}}},{"i":6106,"$":{"0":{"v":"Open Caesar Balancing Agility and Rigor in Model Based Systems Engineering","n":0.302},"1":{"v":"\n- https://www.researchgate.net/publication/373652870_openCAESAR_Balancing_Agility_and_Rigor_in_Model-Based_Systems_Engineering\n- topics: [[t.cs.sd.modeling.conceptual-modeling.ontology-driven]] [[prdct.opencaesar]] [[t.cs.sd.model-based-systems-engineering-mbse]]\n\n## Abstract\n\nModel-Based System Engineering ([[MBSE|t.cs.sd.model-based-systems-engineering-mbse]]) employs models and formal languages to support development of complex (systems-of-) systems. NASA Jet Propulsion Laboratory (JPL) sees MBSE as a key approach to managing the complexity of system development. However, balancing agility and rigor in MBSE has been reported as a challenging task not yet addressed by modeling tools and frameworks. This is because existing MBSE approaches may enable agility but compromise rigor, or enhance rigor but impede agility. We discuss the challenges of balancing agility and rigor in MBSE across seven systems engineering architectural functions defined by the JPL Integrated Model-Centric Engineering (IMCE) initiative. We demonstrate how openCAESAR, an open-source MBSE methodology and framework created at JPL, can strike a balance between agility and rigor through a case study of the Kepler16b project and discussion of lessons learned from past projects.\n\n\n## Highlights\n\n- representation refers to how information is structured and organized to support the system design and development process\n  -  entails identifying the concepts, relationships, and constraints that comprise the system’s architecture such that stakeholders can easily un- derstand, communicate, and analyze.\n  -  reduces the cognitive load in system design as it determines the choice of the initial modeling constructs, how they are depicted, composed, combined, extended, fragmented, and configured to possess certain system characteristics while ensuring logical consistency and correctness\n- An agile systems engineering solution thus requires a configuration management system (CMS), resembling Git functionality, to streamline creating new versions, reviewing and approving new changes, handling conflicting versions, and merging the changes into a baseline branch.  \n\n### openCAESAR\n\n- two openCAESAR methodology phases:\n  - First, the methodologist creates or imports the required vocab- ularies. Then, viewpoints are created based on these vocabularies and authoring tools are built to express these viewpoints.\n  - The second phase is an iterative development process where the methodologist works closely together with authors and stakeholders to continuously build and refine the vocabularies, descriptions, queries, and reports required for the project\n\n\n## References\n\n[^7]: [[ar.ontological-metamodeling-and-analysis-using-open-caesar]]","n":0.055}}},{"i":6107,"$":{"0":{"v":"Ontomedia Creating an Ontology for Marking up the Contents of Heterogeneous Media","n":0.289},"1":{"v":"\n- url: https://eprints.soton.ac.uk/261153/1/onto_workshop.pdf\n- related: [[prdct.cidoc-crm]] [[prdct.ontomedia]]\n- mentions: \n\n## Highlights\n\n- mentions [[prdct.swoogle]]\n- \"narrative\" represents story\n- The availability of such semantically enriched artifacts would allow for narratives to be generated in a manner targeted to the user preference\n  - A discussion of the relevance of\nthe application of narrative theory to Semantic Web enabling technologies is presented in [^7]\n\n\n\n## References\n\n[^7]: Tuffield, M.M., Shadbolt, N.R., Millard, D.E.: [[ar.narrative-as-a-form-of-knowledge-transfer-narrative-theory-and-semantics]]. In: Proceedings of the 1st AKT Doctoral Colloquium, AKT (2005)\n[^9]: Lawrence, K.F., m. c. schraefel: [[Amateur fiction online - the web of community trust|ar.amateur-fiction-online-the-web-of-community-trust]]. In: Proceedings of the 1st AKT Doctoral Colloquium, AKT (2005)","n":0.101}}},{"i":6108,"$":{"0":{"v":"Ontology Infrastructure for the Semantic Web","n":0.408},"1":{"v":"\n- authors: @claudio-masolo, @stefano-borgo, @aldo-gangemi, @nichola-guarino, @alessandro-oltramari\n- url: http://www.loa.istc.cnr.it/old/Papers/D18.pdf\n- topics: [[prdct.dolce]] [[prdct.ochre]] [[prdct.basic-formal-ontology]] [[prdct.wordnet]] [[prdct.kif]]\n\n## Highlights\n\n- \"the most important challenge for the Semantic Web is not so much the agreement on a monolithic set of ontological categories, but rather the careful isolation of the fundamental ontological options and their formal relationships.\"\n- ","n":0.14}}},{"i":6109,"$":{"0":{"v":"Ontology Implementation with gUFO a Hands on Tutorial","n":0.354},"1":{"v":"\n- https://nemo.inf.ufes.br/files/jpalmeida-tpsales-ontobras-2021-gufo-tutorial-v1.0.pdf\n\nt.2024.07.26.21 could use more explanation, maybe a voice-over. \n\n## Patterns\n\n- Quality reification– \n  - Stability in face of change in measurement schemes for qualities\n- Situations\n  - Handling changes in objects/aspects in time\n![](/assets/images/2024-07-26-21-57-58.png)\n- reminds me of [[ar.reification-and-truthmaking-patterns]]\n","n":0.164}}},{"i":6110,"$":{"0":{"v":"Ontology Development 101 a Guide to Creating Your First Ontology","n":0.316},"1":{"v":"\n- https://protege.stanford.edu/publications/ontology_development/ontology101.pdf\n- topics: [[prdct.protege]]\n\n## Reasons\n\n• To share common understanding of the structure of information among people or\nsoftware agents\n• To enable reuse of domain knowledge\n• To make domain assumptions explicit\n• To separate domain knowledge from the operational knowledge\n• To analyze domain knowledge\n\n## Highlights\n\n- Subclasses of a class usually (1) have additional properties that the superclass does not have, or (2) restrictions different from those of the superclass, or (3) participate in different relationships than the superclasses\n- the ontology should not contain all the possible properties of and distinctions among classes in the hierarchy,\n  - e.g. Consider an ontology describing biology experiments. The ontology will likely contain a concept of Biological organisms. It will also contain a concept of an Experimenter performing an experiment (with his name, affiliation, etc.). It is true that an experimenter, as a person, also happens to be a biological organism. However, we probably should not incorporate this distinction in the ontology: for the purposes of this representation an experimenter is not a biological organism and we will probably never conduct experiments on the experimenters themselves. If we were representing everything we can say about the classes in the ontology, an Experimenter would become a subclass of Biological Organism. However, we do not need to include this knowledge for the foreseeable applications. In fact, including this type of additional classification for existing classes actually hurts: now an instance of an Experimenter will have slots for weight, age, species, and other data pertaining to a biological organism, but absolutely irrelevant in the context of describing an experiment. However, we should record such design decision in the documentation for the benefit of the users who will be looking at this ontology and who may not be aware of the application we had in mind.\n\n## inverse slots\n\n- the","n":0.058}}},{"i":6111,"$":{"0":{"v":"Ontology Building for Cyber Physical Systems Application in the Manufacturing Domain","n":0.302},"1":{"v":"\n- https://dl.acm.org/doi/10.1109/COASE.2018.8560465\n\n## Abstract\n\nCyber-physical systems (CPS) usually have to cope with open contexts, i.e. the context that these systems interact with through sensors and actuators or communication networks changes its morphology during runtime. For instance, CPS can be deployed in the manufacturing domain to form a modular production system, which, at some time during its lifecycle, might have to produce new products or to interact with new modules, which have been designed by different stakeholders. In order to be able to cope with open contexts, CPSs rely on ontologies that represent the information being shared among them. However, due to the complexity of a CPS&#x0027;s context, building these ontologies as a basis for information exchange during runtime is a non-trivial task that requires a structured approach. The contribution of this paper is twofold. First, we present an ontology building method that is tailored towards the needs of CPS, beginning with ontological requirements and ending with a formal ontology. Second, we apply this method to build an ontology for communicating information between CPSs about processes and machine states in the manufacturing domain.","n":0.075}}},{"i":6112,"$":{"0":{"v":"Ontology Based Knowledge Representation Technique Domain Modeling Languages and Planners for Robotic Path Planning a Survey","n":0.25},"1":{"v":"\n- https://www.sciencedirect.com/science/article/pii/S2405959518300985\n- topics: [[t.cs.ai.path-planning]]\n\n## Abstract\n\nKnowledge Representation and Reasoning (KR & R) has become one of the promising fields of Artificial Intelligence. KR is dedicated towards representing information about the domain that can be utilized in path planning. Ontology based knowledge representation and reasoning techniques provide sophisticated knowledge about the environment for processing tasks or methods. Ontology helps in representing the knowledge about environment, events and actions that help in path planning and making robots more autonomous. Knowledge reasoning techniques can infer new conclusion and thus aids planning dynamically in a non-deterministic environment. In the initial sections, the representation of knowledge using ontology and the techniques for reasoning that could contribute in path planning are discussed in detail. In the following section, we also provide comparison of various planning domain modeling languages, ontology editors, planners and robot simulation tools.","n":0.085}}},{"i":6113,"$":{"0":{"v":"Ontologies a Wish List for the Humanities","n":0.378},"1":{"v":"\n- https://www.academia.edu/50247032/Ontologies_A_Wish_List_for_the_Humanities\n\n\n## Abstract\n\nIn this paper, we analyze the problems the Humanities currently face and discuss how ontologies could help them – provided the ontology toolkits had support for additional capabilities. We enumerate these capabilities and describe their necessity for research in the Humanities.\n\n\n## Highlights\n\n### Wishlist\n\n#### Wish #1: Ontological Plurality\n\n- ontological toolkits for Humanities research need to be able to deal with a minimum of two ontologies at the same time, namely the mental ontology of the author and the mental ontology of the reader\n  - In some sense, textual interpretation is the act of proposing a formal mapping between the mental ontology of the author and the mental ontology of the reader that explains the differences ^h7t5vnihn7ft\n\n#### Wish #2: Contexts\n\n- One way to implement ontological plurality is by supporting contexts, both for ontology building and for reasoning (Guha, 1991)\n  - In terms of reasoning, contexts provide a way of compartmentalizing mutually contradictory information without inferring a contradiction\n- Contexts provide a straight-forward way to simulate the mental models that researchers construct when they work with texts.\n- At a very coarse level, each of the texts and each of the research positions – both own and others – can be assigned their own context and reconstructed autonomously within. \n- Contexts can however be applied in more fine-grained manners, for example to model the individual steps of the reconstructive process.\n- By assigning separate contexts to the textual reconstruction, the translation, the analysis of the textual form, the analysis of how the text was edited and the investigations into the traditions and motives leveraged by as well as inspired by the text, the researcher can mix and match possible models for each of these steps simply by bundling contexts\n- Furthermore, prior research can be leveraged in equivalent ways, giving a building block quality to the investigation of alternative interpretations.\n- Finally, contexts make for handy units of information exchange between researchers who want to collaboratively construct sets of ontologies.\n- **In a contextualizing approach, shared assumptions would be factored out and inherited.**\n  - Sometimes the additional information augments the inherited information; sometimes more precise restatements override the inherited.\n- one important problem to consider is that the beliefs, desires and interpretations are forms of modal statements. That means they do not obey the normal forms of deductive inference\n  - for the purposes of historical reconstruction it is important to perform deductive inference on the contents of the beliefs held by the agents under study.\n  - The proper way to deal with this distinction is to employ two contexts, one context that captures the beliefs and one context that captures all of the consistent worlds that follow from the contents of the beliefs.\n\n#### Wish #3: Argumentation Systems\n\n- The reconstruction of a text is an argument that assigns meanings to the linguistic elements\n- In order to expose such a reconstruction to peer criticism, the argumentative links between the elements have to be made explicit in the ontology\n- The ontological toolkits need to support qualifying argumentative links\n  - By making the connections between the facts of the arguments obvious, the ramifications of any modifications to the supporting facts become immediately clear as well.\n- the assignment of argumentative links between any fact and an interpretation should not be limited to only one link, or even to several links of only one truth value\n  - ontology toolkits should provide for a way of enumerating the pro and contra supports for a specific step in the reconstructive argument.\n\n#### Wish #4: Question Corpora Management Systems\n\n- the set of research questions does not remain static: Some questions find answers; new questions are identified; old questions are deemed infertile and placed aside.\n- Akin to the way test- and use-cases drive the development of software artifacts, modeling the questions and monitoring the validity of their answer sets can help focus the research effort and ensures that modifications to the theory do not endanger prior gains.\n- require the construction of shared repositories of research question sets – akin to the Penn Treebank (Marcus et al, 1993) in natural language processing, the TREC competition 13 in information retrieval or the TTPTP repository (Sutcliffe et al, 1998) in the automatic theorem prover (ATP) community.\n\n#### Wish #5: Representational Expressivity\n\n- supporting contexts entails switching from description or first order predicate logic to modal or higher-order logic – depending on the implementation of the contexts. [^14]\n  - This means that “computational completeness (all entailments are guaranteed to be computed) and decidability (all computations will finish in finite time)” – cf. (Smith et al, 2004) – are no longer guaranteed.\n  - once incompleteness and undecidability have been incurred – and we believe this step to be unavoidable for the Humanities – one may as well exploit the representational benefits of modal and higher order logic.\n  - \n","n":0.036}}},{"i":6114,"$":{"0":{"v":"Ontological Metamodeling and Analysis Using Open Caesar","n":0.378},"1":{"v":"\n- ","n":1}}},{"i":6115,"$":{"0":{"v":"Ontological Foundations for Structural Conceptual Models","n":0.408},"1":{"v":"\n- https://ris.utwente.nl/ws/portalfiles/portal/6042428/thesis_Guizzardi.pdf\n\n## Abstract\n\nThe main objective of this thesis is to contribute to the theory of Conceptual Modeling by proposing ontological foundations for structural conceptual models. Conceptual Modeling is a discipline of great importance to several areas in Computer Science. Its main objective is concerned with identifying, analyzing and describing the essential concepts and constraints of a universe of discourse, with the help of a (diagrammatic) modeling language that is based on a set of basic modeling concepts (forming a metamodel). In this thesis, we show how conceptual modeling languages can be evaluated and (re)designed with the purpose of improving their ontological adequacy. In simple terms, ontological adequacy is a measure of how close the models produced using a modeling language are to the situations in the reality they are supposed to represent. The thesis starts by proposing a systematic evaluation method for comparing a metamodel of the concepts underlying a language to a reference ontology of the corresponding domain in reality. The focus of this thesis is on general conceptual modeling languages (as opposed to domain specific ones). Hence, the proposed reference ontology is a foundational (or upper-level) ontology. Moreover, since, it focuses on structural modeling aspects (as opposed to dynamic ones), this foundational ontology is an ontology of objects, their properties and relations, their parts, the roles they play, and the types they instantiate. The proposed ontology was developed by adapting and extending a number of theories coming, primarily, from formal ontology in philosophy, but also from cognitive science and linguistics. Once developed, every subtheory of the ontology is used in the creation of methodological tools (e.g., modeling profiles, guidelines and design patterns). The expressiveness and relevance of these tools are shown throughout the thesis to solve some classical and recurrent conceptual modeling problems. Finally, the thesis demonstrates the applicability and usefulness of both the method and the proposed ontology by analyzing and extending a fragment of the Unified Modeling Language (UML) which deals with the construction of structural conceptual models.\n\n","n":0.055}}},{"i":6116,"$":{"0":{"v":"Onto Media Creating an Ontology for Marking up the Contents of Fiction and Other Media","n":0.258},"1":{"v":"\n- https://eprints.soton.ac.uk/261043/1/ontomedia.pdf\n\n\n## Highlights\n\n### Related Work\n\n#### ABC Ontology\n\n- [[prdct.abc-ontology]]\n- The strength and weakness of this approach was that it tried to describe everything using the same basic structures and had its roots in factual events outside the document. [^1]\n  - While the ontology can be used to describe the events that occurred within the document it was “designed to model physical, digital and analogue objects held in libraries, archives, and museums and on the Internet” [5]. Where it goes beyond the physical it focuses on “abstract concepts such as intellectual content and temporal entities such as performance or lifecycle events that happen to an object” [5].\n- With the OntoMedia model we were concerned not only with the facts but also the possibilities and concepts that existed behind those facts. \n  - The ABC model includes the ‘abstraction category’ as a way of expressing ideas which do not exist in the context of a situation but sees this primarily as a way of binding together various manifestations of the same intellectual expression. \n  - Conversely the OntoMedia structure deals primarily with abstractions that exist behind the content. While, like the ABC model, our struc- ture was based on the concepts of entities and events we specifically focus on the needs of best describing content of both analogue and multimedia. \n  - In this way the OntoMedia ontology can be integrated with the ABC model if required but otherwise provides augmentation and an alternative method of interfacing with the expression of that content while allowing other models to describe the relationship between that expression and the physical media that contains it as well as the bibliographic information that relates to either the expression or the physical media","n":0.059}}},{"i":6117,"$":{"0":{"v":"Onto Media an Ontology for the Representation of Heterogeneous Media","n":0.316},"1":{"v":"\n- https://www.researchgate.net/publication/37538426_OntoMedia_An_Ontology_for_the_Representation_ofHeterogeneous_Media\n- mentions: [[prdct.abc-ontology]]","n":0.5}}},{"i":6118,"$":{"0":{"v":"Onto Clean in Owl with a Dl Reasoner a Tutorial","n":0.316},"1":{"v":"\n- https://people.cs.uct.ac.za/~mkeet/OEbook/ontocleantutorialOE19.pdf\n-o","n":0.707}}},{"i":6119,"$":{"0":{"v":"On the Ontology of Fictional Characters a Semiotic Approach","n":0.333},"1":{"v":"\n- author: @umberto-eco\n- similar: [[ar.the-ontology-of-fiction-a-study-of-dependent-objects]]\n\n## Abstract\n\nsuccessful fictional characters become paramount examples of the ‘real’ human condition because they live in an incomplete world that we have cognitive access to but cannot influence in any way and where no deeds can be undone. Unlike all the other semiotic objects, which are culturally subject to revisions, and perhaps only similar to mathematical entities, the fictual characters will never change and will remain the actors of what they did once and forever","n":0.113}}},{"i":6120,"$":{"0":{"v":"Object Event Modeling for Des and Is Engineering","n":0.354},"1":{"v":"\n- https://ceur-ws.org/Vol-3211/CR_099.pdf\n- author: @gerd-wagner\n- topics: [[prdct.dpmn-discrete-event-process-modeling-notation]]\n\n## Abstract\n\nWe propose Object Event Modeling as a new approach to Discrete Event Simulation (DES) engineering and Information Systems (IS) engineering using UML class diagrams for information modeling and BPMN-style process diagrams for process modeling. We consider the case where for a given business system, both a performance analysis is to be conducted with the help of a DES project and an IS is to be constructed with the help of an IS engineering project. Both the DES design model and the IS design model are representations of the same system. We argue that both DES modeling and IS modeling have a substantial overlap and, hence, can learn from each other. While research in DES has focused on events and processes, neglecting objects, IS engineering research has focused on objects, neglecting events.","n":0.085}}},{"i":6121,"$":{"0":{"v":"Notes about Semantic Web Tools for Online Communities","n":0.354},"1":{"v":"\n- https://rhiaro.co.uk/tags/ficnet\n- mentions: [[prdct.fan-online-persona-fop]]\n","n":0.5}}},{"i":6122,"$":{"0":{"v":"Noctua Literaria a Computer Aided Approach for the Formal Description of Literary Characters Using an Ontology","n":0.25},"1":{"v":"\n- https://pub.uni-bielefeld.de/record/2301795\n  - https://pub.uni-bielefeld.de/download/2301795/2301798/diss_08_06_08.pdf\n- author: @amelie-zollner-weber\n- mentions: [[prdct.racer]]\n- topics: [[t.humanities.digital]] [[t.storytelling.character]] [[t.storytelling]]\n\n## Abstract\n\nIn this thesis, an ontology is introduced to model theories for the description and representation of literary characters. Thereby, individual comprehensions of characters by readers are put in focus. To give examples, mostly devil characters derived from different Faust works are described in the ontology. Briefly, several theories of literary characters are combined to create a base of a formal description using an OWL ontology. Here, categories, which describe features and actions of characters mentioned in stories had to be adapted and applied. It is aimed at representing the mental information structure of a reader, which (s)he has in mind when reading a book. Categories describing general aspects of literary characters form the main classes of the ontology, e.g. inner and outer features, actions on subjects and objects. By using sub classes, categories can subsume features of special characters or groups of characters. In addition, so-called instances of the classes represent individual and explicit objects of the domain of literary characters. Here, direct information about a character given in a text is assigned to an instance. Together with the information of the class hierarchy and other instances, a single mental representation of a character is modelled. Different applications have been developed to explore possibilities of the ontology. Even on such a specific ontology, it is possible to apply logic reasoning using Racer and Prolog. But by using these applications, one was faced with problems: queries of logic reasoning can only make implicit information explicit and more individual queries, which cannot be expressed by logic constructs, cannot be retrieved. Nevertheless, one can imagine that logic reasoning is useful for approaches, which intend a usage and retrieval more by machines than by human beings. Furthermore, two applications have been developed to give access to the ontology. A client-server system is introduced to manipulate the ontology, to search and to compare mental representations of literary characters. The system presents a platform for the discussion and access of representations of characters. The inclusion of new subcategories and information about characters as well as different retrievals and comparisons are the core of this system. Results are mostly presented by different visualisations of character representations. This system can support comparisons of literary characters in an essential way. The second application is a method to add semi-automatically instances to the ontology. This approach aims at users well trained in text encoding but who do not have insides into ontologies. In addition, it is worked on reducing the sometimes labour-intensive work of manual insertion of a representation of a character. A TEI encoding scheme was adapted to enable automated parsing of the text and to produce assignments where the different instances might be included into the class hierarchy of the ontology. The user has just to confirm or select a different class. On the basis of derived character representations included in the ontology, the devil characters of the example corpus were analysed and compared to each other taking advantage of the developed client-server system. By using automatically generated histograms of the distribution of instances for certain classes and visualised representations of the characters, it was possible to examine them in detail and to detect similarities and differences. Regarding the literary analysis, a huge development from the first characters until the later ones can be shown. Devil characters become main and modern characters, which means that they can also vary and can be contradictory in their features and motivations. This development takes place independently from the genre. The choice of the genre depends on the single author, but it seems that they each adopted conceptions from different genres. Observed similarities support the assumption of a traditional core of a devil's conception. Although the conceptions vary, it seems that variations are restricted to a specific frame. In summary, one can state that the ontology is an appropriate method to provide structured overviews of characters, observe different representations, and to find information about characters easily, also in the texts, if references are included. By using the mental representations stored in the ontology, it is possible to clarify aspects and to preserve opinions about characters. Although the ontology is restricted in flexible handling of information and can only present things which are included at a particular date, here, it can illustrate mental representations of characters. By using this ontology, the result of a reading process can be shown, but not directly the action of reading and its different states. This approach demonstrates the possibilities and advantages for literature studies if combined with computer-aided approaches.\n\n\n## Highlights\n\n### Approaches to Description and Classification of Characters\n\n- simple-to-complex\n- typical/stereotypical features\n- roles of characters concerning the plot \n- by genre\n- cognitive-orieted approaches (attaching the process of reading and reception of characters)\n  - \"Characters are not anymore just the\npersons in fiction, but a complex of letters and sense in a reader’s mind.\"\n\n### Survey of Theories of Literary Characters\n\n- @vladimir-propp’s theory is an important precursor for the perspective known as [[t.humanities.structuralism]]\n- @edward-morgan-forster groups literary characters as “flat” or “round”.\n  - flat: few features and consisting of a simple structure\n  - round: more complex and have more Information\n    - can be modified during the plot, so it might be difficult to describe it briefly\n- [[t.storytelling.character.greimas-six-actants]]\n- @roland-barthes defines general parts of narration, for example functions and indices.\n  - functions\nare mostly plot related, whereas the indices can refer to characters and their features.\n- @manfred-pfister takes different aspects, like the relation between the audience and the characters\nin dramas, into account\n  - ranks the “dramatis personae”, the\ncharacters, according to general features, like the social status or sex.\n  - suggests examining characters in opposition to others\n- @jurij-lotman classifies characters as active elements, which carry the plot.\n  - By concentrating on oppositional and plot-oriented aspects of characters, other important things might not be taken into account. \n- @fotis-jannidis's approach is based on theories belonging to linguistic and cognitive science oriented literature studies\n  - is interested in the process of collecting information from different text sections and arranging them as a unit, which represents a character.\n  - features or the actions of a character can be a part of more general problems or patterns. The last aspect comprises the attitude of a reader and the reader steering by a character\n  - proposed [[t.storytelling.narratology.jannidis-three-levels]]\n  - Jannidis’s approach does not afford a deep categorisation of character features, rather, its value lies on the description of the process by which signals in a story can lead to a detection and collection of attributes\n\n#### A Character Taxonomy (Nieragden)\n\n- @goran-nieragden's approach belongs to approaches that classify character information.\n  - refuses approaches that only focus on the role of a character in relation to the plot\n- A taxonomy for characters should cover a large range of manifestations of character relevant information and should exceed singular texts and genres.\n- Nieragden’s first step is to assume partial similarities between literary characters and real persons.\n  - he relates character features and actions\nto similar aspects of human beings\n- he introduces the net-like system of @helmut-bonheim using four modes: speech, report, description and comment.\n  - character information can be divided into a dynamic and a static modes. ^w1fgxgiqobvx\n    - Descriptions and comments (“Which characters judge others?”) are regarded as static elements because they do not move the plot further along, and mark stops in the narrated time.\n    - The dynamic mode contains speech and reports (“Which characters initiate action?”)\n    - The categories are not isolated from each other. For example, a character description given in a speech of a character can belong to more than a single category.\n- adopts @seymour-chatman's [[t.storytelling.narratology.chatmans-three-levels-of-narrative]]\n\n### Information Modelling and Representation\n\n- If XML code is directly added to textual data, the data and mark-up can be processed together. \n  - This might be a good solution for modelling for example literary texts and their characteristics like layout and structure. But the mark-up is directed towards the text structure and does not contain a completely different model like a taxonomy or ontology, especially when using suggested annotation schemes like proposed by the [[prdct.text-encoding-initiative-tei]]\n\n#### SUMO\n\n-  one can consider if one can adopt categories of a general ontology like [[prdct.sumo]].\n   -  at first sight, one can observe that the category “Abstract” subsumes categories, which contain aspects like “InternalAttribute”\n-  Difficulties arise if one tries to add the different activities, e.g. verbal and non-verbal actions of characters\n- If one starts mingling categorisations of model theories (for literary characters) with categories of SUMO, one might loose the focus on representing the theories.   \n  - For example, one would have to spread character actions over a lot of categories, but a common accepted division into verbal and non-verbal actions of characters like proposed by Nieragden in section 2.4, would not be presented by such an ontology.\n    - t.2024.08.22.16 but it could be the basis\n- general ontologies don't support the specific tasks and problems of the humanities\n\n### Chapter 4\n\n#### 4.1 Modelling Theories of Literature Studies by an Ontology\n\n- According to [[user.fotis-jannidis]]’s work, a character constitutes as a mental representation (cf. section 2.3) whereas [[user.goran-nieragden]] describes a categorisation for the description of literary characters (cf. section 2.4). [[user.jurij-lotman]] instead, forms characters as a bunch of features (cf. section 2.2)\n- Although these three theories developed in literature studies seem to be different, they will be merged in this approach to form a formal description of characters.","n":0.025}}},{"i":6123,"$":{"0":{"v":"nateliason.com","n":1},"1":{"v":"\r\n- [[p.instanceOf]] [[c.website]]\r\n- [[p.ownedBy]] [[p.hasCreator]] @nat-eliason\r\n- [[p.hasURL]] https://www.nateliason.com/members/home\r\n  - members homepage","n":0.302}}},{"i":6124,"$":{"0":{"v":"Prep Trap","n":0.707},"1":{"v":"\n- https://blog.nateliason.com/p/prep-trap\n\n\n## Definition\n\n- spending too long on Prep, thinking they need to keep studying, keep reading books, keep taking courses, before they’re “Ready” to do the thing.","n":0.192}}},{"i":6125,"$":{"0":{"v":"Nate Eliason's Notes","n":0.577},"1":{"v":"\n\n\n[[p.hasURL]] https://www.nateliason.com/notes\n[[p.instanceOf]] \n","n":0.577}}},{"i":6126,"$":{"0":{"v":"Nat Eliason's Brain","n":0.577},"1":{"v":"\n\n\n- [[p.hasURL]] https://www.nateliason.com/brain\n- @nat-eliason [[p.madeOffer]] \"Lifetime Access to Nat's Book Notes for $25\"\n  - [[p.offerAcceptedBy]] @dave 2021-11-08\n  - [[p.hasURL]] \n    - https://click.convertkit-mail.com/27unlv0mr2s9u4n6nwi3/reh8hohq2new0nb2/aHR0cHM6Ly93d3cubm90aW9uLnNvL2I5MDk3ZTY0NzhlNzQxNTdhMjFiMjE0MTZhNjBiYjg4P3Y9Y2VhYTRkNjgzZGU5NDAyYjhiMzJmMGRhNDQ0Nzc3N2I=\n      - [[p.hasFormat]] [[prdct.notion]]\n    - https://click.convertkit-mail.com/27unlv0mr2s9u4n6nwi3/n2hohvhn8x8eevf6/aHR0cHM6Ly9yb2FtcmVzZWFyY2guY29tLyMvYXBwL05hdHNCcmFpbi9wYWdlL29DdGY1Qk9YaQ==\n      - [[p.hasFormat]] [[prdct.roam]]\n","n":0.183}}},{"i":6127,"$":{"0":{"v":"Narrative as a Form of Knowledge Transfer Narrative Theory and Semantics","n":0.302},"1":{"v":"\n- url: https://eprints.soton.ac.uk/261010/1/AKT_DTA.pdf\n\n## Highlights\n\n- motivation: better search and filter\n- context: FicNet amateur writing online community \n  -  \"noticeable tension was discovered between the desire for this information and the concern that it would spoil the story\n-  requirements:\n   -  describe the media objects that were created by this community in terms of both bibliographic detail and content\n      -  bibliographic detail:  Dublin Core or the Functional Requirements for Bibliographic Records \n   -  ontology to acknowledge that some of the metadata records could be considered sensitive information in that they would give away important plot information\n   -  ","n":0.103}}},{"i":6128,"$":{"0":{"v":"Multi-Level Ontology-Based Conceptual Modeling","n":0.5},"1":{"v":"\n- https://drive.google.com/open?id=1uAopFMa_YRbaVZo5eNGSyZOEIgoYeIkp&usp=drive_fs\n- https://www.sciencedirect.com/science/article/abs/pii/S0169023X17301052\n- authors: @victorio-carvalho @joao-paulo-almeida @claudenir-fonseca @giancarlo-guizzardi\n- topics: [[prdct.unified-foundational-ontology.ufo-mlt]]\n- published: 2017-05\n- similar: \n  - [[ar.extending-the-foundations-of-ontology-based-conceptual-modeling-with-a-multi-level-theory]] \n  - \n\n## Abstract\n\nSince the late 1980s, there has been a growing interest in the use of foundational ontologies to provide a sound theoretical basis for the discipline of conceptual modeling. This has led to the development of ontology-based conceptual modeling techniques whose modeling primitives reflect the conceptual categories defined in a foundational ontology. The ontology-based conceptual modeling language OntoUML, for example, incorporates the distinctions underlying the taxonomy of types in the Unified Foundational Ontology (UFO) (e.g., kinds, phases, roles, mixins, etc.). This approach has focused so far on the support to types whose instances are individuals in the subject domain, with no provision for types of types (or categories of categories). In this paper we address this limitation by extending the Unified Foundational Ontology with the MLT multi-level theory. The UFO-MLT combination serves as a foundation for conceptual models that can benefit from the ontological distinctions of UFO as well as MLT's basic concepts and patterns for multi-level modeling. We discuss the impact of the extended foundation to multi-level conceptual modeling.\n\n## Highlights\n\n### Introduction\n\n- The [[[prdct.ontouml]]-based] approach is so far unable to describe subject domains in which the categorization scheme itself is part of the subject matter.\n  - t.2024.10.01.16 like D&D classes\n- In OntoUML, the taxonomy of types of the Unified Foundational Ontology (UFO) has been reflected in the language such that the distinctions of the foundational ontology can be used to provide useful constraints and modeling guidelines, ultimately leading to ontologically well-founded conceptual models. The resulting conceptual models consist of a collection of types (classes) of individuals in the subject domain (e.g., the “Person” kind, the “Child” phase, the “Student” role). Each of these domain types instantiate types in the foundational ontology (e.g., kind, subkind, role, phase, etc.).\n- \n","n":0.057}}},{"i":6129,"$":{"0":{"v":"Multi Level Conceptual Modeling Theory Language and Application","n":0.354},"1":{"v":"\n- https://nemo.inf.ufes.br/wp-content/papercite-data/pdf/multi_level_conceptual_modeling_theory_language_and_application_2021.pdf\n- authors: @claudenir-fonseca @joao-paulo-almeida @giancarlo-guizzardi @victorio-carvalho\n- topics: [[t.km.ontology.multi-level-theory]]\n\n## Abstract\n\nIn many important subject domains, there are central real-world phenomena that span across multiple classification levels. In these subject domains, besides having the traditional type-level domain regularities (classes) that classify multiple concrete instances, we also have higher-order type-level regularities (metaclasses) that classify multiple instances that are themselves types. Multi-Level Modeling aims to address this technical challenge. Despite the advances in this area in the last decade, a number of requirements arising from representation needs in subject domains have not yet been addressed in current modeling approaches. In this paper, we address this issue by proposing an expressive multi-level conceptual modeling language (dubbed [[prdct.ml2]]). We follow a principled language engineering approach in the design of ML2, constructing its abstract syntax as to reflect a fully axiomatized theory for multi-level modeling (termed MLT*). We show that ML2 enables the expression of a number of multi-level modeling scenarios that cannot be currently expressed in the existing multi-level modeling languages. A textual syntax for ML2 is provided with an implementation in Xtext. We discuss how the formal theory influences the language in two aspects: (i) by providing rigorous justification for the language’s syntactic rules, which follow MLT* theorems and (ii) by forming the basis for model simulation and verification. We show that the language can reveal problems in multi-level taxonomic structures, using Wikidata fragments to demonstrate the language’s practical relevance.\n\n\n\n\n\n## References\n\n[^8]: [[ar.deep-meta-modelling-with-metadepth]]","n":0.065}}},{"i":6130,"$":{"0":{"v":"Multi Agent Oriented Programming the Ja Ca Mo Platform","n":0.333},"1":{"v":"\n- https://www.emse.fr/~boissier/enseignement/maop16/pdf/aop.pdf\n- topics: [[t.cs.agents.multi-agent-oriented-programming]]\n\n## Outline\nProgramming Agents\nFundamentals\n(BDI) Hello World\nIntroduction to Jason\nReasoning Cycle\nMain constructs: beliefs, goals, and plans\nOther language features\nComparison with other paradigms\nConclusions and wrap-up\n","n":0.209}}},{"i":6131,"$":{"0":{"v":"Moehr Better","n":0.707},"1":{"v":"\n\n\n- [[p.instanceOf]] [[c.website]] \n- [[p.hasPart]] http://www.moehrbetter.com/blog\n- http://www.moehrbetter.com/blog [[p.instanceOf]] [[c.blog]]\n- [[p.ownedBy]] @scott-moehring\n  ## Highlights \n- http://www.moehrbetter.com/gtd-advanced-workflow-diagram.html\n- http://www.moehrbetter.com/blog/today-i-turn-55-heres-what-ive-been-learning\n","n":0.25}}},{"i":6132,"$":{"0":{"v":"Modular Ontology Modeling","n":0.577},"1":{"v":"\n- https://content.iospress.com/articles/semantic-web/sw222886\n- topics: [[t.cs.semantic-web.axiomatization]]\n\n## Abstract\n\nReusing ontologies for new purposes, or adapting them to new use-cases, is frequently difficult. In our experiences, we have found this to be the case for several reasons: (i) differing representational granularity in ontologies and in use-cases, (ii) lacking conceptual clarity in potentially reusable ontologies, (iii) lack and difficulty of adherence to good modeling principles, and (iv) a lack of reuse emphasis and process support available in ontology engineering tooling. In order to address these concerns, we have developed the Modular Ontology Modeling (MOMo) methodology, and its supporting tooling infrastructure, CoModIDE (the Comprehensive Modular Ontology IDE – “commodity”). MOMo builds on the established eXtreme Design methodology, and like it emphasizes modular development and design pattern reuse; but crucially adds the extensive use of graphical schema diagrams, and tooling that support them, as vehicles for knowledge elicitation from experts. In this paper, we present the MOMo workflow in detail, and describe several useful resources for executing it. In particular, we provide a thorough and rigorous evaluation of CoModIDE in its role of supporting the MOMo methodology’s graphical modeling paradigm. We find that CoModIDE significantly improves approachability of such a paradigm, and that it displays a high usability.\n\n## Highlights\n\n### Introduction\n\n- it is often much easier to develop a new ontology from scratch, than it is to try to re-use and adapt an existing ontology.\n- four of the major issues preventing wide-spread re-use are (i) differing representational granularity, (ii) lack of conceptual clarity in many ontologies, (iii) lack and difficulty of adherence to established good modeling principles, and (iv) lack of re-use emphasis and process support in available ontology engineering tooling.\n- If a use case requires fine-granularity data, a coarse-grained ontology is essentially useless. On the other hand, using a fine-grained ontology for a use case that requires only coarse granularity data is unwieldy due to (possibly massively) increased size of ontology and data graph.\n- Even simple cases, such as the recommendation to not have perdurants and endurants together in subclass relationships\n- “good modeling” appears to largely be a function of modeling experience and more of an art, than a science, which has not been condensed well enough into tangible insights that can easily be written up in a tutorial or textbook.\n- Once a reusable ontology resource has been located, a suitable reuse method must first be selected; e.g., cloning the entire design into the target ontology/namespace, using owl:imports to include the entire source ontology as-is, cloning individual definitions, locally subsuming or aligning to remote ontology entities, etc.\n- through ontology re-use, the ontologist commits to a design and logic built by a third party.\n  - keeping track of the provenance of re-used ontological resources and their locally instantiated representations may become important,\n  - This is particularly important in case remote resources are reused directly rather than through cloning into a local representation (e.g., using owl:imports or through alignments to remote entities using subclass or equivalence relations);\n- The notion of module has taken on a variety of meanings in the Semantic Web community [2,18,60]. For our purposes, a module is a part of the ontology (i.e., a subset of the ontology axioms) which captures a key notion together with its key attributes. For example, an event module may contain, other than an Event class, also relations and classes designed for the representation of the event’s place, time, and participants.\n- A module is thus as much a technical entity, in the sense of a defined part of an ontology, as well as a conceptual entity, in the sense that it should encompass different classes (and relationships between them) which “naturally” (from the perspective of domain experts) belong together.\n- Modules may overlap. They may be nested. They provide an organization of an ontology as an interconnected collection of modules, each of which resonates with the corresponding part of domain conceptualization by the experts.\n  - modules make it possible to approach ontology modeling in a divide-and-conquer fashion; first, by modeling one module at a time, and then connecting them\n- The systematic use of [[ontology design patterns|t.cs.semantic-web.ontology.design-patterns]] [8,17] is another central aspect of our approach, as many of their promises resonate with the issues that our approach is addressing [28].\n\n\n### Related Work\n\n- The [[prdct.methontology]] methodology is presented by Férnandez et al. in [15]. It is one of the earlier attempts to develop a development method specifically for ontology engineering processes\n- The [[prdct.on-to-knowledge]]  Methodology (OTKM) [61] is, similarly to METHONTOLOGY, a methodology for ontology engineering that covers the big steps, but leaves out the detailed specifics.\n- [[ar.distributed-engineering-of-ontologies-diligent]], by Pinto et al. [43], is an abbreviation for Distributed, Loosely-Controlled and Evolving Engineering of Ontologies, and is a method aimed at guiding ontology engineering processes in a distributed Semantic Web setting\n- In all three of these well-established methods, the process steps that are defined are rather coarse-grained. They give guidance on overall activities that need to be performed in constructing an ontology, but more fine-grained guidance (e.g., how to solve common modeling problems, how to represent particular designs on concept or axiom level, or how to work around limitations in the representation language) is not included. \n\n#### Ontology Design Patterns\n\n- Ontology Design Patterns (ODPs) were introduced at around the same time independently by Gangemi [17] and Blomqvist and Sandkuhl [8]\n- Key contributions include the eXtreme Design methodology (detailed in Section 2.3) and several other pattern-based ontology engineering methods (Section 2.4). The majority of work on ODPs has been based on the use of miniature OWL ontologies as the formal pattern encoding, but there are several examples of other encodings, the most prominent of which are OPPL [14] and more recently OTTR [59].\n- MOMo extends on those methods, but also incorporates results from our past work on how to document ODPs [26,29,32], how to implement ODP support tooling [22] and how to instantiate patterns into modules by “stamping out copies” [24].\n- [[prdct.samod-methodology]] [42], or Simplified Agile Methodology for Ontology Development, is a recently developed methodology that builds on and borrows from test-driven and agile methods (in particular eXtreme Design). SAMOD emphasises the use of tests to confirm that the developed ontology is consistent with requirements, and prescribes that the developer construct three types of such tests: model tests, data tests, and query tests.\n\n#### Graphical Conceptual Modeling\n\n- [[prdct.comodide]] has taken influence from [[prdct.vowl]], e.g., in how we render datatype nodes. However, in a collaborative editing environment in which the graphical layout of nodes and edges needs to remain consistent for all users, and relatively stable over time, we find the force-directed graph structure (which changes continuously as entities are added/removed) to be unsuitable.\n- the commercial offering [[prdct.grafo]]55 offers a very attractive feature set, combining the usability of a VOWL-like notation with stable positioning, and collaborative editing features. Crucially, however, Grafo does not support pattern-based modular modeling or import statements, and only supports RDFS semantics, and as a web-hosted service, does not allow for customizations or plugins that would support such a modeling paradigm.\n- CoModIDE is partially based on the Protégé plugin , as presented in [47]. OWLAx plugin supports one-way translation from graphical schema diagrams drawn by the user, into OWL ontology classes and properties; however, it does not render such constructs back into a graphical form. There is thus no way of continually maintaining and developing an ontology using only OWLAx. There is also no support for design pattern re-use in this tool.\n\n\n### 3 The modular ontology modeling methodology (MOMo)\n\n![](/assets/images/2024-10-12-15-12-34.png)\n\n\n#### 3.3 OWL axioms\n\naxiomatizations can have different interpretations, and while they can, for example, be used for performing deductive reasoning, this is not their main role as part of the MOMo approach. Rather, for our purposes axioms serve to disambiguate meaning, for a human user of the ontology.\n\n##### 3.6.6.Set up documentation and determine axioms for each module\n\n- Since the documentation is meant for human consumption, we prefer to use a concise formal representation of axioms, usually using description logic syntax or rules, together with an additional listing of the axioms in a natural language representation.\n- In our experience, using axioms that only contain two classes and one property suffices to express an overwhelming majority of the desired logical theory [12]. We are thus utilizing the relatively short list of 17 axiom patterns that was determined for support in the OWLAx Protégé plug-in [47] and that can also be found discussed in [56].\n- We would like to mention, in particular, two types of axioms that we found very helpful. One of them are structural tautologies which we have already discussed in Section 3.3. The other are scoped domain (respectively, range) axioms (introduced as the class-oriented strategy in [21]).\n- As such, we recommend a rather complete axiomatization, as long as it does not force an overly specific reading on the ontology. We usually use the checklist from the OWLAx tool [47] to axiomatize with simple axioms. More complex axioms, in particular those that span more than two nodes in a diagram, can be added conventionally or by means of the ROWLTab Protégé plug-in [45,46]. We also utilize what we call structural tautologies which are axioms that are in fact tautologies such as A⊑⩾0R.B, to indicate that individuals in classes A and B may have an R relation between them, and that this would be a typical usage of the property R.88\n\n### Example modular ontologies\n\nHighly spatial data\n\nIt is frequently common to model data that has a strong spatial dimension. The challenges that accompany this are unfortunately myriad. In the GeoLink Modular Ontology [34] we utilize the Semantic Trajectory pattern to model discrete representations of continuous spatial movement. Ongoing work regarding the integration of multiple datasets (e.g., NOAA storm data, USGS earthquake data, and FEMA disaster declarations)1717 while using their spatial data as the dimension of integration can be found online.1818 The RealEstateCore Ontology [20,25] provides a set of patterns and modules for the integration of spatial footprints and structures in a real estate property with sensors and other devices present on the Internet of Things.\nElusive ground truth\n\nSometimes, it is necessary to model data where it is not known if it is true, or that it is necessary to knowingly ingest possibly contradictory knowledge. In this case, we suggest a records-based approach, with a strong emphasis on the first-class modeling of provenance. That is, knowledge or data is not modeled directly, but instead we model a container for the data, which is then strongly connected to its provenance. An example of this approach can be found in the Enslaved Ontology [54], where historical data may contradict or conflict with itself, based on the interpretations of different historians.\nRule-based knowledge\n\nIn some cases, it may be necessary to directly encode rules or conditional data, such as attempting to describe the action-response mechanisms when reacting to an event. The methods for doing so, and the modules therein associated, can be found in the Modular Ontology for Space Weather Research [57] and in the Domain Ontology for Task Instructions [13].\nShortcuts & views\n\nShortcuts and Views are used to manage complexity between rich and detailed ontological truthiness and convenience for data providers, publishers, and consumers. That is, it is frequently desirable to have high fidelity in the underlying knowledge model, which may result in a model that is confusing or unintuitive to the non-ontologist. As such, shortcuts can be used to simplify navigation or publishing according to the model. These shortcuts would also be formally described allowing for a navigation between levels of abstraction. A full examination of these constructs is out of scope, but examples of shortcuts and views, alongside their use, can be found in the Geolink Modular Ontology [34], the tutorial for modeling Chess Game Data [35], and in the Enslaved Ontology [54].\n\n\n\n## References\n\n[^23]: K. Hammar, Content ontology design patterns: Qualities, methods, and tools, PhD thesis, Linköping University, Sweden, 2017. doi:10.3384/diss.diva-139584.\n","n":0.023}}},{"i":6133,"$":{"0":{"v":"Modelling Time within a Strongly Typed Database","n":0.378},"1":{"v":"\n- url: https://blog.vaticle.com/modelling-time-within-a-strongly-typed-database-55ba91ecad62\n- topic: [[prdct.typedb]]\n- \nPublished in\n\nVaticle\n·\n9 min read\n·\nJun 21, 2021\n\n--\n\nTime is the indefinite continued progress of existence and events that occur in an apparently irreversible succession from the past, through the present, into the future¹. The dynamics of systems operating over time are responsible for much of the apparent nonlinearity we observe, causal sequences travel forward in time, and the full impact of time is thereby rather interesting.\nBackground to Temporal Modelling\n\nIn the data context, many conceptual facets of time can be hard to capture, particularly in an RDBMS. Depending on the application, various complexities can arise in modelling time-based data, including:\n\n    Storage and Indexing: How to store time data fields so they can be accessed quickly\n    Division and Aggregation: The smallest sensible time increment, and aggregation methods\n    Multiple Timelines: Dealing with changing data\n    Slowly Changing Dimensions: Classifying responses to temporal data changes\n    Temporally Variable Schema and Data: Capturing schema and data changes\n    Mining Temporal Relations: Methods of relating times to other times (e.g. before, after etc.)\n\nThese basics must be mastered before moving onto dynamic systems and causality. But they are not small issues, as entire databases have been devised and market shares carved out around the idea of being good at Problem 1 and 2 generally (e.g. MapR, TimeDB), or for specific use cases such as IoT.\n\nMuch time and effort have been put into Problems 3, 4 and 5 particularly with RDBMS and Dimensional Warehouses (e.g. DataVault), and even SQL extension recommendations. \n   - [[prdct.owl-time]] is the dominant solution for Problem 6 and has notorious ambiguity problems. ^rpdqex91m56q\n\nMost graph types require everything to be an entity (e.g. property graph), when in fact in the real world, entities are few, and everything else is attributes connected by relations. TypeDB has a unique data model that makes temporal modelling powerful and simple.\nTemporal Variables — A Common Application\n\nA key challenge in databases is to support temporal variables that are only valid for a certain period of time, and can be safely updated while preserving the original value. This requires (1) storage and indexing of timestamped data and, (3) multiple timelines.\nMultiple timelines for one value²\n\nIn order to flesh out the example, the scenario from Timely Concerns in Data Models² will be used.\n\nConsider the diagram below, which shows a typical property graph model (i.e. nodes are mini-tables); the question is how I would change this in order to record all reads/writes and changing values (i.e. have read and write timelines on everything)? There are many ways we could model this system in TypeQL. For example, we could take the property graph view, as in the image and make everything entities.\nExample Data Model²\n\nAs a strongly typed database, TypeDB provides a particularly strong platform for temporal modelling. Consider the image below.\nTypeQL — (Note: A Thing is an Entity, an Attribute or a Relation)\n\nThe diagram demonstrates that in TypeQL relations can do everything entities can do, plus link roles. Further, attributes can own other attributes and play roles in relations. Not shown is the fact that attributes are unique values, which is then related to each instance of use. Finally, I will follow the lead of Haikal (CEO, Vaticle) in his insight that local increases in intricacy lead to lower overall complexity. Thus, we will start from the inside out.\nStep 1: An Expanded definition of time\n\nTime and date are usually recorded with a timestamp, a multi-scale record of the number of periods since a reference event. Each scale represents an integer multiple of a specific time period (years, months, days, hours, mins, secs, msec) and the entire date and time combination is a string of these period scales. Indexing a single year needs to take account of ~3 x 10¹⁰ unique variations.\nUnique Values to Index = 3.1 x 10¹⁰ /year\n\nTypeQL has unique capabilities that enable us to take advantage of this problem since attributes can own other attributes and have unique values. These capabilities enable us to form a composite index on time (a set of buckets using integers), taking the indexing requirement for a single year of microseconds down to 1,188 unique values.\nUnique Values to Index = 1,188 /year\n\nIn a future version of TypeQL, this concept of canonical composite attributes with enums for the units and conversion functions is expected to be implemented to create a powerful system for units. But for the moment, it is only useful in indexing records. Below, the TypeQL schema for UTC is shown.\n\n#####################################\n# TypeQL Temporal Lists Model\n# - capturing the read/writes and changing values\n#########################################define# 1.A. Setup UTC time fast-indexing system   year sub attribute, value long;\n   month sub attribute, value long;\n   day sub attribute, value long;\n   hour sub attribute, value long;\n   mins sub attribute, value long;\n   secs sub attribute, value long;\n   msecs sub attribute, value long;   UTC sub attribute, \n      value date,\n      owns year,\n      owns month,\n      owns day,\n      owns hour,\n      owns mins,\n      owns secs,\n      owns msecs;\n\nSince we are building a business system, it is convenient to expand that definition to bring in the finance temporal categories.\n\n# 1.B. Setup finance time   week sub attribute, value long;\n   quarter sub attribute, value long;\n   fin_quarter sub attribute, value long;\n   half sub attribute, value long;\n   fin_half sub attribute, value long;\n   fin_year sub attribute, value long;   finance_time sub UTC,\n      owns week,\n      owns quarter,\n      owns fin_quarter,\n      owns half,\n      owns fin_half,\n      owns fin_year;\n\nFor the moment, these are standalone data objects and don’t play any roles. They perhaps could have been marked as abstract. To use them, it would be convenient to input all of the indexes as a batch operation and then match them into the insert of a specific date-time-stamp.\nStep 2: Setup a Temporal List\n\nIn a business system, much of the data we deal with, like addresses, dependent, project_work, and dept_managerare not actually independent things. Instead, they have a temporal nature. During periods of time, there are various facts that are true and periods when these facts change. Taking advantage of TypeQL’s polymorphic nature, we define a generic temporal list that contains any number of items and then subclass it for our four temporal data elements.\n\n#2. Setup Temporal List, with SubTypes\n\n   temporal_list sub relation,\n      owns intIndex, # not a key\n      owns op_type, # enum of read/write\n      owns current, # boolean value, set by rules\n      relates owner, # entity owner, employee this data is for \n      relates item, # the data fragment\n      relates user_id, # accessor user id, not an employee number \n      relates created; # finance_time the data was created\n\n   address sub temporal_list;\n   dependant sub temporal_list;\n   project_work sub temporal_list;\n   dept_manager sub temporal_list;`\n\nStep 3: Setup Temporal List Data\n\nThis temporal list structure turns out to be a very handy way of storing objects and accessing them. The aim is to input all list elements with current =falseand then have rules to determine which is current. At present, the list is a bit of hard work, as one must pull the current record and use its index + 1 for the new insert. However, this is expected to get much easier once calculation comes in, as one can automate the index. The data for the temporal list is defined below:\n\n#3. Setup the Data for the Temporal List\n\n   street sub attribute, \n      value string, \n      plays temporal_list:item;\n   city sub attribute, \n      value string, \n      plays temporal_list:item;\n   postcode sub attribute, \n      value string, \n      plays temporal_list:item;\n   state sub attribute, \n      value string, \n      plays temporal_list:item;\n   dep_id sub attribute, \n      value string, \n      plays temporal_list:item;\n   dep_name sub attribute, \n      value string, \n      plays temporal_list:item;\n   dep_gender sub attribute, \n      value string, \n      plays temporal_list:item;\n   dep_birthdate sub attribute, \n      value date, \n      plays temporal_list:item;\n   proj_id sub attribute, \n      value string, \n      plays temporal_list:item;\n   proj_name sub attribute, \n      value string, \n      plays temporal_list:item;\n   dept_id sub attribute, \n      value string, \n      plays temporal_list:item;\n   dept_name sub attribute, \n      value string, \n      plays temporal_list:item;\n\nStep 4: Setup local time definition\n\nThe local-time to use for this database can be sub-classed from the previously defined time structures:\n\n#4. Setup the local time definition\n\n   loc_time sub finance_time, \n      plays temporal_list:created;\n\nStep 5: Setup the Person Entity\n\nFinally, we set up the only entity in this sub-model, which is a person, the employee who “owns” the data records (i.e. the employee whose data is being accessed), as shown below:\n\n# 5. finally setup the employee definition to own the data\n\n   employee_name sub attribute, value string;\n   employee_id sub attribute, value string;\n   social_security sub attribute, value string;\n   birthdate sub attribute, value date;\n   gender sub attribute, value string;\n\n   employee sub entity,\n      owns employee_id,\n      owns employee_name,\n      owns social_security,\n      owns birthdate,\n      owns gender,\n      plays temporal_list:owner;\n\nStep 6: Insert a temporal record\n\nAs discussed previously, assuming we input the time first and the accessor user id is the email address, then inserting a temporal record amounts to:\n\n# 6. insert a temporal record\n\nmatch\n   $emp isa employee, has employee_id '#%$@-@#%';\n   $uid isa userID, $uid 'user@example.com';\n   $tim isa loctime; $tim '2018-09-17T18:54:16.717Z';\ninsert\n   $str isa street; $str '92 Campbell Parade';\n   $cit isa city; $cit 'Bondi Beach';\n   $pos isa postcode; $pos '2026';\n   $sta isa state; $sta 'NSW'\n   $adr (owner:$emp, user_id:$uid, item:$str, item: $cit, \n      item:$pos, item:$sta, created:$tim) isa address,\n      has intIndex 0,\n      has type 'write_op',\n      has current false;\n\nStep 7: Match a temporal record\n\nAssuming the rule to determine the current is in play, then querying the current is easy, as shown below, although one should also write back a new read record.\n\n# 7. get the value from a temporal record\n\nmatch\n   $emp isa employee, owns employee_id '#%$@-@#%';\n      (owner:$emp, item:$it) isa address, \n       has op_type 'write_op',\n       has current true;\n\nDiscussion\n\nAs a strongly typed database, TypeDB’s unique data model makes the representation of temporal records a snap. Firstly, the unique nature of attributes mean a composite index can index any time in a 10-year span within <1,200 unique values. This can be extended into making an easy method to reference all values within a given financial period, such as a particular quarter, or month etc.\n\n    Most graph types require everything to be an entity (e.g. property graph), when in fact in the real world, entities are few, and everything else is attributes connected by relations. TypeDB has a unique data model that makes temporal modelling powerful and simple.\n\nThe interesting thing about the TypeQL query language is that it can model almost any other data storage approach, and I like lists because they are easy. I personally use lists a lot, as well as dicts, for storage in TypeQL, and there are two circumstances:\n\n    I insert an entire list at once, for example, a session in a log with events, and in this case, I use a dummy “stop” value at the end of each list, so it is easy to get.\n    Insert items in a list incrementally, as shown above; in this case, I would match out the index of the current record, add 1 to it (in the client) and insert it in the new list item.\n\nOnce calculations are in, this becomes a lot easier, and it can be accomplished in a single match/insert. We could hope to see calculations and canonical composite attributes late this year.\n\nThis article is an excerpt from a post and subsequent discussion on Vaticle Discord. If you enjoyed this piece and would like to contribute to the active discussions around modelling time in TypeDB, head to the Vaticle Community discord. Thanks to Daniel for encouraging me to post this thread!!\nBibliography\n\n[1] Wikipedia: Time\nhttps://en.wikipedia.org/wiki/Time\n\n[2] Thomas Frisendal — Timely Concerns in Data Models, June 10, 2019\nhttps://www.dataversity.net/timely-concerns-in-data-models/\nTypedb\nData Modeling\nType Systems\nDatabase Development\nDatabase\n\n--\n","n":0.023}}},{"i":6134,"$":{"0":{"v":"Ml2 an Expressive Multi Level Conceptual Modeling Language","n":0.354},"1":{"v":"\n- https://core.ac.uk/download/pdf/161372882.pdf\n- authors: @claudenir-fonseca\n- topics: [[prdct.ml2]] [[prdct.unified-foundational-ontology]]\n\n## Abstract\n\nSubject domains are often conceptualized with entities stratified into a rigid two-level structure: a level of classes and a level of individuals which instantiate these classes. Multi-level modeling extends the conventional two-level classification scheme by admitting classes that are also instances of other classes, a feature which can be used beneficially in a number of domains. Despite the advances in multi-level modeling in the last decade, a number of requirements arising from representation needs in subject domains with multiple levels of classification have not yet been addressed in current modeling approaches. In this work, we investigate the requirements for multi-level modeling and propose an expressive multi-level conceptual modeling language dubbed ML2. We follow here a systematic approach based on a strict separation of concerns. First, we capture and formalize the conceptualization underlying multi- level modeling phenomena, called `MLT*`, building on the multi-level theory called MLT. Second, we employ `MLT*` as bedrock for the definition of ML2, a textual modeling language that addresses the elicited requirements for multi-level modeling. The proposed language is supported by a featured Eclipse-based workbench which verifies adherence of the ML2 model to the `MLT*` rules. The capabilities of ML2 are demonstrated by using it to accomplish three distinct modeling tasks: modeling a multi-level challenge proposed in the context of the MULTI 2017 workshop; modeling the concepts from ML2‟s underlying theory, `MLT*`; modeling the Unified Foundation Ontology (UFO).\n\n","n":0.065}}},{"i":6135,"$":{"0":{"v":"Mira a Model Driven Framework for Semantic Interfaces for Web Applications","n":0.302},"1":{"v":"\n- https://www.researchgate.net/publication/303514856_MIRA_A_Model-Driven_Framework_for_Semantic_Interfaces_for_Web_Applications\n\n## Abstract\n\nA currently recognized barrier for the wider adoption and dissemination of Semantic Web technologies is the absence of suitable interfaces and tools to allow suitable access by end-users. In a wider context, it has also been recognized that modern day interfaces must deal with a large number of heterogeneity factors, such as varying user profiles and runtime hardware and software platforms. This paper presents MIRA, a framework for defining and implementing Semantic Interfaces for Web applications, including those on the Semantic Web. A Semantic Interface is defined as being one capable of understanding and adapting to the data it presents and captures, and its schema, if present. Moreover, the interface must also be able to adapt to its context of use – the device being used, any available information about its user, network conditions, and so on. Using a model-driven approach, MIRA allows developers to define such interfaces, and generates code that can run on clients, servers or both. We have carried out a qualitative evaluation that shows that MIRA does indeed provide a better process for developers, without imposing any significant performance overhead.\n\n\n## Highlights\n\n- In his ESWC 2013 keynote talk1,  David Karger defines a  Semantic Web application as “one whose schema is expected to change”\n- the  Cameleon  Reference  Model  is  a current  reference  framework  for  User Interfaces  gaining  adoption  [4],  the  item of  several  years  of  research  of  a  major European research project, which proposes four abstraction levels  for  modeling  UIs: Task and Domain, Abstract Interface, Concrete Interface, Final User Interface","n":0.063}}},{"i":6136,"$":{"0":{"v":"Millennium Db an Open Source Graph Database System","n":0.354},"1":{"v":"\n- url: https://watermark.silverchair.com/dint_a_00209.pdf\n\n\n## Example\n\nMichelle Bachelet, position held, President of Chile, e1)\n(e1, start date, 2014-03-11, default)\n. . .\n(Michelle Bachelet, position held, President of Chile, e2)\n(e2, start date, 2006-03-11, default)\n\n## Issues\n\n- if we add\nthe qualifiers for both statements, then we would not know which start date pairs with which end\ndate, for example.\n  - [[c.solution]] A proposed workaround involves adding intermediate nodes to denote different occurrences of quoted triples, but\nthis requires a reserved term \n    - @dean-allemang might say: \"A held position/office isn’t some new thing I am inventing just to get around some deficiency in my modeling system; it’s actually the way people talk about holding public office.\"","n":0.097}}},{"i":6137,"$":{"0":{"v":"Melanie Multi Level Modeling and Ontology Engineering Environment","n":0.354},"1":{"v":"\n- https://www.researchgate.net/publication/262168826_Melanie_multi-level_modeling_and_ontology_engineering_environment\n- author: @colin-atkinson\n- topics: [[prdct.melanie]]","n":0.408}}},{"i":6138,"$":{"0":{"v":"Medium","n":1},"1":{"v":"\n\n\n## [[c.Resource.List]] \n\n- https://javascript.plainenglish.io/top-5-programming-publications-on-medium-e154136bded4\n","n":0.5}}},{"i":6139,"$":{"0":{"v":"Vaticle","n":1}}},{"i":6140,"$":{"0":{"v":"Modelling Time within a Strongly Typed Database","n":0.378},"1":{"v":"\n- url: https://medium.com/vaticle/modelling-time-within-a-strongly-typed-database-55ba91ecad62\n- [[c.mention]] [[ar.a-brief-ontology-of-time]]\n\n## Summary\n\n  - various complexities can arise in modelling time-based data, including:\n    1. Storage and Indexing: How to store time data fields so they can be accessed quickly\n    2. Division and Aggregation: The smallest sensible time increment, and aggregation methods\n    3. Multiple Timelines: Dealing with changing data\n    4. Slowly Changing Dimensions: Classifying responses to temporal data changes\n    5. Temporally Variable Schema and Data: Capturing schema and data changes\n    6. Mining Temporal Relations: Methods of relating times to other times (e.g. before, after etc.)\n  \n\n## Issues\n\n- What is the point of intIndex?\n\n## Highlights\n\n- \"I personally use lists a lot, as well as dicts, for storage in TypeQL, and there are two circumstances:\n\n    I insert an entire list at once, for example, a session in a log with events, and in this case, I use a dummy “stop” value at the end of each list, so it is easy to get.\n    Insert items in a list incrementally, as shown above; in this case, I would match out the index of the current record, add 1 to it (in the client) and insert it in the new list item.\"\n- \"Indexing a single year needs to take account of ~3 x 10¹⁰ unique variations... TypeQL has unique capabilities that enable us to take advantage of this problem since attributes can own other attributes and have unique values. These capabilities enable us to form a composite index on time (a set of buckets using integers), taking the indexing requirement for a single year of microseconds down to 1,188 unique values.\"\n\n\n## Text\n\n\n","n":0.062}}},{"i":6141,"$":{"0":{"v":"Swlh","n":1}}},{"i":6142,"$":{"0":{"v":"Cqrs from Scratch with TypeScript","n":0.447},"1":{"v":"\n- url: https://medium.com/swlh/cqrs-from-scratch-with-typescript-e2ccf7fc2b64\n- #topic [[t.cs.sd.architecture.cqrs]] [[prdct.typescript]]","n":0.408}}},{"i":6143,"$":{"0":{"v":"Ssense Tech","n":0.707}}},{"i":6144,"$":{"0":{"v":"Changing Perspective Embracing Temporal Modeling to Capture the Passage of Time ","n":0.302},"1":{"v":"\n## Summary\n\n- [[t.cs.sd.modeling.uml.class-diagram]], [[t.cs.modeling.entity-relationship-diagram]], and [[t.cs.graph.data-models]] represent a focus on structure, i.e., the things in your system.\n  - they fail to tell the story of how the things were created and evolved\n- [[t.cs.sd.event-storming]] and [[t.pdm.story-mapping]]","n":0.169}}},{"i":6145,"$":{"0":{"v":"Simpplr Technology","n":0.707}}},{"i":6146,"$":{"0":{"v":"Event Driven Architecture the Hard Parts Should It Be Event or a Message","n":0.277},"1":{"v":"\n- url: https://medium.com/simpplr-technology/event-driven-architecture-the-hard-parts-should-it-be-event-or-a-message-95e2b1815718\n\n## Summary\n\n- If two services have to be communicated different data payload, then messages are the way to go.\n- Another situation where you want to use Messages is — if you want to control the sequence of execution in a Workflow. For more details on this type of use case, take a look at this blog [Event Driven Architecture, The Hard Parts : Events Vs Messages](https://medium.com/simpplr-technology/event-driven-architecture-the-hard-parts-events-vs-messages-0fcfc7243703?source=post_page-----95e2b1815718--------------------------------)\n  - \"With Events, because all the consumers react in parallel, controlling the sequence is tough. Messages help to achieve this sequential execution when needed.\"","n":0.104}}},{"i":6147,"$":{"0":{"v":"Sacred Capital","n":0.707}}},{"i":6148,"$":{"0":{"v":"Introducting Neighborhoods","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://medium.com/sacred-capital/introducing-neighbourhoods-a7c577eae4c6\n- [[p.hasSubject]] [[prdct.sacred-capital]] [[prdct.neighborhoods]]\n- [[p.hasHighlight]]\n  - ![[prdct.sacred-capital#^1uVLS5bphpiF]]\n","n":0.333}}},{"i":6149,"$":{"0":{"v":"Plainenglish","n":1}}},{"i":6150,"$":{"0":{"v":"Rest Is Dying Get Rid of It","n":0.378},"1":{"v":"\n\n\n- [[p.hasURL]] https://javascript.plainenglish.io/rest-is-dying-get-rid-of-it-d43e6ef80cbe\n- [[p.hasSubject]] [[prdct.tiger]]\n- [[p.hasTopic]] [[t.cs.web.ajax]] [[t.cs.web.soap]]\n- [[p.hasHighlight]]\n  - \"Some might argue that TIGER Webservices are too “loose” and do not adhere to any “recognized” standard. You’re right, they don’t, and for good reason. I don’t like the standards I’ve seen and used. They suck. So I don’t use them. As an application architect, I write my own. And so can you. You don’t have to use some wonky outdated standard just because everyone else does.\"\n","n":0.114}}},{"i":6151,"$":{"0":{"v":"Onezero","n":1}}},{"i":6152,"$":{"0":{"v":"In the Future Video Games Will Care about You","n":0.333},"1":{"v":"\n- https://onezero.medium.com/in-the-future-video-games-will-care-about-you-2bc852357d0b","n":0.707}}},{"i":6153,"$":{"0":{"v":"Mike Dillinger","n":0.707}}},{"i":6154,"$":{"0":{"v":"The Nature of Knowledge Graph Predicates","n":0.408},"1":{"v":"\n- https://medium.com/@mike.dillinger/the-nature-of-knowledge-graph-predicates-e7cdca00f390\n- author: @mike-dillinger\n\n\n## Types of Predicates, by signature\n\n- category-category\n- instance-category\n- instance-instance\n- category-literal\n- instance-literal\n- fact-fact (meta-facts)\n\n## Types of Predicates, by Grounding\n\n- direct-experience\n- cognition\n- emotion\n- social-relations\n- text\n\n## principle of recursive conceptual decomposition\n\n- concepts are made of concepts, which are also made of (“smaller”) concepts, recursively\n\n## comments\n\n- \"Luckily, WD uses opaque URI, so one day they may decide to change the label to \"is a\" or \"type\" or \"is of type\".","n":0.12}}},{"i":6155,"$":{"0":{"v":"Continuous Knowledge Graphs for Neurosymbolic Ai","n":0.408},"1":{"v":"\n- https://medium.com/@mike.dillinger/continuous-knowledge-graphs-for-neurosymbolic-ai-9000b4aa0eb7\n- author: @mike-dillinger\n\n  - yes, continuous and discrete are often arbitrary... it's a continuous spectrum\n  - distributions are important!\n    - e.g. [EuropeanMales haveHeight (μ=180cm, 𝜎=7cm)]\n  - Graph Neural Networks contribute a range of important techniques in this conversion to continuous-format knowledge graphs.\n  - Continuous knowledge graphs with entities and relations defined and matched along continuous dimensions as well as triples that have properties and grounding measured on continuous scales are a natural fit for mathematical and probabilistic modeling. And an exciting next step to take us beyond the straitjacket of two-valued logic and binary variables that people mistakenly associate with non-numeric knowledge.","n":0.099}}},{"i":6156,"$":{"0":{"v":"Edge Coders","n":0.707}}},{"i":6157,"$":{"0":{"v":"Understanding Node.js Event Driven Architecture","n":0.447},"1":{"v":"\n- [[p.hasURL]] https://medium.com/edge-coders/understanding-node-js-event-driven-architecture-223292fcbc2d\n- ","n":0.577}}},{"i":6158,"$":{"0":{"v":"Dallemang","n":1}}},{"i":6159,"$":{"0":{"v":"Why Im Not Excited about Rdf Star","n":0.378},"1":{"v":"\n- author @dean-allemang\n- url https://medium.com/@dallemang/why-im-not-excited-about-rdf-star-5f1993fd0ead\n- [[p.recommended]] [[book.demystifying-owl-for-the-enterprise]]\n\n## Highlights\n\n- Using RDF-Star simply encouraged poor modeling practice.\n- We abused RDF-Star because we used a facility for making statements about statements to instead make statements about doctor visits or airline flights.\n- \"RDF-Star really is important, because it lets us address a lot of things about data usage that aren’t addressed in most data systems, including graph stores, document stores and relational stores, at all. If we want to know whether we want to trust a datum, a good way to figure that out is to look at its source. RDF-Star will let us do this directly. If we have some confidence in our data (or lack of confidence), we can annotate statements with some measure of confidence; maybe a probability estimate or some fuzzy measure. Temporal and bi-temporal reasoning is important in many situations; RDF-Star provides a way we can represent time scales on statement, in a standard, interoperable way.\"\n- There are probably more creative ways to appropriately use RDF-Star; some that come to mind when modeling policy is jurisdiction; under what jurisdictions is this policy statement valid? For data governance, who is allowed to know the content of this statement?\n- A visit to a doctor’s office isn’t some new thing I am inventing just to get around some deficiency in my modeling system\n  - it’s actually the way I talk to my doctor’s office, and the way they officially communicate with me. \n  - Furthermore, my visit summary includes an indication of the caregiver(s) and all the tests that were taken, along with their results. \n  - The page “Visit Summary” looks a lot like Michael’s model.\n\n## References\n\n- https://www.youtube.com/watch?v=gTMvHJdMnzI","n":0.06}}},{"i":6160,"$":{"0":{"v":"Jug O Cool Things I Do with Rdf","n":0.354},"1":{"v":"\n- written_by: @dean-allemang\n\n## Highlights\n\n- [[prdct.jena]] is good at data formatting\n- [[prdct.topbraid-composer]] has a great tool for visualizing metadata. \n- [[prdct.data_world]] has [[prdct.grafo]] ","n":0.213}}},{"i":6161,"$":{"0":{"v":"Ajmmertens","n":1}}},{"i":6162,"$":{"0":{"v":"Why Vanilla Ecs Is Not Enough","n":0.408},"1":{"v":"\n- url: https://ajmmertens.medium.com/why-vanilla-ecs-is-not-enough-d7ed4e3bebe5\n- author: @sander-mertens\n- related: https://forum.unity.com/threads/why-vanilla-ecs-is-not-enough.928287/","n":0.378}}},{"i":6163,"$":{"0":{"v":"Why It Is Time to Start Thinking of Games as Databases","n":0.302},"1":{"v":"\n- url: https://ajmmertens.medium.com/why-it-is-time-to-start-thinking-of-games-as-databases-e7971da33ac3\n- author: @sander-mertens","n":0.447}}},{"i":6164,"$":{"0":{"v":"Building Games in Ecs with Entity Relationships","n":0.378},"1":{"v":"\n- url: https://ajmmertens.medium.com/building-games-in-ecs-with-entity-relationships-657275ba2c6c\n- [[c.topic]] [[prdct.flecs]]\n- inspiration: prolog\n\n- \"player_2 is a regular entity, which means we can’t know its identifier before running the game. This is different from a regular component, which (in most ECS frameworks) has to be known at compile time. This brings us to the second defining feature of relationships: Relationship pairs can contain regular entities\"\n- \"Queries are treated as a list of nodes. Each node implements a function that can return either true or false. When a node returns true, the query moves on to the next node. When a node returns false, it goes back one node. These kinds of functions are called predicates, and this evaluation process is called backtracking.\"\n  - \"ECS queries on the other hand already use fast data structures for finding entities, and with the few tweaks we discussed here they can be extended to general-purpose query engines for graphs.\"\n\n## References\n\n- https://ajmmertens.medium.com/yep-it-is-i-took-a-lot-of-inspiration-from-prolog-while-i-was-designing-the-query-language-b27667f49e03","n":0.082}}},{"i":6165,"$":{"0":{"v":"Understanding Zettelkasten — What does it mean to communicate with the slip-box","n":0.289},"1":{"v":"\n\n\n- [[p.hasURL]] https://medium.com/@ethomasv/understanding-zettelkasten-d0ca5bb1f80e\n- [[p.hasTopic]] [[t.km.zettelkasten]]\n- [[p.hasAuthor]] @eva-thomas\n","n":0.378}}},{"i":6166,"$":{"0":{"v":"The Way We Are Building Event Driven Applications Is Misguided","n":0.316},"1":{"v":"\n- https://gillesbarbier.medium.com/the-way-we-are-building-event-driven-applications-is-misguided-7f7c5f1a9061\n- topics: [[prdct.infinitic]]\n- based_on: [[prdct.pulsar]]","n":0.408}}},{"i":6167,"$":{"0":{"v":"The Most Common Domain Driven Design Mistake","n":0.378},"1":{"v":"\n- https://medium.com/navalia/the-most-common-domain-driven-design-mistake-6c3f90e0ec2b\n\n## Highlights\n\n- A “Bounded Context” is an area of the business where certain processes and rules apply. It’s where the Central Concept shows up repeatedly under different set of rules that make sense for each Bounded Context, such as:\n\n    Account in banking looks different to Loan Origination vs. Billing vs. Debt Collections vs. Marketing & Communications.\n    Policy in Insurance looks different to Underwriting vs. Claims vs. Inspections.\n    Product in Supply Chain Management looks different to Planning vs. Sourcing vs. Inventory Management vs. Delivery.\n    Reservation in Airlines looks different to Booking vs. Operations vs. Cargo Management vs. Loyalty.\n    Order in eCommerce looks different to Purchasing vs. Supply Chain vs. Fulfillment vs. Customer Support.\n    Customer in eCommerce looks different to Advertising vs. Ordering vs. Shipping.\n- claiming a single view of Accounts goes against the core principles of DDD as it results in an inflexible, bloated Domain Model.\n\n### Unnecessary Coupling\n\nThe first is that the Accounts Bounded Context becomes a ‘God Domain,’ taking on more responsibility than it should. As a result, this creates tight coupling with other Bounded Contexts.\n\n### Decomposition\n\nHere is an example of how we may decompose Accounts into Aggregates within different Bounded Contexts:\n\n![](/assets/images/2024-04-11-22-09-12.png)\n\n\n## Comments\n\n- \"The majority of REST examples tend to be concept oriented, and basically just expose the database as things. This leads to incredibly chatty protocols, and all sorts of problems. When you design the bounded contexts and (REST) APIs around processes it becomes much better. But you also need to toss in CQRS and events to communicate changes between these bounded contexts.\"","n":0.063}}},{"i":6168,"$":{"0":{"v":"The Folgezettel Conundrum","n":0.577},"1":{"v":"\n\n\n- [[p.hasURL]] https://medium.com/@ethomasv/the-folgezettel-conundrum-20b14dc986ec\n- [[p.hasTopic]] [[t.km.zettelkasten]] [[t.km.folgezettel]]\n- [[p.hasAuthor]] @eva-thomas\n\n- [[p.hasHighlight]] \n  - > We have two choices when adding a new note. We can add it to the end and record all possible connections as references. The second choice is to pick one of the related notes and put a new note after it, while recording other possible locations as references.\n","n":0.129}}},{"i":6169,"$":{"0":{"v":"The Clean Architecture Beginner S Guide","n":0.408},"1":{"v":"\n\n![](/assets/images/2022-02-12-14-26-12.png)\n\n \n","n":0.707}}},{"i":6170,"$":{"0":{"v":"Nfigay","n":1}}},{"i":6171,"$":{"0":{"v":"What Is an Ontology in the Artificial Intelligence Context","n":0.333},"1":{"v":"\n- https://medium.com/@nfigay/what-is-an-ontology-in-the-artificial-intelligence-context-b0f935d34aab\n\n## Description\n\n- suggests a Protege-based approach to start experimenting with ontology\n\n\n## Highlights\n\n- OWL is not enough for defining an ontology, it only defines its form, not the content which should be the knowledge on a topic of interest for a community, with establishment of consensus.\n- ","n":0.147}}},{"i":6172,"$":{"0":{"v":"Modelling Data with Hypergraphs","n":0.5},"1":{"v":"\n\n \n- [[p.hasAuthor]] @szymon-klarman \n- [[p.hasURL]] https://blog.vaticle.com/modelling-data-with-hypergraphs-edff1e12edf0)\n\n## [[p.references]]\n\n\\[1\\] [Harold Boley. _Directed recursive labelnode hypergraphs: A new representation-language_. Artificial Intelligence, 9(1), 1977.](https://www.sciencedirect.com/science/article/abs/pii/0004370277900145)\n\n\\[2\\] [Ben Goertzel. _Patterns, hypergraphs & embodied general intelligence_. In IEEE World Congress on Computational Intelligence, 2006.](https://ieeexplore.ieee.org/document/1716127)\n\n\\[3\\] [Borislav Iordanov. _HyperGraphDB: A generalized graph database_. In Proceedings of the Web-Age Information Management Workshop (WAIM2010), 2010.](https://link.springer.com/chapter/10.1007/978-3-642-16720-1_3)\n\n\\[4\\] [Mark Levene and Alexandra Poulovassilis. _An object-oriented data model formalised through hypergraphs_. Data & Knowledge Engineering, 6(3), 1991.](https://www.sciencedirect.com/science/article/abs/pii/0169023X9190005I)","n":0.118}}},{"i":6173,"$":{"0":{"v":"Linked Data Uptake","n":0.577},"1":{"v":"\n- https://kvistgaard.medium.com/linked-data-uptake-7171309d3382\n- related: [[prdct.linked-data-fragments]]\n\n\n## Highlights\n\nAnd yes, web developers still don’t speak RDF but now the number of [JavaScript libraries for RDF](http://rdf.js.org/) is significant and new languages like [LDflex](https://drive.verborgh.org/publications/iswc2020-ldflex.pdf) came to make it easier for them to work with RDF. And since web developers are more comfortable with GraphQL than SPARQL, they can now query RDF also with GraphQL.\n\n[SPARQL is easier than most people think](https://www.strategicstructures.com/?p=1889), and yet it still represents a barrier for them to explore and exploit the growing linked knowledge on the web. But this is changing as well. Now there are ways to query SPARQL endpoints with questions asked in natural language ([QAnswer](https://the-qa-company.com/products/QAnswer), [FREyA)](https://sites.google.com/site/naturallanguageinterfaces/freya).","n":0.097}}},{"i":6174,"$":{"0":{"v":"Jug O Cool Things I Do with Rdf","n":0.354},"1":{"v":"\n- https://medium.com/@dallemang/jug-o-cool-things-i-do-with-rdf-3cdb5b059192\n- author: @dean-allemang\n\n","n":0.5}}},{"i":6175,"$":{"0":{"v":"How to Say Hello","n":0.5},"1":{"v":"\n- https://buckhouse.medium.com/how-to-say-hello-bba906e235d3\n\n## Here’s how to do it.\n\n“Hello” happens with your whole body. To do it well, you’ll need to adjust your voice, your body language, and the _focus_ of your attention.\n\n1.  Your voice: take a deep breath or two to drop your voice down from the squeak of social anxiety to its normal, wonderful, natural register. Your voice doesn’t start in your head, as we might imagine, it starts down between your gut and your heart with the pull of your diaphragm. By the time the air travels all the way up your throat to be shaped by your vocal cords, it already should possess the resonance of your body. Think of your voice as something that starts deep inside of you and gains your best qualities as it makes its way towards the ears of others. Your voice should emanate from your center of gravity, and we should feel it as such, even at a whisper. Your goal is to sound sonorous, not sing-songy or loudmouthed, but, dare I say? **beautiful and cool.**\n2.  Roll your shoulders back to pull your frame upwards and raise your gaze. This will shift your posture from the shape of a question mark to an upside-down exclamation point. You want to your spine look like (¡) not (?).\n3.  Relax your face. You don’t have to smile if your mood doesn’t match it—a fake smile erodes trust—instead, just relax away your leftover facial tensions so you don’t accidentally send an expression of hate or worry or disdain to a person you haven’t yet met. Offer positive potential energy instead, and that energy will get reflected and magnified and sent back to you so that you end up getting more than you put in. Breathe in, and then on the exhale, imagine every muscle in your face hearing the end-of-shift whistle and relaxing and taking a break from work. Or imagine your facial muscles as actors on a stage, where you hear the director shout “Cut!” and everyone relaxes and rejoices. Relax your face to neutral — not dead — just not all tensed up from concerns that others do not share.\n4.  “Hello” happens long before you speak. We can tell from across the room when a salutation might soon occur. Start your hello adjustments (mind, body, voice, attention) sooner than later. A challenge: **can you walk into the room already adjusted?**\n5.  You can uncover something interesting about nearly anyone **_if_** you **converse with curiosity** instead of apathy, greed, mistrust, or resignation. And if you don’t happen to uncover something fascinating about the other person—see this as your fault, not theirs. Why? If you blame others for poor conversations you surrender control and condemn yourself to a lifetime of many miserable, meaningless chats. **But, if you take responsibility for building an interesting conversation,** you’ll learn to adjust what you’re doing so that people will want to have positive interactions with you. Also, people will be more willing to share with you their most interesting ideas if you demonstrate that you can be trusted to handle them with care. This takes effort but makes life more vivid. Author Chuck Palahniuk meets people by the hundreds—sometimes for eight hours straight—at his book signings. He [offers this advice](https://www.amazon.com/Consider-This-Moments-Everything-Different/dp/1538717956) on how to do it well: he attempts to treat each person as if they were the only person he would meet that day.\n6.  If someone asks you “what do you do?” resist the temptation to respond with your job title. Instead, **respond with an “I believe” statement.** Example:  \n\n>“So, Jim, What do you do?”  \n    “ I believe story, art, and design can bend the arc of humanity’s progress, and I try to bring that into everything I do: from movies to startups to paintings to books and to ballets.”  \n\n  A statement of belief will start more interesting conversations than your job title. If the person doesn’t immediately ask a question in return, you can _ask them_ _what they believe_. Compare this to the usual path: if you open with your job title or rank, this sets up a confrontational hierarchy. And if you introduce yourself with something vague, like “finance” or “tech” or “science” or “art” this sends a signal that you don’t really want to talk about it. **Open with an idea**, and the conversation is already interesting before it begins. We crave interestingness over almost all else.\n7.  When you greet someone, look at the other person’s eyes. Do not look at their feet or your feet or the ceiling or the person behind them or your phone or your watch or your elbow or anywhere else. **Eyes to Eyes.** If the other person’s eyes are obscured or missing, direct your gaze towards their face, which will magically line up your voice with their ears.\n8.  After you introduce yourself, ask a question. Listen to their response carefully and ask a question that allows them to develop their idea further. You already know your own ideas, so why not focus on theirs? The conversation will be more fun if you uncover interesting ideas hidden behind the foreheads of others.\n9.  Once someone does tell you something, store it away in your mind for the next time you meet. When you see that person again… a day, a week, a year from now… bring it up—so how was that trip to Spain? I remember it sounded wonderful… And weren’t you about to do something interesting at your Tunnel Drilling Startup?\n10.  And with that… no more boring conversations. No more bad first impressions.","n":0.033}}},{"i":6176,"$":{"0":{"v":"From 3 Layered to Ddd Architecture in One Step","n":0.333},"1":{"v":"\n- url: https://medium.com/@iamprovidence/from-3-layered-to-ddd-architecture-in-one-step-f3de204bec2e\n- [[t.cs.sd.architecture.dependency-inversion]]\n- \"BLL still executes classes in DAL, but DAL depends on BLL.\"","n":0.258}}},{"i":6177,"$":{"0":{"v":"Exploring Advanced Error Handling Patterns with Event Driven Architecture Part I","n":0.302},"1":{"v":"\n- https://medium.com/ssense-tech/exploring-advanced-error-handling-patterns-with-event-driven-architecture-part-i-e2f37741d904\n\n## Conclusion\n\nevent-driven architectures come with the need for more complex error detection and handling.\n\nAssessing whether the trade-off actually pays off is an exercise that you have to do and ultimately your context will dictate if it is the right choice.\n\nIf that is the case for you, then revisit where it is applied and look for signs that you should be adopting a choreographed saga to make those errors visible. Then, determine which errors are transient or permanent to tailor your application and achieve a self-healing status as much as possible.\n\nFinally, be aware that dead letter queues, while helpful, have to be treated as first-class citizens of your application. This means ensuring you actively monitor the DLQs and look for ways to improve your application as each root cause of the message is identified.","n":0.086}}},{"i":6178,"$":{"0":{"v":"Event Storming Black Magic or Real","n":0.408},"1":{"v":"\n- url: https://medium.com/@alexdorand/event-storming-black-magic-or-real-4a7ff000b74c\n\n","n":0.577}}},{"i":6179,"$":{"0":{"v":"Event Sourcing versus Event Driven Architecture","n":0.408},"1":{"v":"\n- [[p.hasURL]] https://medium.com/geekculture/event-sourcing-versus-event-driven-architecture-753aa5a5d0f6\n- ![[t.cs.sd.architecture.event-driven#^973t2iqz9www]]\n","n":0.5}}},{"i":6180,"$":{"0":{"v":"Event Driven Programming in Simulation Games","n":0.408},"1":{"v":"\n- https://krisnamughni24.medium.com/event-driven-programming-in-simulation-games-16cbd266680b\n- topics: [[t.cs.sd.architecture.event-driven]] [[c.game.simulation]]\n\n## Thoughts\n\n- this article makes unsupported claims\n\n## Highlights\n\n- One crucial aspect of creating a captivating simulation game is the implementation of event-driven programming.\n\n### Benefits\n\n- Modular and Extensible Design: Event-driven programming promotes a modular and extensible design approach, where different events and event handlers can be added or modified independently. This design flexibility allows developers to easily introduce new features, expand the game’s functionality, and incorporate additional content. It simplifies the development process, reduces code complexity, and facilitates future updates and enhancements.\n- Event-driven AI and Emergent Behaviors: By leveraging event-driven programming, simulation games can implement intelligent agent systems that respond to events and make decisions based on the game’s rules and objectives. These AI agents can exhibit emergent behaviors, creating complex and unpredictable interactions within the virtual world. This adds depth and replayability to the game, as players can discover new outcomes and strategies based on the interactions between events and AI behavior.\n- Multiplayer Interactions: Event-driven programming is crucial in enabling multiplayer interactions in simulation games. Events triggered by one player can be broadcasted and affect other players in the shared virtual world. This facilitates cooperative or competitive gameplay dynamics, allowing players to collaborate, compete, or interact socially within the simulation game environment.","n":0.07}}},{"i":6181,"$":{"0":{"v":"Design Problem Vs Opportunity","n":0.5},"1":{"v":"\n- [[p.hasURL]] https://medium.com/work-in-progress-thoughts-on-design/design-problem-vs-opportunity-769005fb8e90\n- [[p.hasHighlight]] ","n":0.5}}},{"i":6182,"$":{"0":{"v":"Data Modeling with GunDB","n":0.5},"1":{"v":"\n\n\n- [[p.hasURL]] https://medium.com/@ajmeyghani/data-modeling-with-gundb-15220cbfb8da\n- [[p.hasTopic]] [[prdct.gundb]]\n- seems to use a \"nodes for relationships\" model\n- [[p.hasHighlight]]\n  - GunDB by default creates relationships in one direction and doesn’t force you to define properties for edges.\n","n":0.177}}},{"i":6183,"$":{"0":{"v":"Comparing Linked Data Triplestores","n":0.5},"1":{"v":"\n-  https://medium.com/wallscope/comparing-linked-data-triplestores-ebfac8c3ad4f\n\n\n## Highlights\n\n- AllegroGraph takes an extraordinarily long time to populate. Marklogic is overshadowed by AllegroGraph but still takes 2 minutes to load the data in RDF/XML format!\n- Stardog does not optimise federated queries adequately.\n- Virtuoso has the worst interface.\n\n## Conclusions\n\n* GraphDB for development while you are constructing your application.\n* AnzoGraph or Virtuoso when you move into production if speed is important.","n":0.127}}},{"i":6184,"$":{"0":{"v":"Backend Side Architecture Evolution N Layered Ddd Hexagon Onion Clean Architecture","n":0.302},"1":{"v":"\n- url: https://medium.com/@iamprovidence/backend-side-architecture-evolution-n-layered-ddd-hexagon-onion-clean-architecture-643d72444ce4\n- topics: [[t.cs.sd.architecture]] [[t.cs.sd.ddd]] [[t.cs.sd.architecture.hexagon]] [[t.cs.sd.architecture.clean]]\n- [[p.references]] [[From 3 Layered to Ddd Architecture in One Step|ar.medium.from-3-layered-to-ddd-architecture-in-one-step]]\n- [[p.mentioned]] : [[t.cs.sd.architecture.dci]] [[t.cs.sd.architecture.mvc]] [[t.cs.sd.architecture.bce]] [[t.cs.sd.architecture.onion]] [[t.cs.sd.architecture.hexagon]] [[t.cs.sd.architecture.clean]]","n":0.196}}},{"i":6185,"$":{"0":{"v":"A New Software Architecture Metamodel Inspired by C4 Agile and Togaf","n":0.302},"1":{"v":"\n- url: https://nikolaschou.medium.com/a-new-software-architecture-metamodel-inspired-by-c4-agile-and-togaf-b3f21ab9848\n\n\n## Highlights\n\n- ![](/assets/images/2023-07-25-22-03-08.png)\n- ","n":0.447}}},{"i":6186,"$":{"0":{"v":"5 Reasons Knowledge Graph Will Never Bloom","n":0.378},"1":{"v":"\n- https://dongshengwang.medium.com/5-reasons-knowledge-graph-will-never-bloom-418601957f33\n- topics: [[t.cs.semantic-web]]\n\n## thoughts\n\n- logical and gramatical problems abound, but kernels of truth...\n\n## Four Reasons SW has faded\n\n### RDF Sharing disability\n\n- \"Academic agents have been mainly focused on building their knowledge bases, which are intended to be global datasets. However, these RDF databases often suffer from being hard to understand, outdated, unreliable, and substantially diverse, making it challenging to achieve linked data. As a result, they tend to become another type of local databases.\"\n- \"industrial agents are more realistic and pragmatic, and there is currently no strong incentive for them to widely and effectively transform or share their data as RDF.\"\n  - Many companies display data on the internet in JSON format, which is often sufficient for developers. \n  - Even if some private companies and industries are willing to share their data, they may not want to make the additional effort to publish RDF data since it requires more effort than reward.\n\n### Expensive to consume RDF\n\n- When working with RDF data, it is necessary to first study its schema and parse it into local memory to assemble triples into complete instances. This process is necessary because triples of the same entity can be distributed, and predicates can be arbitrary.\n- Without adopting external RDFs effectively, a local RDF database is not superior to a simple relational database.\n\n### Ontology definition splurging\n\n- too many custom ontologies\n  - t.2024.07.20.08 meh, kinda saying \"too many data models\" \n- understanding a new RDF dataset from an unknown source can take a significant amount of time\n  - t.2024.07.20.08 unavoidable to a degree, but good naming helps\n\n### Expensive to use first-order logic\n\n- inference accuracy remains unsatisfactory and unreliable\n  - first-order logics have not been widely adopted in traditional AI systems, and their reasoning efficiency and effectiveness are questionable.\n  - descriptive logics require high-quality and small-scale data, making it infeasible to scale up to the large amounts of dirty data generated daily.\n  - alternative methodologies such as machine learning models trained on massive datasets can be more effective and efficient than descriptive logics. As a result, first-order logics are expensive and replaceable.\n\n## Five reasons KG will not be thriving\n\n### Entities are hard to be generalized\n\n- I think he means/includes classes?\n- granularity and ambiguity\n\n### Relation splurging and explosion\n\n- relations can become exponentially complex, derived from the simple triple format. To express the natural relations between entities, the knowledge graph often uses compound phrases. However, facing hundreds of relations like song_of, written_by, create_by, is_author_of, build_time, cause_by, has_been_to, and has_visited, humans can become confused by the ambiguity, let alone machines. This is why it is sometimes necessary to define the domain and range if you expect certain relations to belong to specific classes. Consumers must first understand the concept and relation definition of the KG. However, as relations grow from different sources, they become increasingly ambiguous with one another, such as belongs_to, part_of, and included_by.\n\n### Simple triple format leads to higher complexity\n\n- the KG creator, in turn, has to define complex relations with the compound phrase for accurate description\n- \"We should not blame that developers sometimes question would it be more straightforward if we can design a relational database table. When you employ a relational database with a table name called ‘president’, you can easily define the properties that belong only to this table like name, x_th, period, spouse, spouse_period, etc. And this concept oriented design, in general, is more accessible and human-understandable than RDF oriented design.\"\n\n### Hard to access Knowledge Graph as a database\n\n- SPARQL is complicated, \n- triples can be located in different lines or different files and databases.\n- triples are usually not readable due to URIs\n\n### Unreliable quality and generation latency\n\n## Why people still insist it\n\n- KG is currently the most promising technology that shares similarities with human thinking.\n- There are no other alternative technologies that can sustain hope for the next breakthrough, especially after the advancements of deep learning from the connectionism community.\n- We acknowledge that there is a compromise between symbolism researchers and connectionism researchers.\n- Technology media often prioritize propaganda over accountability, and researchers may not face consequences for making grandiose claims.\n\n## Suggestions\n\n- Technically, there is a need to strike a balance between the simplicity of triple formats and the information richness of n-tuple structures in representing knowledge. While technologies like Neo4j are moving in this direction, there is a need for a new standard that involves researchers and developers in defining a schema and n-tuple knowledge that can be easily understood and accessed by both humans and machines.\n- While URI is considered a vital requirement for ensuring global uniqueness, cheaper alternatives could be used instead. For example, universally unique identifier (UUID) is a widely known identifier that can be used to identify entities both locally and globally. UUIDs can ensure that entities from different datasets remain globally unique even when merged. Thus, we can use UUIDs to replace URIs for identifying entities and predicates with little impact.\n\n\n## Comments\n\n- In my career, I've transitioned from Knowledge Graph to Entity Component System - an  [[t.cs.entity-component-system]]can be quickly implemented using existing scalable, robust data technologies (e.g. RDBMS), and components/attributes represented as vectors/columns and matrices/dataframes/tables are more useful in data analysis/science (and other software) contexts.\n- Your analysis makes some points in favor of SQL ontologies and semantic SQL: https://timbr.ai/blog/replacing-relational-sql-with-semantic-sql/","n":0.034}}},{"i":6187,"$":{"0":{"v":"Matching Bfo Dolce Gfo and Sumo an Evaluation of Oaei 2018 Matching Systems","n":0.277},"1":{"v":"\n- url: https://ceur-ws.org/Vol-2519/paper7.pdf\n\n## Conclusion\n\n- This paper presented an analysis of the alignments between four top-level ontologies, BFO, DOLCE, GFO and SUMO. Our goal was to analyse the behaviour of current state of the art tools, which apply diverse matching techniques, with respect to this task. We could observe that matching top-level ontologies automatically is a challenging task, in particular when involving subsumption relations\n- matching systems need to be improved to better exploit the knowledge e","n":0.115}}},{"i":6188,"$":{"0":{"v":"maggieappleton.com","n":1},"1":{"v":"\ncollection of essays; NOT her digital garden\n\n- [[p.hasHighlight]] \n\n","n":0.333}}},{"i":6189,"$":{"0":{"v":"Twitter","n":1}}},{"i":6190,"$":{"0":{"v":"Tools for Thought as Cultural Practices, not Computational Objects","n":0.333},"1":{"v":"\n\nurl: https://maggieappleton.com/tools-for-thought\n","n":0.707}}},{"i":6191,"$":{"0":{"v":"Programming Portals","n":0.707},"1":{"v":"\nurl: https://maggieappleton.com/programming-portals\n\n## Highlights \n  \n### Theoretical Framework\n\n> The theoretical groundwork for why this kind of dynamic, interactive medium is critical to the future of interfaces has been well-trodden by [Bret Victor](http://worrydream.com/). In pieces like [Learnable Programming](http://worrydream.com/LearnableProgramming/) and [Drawing Dynamic Visualizations](https://www.youtube.com/watch?v=ef2jpjTEB5U) Bret outlines a series of principles that make programmatic systems learnable. Such as being able to **read the vocabulary** of a programme, **see the state**, and **create by reacting** to what's on the screen in front of you.","n":0.113}}},{"i":6192,"$":{"0":{"v":"Note Oppression","n":0.707},"1":{"v":"\n\n\n- [[p.hasHighlight]]\n  - > So, who is to blame for our linear, textual predicament?\n    >\n    > The designers who invented the paper-based desktop metaphor that haunts all modern interface design? The users who behave like blind, inconsiderate drunks when presented with any slightly novel note-taking system? The venture capitalists who exclusively fund these predictable apps? The entire educational system for its incessant focus on textual literacy over spatial and visual literacy?\n","n":0.119}}},{"i":6193,"$":{"0":{"v":"Home Cooked Software","n":0.577},"1":{"v":"\n- https://maggieappleton.com/home-cooked-software","n":0.707}}},{"i":6194,"$":{"0":{"v":"Growing the Evergreens","n":0.577},"1":{"v":"\n\n\n- [[p.hasURL]] https://maggieappleton.com/evergreens\n- [[p.hasCreator]] @maggie-appleton\n- [[p.isRelated]] [[t.km.digital-gardening]] [[t.km.evergreen-notes]]\n","n":0.354}}},{"i":6195,"$":{"0":{"v":"Maggie Appleton's Digital Garden","n":0.5},"1":{"v":"\n- [[p.hasURL]] https://maggieappleton.com/garden\n- [[p.instanceOf]] [[c.digitalgarden]]\n","n":0.447}}},{"i":6196,"$":{"0":{"v":"Block Data","n":0.707},"1":{"v":"\n- url: https://maggieappleton.com/block-data\n- ","n":0.577}}},{"i":6197,"$":{"0":{"v":"A Brief History and Ethos of the Digital Garden","n":0.333},"1":{"v":"\n\n\n- [[p.hasURL]] https://maggieappleton.com/garden-history\n- [[p.hasCreator]] @maggie-appleton\n- [[p.isRelated]] [[t.km.digital-gardening]] [[t.km.evergreen-notes]]\n- [[p.references]] [[ar.swyx.learn-in-public]]\n","n":0.316}}},{"i":6198,"$":{"0":{"v":"Macaroons Cookies with Contextual Caveats for Decentralized Authorization in the Cloud","n":0.302},"1":{"v":"\n- https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41892.pdf\n\n## Abstract\n\nControlled sharing is fundamental to distributed systems; yet, on the Web, and in the Cloud, sharing is still based on rudimentary mechanisms. More flexible, decentralized cryptographic authorization credentials have not been adopted, largely because their mechanisms have not been incrementally deployable, simple enough, or efficient enough to implement across the relevant systems and devices. \n\nThis paper introduces macaroons: flexible authorization credentials for Cloud services that support decentralized delegation between principals. Macaroons are based on a construction that uses nested, chained MACs (e.g., HMACs [43]) in a manner that is highly efficient, easy to deploy, and widely applicable. \n\nAlthough macaroons are bearer credentials, like Web cookies, macaroons embed caveats that attenuate and contextually confine when, where, by who, and for what purpose a target service should authorize requests. This paper describes macaroons and motivates their design, compares them to other credential systems, such as cookies and SPKI/SDSI [14], evaluates and measures a prototype implementation, and discusses practical security and application considerations. In particular, it is considered how macaroons can enable more fine-grained authorization in the Cloud, e.g., by strengthening mechanisms like OAuth2 [17], and a formalization of macaroons is given in authorization logic.","n":0.072}}},{"i":6199,"$":{"0":{"v":"Lodifier Generating Linked Data from Unstructured Text","n":0.378},"1":{"v":"\n- https://isabelleaugenstein.github.io/papers/ESWC2012-LODifier.pdf","n":0.707}}},{"i":6200,"$":{"0":{"v":"Lode Linking Open Descriptions of Events","n":0.408},"1":{"v":"\n- https://cidoc-crm.org/sites/default/files/14783A.pdf\n- comparands: [[prdct.cidoc-crm]] [[prdct.abc-ontology]]\n\n## Thoughts\n\n- no reference to UFO-B\n\n## Event Typology\n\n- One potential problem with building these types of classifications into an ontology for modeling things that happened is that they force a knowledge engineer to adopt a particular perspective on what happened.\n  - **Distinctions based on aspect or agentivity are not necessarily inherent to what happened, but instead are rooted in particular interpretations. **\n    - Whether a historical event or a event reported in the news involves an identifiable change or not, or whether agency can be assigned, is often a matter of debate, and its resolution should not be a prerequisite for representing what happened using a concept from an ontology\n    - This desire to separate events from their interpretations is what drives the approach taken by DUL, which provides a Situation concept, instances of which may describe different views or interpretations of the same Event instance. \n    - DUL does specialize its Event concept on the basis of agentivity, providing the Action concept for events that have at least one participating agent and the Process concept for events that are not recognized having participating agents.\n\n### Aspect\n\n- whether the event involved is an ongoing activity or process, or the completion of some activity or transition between states.\n  - OpenCYC defines a concept called Situation and uses aspect to distinguish between two main specializations of this concept: StaticSituation and Event. The former denotes a situation in which some state of affairs has persisted throughout the situation’s interval of time, while the latter denotes a situation in which some change has occurred during the situation’s interval of time.\n  - CIDOC makes a similar but conceptually less clear distinction between two types of E2.Temporal Entity: E3.Condition State and E5.Event. It is less clear because CIDOC also introduces the concept E4.Period, a type of tempo- ral entity that is not static, but does not necessarily involve a change of state. E3.Condition State is also defined narrowly to denote only descriptions of “the prevailing physical condition of any material object or feature” which would seem to exclude descriptions of, for example, the relative state of two things. E3.Condition State is similar to the ABC ontology’s Situation concept, in- stances of which describe the states of tangible things at particular times. The ABC ontology then uses this Situation concept to narrowly define an Event concept as a transition between two different Situation instances. This makes it difficult to describe an event that is characterized by a change in the relationship between two things rather than a change in the state of a single object\n\n### Agent\n\n- OpenCyc and DUL distinguish an Action as a particular type of Event, and CIDOC distinguishes an E7.Activity as a particular type of E5.Event.\n- The ABC ontology also distinguishes an Action concept as something performed by an agent, but rather than being a specialization of the Event concept, it is defined as disjoint with the Event concept, which can “contain” actions via a hasAction property.\n  - Thus the ABC ontology suggests that events are fully described as sets of actions taken by specific agents, which may be an issue for modeling events such as earthquakes.\n\n## Events and Temporal Intervals\n\n- One approach to linking events to ranges of time uses datatype properties, directly relating event instances with RDF literals representing calendar dates (and thus typed using one of the date-related XML Schema datatypes such as xsd:date or xsd:dateTime). Another approach introduces a class for representing temporal intervals, and uses object properties to link event instances with instances of this class. Temporal interval instances can then be linked to calendar values using datatype properties.\n  - ABC, CIDOC, and EO all take the second approach, with ABC and CIDOC introducing classes for temporal intervals, and EO using the TemporalEntity class from OWL-Time \n  - DUL allows both approaches: dates for an event can be directly asserted using the hasEventDate datatype property, or the temporal interval involved can be made explicit by instantiating the TimeInterval class and linking an event instance to it using the isObservableAt object property.\n  - The advantage of associating dates directly with events is simplicity: there are fewer abstractions to deal with, and it is simple to filter or sort events using standard date parsing and comparison routines. This also makes it simple to export lists of events for visualization on a timeline. But the tradeoff for this simplicity is an inability to express more complex relationships to time, such as temporal intervals that do not coincide with date units, or uncertainty about when precisely an event took place within some bounded temporal interval. This is a problem for representing historical events ^gg2de01on63i\n  - By introducing classes for representing temporal intervals, one can use a temporal calculus for reasoning about these more complex relationships. For example, if the precise date of a historical event is not known but some bound- aries can be established within which it must have occurred, the time between these boundaries can be represented as a temporal interval, and a containment relationship can be asserted between that interval and the (unknown) interval during which the event occurred. The drawback to such an approach is that it can be off-puttingly complex as it introduces a number of abstract entities. The problem also arises of how to either mint URIs to identify these entities or deal with the problems introduced by using blank nodes.\n\n## Events, Spaces and Places\n\n- Events can be linked to abstract temporal regions (Section 2.3) and to abstract spatial regions or to semantically significant places\n  - ABC, CIDOC and EO only support linking to spatial regions. \n    - CIDOC provides a class (E53.Place) for “ex- tent in space” to which events can be related via the P7.took place at property. Instances of E53.Place may have names (E44.Place Appellation), but there is no way to link an event to a place name except through a specific spatial ex- tent.\n    - ABC’s Place class also emphasizes spatial location rather than meaningful place\n    - EO’s place property has a range of wgs84:SpatialThing, which is also defined in terms of spatial extent.\n  - Only DUL makes an explicit place/space distinction between Place and SpaceRegion. An event instance can be related to a Place via the hasLocation property, or related to a SpaceRegion via the hasRegion property. ^qs5jaxcn4tai\n    - scholars may wish to indicate that some event is recorded as having occurred at a mythical place. ^718pmntzkrqp\n    - Similar problems are posed by contemporary events which may occur at virtual places such as those found within massive multi-player online environments.\n-  making a clear distinction between named places and spatial regions enables one to deal properly with the phenomenon of places changing their absolute spatial location over time. ^a03j97fonuji\n\n## Participation\n\n\n- ABC defines two types of properties for relating an Event to a tangible thing (an Actuality in ABC parlance). \n  - The involves property does not imply anything beyond simple involvement. \n  - The hasResult property relates an Event to a tangible thing or attribute of a thing which exists as a result of that Event.\n  - ABC also defines various sub-properties of these two properties that further specialize these meanings. For example destroys is a specialization of involves implying that the involved Actuality ceased to exist as a result of its involvement in the Event.\n\n### Object involvement\n\n- ABC defines two types of properties for relating an Event to a tangible thing (an Actuality in ABC parlance). \n  - The `involves` property does not imply anything beyond simple involvement. \n  - The `hasResult` property relates an Event to a tangible thing or attribute of a thing which exists as a result of that Event.\n  - ABC also defines various sub-properties of these two properties that further specialize these meanings. For example destroys is a specialization of involves implying that the involved Actuality ceased to exist as a result of its involvement in the Event.\n- CIDOC defines a property P12.occurred in the presence of, which like ABC’s involves relates an E5.Event to a E77.Persistent Item (endurant) without committing to any implied role for that item beyond simple involvement.\n  - `P12.occurred in the presence of` is the root of a hierarchy of properties expressing more specialized forms of involvement such as P25.moved and P31.has modified. \n  - Unlike ABC’s Actuality, CIDOC’s `E77.Persistent Item` encompasses not only tangible entities but also intangible concepts or ideas, making CIDOC’s P12.occurred in the presence of a broader concept than ABC’s involves.\n- DUL defines a hasParticipant for relating an Event to an Object. Like CIDOC’s E77.Persistent Item, DUL’s Object includes social and mental objects as well as physical ones.\n- EO’s factor property, having no range defined, is similarly broad. \n  - EO also defines a `product` property that, like ABC’s `hasResult`, links an Event to some thing that exists as a result of that Event\n\n### Agent participation\n\n- ABC defines a hasPresence property for weakly asserting that an agent was present at an event without implying that the agent took an active role\n  - It is specialized by the hasParticipant property, which does imply an active or causal role for the agent\n- CIDOC’s equivalent of ABC’s hasPresence is P11.had participant, and its equivalent of ABC’s hasParticipant is P14.carried out by\n- DUL’s involvesAgent property is a specialization of hasParticipant for relating an Event to an Agent. EO provides the agent property for the same purpose.\n- F stands apart from the other ontologies in what it offers for modeling participation. Using DUL, one can assert that a given object or agent participated in an event. F uses the descriptions and situations (DnS) [^3] pattern to enable a further classification of this participation as an instance of some role-based class\n  - e.g.:\n    -  using DUL one might state that the agents Brian Boru and M´ael M´orda mac Murchada participated in the Battle of Clontarf\n    -  Using [[prdct.event-model-f]], one can further state that the Battle of Contarf is classified as a battle, that battles have commanders, and that Brian and M´ael M´orda are classified as commanders.\n-  CIDOC’s P14.1 `in the role of` property provides some support for classifying an agent’s participation in an event as an instantiation of a particular role. However, since it is defined as a property of the P14.carried out by property, it requires the use of OWL Full. \n   -  there does not seem to be a way to associate roles with generic event schemas in the manner described above.\n\n### Events, Influence, Purpose, and Causality\n\n- Both EO and CIDOC provide properties for making broad\nassertions linking events to any relevant thing (tangible or not)\n  - CIDOC defines P15.was influenced by, while EO defines factor.\n  - EO does not distinguish between a thing’s participation in an event and a thing’s influence upon an event, using the same property for both relations.\n\n\n## References\n\n[^3]: [[ar.understanding-the-semantic-web-through-descriptions-and-situations]]\n\n## References\n\n- [[ar.advanced-ontology-topics-events-roles-artifacts]]\n- [[ar.lode-linking-open-descriptions-of-events]]\n- \n","n":0.024}}},{"i":6201,"$":{"0":{"v":"Little Living or Big Living","n":0.447},"1":{"v":"\n- related: [[idea.little-living-is-enough]]\n\n## Highlighs\n\n![[idea.little-living-is-enough#^cwge8fz04hc4]]","n":0.5}}},{"i":6202,"$":{"0":{"v":"Linking Graph Databases and Semantic Web for Reasoning in Library Domains","n":0.302},"1":{"v":"\n- url: http://ircdl2022.dei.unipd.it/downloads/papers/IRCDL_2022_paper_15.pdf\n- [[p.references]] [[prdct.graphbrain]] [[prdct.neo4j]] [[prdct.neo4j.neosemantics]]","n":0.378}}},{"i":6203,"$":{"0":{"v":"Linked Data Basics for Techies","n":0.447},"1":{"v":"\n- https://web-archive.southampton.ac.uk//openorg.ecs.soton.ac.uk/wiki/Linked_Data_Basics_for_Techies.html\n- topics: [[t.cs.data.linked]]\n\n","n":0.5}}},{"i":6204,"$":{"0":{"v":"Linked Data and Time Modeling Researcher Life Lines by Events","n":0.316},"1":{"v":"\n- https://www.researchgate.net/publication/257230986_Linked_Data_and_Time_-_Modeling_Researcher_Life_Lines_by_Events\n- authors: @johannes-trame @carsten-kessler @werner-kuhn\n- topics: [[t.km.knowledge-representation]] [[t.cs.semantic-web.temporal]] [[t.cs.sd.event-modeling]] [[prdct.dolce.dns-ultralite]]\n\n## Highlights\n\n### Introduction\n\n- We propose to build on the event participation pattern from the well founded DOLCE+DnS Ultralite Ontology (DUL)\n- Modeling the act of publishing as an event and separating it from the resulting publication as an information object provides us with a sound basis for temporal reasoning\n\n### Time in Knowledge Representation\n\n- [[t.cs.web.w3c.rdf.open-world-assumption]] and [[t.cs.web.w3c.rdf.monotonicity]] \"make the modeling of time-dependent relationships challenging\"\n- [[t.km.reification]] and [[t.cs.web.w3c.rdf.named-graphs]] have been proposed\n- RDF reification is one of the most confusing and controversial constructs in the RDF specification, also since its meaning differs from the meaning of reification in conceptual modeling (representing n-ary relationships through binary ones) or\nlinguistics (turning a verb into noun) ^yyu4yq3zuw4f\n- Named graphs provide a lightweight but useful extension of the initial design encoding and query languages. Named graphs are widely accepted by the community to provide provenance information and they have been incorporated into the W3C recommendation for SPARQL 1.1.5 Since named graphs are formally subgraphs, they have a clearer syntax and semantics. They are easier to handle and more widely supported by software tools than RDF reification. However, as pointed out by Carroll et al. [6] the semantics are intentionally limited and conform to the basic interpretation of RDF(S) in favor of simplicity. Named graphs are explicitly designed to ease the handling of collections of statements and to attach meta information to those collections, such as provenance or licensing information.\n- In summary, both RDF reification and named graphs can in principle be used to handle temporally varying information by attaching timestamps to single statements [24] or to (sub)graphs [40]. However, as the temporal dimension stays on a meta-level, it has no implication for the model theoretical interpretation and its existence cannot be stated in the vocabulary. \n  - **therefore, named graphs should only be used for temporal information belonging to the meta level, such as provenance data.**\n\n#### Extensions of RDF(S)\n\n- Since both approaches to time are similar to traditional database techniques (time-stamping or temporal versioning), many researchers have taken up that di- rection, trying to provide a model-theoretic account of time. Within the database community, extensive research has been conducted on two notions of time: valid time (when a change occurred in the real world) and transaction time (when a change was entered to the database) [22]. Various proposals adapting the notion of valid time have been made by the Linked Data community, such as tem- poral RDF graphs (temporal reification vocabulary) [16, 15], multidimensional RDF (extended triple notion) [10], applied temporal RDF (named graphs) [43], stRDF (temporal quad) [25], RDF SpatialTemporalThematic (based on tempo- ral graphs) [34], and temporal quintuples [26].\n- These approaches have in common that they either extend the RDF syntax or abuse RDF reification or the context quad in order to “label” a triple with a timestamp. The temporal label is then given a model theoretic interpretation modifying the truth value of the statement. This is done by extending the basic entailment rules of RDF(S) or even by moving to a different logic. However, these approaches are in many respects debatable, as they treat the representation of time as a feature of the encoding language. It is unlikely that all existing software implementations will adapt such syntactic and model theoretic extensions. Moreover, time-stamping triples provides no means to share the underlying conceptual model. We can only see changes between different versions, but we fail to explain where these changes in the real world come from. Finally, it is not clear how the notion of valid time interacts with the Open World Assumption, which supports contradicting statements.\n\n#### n-ary relations\n\n- The natural way to deal with the restriction of binary relations in modeling languages is to use the n-ary design pattern. This approach is also known as conceptual reification of binary relations.\n- The basic idea is to turn a property into a class and link it to the existing classes via two additional properties. Figure 2 shows an example suggested by the organization ontology.6 From a practical point of view, n-ary patterns have been criticized because they increase the number of statements and lead to a proliferation of objects. Additionally, the introduction of new (anonymous) individuals through reified relationships causes a maintenance problem and limits the usefulness of RDF and OWL constructs such as domain and range restrictions or inverse property definitions.\n- The biggest problem, however, is that the potential application scope of the logical n-ary pattern is very broad. The n-ary pattern is often considered as an ad-hoc workaround and thus it is frequently used in an arbitrary fashion, lacking any design rationale.\n\n\n### Foundational Ontologies: Objects and Events\n\n- With its cognitive bias [31], the Descriptive Ontology for Linguistic and Cognitive Engineering7 (DOLCE), fits the need of the Semantic Web as a frame of reference for building domain ontologies [9]. It organizes particulars and axiomatizes them according to a set of meta-properties [14]. While DOLCE is relatively complex in its full extent, lightweight versions are provided and can be extended in a modular fashion, for example DOLCE-Lite-Plus7 or DOLCE+DnS Ultralite (DUL).\n\n#### Linguistic view on time\n\n- Linguists face the problem of how to capture adverbial modifiers (locative, temporal or instrumental) of action sentences in logic. Sentences such as “Johannes wrote a paper with a pen in the library at midnight” result in predi- cates of higher arity, such as write(Johannes,a paper,a pen, the library, midnight), where the number of adjuncts for the predicate can become very large\n- As a solution to this variable polyadicity problem of action modifiers, Davidson [7] proposed that action predicates should explicitly range over an ad- ditional, normally hidden, event argument: ∃e [write(Johannes,a paper,e) ∧ with(e,pen) ∧ in(e,library) ∧ at(e,midnight)]. \n  - This event argument can then be existentially quantified and bound to the whole sentence, whereas each adjunct will be attached as a separate conjunction clause, thus allowing for an arbitrary number of adjuncts.\n  - Parsons [33] advocated to treat the event argument as the only argument of the predicate and link it with a set of thematic roles.\n    - Following the proposal by Parson, the structure of our example can be “. . . replaced by a truly compositional theory of predicates whose fundamental notion is that of event participant and whose fundamental predicates are [thematic roles]” [21, p.444]: ∃e [write(e) ∧ agent(e,Johannes) ∧ location(e,library) ∧ time(e, midnight)].\n  - The decomposition enables one to represent temporal relations directly in first order structures and to reason over them without the need to move, for example, to a temporal or modal logic\n\n#### Ontological Event Theories\n\n- A dualistic view, where objects and events complement each other [41], is re- flected in most upper-level ontologies such as the Basic Formal Ontology (BFO)8 or DOLCE [31].\n- Objects get then located in time through their participation relation in events and events get located in space through their physical participants.\n  - Spatial characteristics have an important func- tion for identifying physical objects as well as for defining their unity criteria. \n  - Temporal characteristics play the same role for events\n- Roles, in particular, depend on events to come into existence. They carry identity criteria, but do not supply them. \n  - neglecting this may lead to the so-called isA-overloading, for example, placing a concept Employee under Person in the taxonomy)\n- Extensive work on the representation of roles has been done by Steimann [42], who presented a list of fifteen different features that may apply to roles. \n  - In this list, @claudio-masolo et al. [32, pp.269–270] identified five characteristics\nthat refer to the dynamic and temporal nature of roles:\n(1) an object can play different roles at the same time\n(2) an object can change its roles\n(3) an object can play the same role for multiple times simultaneously\n(4) some roles can be played by different objects, at the same or different times\n(5) some roles can only be played by an object depending on the previous roles\nit played\n- Masolo et al. [32] argue that the problem with a contextual approach is that the notion of context is still quite fuzzy on its own and one contextual approach may subsume the other. \n  -  Consequently, they suggest to reify roles and separate them from their specification which accounts for the relational and contextual nature of roles. \n  -  This pattern rests on the so called Descriptions and Situations (DnS) extension of DOLCE and is also part of the DUL library.\n-  \n\n### Career Trajectories - Events and Roles\n\n- Event ontologies have gained attention in recent years. Examples include [[prdct.cidoc-crm]] [8], the [[prdct.abc-ontology]] [27] or the CultureSampo project [36], where event- based modeling approaches have proven useful to establish a common conceptual reference frame across applications. \n- the [[prdct.event-ontology]] (EO)9 aims for more generic event modeling pattern\n- The authors of the [[prdct.lode-ontology]], which provides a mapping between different event models, provide a good overview of the differences [39].\n- While LODE and EO do not account for roles, CIDOC CRM [1] realizes roles as properties over properties which cannot be implemented in RDF\n- Most recently, the [[prdct.simple-event-model-ontology]] (SEM) [18] has been proposed, as a light-weight model that is neutral with respect to semantic commitments.\n  - However, all concepts and relations in SEM are undefined primitives that are only informally and weakly specified.  ^hfr5g0mqkqkk\n- we chose [[prdct.dolce.dns-ultralite]]\n  - DUL provides a good combination of flexibility and expressiveness and makes at least the basic distinctions explicit, such as that between events, physical objects and social construction ^y3piqf56xjis\n  - Our approach is similar to the [[prdct.event-model-f]] [37] which also builds on DUL and provides a number of specialized instantiations of descriptions and situations (DnS).\n    -  \"By introducing certain types of events and situations, events can be composed to form more complex situations, such as mereological composi- tions of events or causality relations among events.\" ^uh1jn8phbw3o\n    - \"the F-Event model does not suggest how to distinguish among different kinds of participants in an event.\" ^le51vrhfwetp\n\n### Basic Design Decisions and Alignment to DOLCE+DnS Ultralite\n\n#### Events\n\n- Events unfold over time, which means that they can be located directly in a temporal region.\n  - in DUL, the region values can be directly added to the Event using the hasEventDate property, or the temporal region, such as a TimeInterval, can be separated from the Event and linked via the property isObservableAt, which is a sub-property of hasRegion.\n    - While the former approach is simple on the query and application level, the latter provides a “cleaner” and more flexible solution in representing time values from other calendars\n    - **by representing the interval explicitly, the model could be extended to account for fuzzy temporal intervals** ^2zha3u1eje6w\n- Since the isObservableAt property in DUL is in the domain of Entity (Objects, Events, Qualities, Abstracts), we introduce a new sub-property eventTime, explicitly linking the Event to its region TimeInterval\n  - In order to link the TimeInterval to its region values we introduce the properties hasIntervalStartDate and hasIntervalEndDate ranging over values from the XML date schema.\n    - Both are specializations of the hasIntervalDate and hasRegionDataValue property in DUL\n- Concerning the classification of events, we take a pragmatic approach and link the Event to an EventType which is a subclass of Concept.\n- Since the property isClassifiedBy is the domain of all entities, we introduce a new sub-property eventType with a domain constraint on Event and range constraint on EventTypes\n  - This allows us to dynamically type event concepts from external vocabularies as EventTypes.\n\n#### Participation in Events\n\n- A NaturalPerson in DUL belongs to the category of agentive physical objects because they have intentionality and a proper space region.\n- We specialize the involvesAgent property of DUL by introducing a new property involvesPerson, with domain constraints on Event and range constraints on NaturalPerson\n- ","n":0.023}}},{"i":6205,"$":{"0":{"v":"LDflex a Read Write Linked Data Abstraction for Front End Web Developers","n":0.289},"1":{"v":"\n- https://drive.verborgh.org/publications/iswc2020-ldflex.pdf\n- mentions: [[prdct.comunica]] [[prdct.rdf-js]]\n\n## Abstract\n\nMany Web developers nowadays are trained to build applications with a user-facing browser front-end that obtains predictable data structures from a single, well-known back-end. Linked Data invalidates such assumptions, since data can combine several ontologies and span multiple servers with different apis. Front-end developers, who specialize in creating end-user experiences rather than back-ends, thus need an abstraction layer to the Web of Data that integrates with existing frameworks. We have developed LDflex , a domain-specific language that exposes common Linked Data access patterns as reusable JavaScript expressions. In this article, we describe the design and embedding of the language, and discuss its daily usage within two companies. LDflex eliminates a dedicated data layer for common and straightforward data access patterns, without striving to be a replacement for more complex cases. The use cases indicate that designing a Linked Data developer experience—analogous to a user experience—is crucial for adoption by the target group, who in turn create Linked Data apps for end users. Crucially, simple abstractions require research to hide the underlying complexity.\n\n\n## Highlights\n\n- The difficulty [of making Linked Data accessible to front-end developers] lies in finding an abstraction that hides irrelevant rdf complexities, while still exposing the unbounded flexibility that Linked Data has to offer. Abstractions with rigid objects do not suffice, as their encapsulation tends to conceal precisely those advantages of rdf.","n":0.066}}},{"i":6206,"$":{"0":{"v":"Knowledge Level Integration for Jacamo","n":0.447},"1":{"v":"\n- http://www.meneguzzi.eu/felipe/pubs/care-representation-2014.pdf\n- topics: [[t.km.ontology]] [[t.km.knowledge-representation]] [[t.cs.semantic-web.reasoner]] [[t.cs.multi-agent-system]] \n\n## Abstract\n\nThe specification of agent systems comprises different dimensions normally defined using distinct formalisms. This lack of uniform representations makes it harder to express how each level affects the others. To address this problem, we propose a semantic representation that integrates the formalisms that originally cover a single multi-agent system dimension, such as agency, en- vironment, or social organisation. In doing this, we align current trends in se- mantic technologies and in knowledge representation for agents, environments, and organisations thus providing MAS designers with a unified approach at the knowledge-level for the development of complex systems based on collaborative agents. Our approach uses three ontologies to represent the multi-agent system di- mensions, and we exemplify how separate platforms operating at each dimension can be integrated. We discuss the implications of such integrated view for design- ing agents, and highlight advantages of semantic representations for agent-based software development\n\n\n## Highlights\n\n- there are ontologies to represent the agency [^5], environment [6], and organisation [7]\n\n## References\n\n- [^5]: [[ar.owl-t-a-task-ontology-language-for-automatic-service-composition]]","n":0.076}}},{"i":6207,"$":{"0":{"v":"Justin2004","n":1}}},{"i":6208,"$":{"0":{"v":"Semantic Message","n":0.707},"1":{"v":"\n- https://github.com/justin2004/weblog/tree/master/semantic_messages\n- written-by: @justin-dowdy\n- ","n":0.5}}},{"i":6209,"$":{"0":{"v":"Intuitive Graph Viz","n":0.577},"1":{"v":"\n\n![](/assets/images/2024-09-12-09-31-43.png)\n\n- https://github.com/justin2004/weblog/tree/master/intuitive_graph_viz#readme\n- written-by: @justin-dowdy\n\n\n## Highlights\n\nI think KG viz today is dissapointing because:\n\n    (1) they mostly using circles and lines\n    (2) the layout algorithms (radial, circular, force-directed, etc.) are unaware of what the edges and node types mean\n    (3) they don't have a way to downsample (when rendering a large graph) while preserving the spirit of the meaning of the data\n\n## Thoughts\n\n- \n\n## References\n\n- https://www.reddit.com/r/semanticweb/comments/1f5ytbg/intuitive_knowledge_graph_viz/","n":0.125}}},{"i":6210,"$":{"0":{"v":"JSON-LD and Why I Hate the Semantic Web","n":0.354},"1":{"v":"\n- http://manu.sporny.org/2014/json-ld-origins-2/ (dead)\n  - https://web.archive.org/web/20230524052750/http://manu.sporny.org/2014/json-ld-origins-2/\n\n## Summary\n\nThe desire for better Web APIs is what motivated the creation of JSON-LD, not the Semantic Web. If you want to make the Semantic Web a reality, stop making the case for it and spend your time doing something more useful, like actually making machines smarter or helping people publish data in a way that’s useful to them.\n\n## Highlights\n\n- \"Precious time is spent in groups discussing how we can query all this Big Data that is sure to be published via RDF instead of figuring out a way of making it easy to publish that data on the Web by leveraging common practices in use today. Too much time is spent assuming a future that’s not going to unfold in the way that we expect it to. That’s not to say that TURTLE, SPARQL, and Quad stores don’t have their place, but I always struggle to point to a typical startup that has decided to base their product line on that technology\"\n- \"RDF is a shitty data model. It doesn’t have native support for lists.\" ^m9yunsigu2uc\n\n## Comments\n\n- @ruben-verborgh: \"Isn’t it rather content types/schemas/profiles that we need for interoperability—and that’s it?\"\n  - @manu-sporny: \"Computer/Data scientists have this misguided notion that you need a data model for something to be useful. I believe this notion typically comes from the scientific desire to have things rigorously defined and predictable, which isn’t necessarily a bad thing, but it drives people toward nailing something down before it’s really necessary.\"\n  - @manu-sporny: \"To answer your other questions, no, developers don’t want to transform their JSON properties to URIs just for the sake of doing it. They do want to be able to merge and combine data sources, though. You can have universal meaning without having a rigorously defined data model. For example, just making the JSON properties map to URIs and giving a JSON object and identifier of some kind is enough. You don’t need RDF. That’s all you need to give the object universal meaning, everything else is icing on the cake.\"\n\n\n## References\n\n- https://www.reddit.com/r/programming/comments/38f6b1/jsonld_and_why_i_hate_the_semantic_web/","n":0.054}}},{"i":6211,"$":{"0":{"v":"'Jekyll RDF: Template Based Linked Data Publication with Minimized Effort and Maximum Scalability'","n":0.277},"1":{"v":"\n- https://svn.aksw.org/papers/2019/ICWE_JekyllRDF/public.pdf\n- topics: [[t.cs.data.visualization]] [[t.cs.data.publication]] [[t.cs.web.static-site-generator]] [[t.cs.data.linked]]\n\n\n## Abstract\n\nOver the last decades the Web has evolved from a human– human communication network to a network of complex human–machine interactions. An increasing amount of data is available as Linked Data which allows machines to “understand” the data, but RDF is not meant to be understood by humans. With Jekyll RDF we present a method to close the gap between structured data and human accessible exploration interfaces by publishing RDF datasets as customizable static HTML sites. It consists of an RDF resource mapping system to serve the resources under their respective IRI, a template mapping based on schema classes, and a markup language to define templates to render customized resource pages. Using the template system, it is possible to create domain specific browsing interfaces for RDF data next to the Linked Data resources. This enables content management and knowledge management systems to serve datasets in a highly customizable, low effort, and scalable way to be consumed by machines as well as humans.\n\n## Highlights\n\n### Existing Visualization Applications\n\nA great variety of applications exist to visualize RDF data. Such applications are table based triple explorers, like [[prdct.pubby]], [[prdct.lodview]], and [[prdct.ld-viewer]]/DBpedia Viewer and visual graph explorers like [[prdct.lodlive]], [[prdct.lodmilla]], and [[prdct.linked-data-maps]]\n\nTemplating systems usually provide a flexible approach for inserting data into a scaffolding of an HTML page. The [[SPARQL Web Pages|prdct.sparql-web-pages-uispin]] system defines a templating language that allows to incorporate data from an RDF graph into HTML and SVG documents. It is shipped with the commercial version of the TopBraid Composer. A similar approach is followed by LESS [5] which later was integrated with the [[OntoWiki|prdct.ontowiki]]. The OntoWiki Site Extension allows to render RDF resources in HTML views using a PHP base templating language. To serve the required representation of a Linked Data resources the OntoWiki Linked Data server uses content negotiation to dynamically serve an HTML view to web browsers and an RDF representation to Linked Data systems\n\nA different approach to provide customizable web interfaces to explore and even edit RDF data is presented by Khalili et al. with the [[LD-R|prdct.ld-r]]. It provides a framework to define Linked Data-driven Web Components in JavaScript. With this framework it is possible to reuse existing components and compose new dynamic web interfaces. A similar approach to build Semantic Interfaces for Web Applications is presented with the [[MIRA framework|prdct.mira]] [7]. It defines an abstract interface definition that composes elements to form a hierarchy of widgets. These widgets can be used in JavaScript applications to build responsive user interfaces","n":0.049}}},{"i":6212,"$":{"0":{"v":"Jasss","n":1}}},{"i":6213,"$":{"0":{"v":"Participatory Modeling and Simulation with the Gama Platform","n":0.354},"1":{"v":"\n- url: https://www.jasss.org/22/2/3.html\n- [[c.mention]] [[prdct.cormas]] [[prdct.netlogo]]","n":0.408}}},{"i":6214,"$":{"0":{"v":"BEN an Architecture for the Behavior of Social Agents","n":0.333},"1":{"v":"\n- url: https://www.jasss.org/23/4/12.html","n":0.577}}},{"i":6215,"$":{"0":{"v":"jamesclear.com","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://jamesclear.com/\n- [[p.hasIssue]] bullshitty\n- [[p.hasCreator]] [[James Clear|user.james-clear]]","n":0.354}}},{"i":6216,"$":{"0":{"v":"Inversion","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://jamesclear.com/inversion\n- [[p.hasHighlight]]\n  - Great art breaks the previous rules. \n  - @carl-jacobi made a number of important contributions to different scientific fields during his career. In particular, he was known for his ability to solve hard problems by following a strategy of _man muss immer umkehren_ or, loosely translated, “invert, always invert.” \n  - great headlines and titles use the power of inversion to up-end common assumptions\n    - two of my more popular articles, [“Forget About Setting Goals”](https://jamesclear.com/goals-systems) and [“Motivation is Overvalued”](https://jamesclear.com/power-of-environment)\n  - “What do you want to avoid? Such an easy answer: sloth and unreliability. If you’re unreliable it doesn’t matter what your virtues are. You’re going to crater immediately. Doing what you have faithfully engaged to do should be an automatic part of your conduct.”\n    - [[p.attributedTo]] @charlie-munger\n  - \"Failure Premortem\" aka \"Kill the company\"\n  -   fast forward six months and assume the project or goal has failed. Tell the story of how it happened. \n  - Inversion \n      - forces you to treat your decisions like a court of law.\n      - prevents you from making up your mind after your first conclusion.\n      - a way to counteract the gravitational pull of confirmation bias.\n","n":0.071}}},{"i":6217,"$":{"0":{"v":"Identity Based Habits","n":0.577},"1":{"v":"\n\r\n\r\n- [[p.hasURL]] https://jamesclear.com/identity-based-habits\r\n- [[p.hasTheme]] [[idea.change-is-acheivable]]\r\n## Highlights\r\n\r\n- [[p.hasMetaphor]] behavior change is a three-layered onion: outcomes, process, and (at the core) identity\r\n  - 1. Most goals focus on outcomes, i.e. what you get\r\n  - 2. Changing habits requires changing processes and systems are associated with process, i.e what you do\r\n  - 3. Changing your beliefs, e.g. worldview, self-image, judgments about self and others\r\n- [[p.hasRecipe]] \"Sustained Success\"\r\n  - 1. Decide who you want to be\r\n  - 2. Prove it to yourself with small wins\r\n\r\n\r\n\r\n","n":0.111}}},{"i":6218,"$":{"0":{"v":"The Weird Strategy Dr. Seuss Used to Create His Greatest Work","n":0.302},"1":{"v":"\n\r\n\r\n- [[p.hasURL]] https://jamesclear.com/dr-seuss\r\n- [[p.hasTheme]] [[idea.The-Power-of-Constraints]]\r\n## Highlights\r\n\r\n- [[p.hasMetaphor]] constraints are the size of your canvas\r\n\r\n1. constraints can inspire creativity\r\n   - \"limitations drive you to figure out new solutions\"\r\n2. constraints can inspire activity\r\n  - \"professional set a schedule; amateurs wait for motivation\" \r\n   \r\n","n":0.154}}},{"i":6219,"$":{"0":{"v":"Intfiction","n":1},"1":{"v":"\n- [[p.hasURL]] https://intfiction.org","n":0.577}}},{"i":6220,"$":{"0":{"v":"Interactive Theatre","n":0.707},"1":{"v":"\n- https://press.etc.cmu.edu/file/download/1152/3a22048d-3e41-4533-8d0e-9bceea4fc27f\n\n## Highlights\n\n\n### Participatory Agency\n\nAgency is concerned with the range of actions that are available to the guest. When guests have the capacity to act on their will in some way, choose or make a decision, they have agency. Any restriction on what the guest can do limits their agency. Taken to the extreme, a world with full agency would be a world akin to Westworld (HBO, 2016), where anyone can do anything without limitation by the law, morals or conscience. It is up to the designer of the experience to limit the guest agency such that the experience would still be practical for the showrunner and enjoyable for the guest.\n\n### Reactive, Interactive and Proactive Agency (Astrid Breel)\n\nIn the article “Audience agency in participatory performance”, agency is described as follows: “Agency is concerned with intention and choice, so for a participant to have agency they should intentionally perform an action (however small) that causes something to happen or change within the performance as a result.\n\n### Visualizing Agency\n\n- The different types of agencies differ in the areas they are concerned with, from the type and amount of freedoms and interactions they give guests to the type of consequences that come from guest decisions. This cannot be meaningfully simplified with a one-dimensional axis.\n![](/assets/images/2024-09-29-22-11-31.png)\n\n![](/assets/images/2024-09-29-22-12-25.png)","n":0.069}}},{"i":6221,"$":{"0":{"v":"Integration of the Dolce Top Level Ontology into the ontospec Methodology","n":0.302},"1":{"v":"\n- url: https://arxiv.org/ftp/cs/papers/0510/0510050.pdf\n- ","n":0.577}}},{"i":6222,"$":{"0":{"v":"Instrumenting Multi Agent Organisations with Organisational Artifacts and Agents","n":0.333},"1":{"v":"\n- https://www.researchgate.net/publication/220660654_Instrumenting_multi-agent_organisations_with_organisational_artifacts_and_agents_Giving_the_organisational_power_back_to_the_agents\n- topics: [[t.cs.multi-agent-system]]\n\n## Abstract\n\nReputation is often cited as an instrument to enforce norm compliance: agents that do not follow the norms have their reputation decreased. Conceiving reputation as a collective process, i.e. a kind of shared voices as proposed by Conte & Paolucci, is not a simple task. In this paper, we propose a first step in this direction by instrumenting multi-agent organisation with an artifact that publishes some objective evaluations of the performance of the agents with respect to their be- haviour within the organisation. The members of the organisation can then read these evaluations and build up their reputation of others. The artifact serves thus as an instrument that aid in the building of the rep- utation of the agents. We propose that the evaluation of the agents is not simply based on their obedience to norms, but also considers their pro-activeness and their contribution to the success of collective tasks that are being executed in the organisation. This proposal is detailed and exemplified in the context of the Moise+ organisational model sup- ported by a set of organisational artifacts as proposed in the [[prdct.ORA4MAS]] approach.\n\n## Highlights\n\nWe are thus considering two main mechanisms to implement norm in a MAS:2\n  – Regimentation is a mechanism that simply prevents the agents to perform actions that are forbidden by a norm. More precisely, we regiment some actions in order to preserve important features of the system (e.g. the access to the computers).\n  – Enforcement is a mechanism which is applied after the detection of the violation of some norm. While regimentation is a preventive mechanism, enforcement is a reactive one. From the point of view of the agents, they may decide to obey or not the norm according to their local view of the organisation. From a system point of view, the fulfilled/unfulfilled of the norms should be detected, evaluated as a violation or not, and then judged as worth of sanction/reward or not.\n\n### 3. The Moise+ Organisational Model and Its Artifacts\n\n- proposes an organisational modelling language that explic- itly decomposes the specification of organisation into structural, functional, and [[deontic|t.phil.deontology]] dimensions","n":0.053}}},{"i":6223,"$":{"0":{"v":"Inheritance in Rule Based Frame Systems","n":0.408},"1":{"v":"\n- url: https://www3.cs.stonybrook.edu/~kifer/TechReports/inheritance-in-rbfs.pdf\n- [[p.provokedThoughts]]\n- \"F-logic provides frame-based syntax and semantics. It treats instances, classes,\nproperties, and methods as objects in a uniform way. For instance, in one context,\nthe object ostrich can be viewed as a class by itself (with members such as tweety\nand fred); in a different context, this object can be a member of another class\n(e.g., species). Whether an object functions as an instance or a class depends on\nits syntactic position in a logical statement. F-logic does not require instances\nand classes to be disjoint\"\n","n":0.109}}},{"i":6224,"$":{"0":{"v":"Incorporating Types of Types in Ontology Driven Conceptual Modeling","n":0.333},"1":{"v":"\n- https://nemo.inf.ufes.br/wp-content/papercite-data/pdf/incorporating_types_of_types_in_ontology_driven_conceptual_modeling_2022.pdf\n- authors: @claudenir-fonseca @giancarlo-guizzardi @joao-paulo-almeida @tiago-prince-sales @daniele-porello\n- topics: [[t.cs.sd.modeling.conceptual-modeling.ontology-driven]] [[t.km.ontology.multi-level-theory]] [[prdct.ontouml]]\n- published: t.2022-10\n\n## Abstract\n\nThe Unified Foundational Ontology ([[prdct.unified-foundational-ontology]]) has been used to provide foundations for the major conceptual modeling constructs. So far, UFO has reflected a view in which domain entities are fundamentally divided into those that collect invariants of the domain (i.e., types) and those entities that manifest those invariants (i.e., instances), following the conventional two-level classification scheme. This paper extends UFO with support for multi-level classification schemes, in which some entities accumulate both type-like and instance-like characteristics. This requires an ontological interpretation and a formal theory of types of types. This theory is employed to engineer new constructs and constraints into the OntoUML language, and to develop computational support for the formal verification of constraint violation over multi-level conceptual models.\n\n\n## Highlights\n\n### Introduction\n\n- in a multitude of domains, entities that accumulate both type-like and instancelike characteristics play a central role\n  - e.g.,  in biological taxonomy, the type\nCanis familiaris collects the properties manifested in individual dogs (e.g., having fur,\nbeing quadrupeds) while manifesting itself properties of the type Species (e.g., having\na certain biological origin, having an expected lifespan). In other words, in this domain, we are concerned not only with types of individuals (i.e., first-order types), but also with types of types (i.e., high-order types)\n- This paper extends UFO and then OntoUML with support for multi-level modeling, including an ontological interpretation and formal model of high-order types\n- A distinctive feature of our approach is that, by considering types as endurants, we can account for qualitative changes that these types may undergo in time ^18mad1ssk2w1\n- This means that the UFO ontological categories applicable to types of individual endurants (such as kinds, phases, roles, etc.) [22] also apply to types of types\n  - For instance, in biology, this allows us to account for high-order types such as Endangered Species or Extinct Species as phases, as the very same species can instantiate these types in different situations\n- Treating types as endurants also allows us to account for temporal properties of their existence:\n    - particularly important for types such as social roles, artifactual types, and nominal kinds in general\n\n### Background and Motivation\n\n","n":0.053}}},{"i":6225,"$":{"0":{"v":"Ifwiki","n":1},"1":{"v":"\n- https://www.ifwiki.org","n":0.707}}},{"i":6226,"$":{"0":{"v":"Identitas Semantics Free and Human Readable Identifiers","n":0.378},"1":{"v":"\n- https://content.iospress.com/articles/applied-ontology/ao210252\n- topics: [[prdct.identitas]]\n- ","n":0.5}}},{"i":6227,"$":{"0":{"v":"I Have No Words I Must Design","n":0.378},"1":{"v":"\n- author: @greg-costikyan\n- published: 1994\n- mentioned on \n\n## Highlights\n\n### It's Not a Story\n\nAgain and again, we hear about story. Interactive literature. Creating a story through roleplay. The idea that games have something to do with stories has such a hold on designers' imagination that it probably can't be expunged. It deserves at least to be challenged. Stories are inherently linear. However much characters may agonize over the decisions they make, they make them the same way every time we reread the story, and the outcome is always the same. Indeed, this is a strength; the author chose precisely those characters, those events, those decisions, and that outcome, because it made for the strongest story. If the characters did something else, the story wouldn't be as interesting.\n\nGames are inherently non-linear. They depend on decision making. Decisions have to pose real, plausible alternatives, or they aren't real decisions. It must be entirely reasonable for a player to make a decision one way in one game, and a different way in the next. To the degree that you make a game more like a story -- more linear, fewer real options -- you make it less like a game.\n\nConsider: you buy a book, or see a movie, because it has a great story. But how would you react if your gamemaster were to tell you, \"I don't want you players to do that, because it will ruin the story\"? He may well be right, but that's beside the point. Gaming is NOT about telling stories.\n\nThat said, games often, and fruitfully, borrow elements of fiction. Roleplaying games depend on characters; computer adventures and LARPs are often drive by plots. The notion of increasing narrative tension is a useful one for any game that comes to a definite conclusion. But to try to hew too closely to a storyline is to limit players' freedom of action and their ability to make meaningful decisions.\n\nThe hypertext fiction movement is interesting, here. Hypertext is inherently non- linear, so that the traditional narrative is wholly inappropriate to hypertext work. Writers of hypertext fiction are trying to explore the nature of human existence, as does the traditional story, but in a way that permits multiple viewpoints, temporal leaps, and reader construction of the experience. Something -- more than hypertext writers know -- is shared with game design here, and something with traditional narrative; but if hypertext fiction ever becomes artistically successful (nothing I've read is), it will be through the creation of a new narrative form, something that we will be hard-pressed to call \"story.\" Stories are linear. Games are not.\n","n":0.048}}},{"i":6228,"$":{"0":{"v":"How to Export Your Obsidian Vault to Rdf","n":0.354},"1":{"v":"\n- https://volodymyrpavlyshyn.medium.com/how-to-export-your-obsidian-vault-to-rdf-00fb2539ed18","n":0.707}}},{"i":6229,"$":{"0":{"v":"How Does Knowledge Evolve in Open Knowledge Graphs?","n":0.354},"1":{"v":"\n- url: https://hal.science/hal-04373234/document\n\n## Highlights\n\n- ","n":0.5}}},{"i":6230,"$":{"0":{"v":"Home Cooked App","n":0.577},"1":{"v":"\n- https://www.robinsloan.com/notes/home-cooked-app/\n- author: @robin-sloane\n\n## Highlights\n\nWhen you liberate programming from the requirement to be professional and scalable, it becomes a different activity altogether, just as cooking at home is really nothing like cooking in a commercial kitchen. I can report to you: not only is this different activity rewarding in almost exactly the same way that cooking for someone you love is rewarding, there’s another feeling, too, specific to this realm. I have struggled to find words for this, but/and I think it might be the crux of the whole thing:\n\nThis messaging app I built for, and with, my family, it won’t change unless we want it to change. There will be no sudden redesign, no flood of ads, no pivot to chase a userbase inscrutable to us. It might go away at some point, but that will be our decision. What is this feeling? Independence? Security? Sovereignty?\n\nIs it simply … the feeling of being home?","n":0.081}}},{"i":6231,"$":{"0":{"v":"Hatoeas Is for Humans","n":0.5},"1":{"v":"\n- https://intercoolerjs.org/2016/05/08/hatoeas-is-for-humans.html\n- topics: [[t.cs.web.hateoas]]","n":0.5}}},{"i":6232,"$":{"0":{"v":"Hackernews","n":1}}},{"i":6233,"$":{"0":{"v":"Semantic Web Is like the Guy That Tells Everyone That He Is an Asshole","n":0.267},"1":{"v":"\n- https://news.ycombinator.com/item?id=31890041\n- references: [[ar.arxiv.shacl-a-description-logic-in-disguise]]\n\n## Highlights\n\n- \"The issue with the DL approach to FOL fragments is that the operator-subset approach is too coarse grained. We need something more finegrained that allowes for syntactic and semantic constraints over the specific interpretations and theories. An example of such an approach is stratified negation in datalog. DL would simply ban negation or recursion, but limiting the syntax of datalog programs allows for correct semantics while still allowing solutions for many interesting problems.\"\n\n### Real world knowledge is quite messy\n\n- Real world knowledge is quite messy and riddled with exceptions. \n  - People from cultures without a last name. \n  - A stump is still a tree in the right context, even if it doesn't have a crown. \n  - A character in D&D might have traits that are completely uncommon for their class. \n  - The greek gods for sleep, death or the night sky are both concepts and characters.\n\n### Theory vs Interpretation\n\n- @paul-houle: \"The theory vs interpretation split is another one of those decisions you have to make if you want to do logic: I am on a committee where I'm the guy who speaks for interpretations and the A-Box but some of the other people are serious T-Boxers.\"","n":0.07}}},{"i":6234,"$":{"0":{"v":"Gwern Net","n":0.707},"1":{"v":"\n- [[p.hasURL]] https://www.gwern.net\n- [[p.instanceOf]] [[c.digitalgarden]]\n- [[p.hasHighlight]]\n  - \"Unusual features include the monochrome esthetics, sidenotes instead of footnotes on wide windows, efficient drop caps/​smallcaps, collapsible sections, automatic inflation-adjusted currency, Wikipedia-style link icons & infoboxes, custom syntax highlighting⁠, extensive local archives to fight linkrot, and an ecosystem of “popup”/​“popin” annotations & previews of links for frictionless browsing—the net effect of hierarchical structures with collapsing and instant popup access to excerpts enables iceberg-like pages where most information is hidden but the reader can easily drill down as deep as they wish.\"\n    -  https://www.gwern.net/Design","n":0.105}}},{"i":6235,"$":{"0":{"v":"Gustin Annual Review 2021","n":0.5},"1":{"v":"\n\n\n- initially, liked the focus on [[expansive/contracted|vs.expansive-vs-contracted]]\n  - but is @tim-ferris lame?\n","n":0.289}}},{"i":6236,"$":{"0":{"v":"Guidelines for Writing Definitions in Ontologies","n":0.408},"1":{"v":"\n- https://philpapers.org/archive/SEPGFW.pdf\n- authors: @selja-seppaelae @alan-ruttenberg @barry-smith \n\n## Abstract\n\nOntologies are being used increasingly to promote the reusability of scientific information by allowing heterogeneous data to be integrated under a common, normalized representation. Definitions play a central role in the use of ontologies both by humans and by computers. Textual definitions allow ontologists and data curators to understand the intended meaning of ontology terms and to use these terms in a consistent fashion across contexts. Logical definitions allow machines to check the integrity of ontologies and reason over data annotated with ontology terms to make inferences that promote knowledge discovery. Therefore, it is important not only to include in ontologies multiple types of definitions in both formal and in natural languages, but also to ensure that these definitions meet good quality standards so they are useful. While tools such as Protégé can assist in creating well-formed logical definitions, producing good definitions in a natural language is still to a large extent a matter of human ingenuity supported at best by just a small number of general principles. For lack of more precise guidelines, definition authors are often left to their own personal devices. This paper aims to fill this gap by providing the ontology community with a set of principles and conventions to assist in definition writing, editing, and validation, by drawing on existing definition writing principles and guidelines in lexicography, terminology, and logic.\n\n## Highlights\n\n- a definition has \n  - intention (with its counterpart-in-reality, extension)\n  - form (i.e., the text and maybe accompanying axioms)\n- canonical form: \"X is a Y that Zs\"\n  - Y is genus, i.e., what kind of thing\n  - Z is differentiae/distinguishing features\n- In ontologies, definitions include\n**necessary conditions** that apply to all the members\nof the extension, but which may also apply to\nmembers of other term extensions, and, whenever\npossible, jointly **sufficient conditions**, which allow\na user to determine whether a given entity is a\nmember of the extension","n":0.056}}},{"i":6237,"$":{"0":{"v":"The Guardian","n":0.707}}},{"i":6238,"$":{"0":{"v":"What's the Difference between Drama and Theatre","n":0.378},"1":{"v":"\n- https://www.theguardian.com/stage/theatreblog/2008/jan/09/whatsthedifferencebetweend\n\n## Highlights\n\n- The implication usually is that, while \"theatre\" is a vacuous, commercial or essentially trivial enterprise, Drama transcends theatre's vulgar origins and leaps into Art.\n- There is, in any successful production of even the most uncontroversially play-like play, rather more going on onstage than just the words: there's an entire texture of sound, design and performance and, crucially, there's an audience responding to it.\n  - If drama is just about the writer, then it might as well stay on paper.\n- Critic Hans-Thies Lehmann coined the term \"post-dramatic theatre\" to describe a shift in practice away from a hierarchical model, with the writer (usually a dead writer) at the apex and the director interpreting the writer's \"intention\".\n  - In the post-dramatic theatre, the place of the writer is less easily defined, with the creative emphasis equally existing in the contributions of other theatre-makers. Companies like Holland's Dood Pard are perhaps exemplary of this approach.\n  - But the term has also been applied to the writer-centric theatre of playwrights such as Sarah Kane or Howard Barker. Does this mean these writers are not dramatists?","n":0.074}}},{"i":6239,"$":{"0":{"v":"Gremlin's Time Machine","n":0.577},"1":{"v":"\n- url: https://www.datastax.com/blog/gremlins-time-machine\n- [[c.reference]] [[prdct.gremlin]]\n- [x] review applicability ^4xoa42cc60a0\n  - it's property graphs, and properties on edges are not awesome. for events, better to model Davisonian relations","n":0.192}}},{"i":6240,"$":{"0":{"v":"Glenda Querying Rdf Archives with Full Sparql","n":0.378},"1":{"v":"\n- https://2023.eswc-conferences.org/wp-content/uploads/2023/05/paper_Pelgrin_2023_GLENDA.pdf\n\n## Abstract\n\nAbstract. The dynamicity of semantic data has propelled the research on RDF Archiving, i.e., the task of storing and making the full history of large RDF datasets accessible. However, existing archiving techniques fail to scale when confronted with very large RDF datasets and support only simple SPARQL queries. In this demonstration, we therefore showcase G[[prdct.glenda]]LENDA, a system that can run full SPARQL 1.1 compliant queries over large RDF archives. We achieve this through a multi-snapshot change- based storage architecture that we interface using the [[Comunica|prdct.comunica]] query engine. Thanks to this integration we demonstrate that fast SPARQL query processing over multiple versions of a knowledge graph is possible. Moreover, our demonstration provides different statistics about the his- tory of RDF datasets that can be useful for tasks beyond querying and by providing insights about the evolution dynamics of the data.\n\n","n":0.084}}},{"i":6241,"$":{"0":{"v":"GFO: the General Formal Ontology","n":0.447},"1":{"v":"\n- url: \n  - https://www.researchgate.net/publication/358540259_GFO_The_General_Formal_Ontology\n  - https://drive.google.com/open?id=1-NL_FIdtMTFCUfAqs9ZNQIa1ODtBZsMU&usp=drive_fs\n- authors: @frank-loebe @patryk-burek\n- published: 2022-02\n\n## Philosophy\n\n- It turns out that a top-level ontology being used as a monolithic system is not flexible enough to be easily adopted for particular application areas. Therefore, in the continued development of GFO we pursue a novel approach, organizing the ontology into modules related to ontological regions and their levels.\n- the evolution of foundational ontologies is based on two primary stages of revision, (i) the integration stage and (ii) the expansion and reorganization stage. In the integration stage existing foundational ontologies are compared, interrela- tions between them are studied and ontological mappings between them are established. The expansion and reorganization step consists in the inclusion of new insights from science, society, and nature, and in the creation of new corresponding categories that cannot be reconstructed within the given systems. We call this type of knowledge dynamics the community-driven creative evolution of ontologies\n\n## Details\n\n- GFO distinguishes four modes of being, which are associated with the following ontological regions of the world: the region of material entities, the mental-psychological ontological region, the social region (involving socio-systemic entities), and the region of ideal entities, where the latter includes mathematical entities, idealizations, and ideas.\n-  trichotomy of processes, continuants and presentials. The latter [presentials] can roughly be seen as snapshots of continuants at time points. The trichotomy comes with an integration law.\n-  distinct notions of process and event: Processes form a central category of time-extended, immutable (can't change, but can contain changes) entities in GFO, whereas any event is relative to a process\n- GFO provides a basic classification (ontology) of categories, whereas the notion of category covers all abstract entities that can be instantiated by or are predicated of other entities\n\n### Space and Time\n\n- Space and time are considered as categories, the instances of which are stipulated to be concrete individuals\n  - Time comprises (a.o.) instances called chronoids, which may be understood as closely similar to real-valued intervals with endpoints. \n  - The category Space, called phenomenal space, exhibits space regions as instances of primary importance.\n\n### Concrete Individuals\n\n- there is a difference between a process boundary and a material structure. A material structure, being a snapshot / presential of a material object, contains only those qualities of the object that do not depend on a process. If we consider a moving ball B, then the presential of B at t contains qualities, such as its size, form, color, and mass. The process of the movement of the ball, restricted to a time point t, yields a process boundary that contains further qualities besides those mentioned, including the velocity and acceleration of the object at this time point.\n- processes can never be wholly present at time points, whereas presentials possess this property\n- Processes form a subclass of processual complexes, which are the most general kind of concrete individuals that have a temporal extension. The temporal extension of a processual complex is a mereological sum of a non-empty set of chronoids. Cohesive processes form an important subclass of all processes: a process is cohesive if any two process boundaries are causally connected, if their temporal boundaries coincide\n- Events are temporally localized at time boundaries. \n  - Another(?) type of event is a discrete change, for example, switching on the light in a dark room (understood to happen instantaneously\n  - Histories present a further type of occurrents in that they form a sequence of process boundaries, for example, the sequence of measurements of blood pressure during a certain time interval. They play an important role in the investigation of time series\n- Material situations are parts of the material world (at the macroscopic level) that can be consistently comprehended as a whole.\n  -  We distinguish three kinds of situations: object situations, presentic situations, and situoids. \n     -  Object situations consist of material objects and relations between them. \n     -  A presentic situation is a snapshot of an object situation\n     -  a situoid (or processual situation) is a part of the spatiotemporal world that arises from an object situation if all objects are replaced by the corresponding processes\n        -  An example of a situoid is a football match, happening in time, and including all necessary participating entities, among them the players, the football, the goals and other entities, but also the localization and the corresponding environment(?)\n\n### Complexity and Structure of Individuals\n\n![](/assets/images/2024-03-12-16-29-53.png)\n\n- One type of composition uses dependency relations that glue entities together, another\nuses the part-of relation and the construction of mereological sums\n  - Elementary individuals that are related to other individuals by some kind of dependency relation are called attributives. They include, among others, qualities, relators, roles, functions, dispositions, and structural features\n  - Material objects are wholes consisting of bundles of attributives; furthermore, relational material facts are composed of material objects and relators, and material situations are composed of material facts. \n- for \"We are aware of the problems related to bundle-theory. We agree essentially with the criticism by Gustav Bergmann [1967]\" see [[sh.question-log.2024.03.12#what-are-gustav-bergmanns-criticisms-of-bundle-theory]]\n\n#### Attributives\n\n- an additional perspective on attributives – illustrated in Fig. 2 – has been developed as a foundation for an integrated data semantics\n![](/assets/images/2024-04-05-13-01-16.png)\n  - object attributives are only intrinsic\n    - @chatgpt.4 an extrinsic attributive in programming or data modeling is an attribute of an object that is not inherent to the object itself but is instead derived from its relationship with other objects or external factors. For example, in a virtual role-playing game, consider an object like a 'sword.' Intrinsic attributes might be its weight, length, or material. An extrinsic attributive could be its 'reputation' which might be derived from its history in the game world (like the number of victories it's been used in or who previously owned it). This reputation isn't a physical property of the sword but is attributed to it based on external factors and relationships.\n  - among object attributives we differentiate presentic and non-presentic ones. A presentic object attributive is determined fully and as a whole by the object it inheres in and a time during which itexists. For example, an individual color of red inhering in some object can be wholly accessed at time points.\n  - \"An ontology of attributives contributes to an ontology of data because most data should be understood as the result of measurements of attributives. \"\n- \"A presentic object attributive is determined fully and as a whole by the object it inheres in and a time during which it exists. For example, an individual color of red inhering in some object can be wholly accessed at time points. \"\n  - a presentic object attributive thus gives rise to a continuant, on the one hand, which itself exhibits, at each time point of its lifetime, a wholly present attributive at that time (a presential).\n  - Non-presentic object attributives inhere likewise in objects, but they require something in addition to just their bearer and a time point. For example, the age of an object at a certain point in time is not only determined by that object and that very time point, but it requires something else; say, the initial point in time of the object’s existence.\n  - note that the composition of an object with some of its qualities yields more complex entities, called object facts.\n- Processual attributives have processes and process boundaries as bearers and they are classified into presentic and global attributives. Presentic processual attributives are associated with process bound- aries; they must be wholly accessible at time points. The isolated presentic data of process boundaries do not need any reference to a process; they can be completely reduced to object qualities. These are typical qualities of objects that participate in the process. An example of a non-isolated presentic at- tributive of a process is the velocity of a moving body at a time point (even if it is zero, e.g. as an initial velocity). The velocity cannot be determined and specified without a temporally extended process.\n- The global attributives of processes present the richest class of attributives of processes. A systematic classification of these attributives is in its initial stage. Their main feature is that it is not meaningful to specify or refer to them at a process boundary. One type of global attributives is abstracted from time se- ries in the form of diagrams (such as curve diagrams). Examples are electro-cardiograms and long-term blood pressure measurements.\n  - \" Additionally, we emphasize that intrinsic global attributives of processes are themselves processes, called attributive processes. A clear separation between an attributive process and a corresponding bearer-process needs further investigation and clarification. A water wave, for ex- ample, can be considered as an attributive process that occurs on the basic process of local movements of water particles. This basic process is the bearer of the wave\"\n\n- many other global attributives of a process are not derived from time series. Examples are the duration of a process and its occupied space. \n- There are further kinds of attributives, including relators, roles, functions, and dispositions, which are more abstract than phenomenal attributives; they cannot be directly perceived or measured.\n- GFO adopts the general understanding of a role presented by Frank Loebe [2007], where a role individual is defined as a relational entity that links any entity, called the role player (or filler), with some context, in which the entity plays that role. The notion of role is essential for a broad spectrum of modeling areas, one of which supported by GFO is functional modeling. Its objective is to depict a domain in teleological / functional terms, as contrasted with other aspects, such as structural or behavioral ones.\n  - The notion of function is built upon that of role: we introduce a function as a category that captures a role played by some entity in the context of a goal achievement (GA), where the GA provides a teleological specification of transitioning to something that is intended to be achieved.\n- interfacing between attributives and knowledge occurs through the transformation from facts to propositions, and thus, in general, from data to knowledge. This transformation from a fact (being a part of reality) to a proposition is the (mysterious) pivot of the mind’s ability to transcend the sense-data to achieve a meta-level view on the world. This is an extraordinary ability of the human mind. \n\n\n## Formalization in FOL\n\n- the integration law for objects and processes in GFO: For every material object there exists a uniquely determined process, the temporal extension of which equals the lifetime of the material object, and at every time point of that lifetime of the object the presential exhibited by the object is likewise the process boundary of that associated process (at the very same time point).\n- \n\n### Integration Axiom\n\n- For every material object there exists a uniquely determined process, the temporal extension of which equals the lifetime of the material object, and at every time point of that lifetime of the object the presential exhibited by the object is likewise the process boundary of that associated process (at the very same time point).\n  -  In 4D ontologies, there are only processes, while material objects are considered as particular processes.\n  - \n\n\n## Situation vs Situoid vs Process vs Processual Complex \n\n- Situation: A situation is a static snapshot of reality, representing the state of affairs at a particular point in time. It encapsulates the relationships, properties, and configurations of entities without focusing on their temporal evolution. Situations are used to describe a particular set of circumstances or the way things are arranged at a specific moment.\n\n- Situoid: a generalized or potential situation. It doesn't describe a specific state of affairs at a particular time; instead, it represents a type of situation that could occur under certain conditions. Situoids are useful for modeling hypothetical scenarios, possible states, or conditions that could exist given certain parameters.\n\n- Process: A process, on the other hand, is dynamic and temporal. It refers to a series of events or actions unfolding over time. Processes are characterized by change, development, and the sequence of states they pass through. They emphasize the movement from one state to another and are essential for understanding phenomena that involve transformation or progression.\n\n- Processual Complex: interdependent processes\n\n\n\n\n## References\n\n- [[prdct.gfo]]","n":0.022}}},{"i":6242,"$":{"0":{"v":"General Formal Ontology Gfo a Foundational Ontology Integrating Objects and Processes","n":0.302},"1":{"v":"\n- https://www.onto-med.de/sites/www.onto-med.de/files/files/uploads/Publications/2007/gfo-part1-v1-0-1.pdf\n- authors: @heinrich-herre @barbara-heller @patryk-burek @robert-hoehndorf @frank-loebe @hannes-michalek\n\n\n## Abstract\n\nThis report is a living document of the Research Group Ontologies in Medicine (Onto-Med) which represents work in progress towards a proposal for an integrated system of foundational ontologies. It will be applied to several fields of medicine, biomedicine, and biology, and a number of applications are carried out in collaboration with the Center for Clinical Trials at the University of Leipzig, with the Max Planck-Institute for Evolutionary Anthropology, and with the ICCAS at the University of Leipzig. The General Formal Ontology (GFO) is a component of the Integrated System of Foundational Ontologies (ISFO), and ISFO is a part of the Integrated Framework for the Development and Application of Ontologies (IFDAO). The predecessor of IFDAO was the GOL project which was launched in 1999 as a collaborative research effort of the Institute of Medical Informatics, Statistics and Epidemiology (IMISE) and the Institute of Informatics (IfI) at the University of Leipzig.\n\n## Highlights\n\n### 16 Ontology of the Psychological Stratum\n\nThe psychological stratum has its own structure, it is associated to subjects, sometimes called (particularly in the field of artificial intelligence) agents. We assume that psychological/mental entities have no independent existence, but they are founded on/in material objects. Mental entities emerge out of biological entities and it is an open problem where the borderline should be drawn between material and mental entities. We assume that every human agent has a mental level that divides into two basic components, one is called awareness, the other personality. Awareness is comprised mostly of cognitive science subjects, such as perception, memory, and reasoning. Personality, on the other hand, is primarily concerned with the phenomenon of will, and an individuals’s reaction on her experience. The mental level of a human agent is not isolated from the material world, there is a direct interaction between a human agent and the outside world; this interaction is mediated mainly by perception and the [[phenomenal objects|vs.noumenal-vs-phenomenal-objects]] constructed out of them. We call these phenomenal objects intermediate entities, they may be put to/on the side of the material stratum. Phenomenal objects can be understood as dispositions of physical objects that come to appearence in the mental level of an individual subject.\n\nThese phenomenal entities are the individuals of the medioscopic material stratum that was described and investigated in the preceding sections of the report. Phenomenal individuals constitute the basic for every higher order activities of the mind, for memory, reasoning, language, and communication.","n":0.05}}},{"i":6243,"$":{"0":{"v":"Fuzzy Spatiotemporal Data Modeling and Operations in Rdf","n":0.354},"1":{"v":"\n- https://www.mdpi.com/2078-2489/13/10/503\n- topics: [[prdct.rdf]] \n\n## Abstract\n\nWith the emergence of a large number of fuzzy spatiotemporal data on the Web, how to represent and operate fuzzy spatiotemporal data has become an important research issue. Meanwhile, the Resource Description Framework (RDF) is a standard data and knowledge description language of the Semantic Web and has been applied in many application areas, such as geographic information systems and meteorological systems. In this paper, a model for representing fuzzy spatiotemporal data is proposed and a set of algebraic operations for the model are investigated. First, a representation method of fuzzy spatiotemporal RDF data and a fuzzy spatiotemporal RDF graph model are proposed. In addition, a formal fuzzy spatiotemporal RDF algebra is proposed and a set of algebraic operations for manipulating fuzzy spatiotemporal RDF data are developed. The algebraic operations include: set operation, selection operation, projection operation, join operation, and construction operation. Finally, the existing SPARQL query language is extended and an example that shows how to apply the proposed algebraic operations to capture the queries expressed by the extended SPARQL query language is given.\n\n\n## Highlights","n":0.074}}},{"i":6244,"$":{"0":{"v":"Futureverse Whitepaper","n":0.707},"1":{"v":"\n- https://assets.website-files.com/64b459a54c6aeb0b60898fe2/64b602119dad7b80614b744e_Futureverse%20Whitepaper.pdf\n- mentions: [[prdct.fluf-world]]\n\n## Highlights\n\n\n### Enter the Open Metaverse\n\n- The Open Metaverse is the next evolution\nof the internet and the digital economy;\ndecentralized, trustless, community-owned\nand secure\n\n### Principles\n\n1. An immersive experience: The internet as\nit is, operates within many interconnected\nbut separate siloes. The Metaverse\nremoves the boundaries between the\nmajor categories we currently engage\nwith e.g finance, gaming, social media,\ncommerce. This creates a single\nexperience that encompasses all the\ncurrent features of the internet.\n\n2. Ownership: The Metaverse is defined\nby users having control over their assets,\ndata and transactions. Using open\nsource code with open standards gives\nownership back to users and control back\nto communities. It’s a tug away from\nthe mega-corporations that currently\ncontrol almost all of the digital tangible\nvalue in our lives. In The Metaverse,\nusers own their content, identity, data,\navatar and intelligence that sits behind\nprocesses. They can move freely between\napplications at will","n":0.088}}},{"i":6245,"$":{"0":{"v":"Functional Requirements for Information Resource Provenance on the Web","n":0.333},"1":{"v":"\n- https://link.springer.com/chapter/10.1007/978-3-642-34222-6_5\n- topic: [[prdct.functional-requirements-for-information-resources-frir]]\n- authors: @jamie-mccusker @deborah-mcguinness\n\n\n## Highlights\n\n### The Semiotics of HTTP URLs\n\n![](/assets/images/2024-08-21-12-51-39.png)\n\n-  the document retrieved cannot be defined only as a representation of a resource\n   -  The document can be described in terms of either its content or the set of bytes used to represent it – or both ^w1t3fxtaiozl\n   \n### FRBR and FRIR\n\n![[prdct.frbr#^kph9708t2eod]]\n\n- Functional Requirements for Information Resources5 (FRIR) extends the use of frbr:Work, frbr:Expression, frbr:Manifestation, and frbr:Item to electronic resources, and therefore any information resource. \n- a frbr:Work remains a distinct intellectual or artistic creation. \n  - A frbr:Work corresponds to the Resource or Referent in the semiotic framework discussed above, and is identified by a URL, as was shown in Figure 2\n- frbr:Expression corresponds to a specific set of content regardless of its serialization.\n  - For instance, two files would have the same frbr:Expression if they are the same picture stored in two different formats\n    - t.2024.08.21.15 this is a bit blurry, but a Turtle and JSON-LD could be expressions of the same ontology\n- frbr:Manifestations correspond to a specific bit pattern. If a file is an exact copy of another file, they have the same frbr:Manifestation.\n- An frbr:Item is a specific copy of information stored somewhere or transmitted through a communication link. If a copy of the frbr:Item is made, it results in a new frbr:Item.\n- FRIR also integrates FRBR with the W3C Provenance Ontology (PROV-O) by declaring frbr:Endeavour to be a subclass of prov:Entity and mapping 14 of 18 frbr:relatedEndeavour subproperties as subproperties of one or more of prov:wasDerivedFrom, prov:alternateOf, and prov:specializationOf, as shown in Figure 3.\n\n![](/assets/images/2024-08-21-12-56-17.png)\n\n- As part of FRIR we have identified two levels of cryptographically computable identity: content and message.\n  - Conventional message digests correspond to frbr:Manifestation\n  - content digests correspond to frbr:Expressions\n    - content digests have been developed for RDF graphs, spreadsheets, images, and XML documents that provide the same digest hash regardless of any particular serialization\n\n### Explaining HTTP with FRBR, FRIR, and PROV-O\n\n- n.b.: two identifiers can potentially denote the same thing, e.g. a mirror is the same work\n  - t.2024.08.21.15 it's an interesting case when a single identifier can identify a work, an expression, a manifestation, and arguably an item.\n- We uniquely identify the data streamed over a particular HTTP transaction using the combined message digest of the HTTP header and content.\n- This enables provenance trace assertions to be applied to individual HTTP transactions without having to store the entire transaction.\n\n## Implementation\n\n- https://github.com/timrdf/csv2rdf4lod-automation/wiki/Script:-pcurl.py\n  - uses [[prdct.nepomuk-file-ontology-nfo]]\n","n":0.05}}},{"i":6246,"$":{"0":{"v":"Foundational Ontologies Meet Automatic Theorem Provers","n":0.408},"1":{"v":"\n- url: https://ceur-ws.org/Vol-3249/paper1-FOUST.pdf\n- ","n":0.577}}},{"i":6247,"$":{"0":{"v":"Foundational Ontologies in Action","n":0.5},"1":{"v":"\n- author: @stefano-borgo\n- url:\n  - https://drive.google.com/open?id=1-M83WYA8yDFSL8I4ZmzSgBRmkZ6O5qOI&usp=drive_fs\n  - https://www.academia.edu/80990810/Foundational_ontologies_in_action\n- mentions: [[org.international-association-for-ontology-and-its-applications]]\n- compares: [[prdct.basic-formal-ontology]] [[prdct.dolce]] [[prdct.gfo]] [[prdct.gum]] [[prdct.tupper]] [[prdct.unified-foundational-ontology]] [[prdct.yamato]]\n\n## Thoughts\n\n- Only a programmer would define Red as a literal #FF0000 - That's why LLMs are so great... they support fuzziness.\n\n\n## Highlights\n\n- \"All ontologies recognise the distinction between terms denoting individuals and terms denoting generic covering entities by which individuals may be counted as in some way the “same” – whether these be classes, containing individuals as members (e.g., the class of all cats), concepts by which we group together individuals sharing a salient set of common properties (e.g., the idea of cats in general), or some hard-to-define notion of categories, kinds, or universals to which particular individuals are related as instances (the generic cat)... This was already a topic of concern in mediaeval philosophy, where it showed up as the debate between Realists, for whom universals were real-world entities, and Nominalists, for whom they were merely labels, or concepts, used to impose an intelligible order on reality but not themselves part of that reality. The debate is alive and kicking in modern ontology too, as witness the debate between realism and conceptualism played out in the recent exchange of articles (Merrill, 2010a; Smith and Ceusters, 2010; Merrill, 2010b).\"\n- \"some ontologies (e.g., DOLCE) include a category of abstracts in their taxonomy, whereas others (e.g., BFO) do not. Ontologies of the former kind treat times and places, for example, as abstract entities, whereas for those of the latter, they are regarded as concrete, times being occurrents and places continuants.\"\n- \"Substance vs Accident. In classical logic, an entity’s properties are expressed by means of pred- icates such as “. . . is red”, where the dots represent the fact that, as Frege held, predicates are “unsaturated”. This means that a predicate only expresses a thought when combined with a term denoting an entity that may or may not have the property expressed by the predicate.13 Here prop- erties are not themselves entities and so have no place within an ontology’s taxonomy. But this is not the only possible approach. Instead of seeing “Mars is red”, in Fregean fashion, as the result of applying the predicate “. . . is red” to the name “Mars” (where the latter, but not the former, denotes an individual entity), we could rather see it as the result of applying a relational predicate “. . . is . . . ” to two entity-denoting expressions “Mars” and “red”, so that the thought is of a rela- tion holding between the entities they denote. To complete this picture, though, we must specify what kind of entity “red” denotes, and various possibilities have been explored in the literature. One is that “red” denotes a trope – the individual redness of Mars itself, as distinct from that of, say, the star Antares, even if these are qualitatively identical. Another is to take “red” to denote a universal, the same redness featuring in the thoughts expressed by “Mars is red” and “Antares is red”. A third possibility, used in several ontologies, invokes entities called “qualities”, unique to individuals, such as, for example the colour of Mars and the colour of Antares, and then takes “red” to denote a value that such a quality can assume.\"\n\n### Constitution / Composition\n\n- an ontology may be compatible with different ‘interpretations’ of the given description, leading to the construction of distinct models, each one compatible and aligned with that ontology\n\n### Roles\n\n- In some approaches, a role is a dependent entity that exists only when played by some other entity (e.g., when roles are taken as ‘realisable entities’, like dispositions, as in BFO). In other views, roles may exist also when no entity is playing them (e.g., when roles are taken as concepts as in DOLCE and YAMATO).\n- sometimes an ontology allows one to talk about an entity as player of a role, e.g., a person-as-client in a\nbusiness relationship. In the literature, this special kind of entity is known as a qua-entity\n\n### Qualities of objects and events\n\n- A further level of sophistication is to regard the colour of the flower as an entity distinct from either the flower itself or its redness. The colour is an entity specifically dependent on the flower, and at dif- ferent times it may assume different values. Logically, we might crudely characterise this position as HasColour(flower, colour) ∧ HasValue(colour, red, t)\n- Traditionally, logical analysis has favoured what might be called a ‘snapshot’ view, according to which there is nothing to change over and above the holding of different static states (‘snapshots’) at different times. Against this, many have argued that changes – represented by, for example, processes or events – should be regarded as some kind of entities in their own right, and indeed most of the ontologies here do indeed include a category of occurrents or perdurants to put them in. Despite this, the analyses offered by the papers collected here are for the most part content to represent the change in colour of the flower in terms of the succession of two states of the world, in one of which the flower is red, and in the other, brown.\n- \"How is the value of the individual colour of the flower (if reified) related to whatever is denoted by the names such as ‘red’ and ‘brown’ we use to describe them? The different ontologies exhibit a variety of approaches here, the relationship in question depending on what the references of colour names are taken to be. For BFO and GFO, they are universals and the relationship is ‘instance of’; for DOLCE, they are regions and the relationship is ‘part of’; for UFO they are classes and the relationship is ‘member of’; for YAMATO the relationship given is identity.\"\n- \"For BFO ‘red’ and ‘brown’ denote subclasses of ‘colour’ whereas for DOLCE they are parts of a colour space and for UFO they are members of a class of colour concepts. GFO states that the universal ‘red’, of which the value of the individual flower colour may be an instance, is part of the “value structure” for measuring and depicting colours, but the nature of this value structure is not further specified. In DOLCE, by contrast, with a colour space corresponding to GFO’s value structure, it is clear that, as in item (3), the parthood relation here is that of subregion\"\n- YAMATO models the change as a transition between start and end states but it could also represent colour change as an ongoing process. DOLCE even provides a formula to ensure that the change is continuous across the colour space\n\n### Qualities of events\n\n- \"YAMATO, takes a very different approach, drawing a sharp distinction between events, which are classical occurrents as just described, and processes, which are more continuant-like in the sense that they can change while unfolding... an event is constituted by one or more processes,\"\n\n### Events and Goals\n\n- For BFO a plan is a concretisation of a plan specification whose proper parts include action and objective specifications. The former prescribes a process in which the bearer of the plan (the man) may participate over some interval; this process may or may not achieve the specified objective. In the given scenario the initial plan (walk to the station) is replaced by a new plan (return home) before its objective is achieved.\n- In Yamato, \"processes are treated as ongoing entities capable of undergoing change as they progress. A plan is understood as a representation of a sequence of actions; it is executed by performing a sequence of actions satisfying it, but may be abandoned if only part of the sequence is performed. In the modelled scenario, a walking process is present over an interval. Over some initial subinterval, this process constitutes an uncompleted execution of the plan to walk to the station. After that the process changes so that during an immediately succeeding subinterval it constitutes a turning event. This is followed by a final subinterval over which the process constitutes a completed execution of a plan to go home.\"\n- In DOLCE a plan is modelled as a concept, which is a non-physical endurant. \n- the UFO analysis uses the walker’s intentions, via the notion of intended destination. A walking event cannot change, so the analysis uses an associated endurant Walk which encapsulates the walker’s intention with his capabilities qua walker. In the given scenario, Walk changes from an ‘ongoing walk’, in which the destination has not yet been reached, to a ‘finalised walk’, in which it has.\n\n### Social concept evolution\n\n- In one case, for instance, the ontology recognises that a term persists in the language but not the meaning it denotes. In another reading, the ontology takes the meaning as persisting even though some regulatory aspects of it may change as time goes on. Another way to tackle the use case is by distinguishing the intensional vs. extensional content of the concept: the intensional content of a concept is the set of properties (including their relationships) that defines the concept, the extensional content is the set of instances of the concept\n\n\n- Depending on the ontological view, one can decide to read this case in different ways. In one case, forinstance, the ontology recognises that a term persists in the language but not the meaning it denotes. In another reading, the ontology takes the meaning as persisting even though some regulatory aspects of it may change as time goes on. Another way to tackle the use case is by distinguishing the intensional vs. extensional content of the concept: the intensional content of a concept is the set of properties (including their relationships) that defines the concept, the extensional content is the set of instances of the concept.","n":0.025}}},{"i":6248,"$":{"0":{"v":"Foundational Ontologies from Theory to Practice and Back","n":0.354},"1":{"v":"\n- authors: @maria-keet @zubeida-khan\n- references: [[ar.categories-and-foundational-ontology-a-medieval-tutorial]]\n\n## Abstract\n\nThis is a commentary on the article by Augusto (2022; this issue) on cate- gories and foundation ontology (FO). We agree that the notion of categories of kinds of elements to devise a FO deserves more attention than it has received to date. From a practical point of view sensu developing domain ontologies, however, it probably does not matter much as long as a FO is used and that that one was understood.\n\n\n## Highlights\n\n- A descriptive ontology such as [[prdct.dolce]] allows entities that are dependent on human thoughts and beliefs to be represented while a realist ontology such as [[prdct.basic-formal-ontology]] aims for the representation of entities that are free of that. ","n":0.092}}},{"i":6249,"$":{"0":{"v":"Formal Ontologies and Information Systems","n":0.447},"1":{"v":"\n- https://www.researchgate.net/publication/272169039_Formal_Ontologies_and_Information_Systems\n- author: @nicola-guarino\n\n## Highlights\n\n- In some cases, the term “ontology” is just a fancy name denoting the result of familiar activities like conceptual analysis and domain modelling, carried out by means of standard methodologies. In many cases, however, so-called ontologies present their own methodlogical and architectural peculiarities. On the methodological side, the main peculiarity is the adoption of a highly interdisciplinary approach, where philosophy and linguistics play a fundamental role in analyzing the structure of a given reality at a high level of generality and in formulating a clear and rigorous vocabulary. On the architectural side, the most interesting aspect is the centrality of the role that an ontology can play in an information system, leading to the perspective of ontology-driven information systems.\n- In the philosophical sense, we may refer to an ontology as a particular system of catgories accounting for a certain vision of the world. As such, this system does not depend on a particular language: Aristotle’s ontology is always the same, independently of the laguage used to describe it. On the other hand, in its most prevalent use in AI, an ontology refers to an engineering artifact, constituted by a specific vocabulary used to describe a certain reality, plus a set of explicit assumptions regarding the intended meaning of the vcabulary words. This set of assumptions has usually the form of a first-order logical thory5, where vocabulary words appear as unary or binary predicate names, respectively called concepts and relations. In the simplest case, an ontology describes a hierarchy of concepts related by subsumption relationships; in more sophisticated cases, suitable axioms are added in order to express other relationships between concepts and to constrain their intended interpretation. The two readings of “ontology” described above are indeed related each other, but in order to solve the terminological impasse we need to choose one of them, inventing a new name for the other: we shall adopt the AI reading, using the word [[t.phil.conceptualization]] to refer to the philosophical reading.\n- While ordinary relations are defined on a certain dmain, conceptual relations are defined on a domain space. We shall define a domain space as a structure <D, W>, where D is a domain and W is a set of maximal states of affairs of such domain (also called possible worlds).\n- Consider now the structure <D, R> introduced in [17]. Since it refers to a particular world (or state of affairs), we shall call it a world structure. It is easy to see that a concetualization contains many of such world structures, one for each world: they shall be called the intended world structures according to such conceptualization.\n- In general, there will be no way to reconstruct the ontological commitment of a laguage from a set of its intended models, since a model does not necessarily reflect a paticular world: in fact, since the relevant relations considered may not be enough to copletely characterize a state of affairs, a model may actually describe a situation common to many states of affairs. This means that it is impossible to reconstruct the correspondence between worlds and extensional relations established by the underlying conceptualization. A set of intended models is therefore only a weak characterization of a conceptualization: it just excludes some absurd interpretations, without really describing the “meaning” of the vocabulary.\n- Since every model now carries the information concerning the state of the world it refers to, the undelying conceptualization can be reconstructed from the set of its intended models. In this case, if an ontology is axiomatized in such a way to have exactly the same models, then it would be a “perfect” ontology.\n- Another possibility to increase the accuracy of an ontology consists of either adopting a modal logic, which allows one to express constraints across worlds, or just reifying worlds as ordinary objects of the domain. \n- Of course, there is a tradeoff between a coarse and a fine-grained ontology committing to the same conceptualization: \n  - the latter gets closer to specifying the intended meaning of a vocabulary (and therefore may be used to establish consensus about sharing that vocabulary, or a knowledge base which uses that vocablary), but it may be hard to develop and to reason on, both because the number of axioms and the expressiveness of the language adopted. \n  - A coarse ontology, on the other hand, may consist of a minimal set of axioms written in a language of minimal expressivity, to support only a limited set of specific services, intended to be shared among users which already agree on the underlying conceptualization. We can distinguish therefore between detailed reference ontologies and coarse shareable ontologies, or maybe between off-line and oline ontologies: the former are only accessed from time to time for reference purposes, while the latter support core system’s functionalities.\n- Domain ontologies and task ontologies describe, respectively, the vocabulary related to a generic domain (like medicine, or automobiles) or a generic task or activity (like dianosing or selling), by specializing the terms introduced in the top-level ontology\n- Application ontologies describe concepts depending both on a particular domain and task, which are often specializations of both the related ontologies. These concepts oten correspond to roles played by domain entities while performing a certain activity, like replaceable unit or spare component.\n\n![](/assets/images/2024-04-03-14-12-59.png)\n\n\n- As a final consideration, it may be important to make clear the difference between an application ontology and a knowledge base. The answer is related to the purpose of an otology, which is a particular knowledge base, describing facts assumed to be always true by a community of users, in virtue of the agreed-upon meaning of the vocabulary used. A generic knowledge base, instead, may also describe facts and assertions related to a paticular state of affairs or a particular epistemic state. Within a generic knowledge base, we can distinguish therefore two components: the ontology (containing state-independent iformation) and the “core” knowledge base (containing state-dependent information).\n\n### Ontology-driven Information Systems\n\n- When discussing the impact an ontology can have on an IS, we can distinguish two orthogonal dimensions: a temporal dimension, concerning whether an ontology is used at development time or at run time (i.e., for an IS or within an IS)","n":0.031}}},{"i":6250,"$":{"0":{"v":"Fork My Brain","n":0.577},"1":{"v":"\n- https://notes.nicolevanderhoeven.com/Fork+My+Brain\n- author: @nicole-van-der-hoeven\n- platform: [[prdct.obsidian]]","n":0.408}}},{"i":6251,"$":{"0":{"v":"Fipa_rdf_content_language_specification","n":1},"1":{"v":"\n## Thoughts\n\n- for actions, the action \"verb\" is just a text string\n- foreshadowing of rdf-star:\n\n## Examples\n\n### Belief\n\n```\n  <fipa:Proposition>\n\n    <rdf:subject>TCP/IP Illustrated</rdf:subject>\n\n    <rdf:predicate rdf:resource=\"http://description.org/ schema#author\"/>\n\n    <rdf:object>W. Richard Stevens</rdf:object/>\n\n    <fipa:belief>true</fipa:belief>\n\n  </fipa:Proposition>\n```\n\n### Action\n\n```\n@prefix fipa: <http://www.fipa.org/schemas#> .\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n\n<http://issemantic.net/#JohnAction1> a fipa:Action ;\n    fipa:act \"open\" ;\n    fipa:actor \"John\" ;\n    fipa:argument [ a rdf:bag ;\n            rdf:_1 \"door1\" ;\n            rdf:_2 \"door2\" ] .\n```\n\n","n":0.134}}},{"i":6252,"$":{"0":{"v":"Fictional Realism and Commonsense Ontology","n":0.447},"1":{"v":"\n- url: https://philosophia-bg.com/archive/philosophia-28-2021/fictional-realism-and-commonsense-ontology/\n- author: @adetayo-oludare-alade\n\n## Highlights\n\n- Possibilism maintains that fictional stories represent possible worlds and that fictional entities represent possible entities that constitute these fictional worlds. Fictional possibilism is subtly introduced in Aristotle’s Poetics where he argues that fictional entities represent possible entities which are introduced by authors to present their thoughts about the way things could have been in the world.[4] However, possibilism was advanced by David Lewis who argues that fictional stories present accounts of different possible ways the world could be. Fictional entities are the actual inhabitants  of their relevant worlds, and they have the same ontological status in their relevant worlds as actual objects have in our actual world.\n- creationism/artefactualism: Saul Kripke describes fictional entities as “abstract entities which exists in virtue of the activities of human beings.”\n- **It is important to note that at no point in the process of creating a work of fiction is there any recourse conscious to some kind of doubt about whether the propositions uttered by the author make assertions. As Peter Pagin notes, assertions are speech acts which claims that the truths expressed by a proposition holds true of some aspects of reality.[31] Since the propositions expressed by authors in the making of fictional works are not expected to be literally true of any aspect of reality, these propositions cannot be called assertions.[32] It appears that the disclaimer found in many fictional works, expressly indicating that the content is not about any real entities, stresses the point that authors of fiction are not interested in making assertions in the making of fictional works as well as the consequent introduction of fictional entities.**\n- Some scholars have made some attempts to explain what exactly the author of a fictional work does in introducing fictional characters, if the author is not simply representing reality. For instance, Searle argues that the author is involved in a non-deceptive act of pretence because the author does not intend that his/her audience takes the propositions as literally true. However, considering his realist position, Searle argues that this act of pretence leads to the creation of fictional entities. While engaging the work of fiction, the author also expects the audience to join in the act of pretence.[33] What is not clear from Searle’s account is how an ordinary act of pretence leads to  the creation of real entities. This is a major challenge for Searle and other scholars with similar views, especially within the realist framework. Besides, as Gregory Currie argues, authors of fiction do not seem to be pretending about anything when they create their works. These authors simply create those works and questions about whether they are pretending or not do not arise at any point. As such, they “must be doing something more than merely pretending to assert.”[34]\n- If authors of fiction are not involved in an act of pretence, and they are not making assertions, what exactly are they doing? It is also important to note that the author of a work of fiction simply begins to introduce the characters that make up the fictional work by stipulating certain attributes or properties of these characters. This includes the stipulation of names of human and non-human characters, attributes, plot, setting, etc. This indicates an important aspect of the creative role of authors in the making fictional works and fictional entities. They simply make-up or stipulate those entities and their properties into existence. The tools available for this stipulation are linguistic devices. They include referring expressions, descriptions, etc. What the author does with these tools is to create the fictional entities. This suggests that linguistic tools do not only function to describe reality, they can also serve as ontological tools for creating objects. The idea that linguistic devices can also play ontological roles requires some explanation, but that is beyond the scope of the current paper. Suffice to say at this point that the expressions contained in a fictional work do not describe reality. Rather, these expressions create reality.\n\n## Conclusion\n\n- An appropriate theory of the ontology of fictional entities must be able to account for the fact that authors of works of fiction use linguistic devices, not to make assertions or describe reality, but to create some entities which take on a life of their own once they are thus created.\n- the fictional entity is an abstract entity\n- Given an appropriate realist theory of the ontology of fictional entities, fictional entities exist and any proposition of any ontological theory contrary to this will be false unless there are grounds to prove their truth independently of the uncritical reliance on common sense.","n":0.036}}},{"i":6253,"$":{"0":{"v":"Fiat Objects","n":0.707},"1":{"v":"\n- url: http://ontology.buffalo.edu/smith/articles/fiatobjects.pdf\n- author: @barry-smith\n\n\n## Highlights\n\n- crisp vs scruffy (fuzzy, hazy, indeterminate)\n- fiat vs bona fide\n\n\n## Selections\n\n- A typology of entities  Thetime starting point for our categorial scheme is the  concept of extended entity. Two sorts of extended entity  are distinguished initially: objects, which are extended  in space; and processes, which are extended in time\n- Of course, you and I are in a sense extended not only in space but also in time. But we do not have temporal parts in the sense in which lives and headaches and orbits have temporal parts. This, at least, will be the assumption in what follows – sometimes called the [[t.phil.assumption-of three-dimensionalism]]\n  - [[c.thought]] drawing a distinction between me and my life is unintuitive. \n    - t.2024.10.16.09 nope, I'm more than my life. But I'm still extended in time. Isn't everything Barry?\n![](/assets/images/2023-10-06-10-51-13.png)\n- genuine/\"bona fide\" boundaries vs fiat boundaries : \"exists/does not exist independently of human cognitive acts\"\n- \"Examples of genuine inner temporal boundaries – corresponding to some physical discontinuity or intrinsic qualitative differentiation – might be: the point in the flight of the projectile at which it reaches its maximum altitude and begins its descent to earth, the point in the process of cooling of the liquid at which it first begins to solidify, the point in the splitting of an amoeba when one substance suddenly becomes two. Examples of inner boundaries of the second sort might be: the boundary between the fourth and fifth minute of the race, John’s reaching the age of three, the scheduled time for the beginning of the meeting.\n![](/assets/images/2023-10-06-11-14-30.png)\n  - (bf = bona fide, f = fiat, o = object, p = process, sb = spatial boundary, tb = temporal boundary).\n- Geographic features, along with other features of reality that we encounter at human and non-human scales, have parts at both macro and micro levels of granularity, and when we pay careful atten- tion to the latter then the idea that there are abrupt physical discontinuities begins itself to seem question- able (as though what is a discontinuity were itself a fiat matter).\n- \"imperatives: fiats and directive\"\n- ","n":0.054}}},{"i":6254,"$":{"0":{"v":"Fair versus Open Data a Comparison of Objectives","n":0.354},"1":{"v":"\n- https://direct.mit.edu/dint/article/4/4/867/112737/FAIR-Versus-Open-Data-A-Comparison-of-Objectives\n\n## Abstract\n\nThis article assesses the difference between the concepts of ‘open data’ and ‘FAIR data’ in data management. FAIR data is understood as data that complies with the FAIR Guidelines—data that is Findable, Accessible, Interoperable and Reusable—while open data was born out of awareness of the need to democratise data by improving its accessibility, based on the idea that data should not have limitations that prevent people from using it. This study compared FAIR data with open data by analysing relevant documents using a coding analysis with conceptual labels based on Kingdon's theory of agenda setting. The study found that in relation to FAIR data the problem stream focuses on the complexity of data collected for research, while open data primarily emphasises giving the public access to non-confidential data. In the policy stream, the two concepts share common standpoints in terms of making data available and reusable, although different approaches are adopted in practice to accomplish these goals. In the politics stream, stakeholders with different objectives support FAIR data and from those who support open data.","n":0.075}}},{"i":6255,"$":{"0":{"v":"F—A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite","n":0.302},"1":{"v":"\n- https://www.researchgate.net/publication/220916829_F_-_A_model_of_events_based_on_the_foundational_ontology_DOLCEDnS_ultralite\n- subject: [[prdct.event-model-f]]\n\n![](/assets/images/2024-10-05-09-29-42.png)\n\n## Abstract\n\nThe lack of a formal model of events hinders interoper- ability in distributed event-based systems. In this pa- per, we present a formal model of events, called Event- Model-F. The model is based on the foundational ontol- ogy DOLCE+DnS Ultralite (DUL) and provides com- prehensive support to represent time and space, objects and persons, as well as mereological, causal, and cor- relative relationships between events. In addition, the Event-Model-F provides a ﬂexible means for event com- position, modeling event causality and event correla- tion, and representing diﬀerent interpretations of the same event. The Event-Model-F is developed following the pattern-oriented approach of DUL, is modularized in diﬀerent ontologies, and can be easily extended by domain speciﬁc ontologies\n\n## Highlights\n\n- [[t.cs.sd.architecture.event-driven]] typically focus on processing low-level signals and actions, i.e., technical events that happen within computerized systems\n- this ontology describes high-level occurrences in which humans participate\n- we follow DOLCE+DnS Ultralite’s design decision and distinguish events from objects. \n  - By this, we can be precise about the relationships that can occur between events and objects\n- The most comprehensive list of functional requirements\nare the six aspects defined for the event model E [29]\nand the journalism interrogatives of the Eventory sys-\ntem [28].\n\n\n### Functional Requirements\n\n1. Participation of Objects\n2. Temporal duration\n3. Spatial extension\n4. Structural Relationship\n   1. mereological\n   2. causality\n   3. correlation\n5. Documentary support for events and (participant) objects\n   1. e.g. sensor data, media data\n6. Event Interpretations\n\n## References\n\n- [[ar.lode-linking-open-descriptions-of-events]]","n":0.065}}},{"i":6256,"$":{"0":{"v":"Extending the Foundations of Ontology Based Conceptual Modeling with a Multi Level Theory","n":0.277},"1":{"v":"\n- https://www.researchgate.net/publication/278966828_Extending_the_Foundations_of_Ontology-based_Conceptual_Modeling_with_a_Multi-Level_Theory\n- authors: @victorio-carvalho @joao-paulo-almeida @claudenir-fonseca @giancarlo-guizzardi\n- published: 2015-10 \n","n":0.316}}},{"i":6257,"$":{"0":{"v":"Exposing Agents as Web Services a Case Study Using Jade and Spade","n":0.289},"1":{"v":"\n- url: https://gsigma.ufsc.br/wesaac2019/paper/WESAAC_2019_paper_22.pdf\n- author: @henrique-donancio, @arthur-casals, @anarosa-brand","n":0.378}}},{"i":6258,"$":{"0":{"v":"Exploring the Potential of Large Language Models in Graph Generation","n":0.316},"1":{"v":"\n- Exploring the potential of Large Language models in graph generation\n\n## Abstract\n\nLearning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at [this https URL](https://github.com/CurryTang/Graph-LLM).","n":0.071}}},{"i":6259,"$":{"0":{"v":"Every","n":1},"1":{"v":"\n\n\n- [[p.hasSite]] https://every.to\n\n\n## Recently read\n\n### 2021-12-07\n- [The Three Systems Beneath Network Effects](https://every.to/divinations/the-three-systems-beneath-network-effects)  \n- [Event: $10k Work with Khe Hy](https://every.to/superorganizers/event-10k-work-with-khe-hy)  \n- [Packy McCormick on Web3 (how he got sucked in)](https://every.to/means-of-creation/packy-mccormick-on-web3-how-he-got-sucked-in)  \n- [How Crypto Projects Like Loot are Rewriting the Playbook for Building Communities](https://every.to/means-of-creation/crypto-is-rewriting-the-creator-economy-playbook)  \n- [Legitimacy Lost](https://every.to/means-of-creation/legitimacy-lost)  \n- [You Probably Shouldn’t Work at a Startup](https://every.to/napkin-math/you-probably-shouldn-t-work-at-a-startup-9387b632-345c-4a22-bac0-3cb92f0eecf1)  \n- [NFT Projects are just MLMs for Tech Elites](https://every.to/napkin-math/nft-projects-are-just-mlms-for-tech-elites)  \n- [Becoming a Better Storyteller](https://every.to/masterful-storytelling/becoming-a-better-storyteller)  \n- [Notion vs. Microsoft, Storytelling Tips, and more.](https://every.to/everything/notion-vs-microsoft-storytelling-tips-and-more)  \n- [How I Got My Brain Back](https://every.to/superorganizers/how-i-got-my-brain-back)\n","n":0.11}}},{"i":6260,"$":{"0":{"v":"No Small Plans","n":0.577}}},{"i":6261,"$":{"0":{"v":"Worldview Drift","n":0.707},"1":{"v":"\n* [[p.mentioned]] @henry-david-thoreau, @david-foster-wallace, @Mary-Oliver as ","n":0.408}}},{"i":6262,"$":{"0":{"v":"Napkin Math","n":0.707}}},{"i":6263,"$":{"0":{"v":"The Horny Truth about Ai Chatbots","n":0.408},"1":{"v":"\n- https://every.to/napkin-math/the-horny-truth-about-ai-chatbots\n\n## Takeaways\n\n- Chatbots provide a new, incredibly addictive form of entertainment.\n- We are still grappling with what it means to purchase emotions.\n- The attention economy still reigns supreme.\n\n## Conclusion\n\nWhatever the root cause, loneliness is a real problem, and chatbots may offer a temporary salve. Still, that so much of my research pointed to signs of user addiction and a preference for chatbots over humans is cause for concern. A world where humans depend on AI for emotional connection is probably not a better one.","n":0.108}}},{"i":6264,"$":{"0":{"v":"Distribution Is King","n":0.577},"1":{"v":"\n- https://every.to/napkin-math/distribution-is-king\n- mentions: @mitch-lasky\n- author: @evan-armstrong\n\n## Highlights\n\nNovel product usage patterns? That’s distribution. New pricing models? Also distribution. Building social sharing into the core workflow loop of your app? Distribution. Expanding the capabilities you put into the distribution capability bucket allows for founders to be more innovative.\n\n\n","n":0.147}}},{"i":6265,"$":{"0":{"v":"Means of Creation","n":0.577}}},{"i":6266,"$":{"0":{"v":"Legitimacy Lost","n":0.707},"1":{"v":"\n\n\n- [[p.hasURL]] https://every.to/means-of-creation/legitimacy-lost\n- [[p.hasHighlight]]\n  - platforms all derived their legitimacy from Weber’s three sources listed above: charismatic, traditional, and rational-legal. \n  - platforms exercise near-autocratic control over the creators that frequent their platforms\n  - Patreon, Cameo and Substack have gained traction over the past several years by zeroing in on the monetization component of the problem, offering creators pathways to generating revenue directly from their audiences rather than relying solely on platform-controlled advertising revenue. \n  - it’s not just about money: it’s about agency and autonomy, and having the opportunity to participate in decisions that directly impact your livelihood. i.e., \n    - ownership and portability of data\n    - Participatory decision-making and cooperative business models \n","n":0.093}}},{"i":6267,"$":{"0":{"v":"Masterful Storytelling","n":0.707}}},{"i":6268,"$":{"0":{"v":"Becoming a Better Storyteller","n":0.5},"1":{"v":"\n\n\n- [[p.hasURL]] https://every.to/masterful-storytelling/becoming-a-better-storyteller\n- [[p.hasAuthor]] @katie-parrott\n- [[p.hasHighlight]]\n  - Find your minimal viable story\n    - Person + setting + an outcome that matters (also known as stakes). \n      - Who is the protagonist (maybe it’s you, maybe it’s someone else) \n      - Where and when are they? \n      - What do they want? \n      - Why does the outcome matter? \n  - Dial in the details\n    - “The number one problem with stories is too little detail,” Adam says. “The number two problem is too much detail.”\n    - choose details strategically, ie. to help the reader\n  - Set up your stakes with the Five Whys\n    - ultimately should appeal to a peasant in india 1000 yrs ago\n  - build up your storytelling sensor (in your heart and in your brain)\n    - The very act of feeling like you're a crappy storyteller is a very promising thing\n","n":0.083}}},{"i":6269,"$":{"0":{"v":"Learning Curve","n":0.707}}},{"i":6270,"$":{"0":{"v":"You Re Probably Using Ai Wrong","n":0.408},"1":{"v":"\n- https://every.to/learning-curve/you-re-probably-using-ai-wrong\n- author: @rhea-purohit\n\n## Highlights\n\n- I stopped thinking of LLMs as tools that would write for me. Instead, I started using them to help me with a part of writing I don’t enjoy: being stuck.\n- I like the process of choosing the words I commit to posterity on the internet. I don’t just like it, I cherish it.\n- Examine your lifestyle as an adult, because it is often a tangible manifestation of your internal belief system. If you’re always learning new skills, you value personal growth; if a daily workout feels essential to you, you stand for health; if you prioritize dinners at home, you appreciate a strong family unit. Think about where you spend your resources—time, energy, and money—and you’ll have your answer.","n":0.09}}},{"i":6271,"$":{"0":{"v":"Divinations","n":1}}},{"i":6272,"$":{"0":{"v":"How Ideas Grow","n":0.577},"1":{"v":"\n- url: https://every.to/divinations/how-ideas-grow\n- ","n":0.577}}},{"i":6273,"$":{"0":{"v":"Chain of Thought","n":0.577}}},{"i":6274,"$":{"0":{"v":"Is Chat the Future of Ai","n":0.408},"1":{"v":"\n- url: https://every.to/chain-of-thought/is-chat-the-future-of-ai\n- \"Divergence and convergence, together, are breathing for the creative act. You are constantly breathing in new things and breathing out refinements. If you zoom out, the beginnings of projects are divergent and the ends convergent. But it’s fractal: if you zoom in, within any feature or facet, sentence or stanza, the same thing happens. Ideas flow, and then they are narrowed down.\"\n- \"At the end of the semester, the students who had produced the most pots also produced the highest quality ones. Producing more allowed them to explore the creative territory and learn from their mistakes. Trying for perfection backfired: these students ended up spending too much time agonizing and theorizing, and too little time actually making things.\"","n":0.091}}},{"i":6275,"$":{"0":{"v":"You Are the Technical Cofounder You Need","n":0.378},"1":{"v":"\n- https://every.to/p/you-are-the-technical-cofounder-you-need\n- author: @nir-zicherman\n\n## Highlights\n\n- I know very few non-technical folks who have successfully found an engineer willing to be their partner.\n- While I advise you to stop looking for a technical cofounder and to become one yourself, I cannot stress enough how valuable I believe it is to have a cofounder of some kind working alongside you.\n","n":0.131}}},{"i":6276,"$":{"0":{"v":"Why Are We Surprised That Startups Are so Freaking Hard","n":0.316},"1":{"v":"\n## Highlights\n\n- 'the only enduring moat is effort'\n- \"...building Nvidia turned out to have been a million times harder than I expected it to be, than any of us expected it to be. And at that time, if we realized the pain and suffering, and just how vulnerable you're going to feel, and the challenges that you're going to endure, the embarrassment and the shame, and the list of all the things that go wrong, I don't think anyone would start a company. Nobody in their right mind would do it.\"\n  - @jensen_huang\n- \"The clever plan doesn’t remove the need to compete; it just distracts us from it.\"\n\n### Business Aren't Build on Gimmicks\n\n\"People will be excited about your company because you have that missing piece. They won’t ask you about everything you have to copy to build a great email client, or a new CRM, or the next enduring social network—they’ll ask you about your clever wedge. Tell someone about your cloud-first Alteryx, or your warehouse-native HubSpot, or your dbt-backed Tableau, or your AI-enabled Zendesk, and they’ll want to talk about the cloud-first, warehouse-native, dbt-backed, and AI-enabled parts. And we’ll deceive ourselves into believing those are the important parts. But all the work is in building the unremarkable features and business processes that Alteryx, HubSpot, Tableau, and Zendesk already have.\n\nBecause big businesses aren’t built on gimmicks. You can blitz your way through Sand Hill Road and spike up the App Store charts on gimmicks, but you can’t actually use them to replace Gmail, or Salesforce, or Instagram, or Instagram, or Instagram, or Instagram. Even seemingly instant successes can’t become lasting companies without putting in the work—developing checkbox features, building enterprise sales motions, creating support escalation policies, arguing about sales compensation strategies, defining career ladders, preparing for board meetings, negotiating office leases, hiring lawyers, changing lawyers, dealing with Trinet, helping employees deal with Trinet, responding to investor emails about trendy but useless features that nobody will ever want unless they only want to be a part of the latest fad, setting up the office Wi-Fi, fixing the office Wi-Fi, yelling at Comcast Business about the office Wi-Fi, emailing customers about your new pricing model, redoing your all-hands format, introducing and re-introducing OKRs, and a list of 100 other mundane things that every single one of us overlooks in pitch decks\"\n\n## Conclusion\n\nI don’t think it’s a coincidence that the companies that have a reputation for building the best products of this generation—Slack, Figma, Superhuman, Notion, and Linear—are basically new versions of successful predecessors. These companies didn’t distract themselves with four-step strategic maneuvers or clever wedges into a new category that they claimed to be creating. They took on the challenge directly instead—built a better Hipchat, or Illustrator, or Gmail, or Google Docs, or Asana. They knew they’d have to do it eventually, and rather than pretend that they could avoid it, they started with that plan. The strategy was to do the work.\n\n```yaml\nauthor: @benn_stancil\ndescription: \"You don't need a clever idea to build a great company.\"\n\n```\n","n":0.045}}},{"i":6277,"$":{"0":{"v":"To Go 0 to 1 First Go -1 to 0","n":0.316},"1":{"v":"\n- url: https://every.to/p/to-go-0-to-1-first-go-1-to-0\n\n## Highlights\n\n- \"-1 to 0 is when you figure out what you want to work on. It’s when you decide where to allocate the next 5-10 years of your life.\"\n- \"-1 to 0 is about founder-market fit. Figure out what you want to build and why you are the right person to build it before you start.\"\n- conviction/proof points: the thing you build, the story you tell about the problem it solves, and why you are the right person to build that solution\n  - \"Weakness in any of these proof points makes it harder to convince the constituencies whose belief you need in the early stages—customers, recruits, investors, yourself. The less proof you have, the more likely that you are stuck in a local maximum. You might have built a product that 100 users love with no larger market opportunity, or found a market opening without a potential product solution, or lack the founder-market fit to survive the company-building gauntlet.\"\n- -1 to 0 isn’t a break or a stage you should rush. You only get a few shots at building your life’s work—so make them count.","n":0.073}}},{"i":6278,"$":{"0":{"v":"The Three Systems beneath Network Effects","n":0.408},"1":{"v":"\n- #copy [[email.the-three-systems-beneath-network-effects]]\n- [[p.hasHighlight]]\n  - “Acquisition Effect”:: the ability for a product to tap into its network to acquire new customers\n  - “Engagement Effect”:: a denser (or more diverse) network creates higher stickiness and/or new use cases\n  - “Economic Effect”:: the ability for a networked product to accelerate its monetization, reduce its costs, and otherwise improve its business model, as its network grows\n","n":0.126}}},{"i":6279,"$":{"0":{"v":"The Long Conversation","n":0.577},"1":{"v":"\n- author: @rachel-jepsen","n":0.577}}},{"i":6280,"$":{"0":{"v":"The Great Contemplation","n":0.577},"1":{"v":"\nauthor: @paul-millerd\n\nIf Tim Ferriss’s [_4-Hour Workweek_](https://www.amazon.com/4-Hour-Workweek-Escape-Live-Anywhere/dp/0307465357) kickstarted the “first wave” of the post-industrial reimagination of work in 2007, 2022 was the year that a newer, and weirder, second wave began. \n\nUnlike the first wave, which largely played out at the individual level, this one is happening at the societal level. While it is still early, this “great contemplation,” as I’ve been calling it, will likely shape the work stories that people use to orient their lives over the coming decade. \n\nFerriss offered a powerful alternative script that inspired millions around the world to escape the default path, travel the world, take mini-retirements, start businesses, and take breaks from work. However, these people embraced their new paths in direct opposition to the 20th-century industrial economy “organization man” paradigm that still had a strangle-hold over the popular imagination, well into the 2010s. Even if you followed Ferriss’s playbook and found a path you enjoyed, it was likely that many people in your life still thought you were a bit crazy (raises hand). This is what drew people to leave cities organized around big companies and full-time work to escape to nomadic communities around the world, like Bali; Chiang Mai, Thailand; Medellin, Colombia; and Las Palmas, Spain.\n\nAs the worst blows of the pandemic have receded, people who seemed committed to traditional employment and working for big companies have started to soften their attachment to traditional work scripts. This has encouraged many digital nomads, the early adopters of work norms, including myself, to return “home,” noticing that the vibe really has shifted. It was telling that in a visit to Lisbon earlier this year, most of the scrappy digital nomads had been replaced with well-paid full-time workers who were flexing their increased freedom and driving up the cost of rent. \n\nAs someone who quit my job and walked away from a promising and well-paid strategy consulting path more than five years ago, and has been making a living while self-employed, it is jolting to experience people shifting from mocking my lifestyle to asking how they might, too, claim a little more freedom. I’ve had a unique front-row seat to this shift, having been obsessed with our collective relationship to work soon after leaving my full-time job in 2017. I was fascinated by how different being self-employed felt compared to the first 32 years of my life, which had been oriented around school, employment, and a steady stream of goals and achievements. \n\nI was so hungry to talk to anyone about what I was experiencing that I decided to put an open booking link on my website for “curiosity conversations” every Wednesday. Over the next couple of years, I talked to hundreds of people from dozens of countries, and they told me how they felt about work with raw honesty. I was surprised at how consistent issues were across countries, industries, and even socioeconomic status. People told me that they felt trapped, uninspired, stuck, and hopeless, and that they desired a better relationship to work but didn’t know what to do. The most shocking thing was how many people told me they hadn’t even told this to a single person in their life, not even their spouses. Just me—a stranger on the internet.\n\nThis “secret knowledge” fueled my writing, and in 2020, the world seemed to catch up. In April 2020, my calendar was full each week with seven or eight calls. Suddenly, everyone wanted to talk about work. Some of my friends made dramatic changes in their lives that I never would have predicted. Family members inquired about how I was working and living. The media tried to cover this shift but kept missing the mark by getting distracted by terms like “anti-work” and the “great resignation” rather than going deeper.\n\nIf they did go deeper, they would have seen what I was seeing: a more gradual, and harder to define, change bubbling under the surface. While some people made dramatic shifts in 2020, most of those were moves that were accelerated by a couple of years. The bigger impact of the pandemic was planting seeds of possibility in many more people that have yet to even sprout.\n\nI believe that Ferriss—whose book laid the groundwork for this shift—has had a bigger impact on our collective relationship to work than people think. In 2018, I followed many others before me in living abroad and trying to make it work running a business on the internet. I was surprised at how many people I met in places like Indonesia, Taiwan, Korea, Spain, and Mexico, who all treated _The_ _4-Hour Workweek_ like a sacred text. While some were embracing the automation and outsourcing hacks that sometimes get unfairly pinned to Ferriss, most were inspired by his philosophical stance against the default path of work.\n\nYet while Ferriss’s book did have impressive success, staying on the _New York Times_ bestseller list for years, its underlying message to “question work” did not break through to our broader understanding of work. It resonated most with tech-adjacent rebels who had the skills to find opportunities in a growing digital economy and many people who would have done anything to escape the tedium of many full-time jobs. Whenever I mentioned the book to people outside of this bubble, they would mockingly dismiss it: “Only four hours a week—good luck, buddy!”  \n\nThey had never read it. If they did, they would have found that it is a philosophical wake-up call disguised as a bunch of life hacks. The whole book is basically him channeling the energy of poet Mary Oliver and yelling, “Don’t waste your wild and precious life!” \n\nUnfortunately, _The 4-Hour Workweek_ and the first wave of reimagining our relationship with work has become paired with the archetype of the software engineer whose stance toward life is one of optimization and efficiency. Other movements that were aligned with Ferriss’s philosophical vision from the 2010s, like [FIRE](https://www.mrmoneymustache.com/2013/02/22/getting-rich-from-zero-to-hero-in-one-blog-post/) (Financially Independent, Retire Early), also attracted a different type of person, from the early creative weirdos who wanted to get more joy out of life to people who were trying to earn a specific amount by age 30 so that they would never have to work again.\n\nEscaping work is enticing when you’ve never really known what it is to find work that matters to you, and I unwittingly got sucked into a slightly different trap. When I moved abroad to Taiwan and then Bali, and figured out I could be happy living on $1,000 a month, I calculated that I could go five years without earning an income. For a few months, I experienced a blissful state of leisure that was valuable for my own growth, but I realized that playing accountant is useful for paying the bills but wouldn’t make for a great personality as I aged.\n\nIn the 1990s, the sociologist Andre Gorz argued that most people live in what [he called](https://www.amazon.com/Reclaiming-Work-Beyond-Wage-Based-Society/dp/0745621287) “wage-based societies.” What determined membership in such a society was participation in formal work. Put more simply, to be a good person, thou shall be employed. This was undoubtedly a hidden force that held the ideas in Ferriss’s book from reaching mass adoption. But for the first time, the conventional thinking that it is taboo to question these 20th-century scripts is starting to evaporate.\n\nOnce I realized I was trying to escape work, I leaned in a different direction. I embraced a principle I now call “design for liking work.” The reality is that most people want to be useful, and that means some form of work in people’s lives. With patience and a willingness to feel lost and take it slow, over the last few years, I started to find a better relationship with work. Inspired by ideas from internet writers, poets, books on spirituality and religion, my own writing, self-experiments, and those conversations with internet friends from around the world, I’ve been able to build a life I am excited to keep living. While it took me more than five years to come close to matching my previous income—a reality that holds many people back from leaving their jobs—I can say without a doubt, it might be harder on this current path, but it’s worth it.  \n\nTo share what I have learned and inspire others to dream bigger about the possibilities of their lives, I published a book, [_The Pathless Path,_](https://www.amazon.com/Pathless-Path-Imagining-Story-Work/dp/B09QF6Q421) in 2021. I wrote it after many of those people in conversations during 2020 told me I had to do it. If you listen and pay attention, I bet you can find a deeper journey you are meant to be on, too.  \n\nWhat comes next? I have no idea. But I’ve spent enough time on this uncertain journey to know that when it comes to finding work you love and building a life around it, there are no hacks, roadmaps, or instructions. The best we can do is share our stories. _The 4-Hour Workweek_ was one that inspired many, including me. I hope that in 10 years, my book is merely one of many that helps people figure out the “real work” of their lives: finding things to work on that matter. \n\nWe are going to need them because at a societal level, we are indeed on a pathless path.","n":0.026}}},{"i":6281,"$":{"0":{"v":"The Fall of Roam","n":0.5},"1":{"v":"\n- [[p.hasURL]] https://every.to/superorganizers/the-fall-of-roam\n- [[p.hasAuthor]] @dan-shipper\n- [[p.references]] @vannevar-bush\n- [[p.provokedThoughts]]\n  - https://forum.obsidian.md/t/the-fall-of-roam-and-how-to-avoid-the-same-in-obsidian/32375\n#contrarian #critical ","n":0.302}}},{"i":6282,"$":{"0":{"v":"The Best Decision Making Is Emotional","n":0.408},"1":{"v":"\n- url: https://every.to/p/the-best-decision-making-is-emotional\n  - ![](/assets/images/2023-07-11-21-20-36.png)\n- [[p.mentioned]] [[idea.golden-algorithm]]","n":0.378}}},{"i":6283,"$":{"0":{"v":"Startup Lessons from Y Combinator S Most Sought after Executive Coach","n":0.302},"1":{"v":"\n- url: https://every.to/p/startup-lessons-from-y-combinator-s-most-sought-after-executive-coach-e5f9d3fb-0645-429c-8aaa-c11ad6062801\n- #startup #ycombinator #entrepreneur #coaching\n\n## Highlights:\n\n- founder's job: not to have every answer but to forge ahead until they discover them.\n- failure isn’t an indictment of your basic worth but rather a piece of valuable feedback.\n- The opposite of fear? According to Buechler, it’s not peace, quiet, or control: it’s trust.","n":0.137}}},{"i":6284,"$":{"0":{"v":"My Philosophy of Product Building","n":0.447},"1":{"v":"\n\n\nDivinations\nMy Philosophy of Product Building\nMastering the art of 0 to 1\n\nby Nathan Baschez\n\nAs a person progresses in their career they often develop one or two “signature moves”—ways of solving problems in specific situations that produce outstanding results.\n\nFor Tony Hawk it was the 900º spin.\n\nFor Rich Barton—founder of Zillow, Expedia, and Glassdoor—the signature move is “building Data Content Loops to disintermediate incumbents and dominate Search. And then using this traction to own demand in their industries” (according to Kevin Kwok).\n\nFor Reese Witherspoon the signature move is to play a strong yet vulnerable protagonist going through a transformative moment in life.\n\nIf I had to name my signature move at this point in my career, it would probably be the way I approach building new software products. There’s a lot that I’m not good at, but I’m pretty good at going from zero to one.\n\nQuick braggy bio: Nine years ago, I designed and programmed the first version of Product Hunt. A year before that, I built a fun way to learn to code called Scratchpad that got acquired by General Assembly, and then built another product for GA that still exists today and has been used by hundreds of thousands of people, called Dash. Since then I’ve worked on lots of products: some big successes (Substack), others more low-key successes but still cool in their own way (Chompers, an Alexa skill from Gimlet Media that helps kids brush their teeth, and won a Cannes Lion), and some that never really broke out but a couple thousand people love and still use every week (Wordie Bird, a word game). And last month I launched probably the best v1 product I ever built: Lex.\n\nMy focus now is to get really good at going from 1 to 100 and beyond, but before I do, I wanted to stop and appreciate the 0 to 1 game and write up everything I learned about how to play it.\n\nThere are nine components to my approach:\n\n    Coming up with ideas\n    Deciding to pounce\n    Creating the time and space to build\n    Shaping the idea into a simple v1\n    Programming\n    Design\n    Getting and interpreting feedback\n    Positioning\n    Launching\n\nThere is a lot to cover, so this is the first of a two-part series. This part will start with a high-level overview of how they all fit together, then delve into the first three components. Next week’s follow-up will cover the rest.\n\nLet’s dive in.\nHow (and why) I build products\n\nAt some point in college I learned about internet startups by reading Getting Real from Basecamp, and Paul Graham’s essays. I was enthralled. Sure, there was the possibility of making money, but more importantly, building software felt like the perfect creative medium for me. If you’re attracted to the idea of building things by hand that people might love and find useful, and doing so with a sense of craft and love, then my way of doing things might be a good fit for you.\n\nIt took me a while to realize this, but most people in software don’t care inherently about software. They don’t see it as a medium of creative expression. Instead, it’s a means to some other end, like building a valuable business or earning a lucrative salary. There’s nothing wrong with that, but if that’s your vibe, my approach probably won’t work for you. It’s an extremely hands-on, DIY way of product building. This method has advantages and disadvantages, but it’s only worth it if you find it intrinsically satisfying to build things yourself.\n\nHere’s the hard part: to do it my way, you have to learn how to code. There is no avoiding this step.\n\nI tried for years to avoid it but eventually gave in—and it was the best career decision I ever made. I was not a computer science major in college, and I thought it was “too late” for me to become a programmer. Plus, I wasn’t sure if I even wanted to be one. I hated my math and formal logic classes, and staring at a screen of code was intimidating. The only thing that mattered to me was building cool software that people could use. Wasn’t there some way of avoiding code? I would start to learn a bit but then get easily discouraged every time I hit a rough patch or got stuck; I was worried I was wasting my time, and it would take too long for me to ever be a “real” programmer.\n\nThe truth is that programming involves a lot of complexity, and it’s impossible to learn overnight, but it’s a lot of fun, too. I get a special thrill from dreaming up ideas and making them come to life. Nothing—not even writing—is satisfying in quite the same way. When you can combine the idea of what you want to build with the ability to design and build it in the same brain, special things can happen. I got enough of a taste of this learning on my own in college to keep going with it, and in what feels like a blink of an eye, I’m actually a fairly experienced software engineer now.\n\nEven though I’ve been coding since college, I held myself back for a long time because I wasn’t willing to embrace the identity of a “programmer.” I thought I didn’t deserve it. I would always say, “I’m not a real engineer, but…” I avoided the label because I thought it would put me in a box and crowd out other labels that felt more essential to who I am: entrepreneur, product person, etc. Now I realize it doesn’t matter what I “am.” What matters is what I do. And if something is useful or necessary to accomplishing my goals, and I’m interested in it, it’s good to learn to do it and not hold myself back by worrying about what it means for my identity.\n\nSo, if you’re in love with software and you’re excited by the idea of making it yourself by hand, here’s the short version of how I build new products:\n\nWhen I feel aimless, I tend to think up lots of software ideas. Most of them are bad, but when I get excited enough, I pounce. I create the time and space to hyper-focus for a short span of time, and shape the idea into a form that is simple yet polished and has a new element that feels genuinely exciting. I design and code it myself, or with one or two other people. I then show it to people to use and see what they think. Crucially, I watch people use it in person or via screenshare. The most important thing is that some people have a visceral, emotional reaction. I used to get discouraged when they get a flat response, but eventually learned it’s totally fine and means nothing if some people are unenthusiastic. Once I understand what’s resonating with the people who like it, I focus on that and position the whole product message around that thing. Then I make a short but sweet launch video or essay, and post it to Twitter and anywhere else I can.\n\nThat’s it! That’s the move. Now let’s break it down step by step.\n1. Coming up with ideas\n\nThe best way to come up with ideas for software is to learn how to code. This may seem counter-intuitive, but it’s important. People don’t tend to come up with ideas for things they can’t do. When’s the last time you thought up a new type of airplane or nuclear reactor? I’m guessing you haven’t. Once you learn to use a set of creative tools, if you find it fun to use then you tend to think up reasons to pick up the tools again.\n\nIt’s important to have a low bar for what is worth building when you’re just getting started. If an idea is even a little bit interesting to you, go ahead and spend a Saturday working on it rather than studying “how to code” in the abstract.\n\nThe way I learned to code is by wanting to build specific ideas I had, and doing everything I could to find the most direct path to making it real. There were some essential resources to my development (Rails Tutorial, Eloquent Javascript, Learn Ruby The Hard Way, Head First Rails), but I never was able to stick with courses or tutorials for very long. If you can’t, either, don’t assume you aren’t meant to learn to code. Instead, just try to start building your idea and use Google when you get stuck.\n\nIt’s a mistake to focus too much on coming up with good ideas when you’re getting started. Just try to find ideas you think are cool. It doesn’t matter if it’s a good business or if anyone else thinks it’s cool—you’re just jamming and learning your craft.\n\nThe most important thing is to protect your enthusiasm. If you’re enthusiastic, you’ll keep building and generating new ideas. At times you’ll feel naïve around people who don’t understand what you’re doing. They’ll see your “little” project and give you unhelpful feedback on the assumption that you’re trying to raise a series A from Sequoia. For example, they might encourage you to stop building the product yourself and recruit a team. This is good advice if you want to make one valuable thing right now, but it’s bad advice if your goal is to build skills that will enable you to make many valuable things in the future.\n\nOnce you become a skilled builder, you’ll want to graduate from toy ideas to slightly more serious ones. And at that point you’ll need to be more selective about where you invest your energy.\n2. Deciding to pounce\n\nWhen I first started building products, all I cared about was whether it was cool, but as I get older the decision to pounce becomes more about whether it’s cool—and does it serve my goals.\n\nThere are four distinct yet equally important questions to ask yourself:\n\n    How likely is it to work?\n    What will it take to make it work?\n    If it works, what kind of thing will it become?\n    Is that the kind of thing I want to be doing?\n\nMuch like learning to code, there are unfortunately no shortcuts to improving one’s judgment at answering these questions accurately. You simply have to build a lot of things and see how they turn out, and closely watch what happens to things that other people build. It also helps to understand general patterns and principles of strategy, like what I write about here: wedges, power, positioning, trade-offs, etc.\n\nIt’s more important to develop your intuition by trying your own ideas than it is to listen to others. If you follow someone else’s advice without really understanding it, you don’t learn anything. Better to make a mistake and learn from it than to rob yourself of the lesson. So go with your gut—not because your gut is a sacred source of truth, but because it’s the best way to learn.\n\nEarly in my career I took a lot of risks. I quit my job and almost ran out of cash a few times—and I’m glad I did. It taught me how to live frugally. It humbled me, literally: it made me realize my ideas weren’t that special and taught me just how hard it is to build a business.\n\nAs I get older, especially now that I have a kid, I’m not going to take that level of risk anymore. But I’m glad I did, because it taught me how to be “OK” outside of my comfort zone.\n\nWe live in a time when the main form of financial risk-taking you hear about is buying speculative assets (crypto or otherwise). I would encourage you to speculate less with assets that other people control, where all you can do is sit on your hands as you watch a price go up or down, and instead bet on yourself. It’s a much more fun use of capital in my experience.\n3. Creating the time and space to build\n\nIf you’re young or don’t have many demands upon your time, it’s a huge advantage, and you should exploit it to the fullest. You can have a full-time job, build side projects every weekend, and still have time to hang out with friends and relax. This is a rare and valuable thing.\n\nBut even if your time is a bit more constrained like mine is these days, there are ways to create the time and space you need to build. If you have a significant other or spouse, it’s important to get their buy-in. Tell them about the idea, why you’re excited about it, and why you’d like to spend extra time working on it—but also don’t want to leave them high and dry. Brainstorm ways to create the space together.\n\nYou can also take advantage of special occasions, like holidays, to get extra stuff done. This is how I built the first version of Product Hunt: I stayed up until 2 or 3 a.m. every night at my parents’ house in Arkansas when I was home for Thanksgiving break.\n\nThis is how I work: I tend to get hyper-focused on one thing. When I do, I have what feels like unlimited energy to work on that thing at the exclusion of everything else. But even if you’re not like me, I think it helps to have a “sprint” mentality when building the first version of a new product. I have a lot of friends who like to tinker away at things, but they often never end up shipping. The idea stays in the “tinker” zone. To build something you can launch and get feedback on, it’s probably going to require more concentrated effort than one “sacred hour” every morning.\n\nBut besides creating time to focus, the other key component of building new products is to have a clear conception of what you want to build. When you know what you’re aiming for, it’s much easier to move quickly and with urgency, and get to a point where you can launch.\n\nNext week I’ll continue next week with part 2, where I’ll go over the remaining components of my philosophy:\n\n    Shaping the idea into a simple v1\n    Programming\n    Design\n    Getting and interpreting feedback\n    Positioning\n    Launching\n\nI’d also love to answer any questions you have in next week’s post. To leave a question, hit the feedback button below and let me know what you’d like me to address.\n\nThanks and see you next week!\n\n\n\nWhat did you think of this post?\nAmazing Good Meh Bad\n\nYou received this email because you signed up for emails from Every. No longer interested in receiving emails from us? Click here to unsubscribe.\n221 Canal St 5th floor, New York, NY 10013\n","n":0.02}}},{"i":6285,"$":{"0":{"v":"Following the White Hot Fire inside of You","n":0.354},"1":{"v":"\n- url: https://every.to/superorganizers/following-the-white-hot-fire-inside-of-you\n- [[c.quotes]]\n  - All grumbling is tantamount to ‘Oh, why is a lily not an oak?’\n  - \"set reminders to look at the reminders\"\n  - \"I don’t make art. I make things. Framing it like that keeps what I’m doing from becoming precious. And that’s a good thing, because to be precious is to be timid—and that’s bad.\"\n  - Creativity requires attention to detail and persistence in the face of failure: that’s why it’s called a “discipline.”","n":0.113}}},{"i":6286,"$":{"0":{"v":"Event Processing Using an Rdf Database","n":0.408},"1":{"v":"\n- thin\n- https://allegrograph.com/wp-content/uploads/2021/04/Event-Processing-using-an-RDF-Database.pdf\n- topics: [[prdct.allegrograph.rdfs++]]\n- publish-date: 2008\n\n## Highlights\n\n- The REWERSE program (dead) from the 6th Framework Programme of the EU Commission [3] is one of the few systematic efforts to combine RDFS/OWL with geotemporal reasonin","n":0.169}}},{"i":6287,"$":{"0":{"v":"Event Granularity Modelling Events in Event Driven Applications","n":0.354},"1":{"v":"\n- https://barryosull.com/blog/event-granularity-modelling-events-in-event-driven-applications/?utm_source=substack&utm_medium=email\n\n## Highlights\n\n","n":0.577}}},{"i":6288,"$":{"0":{"v":"Event Driven","n":0.707}}},{"i":6289,"$":{"0":{"v":"Type Script Node.js Event Sourcing","n":0.447},"1":{"v":"\n- url: https://event-driven.io/pl/type_script_node_Js_event_sourcing/\n- [[p.hasExample]]  defining events in typescript","n":0.354}}},{"i":6290,"$":{"0":{"v":"Set_up_opentelemetry_wtih_event_sourcing_and_marten","n":1},"1":{"v":"\n- url: https://event-driven.io/en/set_up_opentelemetry_wtih_event_sourcing_and_marten\n- [[p.hasTopic]] [[prdct.opentelemetry]] [[t.cs.sd.architecture.cqrs]]","n":0.408}}},{"i":6291,"$":{"0":{"v":"Projections_and_read_models_in_event_driven_architecture","n":1},"1":{"v":"\n- url: https://event-driven.io/en/projections-and-read-models-in-event-driven-architecture/\n","n":0.577}}},{"i":6292,"$":{"0":{"v":"Projections and Read Models in Event Driven Architecture","n":0.354},"1":{"v":"\n- \"If you’re storing events and read models in the same relational database (like e.g. [[prdct.marten]] in Postgres), then you can wrap all in a transaction.\"\n- \"You could also store events’ ids and ensure their uniqueness. This could be done as part of middleware around your event handler that tries to store the event id and stops processing if it was already handled. It may be part of your inbox pattern deduplication or stored in a dedicated table together with business results wrapped in the database transaction.\"","n":0.107}}},{"i":6293,"$":{"0":{"v":"Environment Programming in Multi Agent Systems an Artifact Based Perspective","n":0.316},"1":{"v":"\n- url: https://www.researchgate.net/publication/220660578_Environment_programming_in_multi-agent_systems_An_artifact-based_perspective\n\n## Abstract\n\nThis article introduces the notion of environment programming in software multiagent systems (MAS) and describes a concrete computational and programming model based on the artifact abstraction and implemented by the CArtAgO framework. Environment programming accounts for conceiving the computational environment where agents are situated as a first-class abstraction for programming MAS, namely a part of the system that can be designed and programmed—aside to agents—to encapsulate functionalities that will be exploited by agents at runtime. From a programming and software engineering perspective, this is meant to improve the modularity, extensibility and reusability of the MAS as a software system. By adopting the A&A meta-model, we consider environments populated by a dynamic set of computational entities called artifacts, collected in workspaces. From the agent viewpoint, artifacts are first-class entities of their environment, representing resources and tools that they can dynamically instantiate, share and use to support individual and collective activities. From the MAS programmer viewpoint, artifacts are a first-class abstraction to shape and program functional environments that agents will exploit at runtime, including functionalities that concern agent interaction, coordination, organisation, and the interaction with the external environment. The article includes a description of the main concepts concerning artifact-based environments and related CArtAgO technology, as well as an overview of their application in MAS programming.\n\n\n## Highlights\n\n- the environment can be used to design and program the computational part of the system that is functional to agents’ work, i.e. that agents can dynamically access and use to exploit some kind of functionality, and possibly adapt to better fit their actual needs. \n-  some desiderata on programming/computational models can be identified:\n\n  - Abstraction: The model adopted should preserve the agent abstraction level, i.e. the main concepts used to program environment structure and dynamics should be consistent with agent concepts and their semantics. Exam- ples include the notion of actions, percepts, events, tasks/goals. \n  - Orthogonality: The model should be as much orthogonal as possible to the mod- els, architectures, languages adopted for agent programming, so as to naturally support the engineering of heterogeneous systems. Generality: The model should be general and expressive enough to allow for developing different kinds of environment according to different application domains and problems, exploiting the same basic set of concepts and constructs.\n  - Modularity: The model should introduce concepts to modularise environments, avoiding monolithic and centralised views.\n  - Dynamic extensibility: The model should support the dynamic construction, replacement, extension of environment parts, in an open system perspective.\n  - Reusability: The model should promote the reuse of environment parts in different application contexts/domains.\n- existing program- ming paradigms can be re-used to define the environment programming model only by bridg- ing the abstraction gap that exists with respect to the agent abstraction level. \n  - e.g.\n    -  the notion of object as defined in the context of object-oriented programming (OOP) cannot be re-used “as it is” as first-class environment abstraction: on the one side, in OOP objects inter- act with each other by means of method invocation and no action/perceptions concepts are defined; on the other side, method invocation is not defined in the context of agent-oriented programming and in the semantics of agent programming languages, consequently it is not meaningful to simply enable “agent–object interaction” in terms of method invocation. This holds also when considering agent frameworks based on OO programming languages, such as Jade [1] (which is based on Java): objects (classes) are used to implement agents, not to create environments shared by agents to enhance their coordination and cooperation—agents are meant to interact solely by means of message passing based on FIPA ACL. In other words: objects are not first-class entities of the agent world, they are the basic construct to implement agents. So, also in this case a further abstraction layer is necessary to wrap objects, defining the semantics of agent–object interaction.\n-  \n\n### Main Aspects of computational model for environment programming\n\n#### Action Model\n\n- in order to know if the execution of an action in the environment has been completed with success, an agent must check its percepts.\n- the set of actions can be considered\npart of the contract that the environment provides to the agents that are logically situated in it\n- current agent programming languages models actions as events, i.e. as a single atomic transition (from the agent viewpoint) changing/inspecting the state of the environment. In this case it is like to say that actions have zero time length and the execution of two actions cannot overlap in time.\n  - programmable environments make it possible to introduce richer semantics, modelling action execution as a process, i.e., a sequence of two or more events, including the event representing the starting of the action execution and the event represent- ing the completion of the execution. This allows for easily representing long-term, possibly concurrent actions and also to define actions useful for agent synchronisation\n\n#### Perception Model\n\n- ","n":0.035}}},{"i":6294,"$":{"0":{"v":"Engineering World Wide Multi Agent Systems with Hypermedia","n":0.354},"1":{"v":"\n- https://www.alexandria.unisg.ch/server/api/core/bitstreams/37e4cdf0-11b2-4ea6-90c4-e21f1e5bb8bf/content\n- topics: [[t.cs.multi-agent-system]] [[t.cs.api.hypermedia]] [[prdct.hmas-ontology]]\n\n## Abstract\n\nA well studied problem in the engineering of open MASs is to enable uniform interaction among heterogeneous agents. However, AOSE as a field has grown to recognize that a MAS consists of more than only agents and thus should be designed on multiple dimensions (including the environment, organization etc.). The problem of enabling interaction among heterogeneous entities across dimensions is either not considered, or it is addressed in an ad hoc and non-uniform manner. In this chapter, we introduce a novel approach to use hypermedia as a general mechanism to support uniform interaction in MASs. The core idea is that agents use hypermedia to discover at runtime (i) other entities in a MAS (e.g., other agents, tools, organizations) and (ii) the means to interact with those entities (e.g., interaction protocols, APIs). This reduces coupling and enhances the scalability and evolvability of the MAS. We present a demonstrator that supports these claims. We believe that a hypermedia-based mechanism for uniform interaction in MASs could provide a foundation for engineering world-wide MASs\n\n## Highlights\n\n- Our hypothesis is that we can use hypermedia to create a general mecha- nism for uniform interaction in MASs. Given such a mechanism, heterogeneous agents would then be able to interact in a uniform manner with other agents as well as other heterogeneous entities (tools, knowledge repositories, organi- zations, datasets etc.) that could help them achieve their goals. \n","n":0.065}}},{"i":6295,"$":{"0":{"v":"Endurant Types in Ontology Driven Conceptual Modeling towards onto Uml 2 0","n":0.289},"1":{"v":"\n- https://bia.unibz.it/esploro/outputs/conferenceProceeding/Endurant-Types-in-Ontology-Driven-Conceptual-Modeling/991006391186701241\n- topics: [[prdct.ontouml]] [[prdct.unified-foundational-ontology]]\n- published: t.2018.09\n- authors: @giancarlo-guizzardi\n\n## Abstract\n\nFor over a decade now, a community of researchers has con- tributed to the development of the Unified Foundational Ontology (UFO) - aimed at providing foundations for all major conceptual modeling con- structs. This ontology has led to the development of an Ontology-Driven Conceptual Modeling language dubbed OntoUML, reflecting the ontolog- ical micro-theories comprising UFO. Over the years, UFO and OntoUML have been successfully employed in a number of academic, industrial and governmental settings to create conceptual models in a variety of differ- ent domains. These experiences have pointed out to opportunities of improvement not only to the language itself but also to its underlying theory. In this paper, we take the first step in that direction by revis- ing the theory of types in UFO in response to empirical evidence. The new version of this theory shows that many of the meta-types present in OntoUML (differentiating Kinds, Roles, Phases, Mixins, etc.) should be considered not as restricted to Substantial types but instead should be applied to model Endurant Types in general, including Relator types, Quality types and Mode types. We also contribute a formal character- ization of this fragment of the theory, which is then used to advance a metamodel for OntoUML 2.0. Finally, we propose a computational sup- port tool implementing this updated metamodel.\n\n\n## Hightlighs\n\n- \"One of these “language subversions” led us in this ar- ticle to reconsider some of the theoretical foundations underlying the language, i.e., it led us to rethink and evolve a core theory in UFO, namely, its theory of Endurant Types and Taxonomic structures \"\n  - e.g. the relationship between Giovanni and UN is of the Kind “Employment”, that it is currently in a “Tenured” Phase, and that it can play the Role of “Legal Grounds” for his visa application\n- Consciously ignoring this restriction, users of the language started to systematically employ these meta-type distinctions to other types of endurants, in particular, to existentially dependent endurants such as qualities (e.g., the perceived value of the experience, the color of the apple), modes (e.g., Paul’s Dengue Fever, Matteo’s capacity of programming in Scratch) and relators (e.g., John and Mary’s Marriage, Giovanni’s Employment at the UN). \n- **like full-fledged endurants, qualities, modes and relators are also subject of both essential and accidental properties**\n","n":0.051}}},{"i":6296,"$":{"0":{"v":"Enabling Retroactive Computing through Event Sourcing","n":0.408},"1":{"v":"\n- https://oparu.uni-ulm.de/server/api/core/bitstreams/169d77df-ea1a-4e5a-8322-148e309f2ee9/content\n- topics: [[t.cs.data.temporality.retroactive-computing]]\n\n\n## Abstract \nEvent sourcing is a style of software architecture wherein state altering operations to an application are captured as immutable events. Each event is appended to an event log, with the current state of a system derived from this series of events. This thesis addresses the utilization of retroactive capabilities in event-sourced systems: comput- ing alternate application states, post hoc bug fixes, or the support of algorithms which have access to their own history, for example. The possibility of retroactively access- ing and modifying this event log is a potential capability of an event-sourced system, but a detailed exploration how these operations can be facilitated and supported has not yet been conducted. \n\nWe examine how retroaction can be applied to event-sourced systems and discuss conceptual considerations. Furthermore, we demonstrate how different architectures can be used to provide retroaction and describe the prototypical implementation of an appropriate programming model. These findings are applied in the Chronograph research project, in order to utilize potential temporal aspects of this platform.\n\n\n## References\n\n- https://conf.researchr.org/details/debs-2017/debs-2017-papers/1/Chronograph-A-Distributed-Processing-Platform-for-Online-and-Batch-Computations-on-Ev","n":0.076}}},{"i":6297,"$":{"0":{"v":"Emshort","n":1},"1":{"v":"\n[[c.blog]] \n","n":0.707}}},{"i":6298,"$":{"0":{"v":"Beyond Branching Quality Based and Salience Based Narrative Structures","n":0.333},"1":{"v":"\n- https://emshort.blog/2016/04/12/beyond-branching-quality-based-and-salience-based-narrative-structures/\n- mentions: [[prdct.storyspace]]\n\n## Highlights\n\n- There is a fair amount of craft writing about how to make branching narrative thematically powerful, incorporate stats, and [avoid combinatorial explosions](https://www.choiceofgames.com/2011/07/by-the-numbers-how-to-write-a-long-interactive-novel-that-doesnt-suck/), as well as just [minimizing the amount of branching relative to the number of choices offered](http://gdcvault.com/play/1023072/All-Choice-No-Consequence-Efficiently). [Jay Taylor-Laird did a talk on branching structures at GDC 2016](http://gdcvault.com/play/1023095/The-Shapes-in-Your-Story), which includes among other things a map of Heavy Rain. And whenever I mention this topic, I am obligated to link [Sam Kabo Ashwell’s famous post on CYOA structures](https://heterogenoustasks.wordpress.com/2015/01/26/standard-patterns-in-choice-based-games/).\n\n### My story is made of pieces of content. How do I choose which piece to show the player next?\n\n- [[[t.storytelling.narratology.quality-based-narrative]] is the term invented by Failbetter Games to refer to [interactive narratives structured around storylets unlocked by qualities](http://www.failbettergames.com/tag/narrative-engineering/). A storylet is typically a paragraph or two of text followed by a choice for the user (each option is referred to as a branch in Failbetter parlance) and text describing the outcome of that choice. Qualities are numerical variables that can go up or down during play, and represent absolutely everything from inventory (how many bottles of laudanum are you carrying?) to skills (what is your Dangerous skill level?) to story progress (how far have you gotten in your relationship to your Aunt?). The StoryNexus tool implements QBN; so did [Varytale](https://emshort.wordpress.com/?s=varytale&submit=Search), while that was still around, though in a hybrid form that allowed storylets themselves to contain CYOA-styled segments.\n  - [[prdct.storynexus]] is hard on new authors because the content tends to be uninteresting until there are a fair number of storylets in the database, so it’s hard to feel like you’re really rolling until you’ve spent quite a bit of time in the tool.\n- [[t.storytelling.narratology.salience-based-narrative]] is a term I just made up to refer to interactive narratives that pick a bit of content out of a large pool depending on which content element is judged to be most applicable at the moment. Like QBN, this approach is agnostic about what kind of information matters: just as a quality in Fallen London could be pretty much anything, salience narrative can be tied to pretty much any testable information in the world state.\n  - relatively easy to build a rudimentary set of content with sensible, broad defaults, and then gradually add new, more salient content for individual situations. ^nt9g9zslhb88\n  - It’s not coincidental that both of the “salience-based” applications I mentioned are for triggering dialogue specifically, and that they’re handling a narrative layer transposed on an otherwise explorable environment.\n  - A much more extreme version of this is Doug Sharp’s [[game.the-king-of-chicago]] (you should really read this article if you haven’t — it’s fascinating). _The King of Chicago_ is not just generating suitable dialogue but actually sequencing what should happen next in the story from a collection of possible scenes, based on everything that has occurred so far. It’s also using numerical rather than boolean state variables to measure salience.","n":0.046}}},{"i":6299,"$":{"0":{"v":"Elements of Eloquence Summary","n":0.5},"1":{"v":"\n\n- [[p.hasURL]] https://kadavy.net/blog/posts/elements-of-eloquence-summary/\n- [[p.hasHighlight]] \n  - Zeugma is using one verb to apply action to multiple clauses\n","n":0.243}}},{"i":6300,"$":{"0":{"v":"Elaboration in Dependent Type Theory","n":0.447},"1":{"v":"\n- https://leodemoura.github.io/files/elaboration.pdf\n\n## Abstract\n\nWe describe the elaboration algorithm that is used in [[prdct.lean]], a new interactive theorem prover based on dependent type theory. To be practical, interactive theorem provers must provide mechanisms to resolve ambiguities and infer implicit information, thereby supporting convenient input of expressions and proofs. Lean’s elaborator supports higher-order unification, ad-hoc overloading, insertion of coercions, type class inference, the use of tactics, and the computational reduction of terms. The interactions between these components are subtle and com- plex, and Lean’s elaborator has been carefully designed to balance effi- ciency and usability.","n":0.104}}},{"i":6301,"$":{"0":{"v":"Easss23 Maop Tutorial","n":0.577},"1":{"v":"\n- repo: https://github.com/orgs/JaCaMo-EASSS23/\n\n## Resources\n\n- [[ar.easss23-maop-tutorial.environment]]","n":0.447}}},{"i":6302,"$":{"0":{"v":"the Environment Dimension","n":0.577}}},{"i":6303,"$":{"0":{"v":"Eagle a Scalable Query Processing Engine for Linked Sensor Data","n":0.316},"1":{"v":"\n- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6832792/\n- topics: [[t.cs.web.w3c.rdf.spatio-temporal]] [[prdct.opentsdb]] \n\n## Abstract\n\nRecently, many approaches have been proposed to manage sensor data using semantic web technologies for effective heterogeneous data integration. However, our empirical observations revealed that these solutions primarily focused on semantic relationships and unfortunately paid less attention to spatio–temporal correlations. Most semantic approaches do not have spatio–temporal support. Some of them have attempted to provide full spatio–temporal support, but have poor performance for complex spatio–temporal aggregate queries. In addition, while the volume of sensor data is rapidly growing, the challenge of querying and managing the massive volumes of data generated by sensing devices still remains unsolved. In this article, we introduce EAGLE, a spatio–temporal query engine for querying sensor data based on the linked data model. The ultimate goal of EAGLE is to provide an elastic and scalable system which allows fast searching and analysis with respect to the relationships of space, time and semantics in sensor data. We also extend SPARQL with a set of new query operators in order to support spatio–temporal computing in the linked sensor data context.\n\n## Highlights\n\nThe current standard query language for RDF, i.e., SPARQL 1.1, does not support spatio–temporal query patterns on sensor data. Recently, there have been several complimentary works towards supporting spatio–temporal queries on RDF. For example, to enable spatio–temporal analysis, in [19], Perry et al. propose the SPARQL-ST query language and introduce the formal syntax and semantics of their proposed language. SPARQL-ST is extended from the SPARQL language to support complex spatial and temporal queries on temporal RDF graphs containing spatial objects. With the same goal as SPARQL-ST, Koubarakis et al. propose st-SPARQL [20]. They introduce stRDF as a data model to model spatial and temporal information and the stSPARQL language to query against stRDF. Another example is [21], where Gutierrez et al. propose a framework that introduces temporal RDF graphs to support temporal reasoning on RDF data. In this approach, the temporal dimension is added to the RDF model. The temporal query language for temporal RDF graphs is also provided. However, the aforementioned works commonly focus on enabling spatio–temporal query features, but hardly any of them fully address the performance and scalability issues of querying billions of triples [22].\n\n- [[prdct.virtuoso]] (https://github.com/openlink/virtuoso-opensource) utilize RDF query engines and spatial indices to manage spatial RDF data... Another example is [[OWLIM|prdct.GraphDB]] [27], which supports a geospatial index in its Standard Edition (SE). However, none of them systematically address the issue of elasticity and scalability for spatio–temporal analytic functions to deal with the massive volume of sensor data.\n  - these approaches only support limited spatial functions, and the spatial entities have to follow the GeoRSS GML","n":0.048}}},{"i":6304,"$":{"0":{"v":"Dynamic Is-a Hierarchy Generation for User Centric Semantic Web","n":0.333},"1":{"v":"\n- url:  http://iswc2011.semanticweb.org/fileadmin/iswc/Papers/Workshops/OCAS/99990029.pdf\n- mentions: [[prdct.hozo]]\n\n## Thoughts\n\n- just use components/aspects/roles\n- just because OBO and DOLCE are single-inheritance doesn't mean multiple-inheritance is bad\n\n## Highlights\n\n- \"Nicola Guarino criticizes the careless usage of is-a relationships without enough ontological consideration as is-a overloading [2] and proposes an ontology development methodology, called OntoClean, which defines concepts based on meta- properties such as rigidity and anti-rigidity\"","n":0.13}}},{"i":6305,"$":{"0":{"v":"Dungeons & Deceptions: The First D&D Players Push Back On The Legend Of Gary Gygax","n":0.258},"1":{"v":"\n- https://kotaku.com/dungeons-deceptions-the-first-d-d-players-push-back-1837516834\n- author: [[user.cecilia-danastasio]]\n  \n## Highlights\n\n- “Role-playing games first began in 1971,”says @dave-arneson\n  - “Don’t ask me why I know that because I’m the one who did it,” he says. “Backed up by court documents. Thank you.”\n- @griffith-morgan The reason why I know the mechanics don’t matter when you’re looking at the research in roleplaying games is once D&D was released, you end up with a mass of copy games coming out and they all have different mechanics. But they’re all using the thing D&D does, and that’s role-playing. \n- @rob-kuntz:  \n  - “Arneson set up his 3-ring binder as a screen between us and him,” wrote Kuntz in an unpublished work called A Tale of Two Daves, Two Gygaxʼs and Two Kuntzʼs, which he shared with Kotaku. “He noted that Dave Megarry, a regular in his game, would be our guide for the adventure. Megarry did most of the interfacing and explaining what it was we were about to do with imaginary characters. Arneson noted that we could be either heroes or wizards. Gary chose to be a wizard and the rest of us heroes.” ^yvlscv5xaros\n\n","n":0.073}}},{"i":6306,"$":{"0":{"v":"dschapman.com","n":1},"1":{"v":"\n- [[p.hasURL]] https://www.dschapman.com/\n- [[p.builtWith]] [[prdct.dendron]] [[prdct.gatsby]]\n- [[p.instanceOf]] [[c.digitalgarden]]\n- [[p.hasHighlight]]\n  - [[ar.dschapman.using-dendron-and-gatsby-together]]\n\n## [[p.hadTouch]]\n\n- t.2022.11.30 because MDX and maggie\n","n":0.243}}},{"i":6307,"$":{"0":{"v":"Using Dendron and Gatsby Together","n":0.447},"1":{"v":"\n- [[p.hasURL]] https://www.dschapman.com/articles/using-dendron-and-gatsby-together","n":0.577}}},{"i":6308,"$":{"0":{"v":"Douroucouli","n":1},"1":{"v":"\n- author: @chris-mungall","n":0.577}}},{"i":6309,"$":{"0":{"v":"A Lightweight Ontology Registry System","n":0.447},"1":{"v":"\n- https://douroucouli.wordpress.com/2015/08/27/a-lightweight-ontology-registry-system/\n\n- topics: [[prdct.obo-foundry]] [[c.software.semantic.publishing.site-generator]]\n- ","n":0.447}}},{"i":6310,"$":{"0":{"v":"Don T like Rdf Reification Making Statements about Statements Using Singleton Property","n":0.289},"1":{"v":"\n- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4350149/\n- https://pmc.ncbi.nlm.nih.gov/articles/PMC4350149/","n":0.577}}},{"i":6311,"$":{"0":{"v":"Domaincentric","n":1}}},{"i":6312,"$":{"0":{"v":"Event Sourcing Projections","n":0.577},"1":{"v":"\n- url: https://domaincentric.net/blog/event-sourcing-projections\n- #topic [[t.cs.sd.event-sourcing.projection]]\n- ","n":0.447}}},{"i":6313,"$":{"0":{"v":"Domain Events versus Event Sourcing","n":0.447},"1":{"v":"\n- url: https://www.innoq.com/en/blog/2019/01/domain-events-versus-event-sourcing/\n- [[c.comparand]] : [[t.cs.sd.event-sourcing]] [[t.cs.sd.ddd.domain-event]]\n\n## Conclusion\n\n- \"The events from event sourcing should therefore only be used internally in the corresponding aggregate or in the context of CQRS to build related read models.\n\nDomain events, on the other hand, represent a specific fact or happening that is relevant regardless of the type of persistence strategy for aggregates, for example, for integrating bounded contexts\n\nEvent sourcing and domain events can of course be used both at the same time, but should not influence each other. The two concepts are used for different purposes and should therefore not be mixed.\"\n\n## Highlights\n\n- \"the semantics of the fine-grained events from event sourcing is too low-level, both in terms of the event itself and the associated information (the “payload”) [to use those events in other contexts]\"\n\n## Thoughts\n\n- interesting point, clarifying example\n  - similar: [[Should event objects used in the event-sourcing implementation also be directly used for communication? No! When solely depending on events used in the event-sourcing pattern, a direct dependency is created on the application's internal data.|t.cs.sd.event-sourcing#^vnn4oe20j4t5]]\n  - but it seems like at least sometimes, domain events could qualify as event sourcing events, and vice versa\n    - e.g. \n      - user clicks \"battle axe\" -> app constructs intentional-command and submits to approval queue (DM, world-service)\"\n  - \"Domain events are a domain modeling pattern\" and \"Event sourcing is a data modeling pattern\"","n":0.067}}},{"i":6314,"$":{"0":{"v":"Dolce a Descriptive Ontology for Linguistic and Cognitive Engineering","n":0.333},"1":{"v":"\n- https://philarchive.org/archive/BORDAD-3 and https://arxiv.org/pdf/2308.01597\n- topics: [[prdct.dolce]] [[prdct.dolce.dns-ultralite]] [[t.km.ontology.foundational]]\n- authors: @stefano-borgo @aldo-gangemi @nicola-guarino \n\n## Abstract\n\nDOLCE, the first top-level (foundational) ontology to be axiomatized, has remained stable for 20 years and today is broadly used in a variety of domains. DOLCE is inspired by cognitive and linguistic considerations and aims to model a com- monsense view of reality, like the one human beings exploit in everyday life in areas as diverse as socio-technical systems, manufacturing, financial transactions and cultural heritage. DOLCE clearly lists the ontological choices it is based upon, relies on philosophical principles, is richly formalized, and is built according to well-established ontological methodologies, e.g. Onto- Clean. Because of these features, it has inspired most of the existing top-level ontologies and has been used to develop or improve standards and public domain resources (e.g. CIDOC CRM, DBpedia and WordNet). Being a foundational ontology, DOLCE is not directly concerned with domain knowledge. Its purpose is to provide the general categories and relations needed to give a coherent view of reality, to integrate domain knowledge, and to mediate across domains. In these 20 years DOLCE has shown that applied ontologies can be stable and that interoperability across reference and domain ontologies is a reality. This paper briefly introduces the ontology and shows how to use it on a few modeling cases.\n\n## Highlights\n\n- what does \"Also, DOLCE’s domain of discourse is formed by ^fqsnps87modh\nparticulars, while properties and relations are taken to be universals\" mean?","n":0.065}}},{"i":6315,"$":{"0":{"v":"djradon's Wiki","n":0.707},"1":{"v":"\n- https://djradon.github.io/wiki","n":0.707}}},{"i":6316,"$":{"0":{"v":"Distributed Engineering of Ontologies Diligent","n":0.447},"1":{"v":"\n- https://link.springer.com/chapter/10.1007/3-540-28347-1_16\n- published: 2005\n- appears-in: [[book.semantic-web-and-peer-to-peer]]\n","n":0.408}}},{"i":6317,"$":{"0":{"v":"Distributed Collaboration on Rdf Datasets Using Git","n":0.378},"1":{"v":"\n- https://svn.aksw.org/papers/2016/Semantics_Quit/public.pdf\n- authors: @natanael-arndt @normal-radtke @michael-martin\n- similar: [[ar.distributed-collaboration-on-rdf-datasets-using-git]]\n- keywords: [[prdct.quit]]\n\n## Abstract\n\nCollaboration is one of the most important topics regarding the evolution of the World Wide Web and thus also for the Web of Data. In scenarios of distributed collaboration on datasets it is necessary to provide support for multiple dif- ferent versions of datasets to exist simultaneously, while also providing support for merging diverged datasets. In this pa- per we present an approach that uses SPARQL 1.1 in com- bination with the version control system Git, that creates commits for all changes applied to an RDF dataset contain- ing multiple named graphs. Further the operations provided by Git are used to distribute the commits among collabora- tors and merge diverged versions of the dataset. We show the advantages of (public) Git repositories for RDF datasets and how this represents a way to collaborate on RDF data and consume it. With SPARQL 1.1 and Git in combina- tion, users are given several opportunities to participate in the evolution of RDF data.","n":0.077}}},{"i":6318,"$":{"0":{"v":"Discourse Graphs for Augmented Knowledge Synthesis What and Why","n":0.333},"1":{"v":"\n- url: http://joelchan.me/assets/pdf/Discourse_Graphs_for_Augmented_Knowledge_Synthesis_What_and_Why.pdf\n- author: @joel-chan\n- #topic [[t.km.discourse-graph]] ","n":0.378}}},{"i":6319,"$":{"0":{"v":"Development of an Extension of Geo Server for Handling 3 D Spatial Data","n":0.277},"1":{"v":"\n- url: https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1004&context=foss4g\n\n## Highlights\n\n- 2. Related Work\nThere are several DBMSs that can store 3D spatial data and perform query processing on spatial information. Oracle Spatial and Graph, a representative commercial database, supports most spatial operations and 3D spatial data types, including a solid geometry. PostGIS, a widely used open source spatial database, partially supports 3D spatial data types and operations. Although spatial DBMSs are fundamental to manipulate spatial data, common interfaces and tools have been demanded to satisfy various geospatial applications. For instance, users may need to overlay and manipulate multiple layers from various data sources without concerns about different implementations on each data store. GeoTools (GeoTools 1998) is an open source library that meets these requirements. It provides excellent abstraction for multiple data sources. GeoServer is an implementation of a geospatial data server based on GeoTools. It allows users to simply load/store layers from/to various databases and file-based data sources, hiding details of how to handle them. A read- able/writable source is called a data store. Thanks to many contributors, GeoServer supports a variety of data stores. Also, it lets users to add data stores via the Web. The reason is that GeoServer has a common interface, called Feature, between data stores and a module that provides the Web Feature Service. Thus, it acts as a bridge between heterogeneous data stores and the user interface, to exchange the spatial information.","n":0.066}}},{"i":6320,"$":{"0":{"v":"Developing Gfo 2.0 Further Initiating the Modules of Space and Material Objects","n":0.289},"1":{"v":"\n- https://ceur-ws.org/Vol-2969/paper69-FOUST.pdf\n\n## Highlights\n\n### Introduction\n\n- Spatiotemporal individuals on [the macro-physical level] are classified into objects, processes,facts, and situations.\n- GFO’s ontology of space [5], (as well as that of time) is heavily inspired by @franz-brentano\n  - the theory of boundaries provides an appropriate understanding of dimension in space.\n  - A similar idea of dimension was developed by @karl-menger\n\n### Modular Architecture of GFO 2.0\n\n- Monolithic design of an ontology, similarly as in the case of other types of software components, imposes problems with its complexity that hinder the usability, maintenance and scalability [^11]\n\n\n\n\n[^11]: [[ar.criteria-and-evaluation-for-ontology-modularization-techniques]]","n":0.105}}},{"i":6321,"$":{"0":{"v":"Developer Guide Event Driven Development","n":0.447},"1":{"v":"\nurl: https://solace.com/blog/developer-guide-event-driven-development/\n\n[[p.mentioned]] [[t.cs.sd.architecture.event-driven.event-broker]]","n":0.577}}},{"i":6322,"$":{"0":{"v":"Detailed Comparison of Seven Approaches for the Annotation of Time Dependent Factual Knowledge in Rdf and Owl","n":0.243}}},{"i":6323,"$":{"0":{"v":"Design Principles behind Smalltalk","n":0.5},"1":{"v":"\n- url: https://www.cs.virginia.edu/~evans/cs655/readings/smalltalk.html\n- author: @daniel-ingalls\n\n\n## Summary\n\n- **Personal Mastery.** If a system is to serve the creative spirit, it must be entirely comprehensible to a single individual.\n- **Reactive Principle.** Every component accessible to the user should be able to present itself in a meaningful way for observation and manipulation.","n":0.144}}},{"i":6324,"$":{"0":{"v":"Design Dynamics Experience","n":0.577},"1":{"v":"\n- url: https://www.researchgate.net/publication/315854140_Design_Dynamics_Experience_DDE_An_Advancement_of_the_MDA_Framework_for_Game_Design","n":0.577}}},{"i":6325,"$":{"0":{"v":"Delta an Ontology for the Distribution of Differences between Rdf Graphs","n":0.302},"1":{"v":"\n- https://www.w3.org/DesignIssues/Diff\n\n## Summary\n\n- discusses what patches could look like, but no concrete solutions?\n\n## Highlights\n\n### Weak and Strong diffs\n\nTo address robustness, we distinguish two types of RDF graph deltas: a _weak_ delta gives enough information to apply it to exactly the graph it was computed from, but a _strong_ delta specifies the changes in a context-independent manner. The difference is not in the patch file format, but in the information a particular patch gives.\n\n\n","n":0.117}}},{"i":6326,"$":{"0":{"v":"Defining N-ary Relations on the Semantic Web","n":0.378},"1":{"v":"\n- https://www.w3.org/TR/swbp-n-aryRelations/\n- authors: @natasha-noy @alan-rector @pat-hayes @christopher-welty\n- published-by: [[org.w3c.semantic-web-best-practices-working-group-swbp]]\n- related: [[ar.representing-classes-as-property-values-on-the-semantic-web]]\n\n## Abstract\n\nIn Semantic Web languages, such as RDF and OWL, a property is a binary relation: it is used to link two individuals or an individual and a value. However, in some cases, the natural and convenient way to represent certain concepts is to use relations to link an individual to more than just one individual or value. These relations are called n-ary relations. For example, we may want to represent properties of a relation, such as our certainty about it, severity or strength of a relation, relevance of a relation, and so on. Another example is representing relations among multiple individuals, such as a buyer, a seller, and an object that was bought when describing a purchase of a book. This document presents ontology patterns for representing n-ary relations in RDF and OWL and discusses what users must consider when choosing these patterns.\n\n## Highlights\n\nIssue 1: If property instances can link only two individuals, how do we deal with cases where we need to describe the instances of relations, such as its certainty, strength, etc?\n\nIssue 2: If instances of properties can link only two individuals, how do we represent relations among more than two individuals? (\"n-ary relations\")\n\nIssue 3: If instances of properties can link only two individuals, how do we represent relations in which one of the participants is an ordered list of individuals rather than a single individual?\n\n### Pattern 1: Introducing a new class for a relation\n\n","n":0.064}}},{"i":6327,"$":{"0":{"v":"Deep Telos and Dmla a Contribution to the Multi 2022 Collaborative Comparison Challenge","n":0.277},"1":{"v":"\n- topics: [[prdct.deeptelos]] \n\n## Abstract\n\nThe MULTI 2022 Collaborative Comparison Challenge was created to promote in-depth discussion between multi-level modeling approaches. This paper presents a comparison of DeepTelos- and DMLA-based solutions in response to the challenge. We first present each approach and solution separately, and then list the similarities and differences between the two solutions, discussing their relative strengths and weaknesses.","n":0.129}}},{"i":6328,"$":{"0":{"v":"Deep Meta Modelling with Metadepth","n":0.447}}},{"i":6329,"$":{"0":{"v":"Decentralized Collaborative Knowledge Management Using Git","n":0.408},"1":{"v":"\n- https://natanael.arndt.xyz/bib/arndt-n-2018--jws\n- keywords: [[prdct.rdf]] [[t.cs.semantic-web]] [[t.km]] [[prdct.quit]]\n- similar: [[ar.distributed-collaboration-on-rdf-datasets-using-git]]\n- mentions: [[quit]]\n\n## Abstract\n\nThe World Wide Web and the Semantic Web are designed as a network of distributed services and datasets. The distributed character of the Web brings manifold collaborative possibilities to interchange data. The commonly adopted collaborative solutions for RDF data are centralized (e. g. SPARQL endpoints and wiki systems). But to support distributed collaboration, a system is needed, that supports divergence of datasets, brings the possibility to conflate diverged states, and allows distributed datasets to be synchronized. In this paper, we present Quit Store, it was inspired by and it builds upon the successful Git system. The approach is based on a formal expression of evolution and consolidation of distributed datasets. During the collaborative curation process, the system automatically versions the RDF dataset and tracks provenance information. It also provides support to branch, merge, and synchronize distributed RDF datasets. The merging process is guarded by specific merge strategies for RDF data. Finally, we use our reference implementation to show overall good performance and demonstrate the practical usability of the system\n\n\n## Highlights\n\n- Projects from a number of domains are striving for distributed models to collaborate on common knowledge bases. In the domain of e-humanities, the projects Pfarrerbuch3, Catalogus Professorum4 [40], Héloïse – Euro- pean Network on Digital Academic History5 [39], and Pro- fessorial Career Patterns of the Early Modern History6 are good examples of the need to explore and track provenance and the evolution of the domain data.\n3http://aksw.org/Projects/Pfarrerbuch\n4http://aksw.org/Projects/CatalogusProfessorum\n5http://heloisenetwork.eu/\n6http://catalogus-professorum.org/projects/pcp-on-web/\n\n-  a system that fosters the evolution of a dataset in a distributed collaborative setup needs to\n• support divergence of datasets;\n• conflate diverged states of datasets; and\n• synchronize different distributed derivatives of the respective dataset.\n\n- creating independent vocabularies (a) in the individual working groups would not help to integrate the datasets. Due to the organizational distribution of the individual research groups, a common vocabulary expressing a mutual agree- ment among the groups (b) can only be the result of a collaborative process\n\n## State of the art\n\n- [[ar.w3.delta-an-ontology-for-the-distribution-of-differences-between-rdf-graphs]]","n":0.055}}},{"i":6330,"$":{"0":{"v":"Data Mesh Principles","n":0.577},"1":{"v":"\n\n- [[p.hasURL]] https://martinfowler.com/articles/data-mesh-principles.html\n- [[p.hasTopic]] [[t.cs.data.data-mesh]]\n","n":0.447}}},{"i":6331,"$":{"0":{"v":"Criteria and Evaluation for Ontology Modularization Techniques","n":0.378},"1":{"v":"\n- http://publications.wim.uni-mannheim.de/informatik/lski/dAquin10CriteriaChapter.pdf\n\n## Summary\n\nWhile many authors have argued for the benefits of applying principles of modularization to ontologies, there is not yet a common understanding of how modules are defined and what properties they should have. In the previous section, this question was addressed from a purely logical point of view. In this chapter, we take a broader view on possible criteria that can be used to determine the quality of a modules. Such criteria include logic-based, but also structural and application-dependent criteria, sometimes borrowing from related fields such as software engineering. We give an overview of possible criteria and identify a lack of application-dependent quality measures. We further report some modularization experiments and discuss the role of quality criteria and evaluation in the context of these experiments.\n\n\n## Highlights\n\n### Introduction\n\n#### Scenarios\n\n- ontology partitioning (a set of modules that form the original)\n- selective use and re-use ( a smaller part of an ontology that covers certain aspects of the domain is identified as a basis for a specific application.)\n\n### Use Cases for Modularization\n\n- maintenance\n- publication (solution-specific subsets)\n- validation (experts have to fit the ontology into their brain)\n  - What is missing is an abstracted view on the overall model and its structure as well as the possibility to focus the inspection of a specific aspect\n- processing, aka scalability\n\n### Modularization Approaches\n\n#### Partitioning Approaches\n\n- some approaches being labeled as partitioning methods do not actually create partitions, as the resulting modules may overlap.\n\n#### Module Extraction Approaches\n\n- traversal approach: starting from the elements of the input sub-vocabulary, relations in the ontology are recursively “traversed” to gather relevant (i.e. related) elements to be included in the module.\n  - Such a technique has been integrated in the [[prdct.protege.prompt]] tool\n\n###  Evaluation Criteria for Modularization\n\n#### Logical Criteria\n\n\n","n":0.059}}},{"i":6332,"$":{"0":{"v":"Creativity as an Epistemic Virtue","n":0.447},"1":{"v":"\n- https://eprints.whiterose.ac.uk/125507/3/Creativity%20as%20an%20Epistemic%20Virtue.pdf\n- author: @matthew-kieran\n- written: 2018\n\n## Highlights\n\n- @immanuel-kant: \"original nonsense is insufficient for creativity\"\n\n### Psychological vs Historical Creativity\n\n- @margaret-boden: distinction between “psychologically creative” (P-creative) and “historically creative” (H-creative)\n  - P-creativity is more fundamental. Anything that is new in all of history (H-creative) must also be new to its creator (P-creative)\n\n","n":0.141}}},{"i":6333,"$":{"0":{"v":"Constructing the Military Landscape: The Board of Ordnance Maps and Plans of Scotland, 1689–1815","n":0.267},"1":{"v":"\n- https://www.semanticscholar.org/paper/Constructing-the-military-landscape%3A-the-Board-of-Anderson/f00c9b9e68a3e2a1ee2317235769350d68f72865\n- topics: [[t.geo.cartography]] [[t.hist.military]]\n\n![](/assets/images/2024-09-28-09-15-20.png)\n","n":0.447}}},{"i":6334,"$":{"0":{"v":"Common Slips in Skos Vocabularies","n":0.447},"1":{"v":"\n- https://ceur-ws.org/Vol-849/paper_2.pdf\n","n":0.707}}},{"i":6335,"$":{"0":{"v":"Co Jack a High Level Cognitive Architecture with Demonstrations of Moderators Variability and Implications for Situation Awareness","n":0.243},"1":{"v":"\n- https://acs.ist.psu.edu/papers/ritterBKEPBip.pdf\n- topics: [[prdct.cojack]] [[t.cs.ai.cognitive-architecture]] [[t.cs.agents.bdi]] \n\n## Abstract\n\nWe report a high-level architecture, CoJACK, that provides insights on behavior variability, situation awareness, and behavioral moderators. CoJACK combines Beliefs/Desires/Intentions (BDI) agents’ high-level knowledge representation and usability with several aspects of low level cognitive architectures, including processing time predictions, errors, and traceability. CoJACK explores new areas for cognitive architectures, such as variability arising from moderators. It also allows aspects of situation awareness (SA) in a cognitive architecture to be explored. Its behavior and the effects of moderators on behavior are demonstrated in a simple adversarial environment. It provides lessons for other architectures including how to define, measure, and control variability due to individual and temporal aspects of cognition; the importance of SA and knowledge representations necessary to support complex SA; the potential for parameter sweeps and paths as measures of variability; and some of the complexities that will arise when aspects of moderators and SA are added to cognitive architectures.","n":0.08}}},{"i":6336,"$":{"0":{"v":"Classifying Processes","n":0.707},"1":{"v":"\n- https://ontology.buffalo.edu/smith/articles/Classifying_Processes.pdf\n- topics: [[t.km.ontology]] [[prdct.basic-formal-ontology]]\n- mentions: [[prdct.information-artifact-ontology]]\n\n## Highlights\n\n- Processes, in particular, cannot change on the four-dimensionalist view, because processes are changes  ^wv5719t8809u\n- Continuants may change not only through change in qualities but also in other ways. For example they may gain and lose parts over time, as for example when you gain and lose cells from your body. To address such changes, BFO’s instance-level continuant parthood relation is indexed by time. The counterpart relation on the side of occurrents, in contrast, holds always in a non-indexed way.\n\n\n### Processes as Dependent Entities\n\n- Processes themselves stand to the independent continuants which are their participants in a relation that is analogous to that in which qualities stand to the independent continuants which are their bearers. In both cases we have to deal with the relation of what BFO calls specific dependence.\n\n- Something which processes may share is a **process profile** -- each contains an instantiation of multiple process profile universals.\n\n## Conclusion\n\n- One important next step will deal with the ways in which such classification is complicated by the fact that processes are embedded within a series of larger process wholes, each nested within yet larger process wholes. \n- Human physiological processes, too, are embedded within series of larger wholes in this way. When studying the heart, for example, physiologists may investigate processes within the interior of the left ventricle, interactions between the left ventricle and other parts of the cardiovascular system, interactions between this system and other bodily systems, and so on. Physiologists may be interested in the processes involving multiple organisms; for example they may be interested in some given organism as part of one or other larger whole which includes some population of organisms of a relevant similar type (all humans, all human babies of a given birth weight, all athletes, and so on). Normal processes are defined for this larger population (as normal qualities were defined above), and deviations from this norm are defined for the single organism relative thereto.\n","n":0.055}}},{"i":6337,"$":{"0":{"v":"Clash of Terms","n":0.577},"1":{"v":"\n\n\n- https://github.com/gchq/MagmaCore/wiki/Clash-of-terms\n- related: [[ar.spatio-tempoarl-extents]]","n":0.5}}},{"i":6338,"$":{"0":{"v":"Categories and Foundational Ontology a Medieval Tutorial","n":0.378},"1":{"v":"\n- https://philarchive.org/archive/AUGCAF\n\n\n## Abstract\n\nFoundational ontologies, central constructs in ontological investigations and engineering alike, are based on ontological categories. Firstly proposed by Aris- totle as the very ur-elements from which the whole of reality can be derived, they are not easy to identify, let alone partition and/or hierarchize; in particular, the question of their number poses serious challenges. The late medieval philosopher Dietrich of Freiberg wrote around 1286 a tutorial that can help us today with this exceedingly difficult task. In this paper, I discuss ontological categories and their importance for foundational ontologies from both the contemporary per- spective and the original Aristotelian viewpoint, I provide the translation from the Latin into English of Dietrich’s De origine II with an introductory elabo- ration, and I extract a foundational ontology–that is in fact a single-category one–from this text rooted in Dietrich’s specification of types of subjecthood and his conception of intentionality as causal operation.\n\n\n## Highlights\n\n### GFO includes non-foundational concepts\n\n- \"GFO (General Formal Ontology) is claimed to be a foundational ontology, but (cf. Herre, 2010): Its multi-categorial approach envisages universals, concepts, and symbol structures and their interrelations, of which only universals, and perhaps concepts, can be said to be basic categories; it includes objects (3D entities) and processes (4D entities) and levels of reality, which might satisfy both conditions (i) and (ii), but is designed for applications, which throws doubt on this supposed satisfaction. All in all, in the summary presentation of this project (Herre, 2010, p. 298) nowhere are to be found ur-elements such as substances, properties, qualities, etc., or ur-distinctions such as part vs. whole, essential vs. accessory, etc. (see Introduction).\"\n\n### UFO-B is an ontology for events","n":0.06}}},{"i":6339,"$":{"0":{"v":"Capability Myths Demolished","n":0.577},"1":{"v":"\n- https://srl.cs.jhu.edu/pubs/SRL2003-02.pdf\n- topics: [[t.cs.authorization.capability-based]]\n\n## Abstract\n\nWe address three common misconceptions about capability-based systems: the Equivalence Myth (access control list systems and capability systems are formally equivalent), the Confinement Myth (capability systems cannot enforce confinement), and the Irrevocability Myth (capability-based access cannot be revoked). The Equivalence Myth obscures the benefits of capabilities as compared to access control lists, while the Confine- ment Myth and the Irrevocability Myth lead people to see problems with capabilities that do not actually exist. \n\nThe prevalence of these myths is due to differing inter- pretations of the capability security model. To clear up the confusion, we examine three different models that have been used to describe capabilities, and define a set of seven security properties that capture the distinctions among them. Our analysis in terms of these properties shows that pure capability systems have significant advantages over access control list systems: capabilities provide much better support for least-privilege operation and for avoiding confused deputy problems.\n\n## Highlights\n\n- Property A: No Designation Without Authority.\n- Property B: Dynamic Subject Creation.\n  - The loss of subject granularity is a severe limitation on the expressiveness of ACL systems\n- Property C: Subject-Aggregated Authority Management.\n  - In ACL-based systems, the power to edit authorities is aggregated by resource: the ability to change one permission generally comes together with the ability to edit an entire ACL. In capability systems, the power to edit authorities is aggregated by subject: subjects manipulate authorities in their own C-lists.\n- Property D: No Ambient Authority.\n- Property E: Composability of Authorities\n- Property F: Access-Controlled Delegation Channels\n- \"authorization is just a form of access\"\n\n### The Equivalence Myth\n\n- Properties A, B, and C are differences between the apabilities-as-rows model and the ACLs-as-column that should put to rest the equivalence myth\n\n### The Confinement Myth\n\n- capability systems cannot limit the propagation of authority\n- \"KeyKOS achieves confinement by a mechanism called factories. Essentially, a factory is a mechanism for creating new instances of protected subsystems.\"\n\n### The Irrevocability Myth\n\n- In an object-capability system, however, capabilities can be composed in such a way as to provide revocable access. Suppose once again that Alice wants to give Bob access to Carol, but Alice also wants to have the option to revoke this access at some time in the future. To accomplish this, Alice could simply create a pair of forwarders, F and R, connected as shown in Figure 6. Of this pair, we may call F the forwarding facet, and R the revoking facet. Alice would send Bob access to F, and retain R for herself. Any messages sent to F get forwarded through R to Carol, so Bob may use F as if it were Carol. This works as long as inter-object interactions are mediated by messages, and messages are handled generically, so that a reusable mechanism can forward any message.\n\n![](/assets/images/2024-04-14-19-05-48.png)","n":0.046}}},{"i":6340,"$":{"0":{"v":"Can Bpmn Be Used for Making Simulation Models","n":0.354},"1":{"v":"\n- https://www.researchgate.net/publication/220921192_Can_BPMN_be_used_for_making_simulation_models\n\n## Editorial\n\n- yes, obviously\n\n[[ar.towards-an-ontological-foundation-of-agent-based-simulation]]","n":0.447}}},{"i":6341,"$":{"0":{"v":"C-OWL: Contextualizing Ontologies","n":0.577},"1":{"v":"\n- https://link.springer.com/chapter/10.1007/978-3-540-39718-2_11\n\n## Abstract\n\nOntologies are shared models of a domain that encode a view which is common to a set of different parties. Contexts are local models that encode a party’s subjective view of a domain. In this paper we show how ontologies can be contextualized, thus acquiring certain useful properties that a pure shared approach cannot provide. We say that an ontology is contextualized or, also, that it is a contextual ontology, when its contents are kept local, and therefore not shared with other ontologies, and mapped with the contents of other ontologies via explicit (context) mappings. The result is Context OWL (C-OWL), a language whose syntax and semantics have been obtained by extending the OWL syntax and semantics to allow for the representation of contextual ontologies.\n\n\n## Highlights\n\n- use case:  peer-to-peer applications with a large degree of autonomy of the peer nodes but still with a strong need of coordination\n- multiple ontologies (or sets or shared ontologies) which contain information which should not be integrated (an obvious example being informa- tion which is mutually inconsistent) should be contextualize\n- in OWL, mappings are not part of the language. The ability of combining models is restricted to the import of complete models and to the use of the imported elements by direct reference.\n- We concentrate on the OWL-DL fragment of OWL. This language is equivalent to the SHOIQ(D+) DL, i.e., SHIQ(D+) extended with an equivalent of the oneOf constructor.\n- ","n":0.065}}},{"i":6342,"$":{"0":{"v":"Bringing Communities to the Semantic Web and the Semantic Web to Communities","n":0.289},"1":{"v":"\n- https://eprints.soton.ac.uk/261799/1/KFLawrenceWWW2006.pdf\n- authors: @faith-lawrence @m-schraefel\n- keywords: [[prdct.cidoc-crm]] [[prdct.frbr]] [[prdct.ontomedia]]\n\n## Abstract\n\nIn this paper we consider the types of community networks that are most often codified within the Semantic Web. We propose the recognition of a new structure which fulfils the definition of community used outside the Semantic Web. We argue that the properties inherent in a community allow additional processing to be done with the described rela- tionships existing between entities within the community network. Taking an existing online community as a case study we describe the ontologies and applications that we developed to support this community in the Semantic Web environment and discuss what lessons can be learnt from this exercise and applied in more general settings.\n\n![](/assets/images/2024-10-03-12-20-37.png)\n\n\n## Highlights\n\n### Creating an Ontomedia Application\n\nThe user will not actually be able to edit the shared entities, instead it will act as a template of values for a new instance. This new instance will belong to the user and exist in their ontomedia:context but will identify itself as having a shadow-of relationship to the instance used as a template.","n":0.076}}},{"i":6343,"$":{"0":{"v":"Boro as a Foundation to Enterprise Ontology","n":0.378},"1":{"v":"\n- http://www.borosolutions.net/boro-foundation-enterprise-ontology\n\n\n## Abstract\n\n- Modern business organizations experience increasing challenges in the development and evolution of their enterprise systems. Typical problems include legacy re-engineering, systems integration/interoperability and the architecting of the enterprise. At the heart of all these problems is enterprise modeling. Many enterprise modeling approaches have been proposed in the literature with some based on ontology. Few however adopt a foundational ontology to underpin a range of enterprise models in a consistent and coherent manner. Fewer still take data-driven re-engineering as their natural starting point for modeling. This is the approach taken by Business Object Reference Ontology (BORO). It has two closely intertwined components: a foundational ontology and a re-engineering methodology. These were originally developed for the re-engineering of enterprise systems and subsequently evolved into approaches to enterprise architecture and systems integration. Together these components are used to systematically unearth reusable and generalized business patterns from existing data. Most of these patterns have been developed for the enterprise context and have been successfully applied in several commercial projects within the financial, defense, and oil and gas industries. BORO’s foundational ontology is grounded in philosophy and its metaontological choices (including perdurantism, extensionalism, and possible worlds) follow well-established theories. BORO’s re-engineering methodology is rooted in the philosophical notion of grounding; it emerged from the practice of deploying its foundational ontology and has been refined over the last 25 years. This paper presents BORO and its application to enterprise modeling","n":0.065}}},{"i":6344,"$":{"0":{"v":"Blobs in Games","n":0.577},"1":{"v":"\n[[c.blog]]\nurl: https://simblob.blogspot.com/\n[[p.publishedBy]] [[org.red-blob-games]]\n\n- [ ] [[p.read]] #game-design\n\n## [[p.recommended]]\n\n- [[https://mapbox.github.io/delaunator/|prdct.delaunator]]\n  - [[p.mentioned]] [[prdct.delaunator]]\n","n":0.289}}},{"i":6345,"$":{"0":{"v":"Bitter Lesson","n":0.707},"1":{"v":"\n- url: http://www.incompleteideas.net/IncIdeas/BitterLesson.html\n\n## Thoughts\n\n- if you want humans to participate, you can't depend on convolution","n":0.258}}},{"i":6346,"$":{"0":{"v":"Bitemporal Data Model: Making it happened in Postgres","n":0.354},"1":{"v":"\n\n- url: https://www.youtube.com/watch?v=MGSdq6EYaKk\n\n## Highlights\n\n### The Linguistic Problem\n\nToo many common terms with overlapping meaning.\n•\tValid Time\n•\tTransaction Time\n•\tSystem Time\n•\tState Time\n•\tInscription Time\n•\tApplication Time\n•\tSpeech Act Time\n•\tAssertive Time\n•\tEffective Time\n\n- ! Assertive Time and Effective Time are their recommendations\n","n":0.177}}},{"i":6347,"$":{"0":{"v":"Bfo 2 0 Specification and Users Guide","n":0.378},"1":{"v":"\n- url: https://raw.githubusercontent.com/BFO-ontology/BFO/master/docs/bfo2-reference/BFO2-Reference.pdf\n\n\n## Selections\n\n### The Monohierarchy Principle\n\n- the asserted taxonomies of types and subtypes in BFO-conformant ontologies should be genuine trees (in the graph-theoretic sense), so that each node in the graph of universals should have at most one asserted is_a parent.\n- This principle is of value not only because it supports a simple strategy for the formulation of definitions and thereby helps to prevent certain common kinds of error in ontology construction, but also because it brings technical benefits when ontologies are implemented computationally.\n- ","n":0.108}}},{"i":6348,"$":{"0":{"v":"Best RDF triplestore/graph database?","n":0.5},"1":{"v":"\n- https://www.reddit.com/r/semanticweb/comments/1faad4e/best_rdf_triplestoregraph_database/","n":0.707}}},{"i":6349,"$":{"0":{"v":"Best Practices for Implementing Fair Vocabularies and Ontologies on the Web","n":0.302},"1":{"v":"\n- https://dgarijo.com/papers/best_practices2020.pdf\n- authors: @daniel-garijo @maria-poveda-villalon\n- keywords: [[t.km.ontology.metadata]] [[t.km.ontology.publication]] [[t.cs.data.fair]]\n\n## Abstract\n\n- With the adoption of Semantic Web technologies, an increas-\ning number of vocabularies and ontologies have been developed in differ-\nent domains, ranging from Biology to Agronomy or Geosciences. How-\never, many of these ontologies are still difficult to find, access and un-\nderstand by researchers due to a lack of documentation, URI resolving\nissues, versioning problems, etc. In this chapter we describe guidelines\nand best practices for creating accessible, understandable and reusable\nontologies on the Web, using standard practices and pointing to exist-\ning tools and frameworks developed by the Semantic Web community.\nWe illustrate our guidelines with concrete examples, in order to help\nresearchers implement these practices in their future vocabularies.\n\n\n## Highlights\n\n### Accessible Ontology URI Design\n\n#### Ontology name and namespace prefix\n\n- short and simple\n- avoid overlapping with other existing vocabularie\n\n#### Hash versus slash URIs\n\n- using a slash allows treating each element of the ontology\nas a separate entity that may be described in an independent manner.\n\n\n#### Opaque URIs for classes and properties\n\n- if we decide to change the name of the class in the future, the URI of the class would not be affected by it\n  - t.2024.10.01.12 meh, just use an alias\n- identifiers are language agnostic.\n- The main drawback of using opaque URIs is the difficulty of interpreting properly classes and properties, which usually requires additional tooling for displaying the right labels. For this reason, we will not use them in our example \n\n\n#### Ontology versioning\n\n- use semantic versioning\n- It is discouraged to include version numbers as part of the ontology URI, as it would deeply affect interoperating with its instances.\n\n#### Using permanent URIs\n\n- There are several open, free services to create permanent URLs on the Web, among which purl.org12 (now hosted by the Internet Archive) and w3id13 (created by the W3C Permanent Identifier Community Group and supported by several companies)\n\n### Generating Reusable Ontology Documentation\n\n#### Ontology Metadata\n\n- two main categories of metadata in an ontology: \n  - the metadata associated with the ontology itself \n  - the metadata associated with its elements (classes, object properties, datatype properties and individuals).\n\nTable 1. Recommended and optional metadata for describing ontologies\n\nProperty name Annotation Property Rationale Guideline\nLicense dcterms:license Usage conditions Recommended\nCreator dcterms:creator Provenance and attribution Recommended\nContributor dcterms:contributor Provenance and attribution Recommended\nCreation date dcterms:created Provenance Recommended\nPrevious version owl:priorVersion Provenance and comparison Recommended\nNamespace URI vann:preferredNamespaceUri Identifying the ontology Recommended\nVersion IRI owl:versionIRI Versioning Recommended\nNamespace prefix vann:preferredNamespacePrefix Identifying the ontology Recommended\nTitle dcterms:title Understanding Recommended\nDescription dcterms:description Understanding Recommended\nCitation dcterms:bibliographicCitation Credit Recommended\nAbstract dcterms:abstract Additional information Optional\nSee also rdfs:seeAlso Additional information Optional\nStatus sw:status Maturity information Optional\nBackward compatibility owl:backwardCompatibleWith Version compatibility Optional\nIncompatibility owl:incompatibleWith Version compatibility Optional\nModification date dcterms:modified Provenance and timeliness Optional\nIssued date dcterms:issued Provenance and timeliness Optional\nSource dcterms:source Provenance Optional\nPublisher dcterms:published Provenance Optional\nDOI bibo:doi Bibliographic information Optional\nLogo foaf:logo Identifying the ontology Optional\nDiagram foaf:depiction Visual documentation Optional\n\n\nTable 2. Recommended and optional properties for describing ontology terms\n\nProperty name Annotation Property Rationale Guideline\nLabel rdfs:label Readibility Recommended\nDefinition rdfs:comment Understanding Recommended\nExample vann:example Understanding Optional\nStatus sw:term status Understanding Optional\nRationale vaem:rationale Understanding Optional\nSource dcterms:source Provenance Optional\nDefined by rdfs:isDefinedBy Provenance Optional\n\n\n#### Ontology Visualization\n\n![](/assets/images/2024-10-01-12-13-49.png)\n\n- in the last years, conventions for ontology diagrams have been proposed (e.g., [[VOWL|prdct.vowl]] [10] and [[Graffoo|prdct.graffoo]]21) but none have been standardized\n\n\n### Ontology Publication on the Web\n\n#### Ontology Accessibility in Multiple Interoperable Formats\n\n- 303s (yech)\n- \"Here we expand these practices with our example ontology to illustrate: 1) How to support multiple serializations of an ontology (HTML and Turtle); 2) how to support version redirection, as we would like all the versions of the ontology to be appropriately available, not only the latest; 3) How to specify if a serial- ization is not supported (for example, requests for JSON-LD will return a 406 non-acceptable code, rather than an RDF/XML serialization); and 4) how to implement a default response in case the user agent doing the request does not specify a target in the request (by default we return Turtle)\"\n\n#### Making an Ontology Findable on the Web\n\n1. Register the namespace prefix using prefix.cc,26 a crowdsourced registry where users can vote the most popular URI for a given prefix.\n2. Register the ontology: There are a number of existing metadata registries that can be used for browsing existing ontologies [15][17]. Our recommenda- tion is to look first for domain-specific registries (e.g., Bioportal [17] in the biomedical domain, Agroportal [7] in Agronomy, etc.) commonly used by the target community of interest. When domain-specific registries do not exist, we suggest registering the ontology in a domain-generic metadata registry, such as Linked Open Vocabularies [15] (which has a manual curation process to ensure that minimum metadata is provided) or FAIRsharing.27\n3. In-document annotations to help crawlers understand the metadata of the ontology when publishing it on the Web. These annotations can be added in your documentation through JSON-LD snippets,28 as shown below:\n\n\n### Ontology Documentation and Publication Frameworks\n\n- frameworks inspired by the continuous integration practices\nin software engineering have arisen to support ontology engineering activities.\n  -  offer end-to-end solutions that support ontology engineers documenting, visualizing, testing and publishing their ontologies; and we recom- mend them as an entry point to adopt some of the practices described in this chapter.\n-  [[prdct.ontoology]]\n-  [[prdct.vocol]]\n-  [[prdct.pool-party]]\n-  \n\n### Conclusion\n\n-In this chapter we have described implementation guidelines and recommen- dations for making ontologies findable (through metadata registries and anno- tations); accessible (through good practices in URI design and content nego- tiation), interoperable (showing how to serve ontologies in different standard serializations) and reusable (by describing the metadata and diagram guidelines needed for proper understanding) on the Web while following the Linked Data principles","n":0.033}}},{"i":6350,"$":{"0":{"v":"Best Practice Recipes for Publishing Rdf Vocabularies","n":0.378},"1":{"v":"\n- https://www.w3.org/TR/swbp-vocab-pub/\n- authors: @diego-berrueta @jon-phipps \n- published-by: [[org.w3c.semantic-web-best-practices-working-group-swbp]]\n\n## Thoughts\n\n- no good recipes for github hosting\n- tempting to just use owl:includes in the vocabulary for every class and property","n":0.189}}},{"i":6351,"$":{"0":{"v":"Being on the Semantic Web Is Easy and Frankly Well Worth the Bother","n":0.277},"1":{"v":"\n- https://csvbase.com/blog/13","n":0.707}}},{"i":6352,"$":{"0":{"v":"Basic Formal Ontology (BFO) July 2023","n":0.408},"1":{"v":"\n- url: https://www.youtube.com/watch?v=uflMfvI-ZxI) @barry-smith\n- presenter @barry-smith\n\n## Typical Reasons for Ontology Failure\n\n- they're easy to make, so lots of them get made, so everyone has their own\n- brittle, use them once and drop them\n- bad languages\n- people don't understand what definitions are\n- no documentation\n- broken links","n":0.149}}},{"i":6353,"$":{"0":{"v":"Base Platform for Knowledge Graphs with Free Software","n":0.354},"1":{"v":"\n- https://ceur-ws.org/Vol-3401/paper6.pdf\n- mentions: [[prdct.trifid]] [[prdct.lodview]] [[prdct.graph-explorer]] [[prdct.linked-data-viewer]] [[prdct.rdf-surveyor]] [[prdct.shiro]] [[t.cs.data.5-star-open-data-model]] [[prdct.widoco]]\n- keywords: [[t.km.knowledge-graph]]\n\n![](/assets/images/2024-10-01-11-42-38.png)\n\n## Abstract\n\nWe present an Open Source base platform for the CoyPu knowledge graph project in the resilience domain. We report on our experiences with several tools which are used to create, maintain, serve, view and explore a modular large-scale knowledge graph, as well as the adaptions that were necessary to enable frictionless interaction from both performance and usability perspectives. For this purpose, several adjustments had to be made. We provide a broad view of different programs which are of relevance to this domain. We demonstrate that while it is already possible to achieve good results with free software, there are still several pain points that need to be addressed. Resolution of these issues is often not only a matter of configuration but requires modification of the source code as well.\n\n## Highlights\n\n### Introduction\n\n- While general approaches for KG development and maintenance are proposed, limited guidance regarding the selection of efficient tools for implementing these methodologies is available.\n\n### Related Work\n\n- While certain commercial tools like [[metaphactory|prdct.metaphactory]] or the [[Enterprise Knowledge Graph Platform|prdct.corporate-memory-enterprise-knowledge-graph-platform]] claim to offer comprehensive, all-in-one solutions, free and open-source alternatives often only address specific aspects. Consequently, users seeking to employ free and open-source tools must combine multiple applications and platforms to arrive at a complete knowledge graph platform.\n\n### Solutions and Other Tools\n\n#### Ontology Authoring\n\n- protege for ontology authoring\n- [[prdct.widoco]] for documentation and visualization\n- [[prdct.rdf-processing-toolkit]] for usage statistics\n- [[prdct.rdfunit]]\n\n#### Mapping structured data to RDF data. \n\n-Several different tools were used by the different project partners, for example [[prdct.tarql]], [[prdct.rdf-processing-toolkit]] or Morph-KGC [ 20 ]. Each tool was chosen by the familiarity of the expert user and applicability to the data source that is to be mapped. Tarql for instance is an excellent choice to map CSV to RDF. RPT on the other hand can easily process CSV, JSON, and XML input files as well as web APIs and remote services using SPARQL, and Morph-KGC can map CSV or connect to SQL databases using [[RML|prdct.rml]].\n- Especially the way to register custom functions in RML is quite heavy-handed, whereas RPT allows defining such functions using either JavaScript or Java annotations.","n":0.053}}},{"i":6354,"$":{"0":{"v":"Autonomous Agents and Multi Agent Systems","n":0.408},"1":{"v":"\n- #publisher [[org.springer]]\n- url: https://www.springer.com/journal/10458","n":0.447}}},{"i":6355,"$":{"0":{"v":"Attention Based Spatial Temporal Graph Convolutional Networks for Traffic Flow Forecasting","n":0.302},"1":{"v":"\n- url: https://guoshnbjtu.github.io/pdfs/AAAI2019-GuoS.2690.pdf","n":0.577}}},{"i":6356,"$":{"0":{"v":"Assessment and Benchmarking of Spatially Enabled Rdf Stores for the Next Generation of Spatial Data Infrastructure","n":0.25},"1":{"v":"\n- https://www.mdpi.com/2220-9964/8/7/310\n\n## Abstract\n\nGeospatial information is indispensable for various real-world applications and is thus a prominent part of today’s data science landscape. Geospatial data is primarily maintained and disseminated through spatial data infrastructures (SDIs). However, current SDIs are facing challenges in terms of data integration and semantic heterogeneity because of their partially siloed data organization. In this context, linked data provides a promising means to unravel these challenges, and it is seen as one of the key factors moving SDIs toward the next generation. In this study, we investigate the technical environment of the support for geospatial linked data by assessing and benchmarking some popular and well-known spatially enabled RDF stores (RDF4J, GeoSPARQL-Jena, Virtuoso, Stardog, and GraphDB), with a focus on GeoSPARQL compliance and query performance. The tests were performed in two different scenarios. In the first scenario, geospatial data forms a part of a large-scale data infrastructure and is integrated with other types of data. In this scenario, we used ICOS Carbon Portal’s metadata—a real-world Earth Science linked data infrastructure. In the second scenario, we benchmarked the RDF stores in a dedicated SDI environment that contains purely geospatial data, and we used geospatial datasets with both crowd-sourced and authoritative data (the same test data used in a previous benchmark study, the Geographica benchmark). The assessment and benchmarking results demonstrate that the GeoSPARQL compliance of the RDF stores has encouragingly advanced in the last several years. The query performances are generally acceptable, and spatial indexing is imperative when handling a large number of geospatial objects. Nevertheless, query correctness remains a challenge for cross-database interoperability. In conclusion, the results indicate that the spatial capacity of the RDF stores has become increasingly mature, which could benefit the development of future SDIs.","n":0.059}}},{"i":6357,"$":{"0":{"v":"Assessing the Suitability of Existing Owl Ontologies for the Representation of Narrative Structures in Sumerian Literature","n":0.25},"1":{"v":"\n- url: http://dlib.nyu.edu/awdl/isaw/isaw-papers/7/nurmikko-fuller/\n- repo: https://github.com/terhinurmikko/morsul\n\n# Text\n\n\n\nThis article is available at the URI http://dlib.nyu.edu/awdl/isaw/isaw-papers/7/nurmikko/ as part of the NYU Library's Ancient World Digital Library in partnership with the Institute for the Study of the Ancient World (ISAW). More information about ISAW Papers is available on the ISAW website.\n\nExcept where noted, ©2014 Terhi Nurmikko-Fuller; distributed under the terms of the Creative Commons Attribution License\nCreative Commons License\n\nThis article can be downloaded as a single file\nISAW Papers 7.18 (2014)\nAssessing the Suitability of Existing OWL Ontologies for the Representation of Narrative Structures in Sumerian Literature\nTerhi Nurmikko-Fuller\n\nOriginally a term from the realm of philosophical thought, the label of ‘ontology’ has been adopted and adapted by Computer Science and refers to a formalised structure used for organising knowledge. Together, a knowledge base (a triple store), an ontological structure and a reasoner (software) form an expert system which enables automated inference over a given data set – whilst this is possible without publication via the Web, in doing so, the expert system effectively gains access to an enriched dataset, as further relevant information becomes available from separate external data-streams across the entirety of the Web. This linking of datasets is subject to the same challenges as any equivalent exchange between humans: in order to share knowledge, systems need an effective method of communication. Our task as human experts in charge of data sets is to publish that data in machine-readable, non-proprietary formats, with clear URIs. The adoption of existing ontologies and controlled vocabularies enables the linking of new datasets to existing projects via shared elements such as locations (Pleiades gazetteer1, for example), people (perhaps though projects such as the Berkeley Prosopography Service2) or any other defined, identified element which occurs in more than one dataset.\nThe tools, the data\n\nOntologies have played a major role in my on-going doctoral research project, which combines elements from the domain of Semantic Technologies but focuses on Ancient World Data. This work in progress involves issues of Knowledge Representation, Description Logic, Coreference, and its tools are SPARQL, RDF, URIs and OWL. The aim of this research project is to assess the suitability of existing tools for the representation of the ambiguous, incomplete and at times unknown literary narratives that play out within the content of compositions written in the ancient language of Sumerian, and published by the Electronic Text Corpus of Sumerian Literature (henceforth ETCSL)3, an online resource from the University of Oxford, which allows the public free and unlimited access to the lemmatised transliteration and English translation of some 400 composite texts.⬈#p2\nTwo OWL ontologies\n\nThis research project began with an extensive review, and led to the identification and subsequent evaluation of two OWL ontologies thought to be suitable for the representation of cultural heritage data and narrative structures: the CIDOC Conceptual Reference Model (CIDOC CRM)4 and Ontomedia (OM)5. The decision to include the CIDOC CRM was two-fold. Firstly, this event-based reference model is specifically designed as the “semantic glue”6 for linking cross-domain cultural heritage data, and has been implemented by institutions with large cuneiform collections, such as the British Museum.7 Although the ETCSL carries little object data directly, the print, electronic and cuneiform sources for each composite text are listed with each transliteration and serve as potential anchoring points for clusters of RDF triples that would allow the enrichment of the ETCSL data from other sources within Assyriology and the wider Digital Heritage community. Secondly, OM, the second ontology and one designed for the representation of narrative, was purposely designed to link to the CIDOC CRM (Lawrence 2008). Unlike the CIDOC CRM which is one large, all-encompassing structure, OM consists of several interlinking sub-ontologies, amongst which the user-consumer can opt to pick and choose any that bear relevance to their data. OM is essentially an domain-specific upper-level ontology : this oxymoron can be justified if one agrees that the ontological representation of narratives is itself a niche topic but that since OM seeks to be applicable to all fictional narratives (regardless of sub-genre), it can be seen as an example of the class of upper-level ontologies.\nmORSuL\n\nThe combination of the CIDOC CRM and OM and the addition of a number of specific elements deemed necessary resulted in the creation of mORSuL (the multi-Ontology Representing Sumerian Literature). Thus far, it has been implemented in the Stanford University ontological editor, Protégé8 and serves as part of a proof-of-concept. Preliminary trials with mORSuL have led to two initial conclusions: the ontology is to be extended further to allow for the mapping of bibliographical data as published by the ETCSL (BIBO9 and FRBRoo10 are likely candidates) and the representation of literary tools such as similes, metaphors and analogies. Secondly, the resulting large and complex structure ought to be reduced to contain only those classes and properties which truly match the data available from the ETCSL.\nSumerian humour as an example case study\n\nThe next step was to test mORSuL with a case-study example. The chosen composition Three Ox-drivers of Adab is thought to be a humorous one (Alster, 1991-1993; Foster, 1974) and has a narrative structure with repetitive patterns within a frame story – due to the incomplete nature of the latter part of the piece (a result of the fracture and loss of the lower parts of the witness tablets on which the composite text is based) the representation was limited to the first 35 lines only. The composite text as published by the ETCSL is based on the witnesses AO 7739 (TCL 16 80), AO 9149 (TCL 16 83) and CBS 1601.\n\nThe story unfolds as follows: There are three friends, all citizens of Adab, who are quarrelling. Unable to solve their dispute, they decide to seek justice and approach the king. They account their story to the king: They are three ox-drivers, one of whom owns an ox, the other a cow, the third a wagon. They became thirsty and suggested that one of them should go and fetch water so that they could all drink. They asked each other, each in turn to go, but all refuse in turn, citing reasons relevant to their possessions: the owner of the ox is afraid it will be devoured by a lion if left unattended; the owner of the cow that his animal will wonder into the desert; the owner of the wagon that the goods will be stolen from it. They agree to all to go together, and in their absence, the ox mounts the cow, the cow gives birth to a calf and the calf eats the load on the wagon. Who, they ask the king, does the calf belong to? The king, unable to provide the solution, seeks the council of a “cloistered lady”, to whom he repeats the story of the ox-drivers verbatim. Sadly, the remainder of the composition which presumably contained the solution to this riddle is fractured and incomplete, and we, the audience, are left in suspense and without closure.\nOntological representation of inscription content\n\nIn terms of representing the narrative content via ontological structures, a number of points of interest arise. Although these issues are discussed in greater detail in my thesis (forthcoming), a few examples can be cited to exemplify the types of decisions which need to be made when representing the narrative and the fabula (as defined by Bal, 2009). Firstly, although the events depicted are fictional, the story is set in, or at least refers to, the historical city of Adab (modern Bismaya). The natural laws that govern our reality are applicable to the main ome:Context too (the “reality” in which the story takes place) and at no point is the reader required to suspend their disbelief or encounter entities or events that are magical, supernatural or within a dream. The events as told by the ox-drivers may appear farcical, but are not beyond the remit of plausible realism. The same can be said of the protagonists and their possessions, none of which are supernatural or anthropomorphised.\n\nAll the protagonists are considered as instances of omb:Character – they are fictional but can be argued to have a perceivable personality. Each protagonist has at least one unique and definable quality (in the case of the ox-drivers, their possessions) and the bonds of friendship and allegiance are fairly straightforward as is the fall into a dispute (over a given timeline, these omb:Characters who share a positive omb:Alliance bond acquire a negative omb:Enmity). The representation of the ox-drivers’ decision to seek justice is however more complex as is the decision whether to treat it as an instance pertaining to a ome:Social subclass of Legal. It is also worth noting that from the perspective of each ox-driver, they are (presumably) each seeking a decision favourable to themselves and not one which is truly fair. Furthermore, the only account of the events that form the main part of the narrative are the focalised memories of the ox-drivers, and the subsequent retelling of these events by the king, who did not witness them first hand. It may also be argued that the focalised story told to the king is to be seen as an amalgamation of three separate accounts of the events that took place outside the narrative, and the story told to the king is effectively a “composite memory”.\nFurther work\n\nResearch into the representation of Sumerian literary narratives using OWL ontologies continues. The next, imminent stages of the project include the extension and reduction of mORSuL, as well as the addition of data from other Sumerian literary compositions, so that the structure can be queried in terms of intertextuality, reoccurring motifs and possible instances of literary allusions.\n\nAuthor's note: This research was funded by the Research Councils UK Digital Economy Programme, Web Science Doctoral Training Centre, University of Southampton. EP/G036926/1.\nNotes\n\n1 http://pleiades.stoa.org/.\n\n2 http://berkeleyprosopography.org/.\n\n3 http://etcsl.orinst.ox.ac.uk/.\n\n4 http://www.cidoc-crm.org.\n\n5 http://www.contextus.net/ontomedia.\n\n6 http://www.cidoc-crm.org/index.html.\n\n7 http://collection.britishmuseum.org/.\n\n8 http://protege.stanford.edu/.\n\n9 http://bibliontology.com/.\n\n10 http://www.cidoc-crm.org/frbr_inro.html.\nWorks Cited\n\nAlster, B. (1991-93). \"The Three Ox-Drivers from Adab\". In Journal of Cuneiform Studies 43-45. 27-38.\n\nBal, M. (2009). Narratology: Introduction to the Theory of Narrative (3rd Ed), University of Toronto Press.\n\nBlack, J.A., Cunningham, G., Ebeling, J., Flückiger-Hawker, E., Robson, E., Taylor, J., and Zólyomi, G. (1998–2006). The Electronic Text Corpus of Sumerian Literature, Oxford. Available at <http://etcsl.orinst.ox.ac.uk/>.\n\nFoster, B. R. (1974). \"Humor and Cuneiform Literature\". In JANES 6. 69-85.\n\nLawrence, F. (2008) “The Web of Community Trust Amateur Fiction Online: A Case Study in Community Focused Design for the Semantic Web”, PhD thesis, University of Southampton. Available at: <http://eprints.soton.ac.uk/264704/2.hasCoversheetVersion/thesis.pdf>.\n\n©2014 Terhi Nurmikko-Fuller. Published under the Creative Commons Attribution 4.0 license.\n\nThis article is part of ISAW Papers 7.\n","n":0.024}}},{"i":6358,"$":{"0":{"v":"Architecture Weekly","n":0.707}}},{"i":6359,"$":{"0":{"v":"Webinar 9 Radek Maziarka Modularization","n":0.447},"1":{"v":"\n- url: https://www.architecture-weekly.com/p/webinar-9-radek-maziarka-modularization","n":0.577}}},{"i":6360,"$":{"0":{"v":"Webinar 7 Design and Test Event Driven","n":0.378},"1":{"v":"\n- url: https://www.architecture-weekly.com/p/webinar-7-design-and-test-event-driven\n- ","n":0.577}}},{"i":6361,"$":{"0":{"v":"In-memory Message Bus in TypeScript","n":0.447},"1":{"v":"\n- https://event-driven.io/en/inmemory_message_bus_in_typescript/\n\n## Highlights\n\n### Direct and Indirect Communication\n\nThere are two ways of communicating: direct and indirect. For direct communication, we ask another component to perform a specific action and want to know if that happened. For indirect communication, we notify others that something has happened and let them decide what to do. In a nutshell, direct is represented by command, and indirect by event. Read more in What’s the difference between a command and an event?.\n\nTypically, direct communication is assumed to be blocking and indirect non-blocking, but that’s a common practice, not a rule. Both types of communication can be blocking or non-blocking. In the real world, we may ask other people to do something and wait until they finish or assume that they will reply to us when they have done it. For indirect communication, even though we’re not interested in what will happen after we broadcast news, we’d like to know whether all interested parties took action.\n\n","n":0.08}}},{"i":6362,"$":{"0":{"v":"Applied Temporal Rdf Efficient Temporal Querying of Rdf Data with Sparql","n":0.302},"1":{"v":"\n- https://drive.google.com/open?id=1-V3E93i9gqdOEHzVMyiHJMTGjahh62GU&usp=drive_fs\n\n## Abstract\n\nMany applications operate on time-sensitive data. Some of these data are only valid for certain intervals (e.g., job-assignments, ver- sions of software code), others describe temporal events that happened at certain points in time (e.g., a person’s birthday). Until recently, the only way to incorporate time into Semantic Web models was as a data type property. Temporal RDF, however, considers time as an additional dimension in data preserving the semantics of time. \n\nIn this paper we present a syntax and storage format based on named graphs to express temporal RDF. Given the restriction to preexisting RDF-syntax, our approach can perform any temporal query using stan- dard SPARQL syntax only. For convenience, we introduce a shorthand format called τ -SPARQL for temporal queries and show how τ -SPARQL queries can be translated to standard SPARQL. Additionally, we show that, depending on the underlying data’s nature, the temporal RDF ap- proach vastly reduces the number of triples by eliminating redundancies resulting in an increased performance for processing and querying. Last but not least, we introduce a new indexing approach method that can significantly reduce the time needed to execute time point queries (e.g., what happened on January 1st).\n\n## Highlights\n\n### Related Approaches\n\n#### Temporal Extensions\n\n- Welty and Fikes [6], Kim et al. [7] and the tOWL [8] project aim at introducing temporal entities into OWL.\n\n#### Time Encoded in the Data Model\n\n- lose the semantics of time\n- temporal properties can't be attached to relations\n\n#### Graph Versions and Version Management Systems\n\n- SemVersion uses its own data model that contains the user’s ontology and its evolution. Our proposi- tion is not to introduce a new data model, but, storing the elements of the users’ data model inside different named graphs according to their temporal context.\n\n### Proposed Temporal Syntax\n\n- As in most of the approaches dealing with temporal entities, we model time as a 1-dimensional discrete value (i.e. no branching time)\n- we extended OWL- Time with a new date format type called IntegerTime to express non-calendaric time representations such as version numbers.\n- We refer to a set of temporally related named graphs as a temporal graph. Each time interval is represented by exactly one named graph, where all triples belonging to this graph share the same validity period.\n  ","n":0.052}}},{"i":6363,"$":{"0":{"v":"Applied Ontology","n":0.707},"1":{"v":"\n- topics: [[t.cs.sd.modeling.conceptual-modeling.ontology-driven]] [[t.phil.conceptualization]]\n\n## Aims and Scope\n\n_Applied Ontology_ is affiliated with the [International Association for Ontology and its Applications (IAOA)](https://iaoa.org/).\n\nIn recent years, the dramatic growth of information and communication technologies has led to an increasingly interdisciplinary approach to research and development activities in these fields. To exploit the immense opportunities of widespread networks effectively, designers of modern information systems need to combine the precision of formal semantics with the needs of cognitive transparency, as they incorporate increasingly sophisticated and heterogeneous information content. The recent explosion of interest on ontologies is an important component of this trend. Researchers in disciplines such as knowledge engineering, information systems modeling, artificial intelligence, formal and computational linguistics, information retrieval, library science, and knowledge management have come to realize that a solid foundation for their research calls for serious work in ontology, understood as a general theory of the types of entities and relations that make up their respective domains of inquiry. In all these areas, attention has started to focus squarely on the content of information, rather than on just the formats and languages used to represent that content.\n\n_Applied Ontology_ focuses on information content in its broadest sense. As the subtitle makes clear, two broad kinds of content-based research activities are envisioned: ontological analysis and conceptual modeling. The former includes any attempt to investigate the nature and structure of a domain of interest using rigorous philosophical or logical tools; the latter concerns the cognitive and linguistic structures we use to model the world, as well as the various analysis tools and methodologies we adopt for producing useful computational models, such as information systems schemes or knowledge structures. _Applied Ontology_ is the first journal with explicit and exclusive focus on ontological analysis and conceptual modeling under an interdisciplinary view. It aims to establish a unique niche in the realm of scientific journals by carefully avoiding unnecessary duplication with discipline-oriented journals. For this reason, authors will be encouraged to use language that will be intelligible also to those outside their specific sector of expertise, and the review process will be tailored to this end. For example, authors of theoretical contributions will be encouraged to show the relevance of their theory for applications, while authors of more technological papers will be encouraged to show the relevance of a well-founded theoretical perspective. Moreover, the journal will publish papers focusing on representation languages or algorithms only where these address relevant content issues, whether at the level of practical application or of theoretical understanding. Similarly, it will publish descriptions of tools or implemented systems only where a contribution to the practice of ontological analysis and conceptual modeling is clearly established.\n\n_Applied Ontology_ aims at being a major publication forum for theoretical and applied research in a variety of topics, tentatively grouped together in research areas, examples of which are indicated in the list below.\n\n-   **Foundational issues** • Philosophical foundations of ontology • Basic ontological categories and relations • Ontology, epistemology, and semiotics\n-   **Specialized ontologies** • Ontology of time, events and processes • Ontology of space and geography • Ontology of physics and physical objects • Ontology of biomedicine • Ontology of mental entities • Ontology of agents and actions • Ontology of organizations and social reality • Ontology of the information society • Ontology of business and e-commerce • Ontology of law • Ontology of history, culture and evolution\n-   **Ontology development and ontology-driven conceptual modeling** • Methodologies for ontology development • Impact of ontological analysis on current modeling practices • Best-practice examples and case studies\n-   **Ontology management** • Tools for ontology development, analysis and comparison • Comparison and evaluation of ontologies • Ontology management, maintenance, versioning • Methodologies for ontology merging, alignment, and integration • Semantic Web\n-   **Ontology and language** • Ontology and natural-language semantics • Ontology and lexical resources • Ontology and terminology • Ontology learning techniques and their evaluation • Role of ontology in natural-language systems\n-   **Ontology, cognition, perception** • Conceptual schemas, perceptual invariances and ontological categorization • Psychological experiments evaluating the cognitive adequacy of ontological categories\n-   **Ontology and content standards** • Library science • Knowledge organization • Museums and cultural repositories • Multimedia content • Product descriptions • Process and service descriptions • Biomedical and other scientific terminologies\n-   **Innovative ontology-based applications**\n","n":0.038}}},{"i":6364,"$":{"0":{"v":"From Slot Mereology to a Mereology of Slots","n":0.354},"1":{"v":"\n## Abstract\n\n","n":0.707}}},{"i":6365,"$":{"0":{"v":"Annotation of Multimedia Using onto Media","n":0.408},"1":{"v":"\n- https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=13a85dd949eefca66c4f6b69187b381a5b5ffd0d\n- authors: @michael-jewell @faith-lawrence @m-schraefel\n- mentions: [[prdct.fiction-finder]] [[prdct.screenplays-in-xml-six]]\n\n## Abstract\n\nWhile ontologies exist for the annotation of monomedia, interoperability between these schemes is an important issue. The OntoMedia ontology consists of a generic core, capable of representing a diverse range of media, as well as extension ontologies to focus on specific formats. This paper provides an overview of the OntoMedia ontologies, together with a detailed case study when applied to video, a scripted form, and an associated short story.\n\n## Highlights\n\n### Annotating Multimedia: A Case Study\n\n-  a scene from [[video.total-recall]] was annotated such that the script and associated characters could be represented the framework. The characters from the related book, ‘[[We Can Remember It For You Wholesale|book.we-can-remember-it-for-you-wholesale]]’ were also annotated, and our example queries demonstrate how the two forms may be linked\n-  \n\n```xml\n<?xml version=\"1.0\" encoding=\"iso-8859-1\" standalone=\"no\" ?>\n<sc:script xmlns=\"http://www.w3.org/1999/xhtml\"\nxmlns:dc=\"http://purl.org/dc/elements/1.1/\"\nxmlns:sc=\"http://mikesroom.org/script\">\n  <sc:info>\n  <dc:title>Total Recall</dc:title>\n  </sc:info>\n  \n  <sc:location time=\"day\" pos=\"int\">HILTON - CORRIDOR/SERVICE ELEVATOR - 6TH FL.</\n  sc:location>\n  <sc:dialogue speaker=\"Lori\">Doug...you wouldn&apos;t hurt me, would you, honey?\n  </sc:dialogue>\n  <sc:direction>She sees his expression.</sc:direction>\n  <sc:dialogue speaker=\"Lori\" ctd=\"1\">Sweetheart, be reasonable...We&apos;re\n  married.</sc:dialogue>\n  <sc:direction>Lori stealthily reaches behind her back for a concealed gun and\n  pulls it on him.</sc:direction>\n  <sc:direction>Quaid shoots Lori in the forehead, leaving a clean, small hole\n  between her eyes.</sc:direction>\n  <sc:dialogue speaker=\"Quaid\" paren=\"rising, to Melina\">Consider that a divorce.\n  </sc:dialogue>\n</sc:script>\n```","n":0.069}}},{"i":6366,"$":{"0":{"v":"Annotation of Heterogenous Media Using onto Media","n":0.378},"1":{"v":"\n- http://image.ntua.gr/swamm2006/resources/paper12.pdf\n- authors: @michael-jewell @faith-lawrence @adam-prugel-bennett @m-schraefel\n- mentions: [[prdct.meditate]]","n":0.333}}},{"i":6367,"$":{"0":{"v":"Annotated Hypergraphs Models and Applications","n":0.447},"1":{"v":"\n- [[p.hasURL]] https://appliednetsci.springeropen.com/articles/10.1007/s41109-020-0252-y\n- #summary\n  - In this article, we consider an important and relatively general class of metadata in which nodes are assigned roles in each edge\n- [[p.hasSummaryPoints]]\n  - networks cannot be represented by via the classical paradigm of dyadic graphs without a significant loss of model fidelity.\n  - \"Roles are assigned neither to nodes or to edges, but rather to node-edge pairs.\"\n- [[p.provokedThoughts]]\n  - \"edges in which the same node appears twice are not allowed\" \n    - why not?\n      - seems like just for \"experimental convenience\"\n    - \"It is difficult to find a modeling justification for hypergraphs with role-degenerate edges, but degenerate edges may have modeling applications\"\n    - role-degenerate: same node v appears twice in e, with the same role.  \n  - \"polyadic interactions\" = \"n-ary relations\"\n  - \"nodes of high degree tend to connect to other nodes of high degree\" \n","n":0.084}}},{"i":6368,"$":{"0":{"v":"Andymatuschak","n":1},"1":{"v":"\n- [[p.hasURL]] https://andymatuschak.org/\n- [[p.instanceOf]] [[c.digitalgarden]]\n","n":0.447}}},{"i":6369,"$":{"0":{"v":"Andy Matuschak's Notes","n":0.577},"1":{"v":"\n\n- [[p.hasURL]] https://notes.andymatuschak.org/\n- [[p.instanceOf]] [[c.digitalgarden]]\n","n":0.447}}},{"i":6370,"$":{"0":{"v":"Anagora","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://anagora.org\n- [[p.isRelated]] [[prdct.agora]]\n","n":0.447}}},{"i":6371,"$":{"0":{"v":"An Overview of OntoClean","n":0.5},"1":{"v":"\n- http://ontolog.cim3.net/file/resource/presentation/OntoClean--ChrisWelty_20041118/guarinowelty_final_v4.pdf\n- authors: @nicola-guarino @christopher-welty\n\n## Summary\n\nOntoClean is a methodology for validating the ontological adequacy of taxonomic relationships. It is based on highly general ontological notions drawn from philosophy, like essence, identity, and unity, which are used to characterize relevant aspects of the intended meaning of the properties, classes, and relations that make up an ontology. These aspects are represented by formal metaproperties, which impose several constraints on the taxonomic structure of an ontology. The analysis of these constraints helps in evaluating and validating the choices made. In this chapter we present an informal overview of the philosophical notions in- volved and their role in OntoClean, review some common ontological pitfalls, and walk through the example that has appeared in pieces in previous papers and has been the basis of numerous tutorials and talks.\n\n\n\n## Highlights\n\n\n### Locations\n\nOur assignment is +O~U+R. We assume the property to be rigid since instances of locations cannot change being locations. Identity is given by the fact that two locations are the same if and only if they have the same parts. This kind of criterion is fairly com- mon, and is known as mereological extensionality. It applies to all entities that are trivially defined to be the sum of their parts. It is important to realize that this cri- terion implies that a location or region cannot “expand” – if so then the identity criteria would have to be different. So, extending a location makes it a different one. ","n":0.064}}},{"i":6372,"$":{"0":{"v":"An Ontology for Videogame Interoperability","n":0.447},"1":{"v":"\n- url: https://dgarijo.com/papers/vgo.pdf\n\n## Abstract\n\n...despite the growth on video game industry, there is a lack of interoperability that allow developers to interchange their information freely and to form stronger partnerships. In this paper we present the Video Game Ontology (VGO), a model for enabling interoperability among video games and enhancing data analysis of gameplay information. We describe the creation process of the ontology, the ontology conceptualization and its evaluation. In addition, we demonstrate the applicability of the Video Game Ontology in action with three example games that take advantage of the created ontology. Also, we demonstrate the use of the VGO in enabling interoperability among the example games.\n\n\n","n":0.097}}},{"i":6373,"$":{"0":{"v":"An Ontology for Supporting the Evolution of Virtual Reality Scenarios","n":0.316},"1":{"v":"\n- https://cgi.csc.liv.ac.uk/~valli/OWLED2015/OWLED_2015_paper_5.pdf\n- related: [[prdct.cojack]] [[prdct.presto-ontology]]\n\n![](/assets/images/2024-10-24-13-17-35.png)\n\n## Abstract\n\nSerious games with 3D interfaces are Virtual Reality (VR) systems that are becoming common for the training of military and emergency teams. A platform for the development of serious games should allow the addition of semantics to the virtual environment and the modularization of the artificial intelligence controlling the behaviors of non-playing characters in order to support a productive end-user development environment. In this paper, we report the ontology design activity performed in the context of the PRESTO project aiming to realize a conceptual model able to abstract the developers from the graphical and geometrical properties of the entities in the virtual reality, as well as the behavioral models associated to the non-playing characters.\n\n## Highlights\n\n- we focus on the experience of using Semantic Web techniques, and in particular lightweight ontologies, for the high level description of the artificial entities (including characters) and their behaviors in gaming in order to uncouple the description of scenarios performed by the trainers from their physical implementation in charge to the developers. Differently from a number of works in literature that often uses ontologies for a detailed description of the geometrical properties of space and objects, the focus of our work is on the description of the entities of a VR scenario from the cognitive point of views of the trainers and the developers alike, in a way that is semantically well founded and independent of a specific game or scenario [1], and with the goal of fostering clarity, reuse, and mutual understanding.\n\n- The open problems addressed by this project may be summarized as follows:\n1. the perception of the virtual environment by an artificial character and the execution of its models and procedures must be able to adapt to the context, to its history and status (fatigue, emotions, intake of stimulants such as caffeine or depressants such as alcohol) and must maintain a level of variability (i.e. in the accuracy of the vision, the rate of reaction, in the choices among alternatives) such that the behavior is plausible but not trivially predictable;\n2. the representation of procedures and patterns of behavior must be independent of one specific usage scenario and accessible to training specialists (i.e. industrial safety or civil protection) rather than just a computer, in an environment facilitating the definition and configuration of training scenarios by such specialists.\n\n### PRESTO Ontology Design\n\n- , building everything from the ground up by relying on domain experts and using one of the state of the art ontology engineering methodologies such as [[prdct.methontology]]\n","n":0.049}}},{"i":6374,"$":{"0":{"v":"An Ontology for Collaborative Tasks in Multi Agent Systems","n":0.333},"1":{"v":"\n- https://ceur-ws.org/Vol-1442/paper_4.pdf\n- topic: [[prdct.owl-t]]\n\n## Abstract\n\nThis paper proposes an ontology for task representation and infer- ence. The ontology was developed to support reasoning about tasks, such as task recognition and relocation. Our proposal is formalized in OWL (Web On- tology Language) and SWRL (Semantic Web Rule Language). We show one scenario to exemplify reasoning situations based on the axioms and rules of our ontology. This knowledge-level representation of tasks can be explored to sup- port reasoning about activities for groups of people. The knowledge asserted and inferred in the ontology is useful in multi-agent systems to enhance agent coordination and collaboration through reasoning over tasks. An evaluation of the proposed ontology is presented\n\n\n## Highlights\n\n![](/assets/images/2024-04-11-10-03-20.png)\n\n- the main and most generic concepts of the proposed task ontology are: Task, Person, Location, Object, TimeInterval and TaskPurpose\n- ","n":0.087}}},{"i":6375,"$":{"0":{"v":"An Ontology for Agent Based Modeling and Simulation","n":0.354},"1":{"v":"\n- https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7db660023a2734b826b6dde61f8c18e8ce146da8\n- authors: @scott-christley, @xiaorong-xiang, @greg-madey\n- keywords: [[t.cs.agents.agent-based-modeling]], [[t.cs.agents.agent-based-simulation]], [[t.cs.ai.automated-reasoning]], [[t.km.ontology]], [[t.cs.simulation.discrete-event]]\n\n## Abstract\n\nOntologies are a formal methodology for establishing a common vocabulary, for defining the concepts and relationships between those concepts of a particular domain, and for reasoning about the objects, behaviors, and knowledge that comprises the domain. In this paper, we present an ontology for agent-based modeling and simulation. Agent-based modeling and simulation has become an important and popular paradigm for the computational social and natural sciences; however, the application of this paradigm tends to be performed in an ad-hoc fashion leading to questions about underlying assumptions in an agent-based model, verification of the software implementation as a representation of that model, and validation of hypothesized conclusions inferred from data produced by computer simulation experiments. An ontology provides a formal, logical knowledge representation that supports automated reasoning. Such reasoning capability provides for consistency checking of the concepts and relationships in an agent-based model, can infer the assumptions inherent in a model, can infer the assumptions and the parameters inherent in a simulation or software representation of a model, and can enforce adherence to formal methods or best practices for verification and validation testing. These reasoning tasks direct, or at least inform, the modeler about relevant techniques and methods in the agent-based paradigm. The reasoning capability also provides a framework for automated generation of software code, automated design and execution of simulation experiments as well as automated generation and execution of validation tests for those experiments. Using the standard Ontology Web Language (OWL), we provide a complete, detailed ontology of agent-based modeling and simulation, and we show how the ontology is used as part of the modeling and simulation process.\n\n\n\nABDESO, a foundational ontology for agent-based discrete event simulation","n":0.059}}},{"i":6376,"$":{"0":{"v":"An Ontological Analysis of Business Process Modeling and Execution","n":0.333},"1":{"v":"\n- https://arxiv.org/abs/1905.00499\n  - https://arxiv.org/pdf/1905.00499\n- topics: [[prdct.bpmn]] [[t.cs.sd.business-process-modeling]] [[t.cs.workflow]] [[t.km.ontology]]\n\n## Abstract\n\nThis work presents a fully elaborated ontology, defined via the Ontology Web Language (OWL), of the Business Process Model and Notation ([[prdct.bpmn]]) standard to define business process models, and we demonstrate that any BPMN model can be serialized as OWL file. Based on ontological analysis and a corresponding definition of a modeling notation as ontology we show that business process models can be transformed from one notation into another one as long as there are common underlying concepts; this is demonstrated with the case of an actor based, or subject-oriented, view on business processes. Furthermore, a reference architecture for Workflow Management Systems (WfMS) based on microservices is discussed which is capable of executing actor based business process models. As a transformation of BPMN models into the actor based view is generally possible, also BPMN models could be enacted. As a result, we can conclude that the actor system is a promising way to stimulate new ways to design workflow management systems and to design business process modeling languages which are more comfortable to use by non-experts without losing necessary expressiveness. Another result is that an ontology is a productive way to define a modeling notation as it can be used as knowledge base, it is a formal conceptualization of the underlying notions, and can be semantically enriched for further use.","n":0.066}}},{"i":6377,"$":{"0":{"v":"An Introduction to the Link Grammar Parser","n":0.378},"1":{"v":"\n- url: https://www.link.cs.cmu.edu/link/dict/introduction.html","n":0.577}}},{"i":6378,"$":{"0":{"v":"An Initial Comparison of Selected Agent Based Simulation Tools in the Context of Industrial Health and Safety Management","n":0.236},"1":{"v":"\n- https://dl.acm.org/doi/fullHtml/10.1145/3543712.3543745\n- comparands: [[prdct.netlogo]] [[prdct.gama]] [[prdct.repast-simphony]]\n\n## Summary\n\n- NetLogo and GAMA appear to be more suitable than Repast. The latter - although very versatile - requires a high amount a programming skills. GAMA's primary strength on the other hand is the heavy focus on GIS data involvement, while NetLogo is not only very intuitive in learning but offers also a large number of features.","n":0.126}}},{"i":6379,"$":{"0":{"v":"An Infrastructure for Collaborative Ontology Development","n":0.408},"1":{"v":"\n- https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA210375\n- authors: @dean-allemang @pawel-garbacz @przemyslaw-gradzki @elisa-kendall @robert-trypuz\n- topics: [[t.km.ontology]] [[t.cs.sd.continuous-integration]] [[prdct.financial-industry-business-ontology-fibo]]\n- related: [[prdct.ontology-development-kit]]\n\n## Abstract\n\nCollaborative development of a shared or standardized ontology presents unique issues in workflow, version control, testing, and quality control. These challenges are similar to challenges faced in large-scale collaborative software development. We have taken this idea as the basis of a collaborative ontology development platform based on familiar software tools, including Continuous Integration platforms, version control systems, testing platforms, and review workflows. We have implemented these using open-source versions of each of these tools, and packaged them into a full-service collaborative platform for collaborative ontology development. This platform has been used in the development of FIBO, the Financial Industry Business Ontology, an ongoing collaborative effort that has been developing and maintaining a set of ontologies for over a decade. The platform is open-source and is being used in other projects beyond FIBO. We hope to continue this trend and improve the state of practice of collaborative ontology design in many more industries\n\n","n":0.078}}},{"i":6380,"$":{"0":{"v":"An Extensible Approach to Multi Level Ontology Modelling","n":0.354},"1":{"v":"\n- https://www.scitepress.org/PublishedPapers/2021/106842/106842.pdf\n- topics: [[t.km.ontology.multi-level-theory]]\n\n## Thoughts\n\n- If you have to run SPARQL queries continuously, you might as well just add the information to the model explicitly\n\n## Highlights\n\n### Introduction\n\n- in the Vertebrate Taxonomy Ontology (VTO) (Phenoscape, 2021) and the NCBI Taxonomy (NCBI, 2021), all biological species are modelled as classes\n- In contrast, in the Wildlife Ontology (WO) (BBC, 2021) and in the Global Biodiversity Information Facility (GBIF, 2021), biological species are modelled as instances.\n  - The authors of the WO state on (BBC, 2021): “One perennial problem associated with modelling biological taxonomies using RDF is whether to attempt to model individual species as classes, or whether to simply model species as instances of a generic Species class. The latter approach is simpler and avoids creating a huge ontology that attempts to model all biological organisms. Existing ontologies have taken different approaches to resolving this issue, some choosing one style, others another. At present there doesn’t seem to be a consensus. With this in mind, the Wildlife Ontology adopts the simpler of the two approaches, i.e. modelling species as instances of a Species class, as this maximises interoperability with many of the existing Linked Data sources, particularly dbpedia, which adopt similar approaches.”\n- **The contribution of this paper is a modelling approach which rigorously utilizes multi-facet (Atkinson and Kühne, 2001; Neumayr et al., 2009; Frank, 2014) behaviour, an aspect of multi-level modelling, allowing entities to be modelled as classes (class facet) and instances (instance facet) simultaneously**\n\n### Related Work\n\n- classes are described as groups of resources and instances as their members. \n- @dean-allemang calls the reaction of defining everything as classes \"rampant classism\"\n  - \"We agree with them\"\n- (Noy and McGuinness, 2021) [[ar.ontology-development-101-a-guide-to-creating-your-first-ontology]]: A criterium they define for the decision to model something as a class or an instance is the lowest level of granularity in the representation.\n  - i.e., individual instances are the most specific concepts represented in a knowledge base\n- various authors recommend modelling pairs of classes where a class is associated with a corresponding type class\n  - modelling pattern is called materialization pattern ^pvldw3ag53on\n  - the term powertype is used in (Odell, 1994) and (Guizzardi, et al., 2015). ^vt540o589i6g\n- With conventional modelling approaches it is not possible to mix the properties of base class and its powertype into one class, since it makes no sense to have a property Number_Plate for a Car_Model.\n- **Our approach is simpler insofar as it does not require separate entities Car and Car Model while still explicitly distinguishing between the different facets.**\n- Another approach to avoid separate entities Car and Car Model is described in (Neumayr et al. 2009), called Multi-Level Domain Modeling. Properties are annotated with meta attributes which define rules for inheritance and instantiation. E.g. for the base class Car the data property maxSpeed is annotated with :model to refer to a Car_Model while the data property Milage is annotated with :physical_entity to refer to an individual car. This allows merging the properties of Car and Car_Model into only one class Car while keeping the semantics of the properties clear.\n- In a comparable approach (Frank, 2014), level numbers are assigned to properties. For Car the property Milage would be defined with level=0 which corresponds to the :physical_entity annotation in (Neumayr et al. 2009), while maxSpeed would be annotated with level=1 which corresponds to the :model annotation. Annotating properties with multiple levels or with different levels for different contexts is not possible, as is enabled in our approach.\n- In (Brasileiro et al., 2016a), a fixed separation of entities into individuals, 1 st order type, 2 nd order type and 3 rd order type is proposed. Our approach is more flexible as it allows context-dependent viewpoints.\n- Multi-facet behaviour as used in (Neumayr et al., 2009) may regard entities as classes and instances simultaneously, where needed. \n  - In contrast, OWL 1 DL requires a strict separation between the classes and individuals (W3C, 2012). Insofar, multi-facet behaviour is not compatible with OWL1 DL. \n  - OWL 2 DL relaxes this separation somewhat to allow different uses of the same term which is called [[t.cs.semantic-web.punning]]. \n    -  “e.g., Eagle, to be used for both a class, the class of all Eagles, and an individual, the individual representing the species Eagle belonging to the (meta)class of all plant and animal species”. \n    - However, OWL 2 DL still imposes certain restrictions, e.g., a name can only be used for one kind of property (W3C, 2012).\n\n### Example: Animal Ontology\n\n- based on [[prdct.wildlife-ontology-wo]] but adds [[prdct.skos]]\n- we favour a simple modelling approach modelling concrete species like polar bear as instances. \n- We use the object property skos:broader to specify\nthe biological taxonomy,\n- concrete taxons are attributed with\nproperties, e.g.:\n```turtle\n:Polar_Bear skos:altLabel \"Ursus maritimus\" .\n```\n\n### Multi-Facet Behaviour\n\n![[t.cs.semantic-web.class#^6ij3g83vefyj]]\n- In RDF/RDFS it is not forbidden to specify an entity as an instance of something which has not been specified as a class. Although this is syntactically correct, we consider this a modelling flaw.\n- It is also allowed to model something as a class and an instance simultaneously. Every class is an example of this pattern since every class is an instance of rdfs:Class. Also rdfs:Class is an example of this since it is a class and additionally an instance of itself.\n  - In (Atkinson and Kühne, 2001) and (Neumayr et al., 2009) this is called multi-facet. \n  - It is argued that this may considerably reduce unnecessary complexity in ontologies with multiple levels. \n  - We agree with them and use the multi-facet behaviour to add capabilities to ontologies like AO incrementally when required by new use cases.\n\n### Property Types\n\n- Datatype properties as well as object properties always relate to the instance facet of an entity\n- Does the fact that the species polar bear is vulnerable mean that the individual polar bear Knut is vulnerable? No\n```turtle\n:Bears :habitat :Terrestrial_habitat.\n:Terrestrial_habitat a :Habitat.\n:Habitat a rdfs:Class.\n```\n- Again, this information relates to the instance facet of the biological family of bears.\n  - Does this information also apply to all genus and species of the family bears? Yes\n  - And how about individual animals like Knut? Yes\n- [although] both properties :conservation_status and :habitat relate to the instance facet, they are semantically different.\n  - The difference is how information can be inferred between the facets along hierarchies within the facets.\n    - this semantic difference is independent of the distinction between object properties and datatype properties\n\n### Inheritance\n\n- for inferring information between facets as well as along hierarchies within facets, e.g., rdfs:subClassOf hierarchies within the class facet or skos:broader hierarchies within the instance facet.\n  - e.g., rdfs:subClassOf hierarchies within the class facet or skos:broader hierarchies within the instance facet.\n  - In our example, the hierarchy between taxons is specified by the object property skos:broader\n\n```turtle\n:Polar_Bear a :Species; skos:broader :Bear.\n:Bear a :Genus; skos:broader :Bears.\n:Bears a :Family; skos:broader :Carnivores.\n:Carnivores a :Order; skos:broader :Mammals.\n:Mammals a :Class; skos:broader :Chordates.\n:Chordates a :Phylum; skos:broader :Animals.\n:Animals a :Kingdom.\n```\n\n  - t.2024.09.23.15 confusing \n    - why not `:Bear subClassOf :Bears` too\n    - why not `:Species skos:broader :Genus` \n\n#### Sample Properties\n\n1. :birth_date \"2006-12-05\" refers to an\ninstance of a concrete species, e.g., :Knut,\nonly.\n2. :population 31000 refers to a concrete\nspecies, genus, family etc., e.g.,\n:polar_bear, but cannot be inherited from\nbroader to narrower taxons, and not to their\ninstances.\n3. :conservation_status : vulnerable\nrefers to a concrete taxon, e.g., the species\n:polar_bear. If a conservation status would\nbe specified for an entire genus or family then\nit could be inferred that all species belonging\nto this genus or family have the same\nconservation status, hence can be inherited\nalong the skos:broader hierarchy.\nHowever, it cannot be inherited to instances of\nconcrete species like :Knut.\n4. :habitat :Terrestrial_habitat refers\nto a concrete species, genus, family etc., e.g.,\n:Bears, it can be inherited along the\nskos:broader hierarchy, e.g., from :Bears\nto :Bear and from :Bear to :Polar_bear.\nAdditionally, it can be inherited from concrete\nspecies like :Polar_Bear to instances of this\nspecies like :Knut.\n\n#### Property Behaviour Explication\n\n- in order to use inferencing for implementing inheritance behaviour, it is necessary to explicate the intended behaviour of properties like :birth_date, :population, :conservation_status, and :habitat. \n\n```turtle\n:conservation_status a rdfs:Property,\n:BroaderInheritedProperty.\n:habitat a rdfs:Property,\n:BroaderInheritedProperty,\n:TypeInheritedProperty\n```\n\n- :conservation_status and :habitat are of type :BroaderInheritedProperty in order to express that those properties can be inherited along the skos:broader hierarchy from broader to narrower taxons. \n- Additionally, :habitat is of type :TypeInheritedProperty in order to express that this property can additionally be inherited along the rdf:type relationship from classes to their instances.\n- so four possibilities, plus can apply to Object properties and Datatype properties\n\n### Querying and Inferencing\n\n```SPARQL\nSELECT *\nWHERE{:Knut ?p ?o.}\n```\n\n- will not contain any information about Knut’s habitat.\n- Likewise, a similar query for all information about the species polar bear will return all predicates and objects explicitly specified for the subject :Polar_Bear like :population 31000, but no information about the habitat of polar bears.\n  - because habitat information is specified for a broader taxon, here the family of bears.\n\n\n#### inheriting properties along skos:broader hierarchies\n\n```SPARQL\nINSERT {?s ?p ?o.}\nWHERE {?p a :BroaderInheritedProperty.\n?s skos:broader* ?b.\n?b ?p ?o.}\n```\n\n- This rule applies for RDF triples with predicates ?p that have been specified of type :BroaderInheritedProperty like, e.g., :conservation_status or :habitat.\n- If a subject ?s is in a transitive skos:broader relationship to some other subject `?b` then all triples with predicate ?p and object ?o can be inherited for subject ?s \n- Executing this SPARQL INSERT statement materializes the inferencing results in the ontology\n\n#### inheriting properties from classes to instances\n\n```SPARQL\nINSERT {?s ?p ?o.}\nWHERE {?p a :TypeInheritedProperty.\n?s a ?c.\n?c ?p ?o.}\n```\n\n- This rule applies for RDF triples with predicates ?p that have been specified of type :TypeInheritedProperty like, e.g., :habitat.\n- If a subject ?s is in a rdf:type relationship to some class ?c then all triples with predicate ?p and object ?o can be inherited for subject ?s .\n\n#### Notes\n\n- in practice, all rules have to be executed repeatedly until no rule fires any more, as is common in forward-chaining rule-based systems.\n- We have deliberately chosen an informal property like skos:broader for the AO in order to demonstrate how semantics for different use case contexts may be added incrementally, independently of the modelling style of the initial ontology\n  - If a more formally specified relationship like rdfs:subClassOf is deemed necessary in a certain use case context then a SPARQL rule for inferring rdfs:subClassOf relationships from skos:broader relationships may easily be added.\n\n### Discussion\n\n- rigorously utilizing the multi-facet behaviour for modelling ontologies supports simplicity, expressiveness, modularity, extensibility and flexibility.\n- Utilizing the multi-facet behaviour is more concise than using the materialization pattern\n- multi-facet behaviour could impede OWL DL reasoning\n- In (Frank, 2014), inheritance is restricted to the definition of properties, i.e., using a property specified in a higher-level object in a lower level. Inferring property values between facets (?) and along hierarchies within facets, e.g., rdfs:subClassOf or skos:broader, is not discussed.\n\n## References\n\n- [[book.practical-ontologies-for-information-professionals]]","n":0.024}}},{"i":6381,"$":{"0":{"v":"Amateur Fiction Online the Web of Community Trust","n":0.354},"1":{"v":"\n- https://eprints.soton.ac.uk/261042/1/case_study.pdf\n\n## Introduction\n\nThis paper considers two of three related projects that are currently being undertaken as part of a larger Human-Computer Interaction investigation into whether the seman- tic web can be brought to hobbyist groups on the Internet. The user group chosen as a case study for this project was online amateur fiction community. This community was chosen because it could benefit from Semantic Services in the form of improved searching, improved meta data, automatic recommendation amalgamations, trust-webs and personalisation of such systems. Because this is a Human-Computer Interaction project evaluation will be through usability tests comparing the developed systems to those that are currently available. This paper will first consider the work that has been done in the area of online com- munities and trust which relates to this project. It will then describe the way that user requirements were gathered from the user community through an online questionnaire as well as through direct interaction with volunteers from the community. Having de- fined the requirements of the community this paper will go on to describe two of the projects that are trying those needs. The first defines a foaf extension tailored to the needs of amateur writers and readers. This paves the way for the second project, adding a web of trust to the community and investigating whether this is a possible way of deal- ing with some of the community’s access control needs. Finally I will consider what the next steps in this research are.\n\n\n## References\n\n- [[ar.notes-about-semantic-web-tools-for-online-communities]]\n","n":0.063}}},{"i":6382,"$":{"0":{"v":"Agents and the Semantic Web","n":0.447},"1":{"v":"\n- url: https://www.nku.edu/~foxr/CSC625/NOTES/agents.ppt\n\n## Types of Environments\n\n* Accessible vs. inaccessible:  agent’s sensors give it access to the complete state of the environment at each point in time\n* Deterministic vs. non-deterministic:  next state of the environment is completely determined by the current state and the action executed by the agent\n* Episodic vs. non-episodic:  agent’s experience is divided into atomic episodes, each episode consisting of a perception-action pair where the action is a single action/event\n* Static vs. dynamic:  environment is unchanged during the agent’s deliberation of an action\n* Discrete vs. continuous:  limited number of distinct, clearly defined percepts and actions\n* Single agent:  the agent works in isolation (no other agents around)\n\n## Types of Agents\n\nReflex Agent\nsimplest form,  the agent merely reacts to its environment – no memory, no internal states, no planning\n\nState-based Agent\nthe next step up is an agent that keeps track of its current (and possibly previous) state(s), this can help with planning and understanding\n\nGoal-oriented Agent\nthis agent has the ability to plan out a sequence of states to achieve in order – planning might be based on a table-lookup approach or something more elaborate using a search mechanism and available planning knowledge\n\nUtility-based Agent\nthe agent has the ability to determine the usefulness of a plan step toward achieving its goals so that it can achieve the goals in a more optimal fashion, and possibly have better final results for goal\n\n![](/assets/images/2024-04-08-11-04-02.png)","n":0.067}}},{"i":6383,"$":{"0":{"v":"Agents and Artifacts a Meta Model for Agent Oriented Computing","n":0.316},"1":{"v":"\n- http://woa07.dibris.unige.it/papers/miniscuola_omicini.pdf\n- ","n":0.707}}},{"i":6384,"$":{"0":{"v":"Aeon","n":1},"1":{"v":"\n\n\n- [[p.hasSisterPublication]] [[ar.psyche]]\n","n":0.577}}},{"i":6385,"$":{"0":{"v":"You Have More in Common with a Psychopath than You Realise","n":0.302},"1":{"v":"\n\n## Highlights\n\n- \"psychopaths are simply better at turning their empathy on and off\"\n- \"what we recognise as morality might be grounded not simply in positive, prosocial emotions but also in negative, stressful and self-oriented ones\"\n\n- [[p.hasURL]] https://aeon.co/essays/you-have-more-in-common-with-a-psychopath-than-you-realise\n","n":0.164}}},{"i":6386,"$":{"0":{"v":"You Dont Have a Right to Believe Whatever You Want To","n":0.302},"1":{"v":"\n\n\"There is an ethic of believing, of acquiring, sustaining, and relinquishing beliefs – and that ethic both generates and limits our right to believe.\"\n\n- [[p.hasURL]] https://aeon.co/ideas/you-dont-have-a-right-to-believe-whatever-you-want-to\n## Highlights\n\n- Belief can be voluntary, but often more like an attitude or state of mind than a decisive action \n- \"irresponsible beliefs\" [[p.hasExample]] disregard evidence; accept gossip, rumour, or testimony from dubious sources; ignore incoherence with one’s other beliefs; embrace wishful thinking; or display a predilection for conspiracy theories\n- \"creed\" is a required belief\n","n":0.112}}},{"i":6387,"$":{"0":{"v":"Why Longtermism Is the Worlds Most Dangerous Secular Credo","n":0.333},"1":{"v":"\n- [[p.hasTopic]] [[idea.longtermism]]\n- [[p.hasURL]] https://aeon.co/essays/why-longtermism-is-the-worlds-most-dangerous-secular-credo?utm_source=Aeon+Newsletter&utm_campaign=0d691568e2-EMAIL_CAMPAIGN_2021_10_18_05_31&utm_medium=email&utm_term=0_411a82e59d-0d691568e2-72396600\n- [[p.hasAuthor]] @phil-torres\n- [[p.hasHighlight]]\n","n":0.354}}},{"i":6388,"$":{"0":{"v":"Is Life a Complex Computational Process","n":0.408},"1":{"v":"\n- https://aeon.co/essays/is-life-a-complex-computational-process\n\n## Highlights\n\n- If one is willing to accept the idea that modelling the world – by extracting information and making inferences about the environment – is constitutive of life, then life should arise everywhere and rather effortlessly. ","n":0.162}}},{"i":6389,"$":{"0":{"v":"Bad Thinkers","n":0.707},"1":{"v":"\n\nMistaken beliefs can be more the result of intellectual character (i.e., intellectual vices) than lack of knowledge\n\n- [[p.hasURL]] https://aeon.co/essays/the-intellectual-character-of-conspiracy-theorists\n- [[p.references]] [[book.virtues-of-the-mind]]\n\n","n":0.218}}},{"i":6390,"$":{"0":{"v":"Advanced Ontology Topics Events Roles Artifacts","n":0.408},"1":{"v":"\n- https://stids.c4i.gmu.edu/papers/STIDSPresentations/STIDS2013_Tutorial2_p2a_Obrst.pdf\n\n## Highlights\n\n### Design Principles\n\n- Take identity seriously\n  - Different identity criteria imply disjoint classes\n- Isolate a basic taxonomic structure\n  - Every entity must instantiate a rigid property with identity\n  - Physical objects can change parts and remain the same, but amounts of matter cannot\n  - Only sortals like “person” (as opposite to “red”) are good candidates for being taxons (classes in subclass relation)\n  - Sortals: objects which carry identity\n  - Categories: objects which generalize sortals\n- Make an explicit distinction between types and roles (and\nother property kinds)\n\n\n### Events\n\n- Events of all kinds are associated with a \"preparation\", or activity that brings the event about, and a \"consequent\", or ensuring state, in a tripartite data structure (from Moens, 1987): preparation :: event :: consequent","n":0.09}}},{"i":6391,"$":{"0":{"v":"'Adaptive Linked Data-Driven Web Components: Building Flexible and Reusable Semantic Web Interfaces'","n":0.289},"1":{"v":"\n- https://link.springer.com/chapter/10.1007/978-3-319-34129-3_41","n":0.707}}},{"i":6392,"$":{"0":{"v":"Aaronlynn","n":1}}},{"i":6393,"$":{"0":{"v":"Journals","n":1},"1":{"v":"\n\n\n- [[p.hasURL]] https://aaronlynn.com/journals/\n  ## Highlights\n","n":0.447}}},{"i":6394,"$":{"0":{"v":"How to Set up Your Personal Task Management System","n":0.333},"1":{"v":"\n\n\n- [[p.hasURL]] https://aaronlynn.com/personal-task-management/\n## Highlights\n","n":0.5}}},{"i":6395,"$":{"0":{"v":"A Universal Knowledge Model and Cognitive Architecture for Prototyping Agi","n":0.316},"1":{"v":"\n- https://www.researchgate.net/publication/381609189_A_Universal_Knowledge_Model_and_Cognitive_Architecture_for_Prototyping_AGI\n\n## Abstract\n\n- The article identified 42 cognitive architectures for creating general artificial intelligence (AGI) and proposed a set of interrelated functional blocks that an agent approaching AGI in its capabilities  should possess. Since the re- quired set of blocks is not found in any of the existing architectures, the article proposes a new cognitive architecture for intelligent systems approaching AGI in their capabilities. As one of the key solutions within the framework of the archi- tecture, a universal method of knowledge representation is proposed, which al- lows combining various non-formalized, partially and fully formalized methods of knowledge representation in a single knowledge base, such as texts in natural languages, images, audio  and video recordings, graphs, algorithms, databases, neural networks, knowledge graphs, ontologies, frames, essence-property-rela- tion models, production systems, predicate calculus models, conceptual models, and others. To  combine and  structure various  fragments of  knowledge, archi- graph models are used, constructed as a development of annotated metagraphs. As components,  the cognitive  architecture being developed  includes machine consciousness, machine subconsciousness, blocks of interaction with the external environment, a goal management block, an emotional control system, a block of social interaction, a block of reflection, an ethics block and a worldview block, a learning block, a monitoring block, blocks of statement and solving problems, self-organization and meta learning block","n":0.068}}},{"i":6396,"$":{"0":{"v":"A Temporal Rdf Model for Multi Grained Time Information Modeling","n":0.316},"1":{"v":"\n- url: https://dl.acm.org/doi/pdf/10.1145/3478905.3478908","n":0.577}}},{"i":6397,"$":{"0":{"v":"A Survey for Managing Temporal Data in Rdf","n":0.354},"1":{"v":"\n- url: https://www.sciencedirect.com/science/article/abs/pii/S0306437924000267\n","n":0.577}}},{"i":6398,"$":{"0":{"v":"A Review of the Semantic Web Field","n":0.378},"1":{"v":"\n- url: https://cacm.acm.org/research/a-review-of-the-semantic-web-field/\n\n## Resources\n\n- https://news.ycombinator.com/item?id=25907346","n":0.447}}},{"i":6399,"$":{"0":{"v":"A Reusable Ontology for Fluents in Owl","n":0.378},"1":{"v":"\n- https://www.researchgate.net/publication/221234960_A_Reusable_Ontology_for_Fluents_in_OWL\n- authors: @christopher-welty\n- published: 2006-01\n- topics: [[t.phil.perdurantism]]\n\n\n## Abstract\n\nA critical problem for practical KR is dealing with relationships that change over time. This problem is compounded by representation languages such as OWL that are biased towards binary relations, even when the relationships that vary with time are binary. We discuss several approaches to this problem in OWL, and focus on the advantages of a four-dimensionalist (perdurantist) solution, which allows us to use more of the expressive power of the language.\n\n## Highlights\n\n- synchronic, i.e. it refers to only one point in time\n- diachronic, vary with time\n- we consider fluents to be relations that hold within a certain time interval and not in others.\n- In the original formulation of fluents discussed by McCarthy&Hayes, another choice presented is to add a meta-logical predicate to relate the relationship to a time interval. \n  - e.g. holds(ceoOf(Sam, IBM), t 1 )\n    - OWL does not allow relationships themselves to participate in relationships, which this would require.\n- requirement: fluents are round-trip compatible with a representation in [[prdct.kif]] that uses *holds*\n  - they perform \"more advanced temporal reasoning\" with a special-purpose plugin for [[prdct.jtp]]\n\n### Solution Approaches for OWL\n\n#### Reification\n\n- turn each tuple in the extension of a relation into an object that itself has binary relationships, typically called\nroles, identifying all the elements of the tuple\n  - a reified relationship class, is created for each relation,\n  - e.g. for ceoOf(Sam, IBM, t 1 )\n\n```\nIndividual(IBM type(Company))\nIndividual(JohnsHopkinsUniversity type(University))\nIndividual(SamPalmisano type(Person))\nIndividual(Rel1 type(CeoOf)\nvalue(CeoOf:ceo SamPalmisano)\nvalue(CeoOf:company IBM)\nvalue(CeoOf:holds t 1))\n```\n\n- Reification has a number of known problems that are outlined in more detail in [Noy and Rector, 2005]. \n  - None of these are serious, but they are important to be aware of.\n  - proliferation of objects\n  - *Redundant Objects*. Since relationship reifications are objects, it is possible to create multiple objects that reify the same relationship, where in other languages that permit n-ary predicates there would only be one tuple in the extension of the corresponding relation. This can be problematic when using reasoners (such as Racer [Haarslev and Möller, 2001]) that make a unique names assumption, as these multiple objects if present can be counted twice when satisfying counting axioms such as cardinality constraints.  ^t9qzkemy80rd\n  - *Confusing ontology*. When classes and their instances are defined in an ontology, it is important to define what they refer to. The presence of reified relation classes and roles can create a confusion between events and fluents if one is not careful.\n    - t.2024.08.07.03 yeah, but just be careful\n  - *Limited use of OWL reasoning*. The use of OWL language constructs becomes severely limited with reified relationships\n    - simple reasoning about inverses can have the highest impact\n    - There is no a priori way todetermine which direction may be of more use to an end user.\n    -  Reification prevents us from being able to express in OWL the relation inverses, ^zqsq4cdml6ud\n       -  thus we are stuck with whichever direction is stated in the text\n    -  Reification also prevents usage of the OWL operators transitive, symmetric, functional, and inverseFunctional on the intended relation.\n   -  Local range restrictions on properties in the reified relation class must also be understood to be global restrictions on the intended relation. \n      -  To express the equivalent of local range restrictions on the intended relation, one must use nested restrictions on the role inverses\n         - e.g. \n```\nObjectProperty(ManagerRel:manages\n  inverseOf(ManagerRel:managedBy))\nClass(Person partial\n  Restriction(ManagerRel:managedBy\n    allValuesFrom(\n      restriction(ManagerRel:manager\n        allValuesFrom(Person)))\n```\n\n  - Finally, for representing binary fluents, cardinality and value restrictions on the role inverses end up restricting the intended relation for all time\n    - e.g. we cannot express in OWL that a person can have at most one manager at a time.\n    - the most we can say is a person can have at most one manager\n    - In most cases where such an axiom may be useful, e.g. the hasMother relation, it’s not clear the relation should be a fluent at all. \n    - At the very least, in our ontologies we could not find a use for cardinality or value restrictions on the role inverses.\n\n#### Temporal Description Logics\n\n-  temporal description logics reduce to a modal logic, in which times (or situations) are removed from the syntax and instead are part of the implicit quantification with only one ordering relation.\n   -  we are unable to talk about what is true at any particular time in a temporal DL, we can only quantify over past and future times\n   - we can not use the full Allen calculus, which is critical to our application\n\n#### The Four-Dimensional Approach\n\n- When two entities participate in some fluent, the fluent holds between temporal parts of those entities.\n\n##### high-level and reusable ontology in OWL for 4D fluents\n\n```\n(Ontology 4dFluents\n  (Class TimeSlice)\n  (DisjointClasses TimeSlice TimeInterval)\n  (Property fluentProperty Symmetric\n    (domain TimeSlice)\n    (range TimeSlice))\n  (Property tsTimeSliceOf functional\n    (domain TimeSlice)\n    (range complementOf(TimeInterval)))\n  (Property tsTimeInterval Functional\n    (domain TimeSlice)\n    (range TimeInterval)))\n```\n\n- As is often the case with high-level ontologies, there are more intended semantic constraints than can be expressed in OWL. \n  - we intend that time slices be maximal with respect to the time interval of all fluents it participates in.\n    - i.e., the time interval of a time slice is defined to be the duration of the fluent holding.\n    - Thus if a time slice participates in more than one fluent, they (the fluents) must hold for precisely the same interval.\n      - t.2024.08.02.06 seems problematic\n  - two time slices of the same entity for the same interval are equal.\n- In our system, it is the responsibility of the component that transforms the output of text analysis into the knowledge-base to enforce these semantics\n- The first advantage of the 4D representation is that we can use the OWL inverse operator in the expected way, as shown in the example ontology.\n- Transitivity and symmetry also have the expected meaning, allowing us to express many spatial axioms in the OWL ontology:\n- Cardinality restrictions can also be expressed with this approach in a way that was useful for our domain. We had several intended relations whose semantics required temporally qualified cardinality, such as “a company has at-most one CEO at a time”. \n  - does not prevent the unintended model in which a company has two overlapping time slices that have a hasCeo relation to different people\n- The 4D approach is the worst among the approaches discussed here with respect to the proliferation of objects. \n  - A single fluent requires two extra objects (the time slices) and four triples.\n\n## Conclusion\n\n- reification of relationships further limits the use of what limited expressiveness OWL already has\n- ","n":0.03}}},{"i":6400,"$":{"0":{"v":"A Preliminary Poetics for Interactive Drama and Games","n":0.354},"1":{"v":"\n- https://users.soe.ucsc.edu/~michaelm/publications/mateas-dc-2001.pdf\n\n## Highlights\n\n### Introduction\n\n- The game industry has been producing plot-based interactive experiences (adventure games) since the beginning of the industry, but only a few of them (such as The Last Express) begin to approach the status of interactive drama.\n- Part of the difficulty in achieving interactive drama is due to the lack of a theoretical framework guiding the exploration of the technological and design issues surrounding it.\n- This paper proposes a theory of interactive drama based on Aristotle’s dramatic theory but modified to address the interactivity added by player agency.\n- In addition to clarifying notions of interactive drama, the model developed in this paper also provides a general framework for analysing player agency in any interactive experience (e.g. interactive games).\n- This neo-Aristotelian theory integrates Murray’s (1998) proposed aesthetic categories for interactive stories and Aristotle’s structural categories for drama (Aristotle 330 BC).\n\n\n## References\n\n- [[book.hamlet-on-the-holodeck]]","n":0.083}}},{"i":6401,"$":{"0":{"v":"A Non Euclidean View of California as a Cold Place to Be","n":0.289},"1":{"v":"\n- author: @ursula-leguin\n- url: https://bpb-us-e1.wpmucdn.com/sites.ucsc.edu/dist/9/20/files/2019/07/1989a_Le-Guin_non-Euclidean-view-California.pdf\n\n\n## Highilghts\n\n- Usà puyew usu wapiw! \"The opening formula for a Cree story is “an invitation to listen , followed by the phrase ‘I go backward, look forward, as the porcupine does.’”\n- Victor Turner’s antitheses of structure and communitas are useful to my attempt to think about it: structure in society, in his terms, is cognitive, communitas existential; structure provides a model, communitas a pot ential; structure classifies , communitas reclassifies ; structure is expressed in legal and political institutions, communitas in art and religion.\n- Utopian thought has often sought to institutionalize or legislate the experience of communitas, and each time it has done so it has run up against the Grand Inquisitor.\n- \"The activities of a machine are determined by its structure, but the relation is reversed in organisms — organic structure is determined by its processes.\"\n  - Fritjof Capra, The Turning Point ","n":0.082}}},{"i":6402,"$":{"0":{"v":"A Knowledge Graph Approach to Predict and Interpret Disease Causing Gene Interactions","n":0.289},"1":{"v":"\n- https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-023-05451-5","n":0.707}}},{"i":6403,"$":{"0":{"v":"A Formal Approach for Customization of Schema Org Based on Shacl","n":0.302},"1":{"v":"\nhttps://arxiv.org/pdf/1906.06492\n\n## Abstract\n\nSchema.org is a widely adopted vocabulary for semantic annotation of content and data. However, its generic nature makes it com- plicated for data publishers to pick right types and properties for a specific domain and task. In this paper we propose a formal approach, a domain specification process that generates domain specific patterns by applying operators implemented in SHACL to the schema.org vocabulary. These patterns can support knowledge generation and assessment processes for specific domains and tasks. We demonstrated our approach with use cases in tourism domain.","n":0.107}}},{"i":6404,"$":{"0":{"v":"A First Order Logic Formalization of the Unified Foundational Ontology","n":0.316},"1":{"v":"\n- url: https://github.com/unibz-core/ufo-formalization/blob/development/formalization.pdf\n\n## Description\n\n- This document presents a formalization of the Unified Foundational Ontology (UFO) in first- order logic. This formalization is documented by means of three complementary representations: (i) a representation in standard [[prdct.common-logic]] using the CLIF syntax; (ii) a representation in natural language; and, when applicable, (iii) a UML-based diagrammatic representation. The presented formalization is supported by consistency and satisfiability checks performed through automated proofing tools.\n\nn- coded in the ontologies, to include more abstract and philosophical semantic relations and semiotic matching, to take advantage of structural features of the ontologies and axioms in order to better compare their formal definitions, and to take advantage of background knowledge from external resources targeting subsumption and other semantic relations. These have to be combined with logical reasoning techniques for guarantee the consis- tency of the generated alignments. The current approaches have to be hence revised to better deal with the specificities of matching foundational ontologies.","n":0.081}}},{"i":6405,"$":{"0":{"v":"A Fipa Compliant Agent Framework Integrating Protege 2000","n":0.354},"1":{"v":"\n- https://protege.stanford.edu/conference/2004/posters/Caron2.pdf\n- topics: [[t.cs.multi-agent-system]] [[prdct.Jade]] [[t.km.ontology]] [[prdct.protege]] [[t.km]] [[t.cs.semantic-web]]","n":0.333}}},{"i":6406,"$":{"0":{"v":"A Decentralized Architecture for Sharing and Querying Semantic Data","n":0.333},"1":{"v":"\n- https://qweb.cs.aau.dk/piqnic/files/ESWC2019.pdf\n\n\n## Abstract\n\nAlthough the Semantic Web in principle provides access to a vast Web of interlinked data, the full potential currently remains mostly unexploited. One of the main reasons is the fact that the architecture of the current Web of Data relies on a set of servers providing access to the data. These servers represent bottlenecks and single points of failure that result in instability and unavailability of data at certain points in time. In this paper, we therefore propose a decentralized architecture (Piqnic) for sharing and querying semantic data. By combining both client and server functionality at each participating node and introduc- ing replication, Piqnic avoids bottlenecks and keeps datasets available and queryable although the original source might (temporarily) not be available. Our experimental results using a standard benchmark of real datasets show that Piqnic can serve as an architecture for sharing and querying semantic data, even in the presence of node failures.","n":0.081}}},{"i":6407,"$":{"0":{"v":"A Comprehensive Overview of Rdf for Spatial and Spatiotemporal Data Management","n":0.302},"1":{"v":"\n## Abstract\n\nCurrently, a large amount of spatial and spatiotemporal RDF data has been shared and exchanged on the Internet and various applications. Resource Description Framework (RDF) is widely accepted for rep- resenting and processing data in different (including spatiotemporal) application domains. The effective management of spatial and spatiotemporal RDF data are becoming more and more important. A lot of work has been done to study how to represent, query, store, and manage spatial and spatiotemporal RDF data. In order to grasp and learn the main ideas and research results of spatial and spatiotemporal RDF data, in this paper, we provide a comprehensive overview of RDF for spatial and spatiotemporal data management. We summarize spatial and spatiotemporal RDF data management from several essential aspects such as representation, querying, storage, performance assessment, datasets, and management tools. In addition, the direction of future research and some comparisons and analysis are also discussed in depth.\n\n","n":0.081}}},{"i":6408,"$":{"0":{"v":"A Comparison of Upper Ontologies","n":0.447},"1":{"v":"\n- author: @viviana-mascardi @valentina-cordi @paolo-rosso\n- url: https://person.dibris.unige.it/mascardi-viviana/Download/DISI-TR-06-21.pdf\n- comparands: [[prdct.basic-formal-ontology]] [[prdct.cyc]] \n- \n\n## Abstract\n\nUpper Ontologies are quickly becoming a key technology for inte- grating heterogeneous knowledge coming from different sources. In this techni- cal report we analyse 7 Upper Ontologies, namely BFO, Cyc, DOLCE, GFO, PROTON, Sowa’s ontology, and SUMO, according to a set of standard software engineering criteria, and we synthesise our analysis in form of a comparative ta- ble. A summary of some existing comparisons drawn among subsets of the 7 Upper Ontologies that we deal with in this document, is also provided.\n\n## Comparisons\n\n### Pease’s comparison of DOLCE and SUMO\n\n- DOLCE is an “ontology of particulars”; it does have universals (classes and properties), but the claim is that they are only employed in the service of describing particulars. In contrast, SUMO could be described as an ontology of both particulars and universals. It has a hierarchy of properties as well as classes\n- With respect to SUMO, DOLCE does not include such items as a hierarchy of process types, physical objects, organisms, units and measures, and event roles.\n![[book.ontology-a-practical-guide#^79dmzjqovfhx]]\n\n### Onto-Med’s comparison of GFO, DOLCE, and Sowa’s ontology\n\n In DOLCE, levels of reality are not introduced explicitly, while in GFO the authors explicitly distinguish three levels of reality.\n","n":0.07}}},{"i":6409,"$":{"0":{"v":"A Common Ground for Virtual Humans","n":0.408},"1":{"v":"\n- https://ict.usc.edu/pubs/A%20Common%20Ground%20for%20Virtual%20Humans-%20Using%20an%20Ontology%20in%20a%20Natural%20%20%20Language%20Oriented%20Virtual%20Human%20Architecture.pdf  \n\n\n## Highlights\n\n- We have a common, general-purpose world ontology. Most classes, like ‘Person’ and ‘Action’, are defined here. Inheriting the world ontology and adding more specialized knowledge shared by multiple scenarios—locations, props, characters and basic task structures—is the scenario family level. This allows us easily to share certain information over a set of closely-related scenarios. Finally, at the lowest level, we have a scenario ontology that stores scenario-specific information.","n":0.119}}},{"i":6410,"$":{"0":{"v":"A Commitment Based Reference Ontology for Services","n":0.378},"1":{"v":"\n- https://www.researchgate.net/publication/274700112_A_Commitment-based_Reference_Ontology_for_Services\n- topics: [[prdct.unified-foundational-ontology.ufo-c]] \n- publish-date: 2015\n\n\n## Abstract\n\n- The concept of “service” has been characterized in different disciplines and by different authors from various points of view. This variety of characterizations has emerged because although this notion seems intuitive, it is far from trivial, with many interrelated perspectives . Given their importance in enterprise computing and Service Science in general, we believe that a clear account of services and service -related concepts is necessary and would serve as a basis for communication, consensus and alignment among approaches and perspectives. In this paper we propose a commitment-based account of the notion of service captured in a core reference ontology called UFO-S. We address the commitments established between service providers and customers, and show how such commitments affect the service lifecycle. Moreover, we show that the commitment-based account can serve to harmonize different notions of service in the literature.\n\n## Highlights\n\n### UFO-C\n\n\n","n":0.082}}},{"i":6411,"$":{"0":{"v":"A Comics Ontology","n":0.577},"1":{"v":"\n- https://paulrissen.com/2012/04/17/a-comics-ontology/\n- author: @paul-rissen","n":0.5}}},{"i":6412,"$":{"0":{"v":"A Brief Ontology of Time","n":0.447},"1":{"v":"\n- url: https://caminao.blog/2018/05/23/a-brief-ontology-of-time/\n\n## Questions\n\n- \" ontologies are at their best when a distinction can be maintained between representation and semantics\"\n- ","n":0.224}}},{"i":6413,"$":{"0":{"v":"A Brief Note on How Phenomenal Objects Relate to Objects Themselves","n":0.302},"1":{"v":"\n- https://www.researchgate.net/publication/233612708_A_Brief_Note_on_How_Phenomenal_Objects_Relate_to_Objects_Themselves\n- author: @max-velmans\n- related: \n\n## Highlights\n\n- “…there  is  just  one  material  cat  out  there  in  the  world—the  “noumenal”  cat  which  exists whether the subject perceives it or not.  When the subject or the external observer looks at the noumenal cat, it is a phenomenal cat that they see. So we have a cat itself (the noumenal cat) whose  existence  and  nature  is  observer-independent,  and  a  seen  (phenomenal)  cat  that represents the noumenal cat, whose existence and nature is observer-dependent.  In everyday life we usually think of the cat we see as a “physical cat” and, for the purposes of everyday life, we usually treat it as being the cat itself rather than a representation of the cat itself.  But this does not double the number of actual cats, not does it ‘smear’ any additional phenomenal cats all  over  the  noumenal  cat.  Rather,  the one,  noumenal  cat  has  as  many  numerically  distinct appearances as there are views of it by individual observers.” (Velmans, 2008, p41) ^2a0y73y0gq9x\n\n- “... strictly speaking ...it is always the cat itself that one is looking at although it is a \nphenomenal cat that one sees, which makes the phenomenal cat the observation and the \ncat itself the observed. In everyday life we blur these distinctions for the reason that we \nhabitually treat phenomenal objects to be the observed objects for the reason that this is \nhow those objects appear to us. I will return to some of these distinctions below, when they \nbecome important to the issues under discussion—and I have unravelled them in depth in \nVelmans (2000) chapters 6, 7, and 8.”  (Ibid, p10, note 7) \n","n":0.061}}}]}
